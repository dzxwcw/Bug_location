<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="CALCITE">
  <bug id="1664" opendate="2017-2-27 00:00:00" fixdate="2017-5-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CAST(&amp;#39;&lt;string&gt;&amp;#39; as TIMESTAMP) adds part of sub-second fraction to the value</summary>
      <description>select TIMESTAMP '2016-02-26 19:06:00', CAST('2016-02-26 19:06:00' as TIMESTAMP); +---------------------+---------------------+ | EXPR$0 | EXPR$1 | +---------------------+---------------------+ | 2016-02-26 19:06:00 | 2016-02-26 19:06:00 | +---------------------+---------------------+!okselect TIMESTAMP '2016-02-26 19:06:00.1', CAST('2016-02-26 19:06:00.1' as TIMESTAMP), TIMESTAMPDIFF(SECOND, TIMESTAMP '2016-02-26 19:06:00.1', CAST('2016-02-26 19:06:00.1' as TIMESTAMP)); +---------------------+---------------------+--------+ | EXPR$0 | EXPR$1 | EXPR$2 | +---------------------+---------------------+--------+ | 2016-02-26 19:06:00 | 2016-02-26 19:06:00 | 0 | +---------------------+---------------------+--------+!okselect TIMESTAMP '2016-02-26 19:06:00.123456', CAST('2016-02-26 19:06:00.123456' as TIMESTAMP), TIMESTAMPDIFF(SECOND, TIMESTAMP '2016-02-26 19:06:00.123456', CAST('2016-02-26 19:06:00.123456' as TIMESTAMP)); +---------------------+---------------------+--------+ | EXPR$0 | EXPR$1 | EXPR$2 | +---------------------+---------------------+--------+ | 2016-02-26 19:06:00 | 2016-02-26 19:08:03 | 123 | +---------------------+---------------------+--------+!okselect TIMESTAMP '2016-02-26 19:06:00.12345678', CAST('2016-02-26 19:06:00.12345678' as TIMESTAMP), TIMESTAMPDIFF(SECOND, TIMESTAMP '2016-02-26 19:06:00.123456789', CAST('2016-02-26 19:06:00.123456789' as TIMESTAMP)); +---------------------+---------------------+--------+ | EXPR$0 | EXPR$1 | EXPR$2 | +---------------------+---------------------+--------+ | 2016-02-26 19:06:00 | 2016-02-26 22:31:46 | 123456 | +---------------------+---------------------+--------+!okNote how TIMESTAMP &lt;string&gt; parses the value correctly (not sure if the sub-second fraction is parsed though) but CAST adds part of the sub-second fraction as a seconds to the value.</description>
      <version>None</version>
      <fixedVersion>avatica-1.10.0,1.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">core.src.test.resources.sql.misc.iq</file>
      <file type="M">avatica.core.src.test.java.org.apache.calcite.avatica.util.DateTimeUtilsTest.java</file>
      <file type="M">avatica.core.src.main.java.org.apache.calcite.avatica.util.DateTimeUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="1682" opendate="2017-3-8 00:00:00" fixdate="2017-4-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>New metadata providers for expression column origin and all predicates in plan</summary>
      <description>I am working on the integration of materialized view rewriting within Hive.Once a view matches an operator plan, rewriting is split vastly in two steps. The first step will verify that the input to the root operator of the matched plan is equivalent or contained within the input to the root operator of the query representing the view. The second step will trigger a unify rule, which tries to rewrite the matched operator tree into a scan on the view and possibly some additional operators to compute the exact results needed by the query (think about Project that alters the column order, additional Filter on the view, additional Join operation, etc.)If we focus on step 1, checking equivalence/containment, I would like to extend the metadata providers in Calcite to give us more information about the matched (sub)plan. In particular, I am thinking on: Expression column origin. Currently Calcite can provide the column origins for a certain column and whether it is derived or not. However, we would need to obtain the expression that generated a certain column. This expression should contain references to the input tables. For instance, given expression column c, the new md provider would return that it was generated by expression A.a + B.b. All predicates. Currently Calcite can extract predicates that have been applied on an RelNode output (we can think on them as constraints on the output). However, I would like to extract all predicates that have been applied on a given RelNode (sub)plan. Since nodes might not be part of the output, expressions should contain references to the input tables. For instance, the new md provider might return the expressions A.a + B.b &gt; C.c AND D.d = 100. PK-FK relationship. I do not plan to implement this one immediately. However, exposing this information (given it is provided) can help us to trigger more rewriting containing join operators. Thus, I was wondering if it is worth adding it.Once this information is available, we can rely on it to implement logic similar to &amp;#91;1&amp;#93; to check whether a given (sub)plan is equivalent/contained within a given view.One question I have is about representing the table columns as a RexNode, as I think it is the easiest way to be returned by the new metadata providers. I checked RexPatternFieldRef and I think it will meet our requirements: alpha would be the qualified table name, while the index is the column idx for the table. Thoughts?I have started working on this and will provide a patch shortly; feedback is greatly appreciated.&amp;#91;1&amp;#93; ftp://ftp10.us.freebsd.org/users/azhang/disc/SIGMOD/pdf-files/331/202-optimizing.pdf</description>
      <version>1.12.0</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">core.src.test.resources.org.apache.calcite.test.RelOptRulesTest.xml</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.RelMetadataTest.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.util.BuiltInMethod.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql.SqlKind.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.rex.RexVisitorImpl.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.rex.RexVisitor.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.rex.RexUtil.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.rex.RexSimplify.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.rex.RexShuttle.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.rex.RexBiVisitor.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.rex.LogicVisitor.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.rel.metadata.RelMetadataQuery.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.rel.metadata.RelMdUtil.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.rel.metadata.DefaultRelMetadataProvider.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.rel.metadata.BuiltInMetadata.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.plan.RelOptUtil.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.plan.RelOptCluster.java</file>
    </fixedFiles>
  </bug>
  <bug id="1694" opendate="2017-3-14 00:00:00" fixdate="2017-3-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clash in protobuf versions between Avatica and Hadoop</summary>
      <description>When running Pig adapter tests, we get the following stack:java.lang.NoClassDefFoundError: com/google/protobuf/GeneratedMessageV3 at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:760) at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) at java.net.URLClassLoader.defineClass(URLClassLoader.java:455) at java.net.URLClassLoader.access$100(URLClassLoader.java:73) at java.net.URLClassLoader$1.run(URLClassLoader.java:367) at java.net.URLClassLoader$1.run(URLClassLoader.java:361) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:360) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at org.apache.calcite.avatica.ConnectionPropertiesImpl.&lt;clinit&gt;(ConnectionPropertiesImpl.java:37) at org.apache.calcite.avatica.MetaImpl.&lt;init&gt;(MetaImpl.java:71) at org.apache.calcite.jdbc.CalciteMetaImpl.&lt;init&gt;(CalciteMetaImpl.java:82) at org.apache.calcite.jdbc.Driver.createMeta(Driver.java:169) at org.apache.calcite.avatica.AvaticaConnection.&lt;init&gt;(AvaticaConnection.java:118) at org.apache.calcite.jdbc.CalciteConnectionImpl.&lt;init&gt;(CalciteConnectionImpl.java:113) at org.apache.calcite.jdbc.CalciteJdbc41Factory$CalciteJdbc41Connection.&lt;init&gt;(CalciteJdbc41Factory.java:114) at org.apache.calcite.jdbc.CalciteJdbc41Factory.newConnection(CalciteJdbc41Factory.java:59) at org.apache.calcite.jdbc.CalciteJdbc41Factory.newConnection(CalciteJdbc41Factory.java:44) at org.apache.calcite.jdbc.CalciteFactory.newConnection(CalciteFactory.java:53) at org.apache.calcite.avatica.UnregisteredDriver.connect(UnregisteredDriver.java:143) at java.sql.DriverManager.getConnection(DriverManager.java:664) at java.sql.DriverManager.getConnection(DriverManager.java:208) at org.apache.calcite.test.CalciteAssert$MapConnectionFactory.createConnection(CalciteAssert.java:1151) at org.apache.calcite.test.CalciteAssert$AssertQuery.createConnection(CalciteAssert.java:1189) at org.apache.calcite.test.CalciteAssert$AssertQuery.returns(CalciteAssert.java:1260) at org.apache.calcite.test.CalciteAssert$AssertQuery.explainMatches(CalciteAssert.java:1350) at org.apache.calcite.test.CalciteAssert$AssertQuery.explainContains(CalciteAssert.java:1345) at org.apache.calcite.test.PigAdapterTest.testImplWithGroupByMultipleFields(PigAdapterTest.java:116) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:483) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51) at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:237) at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:483) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)Caused by: java.lang.ClassNotFoundException: com.google.protobuf.GeneratedMessageV3 at java.net.URLClassLoader$1.run(URLClassLoader.java:372) at java.net.URLClassLoader$1.run(URLClassLoader.java:361) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:360) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ... 58 morefollowed byjava.lang.NoClassDefFoundError: Could not initialize class org.apache.calcite.avatica.ConnectionPropertiesImpl at org.apache.calcite.avatica.MetaImpl.&lt;init&gt;(MetaImpl.java:71) at org.apache.calcite.jdbc.CalciteMetaImpl.&lt;init&gt;(CalciteMetaImpl.java:82) at org.apache.calcite.jdbc.Driver.createMeta(Driver.java:169) at org.apache.calcite.avatica.AvaticaConnection.&lt;init&gt;(AvaticaConnection.java:118) at org.apache.calcite.jdbc.CalciteConnectionImpl.&lt;init&gt;(CalciteConnectionImpl.java:113) at org.apache.calcite.jdbc.CalciteJdbc41Factory$CalciteJdbc41Connection.&lt;init&gt;(CalciteJdbc41Factory.java:114) at org.apache.calcite.jdbc.CalciteJdbc41Factory.newConnection(CalciteJdbc41Factory.java:59) at org.apache.calcite.jdbc.CalciteJdbc41Factory.newConnection(CalciteJdbc41Factory.java:44) at org.apache.calcite.jdbc.CalciteFactory.newConnection(CalciteFactory.java:53) at org.apache.calcite.avatica.UnregisteredDriver.connect(UnregisteredDriver.java:143) at java.sql.DriverManager.getConnection(DriverManager.java:664) at java.sql.DriverManager.getConnection(DriverManager.java:208) at org.apache.calcite.test.CalciteAssert$MapConnectionFactory.createConnection(CalciteAssert.java:1151) at org.apache.calcite.test.CalciteAssert$AssertQuery.createConnection(CalciteAssert.java:1189) at org.apache.calcite.test.CalciteAssert$AssertQuery.returns(CalciteAssert.java:1260) at org.apache.calcite.test.CalciteAssert$AssertQuery.explainMatches(CalciteAssert.java:1350) at org.apache.calcite.test.CalciteAssert$AssertQuery.explainContains(CalciteAssert.java:1345) at org.apache.calcite.test.PigAdapterTest.testImplWithMultipleFilters(PigAdapterTest.java:59) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:483) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51) at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:237) at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:483) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)If you explicitly load ConnectionPropertiesImpl by adding the lineUtil.discard(org.apache.calcite.avatica.ConnectionPropertiesImpl.class);to PigSchemaFactory the error goes away.I think the problem might be that the Pig adapter pulls in Pig, which pulls in Hadoop, which depends on protobuf 2, whereas Avatica's ConnectionPropertiesImpl has some members that depend on protobuf 3.We can work around by having the Pig adapter load Calcite's MetaImpl (thereby avoiding an explicit dependency of the Pig adapter on Avatica).But the real solution, I think, is too reduce the dependencies of ConnectionPropertiesImpl. Calcite (and other Avatica users) do not care about the protobuf implementation of Avatica's wire protocol, but protobuf gets loaded due to the fromProto(Common.ConnectionProperties) method.elserj, What do you think?</description>
      <version>None</version>
      <fixedVersion>1.12.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">pig.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1702" opendate="2017-3-16 00:00:00" fixdate="2017-3-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support extended columns in DML</summary>
      <description>DML support was partially implemented in CALCITE-493.I am working on a patch for the implementation and tests.</description>
      <version>1.12.0</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">core.src.test.resources.org.apache.calcite.test.SqlToRelConverterTest.xml</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.SqlValidatorTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.SqlToRelTestBase.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.SqlToRelConverterTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.MockCatalogReader.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.sql.test.SqlAdvisorTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.sql.parser.SqlParserTest.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql.validate.TableNamespace.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql.validate.SqlValidatorUtil.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql.validate.SqlValidatorTable.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql.validate.SqlValidatorImpl.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql.validate.IdentifierNamespace.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql2rel.StandardConvertletTable.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql2rel.SqlToRelConverter.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql2rel.NullInitializerExpressionFactory.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql2rel.InitializerExpressionFactory.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.schema.impl.ViewTableMacro.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.schema.impl.ViewTable.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.schema.impl.ModifiableViewTable.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.prepare.Prepare.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.plan.RelOptUtil.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.plan.RelOptTable.java</file>
      <file type="M">core.src.main.codegen.templates.Parser.jj</file>
    </fixedFiles>
  </bug>
  <bug id="1707" opendate="2017-3-17 00:00:00" fixdate="2017-4-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Push Extraction filter on Year/Month/Day to druid</summary>
      <description>This will enable pushing down of filter with time extraction to druid.Only day/month/year is supported.</description>
      <version>1.12.0</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">druid.src.test.java.org.apache.calcite.test.DruidAdapterIT.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.TimeExtractionFunction.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.DruidRules.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.DruidQuery.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.DruidDateTimeUtils.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.rel.rules.DateRangeRules.java</file>
    </fixedFiles>
  </bug>
  <bug id="1714" opendate="2017-3-20 00:00:00" fixdate="2017-3-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Do not push group by on druid metrics fields</summary>
      <description>Druid does not support grouping by metrics, hence we can not push the group by to druid. Instead we should generate a select query.</description>
      <version>1.12.0</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">druid.src.test.java.org.apache.calcite.test.DruidAdapterIT.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.DruidRules.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.DruidQuery.java</file>
    </fixedFiles>
  </bug>
  <bug id="1715" opendate="2017-3-20 00:00:00" fixdate="2017-3-20 01:00:00" resolution="Resolved">
    <buginformation>
      <summary>Cassandra adapter is broken by Guava change</summary>
      <description>The Cassandra driver appears to be incompatible with Guava 20. Works fine when downgrading to Guava 18. Stack trace of the exception produced when trying to connect via sqlline below:java.lang.NoSuchMethodError: com.google.common.util.concurrent.Futures.transform(Lcom/google/common/util/concurrent/ListenableFuture;Lcom/google/common/util/concurrent/AsyncFunction;Ljava/util/concurrent/Executor;)Lcom/google/common/util/concurrent/ListenableFuture; at com.datastax.driver.core.Connection.initAsync(Connection.java:182) at com.datastax.driver.core.Connection$Factory.open(Connection.java:796) at com.datastax.driver.core.ControlConnection.tryConnect(ControlConnection.java:253) at com.datastax.driver.core.ControlConnection.reconnectInternal(ControlConnection.java:201) at com.datastax.driver.core.ControlConnection.connect(ControlConnection.java:79) at com.datastax.driver.core.Cluster$Manager.init(Cluster.java:1483) at com.datastax.driver.core.Cluster.init(Cluster.java:159) at com.datastax.driver.core.Cluster.connectAsync(Cluster.java:330) at com.datastax.driver.core.Cluster.connect(Cluster.java:280) at org.apache.calcite.adapter.cassandra.CassandraSchema.&lt;init&gt;(CassandraSchema.java:109) at org.apache.calcite.adapter.cassandra.CassandraSchemaFactory.create(CassandraSchemaFactory.java:40) at org.apache.calcite.model.ModelHandler.visit(ModelHandler.java:215) at org.apache.calcite.model.JsonCustomSchema.accept(JsonCustomSchema.java:45) at org.apache.calcite.model.ModelHandler.visit(ModelHandler.java:143) at org.apache.calcite.model.ModelHandler.&lt;init&gt;(ModelHandler.java:85) at org.apache.calcite.jdbc.Driver$1.onConnectionInit(Driver.java:104) at org.apache.calcite.avatica.UnregisteredDriver.connect(UnregisteredDriver.java:145) at sqlline.DatabaseConnection.connect(DatabaseConnection.java:157) at sqlline.DatabaseConnection.getConnection(DatabaseConnection.java:203) at sqlline.Commands.connect(Commands.java:1064) at sqlline.Commands.connect(Commands.java:996) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at sqlline.ReflectiveCommandHandler.execute(ReflectiveCommandHandler.java:38) at sqlline.SqlLine.dispatch(SqlLine.java:809) at sqlline.SqlLine.begin(SqlLine.java:686) at sqlline.SqlLine.start(SqlLine.java:398) at sqlline.SqlLine.main(SqlLine.java:291)</description>
      <version>1.12.0</version>
      <fixedVersion>1.12.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1716" opendate="2017-3-20 00:00:00" fixdate="2017-3-20 01:00:00" resolution="Resolved">
    <buginformation>
      <summary>Cassandra integration tests broken due to change in CAST behavior</summary>
      <description>Small fixes needed to expected test output.</description>
      <version>None</version>
      <fixedVersion>1.12.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">cassandra.src.test.java.org.apache.calcite.test.CassandraAdapterIT.java</file>
    </fixedFiles>
  </bug>
  <bug id="1722" opendate="2017-3-23 00:00:00" fixdate="2017-3-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Druid adapter uses un-scaled value of DECIMAL literals</summary>
      <description>We have 2 issue here:1 Major, it is the lose of precision when converting filters with double values eg value &lt; 1.455 For instance this is an example of wrong plan due to this bug. explain select d_year from ssb_druid where cast(d_year as double) &lt; 1.2221;OKPlan optimized by CBO.Stage-0 Fetch Operator limit:-1 Select Operator [SEL_1] Output:["_col0"] TableScan [TS_0] Output:["d_year"],properties:{"druid.query.json":"{\"queryType\":\"select\",\"dataSource\":\"ssb_druid\",\"descending\":false,\"intervals\":[\"1900-01-01T00:00:00.000/3000-01-01T00:00:00.000\"],\"filter\":{\"type\":\"bound\",\"dimension\":\"d_year\",\"upper\":\"12221\",\"upperStrict\":true,\"alphaNumeric\":true},\"dimensions\":[\"d_year\"],\"metrics\":[],\"granularity\":\"all\",\"pagingSpec\":{\"threshold\":16384,\"fromNext\":true},\"context\":{\"druid.query.fetch\":false}}","druid.query.type":"select"}The second issue (Minor) is to use ordering instead of Alphanumeric, this is needed when comparing floats/doubles.</description>
      <version>1.12.0</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">druid.src.test.java.org.apache.calcite.test.DruidAdapterIT.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.DruidQuery.java</file>
    </fixedFiles>
  </bug>
  <bug id="1723" opendate="2017-3-27 00:00:00" fixdate="2017-3-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Match DruidProjectFilterTransposeRule against DruidQuery</summary>
      <description>Follow-up CALCITE-1683.</description>
      <version>None</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.DruidRules.java</file>
    </fixedFiles>
  </bug>
  <bug id="1724" opendate="2017-3-27 00:00:00" fixdate="2017-4-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Wrong comparison for floats/double type in Druid</summary>
      <description>Follow-up on CALCITE-1722.The second issue (Minor) is to use ordering instead of Alphanumeric, this is needed when comparing floats/doubles.It needs Calcite to move to Druid 0.9.2.</description>
      <version>None</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">druid.src.test.java.org.apache.calcite.test.DruidAdapterIT.java</file>
      <file type="M">druid.src.test.java.org.apache.calcite.adapter.druid.DruidQueryFilterTest.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.DruidQuery.java</file>
    </fixedFiles>
  </bug>
  <bug id="1725" opendate="2017-3-28 00:00:00" fixdate="2017-4-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Push project aggregate of time extract to druid</summary>
      <description>Push aggs on Extract (Year/Month/Day) as Extraction function to druid.Avoid usage of granularity NONE by adding time extract instead.</description>
      <version>None</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.DruidConnectionImpl.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.ExtractionFunction.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.DimensionSpec.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.DefaultDimensionSpec.java</file>
      <file type="M">druid.src.test.java.org.apache.calcite.test.DruidAdapterIT.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.TimeExtractionFunction.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.TimeExtractionDimensionSpec.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.ExtractionDimensionSpec.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.DruidRules.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.DruidQuery.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.DruidDateTimeUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="1726" opendate="2017-3-28 00:00:00" fixdate="2017-2-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Subquery in FILTER is left untransformed</summary>
      <description>ReproducerQuery:select * from emp where empno IN (select (select max(sal) from emp) from dept)Plan after SubqueryRemoveRuleLogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], MGR=[$3], HIREDATE=[$4], SAL=[$5], COMM=[$6], DEPTNO=[$7], SLACKER=[$8]) LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], MGR=[$3], HIREDATE=[$4], SAL=[$5], COMM=[$6], DEPTNO=[$7], SLACKER=[$8]) LogicalJoin(condition=[=($0, $9)], joinType=[inner]) LogicalTableScan(table=[[CATALOG, SALES, EMP]]) LogicalAggregate(group=[{0}]) LogicalProject(EXPR$0=[$SCALAR_QUERY({LogicalAggregate(group=[{}], EXPR$0=[MAX($0)]) LogicalProject(SAL=[$5]) LogicalTableScan(table=[[CATALOG, SALES, EMP]])})]) LogicalTableScan(table=[[CATALOG, SALES, DEPT]])As you can notice scalar query in LogicalProject is left as it is</description>
      <version>None</version>
      <fixedVersion>1.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">core.src.test.resources.sql.sub-query.iq</file>
      <file type="M">core.src.main.java.org.apache.calcite.tools.Programs.java</file>
    </fixedFiles>
  </bug>
  <bug id="1730" opendate="2017-3-30 00:00:00" fixdate="2017-4-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade Druid to 0.9.2</summary>
      <description>Upgrade Druid to 0.9.2. Since we speak REST to Druid there are no maven dependencies to update, but we do need to make calcite-test-dataset work reliably with a 0.9.2 instance and there are a couple of places in the doc/site IIRC.</description>
      <version>None</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">site..docs.history.md</file>
      <file type="M">site..docs.druid.adapter.md</file>
    </fixedFiles>
  </bug>
  <bug id="1734" opendate="2017-3-31 00:00:00" fixdate="2017-4-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>select query result not parsed correctly with druid 0.9.2</summary>
      <description>In druid 0.9.2 - list of dimensions and metrics was added to druidresults Druid PR - https://github.com/druid-io/druid/pull/2491calcite has its own parsing logic for results and events in the results are ignored silently by current parsing logic.</description>
      <version>None</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.DruidConnectionImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="1749" opendate="2017-4-11 00:00:00" fixdate="2017-4-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Push filter conditions partially into Druid</summary>
      <description>When we cannot push the full filter predicate into DruidQuery, we should push it partially and leave the rest of the predicate on top of it.This issue extends the logic of the DruidFilterRule to do that.</description>
      <version>None</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">druid.src.test.java.org.apache.calcite.test.DruidAdapterIT.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.DruidRules.java</file>
      <file type="M">druid.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1750" opendate="2017-4-11 00:00:00" fixdate="2017-4-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix unit test failures when the path to the repository contains spaces</summary>
      <description>Trying to consolidate some jenkins jobs, and ran into an issue where some tests were failing when the path to the local checkout contained spaces.</description>
      <version>None</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pig.src.test.java.org.apache.calcite.test.PigAdapterTest.java</file>
      <file type="M">example.csv.src.test.java.org.apache.calcite.test.CsvTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.sql.parser.SqlParserTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="1752" opendate="2017-4-11 00:00:00" fixdate="2017-4-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use URLDecoder#decode to handle URLs acquired from getResource(..) calls in test cases</summary>
      <description>From https://github.com/apache/calcite/commit/6543c0fd8b63efb00d035790209f8546668d7aa5#commitcomment-21723380:michaelmior suggested that it would be better to replace my String.replace("%20", " ") with java.net.URLDecoder.decode instead. I am apt to agree with him Maybe we can pull this into a utility instead of littering it around test cases in avatica and calcite.</description>
      <version>None</version>
      <fixedVersion>avatica-1.10.0,1.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pig.src.test.java.org.apache.calcite.test.PigAdapterTest.java</file>
      <file type="M">example.csv.src.test.java.org.apache.calcite.test.CsvTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.sql.parser.SqlParserTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="1758" opendate="2017-4-18 00:00:00" fixdate="2017-4-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Push to Druid OrderBy/Limit operation over time dimension and additional columns</summary>
      <description>Push as much as we can order by limit operators.This use to be not possible because of the way druid bucket the data. With Extraction dimension specs we can now set granularity to all and craft the extraction dimension spec in order to make time as new group by column.</description>
      <version>None</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">druid.src.test.java.org.apache.calcite.test.DruidAdapterIT.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.TimeExtractionFunction.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.TimeExtractionDimensionSpec.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.ExtractionFunctionUtil.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.DruidRules.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.DruidQuery.java</file>
    </fixedFiles>
  </bug>
  <bug id="1759" opendate="2017-4-20 00:00:00" fixdate="2017-4-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add SQL:2014 reserved words to parser</summary>
      <description>Add SQL:2014 reserved words to parser.SQL:2014 added the following reserved words (over SQL:2011): ARRAY_MAX_CARDINALITY, BEGIN_FRAME, BEGIN_PARTITION, CLASSIFIER, CURRENT_ROW, DEFINE, EMPTY, END_FRAME, END_PARTITION, FRAME_ROW, GROUPS, INITIAL, MATCHES, MATCH_NUMBER, MATCH_RECOGNIZE, OMIT, ONE, PATTERN, PER, PERCENT, PERIOD, PORTION, RUNNING, SEEK, SHOW, SKIP, SUBSET, SYSTEM_TIME, VALUE_OF. With this change, all of these are now reserved in Calcite. Some of them were reserved already (e.g. due to CALCITE-1641).SQL:2014 removed: DAYS, FOREVER, HOURS, KEEP, MAX_CARDINALITY, MINUTES, SECONDS. None of these were reserved in Calcite, and that remains the case.The following became reserved in SQL:2011, and are now reserved in Calcite: LAG, LEAG, LIKE_REGEX, NTH_VALUE, NTILE, OCCURRENCES_REGEX, POSITION_REGEX, SUBSTRING_REGEX, TRANSLATE_REGEX, TRIM_ARRAY, TRUNCATE, VERSIONING.</description>
      <version>None</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">site..docs.reference.md</file>
      <file type="M">file.src.test.java.org.apache.calcite.adapter.file.SqlTest.java</file>
      <file type="M">core.src.test.resources.org.apache.calcite.test.SqlToRelConverterTest.xml</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.SqlValidatorTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.SqlToRelConverterTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.JdbcTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.sql.test.SqlAdvisorTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.sql.parser.SqlParserTest.java</file>
      <file type="M">core.src.main.codegen.templates.Parser.jj</file>
    </fixedFiles>
  </bug>
  <bug id="1760" opendate="2017-4-25 00:00:00" fixdate="2017-4-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement utility method to identify lossless casts</summary>
      <description>Implement utility method to identify 'lossless' casts, i.e., casts from which the original value of the field can be certainly recovered?For instance, int -&gt; bigint is true (as you can cast back to int without loss of information), however bigint -&gt; int is false.</description>
      <version>None</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">core.src.test.java.org.apache.calcite.test.RexProgramTest.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.rex.RexUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="1762" opendate="2017-4-26 00:00:00" fixdate="2017-10-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade to Spark 2.X</summary>
      <description>Spark 2.X have released with a lot of improvement and new features .</description>
      <version>None</version>
      <fixedVersion>1.15.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">spark.src.main.java.org.apache.calcite.adapter.spark.SparkRules.java</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1763" opendate="2017-4-26 00:00:00" fixdate="2017-4-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Recognize lossless casts in join/aggregate materialized view rewriting rule</summary>
      <description>Integrate CALCITE-1760 with rewriting rule so we can cover additional cases.</description>
      <version>None</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">core.src.test.java.org.apache.calcite.test.MaterializationTest.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.rel.rules.AbstractMaterializedViewRule.java</file>
    </fixedFiles>
  </bug>
  <bug id="1764" opendate="2017-4-26 00:00:00" fixdate="2017-4-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Adding sort ordering type for druid sort json field</summary>
      <description>Currently limit spec will use default string compactor to sort fields.That is wrong when the field is numeric for instance 9 will sort after 10.</description>
      <version>1.12.0</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">druid.src.test.java.org.apache.calcite.test.DruidAdapterIT.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.DruidQuery.java</file>
    </fixedFiles>
  </bug>
  <bug id="1766" opendate="2017-4-28 00:00:00" fixdate="2017-4-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support system functions having no args with parenthesis too</summary>
      <description>Currently, SYSTEM functions with no args need to be queried as a SQL identifier without parenthesis but some DBs still allows it with parentheses too like MySQL and Phoenix.</description>
      <version>None</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">site..docs.reference.md</file>
      <file type="M">core.src.test.java.org.apache.calcite.sql.test.SqlTesterImpl.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.sql.test.SqlOperatorBaseTest.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql.validate.SqlValidatorImpl.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql.validate.SqlDelegatingConformance.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql.validate.SqlConformanceEnum.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql.validate.SqlConformance.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql.validate.SqlAbstractConformance.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql.SqlSyntax.java</file>
    </fixedFiles>
  </bug>
  <bug id="1769" opendate="2017-4-28 00:00:00" fixdate="2017-5-28 01:00:00" resolution="Invalid">
    <buginformation>
      <summary>Push Filters down to druid when there a cast to numeric</summary>
      <description>Currently if we have cast to numeric over literal filter will not get pushed.For instance query like SELECT page from druid_table_1 WHERE page &lt; 5 group by page from hive will introduce a cast over `5`.</description>
      <version>None</version>
      <fixedVersion>1.13.0,1.12.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">druid.src.test.resources.log4j.properties</file>
      <file type="M">druid.src.test.java.org.apache.calcite.test.DruidAdapterIT.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.prepare.Prepare.java</file>
    </fixedFiles>
  </bug>
  <bug id="1770" opendate="2017-4-30 00:00:00" fixdate="2017-5-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Druid adapter: CAST(NULL AS ...) gives NPE</summary>
      <description>Following query fails with NPE SELECT product_id from foodmart where product_id = NULL group by product_id</description>
      <version>None</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">druid.src.test.java.org.apache.calcite.test.DruidAdapterIT.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.DruidQuery.java</file>
    </fixedFiles>
  </bug>
  <bug id="1771" opendate="2017-5-1 00:00:00" fixdate="2017-5-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade to Druid 0.10.0</summary>
      <description>Upgrade to latest druid stable 0.10.0</description>
      <version>None</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">site..docs.history.md</file>
    </fixedFiles>
  </bug>
  <bug id="1799" opendate="2017-5-22 00:00:00" fixdate="2017-7-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>"OR ... IN" sub-query conversion is wrong</summary>
      <description>This query:select * from emp where deptno = 10 or deptno in ( select dept.deptno from dept where deptno &lt; 5)Is converted to this by SqlToRelConverter:LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], MGR=[$3], HIREDATE=[$4], SAL=[$5], COMM=[$6], DEPTNO=[$7], SLACKER=[$8]) LogicalFilter(condition=[OR(=($7, 10), true)]) LogicalJoin(condition=[=($7, $9)], joinType=[inner]) LogicalTableScan(table=[[CATALOG, SALES, EMP]]) LogicalAggregate(group=[{0}]) LogicalProject(DEPTNO=[$0]) LogicalFilter(condition=[&lt;($0, 5)]) LogicalTableScan(table=[[CATALOG, SALES, DEPT]])But that's not right. LogicalFilter(condition=[OR(=($7, 10), true)]) is always true and is in the wrong place anyway (it's applied after the inner join, where all the deptno = 10 records have already been removed).</description>
      <version>1.12.0</version>
      <fixedVersion>1.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">linq4j.src.main.java.org.apache.calcite.linq4j.Enumerator.java</file>
      <file type="M">example.csv.src.main.java.org.apache.calcite.adapter.csv.CsvStreamReader.java</file>
      <file type="M">core.src.test.resources.org.apache.calcite.test.SqlToRelConverterTest.xml</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.SqlToRelConverterTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="1805" opendate="2017-5-24 00:00:00" fixdate="2017-6-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Druid adapter incorrectly pushes down "COUNT(c)"; Druid only supports "COUNT(*)"</summary>
      <description>Currently queries like select count(column) from table is pushed to druid as timeseries with an aggregator {"type":"count","name":"EXPR$0","fieldName":"countryName"} Such an aggregator does not exist in druid. The count aggregator does only work as count(*) . here is a test case that summarize the issue. @Test public void testCount() { final String sql = "SELECT count(\"countryName\") FROM (SELECT \"countryName\" FROM \"wikiticker\" WHERE \"countryName\" IS NOT NULL) as a"; // correct count sql(sql, WIKI_AUTO2).returnsUnordered("EXPR$0=3799"); final String sql2 = "SELECT count(\"countryName\") FROM (SELECT \"countryName\" FROM \"wikiticker\") as a"; sql(sql2, WIKI_AUTO2).returnsUnordered("EXPR$0=3799"); // it will fail } First test will pass while the second will not.</description>
      <version>1.12.0</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">core.src.main.java.org.apache.calcite.interpreter.AggregateNode.java</file>
      <file type="M">druid.src.test.java.org.apache.calcite.test.DruidAdapterIT.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.DruidRules.java</file>
    </fixedFiles>
  </bug>
  <bug id="1815" opendate="2017-5-31 00:00:00" fixdate="2017-7-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change Avatica dependency of the Pig adapter to avatica-core</summary>
      <description>Calcite-pig unnecessarily depends on the full avatica instead of avatica-core. This causes problems in some environments because avatica jar contains slf4j classes.</description>
      <version>1.12.0</version>
      <fixedVersion>1.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pig.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1819" opendate="2017-5-31 00:00:00" fixdate="2017-6-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Druid Adapter does not push the boolean operator "&lt;&gt;" as a filter correctly</summary>
      <description>The querySELECT COUNT(DISTINCT "the_month") FROM "foodmart" WHERE "the_month" &lt;&gt; 'October';Will produce a Druid query with the following filter:"filter":{ "type":"not", "fields":[ { "type":"selector", "dimension":"the_month", "value":"October" } ] }But the expected filter should look like:"filter":{ "type":"not", "field":{ "type":"selector", "dimension":"the_month", "value":"October" } }</description>
      <version>1.12.0</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">druid.src.test.java.org.apache.calcite.test.DruidAdapterIT.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.DruidQuery.java</file>
    </fixedFiles>
  </bug>
  <bug id="1824" opendate="2017-6-1 00:00:00" fixdate="2017-2-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>GROUP_ID returns wrong result</summary>
      <description>We implemented the GROUP_ID() function in CALCITE-512 but we got the specification wrong, and it returns the wrong result.GROUP_ID is not in the SQL standard. It is implemented only by Oracle.I mistakenly believed that GROUP_ID() is equivalent to GROUPING_ID(g1, ..., gn) (in a query with GROUP BY g1, ..., gn). In fact, GROUP_ID is useful only if you have duplicate grouping sets. If grouping sets are distinct, GROUP_ID() will always return zero.Example 1SELECT deptno, job, GROUP_ID() AS gFROM EmpGROUP BY ROLLUP(deptno, job) DEPTNO JOB G---------- --------- ---------- 10 CLERK 0 10 MANAGER 0 10 PRESIDENT 0 10 0 20 CLERK 0 20 ANALYST 0 20 MANAGER 0 20 0 30 CLERK 0 30 MANAGER 0 30 SALESMAN 0 30 0 0 produces grouping sets (deptno, job), (deptno), (). These are distinct, so GROUP_ID() is 0 for all rows.Example 2SELECT deptno, GROUP_ID() AS gFROM EmpGROUP BY GROUPING SETS (deptno, (), ()); DEPTNO G---------- ---------- 10 0 20 0 30 0 0 1As you can see, the grouping set () occurs twice. So there is one row in the result for each occurrence: the first occurrence has g = 0; the second has g = 1.In my fix for CALCITE-1069, I will change GROUP_ID() to always return 0. This is wrong, but nevertheless closer to the required behavior.</description>
      <version>None</version>
      <fixedVersion>1.22.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">core.src.test.resources.sql.agg.iq</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.JdbcTest.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql.validate.AggregatingSelectScope.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql.fun.SqlGroupIdFunction.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql2rel.SqlToRelConverter.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.adapter.enumerable.RexImpTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="1827" opendate="2017-6-2 00:00:00" fixdate="2017-6-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document TIMESTAMPADD, TIMESTAMPDIFF functions</summary>
      <description>Document TIMESTAMPADD, TIMESTAMPDIFF functions.(Initial request was to add DATEADD as built-in scalar function, as follows. But it turns out that TIMESTAMPADD is similar enough.)Syntax: DATEADD (datepart , number , date )Arguments: datepart - Is the part of date to which an integer number is added. number - Is an expression that can be resolved to an int that is added to a datepart of date date - Is an expression that can be resolved to a time.ExampleSELECT DATEADD(month, 1, '2017-05-31') from tab;returns 2017-06-30 00:00:00.000MSSQL: https://docs.microsoft.com/en-us/sql/t-sql/functions/dateadd-transact-sqlMySql: https://dev.mysql.com/doc/refman/5.7/en/date-and-time-functions.html#function_date-add</description>
      <version>None</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">site..docs.reference.md</file>
    </fixedFiles>
  </bug>
  <bug id="1834" opendate="2017-6-8 00:00:00" fixdate="2017-7-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement precedence list for Array and Multiset</summary>
      <description>Arrays and Multisets can have precedence according to the precedence of its component type.</description>
      <version>None</version>
      <fixedVersion>1.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">core.src.test.java.org.apache.calcite.util.Smalls.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.UdfTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.sql.type.SqlTypeFactoryTest.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql.type.MultisetSqlType.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql.type.JavaToSqlTypeConversionRules.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql.type.ArraySqlType.java</file>
    </fixedFiles>
  </bug>
  <bug id="1837" opendate="2017-6-12 00:00:00" fixdate="2017-6-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Release Calcite 1.13.0</summary>
      <description>Release Apache Calcite 1.13.0.</description>
      <version>None</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">site..docs.howto.md</file>
      <file type="M">site..docs.history.md</file>
      <file type="M">README</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1845" opendate="2017-6-16 00:00:00" fixdate="2017-7-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Quantified comparison predicates (SOME, ANY, ALL)</summary>
      <description>Support quantified comparison predicates (SOME, ANY, ALL), per the SQL standard.&lt;comp op&gt; ::= &lt;equals operator&gt; &amp;#124; &lt;not equals operator&gt; &amp;#124; &lt;less than operator&gt; &amp;#124; &lt;greater than operator&gt; &amp;#124; &lt;less than or equals operator&gt; &amp;#124; &lt;greater than or equals operator&gt;&lt;quantifier&gt; ::= &lt;all&gt; &amp;#124; &lt;some&gt;&lt;all&gt; ::= ALL&lt;some&gt; ::= SOME &amp;#124; ANYThe result of R &lt;comp op&gt; &lt;quantifier&gt; T is derived by the application of the implied &lt;comparison predicate&gt; R &lt;comp op&gt; RT to every row RT in T.Case: a) If T is empty or if the implied &lt;comparison predicate&gt; is True for every row RT in T, then R &lt;comp op&gt; &lt;all&gt; T is True. b) If the implied &lt;comparison predicate&gt; is False for at least one row RT in T, then R &lt;comp op&gt; &lt;all&gt; T is False. c) If the implied &lt;comparison predicate&gt; is True for at least one row RT in T, then R &lt;comp op&gt; &lt;some&gt; T is True. d) If T is empty or if the implied &lt;comparison predicate&gt; is False for every row RT in T, then R &lt;comp op&gt; &lt;some&gt; T is False. e) If R &lt;comp op&gt; &lt;quantifier&gt; T is neither True nor False, then it is Unknown.</description>
      <version>None</version>
      <fixedVersion>1.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">site..docs.reference.md</file>
      <file type="M">core.src.test.resources.sql.sub-query.iq</file>
      <file type="M">core.src.test.resources.org.apache.calcite.test.SqlToRelConverterTest.xml</file>
      <file type="M">core.src.test.resources.org.apache.calcite.test.RelOptRulesTest.xml</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.SqlValidatorTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.SqlToRelConverterTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.RelOptRulesTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.QuidemTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.sql.test.SqlAdvisorTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.sql.parser.SqlParserTest.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql.validate.SqlValidatorImpl.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql.SqlKind.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql.fun.SqlStdOperatorTable.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql.fun.SqlInOperator.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql2rel.SqlToRelConverter.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.rex.RexSubQuery.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.rel.rules.SubQueryRemoveRule.java</file>
      <file type="M">core.src.main.codegen.templates.Parser.jj</file>
    </fixedFiles>
  </bug>
  <bug id="1846" opendate="2017-6-17 00:00:00" fixdate="2017-6-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Metadata pulled up predicates should skip non-deterministic calls</summary>
      <description>Metadata MdPredicates should ignore undeterministic calls, or else there would be unexpected result.</description>
      <version>None</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">core.src.test.java.org.apache.calcite.test.RexProgramTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.RelMetadataTest.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.rex.RexUtil.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.rel.metadata.RelMdPredicates.java</file>
    </fixedFiles>
  </bug>
  <bug id="1853" opendate="2017-6-20 00:00:00" fixdate="2017-6-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Push Count distinct into Druid when approximate results are acceptable</summary>
      <description>Currently queries such asselect count(distinct "dimension") from "table";are not pushed into Druid using the cardinality aggregator because it produces an approximate result. There exists a JDBC string parameter called approximateDistinctCount introduced in CALCITE-1587 that lets the user specify whether approximate results are acceptable in count distinct queries, however this parameter is not currently utilized by the Druid adapter.</description>
      <version>None</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">druid.src.test.java.org.apache.calcite.test.DruidAdapterIT.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.DruidTable.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.DruidRules.java</file>
      <file type="M">druid.src.main.java.org.apache.calcite.adapter.druid.DruidQuery.java</file>
    </fixedFiles>
  </bug>
  <bug id="1854" opendate="2017-6-21 00:00:00" fixdate="2017-6-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix value range of TINYINT in documentation</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">site..docs.reference.md</file>
    </fixedFiles>
  </bug>
  <bug id="1855" opendate="2017-6-21 00:00:00" fixdate="2017-6-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Type error for floats returned from Cassandra adapter</summary>
      <description></description>
      <version>1.12.0</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">cassandra.src.main.java.org.apache.calcite.adapter.cassandra.CassandraEnumerator.java</file>
    </fixedFiles>
  </bug>
  <bug id="1864" opendate="2017-6-29 00:00:00" fixdate="2017-7-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow NULL literal as argument</summary>
      <description>Even though the SQL standard does not allow raw (non-casted) NULL literals, most databases do. So we should allow 1 = null or select * from emp where empno &gt; null. Of course, these expressions always return UNKNOWN.</description>
      <version>None</version>
      <fixedVersion>1.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">core.src.test.resources.sql.misc.iq</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.SqlValidatorTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.sql.test.SqlOperatorBaseTest.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql.validate.SqlValidatorImpl.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql.type.SqlTypeUtil.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql.type.SqlTypeFactoryImpl.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql.type.SameOperandTypeChecker.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql.SqlOperator.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.rel.type.RelDataTypeFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="2878" opendate="2019-2-27 00:00:00" fixdate="2019-2-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Avoid use of new RuntimeException(e) in tests</summary>
      <description>new RuntimeException(e) adds very little info in tests, and it makes stacktraces harder to read.So it makes sense to just sneaky-throw in those cases, especially for test purposes</description>
      <version>None</version>
      <fixedVersion>1.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">splunk.src.test.java.org.apache.calcite.test.SplunkAdapterTest.java</file>
      <file type="M">plus.src.test.java.org.apache.calcite.adapter.os.OsAdapterTest.java</file>
      <file type="M">pig.src.test.java.org.apache.calcite.test.PigRelBuilderStyleTest.java</file>
      <file type="M">piglet.src.test.java.org.apache.calcite.test.CalciteHandler.java</file>
      <file type="M">piglet.pom.xml</file>
      <file type="M">mongodb.src.test.java.org.apache.calcite.test.MongoAssertions.java</file>
      <file type="M">mongodb.src.test.java.org.apache.calcite.adapter.mongodb.MongoAdapterTest.java</file>
      <file type="M">file.src.test.java.org.apache.calcite.adapter.file.SqlTest.java</file>
      <file type="M">example.csv.src.test.java.org.apache.calcite.test.CsvTest.java</file>
      <file type="M">example.csv.pom.xml</file>
      <file type="M">elasticsearch.src.test.java.org.apache.calcite.adapter.elasticsearch.Projection2Test.java</file>
      <file type="M">elasticsearch.src.test.java.org.apache.calcite.adapter.elasticsearch.EmbeddedElasticsearchNode.java</file>
      <file type="M">elasticsearch.src.test.java.org.apache.calcite.adapter.elasticsearch.ElasticSearchAdapterTest.java</file>
      <file type="M">druid.src.test.java.org.apache.calcite.test.DruidAdapterIT2.java</file>
      <file type="M">druid.src.test.java.org.apache.calcite.test.DruidAdapterIT.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.util.TestUtil.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.tools.FrameworksTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.TableFunctionTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.StreamTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.SqlToRelTestBase.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.SqlToRelConverterExtendedTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.SqlTestGen.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.RelMetadataTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.ReflectiveSchemaTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.Matchers.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.LatticeTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.JdbcTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.JdbcFrontLinqBackTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.JdbcFrontJdbcBackTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.JdbcAdapterTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.DiffTestCase.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.CalciteAssert.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.sql.test.SqlOperatorBaseTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.sql.test.AbstractSqlTester.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.sql.parser.SqlParserTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.rex.RexSqlStandardConvertletTableTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.rel.rel2sql.RelToSqlConverterTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.profile.ProfilerTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.plan.RelWriterTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.jdbc.CalciteRemoteDriverTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="2881" opendate="2019-2-28 00:00:00" fixdate="2019-3-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add the JSON_PRETTY function</summary>
      <description>``` JSON_PRETTY(json_doc) ```Returns the pretty formatted JSON document. Returns `NULL` if any argument is `NULL` or if JSON document is invalid.Example Sql:```sql SELECT JSON_PRETTY(v) AS c1 FROM (VALUES ('{"a": [10, true],"b": [10, true]}')) as t(v) limit 10 ```Result:c1{ "a" : [ 10, true ], "b" : [ 10, true ] }</description>
      <version>None</version>
      <fixedVersion>1.19.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">site..docs.reference.md</file>
      <file type="M">server.src.main.codegen.config.fmpp</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.SqlValidatorTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.SqlJsonFunctionsTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.test.JdbcTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.sql.test.SqlOperatorBaseTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.sql.parser.SqlParserTest.java</file>
      <file type="M">core.src.test.java.org.apache.calcite.rel.rel2sql.RelToSqlConverterTest.java</file>
      <file type="M">core.src.test.codegen.config.fmpp</file>
      <file type="M">core.src.main.resources.org.apache.calcite.runtime.CalciteResource.properties</file>
      <file type="M">core.src.main.java.org.apache.calcite.util.BuiltInMethod.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.sql.fun.SqlStdOperatorTable.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.runtime.SqlFunctions.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.runtime.CalciteResource.java</file>
      <file type="M">core.src.main.java.org.apache.calcite.adapter.enumerable.RexImpTable.java</file>
      <file type="M">core.src.main.codegen.templates.Parser.jj</file>
      <file type="M">core.src.main.codegen.config.fmpp</file>
      <file type="M">babel.src.main.codegen.config.fmpp</file>
    </fixedFiles>
  </bug>
</bugrepository>
