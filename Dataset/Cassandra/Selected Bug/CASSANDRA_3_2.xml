<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="CASSANDRA">
  
  <bug fixdate="2015-11-25 01:00:00" id="10188" opendate="2015-8-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>sstableloader does not use MAX_HEAP_SIZE env parameter</summary>
      <description>Currently the sstableloader script hard codes java's max heap size parameter to 256MB. The issue was discussed in CASSANDRA-7385 and it looks like the agreed solution was to allow the value to change through parameters that were going to be introduced as part of CASSANDRA-5969. This parameter wasn't added to sstableloader, making it inconsistent with the other utilities and provides a problem loading large files.</description>
      <version>2.1.12,2.2.4,3.0.1,3.1,3.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.sstableloader</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-11-28 01:00:00" id="10225" opendate="2015-8-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make compression ratio much more accurate</summary>
      <description>Currently in cfstats, it will take an average over the compression ratios of all of the sstables without regard to the data sizes. This can lead to a very inaccurate value. It would be good to factor in the uncompressed and compressed sizes for the sstables to give an accurate number.</description>
      <version>3.2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.metrics.TableMetrics.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-12-1 01:00:00" id="10243" opendate="2015-9-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Warn or fail when changing cluster topology live</summary>
      <description>Moving a node from one rack to another in the snitch, while it is alive, is almost always the wrong thing to do.</description>
      <version>2.1.12,2.2.4,3.0.1,3.1,3.2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.locator.YamlFileNetworkTopologySnitchTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.locator.GossipingPropertyFileSnitchTest.java</file>
      <file type="M">src.java.org.apache.cassandra.locator.SnitchProperties.java</file>
      <file type="M">src.java.org.apache.cassandra.locator.GossipingPropertyFileSnitch.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.service.MigrationManager.java</file>
      <file type="M">src.java.org.apache.cassandra.locator.YamlFileNetworkTopologySnitch.java</file>
      <file type="M">src.java.org.apache.cassandra.locator.PropertyFileSnitch.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.Gossiper.java</file>
      <file type="M">conf.cassandra.yaml</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2015-11-4 01:00:00" id="10651" opendate="2015-11-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>allow unit testing by defined list of files</summary>
      <description>"Testing by list" allows distributing defined test lists across machines to run tests in parallel.Additionally it can be used by devs to create a simple list of tests they are interested in during feature development, without crafting a complicated command.A final reason would be adding a new way to divide tests into suites without requiring more unique ant targets (which may differ in subtle ways for better or worse).</description>
      <version>3.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2015-12-13 01:00:00" id="10701" opendate="2015-11-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>stop referring to batches as atomic</summary>
      <description>We still refer to logged batches as atomic, we should remove those references.</description>
      <version>2.1.13,2.2.5,3.0.3,3.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">doc.cql3.CQL.textile</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  
  
  
  
  <bug fixdate="2015-12-13 01:00:00" id="10854" opendate="2015-12-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh COPY FROM csv having line with more than one consecutive &amp;#39;,&amp;#39; delimiter is throwing &amp;#39;list index out of range&amp;#39;</summary>
      <description>cqlsh COPY FROM csv having line with more than one consecutive ',' delimiter is throwing 'list index out of range'Steps to re-produce:CREATE TABLE tracks_by_album ( album_title TEXT, album_year INT, performer TEXT STATIC, album_genre TEXT STATIC, track_number INT, track_title TEXT, PRIMARY KEY ((album_title, album_year), track_number));Create a file: tracks_by_album.csv having following 2 lines :album,year,performer,genre,number,titlea,2015,b c d,e f g,,cqlsh&gt; COPY music.tracks_by_album (album_title, album_year, performer, album_genre, track_number, track_title)FROM '~/tracks_by_album.csv'WITH HEADER = 'true';Error :Starting copy of music.tracks_by_album with columns ['album_title', 'album_year', 'performer', 'album_genre', 'track_number', 'track_title'].list index out of rangeAborting import at record #1. Previously inserted records are still present, and some records after that may be present as well.</description>
      <version>2.1.13,2.2.5,3.0.3,3.2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.copyutil.py</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-1-16 01:00:00" id="10880" opendate="2015-12-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Paging state between 2.2 and 3.0 are incompatible on protocol v4</summary>
      <description>In CASSANDRA-10254, the paging states generated by 3.0 for the native protocol v4 were made 3.0 specific. This was done because the paging state in pre-3.0 versions contains a serialized cell name, but 3.0 doesn't talk in term of cells internally (at least not the pre-3.0 ones) and so using an old-format cell name when we only have 3.0 nodes is inefficient and inelegant.Unfortunately that change was made on the assumption than the protocol v4 was 3.0 only but it's not, it ended up being released with 2.2 and that completely slipped my mind. So in practice, you can't properly have a mixed 2.2/3.0 cluster if your driver is using the protocol v4.And unfortunately, I don't think there is an easy way to fix that without breaking something. Concretely, I can see 3 choices: we change 3.0 so that it generates old-format paging states on the v4 protocol. The 2 main downsides are that 1) this breaks 3.0 upgrades if the driver is using the v4 protocol, and at least on the java side the only driver versions that support 3.0 will use v4 by default and 2) we're signing off on having sub-optimal paging state until the protocol v5 ships (probably not too soon). we remove the v4 protocol from 2.2. This means 2.2 will have to use v3 before upgrade at the risk of breaking upgrade. This is also bad, but I'm not sure the driver version using the v4 protocol are quite ready yet (at least the java driver is not GA yet) so if we work with the drivers teams to make sure the v3 protocol gets prefered by default on 2.2 in the GA versions of these driver, this might be somewhat transparent to users. we don't change anything code-wise, but we document clearly that you can't upgrade from 2.2 to 3.0 if your clients use protocol v4 (so we leave upgrade broken if the v4 protocol is used as it is currently). This is not great, but we can work with the drivers teams here again to make sure drivers prefer the v3 version for 2.2 nodes so most people don't notice in practice.I think I'm leaning towards solution 3). It's not great but at least we break no minor upgrades (neither on 2.2, nor on 3.0) which is probably the most important. We'd basically be just adding a new condition on 2.2-&gt;3.0 upgrades. We could additionally make 3.0 node completely refuse v4 connections if they know a 2.2 nodes is in the cluster for extra safety.Ping omichallat, adutra and aholmber as you might want to be aware of that ticket.</description>
      <version>3.0.3,3.2</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">NEWS.txt</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2014-12-20 01:00:00" id="8142" opendate="2014-10-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>prevent the command "cassandra start" from starting a cluster</summary>
      <description>Students often type "sudo service cassandra start" wrong, and type "sudo cassandra start".Running a package installation as root messes up their environments.since "start" is not a valid option on the "cassandra" command, we should block cassandra from starting.</description>
      <version>3.2</version>
      <fixedVersion>Packaging</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cassandra</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-12-16 01:00:00" id="8639" opendate="2015-1-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Can OOM on CL replay with dense mutations</summary>
      <description>If you write dense mutations with many clustering keys, the replay of the CL can quickly overwhelm a node on startup. This looks to be caused by the fact we only ensure there are 1000 mutations in flight at a time. but those mutations could have thousands of cells in them.A better approach would be to limit the CL replay to the amount of memory in flight using cell.unsharedHeapSize()</description>
      <version>3.2</version>
      <fixedVersion>Legacy/LocalWrite-ReadPaths</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.RecoveryManagerTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLogReplayer.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2015-12-5 01:00:00" id="9302" opendate="2015-5-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Optimize cqlsh COPY FROM, part 3</summary>
      <description>We've had some discussion moving to Spark CSV import for bulk load in 3.x, but people need a good bulk load tool now. One option is to add a separate Java bulk load tool (CASSANDRA-9048), but if we can match that performance from cqlsh I would prefer to leave COPY FROM as the preferred option to which we point people, rather than adding more tools that need to be supported indefinitely.Previous work on COPY FROM optimization was done in CASSANDRA-7405 and CASSANDRA-8225.</description>
      <version>2.1.13,2.2.5,3.0.3,3.2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.util.py</file>
      <file type="M">pylib.cqlshlib.copyutil.py</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2015-12-27 01:00:00" id="9494" opendate="2015-5-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Need to set TTL with COPY command</summary>
      <description>I can import a chunk of data into Cassandra table with COPY command like:COPY my_table (name, address) FROM my_file.csv WITH option='value' ... ;But I am not able to specify a finite TTL in COPY command with "USING TTL 3600", for example.</description>
      <version>3.2</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.copyutil.py</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh.py</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-11-18 01:00:00" id="9844" opendate="2015-7-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reevaluate inspections in generate-idea-files target</summary>
      <description>Current default inspections generated by the generate-idea-files ant target are generally fine.However there's room to improvement especially wrt Java8 lambda warnings that have (negative) performance impacts.So, this ticket is about to revisit all inspections wrt performance</description>
      <version>2.2.4,3.0.1,3.1,3.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ide.idea.inspectionProfiles.Project.Default.xml</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-12-23 01:00:00" id="9879" opendate="2015-7-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add the name of the compressor in the output of sstablemetadata</summary>
      <description>Here is a simple patch to add to the output of sstablemetadata the name the compressor used for the sstable.I also made sstablemetadata embedded into the .deb distribution</description>
      <version>3.2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.SSTableMetadataViewer.java</file>
      <file type="M">debian.cassandra.install</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
</bugrepository>