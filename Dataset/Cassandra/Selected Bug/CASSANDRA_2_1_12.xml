<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="CASSANDRA">
  
  <bug fixdate="2015-11-25 01:00:00" id="10188" opendate="2015-8-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>sstableloader does not use MAX_HEAP_SIZE env parameter</summary>
      <description>Currently the sstableloader script hard codes java's max heap size parameter to 256MB. The issue was discussed in CASSANDRA-7385 and it looks like the agreed solution was to allow the value to change through parameters that were going to be introduced as part of CASSANDRA-5969. This parameter wasn't added to sstableloader, making it inconsistent with the other utilities and provides a problem loading large files.</description>
      <version>2.1.12,2.2.4,3.0.1,3.1,3.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.sstableloader</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-10-1 01:00:00" id="10242" opendate="2015-9-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Validate rack information on startup</summary>
      <description>Moving to a new rack means that different data should be stored on a node. We already persist rack information in a system table; we should fail startup if this doesn't match what the snitch thinks it should be. (Either the snitch is wrong, and needs to be fixed, or the machine has been moved and needs to be rebootstrapped.)</description>
      <version>2.1.12,2.2.4,3.0.0rc2</version>
      <fixedVersion>Local/Config</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.SystemKeyspace.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">conf.cassandra-rackdc.properties</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-12-1 01:00:00" id="10243" opendate="2015-9-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Warn or fail when changing cluster topology live</summary>
      <description>Moving a node from one rack to another in the snitch, while it is alive, is almost always the wrong thing to do.</description>
      <version>2.1.12,2.2.4,3.0.1,3.1,3.2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.locator.YamlFileNetworkTopologySnitchTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.locator.GossipingPropertyFileSnitchTest.java</file>
      <file type="M">src.java.org.apache.cassandra.locator.SnitchProperties.java</file>
      <file type="M">src.java.org.apache.cassandra.locator.GossipingPropertyFileSnitch.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.service.MigrationManager.java</file>
      <file type="M">src.java.org.apache.cassandra.locator.YamlFileNetworkTopologySnitch.java</file>
      <file type="M">src.java.org.apache.cassandra.locator.PropertyFileSnitch.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.Gossiper.java</file>
      <file type="M">conf.cassandra.yaml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-10-3 01:00:00" id="10264" opendate="2015-9-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unable to use conditions on static columns for DELETE</summary>
      <description>cqlsh:test&gt; create table static_table(id int, stat int static, ord int, val text, primary key(id,ord));cqlsh:test&gt; insert into static_table (id,stat,ord,val) VALUES ( 1, 1, 1, '1');cqlsh:test&gt; delete from static_table where id=1 and ord=1 if stat != 1;Invalid syntax at line 1, char 55 delete from static_table where id=1 and ord=1 if stat != 1; ^Same error if using =, &lt;, &lt;=, &gt;= or &gt; conditionAccording to thobbs the syntax should work. Plus, the error message is wrong</description>
      <version>2.1.12,2.2.4,3.0.0</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.InsertUpdateIfConditionTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.ModificationStatement.java</file>
      <file type="M">pylib.cqlshlib.cql3handling.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-11-7 01:00:00" id="10280" opendate="2015-9-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make DTCS work well with old data</summary>
      <description>Operational tasks become incredibly expensive if you keep around a long timespan of data with DTCS - with default settings and 1 year of data, the oldest window covers about 180 days. Bootstrapping a node with vnodes with this data layout will force cassandra to compact very many sstables in this window.We should probably put a cap on how big the biggest windows can get. We could probably default this to something sane based on max_sstable_age (ie, say we can reasonably handle 1000 sstables per node, then we can calculate how big the windows should be to allow that)</description>
      <version>2.1.12,2.2.4,3.0.1,3.1</version>
      <fixedVersion>Local/Compaction</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.compaction.DateTieredCompactionStrategyTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.DateTieredCompactionStrategyOptions.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.DateTieredCompactionStrategy.java</file>
      <file type="M">pylib.cqlshlib.cql3handling.py</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">NEWS.txt</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2015-10-19 01:00:00" id="10553" opendate="2015-10-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>MAX_HEAP_SIZE environment variable ignored on Windows</summary>
      <description>philipthompson had a look at a few Windows timeouts on CassCI:https://cassci.datastax.com/view/cassandra-3.0/job/cassandra-3.0_dtest_win32/86/consolehttps://cassci.datastax.com/view/cassandra-3.0/job/cassandra-3.0_dtest_win32/87/consolehttps://cassci.datastax.com/view/cassandra-3.0/job/cassandra-3.0_dtest_win32/88/consoleThe offending tests were bootstrap_test.py:TestBootstrap.killed_wiped_node_cannot_join_test in two runs and consistency_test.py:TestAccuracy.test_network_topology_strategy_counters in one. In the latter case, killed_wiped_node_cannot_join_test passed, so this doesn't happen 100% of the time.Philip has reproduced this locally (bootstrap_test.py:TestBootstrap.decommissioned_wiped_node_can_join_test), so it's not purely a CassCI problem. The cause there seems to be an OOM &amp;#8211; when running the tests, he sees 8GB "committed" in the process explorer, but only 4 actually used.I'm opening this ticket to track work on configuring the Windows dtests so this doesn't happen on CassCI anymore. Assigning JoshuaMcKenzie for the moment, but pauloricardomg might be able to make short work of this.</description>
      <version>None</version>
      <fixedVersion>Local/StartupandShutdown</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.cassandra-env.ps1</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-10-21 01:00:00" id="10559" opendate="2015-10-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support encrypted and plain traffic on the same port</summary>
      <description>To be able to migrate clusters in a rolling way from plain to encrypted traffic it would be very helpful if we could have Cassandra accept both on the same port.</description>
      <version>2.1.12,2.2.4,3.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.service.NativeTransportServiceTest.java</file>
      <file type="M">src.java.org.apache.cassandra.transport.Server.java</file>
      <file type="M">src.java.org.apache.cassandra.config.EncryptionOptions.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-10-23 01:00:00" id="10577" opendate="2015-10-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix cqlsh COPY commands that use NULL</summary>
      <description>Looks like this commit:https://github.com/apache/cassandra/commit/806378c8c295fb062f94eb8bf0f719b398d27745broke some of the behavior of cqlsh COPY:http://cassci.datastax.com/view/cassandra-3.0/job/cassandra-3.0_dtest/280/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_null_as_null_indicator/history/http://cassci.datastax.com/view/cassandra-3.0/job/cassandra-3.0_dtest/280/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_undefined_as_null_indicator/history/The NULL tests are the only ones that fail, so it doesn't look like any other parts of it are broken:http://cassci.datastax.com/view/cassandra-3.0/job/cassandra-3.0_dtest/280/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/</description>
      <version>2.1.12,2.2.4,3.0.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2015-11-12 01:00:00" id="10692" opendate="2015-11-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Don&amp;#39;t remove level info when doing upgradesstables</summary>
      <description>Seems we blow away the level info when doing upgradesstables. Introduced in CASSANDRA-8004</description>
      <version>2.1.12,2.2.4</version>
      <fixedVersion>Local/Compaction</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.compaction.LeveledCompactionStrategyTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.WrappingCompactionStrategy.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-11-23 01:00:00" id="10755" opendate="2015-11-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>PreparedStatement is the same id for different Japanese katakana characters with same length</summary>
      <description>String q1 = "UPDATE table SET value='タニャア' WHERE key=? AND key2=?";String q2 = "UPDATE table SET value='ャアタニ' WHERE key=? AND key2=?";when using session.prepare().q1 and q2 will return the prepared-statement with the same prepared ID, but the query in prepared-statement is correct.So if I update using q1 first, all later q2 will not be able to update.( It's means , it still updates q1)Please note that the Japanese katakana is the same length in q1 and q2.I know it's a bad use case for putting value into prepared-query itself. Is it related to how Cassandra cache prepared statement?</description>
      <version>2.1.12,2.2.4,3.0.1</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.utils.MD5Digest.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2015-11-9 01:00:00" id="8935" opendate="2015-3-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh: Make the column order in COPY FROM more apparent</summary>
      <description>When running COPY FROM, we should print the order of columns that we're expecting to make it more obvious when the data is not properly aligned. Otherwise, the user will simply see a type or syntax error and have to try to decipher it.</description>
      <version>2.1.12,2.2.4,3.0.1,3.1</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-11-14 01:00:00" id="8970" opendate="2015-3-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow custom time_format on cqlsh COPY TO</summary>
      <description>When executing a COPY TO from cqlsh, the user is currently has no control over the format of exported timestamp columns. If the user has indicated a time_format in their cqlshrc file, that format will be used. Otherwise, the system default format will be used.The problem comes into play when the timestamp format used on a COPY TO, is not valid when the data is sent back into Cassandra with a COPY FROM.For instance, if a user has time_format = %Y-%m-%d %H:%M:%S%Z specified in their cqlshrc, COPY TO will format timestamp columns like this:userid|posttime|postcontent0|2015-03-14 14:59:00CDT|rtyeryerweh0|2015-03-14 14:58:00CDT|sdfsdfsdgfjdsgojr0|2015-03-12 14:27:00CDT|sdgfjdsgojrExecuting a COPY FROM on that same file will produce an "unable to coerce to formatted date(long)" error.Right now, the only way to change the way timestamps are formatted is to exit cqlsh, modify the time_format property in cqlshrc, and restart cqlsh. The ability to specify a COPY option of TIME_FORMAT with a Python strftime format, would allow the user to quickly alter the timestamp format for export, without reconfiguring cqlsh.aploetz@cqlsh:stackoverflow&gt; COPY posts1 TO '/home/aploetz/posts1.csv' WITH DELIMITER='|' AND HEADER=true AND TIME_FORMAT='%Y-%m-%d %H:%M:%S%z;</description>
      <version>2.1.12,2.2.4,3.0.0rc2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-11-26 01:00:00" id="9043" opendate="2015-3-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve COPY command to work with Counter columns</summary>
      <description>Noticed today that the copy command doesn't work with counter column tables.This makes sense given that we need to use UPDATE instead of INSERT with counters.Given that we're making improvements in the COPY command in 3.0 with CASSANDRA-7405, can we also tweak it to work with counters?</description>
      <version>2.1.12,2.2.4,3.0.1,3.1</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-11-5 01:00:00" id="9304" opendate="2015-5-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>COPY TO improvements</summary>
      <description>COPY FROM has gotten a lot of love. COPY TO not so much. One obvious improvement could be to parallelize reading and writing (write one page of data while fetching the next).</description>
      <version>2.1.12,2.2.4,3.0.1,3.1</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.formatting.py</file>
      <file type="M">pylib.cqlshlib.displaying.py</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  
</bugrepository>