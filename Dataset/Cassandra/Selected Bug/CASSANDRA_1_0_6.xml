<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="CASSANDRA">
  
  
  <bug fixdate="2011-12-8 01:00:00" id="3337" opendate="2011-10-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create a way to obliterate nodes from the ring</summary>
      <description>Sometimes you just want a token gone: no re-replication, nothing, just excise it.</description>
      <version>1.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.gms.GossiperMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.Gossiper.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-11-28 01:00:00" id="3419" opendate="2011-10-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>CQL queries should allow CF names to be qualified by keyspace, part 2</summary>
      <description>See CASSANDRA-3130. The same treatment should be applied to the other related CQL commands dealing with column family names, viz: INSERT UPDATE DELETE TRUNCATEAlso, if the intent is to make it possible to go without USE entirely (I'm not sure if it is): CREATE COLUMNFAMILY CREATE INDEX DROP COLUMNFAMILY ALTER COLUMNFAMILY DROP INDEX (support keyspacename.indexname?)</description>
      <version>1.0.6</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql.UpdateStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.QueryProcessor.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.DeleteStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.Cql.g</file>
      <file type="M">src.java.org.apache.cassandra.cql.AbstractModification.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-12-29 01:00:00" id="3422" opendate="2011-10-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Can create a Column Family with comparator CounterColumnType which is subsequently unusable</summary>
      <description>It's probably the case that this shouldn't be allowed at all but one is currently allowed to create a Column Family with comparator CounterColumnType which then appears unusable.CREATE COLUMNFAMILY comparator_cf_counter (id text PRIMARY KEY) WITH comparator=CounterColumnType FailsUPDATE comparator_cf_counter SET 1=1 + 1 WHERE id='test_key'Error =&gt; invalid operation for non commutative columnfamily comparator_cf_counter</description>
      <version>0.8.9,1.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql.CreateColumnFamilyStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-12-4 01:00:00" id="3457" opendate="2011-11-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make cqlsh look for a suitable python version</summary>
      <description>On RHEL 5, which I guess we still want to support, the default "python" in the path is still 2.4. cqlsh does use a fair number of python features introduced in 2.5, like collections.defaultdict, functools.partial, generators. We can require RHEL 5 users to install a later python from EPEL, but we'd have to call it as 'python2.5', or 'python2.6', etc.So rather than take the time to vet everything against python2.4, we may want to make a wrapper script for cqlsh that checks for the existence of python2.7, 2.6, and 2.5, and calls the appropriate one to run the real cqlsh.</description>
      <version>1.0.6</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-12-13 01:00:00" id="3489" opendate="2011-11-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>EncryptionOptions should be instantiated</summary>
      <description>As the title says, otherwise you get an NPE when the options are missing from the yaml. It's included in my second patch on CASSANDRA-3045 and is a one line fix.</description>
      <version>1.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2011-11-29 01:00:00" id="3541" opendate="2011-11-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support timeuuid column names</summary>
      <description>Real-world Cassandra applications often use "wide rows" to denormalize queries into. Most often, this means they do a lot of appending to existing rows, with few overwrites. An easy way to add this to Stress would be to allow specifying timeuuid column names (which will be inherently sequential, or nearly so). For forwards-compatibility, we could add a --comparator option that only supports the existing Ascii type and the proposed UUID type, to start with.</description>
      <version>1.0.6</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.operations.CqlInserter.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.util.Operation.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.Session.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.operations.Inserter.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-12-1 01:00:00" id="3551" opendate="2011-12-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Timeout exception for quorum reads after upgrade from 1.0.2 to 1.0.5</summary>
      <description>I upgraded from 1.0.2 to 1.0.5. For some column families always got TimeoutException. I turned on debug and increase rpc_timeout to 1 minute, but still got timeout. I believe it is bug on 1.0.5.ConsistencyLevel is QUORUM, replicate factor is 3. Here are partial logs. DEBUG &amp;#91;pool-2-thread-1&amp;#93; 2011-12-01 22:25:39,717 StorageProxy.java (line 813) RangeSliceCommand{keyspace='keyspaceLBSDATAPRODUS', column_family='dataProvider', super_column=null, predicate=SlicePredicate(slice_range:SliceRange(start:80 01 00 01 00 00 00 10 67 65 74 5F 72 61 6E 67 65 5F 73 6C 69 63 65 73 00 00 00 03 0C 00 01 0B 00 03 00 00 00 0C 64 61 74 61 50 72 6F 76 69 64 65 72 00 0C 00 02 0C 00 02 0B 00 01 00 00 00 00, finish:80 01 00 01 00 00 00 10 67 65 74 5F 72 61 6E 67 65 5F 73 6C 69 63 65 73 00 00 00 03 0C 00 01 0B 00 03 00 00 00 0C 64 61 74 61 50 72 6F 76 69 64 65 72 00 0C 00 02 0C 00 02 0B 00 01 00 00 00 00 0B 00 02 00 00 00 00, reversed:false, count:1024)), range=[PROD/US/000/0,PROD/US/999/99999], max_keys=1024}DEBUG &amp;#91;pool-2-thread-1&amp;#93; 2011-12-01 22:25:39,718 StorageProxy.java (line 1012) restricted ranges for query &amp;#91;PROD/US/000/0,PROD/US/999/99999&amp;#93; are [&amp;#91;PROD/US/000/0,PROD/US/300/~&amp;#93;, (PROD/US/300/~,PROD/US/600/], (PROD/US/600/,PROD/US/999/99999]]DEBUG &amp;#91;pool-2-thread-1&amp;#93; 2011-12-01 22:25:39,720 VoxeoStrategy.java (line 157) ReplicationFactor 3DEBUG &amp;#91;pool-2-thread-1&amp;#93; 2011-12-01 22:25:39,720 VoxeoStrategy.java (line 33) PROD/US/300/~DEBUG &amp;#91;pool-2-thread-1&amp;#93; 2011-12-01 22:25:39,721 VoxeoStrategy.java (line 96) End region for token PROD/US/300/~ PROD/US/300/~ 10.92.208.103DEBUG &amp;#91;pool-2-thread-1&amp;#93; 2011-12-01 22:25:39,721 VoxeoStrategy.java (line 96) End region for token PROD/US/300/~ PROD/US/600/~ 10.72.208.103DEBUG &amp;#91;pool-2-thread-1&amp;#93; 2011-12-01 22:25:39,721 VoxeoStrategy.java (line 96) End region for token PROD/US/300/~ PROD/US/999/~ 10.8.208.103DEBUG &amp;#91;pool-2-thread-1&amp;#93; 2011-12-01 22:25:39,723 VoxeoStrategy.java (line 157) ReplicationFactor 3DEBUG &amp;#91;pool-2-thread-1&amp;#93; 2011-12-01 22:25:39,724 ReadCallback.java (line 77) Blockfor/repair is 2/false; setting up requests to /10.92.208.103,/10.72.208.103DEBUG &amp;#91;WRITE-/10.92.208.103&amp;#93; 2011-12-01 22:25:39,725 OutboundTcpConnection.java (line 206) attempting to connect to /10.92.208.103DEBUG &amp;#91;pool-2-thread-1&amp;#93; 2011-12-01 22:25:39,726 StorageProxy.java (line 859) reading RangeSliceCommand{keyspace='keyspaceLBSDATAPRODUS', column_family='dataProvider', super_column=null, predicate=SlicePredicate(slice_range:SliceRange(start:80 01 00 01 00 00 00 10 67 65 74 5F 72 61 6E 67 65 5F 73 6C 69 63 65 73 00 00 00 03 0C 00 01 0B 00 03 00 00 00 0C 64 61 74 61 50 72 6F 76 69 64 65 72 00 0C 00 02 0C 00 02 0B 00 01 00 00 00 00, finish:80 01 00 01 00 00 00 10 67 65 74 5F 72 61 6E 67 65 5F 73 6C 69 63 65 73 00 00 00 03 0C 00 01 0B 00 03 00 00 00 0C 64 61 74 61 50 72 6F 76 69 64 65 72 00 0C 00 02 0C 00 02 0B 00 01 00 00 00 00 0B 00 02 00 00 00 00, reversed:false, count:1024)), range=[PROD/US/000/0,PROD/US/300/~], max_keys=1024} from /10.92.208.103DEBUG &amp;#91;pool-2-thread-1&amp;#93; 2011-12-01 22:25:39,726 StorageProxy.java (line 859) reading RangeSliceCommand{keyspace='keyspaceLBSDATAPRODUS', column_family='dataProvider', super_column=null, predicate=SlicePredicate(slice_range:SliceRange(start:80 01 00 01 00 00 00 10 67 65 74 5F 72 61 6E 67 65 5F 73 6C 69 63 65 73 00 00 00 03 0C 00 01 0B 00 03 00 00 00 0C 64 61 74 61 50 72 6F 76 69 64 65 72 00 0C 00 02 0C 00 02 0B 00 01 00 00 00 00, finish:80 01 00 01 00 00 00 10 67 65 74 5F 72 61 6E 67 65 5F 73 6C 69 63 65 73 00 00 00 03 0C 00 01 0B 00 03 00 00 00 0C 64 61 74 61 50 72 6F 76 69 64 65 72 00 0C 00 02 0C 00 02 0B 00 01 00 00 00 00 0B 00 02 00 00 00 00, reversed:false, count:1024)), range=[PROD/US/000/0,PROD/US/300/~], max_keys=1024} from /10.72.208.103DEBUG &amp;#91;WRITE-/10.8.208.103&amp;#93; 2011-12-01 22:25:39,727 OutboundTcpConnection.java (line 206) attempting to connect to /10.8.208.103DEBUG &amp;#91;pool-2-thread-1&amp;#93; 2011-12-01 22:25:39,727 StorageProxy.java (line 859) reading RangeSliceCommand{keyspace='keyspaceLBSDATAPRODUS', column_family='dataProvider', super_column=null, predicate=SlicePredicate(slice_range:SliceRange(start:80 01 00 01 00 00 00 10 67 65 74 5F 72 61 6E 67 65 5F 73 6C 69 63 65 73 00 00 00 03 0C 00 01 0B 00 03 00 00 00 0C 64 61 74 61 50 72 6F 76 69 64 65 72 00 0C 00 02 0C 00 02 0B 00 01 00 00 00 00, finish:80 01 00 01 00 00 00 10 67 65 74 5F 72 61 6E 67 65 5F 73 6C 69 63 65 73 00 00 00 03 0C 00 01 0B 00 03 00 00 00 0C 64 61 74 61 50 72 6F 76 69 64 65 72 00 0C 00 02 0C 00 02 0B 00 01 00 00 00 00 0B 00 02 00 00 00 00, reversed:false, count:1024)), range=[PROD/US/000/0,PROD/US/300/~], max_keys=1024} from /10.8.208.103DEBUG &amp;#91;ReadStage:1&amp;#93; 2011-12-01 22:25:39,731 SliceQueryFilter.java (line 123) collecting 0 of 1024: active:false:1@1322777621601000DEBUG &amp;#91;ReadStage:1&amp;#93; 2011-12-01 22:25:39,731 SliceQueryFilter.java (line 123) collecting 1 of 1024: name:false:4@1322777621601000DEBUG &amp;#91;ReadStage:1&amp;#93; 2011-12-01 22:25:39,731 SliceQueryFilter.java (line 123) collecting 2 of 1024: providerData:false:2283@1321549067179000DEBUG &amp;#91;ReadStage:1&amp;#93; 2011-12-01 22:25:39,731 SliceQueryFilter.java (line 123) collecting 3 of 1024: providerID:false:1@1322777621601000DEBUG &amp;#91;ReadStage:1&amp;#93; 2011-12-01 22:25:39,732 SliceQueryFilter.java (line 123) collecting 4 of 1024: timestamp:false:13@1322777621601000DEBUG &amp;#91;ReadStage:1&amp;#93; 2011-12-01 22:25:39,732 SliceQueryFilter.java (line 123) collecting 5 of 1024: vendorData:false:2364@1322777621601000DEBUG &amp;#91;ReadStage:1&amp;#93; 2011-12-01 22:25:39,733 ColumnFamilyStore.java (line 1331) scanned DecoratedKey(PROD/US/001/1, 50524f442f55532f3030312f31)DEBUG &amp;#91;ReadStage:1&amp;#93; 2011-12-01 22:25:39,733 RangeSliceVerbHandler.java (line 55) Sending RangeSliceReply{rows=Row(key=DecoratedKey(PROD/US/001/1, 50524f442f55532f3030312f31), cf=ColumnFamily(dataProvider [active:false:1@1322777621601000,name:false:4@1322777621601000,providerData:false:2283@1321549067179000,providerID:false:1@1322777621601000,timestamp:false:13@1322777621601000,vendorData:false:2364@1322777621601000,]))} to 72@/10.72.208.103DEBUG &amp;#91;RequestResponseStage:1&amp;#93; 2011-12-01 22:25:39,734 ResponseVerbHandler.java (line 44) Processing response on a callback from 72@/10.72.208.103DEBUG &amp;#91;RequestResponseStage:2&amp;#93; 2011-12-01 22:25:39,887 ResponseVerbHandler.java (line 44) Processing response on a callback from 71@/10.92.208.103DEBUG &amp;#91;pool-2-thread-1&amp;#93; 2011-12-01 22:25:39,889 SliceQueryFilter.java (line 123) collecting 0 of 2147483647: active:false:1@1322777621601000DEBUG &amp;#91;pool-2-thread-1&amp;#93; 2011-12-01 22:25:39,890 SliceQueryFilter.java (line 123) collecting 1 of 2147483647: name:false:4@1322777621601000DEBUG &amp;#91;pool-2-thread-1&amp;#93; 2011-12-01 22:25:39,890 SliceQueryFilter.java (line 123) collecting 2 of 2147483647: providerData:false:2283@1321549067179000DEBUG &amp;#91;pool-2-thread-1&amp;#93; 2011-12-01 22:25:39,890 SliceQueryFilter.java (line 123) collecting 3 of 2147483647: providerID:false:1@1322777621601000DEBUG &amp;#91;pool-2-thread-1&amp;#93; 2011-12-01 22:25:39,890 SliceQueryFilter.java (line 123) collecting 4 of 2147483647: timestamp:false:13@1322777621601000DEBUG &amp;#91;pool-2-thread-1&amp;#93; 2011-12-01 22:25:39,891 SliceQueryFilter.java (line 123) collecting 5 of 2147483647: vendorData:false:2364@1322777621601000DEBUG &amp;#91;pool-2-thread-1&amp;#93; 2011-12-01 22:25:39,892 StorageProxy.java (line 867) range slices read DecoratedKey(PROD/US/001/1, 50524f442f55532f3030312f31)DEBUG &amp;#91;RequestResponseStage:3&amp;#93; 2011-12-01 22:25:39,936 ResponseVerbHandler.java (line 44) Processing response on a callback from 73@/10.8.208.103DEBUG &amp;#91;ScheduledTasks:1&amp;#93; 2011-12-01 22:26:19,788 LoadBroadcaster.java (line 86) Disseminating load info ...DEBUG &amp;#91;pool-2-thread-1&amp;#93; 2011-12-01 22:26:39,904 StorageProxy.java (line 874) Range slice timeout: java.util.concurrent.TimeoutException: Operation timed out.</description>
      <version>1.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.ReadRepairVerbHandler.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-12-2 01:00:00" id="3556" opendate="2011-12-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>nodetool info reports inaccurate datacenter/rack for localhost</summary>
      <description>The datacenter &amp; rack information provided by 'nodetool info' is incorrect when using 'nodetool -h localhost info'. This is because the IP address passed to the EndpointSnitch to determine the datacenter &amp; rack is sourced from the host parameter provided to nodetool and not the actual endpoint address used in the ring.</description>
      <version>0.8.9,1.0.6</version>
      <fixedVersion>Tool/nodetool</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeProbe.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2011-12-2 01:00:00" id="3563" opendate="2011-12-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Packaging should increase vm.max_map_count to accommodate leveled compaction</summary>
      <description>As the title says, leveled can create a lot of files and you can run into an IOError trying to mmap all of them.</description>
      <version>1.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">debian.rules</file>
      <file type="M">debian.cassandra.postinst</file>
      <file type="M">debian.cassandra.install</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-12-7 01:00:00" id="3584" opendate="2011-12-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Check for 0.0.0.0 is incorrect</summary>
      <description>As noted by Jake in the comments to CASSANDRA-3214, we are using == for a String comparison.</description>
      <version>1.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.hadoop.ColumnFamilyInputFormat.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-1-7 01:00:00" id="3586" opendate="2011-12-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add new SHOW command in CQL shell to list column families</summary>
      <description>add command SHOW COLUMN FAMILIES to list all column families in a current keyspace by name.</description>
      <version>None</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-1-7 01:00:00" id="3587" opendate="2011-12-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>DESC alias for DESCRIBE keyword in CQL shell</summary>
      <description>Allow DESC to be used instead of full DESCRIBE keyword. MySQL and Oracle users are used to DESC.</description>
      <version>None</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-12-7 01:00:00" id="3588" opendate="2011-12-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh: HELP for DELETE_USING and DELETE_COLUMNS broken</summary>
      <description>type "HELP DELETE_USING" or "HELP DELETE_COLUMNS" in cqlsh. both of those are referred to by the HELP index, by tab-completion after "HELP", and in the help text for DELETE.nothing is shown but a new command prompt.</description>
      <version>1.0.6</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-12-8 01:00:00" id="3591" opendate="2011-12-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>a better exception than "Keyspace names must be case-insensitively unique"</summary>
      <description>The exception "Keyspace names must be case-insensitively unique" does not give the implied names.</description>
      <version>1.0.6</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.thrift.ThriftValidation.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-12-8 01:00:00" id="3596" opendate="2011-12-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh: DESCRIBE output for a columnfamily does not work as input to same C* instance</summary>
      <description>The DESCRIBE COLUMNFAMILY cqlsh command produces output that is intended to be usable as valid CQL (at least, when given to another Cassandra instance of the same version). But the output yields errors when run:cqlsh&gt; USE blah;cqlsh:blah&gt; CREATE COLUMNFAMILY cf1 (c1 int PRIMARY KEY, c2 varchar);cqlsh:blah&gt; DESCRIBE COLUMNFAMILY cf1;CREATE COLUMNFAMILY cf1 ( c1 int PRIMARY KEY, c2 text) WITH comment='' AND comparator=text AND row_cache_provider='ConcurrentLinkedHashCacheProvider' AND key_cache_size=200000.000000 AND row_cache_size=0.000000 AND read_repair_chance=0.100000 AND gc_grace_seconds=864000 AND default_validation=text AND min_compaction_threshold=4 AND max_compaction_threshold=32 AND row_cache_save_period_in_seconds=0 AND key_cache_save_period_in_seconds=14400 AND replication_on_write=True;cqlsh:blah&gt; CREATE COLUMNFAMILY cf1 ( ... c1 int PRIMARY KEY, ... c2 text ... ) WITH ... comment='' AND ... comparator=text AND ... row_cache_provider='ConcurrentLinkedHashCacheProvider' AND ... key_cache_size=200000.000000 AND ... row_cache_size=0.000000 AND ... read_repair_chance=0.100000 AND ... gc_grace_seconds=864000 AND ... default_validation=text AND ... min_compaction_threshold=4 AND ... max_compaction_threshold=32 AND ... row_cache_save_period_in_seconds=0 AND ... key_cache_save_period_in_seconds=14400 AND ... replication_on_write=True;Bad Request: replication_on_write is not a valid keyword argument for CREATE COLUMNFAMILYSo it needs to do a better job of determining which CF attributes are valid for which C* versions.</description>
      <version>1.0.6</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.cqlhandling.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-12-8 01:00:00" id="3598" opendate="2011-12-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Index Scan&amp;#39;s will span across multiple DC&amp;#39;s</summary>
      <description>Looks like we send requests to all the nodes provided by StorageService.instance.getLiveNaturalEndpoints(keyspace, range.right);We dont filter it based on blockedFor (Consistency levels).In a multi DC setup this will cause unnecessary load on the other DC. And even within a DC we might query more nodes than needed.</description>
      <version>0.7.4,0.8.9,1.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
</bugrepository>