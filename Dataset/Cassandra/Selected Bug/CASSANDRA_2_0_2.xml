<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="CASSANDRA">
  <bug fixdate="2012-9-15 01:00:00" id="3916" opendate="2012-2-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Do not bind the storage_port if internode_encryption = all</summary>
      <description>We are highly security conscious and having additional clear text ports open are undesirable.I have modified locally to get around but it seems that this is a very trivial fix to only bind the clear text storage_port if the internode_encryption is not all. If all is selected then no clear text communication should be permitted.</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-10-9 01:00:00" id="4430" opendate="2012-7-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>optional pluggable o.a.c.metrics reporters</summary>
      <description>CASSANDRA-4009 expanded the use of the metrics library which has a set of reporter modules http://metrics.codahale.com/manual/core/#reporters You can report to flat files, ganglia, spit everything over http, etc. The next step is a mechanism for using those reporters with o.a.c.metrics. To avoid bundling everything I suggest following the mx4j approach of "enable only if on classpath coupled with a reporter configuration file.Strawman file:console: time: 1 timeunit: "seconds"csv: - time: 1 timeunit: minutes file: foo.csv - time: 10 timeunit: seconds file: bar.csvganglia: - time: 30 timunit: seconds host: server-1 port: 8649 - time: 30 timunit: seconds host: server-2 port: 8649</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.CassandraDaemon.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-10-16 01:00:00" id="4549" opendate="2012-8-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update the pig examples to include more recent pig/cassandra features</summary>
      <description>Now that there is support for a variety of Cassandra features from Pig (esp 1.1+), it would great to have some of them in the examples so that people can see how to use them.</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">examples.pig.example-script.pig</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2013-8-26 01:00:00" id="5517" opendate="2013-4-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cassandra crashes at start with segmentation fault</summary>
      <description>Sometimes Cassandra fails at start with segmentation fault: /usr/sbin/cassandra -fxss = -ea -javaajent:/usr/share/cassandra/lib/jamm-0.2.5.jar -XX:+UseThreadPriorities -XX:ThreadPriorityPolicy=42 -Xms1024M -Xmx1024M -Xmn100M -XX:+HeapDumpOnOutOfMemoryError -Xss180kSegmentation faultIt seems that not only me encountered this bug: http://snapwebsites.org/known-issues/cassandra-crashes-java-segmentation-faultSolution proposed on this link works.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">conf.cassandra-env.sh</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-9-8 01:00:00" id="5730" opendate="2013-7-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Re-add ScrubTest post single-pass compaction</summary>
      <description>Follow up of CASSANDRA-5429 for adding back a ScrubTest.</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.data.corrupt-sstables.Keyspace1-Standard3-ja-1-TOC.txt</file>
      <file type="M">test.data.corrupt-sstables.Keyspace1-Standard3-ja-1-Summary.db</file>
      <file type="M">test.data.corrupt-sstables.Keyspace1-Standard3-ja-1-Statistics.db</file>
      <file type="M">test.data.corrupt-sstables.Keyspace1-Standard3-ja-1-Index.db</file>
      <file type="M">test.data.corrupt-sstables.Keyspace1-Standard3-ja-1-Filter.db</file>
      <file type="M">test.data.corrupt-sstables.Keyspace1-Standard3-ja-1-Digest.sha1</file>
      <file type="M">test.data.corrupt-sstables.Keyspace1-Standard3-ja-1-Data.db</file>
      <file type="M">test.data.corrupt-sstables.Keyspace1-Standard3-ja-1-CRC.db</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-10-14 01:00:00" id="5889" opendate="2013-8-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>add tombstone metrics to cfstats or cfhistograms</summary>
      <description>/cc pmcfadin</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStoreMBean.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-10-21 01:00:00" id="5916" opendate="2013-8-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>gossip and tokenMetadata get hostId out of sync on failed replace_node with the same IP address</summary>
      <description>If you try to replace_node an existing, live hostId, it will error out. However if you're using an existing IP to do this (as in, you chose the wrong uuid to replace on accident) then the newly generated hostId wipes out the old one in TMD, and when you do try to replace it replace_node will complain it does not exist. Examination of gossipinfo still shows the old hostId, however now you can't replace it either.</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.Gossiper.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.GossipDigestSynVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.GossipDigestAckVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.db.SystemTable.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">NEWS.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-9-29 01:00:00" id="5950" opendate="2013-8-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make snapshot/sequential repair the default</summary>
      <description/>
      <version>2.0.2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.resources.org.apache.cassandra.tools.NodeToolHelp.yaml</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-10-12 01:00:00" id="6016" opendate="2013-9-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Ability to change replication factor for the trace keyspace</summary>
      <description>They trace keyspace is currently RF=1, and can't be changed. I want to be able to trace stuff when nodes are down/being stupid.</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.ClientState.java</file>
      <file type="M">src.java.org.apache.cassandra.service.CassandraDaemon.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Schema.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">pylib.cqlshlib.cql3handling.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-9-17 01:00:00" id="6037" opendate="2013-9-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Parens around WHERE condition break query</summary>
      <description>SELECT * FROM user WHERE (key=&lt;UUID&gt;);Bad Request: line 1:25 no viable alternative at input '('SELECT * FROM user WHERE key=&lt;UUID&gt;; &amp;#8211; No parens&amp;#8211; Normal outputThe example provided is minimal, bug was discovered with AND logic on indexed columns.Parens-enclosed conditions is good SQL and so is produced by database abstraction layers in complex queries to avoid operation precedence problems.Fixing this at application side is no option - this will open the can of logic bugs.</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.Cql.g</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-9-19 01:00:00" id="6059" opendate="2013-9-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve memory-use defaults</summary>
      <description>Anecdotally, it's still too easy to OOM Cassandra even after moving sstable internals off heap.</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-9-19 01:00:00" id="6069" opendate="2013-9-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Sets not stored by INSERT with IF NOT EXISTS</summary>
      <description>An INSERT of a set column type is not stored when using IF NOT EXISTS</description>
      <version>2.0.2</version>
      <fixedVersion>Feature/LightweightTransactions</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.paxos.Commit.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-9-23 01:00:00" id="6081" opendate="2013-9-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thrift validation refuses row markers on CQL3 tables</summary>
      <description>CASSANDRA-5138 don't let row markers pass. It should.</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.thrift.ThriftValidation.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-9-25 01:00:00" id="6093" opendate="2013-9-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cant migrate json manifest with multiple data directories</summary>
      <description>http://mail-archives.apache.org/mod_mbox/cassandra-user/201309.mbox/%3C002401ceb980%2485a26d10%2490e74730%24%40struq.com%3Emost likely due to having multiple data dirs</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LegacyLeveledManifest.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-10-1 01:00:00" id="6117" opendate="2013-10-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Avoid death-by-tombstone by default</summary>
      <description>We added warnings to 1.2 (CASSANDRA-6042); for 2.0 we should go farther and drop requests (with an error logged) that exceed the threshold. Users who want to tread dangerously are free to crank the threshold up, but "I queried a lot of tombstones and Cassandra fell over" is possibly the number one way of killing Cassandra nodes right now.</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageServiceMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.RangeSliceVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ReadVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.SliceQueryFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.db.columniterator.IdentityQueryFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-10-1 01:00:00" id="6128" opendate="2013-10-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add more data mappings for Pig</summary>
      <description>We need add more data mappings for DecimalType InetAddressType LexicalUUIDType TimeUUIDType UUIDTypeExisting implementation throws exception for those data type</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.hadoop.pig.CqlStorage.java</file>
      <file type="M">src.java.org.apache.cassandra.hadoop.pig.CassandraStorage.java</file>
      <file type="M">src.java.org.apache.cassandra.hadoop.pig.AbstractCassandraStorage.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-10-2 01:00:00" id="6136" opendate="2013-10-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>CQL should not allow an empty string as column identifier</summary>
      <description>CQL currently allows users to create a table with an empty string as column identifier:CREATE TABLE t (k int primary key, "" int);Which results in the following table:CREATE TABLE t ( k int, "" int, PRIMARY KEY (k)) WITH bloom_filter_fp_chance=0.010000 AND caching='KEYS_ONLY' AND comment='' AND dclocal_read_repair_chance=0.000000 AND gc_grace_seconds=864000 AND index_interval=128 AND read_repair_chance=0.100000 AND replicate_on_write='true' AND populate_io_cache_on_flush='false' AND default_time_to_live=0 AND speculative_retry='NONE' AND memtable_flush_period_in_ms=0 AND compaction={'class': 'SizeTieredCompactionStrategy'} AND compression={'sstable_compression': 'SnappyCompressor'};Empty strings are not allowed for keyspace and table identifiers though.I guess it's just a case that we haven't covered. Of course making it illegal in a future version would be a breaking change, but nobody serious would manually have chosen such an identifier...</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.Cql.g</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-10-3 01:00:00" id="6139" opendate="2013-10-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cqlsh shouldn&amp;#39;t display empty "value alias"</summary>
      <description>When someone creates:CREATE TABLE foo ( k int, v int, PRIMARY KEY (k, v)) WITH COMPACT STORAGEthen we internally create a "value alias" (1.2)/"compact value definition" (2.0) with an empty name. Seems that cqlsh don't recognize that fact and display that as:cqlsh:ks&gt; DESC TABLE foo;CREATE TABLE foo ( k int, v int, "" blob, PRIMARY KEY (k, v)) WITH COMPACT STORAGE AND ...</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.cql3handling.py</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-10-8 01:00:00" id="6164" opendate="2013-10-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Switch CFS histograms to biased sampling</summary>
      <description/>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.metrics.ColumnFamilyMetrics.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStoreMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-10-9 01:00:00" id="6175" opendate="2013-10-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>counter increment hangs</summary>
      <description>In a three node cluster, a simple counter increment at quorum hangs the query indefinitely. git blames our familiar friend CASSANDRA-6132 once again.</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-10-11 01:00:00" id="6183" opendate="2013-10-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Skip mutations that pass CRC but fail to deserialize</summary>
      <description>We've had a couple reports of CL replay failure that appear to be caused by dropping and recreating the same table with a different schema, e.g. CASSANDRA-5905. While CASSANDRA-5202 is the "right" fix for this, it's too involved for 2.0 let alone 1.2, so we need a stopgap until then.</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLogReplayer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-10-13 01:00:00" id="6191" opendate="2013-10-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a warning for small sstable size setting in LCS</summary>
      <description>Not sure "bug" is the right description, because I can't say for sure that the large number of SSTables is the cause of the memory issues. I'll share my research so far:Under high read-load with a very large number of compressed SSTables (caused by the initial default 5mb sstable_size in LCS) it seems memory is exhausted, without any room for GC to fix this. It tries to GC but doesn't reclaim much.The node first hits the "emergency valves" flushing all memtables, then reducing caches. And finally logs 0.99+ heap usages and hangs with GC failure or crashes with OutOfMemoryError.I've taken a heapdump and started analysis to find out what's wrong. The memory seems to be used by the byte[] backing the HeapByteBuffer in the "compressed" field of org.apache.cassandra.io.compress.CompressedRandomAccessReader. The byte[] are generally 65536 byes in size, matching the block-size of the compression.Looking further in the heap-dump I can see that these readers are part of the pool in org.apache.cassandra.io.util.CompressedPoolingSegmentedFile. Which is linked to the "dfile" field of org.apache.cassandra.io.sstable.SSTableReader. The dump-file lists 45248 instances of CompressedRandomAccessReader.Is this intended to go this way? Is there a leak somewhere? Or should there be an alternative strategy and/or warning for cases where a node is trying to read far too many SSTables?EDIT:Searching through the code I found that PoolingSegmentedFile keeps a pool of RandomAccessReader for re-use. While the CompressedRandomAccessReader allocates a ByteBuffer in it's constructor and (to make things worse) enlarges it if it's reasing a large chunk. This (sometimes enlarged) ByteBuffer is then kept alive because it becomes part of the CompressedRandomAccessReader which is in turn kept alive as part of the pool in the PoolingSegmentedFile.</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LeveledCompactionStrategy.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-10-13 01:00:00" id="6196" opendate="2013-10-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add compaction, compression to cqlsh tab completion for CREATE TABLE</summary>
      <description/>
      <version>1.2.12,2.0.2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.cql3handling.py</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-10-14 01:00:00" id="6197" opendate="2013-10-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create more Pig unit tests for type mappings</summary>
      <description>We need add more Pig unit testing for data type mappings including collections</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.hadoop.pig.CqlStorage.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-10-17 01:00:00" id="6211" opendate="2013-10-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>NPE in system.log</summary>
      <description>I wrote a stresstest to test C* and my code that uses CAS heavily. I see strange exception messages in logs:ERROR [MutationStage:320] 2013-10-17 13:59:10,710 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:320,5,main]java.lang.NullPointerExceptionERROR [MutationStage:328] 2013-10-17 13:59:10,718 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:328,5,main]java.lang.NullPointerExceptionERROR [MutationStage:327] 2013-10-17 13:59:10,732 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:327,5,main]java.lang.NullPointerExceptionERROR [MutationStage:325] 2013-10-17 13:59:10,750 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:325,5,main]java.lang.NullPointerExceptionERROR [MutationStage:326] 2013-10-17 13:59:10,762 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:326,5,main]java.lang.NullPointerExceptionERROR [MutationStage:330] 2013-10-17 13:59:10,768 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:330,5,main]java.lang.NullPointerExceptionERROR [MutationStage:331] 2013-10-17 13:59:10,775 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:331,5,main]java.lang.NullPointerExceptionERROR [MutationStage:334] 2013-10-17 13:59:10,789 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:334,5,main]java.lang.NullPointerExceptionERROR [MutationStage:329] 2013-10-17 13:59:10,803 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:329,5,main]java.lang.NullPointerExceptionERROR [MutationStage:335] 2013-10-17 13:59:10,812 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:335,5,main]java.lang.NullPointerExceptionERROR [MutationStage:333] 2013-10-17 13:59:10,826 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:333,5,main]java.lang.NullPointerExceptionERROR [MutationStage:332] 2013-10-17 13:59:10,834 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:332,5,main]java.lang.NullPointerExceptionERROR [MutationStage:337] 2013-10-17 13:59:10,842 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:337,5,main]java.lang.NullPointerExceptionERROR [MutationStage:336] 2013-10-17 13:59:10,859 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:336,5,main]java.lang.NullPointerExceptionERROR [MutationStage:338] 2013-10-17 13:59:10,870 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:338,5,main]java.lang.NullPointerExceptionERROR [MutationStage:339] 2013-10-17 13:59:10,884 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:339,5,main]java.lang.NullPointerExceptionERROR [MutationStage:341] 2013-10-17 13:59:10,894 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:341,5,main]java.lang.NullPointerExceptionERROR [MutationStage:340] 2013-10-17 13:59:10,910 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:340,5,main]java.lang.NullPointerExceptionERROR [MutationStage:344] 2013-10-17 13:59:10,920 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:344,5,main]java.lang.NullPointerException</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.SystemKeyspace.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-10-17 01:00:00" id="6213" opendate="2013-10-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Updating Pig to 0.11.1 breaks the existing Pig driver</summary>
      <description>Current trunk upgrades Pig to 0.11.1 which causes the Pig storages code can't compile. Pig storages need implement the new API method cleanupOnSuccess(String,Job).</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.hadoop.pig.AbstractCassandraStorage.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-10-18 01:00:00" id="6217" opendate="2013-10-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>replace doesn&amp;#39;t clean up system.peers if you have a new IP</summary>
      <description>When you use replace_token (or replace_node or replace_address) if the new node has a different IP, the old node will still be in system.peers</description>
      <version>1.2.12,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
    </fixedFiles>
  </bug>
</bugrepository>