<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="CASSANDRA">
  
  
  
  
  <bug fixdate="2014-5-28 01:00:00" id="6950" opendate="2014-3-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Secondary index query fails with tc range query when ordered by DESC</summary>
      <description>create table test4 ( name text, lname text, tc bigint, record text, PRIMARY KEY ((name, lname), tc)) WITH CLUSTERING ORDER BY (tc DESC) AND compaction={'class': 'LeveledCompactionStrategy'}; create index test4_index ON test4(lname);Populate it with some data and non-zero tc values, then try: select * from test4 where lname='blah' and tc&gt;0 allow filtering;And, (0 rows) returned, even though there are rows which should be found.When I create the table using CLUSTERING ORDER BY (tc ASC), the above query works. Rows are correctly returned based on the range check.Tried various combinations but with descending order on tc nothing works.</description>
      <version>2.0.8</version>
      <fixedVersion>Feature/2iIndex</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2009-8-10 01:00:00" id="70" opendate="2009-4-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>MultiGet</summary>
      <description>Avinash is working on a multiget interface (requesting data from multiple keys at once).</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.service.QuorumResponseHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.net.MultiAsyncResult.java</file>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
      <file type="M">src.java.org.apache.cassandra.net.IMessagingService.java</file>
      <file type="M">src.java.org.apache.cassandra.net.IAsyncResult.java</file>
      <file type="M">src.java.org.apache.cassandra.net.AsyncResult.java</file>
      <file type="M">test.system.test.server.py</file>
      <file type="M">src.java.org.apache.cassandra.service.CassandraServer.java</file>
      <file type="M">interface.gen-java.org.apache.cassandra.service.Cassandra.java</file>
      <file type="M">interface.cassandra.thrift</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2014-4-17 01:00:00" id="7052" opendate="2014-4-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Query on compact storage with limit returns extra rows</summary>
      <description>I tested this on Cassandra 2.0.6 and 2.0.3 and got the same result on both:cqlsh&gt; create KEYSPACE "test" WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1};cqlsh&gt; USE "test";cqlsh:test&gt; CREATE COLUMNFAMILY "VerifyPagedColumnQueryStartAndEnd" ("keyId" text, "columnName" text, "value" text, PRIMARY KEY ("keyId", "columnName")) WITH COMPACT STORAGE;cqlsh:test&gt; INSERT INTO "VerifyPagedColumnQueryStartAndEnd" ("keyId", "columnName", "value") VALUES ( 'key', 'a', '1' ) ;cqlsh:test&gt; INSERT INTO "VerifyPagedColumnQueryStartAndEnd" ("keyId", "columnName", "value") VALUES ( 'key', 'b', '1' ) ;cqlsh:test&gt; INSERT INTO "VerifyPagedColumnQueryStartAndEnd" ("keyId", "columnName", "value") VALUES ( 'key', 'c', '1' ) ;cqlsh:test&gt; INSERT INTO "VerifyPagedColumnQueryStartAndEnd" ("keyId", "columnName", "value") VALUES ( 'key', 'd', '1' ) ;cqlsh:test&gt; INSERT INTO "VerifyPagedColumnQueryStartAndEnd" ("keyId", "columnName", "value") VALUES ( 'key', 'e', '1' ) ;cqlsh:test&gt; SELECT * FROM "VerifyPagedColumnQueryStartAndEnd" WHERE "keyId" = 'key' AND "columnName" &gt; '' AND "columnName" &lt;= 'e' LIMIT 2; keyId | columnName | value-------+------------+------- key | a | 1 key | b | 1 key | c | 1(3 rows)cqlsh:test&gt;</description>
      <version>2.0.8</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.pager.QueryPager.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-4-17 01:00:00" id="7053" opendate="2014-4-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>USING TIMESTAMP for batches does not work</summary>
      <description>When using the "USING TIMESTAMP &lt;timestamp&gt;" syntax for a batch statement, the supplied timestamp is ignored.</description>
      <version>2.0.8</version>
      <fixedVersion>Feature/LightweightTransactions</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.BatchStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-4-19 01:00:00" id="7058" opendate="2014-4-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HHOM and BM direct delivery should not cause hints to be written on timeout</summary>
      <description>Currently, a timed out HHOM hint delivery would create a further hint, with a wrong TTL. BM direct delivery code is using the same code snippet basically, so is also affected (with slightly worse consequences).</description>
      <version>1.2.17,2.0.8,2.1beta2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.HintedHandOffManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.BatchlogManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2014-5-24 01:00:00" id="7081" opendate="2014-4-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>select writetime(colname) returns 0 for static columns</summary>
      <description>Selecting the write time for a static column returns 0 in Cassandra 2.0 (c3550fe) and an expected timestamp in 2.1 (trunk, acdbbb9). Would it be possible to include this timestamp in a 2.0 release too?&gt; CREATE TABLE test (partition_key text, cluster_key text, data text, st text static, PRIMARY KEY(partition_key, cluster_key));&gt; INSERT INTO test (partition_key, cluster_key, data, st) VALUES ( 'PK', 'CK', 'DATA', 'ST');&gt; SELECT writetime(st), writetime(data) FROM test where partition_key='PK'; writetime(st) | writetime(data)---------------+------------------ 0 | 1398314681729000(1 rows)</description>
      <version>2.0.8</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.ColumnGroupMap.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-4-24 01:00:00" id="7087" opendate="2014-4-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use JMX_PORT for the RMI port to simplify nodetool connectivity</summary>
      <description>Mentioned in the user list by Steven Robenalt there is a config option in Java7 to allow configuring the port used for the followup rmi connection in JMX. It simplifies things a lot to have both connections use 7199 since it could be reused for both.There's a little-known change in the way JMX uses ports that was add to JDK7u4 which simplifies the use of JMX in a firewalled environment. The standard RMI registry port for JMX is controlled by the com.sun.management.jmxremote.port property. The change to Java 7 was to introduce the related com.sun.management.jmxremote.rmi.port property, Setting this second property means that JMX will use that second port, rather than a randomly assigned port, for making the actual connection. This solution works well in the AWS VPC environment that I'm running in, and I've heard of others using it successfully as well.</description>
      <version>2.0.8,2.1beta2</version>
      <fixedVersion>Local/Config</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.cassandra-env.sh</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2014-5-1 01:00:00" id="7132" opendate="2014-5-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a new Snitch for Google Cloud Platform</summary>
      <description>In order to correctly identify the rack and datacenter, the snitch needs to query the metadata from the host. I will be attaching a diff to this issue shortly with the new snitch file.</description>
      <version>2.0.8,2.1rc1</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-5-2 01:00:00" id="7142" opendate="2014-5-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Suggest CTRL-C/D or semicolon after three blank lines in cqlsh</summary>
      <description>After observing a few people use Cassandra and cqlsh for the first time, most of them miss a quote or a semi-colon in cqlsh and do something like this:cqlsh&gt; INSERT INTO users (name, email) VALUES ('joe', 'joe@gmail') ... ... ... ... ... If cqlsh gets three blank lines in a row, it could print something like:Statements are terminated with a ';'. You can press CTRL-C to cancel an imcomplete statement.</description>
      <version>2.0.8,2.1rc1</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2014-7-3 01:00:00" id="7147" opendate="2014-5-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a new snitch for Apache Cloudstack platforms</summary>
      <description>The attached patch adds a new Snitch that queries meta data for a host on Apache Cloudstack environments. Since the metadata service is colocated with the DHCP service in Cloudstack, common lease file locations are looked up to retrieve.Since zone naming is freeform in Apache Cloudstack, the widely used &lt;country&gt;&lt;location&gt;&lt;az&gt; notation is assumed.The patch includes a simple unit test and has been tested on exoscale.ch, a public cloud based on Apache Cloudstack</description>
      <version>1.2.18,2.0.8,2.1rc1</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
</bugrepository>