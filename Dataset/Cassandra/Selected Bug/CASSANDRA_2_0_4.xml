<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="CASSANDRA">
  
  <bug fixdate="2013-11-9 01:00:00" id="6172" opendate="2013-10-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>COPY TO command doesn&amp;#39;t escape single quote in collections</summary>
      <description>CREATE TABLE test (key text PRIMARY KEY , testcollection set&lt;text&gt;) ;INSERT INTO test (key, testcollection ) VALUES ( 'test', {'foo''bar'});COPY test TO '/tmp/test.csv';COPY test FROM '/tmp/test.csv';Bad Request: line 1:73 mismatched character '&lt;EOF&gt;' expecting '''Aborting import at record #0 (line 1). Previously-inserted values still present.Content of generated '/tmp/test.csv':test,{'foo'bar'}Unfortunately, I didn't find workaround with any combination of COPY options</description>
      <version>1.2.13,2.0.4</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.formatting.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2013-11-27 01:00:00" id="6409" opendate="2013-11-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>gossip performance improvement at node startup</summary>
      <description>With large clusters (&gt; 500 nodes) and num_tokens &gt; 255 we sometimes see a node have trouble starting up. CPU usage for one thread is pegged.We see this concurrent with Gossip flaps on the node trying to learn the ring topology. Other nodes on the ring, that are already at steady state do not seem to suffer. It is the node joining the large ring that has trouble.</description>
      <version>1.2.13,2.0.4</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-12-27 01:00:00" id="6415" opendate="2013-11-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Snapshot repair blocks for ever if something happens to the "I made my snapshot" response</summary>
      <description>The "snapshotLatch.await();" can be waiting for ever and block all repair operations indefinitely if something happens that another node doesn't respond. public void makeSnapshots(Collection&lt;InetAddress&gt; endpoints) { try { snapshotLatch = new CountDownLatch(endpoints.size()); IAsyncCallback callback = new IAsyncCallback() { public boolean isLatencyForSnitch() { return false; } public void response(MessageIn msg) { RepairJob.this.snapshotLatch.countDown(); } }; for (InetAddress endpoint : endpoints) MessagingService.instance().sendRR(new SnapshotCommand(tablename, cfname, sessionName, false).createMessage(), endpoint, callback); snapshotLatch.await(); snapshotLatch = null; } catch (InterruptedException e) { throw new RuntimeException(e); } }</description>
      <version>1.2.13,2.0.4</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.SnapshotVerbHandler.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-12-12 01:00:00" id="6481" opendate="2013-12-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Batchlog endpoint candidates should be picked randomly, not sorted by proximity</summary>
      <description>Batchlog endpoint candidates should be picked randomly, not sorted by proximity. I'll be lazy and just copy-paste some lines from IRC:&amp;#91;20:23:27&amp;#93; rbranson: is there an issue where batch logs tend to get written to a subset of the nodes?&amp;#91;20:28:04&amp;#93; rbranson: I mean all the write batches are going thru 10% of the nodes&amp;#91;20:28:16&amp;#93; rbranson: it means writes won't scale linearly w/the cluster sizeAttaching a trivial patch.</description>
      <version>1.2.13,2.0.4</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-12-22 01:00:00" id="6521" opendate="2013-12-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thrift should validate SliceRange start and finish lengths</summary>
      <description>To quote benbromhead:It appears that Cassandra does not check the length of a column name that is part of a range predicate for a *_slice query before it serialises the slice query to pass to the replicas. Names with a length greater than 0xFFFF cause an assertion error to occur in ByteBufferUtil.writeWithShortLength. This further causes subsequent reads on the node to fail until Cassandra is restarted</description>
      <version>1.2.14,2.0.4</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.thrift.ThriftValidation.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
</bugrepository>