<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="CASSANDRA">
  <bug fixdate="2012-9-15 01:00:00" id="3916" opendate="2012-2-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Do not bind the storage_port if internode_encryption = all</summary>
      <description>We are highly security conscious and having additional clear text ports open are undesirable.I have modified locally to get around but it seems that this is a very trivial fix to only bind the clear text storage_port if the internode_encryption is not all. If all is selected then no clear text communication should be permitted.</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-10-16 01:00:00" id="4549" opendate="2012-8-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update the pig examples to include more recent pig/cassandra features</summary>
      <description>Now that there is support for a variety of Cassandra features from Pig (esp 1.1+), it would great to have some of them in the examples so that people can see how to use them.</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">examples.pig.example-script.pig</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2013-10-12 01:00:00" id="5752" opendate="2013-7-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thrift tables are not supported from CqlPagingInputFormat</summary>
      <description>CqlPagingInputFormat inspects the system schema to generate the WHERE clauses needed to page "wide rows," but for a classic Thrift table there are no entries for the "default" column names of key, column1, column2, ..., value so CPIF breaks.</description>
      <version>1.2.11</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.hadoop.cql3.CqlRecordWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.hadoop.cql3.CqlPagingRecordReader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-10-14 01:00:00" id="5889" opendate="2013-8-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>add tombstone metrics to cfstats or cfhistograms</summary>
      <description>/cc pmcfadin</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStoreMBean.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-10-21 01:00:00" id="5916" opendate="2013-8-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>gossip and tokenMetadata get hostId out of sync on failed replace_node with the same IP address</summary>
      <description>If you try to replace_node an existing, live hostId, it will error out. However if you're using an existing IP to do this (as in, you chose the wrong uuid to replace on accident) then the newly generated hostId wipes out the old one in TMD, and when you do try to replace it replace_node will complain it does not exist. Examination of gossipinfo still shows the old hostId, however now you can't replace it either.</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.Gossiper.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.GossipDigestSynVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.GossipDigestAckVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.db.SystemTable.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">NEWS.txt</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2013-9-17 01:00:00" id="6037" opendate="2013-9-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Parens around WHERE condition break query</summary>
      <description>SELECT * FROM user WHERE (key=&lt;UUID&gt;);Bad Request: line 1:25 no viable alternative at input '('SELECT * FROM user WHERE key=&lt;UUID&gt;; &amp;#8211; No parens&amp;#8211; Normal outputThe example provided is minimal, bug was discovered with AND logic on indexed columns.Parens-enclosed conditions is good SQL and so is produced by database abstraction layers in complex queries to avoid operation precedence problems.Fixing this at application side is no option - this will open the can of logic bugs.</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.Cql.g</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-9-22 01:00:00" id="6076" opendate="2013-9-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>implement HELP COMPOSITE_PRIMARY_KEYS</summary>
      <description>HELP COMPOSITE_PRIMARY_KEYS is referenced from HELP CREATE_TABLE, but doesn't exist. added.</description>
      <version>1.2.11</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.helptopics.py</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-10-1 01:00:00" id="6128" opendate="2013-10-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add more data mappings for Pig</summary>
      <description>We need add more data mappings for DecimalType InetAddressType LexicalUUIDType TimeUUIDType UUIDTypeExisting implementation throws exception for those data type</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.hadoop.pig.CqlStorage.java</file>
      <file type="M">src.java.org.apache.cassandra.hadoop.pig.CassandraStorage.java</file>
      <file type="M">src.java.org.apache.cassandra.hadoop.pig.AbstractCassandraStorage.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-10-8 01:00:00" id="6160" opendate="2013-10-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Throw errror when attempting to create a secondary index against counter</summary>
      <description>Using CQL you can create a secondary index against a counter which is then non-functional. cqlsh:test&gt; create table test2 (col1 int, col2 counter, primary key (col1)) ;cqlsh:test&gt; create index dodgy on test2(col2) ;cqlsh:test&gt; update test2 set col2 = col2 + 0 where col1 = 1 ;cqlsh:test&gt; select * from test2 ; col1 | col2------+------ 1 | 0cqlsh:t7088&gt; select * from test2 where col2 = 0 ;We should return an error to let users know they are in unsupported territory.</description>
      <version>1.2.11</version>
      <fixedVersion>Feature/2iIndex,Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateIndexStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-10-8 01:00:00" id="6164" opendate="2013-10-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Switch CFS histograms to biased sampling</summary>
      <description/>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.metrics.ColumnFamilyMetrics.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStoreMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-10-11 01:00:00" id="6183" opendate="2013-10-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Skip mutations that pass CRC but fail to deserialize</summary>
      <description>We've had a couple reports of CL replay failure that appear to be caused by dropping and recreating the same table with a different schema, e.g. CASSANDRA-5905. While CASSANDRA-5202 is the "right" fix for this, it's too involved for 2.0 let alone 1.2, so we need a stopgap until then.</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLogReplayer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-10-13 01:00:00" id="6191" opendate="2013-10-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a warning for small sstable size setting in LCS</summary>
      <description>Not sure "bug" is the right description, because I can't say for sure that the large number of SSTables is the cause of the memory issues. I'll share my research so far:Under high read-load with a very large number of compressed SSTables (caused by the initial default 5mb sstable_size in LCS) it seems memory is exhausted, without any room for GC to fix this. It tries to GC but doesn't reclaim much.The node first hits the "emergency valves" flushing all memtables, then reducing caches. And finally logs 0.99+ heap usages and hangs with GC failure or crashes with OutOfMemoryError.I've taken a heapdump and started analysis to find out what's wrong. The memory seems to be used by the byte[] backing the HeapByteBuffer in the "compressed" field of org.apache.cassandra.io.compress.CompressedRandomAccessReader. The byte[] are generally 65536 byes in size, matching the block-size of the compression.Looking further in the heap-dump I can see that these readers are part of the pool in org.apache.cassandra.io.util.CompressedPoolingSegmentedFile. Which is linked to the "dfile" field of org.apache.cassandra.io.sstable.SSTableReader. The dump-file lists 45248 instances of CompressedRandomAccessReader.Is this intended to go this way? Is there a leak somewhere? Or should there be an alternative strategy and/or warning for cases where a node is trying to read far too many SSTables?EDIT:Searching through the code I found that PoolingSegmentedFile keeps a pool of RandomAccessReader for re-use. While the CompressedRandomAccessReader allocates a ByteBuffer in it's constructor and (to make things worse) enlarges it if it's reasing a large chunk. This (sometimes enlarged) ByteBuffer is then kept alive because it becomes part of the CompressedRandomAccessReader which is in turn kept alive as part of the pool in the PoolingSegmentedFile.</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LeveledCompactionStrategy.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-10-14 01:00:00" id="6197" opendate="2013-10-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create more Pig unit tests for type mappings</summary>
      <description>We need add more Pig unit testing for data type mappings including collections</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.hadoop.pig.CqlStorage.java</file>
    </fixedFiles>
  </bug>
</bugrepository>