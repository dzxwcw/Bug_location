<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="CASSANDRA">
  
  <bug fixdate="2016-11-24 01:00:00" id="12535" opendate="2016-8-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Prevent reloading of logback.xml from UDF sandbox</summary>
      <description>I have defined a UDA to implement standard deviation:cqlsh:mykeyspace&gt; CREATE OR REPLACE FUNCTION sdState ( state tuple&lt;int,double,double&gt;, val double ) CALLED ON NULL INPUT RETURNS tuple&lt;int,double,double&gt; LANGUAGE java AS ... 'int n = state.getInt(0); double mean = state.getDouble(1); double m2 = state.getDouble(2); n++; double delta = val - mean; mean += delta / n; m2 += delta * (val - mean); state.setInt(0, n); state.setDouble(1, mean); state.setDouble(2, m2); return state;'; cqlsh:mykeyspace&gt; CREATE OR REPLACE FUNCTION sdFinal ( state tuple&lt;int,double,double&gt; ) CALLED ON NULL INPUT RETURNS double LANGUAGE java AS ... 'int n = state.getInt(0); double m2 = state.getDouble(2); if (n &lt; 1) { return null; } return Math.sqrt(m2 / (n - 1));';cqlsh:mykeyspace&gt; CREATE AGGREGATE IF NOT EXISTS stdev ( double ) ... SFUNC sdState STYPE tuple&lt;int,double,double&gt; FINALFUNC sdFinal INITCOND (0,0,0);My table:CREATE TABLE readings ( sensor_id int, time timestamp, temperature double, status text, PRIMARY KEY (sensor_id, time)) WITH CLUSTERING ORDER BY (time ASC);I'm inserting a row every 0.1 seconds. The data looks like this:cqlsh:mykeyspace&gt; select * from readings limit 10; sensor_id | time | status | temperature-----------+---------------------------------+--------+------------- 5 | 2016-08-24 19:11:34.896000+0000 | OK | 9.97 5 | 2016-08-24 19:11:43.933000+0000 | OK | 10.28 5 | 2016-08-24 19:11:49.958000+0000 | OK | 7.65 5 | 2016-08-24 19:11:51.968000+0000 | OK | 10.11 5 | 2016-08-24 19:12:58.512000+0000 | Fault | 10.41 5 | 2016-08-24 19:13:04.542000+0000 | OK | 9.66 5 | 2016-08-24 19:13:16.593000+0000 | OK | 10.9 5 | 2016-08-24 19:13:37.692000+0000 | OK | 11.2 5 | 2016-08-24 19:13:46.738000+0000 | OK | 10.34 5 | 2016-08-24 19:13:49.757000+0000 | OK | 10.6I'm running a query every few seconds with my UDA - like this (timestamps are different each time):select avg(temperature), stdev(temperature) from readings where sensor_id = 1 and time &gt; 1472066523193;Most of the time, this works just fine:cqlsh:mykeyspace&gt; select avg(temperature), stdev(temperature) from readings where sensor_id = 1 and time &gt; 1472066523193; system.avg(temperature) | mykeyspace.stdev(temperature)-------------------------+------------------------------- 9.9291 | 0.94179(1 rows)But, occasionally, it fails with one of two exceptions:cqlsh:mykeyspace&gt; select avg(temperature), stdev(temperature) from readings where sensor_id = 1 and time &gt; 1472066523193;Traceback (most recent call last): File "/usr/local/Cellar/cassandra/3.7/libexec/bin/cqlsh.py", line 1277, in perform_simple_statement result = future.result() File "cassandra/cluster.py", line 3629, in cassandra.cluster.ResponseFuture.result (cassandra/cluster.c:69369) raise self._final_exceptionFunctionFailure: Error from server: code=1400 [User Defined Function failure] message="execution of 'mykeyspace.sdstate[frozen&lt;tuple&lt;int, double, double&gt;&gt;, double]' failed: java.security.AccessControlException: access denied ("java.io.FilePermission" "/usr/local/etc/cassandra/logback.xml" "read")"orcqlsh:mykeyspace&gt; select count(*), avg(temperature), stdev(temperature) from readings where sensor_id = 1 and time &gt; '2016-08-24 15:00:00.000+0000';Traceback (most recent call last): File "/usr/local/Cellar/cassandra/3.7/libexec/bin/cqlsh.py", line 1277, in perform_simple_statement result = future.result() File "cassandra/cluster.py", line 3629, in cassandra.cluster.ResponseFuture.result (cassandra/cluster.c:69369) raise self._final_exceptionFunctionFailure: Error from server: code=1400 [User Defined Function failure] message="execution of 'mykeyspace.sdstate[frozen&lt;tuple&lt;int, double, double&gt;&gt;, double]' failed: com.datastax.driver.core.exceptions.CodecNotFoundException"The next query usually works ok.I don't see any clues in /usr/local/var/log/cassandra/system.logIf I can pin it down more, I'll post follow-up comments.</description>
      <version>3.0.11,3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.AggregationTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.functions.ThreadAwareSecurityManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2016-12-30 01:00:00" id="12739" opendate="2016-9-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Nodetool uses cassandra-env.sh MAX_HEAP_SIZE if set</summary>
      <description>Nodetool and other bash startup scripts load cassandra-env.sh variables including MAX_HEAP_SIZE as part of CASSANDRA-10679. If cassandra-env.sh has MAX_HEAP_SIZE set to any value the default heap size needed for the cassandra tool to run is overridden. This is a problem if the using a large heap in C* i.e. 16-32G due to each instance of nodetool or other tool will allocate large heap regardless of need and could exceed the total RAM available on the system.Patch removes the check for MAX_HEAP_SIZE being set and uses the default heap size needed for each tool.</description>
      <version>3.0.11,3.10</version>
      <fixedVersion>Tool/nodetool</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.nodetool</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-1-16 01:00:00" id="12794" opendate="2016-10-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>COPY FROM with NULL=&amp;#39;&amp;#39; fails when inserting empty row in primary key</summary>
      <description>Using this table:CREATE TABLE testtab ( a_id text, b_id text, c_id text, d_id text, order_id uuid, acc_id bigint, bucket bigint, r_id text, ts bigint, PRIMARY KEY ((a_id, b_id, c_id, d_id), order_id));insert one row:INSERT INTO testtab (a_id, b_id , c_id , d_id , order_id, r_id ) VALUES ( '', '', '', 'a1', 645e7d3c-aef7-4e3c-b834-24b792cf2e55, 'r1');Use COPY to dump the row to temp.csv:copy testtab TO 'temp.csv';Which creates this file:$ cat temp.csv ,,,a1,645e7d3c-aef7-4e3c-b834-24b792cf2e55,,,r1,Truncate the testtab table and then use copy from with NULL='' to insert the row:cqlsh:sbkeyspace&gt; COPY testtab FROM 'temp.csv' with NULL='';Using 1 child processesStarting copy of sbkeyspace.testtab with columns ['a_id', 'b_id', 'c_id', 'd_id', 'order_id', 'acc_id', 'bucket', 'r_id', 'ts'].Failed to import 1 rows: ParseError - Cannot insert null value for primary key column 'a_id'. If you want to insert empty strings, consider using the WITH NULL=&lt;marker&gt; option for COPY., given up without retriesFailed to process 1 rows; failed rows written to import_sbkeyspace_testtab.errProcessed: 1 rows; Rate: 2 rows/s; Avg. rate: 3 rows/s1 rows imported from 1 files in 0.398 seconds (0 skipped).It shows 1 rows inserted, but the table is empty:select * from testtab ; a_id | b_id | c_id | d_id | order_id | acc_id | bucket | r_id | ts------+------+------+------+----------+--------+--------+------+----(0 rows)The same error is returned even without the with NULL=''. Is it actually possible for copy from to insert an empty row into the primary key? The insert command shown above inserts the empty row for the primary key without any problems.Is this related to https://issues.apache.org/jira/browse/CASSANDRA-7792?</description>
      <version>3.0.11,3.10</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.copyutil.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2016-2-3 01:00:00" id="12876" opendate="2016-11-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Negative mean write latency</summary>
      <description>The mean write latency returned by JMX turns negative every 30 minutes. As the attached screenshots show, the value turns negative every 30 minutes after the startup of the node.We did not experience this behavior in 2.1.16.</description>
      <version>2.2.9,3.0.11,3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>Legacy/Observability</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.metrics.DecayingEstimatedHistogramReservoirTest.java</file>
      <file type="M">src.java.org.apache.cassandra.metrics.DecayingEstimatedHistogramReservoir.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2016-12-14 01:00:00" id="12909" opendate="2016-11-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh copy cannot parse strings when counters are present</summary>
      <description>We get parse error Failed to import 1 rows: ParseError - argument for 's' must be a string when using the following table and data:CREATE TABLE ks.test ( object_id ascii, user_id timeuuid, counter_id ascii, count counter, PRIMARY KEY ((object_id, user_id), counter_id))EVT:be3bd2d0-a68d-11e6-90d4-1b2a65b8a28a,f7ce3ac0-a66e-11e6-b58e-4e29450fd577,SA,2The problem is this line here, strings are serialized as unicode rather than ordinary strings but only for non-prepared statements (unsure why).</description>
      <version>2.2.9,3.0.11,3.10</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.copyutil.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-12-27 01:00:00" id="12959" opendate="2016-11-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>copy from csv import wrong values with udt having set when fields are not specified in correct order in csv</summary>
      <description>create KEYSPACE test WITH replication = { 'class': 'SimpleStrategy', 'replication_factor': 1};CREATE TYPE test.my_udt ( first_field text, second_field frozen&lt;set&lt;text&gt;&gt;);CREATE TABLE test.test ( key text, value my_udt, PRIMARY KEY (key));The following works as expected : INSERT INTO test.test (key , value ) VALUES ( 'key1', {second_field: {'test1', 'test2'}, first_field: 'first_field'}); key | value-----+--------------------------------------------------------------- key1 | {first_field: 'first_field', second_field: {'test1', 'test2'}}but when inserted using a .csv the result is wrong:"key1","{second_field: {'test1', 'test2'}, first_field: 'first_field'}"COPY test.test FROM '~/test.csv'; key | value-----+--------------------------------------------------------------------- key1 | {first_field: '{''test1'', ''test2''}', second_field: {'irst_fiel'}}it works as expected if the keys are in order: "key1","{first_field: 'first_field', second_field: {'test1', 'test2'}}")</description>
      <version>2.1.17,2.2.9,3.0.11,3.10</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.copyutil.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  
  
  <bug fixdate="2017-2-11 01:00:00" id="13117" opendate="2017-1-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Dump threads when unit test times out</summary>
      <description>It would be nice to get a thread dump when unit tests time out</description>
      <version>3.0.11,3.11.0</version>
      <fixedVersion>Legacy/Testing</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2017-2-31 01:00:00" id="13173" opendate="2017-1-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reloading logback.xml does not work</summary>
      <description>Regression of CASSANDRA-12535Reloading of logback.xml is broken by CASSANDRA-12535 because the delegate ReconfigureOnChangeFilter is not properly initialized.(Broken in 3.0.11 + 3.10)</description>
      <version>3.0.11,3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.functions.ThreadAwareSecurityManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2017-2-2 01:00:00" id="13177" opendate="2017-2-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>sstabledump doesn&amp;#39;t handle non-empty partitions with a partition-level deletion correctly</summary>
      <description>If a partition has a partition-level deletion, but still contains rows (with timestamps higher than the deletion), sstabledump will only show the deletion and not the rows.</description>
      <version>3.0.11,3.11.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.JsonTransformer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2017-2-9 01:00:00" id="13205" opendate="2017-2-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hint related logging should include the IP address of the destination in addition to host ID</summary>
      <description>After the hint rewrite in 3.0, many of the hint related logs now use hostId UUIDs rather than endpoint addresses. This complicates debugging unnecessarily. We should include both.</description>
      <version>3.0.11,3.11.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.hints.HintVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.hints.HintsReader.java</file>
      <file type="M">src.java.org.apache.cassandra.hints.HintsDispatchExecutor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-2-23 01:00:00" id="9639" opendate="2015-6-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>size_estimates is inacurate in multi-dc clusters</summary>
      <description>CASSANDRA-7688 introduced size_estimates to replace the thrift describe_splits_ex command.Users have reported seeing estimates that are widely off in multi-dc clusters.system.size_estimates show the wrong range_start / range_end</description>
      <version>3.0.11</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.SizeEstimatesRecorder.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>