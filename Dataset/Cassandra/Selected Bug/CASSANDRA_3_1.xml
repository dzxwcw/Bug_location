<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="CASSANDRA">
  
  <bug fixdate="2015-11-9 01:00:00" id="10027" opendate="2015-8-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>ALTER TABLE TYPE check broken</summary>
      <description>I stumbled onto the fact that 2.2.0 will allow you to ALTER TYPE of a varint to the new date type. I thought that was an odd conversion to allow, so I attempted to query it. I received an error on all subsequent queries, unless I exited or truncated the table.After truncating, I could then INSERT and query as normal. But the new varint values inserted simply were reflected as an offset of the minimum varint value.I'm not sure why that's happening, but if we could simply prevent type conversion between varint and date (and just show the "types are incompatible" message) that should fix this.Steps to reproduce:aploetz@cqlsh:typeconversion&gt; CREATE TABLE varinttest (key int PRIMARY KEY, c1 varint);aploetz@cqlsh:typeconversion&gt; INSERT INTO varinttest (key, c1) VALUES (1,1);aploetz@cqlsh:typeconversion&gt; SELECT * FROM varinttest ; key | c1-----+---- 1 | 1(1 rows)aploetz@cqlsh:typeconversion&gt; ALTER TABLE varinttest ALTER c1 TYPE date;aploetz@cqlsh:typeconversion&gt; SELECT * FROM varinttest ;Traceback (most recent call last): File "/usr/bin/cqlsh.py", line 1150, in perform_simple_statement rows = future.result(self.session.default_timeout) File "/usr/share/cassandra/lib/cassandra-driver-internal-only-2.6.0c2.post.zip/cassandra-driver-2.6.0c2.post/cassandra/cluster.py", line 3296, in result raise self._final_exceptionerror: unpack requires a string argument of length 4aploetz@cqlsh:typeconversion&gt; SELECT * FROM varinttest ;NoHostAvailable: ('Unable to complete the operation against any hosts', {&lt;Host: 127.0.0.1 PloetzLabs&gt;: ConnectionShutdown('Connection to 127.0.0.1 is defunct',)})aploetz@cqlsh:typeconversion&gt; TRUNCATE varinttest ;aploetz@cqlsh:typeconversion&gt; SELECT * FROM varinttest ; key | c1-----+----(0 rows)aploetz@cqlsh:typeconversion&gt; INSERT INTO varinttest (key, c1) VALUES (1,1);aploetz@cqlsh:typeconversion&gt; INSERT INTO varinttest (key, c1) VALUES (2,2);aploetz@cqlsh:typeconversion&gt; INSERT INTO varinttest (key, c1) VALUES (3,3);aploetz@cqlsh:typeconversion&gt; SELECT * FROM varinttest ; key | c1-----+------------- 1 | -2147483647 2 | -2147483646 3 | -2147483645(3 rows)</description>
      <version>2.2.4,3.0.1,3.1</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.AlterTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.SimpleDateType.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-12-12 01:00:00" id="10059" opendate="2015-8-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Test Coverage and related bug-fixes for AbstractBTreePartition and hierarchy</summary>
      <description>Follow up to CASSANDRA-9932. The test coverage for AbstractBTreePartition and its hierarchy is entirely indirect. That is not to say it is not covered, but we may have some unexplored behaviour. Coverage for BTree is also missing around a couple of edges, and the gaps should be filled in.</description>
      <version>3.0.1,3.1</version>
      <fixedVersion>Legacy/LocalWrite-ReadPaths</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.Util.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.SearchIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RangeTombstoneList.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-11-25 01:00:00" id="10188" opendate="2015-8-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>sstableloader does not use MAX_HEAP_SIZE env parameter</summary>
      <description>Currently the sstableloader script hard codes java's max heap size parameter to 256MB. The issue was discussed in CASSANDRA-7385 and it looks like the agreed solution was to allow the value to change through parameters that were going to be introduced as part of CASSANDRA-5969. This parameter wasn't added to sstableloader, making it inconsistent with the other utilities and provides a problem loading large files.</description>
      <version>2.1.12,2.2.4,3.0.1,3.1,3.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.sstableloader</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-12-1 01:00:00" id="10243" opendate="2015-9-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Warn or fail when changing cluster topology live</summary>
      <description>Moving a node from one rack to another in the snitch, while it is alive, is almost always the wrong thing to do.</description>
      <version>2.1.12,2.2.4,3.0.1,3.1,3.2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.locator.YamlFileNetworkTopologySnitchTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.locator.GossipingPropertyFileSnitchTest.java</file>
      <file type="M">src.java.org.apache.cassandra.locator.SnitchProperties.java</file>
      <file type="M">src.java.org.apache.cassandra.locator.GossipingPropertyFileSnitch.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.service.MigrationManager.java</file>
      <file type="M">src.java.org.apache.cassandra.locator.YamlFileNetworkTopologySnitch.java</file>
      <file type="M">src.java.org.apache.cassandra.locator.PropertyFileSnitch.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.Gossiper.java</file>
      <file type="M">conf.cassandra.yaml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-11-7 01:00:00" id="10280" opendate="2015-9-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make DTCS work well with old data</summary>
      <description>Operational tasks become incredibly expensive if you keep around a long timespan of data with DTCS - with default settings and 1 year of data, the oldest window covers about 180 days. Bootstrapping a node with vnodes with this data layout will force cassandra to compact very many sstables in this window.We should probably put a cap on how big the biggest windows can get. We could probably default this to something sane based on max_sstable_age (ie, say we can reasonably handle 1000 sstables per node, then we can calculate how big the windows should be to allow that)</description>
      <version>2.1.12,2.2.4,3.0.1,3.1</version>
      <fixedVersion>Local/Compaction</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.compaction.DateTieredCompactionStrategyTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.DateTieredCompactionStrategyOptions.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.DateTieredCompactionStrategy.java</file>
      <file type="M">pylib.cqlshlib.cql3handling.py</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">NEWS.txt</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  <bug fixdate="2015-11-6 01:00:00" id="10669" opendate="2015-11-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scrub dtests are failing</summary>
      <description>A bunch of scrub dtest have been failing for a while. Looking at the history of one of those test, it used to pass reliably but stopped working a while ago, and the changes when that happened doesn't seem related from a quick glance. So maybe that's due to a change in the dtest framework (maybe a ccm change even).</description>
      <version>3.0.1,3.1</version>
      <fixedVersion>Legacy/LocalWrite-ReadPaths</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.utils.CLibraryTest.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.CLibrary.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableRewriter.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-11-7 01:00:00" id="10672" opendate="2015-11-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>jacoco instrumentation breaks UDF validation</summary>
      <description>The jacoco agent injects a synthetic method into UDF classes as part of instrumentation for code coverage. Currently the UDF code checks the method count on java UDF classes, and it fails due to the jacoco synthetic method increasing the method count.This causes a number of false test failures when running unit tests with jacoco instrumentation.A simple fix is just to ignore synthetic methods in the counting process.</description>
      <version>2.2.4,3.0.1,3.1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.functions.JavaSourceUDFFactory.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-11-10 01:00:00" id="10682" opendate="2015-11-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix timeouts in BeforeFirstTest</summary>
      <description>Some unit tests fail with a timeout in BeforeFirstTest, see for example here. In the corresponding log file, attached, there is a NoSuchFileException which might be the cause.</description>
      <version>3.0.1,3.1</version>
      <fixedVersion>Legacy/Testing</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.SchemaLoader.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.CQLTester.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-12-19 01:00:00" id="10739" opendate="2015-11-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Timeout for CQL Deletes on an Entire Partition Against Specified Columns</summary>
      <description>cqlsh:graphs&gt; delete color from composite_pk where k1 = '1' and k2 = '1';cqlsh:graphs&gt; create table composite_with_clustering(k1 text, k2 text, c1 text, color text, value float, primary key ((k1, k2), c1));cqlsh:graphs&gt; insert into composite_with_clustering(k1, k2, c1, value) values ('1','1', '1', 6);cqlsh:graphs&gt; insert into composite_with_clustering(k1, k2, c1, color) values ('1','1', '2', 'green');cqlsh:graphs&gt; delete color from composite_with_clustering where k1 = '1' and k2 = '1';WriteTimeout: code=1100 [Coordinator node timed out waiting for replica nodes' responses] message="Operation timed out - received only 0 responses." info={'received_responses': 0, 'required_responses': 1, 'consistency': 'ONE'}Clustering$Serializer clearly doesn't like this:WARN [SharedPool-Worker-2] 2015-11-19 20:55:15,935 AbstractTracingAwareExecutorService.java:169 - Uncaught exception on thread Thread[SharedPool-Worker-2,5,main]: {}java.lang.AssertionError: Invalid clustering for the table: org.apache.cassandra.db.Clustering$2@3157dded at org.apache.cassandra.db.Clustering$Serializer.serialize(Clustering.java:136) ~[cassandra-all-3.0.0.710.jar:3.0.0.710] at org.apache.cassandra.db.rows.UnfilteredSerializer.serialize(UnfilteredSerializer.java:159) ~[cassandra-all-3.0.0.710.jar:3.0.0.710] at org.apache.cassandra.db.rows.UnfilteredSerializer.serialize(UnfilteredSerializer.java:108) ~[cassandra-all-3.0.0.710.jar:3.0.0.710] at org.apache.cassandra.db.rows.UnfilteredSerializer.serialize(UnfilteredSerializer.java:96) ~[cassandra-all-3.0.0.710.jar:3.0.0.710] at org.apache.cassandra.db.rows.UnfilteredRowIteratorSerializer.serialize(UnfilteredRowIteratorSerializer.java:132) ~[cassandra-all-3.0.0.710.jar:3.0.0.710] at org.apache.cassandra.db.rows.UnfilteredRowIteratorSerializer.serialize(UnfilteredRowIteratorSerializer.java:87) ~[cassandra-all-3.0.0.710.jar:3.0.0.710] at org.apache.cassandra.db.partitions.PartitionUpdate$PartitionUpdateSerializer.serialize(PartitionUpdate.java:599) ~[cassandra-all-3.0.0.710.jar:3.0.0.710] at org.apache.cassandra.db.Mutation$MutationSerializer.serialize(Mutation.java:291) ~[cassandra-all-3.0.0.710.jar:3.0.0.710] at org.apache.cassandra.db.commitlog.CommitLog.add(CommitLog.java:279) ~[cassandra-all-3.0.0.710.jar:3.0.0.710]If this isn't supported, there should probably be a more obvious error message.</description>
      <version>3.0.1,3.1</version>
      <fixedVersion>Legacy/CQL,Legacy/LocalWrite-ReadPaths</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.DeleteTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.DeleteStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-11-20 01:00:00" id="10741" opendate="2015-11-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unable to create a function with argument of type Inet</summary>
      <description>We are unable to create a function with an argument of type inet using 3.0.This works in 2.2, but fails in 3.0CREATE OR REPLACE FUNCTION test.f2 (p1 inet)CALLED ON NULL INPUT RETURNS int LANGUAGE java AS 'return 2;';From cqlsh:05:14 PM:~/projects/cassandra-3.0$ ./bin/cqlshConnected to Test Cluster at 127.0.0.1:9042.[cqlsh 5.0.1 | Cassandra 3.0.0-SNAPSHOT | CQL spec 3.3.1 | Native protocol v4]Use HELP for help.cqlsh&gt; CREATE OR REPLACE FUNCTION test.f2 (p1 inet) ... CALLED ON NULL INPUT RETURNS int LANGUAGE java AS 'return 2;';InvalidRequest: code=2200 [Invalid query] message="Could not compile function 'test.f2' from Java source: org.apache.cassandra.exceptions.InvalidRequestException: Java source compilation failed:GENERATED SOURCE ERROR: line 20 (in generated source): java.net.InetAddress cannot be resolved to a typeGENERATED SOURCE ERROR: line 25 (in generated source): java.net.InetAddress cannot be resolved to a type generated source:package org.apache.cassandra.cql3.udf.gen.ptest2ef2_4746343_7;import java.nio.ByteBuffer;import java.util.List;import org.apache.cassandra.cql3.functions.JavaUDF;import com.datastax.driver.core.DataType;public final class Ctest2ef2_12216880_8 extends JavaUDF{ public Ctest2ef2_12216880_8(DataType returnDataType, DataType[] argDataTypes) { super(returnDataType, argDataTypes); } protected ByteBuffer executeImpl(int protocolVersion, List&lt;ByteBuffer&gt; params) { Integer result = xtest2ef2_16165915_9( (java.net.InetAddress) super.compose(protocolVersion, 0, params.get(0)) ); return super.decompose(protocolVersion, result); } private Integer xtest2ef2_16165915_9(java.net.InetAddress p1) {return 2; }}"</description>
      <version>3.0.1,3.1</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.UFTest.java</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2015-11-26 01:00:00" id="10775" opendate="2015-11-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>SSTable compression ratio is not serialized properly</summary>
      <description>While reviewing CASSANDRA-10225, I found out that the compression ratio returned by the StatsMetadata for some compressed sstables was - 1 (NO_COMPRESSION_RATIO). After investigation it seems that the wrong compression ratio was serialized to disk.</description>
      <version>2.2.4,3.0.1,3.1</version>
      <fixedVersion>Legacy/LocalWrite-ReadPaths</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.sstable.format.big.BigTableWriter.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2015-11-9 01:00:00" id="8935" opendate="2015-3-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh: Make the column order in COPY FROM more apparent</summary>
      <description>When running COPY FROM, we should print the order of columns that we're expecting to make it more obvious when the data is not properly aligned. Otherwise, the user will simply see a type or syntax error and have to try to decipher it.</description>
      <version>2.1.12,2.2.4,3.0.1,3.1</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-11-26 01:00:00" id="9043" opendate="2015-3-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve COPY command to work with Counter columns</summary>
      <description>Noticed today that the copy command doesn't work with counter column tables.This makes sense given that we need to use UPDATE instead of INSERT with counters.Given that we're making improvements in the COPY command in 3.0 with CASSANDRA-7405, can we also tweak it to work with counters?</description>
      <version>2.1.12,2.2.4,3.0.1,3.1</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-11-5 01:00:00" id="9304" opendate="2015-5-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>COPY TO improvements</summary>
      <description>COPY FROM has gotten a lot of love. COPY TO not so much. One obvious improvement could be to parallelize reading and writing (write one page of data while fetching the next).</description>
      <version>2.1.12,2.2.4,3.0.1,3.1</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.formatting.py</file>
      <file type="M">pylib.cqlshlib.displaying.py</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2015-11-18 01:00:00" id="9844" opendate="2015-7-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reevaluate inspections in generate-idea-files target</summary>
      <description>Current default inspections generated by the generate-idea-files ant target are generally fine.However there's room to improvement especially wrt Java8 lambda warnings that have (negative) performance impacts.So, this ticket is about to revisit all inspections wrt performance</description>
      <version>2.2.4,3.0.1,3.1,3.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ide.idea.inspectionProfiles.Project.Default.xml</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  
</bugrepository>