<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="CASSANDRA">
  
  
  
  
  <bug fixdate="2020-3-4 01:00:00" id="15622" opendate="2020-3-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unit tests throw UnknownHostException trying to use `InetAddress.getLocalHost()` instead of `FBUtilities.getLocalAddress()`</summary>
      <description>Many of the unit tests in Jenkins fail because of the use of `InetAddress.getLocalHost()` in the test classes.The Jenkins agents need a public ipaddress (and a hostname associated to it) so the Jenkins master can connect to them (agents can be hosted externally, by donating third-parties).The call to `InetAddress.getLocalHost()` can resolve to a hostname that can't be looked up.Not only can it not be listed in `/etc/hosts`, but we don't want it to be either (in case of accidental external port opening if the hostname points to the public ipaddress). (Which is also ASF policy on this infrastructure.)The unit test code needs to replace these code occurrences with the call to `FBUtilities.getLocalAddress()`</description>
      <version>2.2.17,3.0.21,3.11.7,4.0-alpha4,4.0</version>
      <fixedVersion>Test/unit</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.triggers.TriggersTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.security.SSLFactoryTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.gms.ArrivalWindowTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.ThriftCQLTester.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.GuidGenerator.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2020-4-6 01:00:00" id="15623" opendate="2020-3-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>When running CQLSH with STDIN input, exit with error status code if script fails</summary>
      <description>Assuming CASSANDRA-6344 is in place for years and considering that scripts submitted with the `-e` option behave in a similar fashion, it is very surprising that scripts submitted to STDIN (i.e. piped in) always exit with a zero code, regardless of errors. I believe this should be fixed.</description>
      <version>3.0.21,3.11.7,4.0-beta1,4.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh.py</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2020-3-21 01:00:00" id="15651" opendate="2020-3-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Jenkins tests to use testclasslist where possible (like CircleCI)</summary>
      <description>Following up on CASSANDRA-15639 make all the jenkins test jobs run in the same manner.This standards the approach across test jobs and to CircleCI, and will make it easier to parallelise test runs later on.</description>
      <version>2.2.17,3.0.21,3.11.7,4.0-alpha4,4.0</version>
      <fixedVersion>Build,CI,Test/unit</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2020-3-27 01:00:00" id="15668" opendate="2020-3-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Jenkins &amp;#39;Cassandra&amp;#39; label applied to the declarative pipeline</summary>
      <description>On the new ci-cassandra.apache.org infrastructure agents are siloed to projects.The declarative pipeline in the 2.2, 3.0, 3.11, and trunk branches do not restrict the builds to agents with the 'cassandra' label. Because these agents will not run jobs that don't specify this label, the pipeline task only ever runs on unlabelled agents, of which there are very few (and likely shouldn't exist, existing only from for now because of misconfigurations).Example of the failure to run the pipeline tasks is[Pipeline] Start of Pipeline[Pipeline] nodeStill waiting to schedule task'cassandra10' is reserved for jobs with matching label expression; 'cassandra11' is reserved for jobs with matching label expression; 'cassandra12' is reserved for jobs with matching label expression; 'cassandra13' is reserved for jobs with matching label expression; 'cassandra14' is reserved for jobs with matching label expression; 'cassandra15' is reserved for jobs with matching label expression; 'cassandra16' is reserved for jobs with matching label expression; 'cassandra1' is reserved for jobs with matching label expression; 'cassandra2' is reserved for jobs with matching label expression; 'cassandra3' is reserved for jobs with matching label expression; 'cassandra4' is reserved for jobs with matching label expression; 'cassandra5' is reserved for jobs with matching label expression; 'cassandra6' is reserved for jobs with matching label expression; 'cassandra7' is reserved for jobs with matching label expression; 'cassandra8' is reserved for jobs with matching label expression; 'cassandra9' is reserved for jobs with matching label expressionAlong with this change, we can improve the name of the *-test-jvm-dtest-forking stages.</description>
      <version>2.2.17,3.0.21,3.11.7,4.0-alpha4,4.0</version>
      <fixedVersion>Build,CI,Test/unit</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">.jenkins.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2020-4-3 01:00:00" id="15690" opendate="2020-4-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Single partition queries can mistakenly omit partition deletions and resurrect data</summary>
      <description>We have logic that allows us to exclude sstables with partition deletions that are older than the minimum collected timestamp in a local request. However, it’s possible that another node could have rows that aren’t known to the local node that are in turn older than the excluded partition deletion. In such a scenario, those will be mistakenly resurrected, which is a correctness issue.</description>
      <version>3.0.21,3.11.7,4.0-beta1,4.0</version>
      <fixedVersion>Consistency/Coordination</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.distributed.org.apache.cassandra.distributed.test.SimpleReadWriteTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.SinglePartitionReadCommand.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2020-5-28 01:00:00" id="15768" opendate="2020-4-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Tarball contains duplicate entries</summary>
      <description>The tarball contains a lot of duplicate entries. One example is cassandra-stress.bat:tar -tvf /home/map/Downloads/apache-cassandra-3.11.6-bin.tar.gz |grep "cassandra-stress.bat"-rw-r--r-- 0/0 1097 2020-02-10 23:57 apache-cassandra-3.11.6/tools/bin/cassandra-stress.bat-rwxr-xr-x 0/0 1097 2020-02-10 23:57 apache-cassandra-3.11.6/tools/bin/cassandra-stress.bat</description>
      <version>2.2.17,3.0.21,3.11.7,4.0-beta1,4.0</version>
      <fixedVersion>Build,Packaging</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2020-6-8 01:00:00" id="15863" opendate="2020-6-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bootstrap resume and TestReplaceAddress fixes</summary>
      <description>This has been broken for ages</description>
      <version>3.0.21,3.11.7,4.0-beta1,4.0</version>
      <fixedVersion>Consistency/BootstrapandDecommission,Test/dtest/python</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.CassandraDaemon.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2020-6-22 01:00:00" id="15890" opendate="2020-6-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add token to tombstone warning and error log message</summary>
      <description>If Cassandra scans too many tombstones while reading a partition, then it prints log messages with query based on warning/failure thresholds. The token is not printed in the log message. If tombstones are hurting the instance/replica set, then running force compaction for the partition ("nodetool compact" using start and end tokens i.e. token -/+ some delta) is one of the actions taken to recover. In order to find out the token, someone has to manually connect to cluster and run SELECT TOKEN query. Printing token with the log message helps to avoid manual effort and execute force compaction quickly.</description>
      <version>3.0.21,3.11.7,4.0-beta1,4.0</version>
      <fixedVersion>Observability/Logging</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.ReadCommand.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.TombstoneOverwhelmingException.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
</bugrepository>