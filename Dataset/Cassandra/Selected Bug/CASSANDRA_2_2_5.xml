<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="CASSANDRA">
  
  
  <bug fixdate="2015-1-20 01:00:00" id="10140" opendate="2015-8-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable GC logging by default</summary>
      <description>Overhead for the gc logging is very small (with cycling logs in 7+) and it provides a ton of useful information. This will open up more for C* diagnostic tools to provide feedback as well without requiring restarts.</description>
      <version>2.2.5,3.0.3,3.3</version>
      <fixedVersion>Local/Config</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">NEWS.txt</file>
      <file type="M">debian.patches.002cassandra.logdir.fix.dpatch</file>
      <file type="M">conf.jvm.options</file>
      <file type="M">conf.cassandra-env.sh</file>
      <file type="M">conf.cassandra-env.ps1</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-12-13 01:00:00" id="10701" opendate="2015-11-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>stop referring to batches as atomic</summary>
      <description>We still refer to logged batches as atomic, we should remove those references.</description>
      <version>2.1.13,2.2.5,3.0.3,3.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">doc.cql3.CQL.textile</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-1-4 01:00:00" id="10817" opendate="2015-12-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>DROP USER is not case-sensitive</summary>
      <description>As per the summary DROP USER is not case sensitive, so:CREATE USER 'Test';LIST USERS; name | super-----------+------- Test | False cassandra | TrueDROP USER 'Test';InvalidRequest: code=2200 [Invalid query] message="test doesn't exist"DROP ROLE is case-sensitive and will drop the above user.</description>
      <version>2.2.5,3.0.3,3.3</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.cassandra.cql3.Cql.g</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-12-13 01:00:00" id="10854" opendate="2015-12-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh COPY FROM csv having line with more than one consecutive &amp;#39;,&amp;#39; delimiter is throwing &amp;#39;list index out of range&amp;#39;</summary>
      <description>cqlsh COPY FROM csv having line with more than one consecutive ',' delimiter is throwing 'list index out of range'Steps to re-produce:CREATE TABLE tracks_by_album ( album_title TEXT, album_year INT, performer TEXT STATIC, album_genre TEXT STATIC, track_number INT, track_title TEXT, PRIMARY KEY ((album_title, album_year), track_number));Create a file: tracks_by_album.csv having following 2 lines :album,year,performer,genre,number,titlea,2015,b c d,e f g,,cqlsh&gt; COPY music.tracks_by_album (album_title, album_year, performer, album_genre, track_number, track_title)FROM '~/tracks_by_album.csv'WITH HEADER = 'true';Error :Starting copy of music.tracks_by_album with columns ['album_title', 'album_year', 'performer', 'album_genre', 'track_number', 'track_title'].list index out of rangeAborting import at record #1. Previously inserted records are still present, and some records after that may be present as well.</description>
      <version>2.1.13,2.2.5,3.0.3,3.2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.copyutil.py</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-1-17 01:00:00" id="10902" opendate="2015-12-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Skip saved cache directory when checking SSTables at startup</summary>
      <description>The SSTable StartupCheck looks for all files which end with "*.db" and compares the version. This causes problems if saved_cache_directory is a subdirectory of a data_file_directories. We should make sure that we are not checking any subdirectory where we might be writing *.db files.This is the cause of not being able to restart in CASSANDRA-10821.</description>
      <version>2.2.5,3.0.3,3.3</version>
      <fixedVersion>Local/Config</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StartupChecks.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-2-24 01:00:00" id="10938" opendate="2015-12-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>test_bulk_round_trip_blogposts is failing occasionally</summary>
      <description>We get timeouts occasionally that cause the number of records to be incorrect:http://cassci.datastax.com/job/trunk_dtest/858/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_bulk_round_trip_blogposts/</description>
      <version>2.1.13,2.2.5,3.0.3,3.3</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.transport.ServerConnection.java</file>
      <file type="M">pylib.cqlshlib.copyutil.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2016-1-7 01:00:00" id="10980" opendate="2016-1-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>nodetool scrub NPEs when keyspace isn&amp;#39;t specified</summary>
      <description>I've attached logs of what I saw. Running nodetool scrub without anything else specified resulted in the NPE. Running with the keyspace specified saw successful termination.</description>
      <version>2.2.5,3.0.3,3.3</version>
      <fixedVersion>Local/Compaction,Tool/nodetool</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2014-1-13 01:00:00" id="7925" opendate="2014-9-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>TimeUUID LSB should be unique per process, not just per machine</summary>
      <description>as pointed out in CASSANDRA-7919 lsb collisions are also possible serverside.a sufficient solution would be to include references to pid and classloader within lsb.</description>
      <version>2.2.5,3.0.3,3.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.utils.UUIDGen.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.SigarLibrary.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StartupChecks.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-12-13 01:00:00" id="9179" opendate="2015-4-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unable to "point in time" restore if table/cf has been recreated</summary>
      <description>With Cassandra 2.1, and the addition of the CF UUID, the ability to do a "point in time" restore by restoring a snapshot and replaying commitlogs is lost if the table has been dropped and recreated.When the table is recreated, the cf_id changes, and the commitlog replay mechanism skips the desired mutations as the cf_id no longer matches what's present in the schema.There should exist a way to inform the replay that you want the mutations replayed even if the cf_id doesn't match.</description>
      <version>2.1.13,2.2.5,3.0.3,3.2</version>
      <fixedVersion>Legacy/CQL,Legacy/DistributedMetadata</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateTableStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CFPropDefs.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.AlterTableStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-12-5 01:00:00" id="9302" opendate="2015-5-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Optimize cqlsh COPY FROM, part 3</summary>
      <description>We've had some discussion moving to Spark CSV import for bulk load in 3.x, but people need a good bulk load tool now. One option is to add a separate Java bulk load tool (CASSANDRA-9048), but if we can match that performance from cqlsh I would prefer to leave COPY FROM as the preferred option to which we point people, rather than adding more tools that need to be supported indefinitely.Previous work on COPY FROM optimization was done in CASSANDRA-7405 and CASSANDRA-8225.</description>
      <version>2.1.13,2.2.5,3.0.3,3.2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.util.py</file>
      <file type="M">pylib.cqlshlib.copyutil.py</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  
</bugrepository>