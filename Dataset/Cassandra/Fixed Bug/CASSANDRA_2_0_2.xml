<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="CASSANDRA">
  <bug id="3916" opendate="2012-2-15 00:00:00" fixdate="2012-9-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Do not bind the storage_port if internode_encryption = all</summary>
      <description>We are highly security conscious and having additional clear text ports open are undesirable.I have modified locally to get around but it seems that this is a very trivial fix to only bind the clear text storage_port if the internode_encryption is not all. If all is selected then no clear text communication should be permitted.</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4053" opendate="2012-3-15 00:00:00" fixdate="2012-9-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>IncomingTcpConnection can not be closed when the peer is brutaly terminated or switch is failed</summary>
      <description>IncomingTcpConnection has no way to detect the peer is down when the peer meets power loss or the network infrastructure is failed, and the thread is leaked...For safety, as least SO_KEEPALIVE should be set on those IncomingTcpConnections. The better way is to close the incoming connections when failure detector notifies the peer failure, but it requires some extra bookmarking.Besides it, it would be better if IncomingTcpConnection and OutgoingTcpConnection is marked as daemon thread...</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4191" opendate="2012-4-26 00:00:00" fixdate="2012-10-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add `nodetool cfstats &lt;ks&gt; &lt;cf&gt;` abilities</summary>
      <description>This way cfstats will only print information per keyspace/column family combinations.Another related proposal as an alternative to this ticket:Allow for `nodetool cfstats` to use --excludes or --includes to accept keyspace and column family arguments.</description>
      <version>1.2.12,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.resources.org.apache.cassandra.tools.NodeToolHelp.yaml</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4430" opendate="2012-7-9 00:00:00" fixdate="2012-10-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>optional pluggable o.a.c.metrics reporters</summary>
      <description>CASSANDRA-4009 expanded the use of the metrics library which has a set of reporter modules http://metrics.codahale.com/manual/core/#reporters You can report to flat files, ganglia, spit everything over http, etc. The next step is a mechanism for using those reporters with o.a.c.metrics. To avoid bundling everything I suggest following the mx4j approach of "enable only if on classpath coupled with a reporter configuration file.Strawman file:console: time: 1 timeunit: "seconds"csv: - time: 1 timeunit: minutes file: foo.csv - time: 10 timeunit: seconds file: bar.csvganglia: - time: 30 timunit: seconds host: server-1 port: 8649 - time: 30 timunit: seconds host: server-2 port: 8649</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.CassandraDaemon.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="4549" opendate="2012-8-16 00:00:00" fixdate="2012-10-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update the pig examples to include more recent pig/cassandra features</summary>
      <description>Now that there is support for a variety of Cassandra features from Pig (esp 1.1+), it would great to have some of them in the examples so that people can see how to use them.</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">examples.pig.example-script.pig</file>
    </fixedFiles>
  </bug>
  <bug id="4925" opendate="2012-11-6 00:00:00" fixdate="2012-10-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Failure Detector should log or ignore sudden time change to the past</summary>
      <description>If a machine goes back in time all of a sudden because of a problem, Gossip will insert a negative interArrivalTime. This will decrease the mean value and can cause this machine to mark other nodes as down and then mark them up as time passed. But we should log such occurrences.</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.utils.BoundedStatsDequeTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.gms.ArrivalWindowTest.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.BoundedStatsDeque.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.FailureDetector.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4949" opendate="2012-11-12 00:00:00" fixdate="2012-10-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expose reload trigger functionality to nodetool to orchestrate trigger (re)loads across the cluster</summary>
      <description>Pending completion of CASSANDRA-1311, this would expose the load/reload trigger library functionality to nodetool</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.resources.org.apache.cassandra.tools.NodeToolHelp.yaml</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeProbe.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxyMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5078" opendate="2012-12-19 00:00:00" fixdate="2012-10-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>save compaction merge counts in a system table</summary>
      <description>we should save the compaction merge stats from CASSANDRA-4894 in the system table and probably expose them via JMX (and nodetool)</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.resources.org.apache.cassandra.tools.NodeToolHelp.yaml</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeProbe.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">src.java.org.apache.cassandra.db.SystemKeyspace.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionTask.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManagerMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">src.java.org.apache.cassandra.config.KSMetaData.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5515" opendate="2013-4-25 00:00:00" fixdate="2013-9-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Track sstable coldness</summary>
      <description>Keeping a count of reads per-sstable would allow STCS to automatically ignore cold data rather than recompacting it constantly with hot data, dramatically reducing compaction load for typical time series applications and others with time-correlated access patterns. We would not need a separate age-tiered compaction strategy.(This will really be useful in conjunction with CASSANDRA-5514.)</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableReader.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableDeletingTask.java</file>
      <file type="M">src.java.org.apache.cassandra.db.SystemKeyspace.java</file>
      <file type="M">src.java.org.apache.cassandra.db.DataTracker.java</file>
      <file type="M">src.java.org.apache.cassandra.db.CollationController.java</file>
      <file type="M">src.java.org.apache.cassandra.config.KSMetaData.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5517" opendate="2013-4-26 00:00:00" fixdate="2013-8-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cassandra crashes at start with segmentation fault</summary>
      <description>Sometimes Cassandra fails at start with segmentation fault: /usr/sbin/cassandra -fxss = -ea -javaajent:/usr/share/cassandra/lib/jamm-0.2.5.jar -XX:+UseThreadPriorities -XX:ThreadPriorityPolicy=42 -Xms1024M -Xmx1024M -Xmn100M -XX:+HeapDumpOnOutOfMemoryError -Xss180kSegmentation faultIt seems that not only me encountered this bug: http://snapwebsites.org/known-issues/cassandra-crashes-java-segmentation-faultSolution proposed on this link works.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">conf.cassandra-env.sh</file>
    </fixedFiles>
  </bug>
  <bug id="5571" opendate="2013-5-15 00:00:00" fixdate="2013-10-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reject bootstrapping endpoints that are already in the ring with different gossip data</summary>
      <description>The ring can be silently broken by improperly bootstrapping an endpoint that has an existing entry in the gossip table. In the case where a node attempts to bootstrap with the same IP address as an existing ring member, the old token metadata is dropped without warning, resulting in range shifts for the cluster.This isn't so bad for non-vnode cases where, in general, tokens are explicitly assigned, and a bootstrap on the same token would result in no range shifts. For vnode cases, the convention is to just let nodes come up by selecting their own tokens, and a bootstrap will override the existing tokens for that endpoint.While there are some other issues open for adding an explicit rebootstrap feature for vnode cases, given the changes in operator habits for vnode rings, it seems a bit too easy to make this happen. Even more undesirable is the fact that it's basically silent.This is a proposal for checking for this exact case: bootstraps on endpoints with existing ring entries that have different hostIDs and/or tokens should be rejected with an error message describing what happened and how to override the safety check. It looks like the override can be supported using the existing "nodetool removenode -force".I can work up a patch for this.</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.Gossiper.java</file>
    </fixedFiles>
  </bug>
  <bug id="5695" opendate="2013-6-24 00:00:00" fixdate="2013-10-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Convert pig smoke tests into real PigUnit tests</summary>
      <description>Currently, we have some ghetto pig tests in examples/pig/test, but there's currently no way to continuously integrate these since a human needs to check that the output isn't wrong, not just that the tests ran successfully. We've had garbled output problems in the past, so it would be nice to formalize our tests to catch this. PigUnit appears to be a good choice for this.</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.conf.log4j-junit.properties</file>
      <file type="M">src.java.org.apache.cassandra.hadoop.pig.CqlStorage.java</file>
      <file type="M">src.java.org.apache.cassandra.hadoop.pig.CassandraStorage.java</file>
      <file type="M">src.java.org.apache.cassandra.hadoop.pig.AbstractCassandraStorage.java</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="5730" opendate="2013-7-8 00:00:00" fixdate="2013-9-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Re-add ScrubTest post single-pass compaction</summary>
      <description>Follow up of CASSANDRA-5429 for adding back a ScrubTest.</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.data.corrupt-sstables.Keyspace1-Standard3-ja-1-TOC.txt</file>
      <file type="M">test.data.corrupt-sstables.Keyspace1-Standard3-ja-1-Summary.db</file>
      <file type="M">test.data.corrupt-sstables.Keyspace1-Standard3-ja-1-Statistics.db</file>
      <file type="M">test.data.corrupt-sstables.Keyspace1-Standard3-ja-1-Index.db</file>
      <file type="M">test.data.corrupt-sstables.Keyspace1-Standard3-ja-1-Filter.db</file>
      <file type="M">test.data.corrupt-sstables.Keyspace1-Standard3-ja-1-Digest.sha1</file>
      <file type="M">test.data.corrupt-sstables.Keyspace1-Standard3-ja-1-Data.db</file>
      <file type="M">test.data.corrupt-sstables.Keyspace1-Standard3-ja-1-CRC.db</file>
    </fixedFiles>
  </bug>
  <bug id="5732" opendate="2013-7-8 00:00:00" fixdate="2013-10-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Can not query secondary index</summary>
      <description>Noticed after taking a column family that already existed and assigning to an IntegerType index_type:KEYS and the caching was already set to 'ALL' that the prepared statement do not return rows neither did it throw an exception. Here is the sequence.1. Starting state query running with caching off for a Column Family with the query using the secondary index for te WHERE clause.2, Set Column Family caching to ALL using Cassandra-CLI and update CQL. Cassandra-cli Describe shows column family caching set to ALL3. Rerun query and it works.4. Restart Cassandra and run query and no rows returned. Cassandra-cli Describe shows column family caching set to ALL5. Set Column Family caching to NONE using Cassandra-cli and update CQL. Rerun query and no rows returned. Cassandra-cli Describe for column family shows caching set to NONE.6. Restart Cassandra. Rerun query and it is working again. We are now back to the starting state.Best Regards,-Tony</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>Feature/2iIndex</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.index.AbstractSimplePerColumnSecondaryIndex.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5889" opendate="2013-8-14 00:00:00" fixdate="2013-10-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>add tombstone metrics to cfstats or cfhistograms</summary>
      <description>/cc pmcfadin</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStoreMBean.java</file>
    </fixedFiles>
  </bug>
  <bug id="5916" opendate="2013-8-21 00:00:00" fixdate="2013-10-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>gossip and tokenMetadata get hostId out of sync on failed replace_node with the same IP address</summary>
      <description>If you try to replace_node an existing, live hostId, it will error out. However if you're using an existing IP to do this (as in, you chose the wrong uuid to replace on accident) then the newly generated hostId wipes out the old one in TMD, and when you do try to replace it replace_node will complain it does not exist. Examination of gossipinfo still shows the old hostId, however now you can't replace it either.</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.Gossiper.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.GossipDigestSynVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.GossipDigestAckVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.db.SystemTable.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">NEWS.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5932" opendate="2013-8-24 00:00:00" fixdate="2013-9-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Speculative read performance data show unexpected results</summary>
      <description>I've done a series of stress tests with eager retries enabled that show undesirable behavior. I'm grouping these behaviours into one ticket as they are most likely related.1) Killing off a node in a 4 node cluster actually increases performance.2) Compactions make nodes slow, even after the compaction is done.3) Eager Reads tend to lessen the immediate performance impact of a node going down, but not consistently.My Environment:1 stress machine: node04 C* nodes: node4, node5, node6, node7My script:node0 writes some data: stress -d node4 -F 30000000 -n 30000000 -i 5 -l 2 -K 20node0 reads some data: stress -d node4 -n 30000000 -o read -i 5 -K 20Examples:A node going down increases performance:Data for this test hereAt 450s, I kill -9 one of the nodes. There is a brief decrease in performance as the snitch adapts, but then it recovers... to even higher performance than before.Compactions make nodes permanently slow:The green and orange lines represent trials with eager retry enabled, they never recover their op-rate from before the compaction as the red and blue lines do.Data for this test hereSpeculative Read tends to lessen the immediate impact:This graph looked the most promising to me, the two trials with eager retry, the green and orange line, at 450s showed the smallest dip in performance. Data for this test hereBut not always:This is a retrial with the same settings as above, yet the 95percentile eager retry (red line) did poorly this time at 450s.Data for this test here</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.service.ReadCallback.java</file>
      <file type="M">src.java.org.apache.cassandra.service.AbstractReadExecutor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5950" opendate="2013-8-29 00:00:00" fixdate="2013-9-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make snapshot/sequential repair the default</summary>
      <description></description>
      <version>2.0.2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.resources.org.apache.cassandra.tools.NodeToolHelp.yaml</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5954" opendate="2013-8-30 00:00:00" fixdate="2013-9-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make nodetool ring print an error message and suggest nodetool status when vnodes are enabled</summary>
      <description></description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>Tool/nodetool</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
    </fixedFiles>
  </bug>
  <bug id="6016" opendate="2013-9-12 00:00:00" fixdate="2013-10-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Ability to change replication factor for the trace keyspace</summary>
      <description>They trace keyspace is currently RF=1, and can't be changed. I want to be able to trace stuff when nodes are down/being stupid.</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.ClientState.java</file>
      <file type="M">src.java.org.apache.cassandra.service.CassandraDaemon.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Schema.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">pylib.cqlshlib.cql3handling.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6037" opendate="2013-9-17 00:00:00" fixdate="2013-9-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Parens around WHERE condition break query</summary>
      <description>SELECT * FROM user WHERE (key=&lt;UUID&gt;);Bad Request: line 1:25 no viable alternative at input '('SELECT * FROM user WHERE key=&lt;UUID&gt;; &amp;#8211; No parens&amp;#8211; Normal outputThe example provided is minimal, bug was discovered with AND logic on indexed columns.Parens-enclosed conditions is good SQL and so is produced by database abstraction layers in complex queries to avoid operation precedence problems.Fixing this at application side is no option - this will open the can of logic bugs.</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.Cql.g</file>
    </fixedFiles>
  </bug>
  <bug id="6042" opendate="2013-9-17 00:00:00" fixdate="2013-9-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add WARN when there are a lot of tombstones in a query</summary>
      <description>Now that we count the number of tombstones hit (so it can go in tracing), can we pick some threshold (or make it configurable with 0 being don't warn), and spit out a warning saying "Just went through 10000 tombstones in partition XYZ".Right now if you are having GC problems because some row got a bunch of tombstones, you can turn on server side tracing, and hope the bad query gets in there, or you can keep making heap dumps, dig through them, and hope you catch the query in there.I have seen code problems at multiple places causing this same issue (some code causing way more tombstones than it should, for just one row). And it is a PITA+Luck to debug it right now.</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageServiceMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.metrics.ColumnFamilyMetrics.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.SliceQueryFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStoreMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6059" opendate="2013-9-19 00:00:00" fixdate="2013-9-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve memory-use defaults</summary>
      <description>Anecdotally, it's still too easy to OOM Cassandra even after moving sstable internals off heap.</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6068" opendate="2013-9-19 00:00:00" fixdate="2013-10-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support login/password auth in cassandra-stress</summary>
      <description>Support login/password auth in cassandra-stress</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.Session.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6069" opendate="2013-9-19 00:00:00" fixdate="2013-9-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Sets not stored by INSERT with IF NOT EXISTS</summary>
      <description>An INSERT of a set column type is not stored when using IF NOT EXISTS</description>
      <version>2.0.2</version>
      <fixedVersion>Feature/LightweightTransactions</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.paxos.Commit.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6080" opendate="2013-9-23 00:00:00" fixdate="2013-9-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bad metadata returned for SELECT COUNT</summary>
      <description>The native protocol v2 returns the result metadata with a prepared statement, but for count queries this is currently incorrect, we return the metadata corresponding to a 'SELECT *' instead.</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.ResultSet.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6081" opendate="2013-9-23 00:00:00" fixdate="2013-9-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thrift validation refuses row markers on CQL3 tables</summary>
      <description>CASSANDRA-5138 don't let row markers pass. It should.</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.thrift.ThriftValidation.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6093" opendate="2013-9-25 00:00:00" fixdate="2013-9-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cant migrate json manifest with multiple data directories</summary>
      <description>http://mail-archives.apache.org/mod_mbox/cassandra-user/201309.mbox/%3C002401ceb980%2485a26d10%2490e74730%24%40struq.com%3Emost likely due to having multiple data dirs</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LegacyLeveledManifest.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6114" opendate="2013-9-30 00:00:00" fixdate="2013-10-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Pig with widerows=true and batch size = 1 works incorrectly</summary>
      <description>If I run the demo pig scripts, I end up with a column family with 6 fairly wide rows. If I load and dump those rows with widerows=true or set the cassandra.range.batch.size=1, the dump returns the correct values. However, if I set both of those, it does not. So in the case of a batch size of 1, wide rows support is broken.So it's relatively simple to reproduce from the demo data:grunt&gt; SET cassandra.range.batch.size 1 grunt&gt; rows = LOAD 'cassandra://PigDemo/Scores' using CassandraStorage(); grunt&gt; dump rows;...(sylvain,{(4,),(7,),(10,),(21,),(24,),(46,),(47,),(49,),(51,),(52,),(67,),(68,),(72,),(73,),(82,),(83,),(86,),(98,),(101,),(105,),(108,),(112,),(114,),(124,),(125,),(136,),(139,),(145,),(150,),(151,),(153,),(165,),(167,),(171,),(178,),(182,),(202,),(211,),(212,),(215,),(226,),(237,),(242,),(243,),(255,),(261,),(273,),(282,),(300,),(307,),(308,),(311,),(312,),(313,),(316,),(317,),(332,),(337,),(338,),(348,),(355,),(360,),(361,),(373,),(375,),(377,),(384,),(401,),(404,),(412,),(418,),(429,),(436,),(441,),(451,),(453,),(461,),(473,),(478,),(483,),(485,),(486,),(489,),(509,),(511,),(516,),(517,),(521,),(536,),(541,),(543,),(545,),(550,),(583,),(587,),(592,),(611,),(613,),(622,),(625,),(627,),(633,),(648,),(649,),(651,),(659,),(665,),(668,),(670,),(672,),(679,),(688,),(692,),(700,),(703,),(707,),(709,),(730,),(731,),(738,),(740,),(744,),(750,),(759,),(764,),(766,),(768,),(774,),(776,),(778,),(779,),(788,),(795,),(796,),(813,),(821,),(825,),(830,),(831,),(835,),(843,),(846,),(847,),(848,),(851,),(862,),(863,),(872,),(878,),(881,),(883,),(884,),(888,),(905,),(906,),(916,),(921,),(926,),(928,),(944,),(946,),(947,),(952,),(954,),(972,),(973,),(974,),(976,),(978,),(982,),(991,)})(brandon,{(6,),(7,),(14,),(15,),(25,),(36,),(37,),(38,),(46,),(53,),(57,),(65,),(74,),(75,),(84,),(91,),(104,),(120,),(128,),(137,),(148,),(159,),(171,),(174,),(176,),(179,),(183,),(192,),(195,),(201,),(205,),(210,),(216,),(222,),(223,),(243,),(255,),(264,),(271,),(287,),(290,),(308,),(309,),(326,),(343,),(347,),(356,),(359,),(360,),(363,),(367,),(368,),(378,),(398,),(400,),(402,),(410,),(412,),(419,),(427,),(429,),(447,),(449,),(462,),(464,),(468,),(470,),(472,),(480,),(482,),(506,),(511,),(520,),(521,),(522,),(524,),(535,),(548,),(553,),(565,),(569,),(571,),(573,),(575,),(583,),(584,),(595,),(597,),(606,),(608,),(634,),(646,),(650,),(654,),(667,),(673,),(677,),(686,),(690,),(692,),(713,),(715,),(721,),(723,),(736,),(737,),(752,),(753,),(758,),(759,),(764,),(766,),(767,),(776,),(778,),(786,),(812,),(816,),(818,),(823,),(826,),(832,),(838,),(842,),(860,),(873,),(879,),(918,),(919,),(935,),(941,),(942,),(948,),(956,),(961,),(966,),(973,),(974,),(977,),(979,),(983,),(984,),(986,),(995,),(997,)})(jake,{(1,),(7,),(10,),(14,),(29,),(52,),(54,),(65,),(67,),(78,),(82,),(83,),(89,),(97,),(100,),(115,),(126,),(140,),(141,),(145,),(214,),(221,),(230,),(231,),(232,),(241,),(245,),(247,),(265,),(266,),(269,),(271,),(282,),(286,),(288,),(299,),(316,),(323,),(331,),(332,),(335,),(338,),(348,),(353,),(355,),(364,),(367,),(371,),(379,),(398,),(409,),(420,),(428,),(429,),(439,),(443,),(450,),(454,),(467,),(477,),(482,),(488,),(490,),(502,),(503,),(512,),(520,),(521,),(535,),(536,),(541,),(548,),(552,),(557,),(560,),(596,),(600,),(604,),(606,),(611,),(613,),(621,),(624,),(630,),(635,),(641,),(647,),(655,),(660,),(665,),(674,),(676,),(690,),(693,),(694,),(704,),(719,),(720,),(724,),(731,),(749,),(751,),(763,),(765,),(767,),(771,),(779,),(782,),(784,),(789,),(793,),(797,),(798,),(801,),(802,),(806,),(820,),(825,),(839,),(845,),(848,),(856,),(865,),(866,),(867,),(870,),(876,),(887,),(891,),(901,),(905,),(908,),(922,),(929,),(944,),(960,),(964,),(980,),(988,),(996,)})(eric,{(14,),(17,),(23,),(25,),(26,),(34,),(42,),(43,),(57,),(64,),(68,),(80,),(88,),(93,),(100,),(114,),(131,),(132,),(134,),(143,),(146,),(147,),(156,),(157,),(170,),(171,),(172,),(177,),(186,),(197,),(198,),(206,),(209,),(223,),(224,),(233,),(236,),(241,),(251,),(252,),(255,),(263,),(266,),(267,),(268,),(272,),(277,),(280,),(289,),(293,),(294,),(297,),(301,),(306,),(310,),(312,),(321,),(326,),(333,),(334,),(335,),(345,),(357,),(362,),(363,),(370,),(380,),(389,),(392,),(393,),(401,),(420,),(431,),(462,),(464,),(465,),(471,),(484,),(486,),(490,),(493,),(504,),(505,),(509,),(515,),(521,),(534,),(538,),(547,),(554,),(557,),(561,),(564,),(572,),(573,),(578,),(582,),(584,),(590,),(598,),(599,),(603,),(605,),(609,),(618,),(634,),(636,),(639,),(648,),(656,),(661,),(667,),(671,),(674,),(675,),(687,),(713,),(721,),(733,),(736,),(763,),(767,),(776,),(785,),(787,),(809,),(813,),(826,),(829,),(830,),(832,),(840,),(841,),(844,),(846,),(854,),(855,),(876,),(890,),(892,),(902,),(910,),(930,),(934,),(938,),(940,),(943,),(955,),(959,),(965,),(966,),(968,),(972,),(980,),(985,),(989,)})(jonathan,{(17,),(18,),(31,),(34,),(37,),(40,),(67,),(69,),(75,),(93,),(111,),(124,),(127,),(128,),(137,),(142,),(168,),(178,),(190,),(193,),(194,),(207,),(211,),(216,),(221,),(229,),(237,),(242,),(252,),(253,),(264,),(265,),(267,),(270,),(272,),(274,),(276,),(278,),(280,),(283,),(297,),(299,),(300,),(302,),(303,),(309,),(311,),(318,),(323,),(329,),(330,),(332,),(344,),(346,),(351,),(354,),(358,),(361,),(363,),(366,),(367,),(374,),(378,),(379,),(386,),(389,),(392,),(395,),(398,),(404,),(424,),(426,),(429,),(434,),(439,),(443,),(445,),(448,),(472,),(477,),(494,),(500,),(504,),(522,),(525,),(538,),(539,),(541,),(548,),(553,),(557,),(560,),(563,),(566,),(567,),(578,),(591,),(593,),(595,),(599,),(605,),(610,),(626,),(635,),(636,),(640,),(642,),(644,),(649,),(660,),(662,),(663,),(667,),(674,),(690,),(706,),(708,),(712,),(716,),(723,),(733,),(741,),(747,),(758,),(765,),(797,),(798,),(801,),(822,),(827,),(828,),(837,),(850,),(863,),(867,),(894,),(895,),(896,),(904,),(911,),(917,),(932,),(949,),(951,),(952,),(958,),(969,),(974,),(983,),(985,),(988,),(989,),(996,),(1000,)})(gary,{(3,),(13,),(21,),(23,),(33,),(36,),(44,),(45,),(48,),(62,),(65,),(68,),(75,),(80,),(81,),(90,),(111,),(113,),(119,),(123,),(137,),(149,),(152,),(153,),(157,),(161,),(166,),(178,),(179,),(180,),(183,),(184,),(188,),(189,),(191,),(197,),(199,),(200,),(204,),(212,),(221,),(229,),(239,),(265,),(270,),(272,),(276,),(279,),(282,),(295,),(296,),(304,),(305,),(314,),(326,),(329,),(335,),(342,),(345,),(346,),(362,),(370,),(371,),(375,),(380,),(382,),(387,),(389,),(390,),(393,),(399,),(403,),(406,),(414,),(417,),(424,),(428,),(445,),(458,),(462,),(486,),(490,),(492,),(495,),(499,),(500,),(507,),(514,),(520,),(542,),(550,),(551,),(570,),(571,),(572,),(574,),(577,),(588,),(604,),(614,),(619,),(626,),(634,),(640,),(648,),(659,),(663,),(684,),(687,),(690,),(694,),(715,),(741,),(750,),(765,),(772,),(776,),(781,),(782,),(783,),(785,),(789,),(802,),(806,),(812,),(816,),(820,),(829,),(836,),(843,),(850,),(855,),(868,),(873,),(875,),(889,),(900,),(904,),(922,),(928,),(929,),(935,),(946,),(949,),(954,),(956,),(959,),(960,),(962,),(992,)})grunt&gt; SET cassandra.range.batch.size 1 grunt&gt; rows = LOAD 'cassandra://PigDemo/Scores?widerows=true' using CassandraStorage();grunt&gt; dump rows;...(jonathan,{(17,)})(sylvain,{(4,)})When I try with set batch size to something higher than 1 and it works fine.</description>
      <version>1.2.12,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.hadoop.ColumnFamilyRecordReader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6117" opendate="2013-10-1 00:00:00" fixdate="2013-10-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Avoid death-by-tombstone by default</summary>
      <description>We added warnings to 1.2 (CASSANDRA-6042); for 2.0 we should go farther and drop requests (with an error logged) that exceed the threshold. Users who want to tread dangerously are free to crank the threshold up, but "I queried a lot of tombstones and Cassandra fell over" is possibly the number one way of killing Cassandra nodes right now.</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageServiceMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.RangeSliceVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ReadVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.SliceQueryFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.db.columniterator.IdentityQueryFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6122" opendate="2013-10-1 00:00:00" fixdate="2013-10-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Optimize the auth default super user/default user check</summary>
      <description>Optimize the auth default super user/default user check by checking for the 'cassandra' user first, and only if that fails, doing the range query.For people following our docs (don't drop 'cassandra', just strip its superuser status and change the password), this will always mean performing just one get.</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.auth.PasswordAuthenticator.java</file>
      <file type="M">src.java.org.apache.cassandra.auth.Auth.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6128" opendate="2013-10-1 00:00:00" fixdate="2013-10-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add more data mappings for Pig</summary>
      <description>We need add more data mappings for DecimalType InetAddressType LexicalUUIDType TimeUUIDType UUIDTypeExisting implementation throws exception for those data type</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.hadoop.pig.CqlStorage.java</file>
      <file type="M">src.java.org.apache.cassandra.hadoop.pig.CassandraStorage.java</file>
      <file type="M">src.java.org.apache.cassandra.hadoop.pig.AbstractCassandraStorage.java</file>
    </fixedFiles>
  </bug>
  <bug id="6132" opendate="2013-10-2 00:00:00" fixdate="2013-10-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CL.ANY writes can still time out</summary>
      <description>If we know that all replicas are down at the beginning of a mutation, we will write a hint and return success.But if we do not, we will attemp to write to replicas, time out, return failure, and then write a hint, violating our contract that (unless the coordinator goes down), writes at CL.ANY should always succeed.</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.net.WriteCallbackInfo.java</file>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
      <file type="M">src.java.org.apache.cassandra.net.CallbackInfo.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.BootStrapper.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6136" opendate="2013-10-2 00:00:00" fixdate="2013-10-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CQL should not allow an empty string as column identifier</summary>
      <description>CQL currently allows users to create a table with an empty string as column identifier:CREATE TABLE t (k int primary key, "" int);Which results in the following table:CREATE TABLE t ( k int, "" int, PRIMARY KEY (k)) WITH bloom_filter_fp_chance=0.010000 AND caching='KEYS_ONLY' AND comment='' AND dclocal_read_repair_chance=0.000000 AND gc_grace_seconds=864000 AND index_interval=128 AND read_repair_chance=0.100000 AND replicate_on_write='true' AND populate_io_cache_on_flush='false' AND default_time_to_live=0 AND speculative_retry='NONE' AND memtable_flush_period_in_ms=0 AND compaction={'class': 'SizeTieredCompactionStrategy'} AND compression={'sstable_compression': 'SnappyCompressor'};Empty strings are not allowed for keyspace and table identifiers though.I guess it's just a case that we haven't covered. Of course making it illegal in a future version would be a breaking change, but nobody serious would manually have chosen such an identifier...</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.Cql.g</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6139" opendate="2013-10-3 00:00:00" fixdate="2013-10-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cqlsh shouldn&amp;#39;t display empty "value alias"</summary>
      <description>When someone creates:CREATE TABLE foo ( k int, v int, PRIMARY KEY (k, v)) WITH COMPACT STORAGEthen we internally create a "value alias" (1.2)/"compact value definition" (2.0) with an empty name. Seems that cqlsh don't recognize that fact and display that as:cqlsh:ks&gt; DESC TABLE foo;CREATE TABLE foo ( k int, v int, "" blob, PRIMARY KEY (k, v)) WITH COMPACT STORAGE AND ...</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.cql3handling.py</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug id="6149" opendate="2013-10-6 00:00:00" fixdate="2013-10-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>OOM in Cassandra 2.0.1</summary>
      <description>I have a program to stress test Cassandra. What it does is remove/insert rows with a small set of row keys as fast as possible. Two CFs are involved. When I test against C* 1.2.3 with default configurations, it ran for 24 hours and C* doesn't having any issue. However after I upgraded to C* 2.0.1, C* crashes on OOM within 1-2 minutes. I can consistently reproduce this.I built C* from the source and found out the last good changeset is cfa097cdd5e28d7fe8204248e246a1fae226d2c0. As soon as I include the next changeset 1e0d9513b748fae4ec0737283da71c65e9272102, C* starts to crash. What's interesting is although it seems the change was reverted by fc1a7206fe15882fd64e7ba8eb68ba9dc320275f. C* built from fc1a7206fe15882fd64e7ba8eb68ba9dc320275f has the same problem - OOM within minutes.I didn't test against the official 2.0.0. But the C* built from 03045ca22b11b0e5fc85c4fabd83ce6121b5709b seems OK. I assume that's what 2.0.0 is.I use default configurations in all cases. I didn't tune anything.</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.FileCacheService.java</file>
      <file type="M">src.java.org.apache.cassandra.io.util.SegmentedFile.java</file>
      <file type="M">src.java.org.apache.cassandra.io.util.RandomAccessReader.java</file>
      <file type="M">src.java.org.apache.cassandra.io.compress.CompressedRandomAccessReader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6164" opendate="2013-10-8 00:00:00" fixdate="2013-10-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Switch CFS histograms to biased sampling</summary>
      <description></description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.metrics.ColumnFamilyMetrics.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStoreMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6175" opendate="2013-10-9 00:00:00" fixdate="2013-10-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>counter increment hangs</summary>
      <description>In a three node cluster, a simple counter increment at quorum hangs the query indefinitely. git blames our familiar friend CASSANDRA-6132 once again.</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
    </fixedFiles>
  </bug>
  <bug id="6183" opendate="2013-10-11 00:00:00" fixdate="2013-10-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Skip mutations that pass CRC but fail to deserialize</summary>
      <description>We've had a couple reports of CL replay failure that appear to be caused by dropping and recreating the same table with a different schema, e.g. CASSANDRA-5905. While CASSANDRA-5202 is the "right" fix for this, it's too involved for 2.0 let alone 1.2, so we need a stopgap until then.</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLogReplayer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6191" opendate="2013-10-13 00:00:00" fixdate="2013-10-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a warning for small sstable size setting in LCS</summary>
      <description>Not sure "bug" is the right description, because I can't say for sure that the large number of SSTables is the cause of the memory issues. I'll share my research so far:Under high read-load with a very large number of compressed SSTables (caused by the initial default 5mb sstable_size in LCS) it seems memory is exhausted, without any room for GC to fix this. It tries to GC but doesn't reclaim much.The node first hits the "emergency valves" flushing all memtables, then reducing caches. And finally logs 0.99+ heap usages and hangs with GC failure or crashes with OutOfMemoryError.I've taken a heapdump and started analysis to find out what's wrong. The memory seems to be used by the byte[] backing the HeapByteBuffer in the "compressed" field of org.apache.cassandra.io.compress.CompressedRandomAccessReader. The byte[] are generally 65536 byes in size, matching the block-size of the compression.Looking further in the heap-dump I can see that these readers are part of the pool in org.apache.cassandra.io.util.CompressedPoolingSegmentedFile. Which is linked to the "dfile" field of org.apache.cassandra.io.sstable.SSTableReader. The dump-file lists 45248 instances of CompressedRandomAccessReader.Is this intended to go this way? Is there a leak somewhere? Or should there be an alternative strategy and/or warning for cases where a node is trying to read far too many SSTables?EDIT:Searching through the code I found that PoolingSegmentedFile keeps a pool of RandomAccessReader for re-use. While the CompressedRandomAccessReader allocates a ByteBuffer in it's constructor and (to make things worse) enlarges it if it's reasing a large chunk. This (sometimes enlarged) ByteBuffer is then kept alive because it becomes part of the CompressedRandomAccessReader which is in turn kept alive as part of the pool in the PoolingSegmentedFile.</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LeveledCompactionStrategy.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6194" opendate="2013-10-13 00:00:00" fixdate="2013-10-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>speculative retry can sometimes violate consistency</summary>
      <description>This is most evident with intermittent failures of the short_read dtests. I'll focus on short_read_reversed_test for explanation, since that's what I used to bisect. This test inserts some columns into a row, then deletes a subset, but it performs each delete on a different node, with another node down (hints are disabled.) Finally it reads the row back at QUORUM and checks that it doesn't see any deleted columns, however with speculative retry on this often fails. I bisected this to the change that made 99th percentile SR the default reliably by looping the test enough times at each iteration to be sure it was passing or failing.</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.service.RowDigestResolver.java</file>
      <file type="M">src.java.org.apache.cassandra.service.ReadCallback.java</file>
      <file type="M">src.java.org.apache.cassandra.service.RangeSliceResponseResolver.java</file>
      <file type="M">src.java.org.apache.cassandra.service.IResponseResolver.java</file>
      <file type="M">src.java.org.apache.cassandra.service.AbstractRowResolver.java</file>
      <file type="M">src.java.org.apache.cassandra.service.AbstractReadExecutor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6196" opendate="2013-10-13 00:00:00" fixdate="2013-10-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add compaction, compression to cqlsh tab completion for CREATE TABLE</summary>
      <description></description>
      <version>1.2.12,2.0.2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.cql3handling.py</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug id="6197" opendate="2013-10-14 00:00:00" fixdate="2013-10-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create more Pig unit tests for type mappings</summary>
      <description>We need add more Pig unit testing for data type mappings including collections</description>
      <version>1.2.11,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.hadoop.pig.CqlStorage.java</file>
    </fixedFiles>
  </bug>
  <bug id="6206" opendate="2013-10-16 00:00:00" fixdate="2013-3-16 01:00:00" resolution="Won&amp;#39;t Fix">
    <buginformation>
      <summary>Thrift socket listen backlog</summary>
      <description>Although Thrift is a depreciated method of accessing Cassandra, default backlog is way too low on that socket. It shouldn't be a problem to implement it and I am including a POC patch for this (sorry, really low on time with limited Java knowledge so just to give an idea).This is an old report which was never addressed and the bug remains till this day, except in my case I have a much larger scale application with 3rd party software which I cannot modify to include connection pooling:https://issues.apache.org/jira/browse/CASSANDRA-1663There is also a pending change in the Thrift itself which Cassandra should be able to use for parts using TServerSocket (SSL):https://issues.apache.org/jira/browse/THRIFT-1868</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.thrift.TServerFactory.java</file>
      <file type="M">src.java.org.apache.cassandra.thrift.ThriftServer.java</file>
      <file type="M">src.java.org.apache.cassandra.thrift.TCustomServerSocket.java</file>
      <file type="M">src.java.org.apache.cassandra.thrift.CustomTThreadPoolServer.java</file>
      <file type="M">src.java.org.apache.cassandra.service.CassandraDaemon.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
    </fixedFiles>
  </bug>
  <bug id="6211" opendate="2013-10-17 00:00:00" fixdate="2013-10-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>NPE in system.log</summary>
      <description>I wrote a stresstest to test C* and my code that uses CAS heavily. I see strange exception messages in logs:ERROR [MutationStage:320] 2013-10-17 13:59:10,710 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:320,5,main]java.lang.NullPointerExceptionERROR [MutationStage:328] 2013-10-17 13:59:10,718 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:328,5,main]java.lang.NullPointerExceptionERROR [MutationStage:327] 2013-10-17 13:59:10,732 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:327,5,main]java.lang.NullPointerExceptionERROR [MutationStage:325] 2013-10-17 13:59:10,750 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:325,5,main]java.lang.NullPointerExceptionERROR [MutationStage:326] 2013-10-17 13:59:10,762 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:326,5,main]java.lang.NullPointerExceptionERROR [MutationStage:330] 2013-10-17 13:59:10,768 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:330,5,main]java.lang.NullPointerExceptionERROR [MutationStage:331] 2013-10-17 13:59:10,775 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:331,5,main]java.lang.NullPointerExceptionERROR [MutationStage:334] 2013-10-17 13:59:10,789 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:334,5,main]java.lang.NullPointerExceptionERROR [MutationStage:329] 2013-10-17 13:59:10,803 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:329,5,main]java.lang.NullPointerExceptionERROR [MutationStage:335] 2013-10-17 13:59:10,812 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:335,5,main]java.lang.NullPointerExceptionERROR [MutationStage:333] 2013-10-17 13:59:10,826 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:333,5,main]java.lang.NullPointerExceptionERROR [MutationStage:332] 2013-10-17 13:59:10,834 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:332,5,main]java.lang.NullPointerExceptionERROR [MutationStage:337] 2013-10-17 13:59:10,842 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:337,5,main]java.lang.NullPointerExceptionERROR [MutationStage:336] 2013-10-17 13:59:10,859 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:336,5,main]java.lang.NullPointerExceptionERROR [MutationStage:338] 2013-10-17 13:59:10,870 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:338,5,main]java.lang.NullPointerExceptionERROR [MutationStage:339] 2013-10-17 13:59:10,884 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:339,5,main]java.lang.NullPointerExceptionERROR [MutationStage:341] 2013-10-17 13:59:10,894 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:341,5,main]java.lang.NullPointerExceptionERROR [MutationStage:340] 2013-10-17 13:59:10,910 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:340,5,main]java.lang.NullPointerExceptionERROR [MutationStage:344] 2013-10-17 13:59:10,920 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:344,5,main]java.lang.NullPointerException</description>
      <version>2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.SystemKeyspace.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6213" opendate="2013-10-17 00:00:00" fixdate="2013-10-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Updating Pig to 0.11.1 breaks the existing Pig driver</summary>
      <description>Current trunk upgrades Pig to 0.11.1 which causes the Pig storages code can't compile. Pig storages need implement the new API method cleanupOnSuccess(String,Job).</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.hadoop.pig.AbstractCassandraStorage.java</file>
    </fixedFiles>
  </bug>
  <bug id="6214" opendate="2013-10-17 00:00:00" fixdate="2013-10-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make LOCAL_ONE the default consistency for cassandra.consistencylevel.[read|write]</summary>
      <description>Now that we have LOCAL_ONE consistency level, we should make it the default for Hadoop, which is cassandra.consistencylevel.&amp;#91;read|write&amp;#93;.See CASSANDRA-6202 and CASSANDRA-6124</description>
      <version>1.2.12,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.hadoop.ConfigHelper.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6217" opendate="2013-10-18 00:00:00" fixdate="2013-10-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>replace doesn&amp;#39;t clean up system.peers if you have a new IP</summary>
      <description>When you use replace_token (or replace_node or replace_address) if the new node has a different IP, the old node will still be in system.peers</description>
      <version>1.2.12,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
    </fixedFiles>
  </bug>
</bugrepository>
