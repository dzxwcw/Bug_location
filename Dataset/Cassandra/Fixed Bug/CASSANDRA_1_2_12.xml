<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="CASSANDRA">
  <bug id="4191" opendate="2012-4-26 00:00:00" fixdate="2012-10-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add `nodetool cfstats &lt;ks&gt; &lt;cf&gt;` abilities</summary>
      <description>This way cfstats will only print information per keyspace/column family combinations.Another related proposal as an alternative to this ticket:Allow for `nodetool cfstats` to use --excludes or --includes to accept keyspace and column family arguments.</description>
      <version>1.2.12,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.resources.org.apache.cassandra.tools.NodeToolHelp.yaml</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5988" opendate="2013-9-9 00:00:00" fixdate="2013-10-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make hint TTL customizable</summary>
      <description>Currently time to live for stored hints is hardcoded to be gc_grace_seconds. This causes problems for applications using backdated deletes as a form of optimistic locking. Hints for updates made to the same data on which delete was attempted can persist for days, making it impossible to determine if delete succeeded by doing read(ALL) after a reasonable delay. We need a way to explicitly configure hint TTL, either through schema parameter or through a yaml file.</description>
      <version>1.2.12,2.0.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.RowMutation.java</file>
      <file type="M">src.java.org.apache.cassandra.db.HintedHandOffManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="6114" opendate="2013-9-30 00:00:00" fixdate="2013-10-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Pig with widerows=true and batch size = 1 works incorrectly</summary>
      <description>If I run the demo pig scripts, I end up with a column family with 6 fairly wide rows. If I load and dump those rows with widerows=true or set the cassandra.range.batch.size=1, the dump returns the correct values. However, if I set both of those, it does not. So in the case of a batch size of 1, wide rows support is broken.So it's relatively simple to reproduce from the demo data:grunt&gt; SET cassandra.range.batch.size 1 grunt&gt; rows = LOAD 'cassandra://PigDemo/Scores' using CassandraStorage(); grunt&gt; dump rows;...(sylvain,{(4,),(7,),(10,),(21,),(24,),(46,),(47,),(49,),(51,),(52,),(67,),(68,),(72,),(73,),(82,),(83,),(86,),(98,),(101,),(105,),(108,),(112,),(114,),(124,),(125,),(136,),(139,),(145,),(150,),(151,),(153,),(165,),(167,),(171,),(178,),(182,),(202,),(211,),(212,),(215,),(226,),(237,),(242,),(243,),(255,),(261,),(273,),(282,),(300,),(307,),(308,),(311,),(312,),(313,),(316,),(317,),(332,),(337,),(338,),(348,),(355,),(360,),(361,),(373,),(375,),(377,),(384,),(401,),(404,),(412,),(418,),(429,),(436,),(441,),(451,),(453,),(461,),(473,),(478,),(483,),(485,),(486,),(489,),(509,),(511,),(516,),(517,),(521,),(536,),(541,),(543,),(545,),(550,),(583,),(587,),(592,),(611,),(613,),(622,),(625,),(627,),(633,),(648,),(649,),(651,),(659,),(665,),(668,),(670,),(672,),(679,),(688,),(692,),(700,),(703,),(707,),(709,),(730,),(731,),(738,),(740,),(744,),(750,),(759,),(764,),(766,),(768,),(774,),(776,),(778,),(779,),(788,),(795,),(796,),(813,),(821,),(825,),(830,),(831,),(835,),(843,),(846,),(847,),(848,),(851,),(862,),(863,),(872,),(878,),(881,),(883,),(884,),(888,),(905,),(906,),(916,),(921,),(926,),(928,),(944,),(946,),(947,),(952,),(954,),(972,),(973,),(974,),(976,),(978,),(982,),(991,)})(brandon,{(6,),(7,),(14,),(15,),(25,),(36,),(37,),(38,),(46,),(53,),(57,),(65,),(74,),(75,),(84,),(91,),(104,),(120,),(128,),(137,),(148,),(159,),(171,),(174,),(176,),(179,),(183,),(192,),(195,),(201,),(205,),(210,),(216,),(222,),(223,),(243,),(255,),(264,),(271,),(287,),(290,),(308,),(309,),(326,),(343,),(347,),(356,),(359,),(360,),(363,),(367,),(368,),(378,),(398,),(400,),(402,),(410,),(412,),(419,),(427,),(429,),(447,),(449,),(462,),(464,),(468,),(470,),(472,),(480,),(482,),(506,),(511,),(520,),(521,),(522,),(524,),(535,),(548,),(553,),(565,),(569,),(571,),(573,),(575,),(583,),(584,),(595,),(597,),(606,),(608,),(634,),(646,),(650,),(654,),(667,),(673,),(677,),(686,),(690,),(692,),(713,),(715,),(721,),(723,),(736,),(737,),(752,),(753,),(758,),(759,),(764,),(766,),(767,),(776,),(778,),(786,),(812,),(816,),(818,),(823,),(826,),(832,),(838,),(842,),(860,),(873,),(879,),(918,),(919,),(935,),(941,),(942,),(948,),(956,),(961,),(966,),(973,),(974,),(977,),(979,),(983,),(984,),(986,),(995,),(997,)})(jake,{(1,),(7,),(10,),(14,),(29,),(52,),(54,),(65,),(67,),(78,),(82,),(83,),(89,),(97,),(100,),(115,),(126,),(140,),(141,),(145,),(214,),(221,),(230,),(231,),(232,),(241,),(245,),(247,),(265,),(266,),(269,),(271,),(282,),(286,),(288,),(299,),(316,),(323,),(331,),(332,),(335,),(338,),(348,),(353,),(355,),(364,),(367,),(371,),(379,),(398,),(409,),(420,),(428,),(429,),(439,),(443,),(450,),(454,),(467,),(477,),(482,),(488,),(490,),(502,),(503,),(512,),(520,),(521,),(535,),(536,),(541,),(548,),(552,),(557,),(560,),(596,),(600,),(604,),(606,),(611,),(613,),(621,),(624,),(630,),(635,),(641,),(647,),(655,),(660,),(665,),(674,),(676,),(690,),(693,),(694,),(704,),(719,),(720,),(724,),(731,),(749,),(751,),(763,),(765,),(767,),(771,),(779,),(782,),(784,),(789,),(793,),(797,),(798,),(801,),(802,),(806,),(820,),(825,),(839,),(845,),(848,),(856,),(865,),(866,),(867,),(870,),(876,),(887,),(891,),(901,),(905,),(908,),(922,),(929,),(944,),(960,),(964,),(980,),(988,),(996,)})(eric,{(14,),(17,),(23,),(25,),(26,),(34,),(42,),(43,),(57,),(64,),(68,),(80,),(88,),(93,),(100,),(114,),(131,),(132,),(134,),(143,),(146,),(147,),(156,),(157,),(170,),(171,),(172,),(177,),(186,),(197,),(198,),(206,),(209,),(223,),(224,),(233,),(236,),(241,),(251,),(252,),(255,),(263,),(266,),(267,),(268,),(272,),(277,),(280,),(289,),(293,),(294,),(297,),(301,),(306,),(310,),(312,),(321,),(326,),(333,),(334,),(335,),(345,),(357,),(362,),(363,),(370,),(380,),(389,),(392,),(393,),(401,),(420,),(431,),(462,),(464,),(465,),(471,),(484,),(486,),(490,),(493,),(504,),(505,),(509,),(515,),(521,),(534,),(538,),(547,),(554,),(557,),(561,),(564,),(572,),(573,),(578,),(582,),(584,),(590,),(598,),(599,),(603,),(605,),(609,),(618,),(634,),(636,),(639,),(648,),(656,),(661,),(667,),(671,),(674,),(675,),(687,),(713,),(721,),(733,),(736,),(763,),(767,),(776,),(785,),(787,),(809,),(813,),(826,),(829,),(830,),(832,),(840,),(841,),(844,),(846,),(854,),(855,),(876,),(890,),(892,),(902,),(910,),(930,),(934,),(938,),(940,),(943,),(955,),(959,),(965,),(966,),(968,),(972,),(980,),(985,),(989,)})(jonathan,{(17,),(18,),(31,),(34,),(37,),(40,),(67,),(69,),(75,),(93,),(111,),(124,),(127,),(128,),(137,),(142,),(168,),(178,),(190,),(193,),(194,),(207,),(211,),(216,),(221,),(229,),(237,),(242,),(252,),(253,),(264,),(265,),(267,),(270,),(272,),(274,),(276,),(278,),(280,),(283,),(297,),(299,),(300,),(302,),(303,),(309,),(311,),(318,),(323,),(329,),(330,),(332,),(344,),(346,),(351,),(354,),(358,),(361,),(363,),(366,),(367,),(374,),(378,),(379,),(386,),(389,),(392,),(395,),(398,),(404,),(424,),(426,),(429,),(434,),(439,),(443,),(445,),(448,),(472,),(477,),(494,),(500,),(504,),(522,),(525,),(538,),(539,),(541,),(548,),(553,),(557,),(560,),(563,),(566,),(567,),(578,),(591,),(593,),(595,),(599,),(605,),(610,),(626,),(635,),(636,),(640,),(642,),(644,),(649,),(660,),(662,),(663,),(667,),(674,),(690,),(706,),(708,),(712,),(716,),(723,),(733,),(741,),(747,),(758,),(765,),(797,),(798,),(801,),(822,),(827,),(828,),(837,),(850,),(863,),(867,),(894,),(895,),(896,),(904,),(911,),(917,),(932,),(949,),(951,),(952,),(958,),(969,),(974,),(983,),(985,),(988,),(989,),(996,),(1000,)})(gary,{(3,),(13,),(21,),(23,),(33,),(36,),(44,),(45,),(48,),(62,),(65,),(68,),(75,),(80,),(81,),(90,),(111,),(113,),(119,),(123,),(137,),(149,),(152,),(153,),(157,),(161,),(166,),(178,),(179,),(180,),(183,),(184,),(188,),(189,),(191,),(197,),(199,),(200,),(204,),(212,),(221,),(229,),(239,),(265,),(270,),(272,),(276,),(279,),(282,),(295,),(296,),(304,),(305,),(314,),(326,),(329,),(335,),(342,),(345,),(346,),(362,),(370,),(371,),(375,),(380,),(382,),(387,),(389,),(390,),(393,),(399,),(403,),(406,),(414,),(417,),(424,),(428,),(445,),(458,),(462,),(486,),(490,),(492,),(495,),(499,),(500,),(507,),(514,),(520,),(542,),(550,),(551,),(570,),(571,),(572,),(574,),(577,),(588,),(604,),(614,),(619,),(626,),(634,),(640,),(648,),(659,),(663,),(684,),(687,),(690,),(694,),(715,),(741,),(750,),(765,),(772,),(776,),(781,),(782,),(783,),(785,),(789,),(802,),(806,),(812,),(816,),(820,),(829,),(836,),(843,),(850,),(855,),(868,),(873,),(875,),(889,),(900,),(904,),(922,),(928,),(929,),(935,),(946,),(949,),(954,),(956,),(959,),(960,),(962,),(992,)})grunt&gt; SET cassandra.range.batch.size 1 grunt&gt; rows = LOAD 'cassandra://PigDemo/Scores?widerows=true' using CassandraStorage();grunt&gt; dump rows;...(jonathan,{(17,)})(sylvain,{(4,)})When I try with set batch size to something higher than 1 and it works fine.</description>
      <version>1.2.12,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.hadoop.ColumnFamilyRecordReader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6196" opendate="2013-10-13 00:00:00" fixdate="2013-10-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add compaction, compression to cqlsh tab completion for CREATE TABLE</summary>
      <description></description>
      <version>1.2.12,2.0.2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.cql3handling.py</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug id="6214" opendate="2013-10-17 00:00:00" fixdate="2013-10-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make LOCAL_ONE the default consistency for cassandra.consistencylevel.[read|write]</summary>
      <description>Now that we have LOCAL_ONE consistency level, we should make it the default for Hadoop, which is cassandra.consistencylevel.&amp;#91;read|write&amp;#93;.See CASSANDRA-6202 and CASSANDRA-6124</description>
      <version>1.2.12,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.hadoop.ConfigHelper.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6217" opendate="2013-10-18 00:00:00" fixdate="2013-10-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>replace doesn&amp;#39;t clean up system.peers if you have a new IP</summary>
      <description>When you use replace_token (or replace_node or replace_address) if the new node has a different IP, the old node will still be in system.peers</description>
      <version>1.2.12,2.0.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
    </fixedFiles>
  </bug>
  <bug id="6238" opendate="2013-10-24 00:00:00" fixdate="2013-11-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LOCAL_ONE doesn&amp;#39;t work for SimpleStrategy</summary>
      <description>LOCAL_ONE only works for NetworkTopologyStrategy which has DC specification. Any other strategy fails.If there is no DC specified in the strategy, we should treat LOCAL_ONE as ONE</description>
      <version>1.2.12,2.0.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.ConsistencyLevel.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6239" opendate="2013-10-24 00:00:00" fixdate="2013-10-24 01:00:00" resolution="Duplicate">
    <buginformation>
      <summary>pidfile is never written, "/etc/init.d/cassandra stop" fails</summary>
      <description>The init script tries, via start-stop-daemon, to write a pidfile to /var/run/cassandra/cassandra.pid. /var/run/cassandra doesn't exist (righftully so, /var/run can be a tmpfs), so the init script has this stanza above the start-stop-daemon invocation: [ -e `dirname "PIDFILE"` ] || \ install -d -ocassandra -gcassandra -m750 `dirname $PIDFILE`The first line is missing the dollar sign before the PIDFILE variable (i.e. it should be 'dirname "$PIDFILE"'). This has the effect that "dirname PIDFILE" is called, with the PIDFILE as a literal, which always returns "." as the output, which always exists, so the "install" call never gets executed, the directory never gets created and start-stop-daemon is unable to write the pidfile.The pidfile is never written and "/etc/init.d/cassandra stop" never works.Adding a $ before PIDFILE fixes the issue. This has been tested.</description>
      <version>None</version>
      <fixedVersion>Packaging</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">examples.pig.example-script.pig</file>
    </fixedFiles>
  </bug>
  <bug id="6244" opendate="2013-10-25 00:00:00" fixdate="2013-11-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>calculatePendingRanges could be asynchronous on 1.2 too</summary>
      <description>calculatePendingRanges can hang up the Gossip thread to the point of a node marking all the other nodes down.I noticed that the same problem was resolved with CASSANDRA-5135, so I attempted to port the patch from that issue to the 1.2 codebase.</description>
      <version>1.2.12,2.0.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.locator.SimpleStrategyTest.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
    </fixedFiles>
  </bug>
  <bug id="6254" opendate="2013-10-28 00:00:00" fixdate="2013-10-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thrift&amp;#39;s prepare_cql*_query() should validate login</summary>
      <description>Non-logged in users shouldn't be able to prepare statements when authentication is enabled.Native protocol is not affected by this, since it doesn't let you do anything unless you authenticate when auth is enabled.</description>
      <version>1.2.12,2.0.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraServer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6267" opendate="2013-10-29 00:00:00" fixdate="2013-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>restrict max num_tokens to something Gossip can handle</summary>
      <description></description>
      <version>1.2.12,2.0.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6272" opendate="2013-10-30 00:00:00" fixdate="2013-10-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>sstableloader data distribution is broken since 1.2.7</summary>
      <description>Running sstableloader on 1.2.10+ results in radically different distribution compared with earlier versions. It looks as though the 'bare-bones' IndexSummary created in SSTR.loadForBatch is the cause (CASSANDRA-5555); because it contains only a single entry, we end up with the wrong segment of the index file in SSTR.getPosition (its position is always 0), so only the first segment of the index file is considered when searching for the range's position.This doesn't affect 2.0/trunk</description>
      <version>1.2.12</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.io.sstable.SSTableReaderTest.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableReader.java</file>
    </fixedFiles>
  </bug>
  <bug id="6273" opendate="2013-10-30 00:00:00" fixdate="2013-10-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>nodetool should get default JMX port from cassandra-env.sh</summary>
      <description>Although nodetool provides command line switches to specify the JMX port, it would be convenient if it could default to the value specified in cassandra-env.sh</description>
      <version>1.2.12,2.0.3</version>
      <fixedVersion>Tool/nodetool</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.nodetool</file>
    </fixedFiles>
  </bug>
  <bug id="6308" opendate="2013-11-6 00:00:00" fixdate="2013-11-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thread leak caused in creating OutboundTcpConnectionPool</summary>
      <description>We have seen in one of our large clusters that there are many OutboundTcpConnection threads having the same names. From a thread dump, OutboundTcpConnection threads have accounted for the largest shares of the total threads (65%+) and kept growing.Here is a portion of a grep output for threads in which names start with "WRITE-":"WRITE-/10.28.131.195" daemon prio=10 tid=0x00002aaac4022000 nid=0x2cb5 waiting on condition &amp;#91;0x00002acfbacda000&amp;#93;"WRITE-/10.28.131.195" daemon prio=10 tid=0x00002aaac42fe000 nid=0x2cb4 waiting on condition &amp;#91;0x00002acfbacad000&amp;#93;"WRITE-/10.30.142.49" daemon prio=10 tid=0x0000000040840000 nid=0x2cb1 waiting on condition &amp;#91;0x00002acfbac80000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x000000004083e000 nid=0x2cb0 waiting on condition &amp;#91;0x00002acfbac53000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x000000004083b800 nid=0x2caf waiting on condition &amp;#91;0x00002acfbac26000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x0000000040839800 nid=0x2cae waiting on condition &amp;#91;0x00002acfbabf9000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x0000000040837800 nid=0x2cad waiting on condition &amp;#91;0x00002acfbabcc000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00000000404a3800 nid=0x2cac waiting on condition &amp;#91;0x00002acfbab9f000&amp;#93;"WRITE-/10.30.142.49" daemon prio=10 tid=0x00000000404a1800 nid=0x2cab waiting on condition &amp;#91;0x00002acfbab72000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x000000004049f800 nid=0x2caa waiting on condition &amp;#91;0x00002acfbab45000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x000000004049e000 nid=0x2ca9 waiting on condition &amp;#91;0x00002acfbab18000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x000000004049c800 nid=0x2ca8 waiting on condition &amp;#91;0x00002acfbaaeb000&amp;#93;"WRITE-/10.157.10.134" daemon prio=10 tid=0x000000004049a800 nid=0x2ca7 waiting on condition &amp;#91;0x00002acfbaabe000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x0000000040498800 nid=0x2ca6 waiting on condition &amp;#91;0x00002acfbaa91000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x0000000040496800 nid=0x2ca5 waiting on condition &amp;#91;0x00002acfbaa64000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x0000000040717800 nid=0x2ca4 waiting on condition &amp;#91;0x00002acfbaa37000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x0000000040716000 nid=0x2ca3 waiting on condition &amp;#91;0x00002acfbaa0a000&amp;#93;"WRITE-/10.30.146.195" daemon prio=10 tid=0x0000000040714800 nid=0x2ca2 waiting on condition &amp;#91;0x00002acfba9dd000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x0000000040712800 nid=0x2ca1 waiting on condition &amp;#91;0x00002acfba9b0000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x0000000040710800 nid=0x2ca0 waiting on condition &amp;#91;0x00002acfba983000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x000000004070e800 nid=0x2c9f waiting on condition &amp;#91;0x00002acfba956000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x000000004070d000 nid=0x2c9e waiting on condition &amp;#91;0x00002acfba929000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x000000004070b800 nid=0x2c9d waiting on condition &amp;#91;0x00002acfba8fc000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x000000004070a000 nid=0x2c9c waiting on condition &amp;#91;0x00002acfba8cf000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x0000000040827000 nid=0x2c9b waiting on condition &amp;#91;0x00002acfba8a2000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x0000000040825000 nid=0x2c9a waiting on condition &amp;#91;0x00002acfba875000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00002aaac488e000 nid=0x2c99 waiting on condition &amp;#91;0x00002acfba848000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x0000000040823000 nid=0x2c98 waiting on condition &amp;#91;0x00002acfba81b000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x0000000040821800 nid=0x2c97 waiting on condition &amp;#91;0x00002acfba7ee000&amp;#93;"WRITE-/10.30.146.195" daemon prio=10 tid=0x000000004081f000 nid=0x2c96 waiting on condition &amp;#91;0x00002acfba7c1000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x000000004081d000 nid=0x2c95 waiting on condition &amp;#91;0x00002acfba794000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x000000004081b000 nid=0x2c94 waiting on condition &amp;#91;0x00002acfba767000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00002aaac488b000 nid=0x2c93 waiting on condition &amp;#91;0x00002acfba73a000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x0000000040819000 nid=0x2c92 waiting on condition &amp;#91;0x00002acfba70d000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00000000407f9000 nid=0x2c91 waiting on condition &amp;#91;0x00002acfba6e0000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00000000407f7000 nid=0x2c90 waiting on condition &amp;#91;0x00002acfba6b3000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00000000407f5000 nid=0x2c8f waiting on condition &amp;#91;0x00002acfba686000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00000000407f3000 nid=0x2c8d waiting on condition &amp;#91;0x00002acfba659000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00000000407f1800 nid=0x2c8c waiting on condition &amp;#91;0x00002acfba62c000&amp;#93;"WRITE-/10.157.10.134" daemon prio=10 tid=0x00000000407ef000 nid=0x2c8b waiting on condition &amp;#91;0x00002acfba5ff000&amp;#93;"WRITE-/10.157.10.134" daemon prio=10 tid=0x00000000407ed800 nid=0x2c8a waiting on condition &amp;#91;0x00002acfba5d2000&amp;#93;"WRITE-/10.28.131.195" daemon prio=10 tid=0x00000000407ec000 nid=0x2c89 waiting on condition &amp;#91;0x00002acfba5a5000&amp;#93;"WRITE-/10.30.161.144" daemon prio=10 tid=0x00000000407e9800 nid=0x2c88 waiting on condition &amp;#91;0x00002acfba578000&amp;#93;"WRITE-/10.157.10.134" daemon prio=10 tid=0x00000000405f5000 nid=0x2c87 waiting on condition &amp;#91;0x00002acfba54b000&amp;#93;"WRITE-/10.157.10.134" daemon prio=10 tid=0x00000000405f3000 nid=0x2c86 waiting on condition &amp;#91;0x00002acfba51e000&amp;#93;"WRITE-/10.157.10.134" daemon prio=10 tid=0x00000000405f1000 nid=0x2c85 waiting on condition &amp;#91;0x00002acfba4f1000&amp;#93;"WRITE-/10.157.10.134" daemon prio=10 tid=0x00000000405ef000 nid=0x2c83 waiting on condition &amp;#91;0x00002acfba4c4000&amp;#93;"WRITE-/10.157.10.134" daemon prio=10 tid=0x00000000405ed800 nid=0x2c82 waiting on condition &amp;#91;0x00002acfba497000&amp;#93;"WRITE-/10.157.10.134" daemon prio=10 tid=0x00000000405eb800 nid=0x2c81 waiting on condition &amp;#91;0x00002acfba46a000&amp;#93;"WRITE-/10.157.10.134" daemon prio=10 tid=0x00000000405ea000 nid=0x2c80 waiting on condition &amp;#91;0x00002acfba43d000&amp;#93;"WRITE-/10.157.10.134" daemon prio=10 tid=0x00000000405e8800 nid=0x2c7f waiting on condition &amp;#91;0x00002acfba40f000&amp;#93;"WRITE-/10.157.10.134" daemon prio=10 tid=0x00000000405e7800 nid=0x2c7e waiting on condition &amp;#91;0x00002acfba3e2000&amp;#93;"WRITE-/10.30.161.144" daemon prio=10 tid=0x0000000040607000 nid=0x2c7d waiting on condition &amp;#91;0x00002acfba3b5000&amp;#93;"WRITE-/10.30.161.144" daemon prio=10 tid=0x0000000040605800 nid=0x2c7c waiting on condition &amp;#91;0x00002acfba388000&amp;#93;"WRITE-/10.30.142.49" daemon prio=10 tid=0x0000000040604000 nid=0x2c7b waiting on condition &amp;#91;0x00002acfba35b000&amp;#93;"WRITE-/10.157.10.134" daemon prio=10 tid=0x0000000040602000 nid=0x2c7a waiting on condition &amp;#91;0x00002acfba32e000&amp;#93;"WRITE-/10.157.10.134" daemon prio=10 tid=0x00000000405ff800 nid=0x2c79 waiting on condition &amp;#91;0x00002acfba301000&amp;#93;"WRITE-/10.157.10.134" daemon prio=10 tid=0x00000000405fe000 nid=0x2c78 waiting on condition &amp;#91;0x00002acfba2d4000&amp;#93;"WRITE-/10.157.10.134" daemon prio=10 tid=0x00000000405fc000 nid=0x2c77 waiting on condition &amp;#91;0x00002acfba2a7000&amp;#93;"WRITE-/10.157.10.134" daemon prio=10 tid=0x00000000405fa800 nid=0x2c75 waiting on condition &amp;#91;0x00002acfba27a000&amp;#93;"WRITE-/10.157.10.134" daemon prio=10 tid=0x0000000040af9800 nid=0x2c74 waiting on condition &amp;#91;0x00002acfba24d000&amp;#93;"WRITE-/10.157.10.134" daemon prio=10 tid=0x0000000040af8000 nid=0x2c73 waiting on condition &amp;#91;0x00002acfba220000&amp;#93;"WRITE-/10.30.161.144" daemon prio=10 tid=0x0000000040af6000 nid=0x2c72 waiting on condition &amp;#91;0x00002acfba1f3000&amp;#93;"WRITE-/10.28.131.195" daemon prio=10 tid=0x0000000040af4000 nid=0x2c71 waiting on condition &amp;#91;0x00002acfba1c6000&amp;#93;"WRITE-/10.157.10.134" daemon prio=10 tid=0x0000000040af2000 nid=0x2c70 waiting on condition &amp;#91;0x00002acfba199000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x0000000040af0800 nid=0x2c6f waiting on condition &amp;#91;0x00002acfba16c000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x0000000040aef000 nid=0x2c6e waiting on condition &amp;#91;0x00002acfba13f000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x0000000040aed000 nid=0x2c6d waiting on condition &amp;#91;0x00002acfba112000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x0000000040aeb800 nid=0x2c6b waiting on condition &amp;#91;0x00002acfba0b8000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00002aaac46b9000 nid=0x2c6a waiting on condition &amp;#91;0x00002acfba08b000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00000000407b3000 nid=0x2c69 waiting on condition &amp;#91;0x00002acfba05e000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00000000407b1800 nid=0x2c68 waiting on condition &amp;#91;0x00002acfba031000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00000000407af800 nid=0x2c66 waiting on condition &amp;#91;0x00002acfba004000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00000000407ae000 nid=0x2c65 waiting on condition &amp;#91;0x00002acfb9fd7000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00000000407ab800 nid=0x2c64 waiting on condition &amp;#91;0x00002acfb9faa000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00000000407a9800 nid=0x2c63 waiting on condition &amp;#91;0x00002acfb9f7d000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00000000407a8000 nid=0x2c62 waiting on condition &amp;#91;0x00002acfb9f50000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00000000407a6800 nid=0x2c61 waiting on condition &amp;#91;0x00002acfb9f23000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00000000408d2800 nid=0x2c60 waiting on condition &amp;#91;0x00002acfb9ef6000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00000000408d1000 nid=0x2c5f waiting on condition &amp;#91;0x00002acfb9ec9000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00000000408cf800 nid=0x2c5d waiting on condition &amp;#91;0x00002acfb9e9c000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00000000408cd800 nid=0x2c5c waiting on condition &amp;#91;0x00002acfb9e6f000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00000000408cc000 nid=0x2c5b waiting on condition &amp;#91;0x00002acfb9e42000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x000000004088d800 nid=0x2c5a waiting on condition &amp;#91;0x00002acfb9e15000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x000000004088b000 nid=0x2c59 waiting on condition &amp;#91;0x00002acfb9de8000&amp;#93;"WRITE-/10.157.10.134" daemon prio=10 tid=0x0000000040889000 nid=0x2c58 waiting on condition &amp;#91;0x00002acfb9dbb000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x0000000040887800 nid=0x2c57 waiting on condition &amp;#91;0x00002acfb9d8e000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x0000000040720000 nid=0x2c56 waiting on condition &amp;#91;0x00002acfb9d61000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x000000004071f000 nid=0x2c55 waiting on condition &amp;#91;0x00002acfb9d34000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00000000407c3000 nid=0x2c54 waiting on condition &amp;#91;0x00002acfb9d07000&amp;#93;"WRITE-/10.78.95.30" daemon prio=10 tid=0x00000000407c1800 nid=0x2c53 waiting on condition &amp;#91;0x00002acfb9cda000&amp;#93;"WRITE-/10.28.131.195" daemon prio=10 tid=0x00000000407c0000 nid=0x2c52 waiting on condition &amp;#91;0x00002acfb9cac000&amp;#93;"WRITE-/10.28.131.195" daemon prio=10 tid=0x00000000407be000 nid=0x2c51 waiting on condition &amp;#91;0x00002acfb9c7f000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00000000405cc000 nid=0x2c50 waiting on condition &amp;#91;0x00002acfb9c52000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00000000405ca800 nid=0x2c4f waiting on condition &amp;#91;0x00002acfb9c24000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00000000405c8800 nid=0x2c4e waiting on condition &amp;#91;0x00002acfb9bf7000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00000000405c6800 nid=0x2c4d waiting on condition &amp;#91;0x00002acfb9bca000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00002aaac5010800 nid=0x2c4c waiting on condition &amp;#91;0x00002acfb9b9c000&amp;#93;"WRITE-/10.6.222.233" daemon prio=10 tid=0x00002aaac4cd9800 nid=0x2c4b waiting on condition &amp;#91;0x00002acfb9b6f000&amp;#93;"WRITE-/10.11.15.209" daemon prio=10 tid=0x0000000040756800 nid=0x2c4a waiting on condition &amp;#91;0x00002acfb9b42000&amp;#93;"WRITE-/10.11.15.209" daemon prio=10 tid=0x0000000040754800 nid=0x2c49 waiting on condition &amp;#91;0x00002acfb9b15000&amp;#93;We have patched this https://issues.apache.org/jira/browse/CASSANDRA-5175 but I don't this fix solves the issue totally. I will attach a patch soon.</description>
      <version>1.2.12,2.0.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6325" opendate="2013-11-9 00:00:00" fixdate="2013-2-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>AssertionError on startup reading saved Serializing row cache</summary>
      <description>I don't see any reason what this could have to do with the upgrade, but don't have a large enough non-prod cluster to just keep restarting on. Occurred on roughly 2 out of 100 restarted nodes. ERROR [main] 2013-11-08 14:40:13,535 CassandraDaemon.java (line 482) Exception encountered during startupjava.lang.AssertionError at org.apache.cassandra.cache.SerializingCacheProvider$RowCacheSerializer.serialize(SerializingCacheProvider.java:41) at org.apache.cassandra.cache.SerializingCacheProvider$RowCacheSerializer.serialize(SerializingCacheProvider.java:37) at org.apache.cassandra.cache.SerializingCache.serialize(SerializingCache.java:118) at org.apache.cassandra.cache.SerializingCache.put(SerializingCache.java:176) at org.apache.cassandra.cache.InstrumentingCache.put(InstrumentingCache.java:44) at org.apache.cassandra.cache.AutoSavingCache.loadSaved(AutoSavingCache.java:156) at org.apache.cassandra.db.ColumnFamilyStore.initRowCache(ColumnFamilyStore.java:444) at org.apache.cassandra.db.Table.open(Table.java:114) at org.apache.cassandra.db.Table.open(Table.java:87) at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:278) at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:465)I have the files if there is any useful analysis that can be run. Looked 'normal' to a cursory `less` inspection.Possibly related: CASSANDRA-4463</description>
      <version>1.2.12,2.0.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6330" opendate="2013-11-11 00:00:00" fixdate="2013-11-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LIMIT fetches one less than requested value</summary>
      <description>Using Cassandra 1.2.11, the following sequence demonstrates the issue:CREATE TABLE blah (key text, column text, value text, PRIMARY KEY (key, column)) WITH COMPACT STORAGE;INSERT INTO blah (key, column, value) VALUES ('a', 'a', 'a');INSERT INTO blah (key, column, value) VALUES ('a', 'b', 'e');INSERT INTO blah (key, column, value) VALUES ('a', 'c', 'e');INSERT INTO blah (key, column, value) VALUES ('a', 'd', 'e');INSERT INTO blah (key, column, value) VALUES ('a', 'e', 'e');SELECT column FROM blah WHERE key = 'a' AND column &lt; 'c' ORDER BY column DESC LIMIT 2; column-------- bHowever I would expect columns b and a to both be returned. Only seems to be an issue if the range bound is an exact match, and only if ORDER BY column DESC is used.</description>
      <version>1.2.12</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6341" opendate="2013-11-13 00:00:00" fixdate="2013-11-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>After executing abnormal cql statement, not working (hang)</summary>
      <description>I use a set type in table like sample, but if awkward cql statement failed, cqlsh is not worked like belows.serkeyspace&gt; CREATE TABLE images ( ... name text PRIMARY KEY, ... owner text, ... date timestamp, ... tags set&lt;text&gt; ... );cqlsh:userkeyspace&gt; delete tags&amp;#91;&amp;#39;cuddly&amp;#39;&amp;#93; from images where name = 'cat.jpg'; // not allowd cql statement(hang)^C cqlsh:userkeyspace&gt; select * from plays;(hang)^Ccqlsh:userkeyspace&gt; describe table plays;(hang)^Ccqlsh:userkeyspace&gt; quit---------------------------------cassandra log when hang is occured.ERROR 16:59:57,653 Exception in thread Thread&amp;#91;Thrift:8,5,main&amp;#93;java.lang.AssertionError at org.apache.cassandra.cql3.Lists$Discarder.execute(Lists.java:414) at org.apache.cassandra.cql3.statements.DeleteStatement.updateForKey(DeleteStatement.java:82) at org.apache.cassandra.cql3.statements.ModificationStatement.getMutations(ModificationStatement.java:506) at org.apache.cassandra.cql3.statements.ModificationStatement.executeWithoutCondition(ModificationStatement.java:377) at org.apache.cassandra.cql3.statements.ModificationStatement.execute(ModificationStatement.java:363) at org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:101) at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:117) at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:108) at org.apache.cassandra.thrift.CassandraServer.execute_cql3_query(CassandraServer.java:1933) at org.apache.cassandra.thrift.Cassandra$Processor$execute_cql3_query.getResult(Cassandra.java:4394) at org.apache.cassandra.thrift.Cassandra$Processor$execute_cql3_query.getResult(Cassandra.java:4378) at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39) at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) at org.apache.cassandra.thrift.CustomTThreadPoolServer$WorkerProcess.run(CustomTThreadPoolServer.java:194) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:744)</description>
      <version>1.2.12,2.0.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.Operation.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6347" opendate="2013-11-14 00:00:00" fixdate="2013-11-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LOCAL_ONE code in the native protocol is not the same in C* 1.2 and C* 2.0</summary>
      <description>When LOCAL_ONE was added (CASSANDRA-6202), it was unfortunately not given the same code (the one used by the native protocol) in C* 1.2 and C* 2.0. In 1.2 it's 8 (even though the specification document pretends it's 10) while it's 10 in 2.0.This basically breaks backward compatibility for the v1 protocol between C* 1.2 and C* 2.0. Now, we could "fix" 2.0 adding special cases for the v1 protocol but that's going to be a bit of a pain, so instead I suggest to just switch to 10 in 1.2. Since the spec was wrong anyway and nobody complained so far this suggest no-one has really added support for LOCAL_ONE in the native protocol against 1.2.11, so if we change it now we can just say to people to upgrade to 1.2.12 directly if they want to use LOCAL_ONE with the native protocol. Attaching simple patch for that.</description>
      <version>1.2.12</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.ConsistencyLevel.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6351" opendate="2013-11-15 00:00:00" fixdate="2013-11-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>When dropping a CF, row cache is not invalidated</summary>
      <description>When dropping a ColumnFamily with row cache enabled, then row cache is not invalidated for this CF.This can be a bit annoying if the ColumnFamily is recreated because it will be empty, but row cache won't.Note : this is similar to a "TRUNCATE" command (and TRUNCATE does invalidate the cache...)Attached is patch which removes the rows of the currently dropped CF from row cache.</description>
      <version>1.2.12,2.0.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6370" opendate="2013-11-18 00:00:00" fixdate="2013-11-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Updating cql created table through cassandra-cli transform it into a compact storage table</summary>
      <description>To reproduce :echo "CREATE TABLE test (aid int, period text, event text, viewer text, PRIMARY KEY (aid, period, event, viewer) );" | cqlsh -kmykeyspace;echo "describe table test;" | cqlsh -kmykeyspace;Output &gt;CREATE TABLE test ( aid int, period text, event text, viewer text, PRIMARY KEY (aid, period, event, viewer)) WITH bloom_filter_fp_chance=0.010000 AND caching='KEYS_ONLY' AND comment='' AND dclocal_read_repair_chance=0.000000 AND gc_grace_seconds=864000 AND read_repair_chance=0.100000 AND replicate_on_write='true' AND populate_io_cache_on_flush='false' AND compaction={'class': 'SizeTieredCompactionStrategy'} AND compression={'sstable_compression': 'SnappyCompressor'};Then do :echo "update column family test with dclocal_read_repair_chance = 0.1;" | cassandra-cli -kmykeyspaceAnd finally again : echo "describe table test;" | cqlsh -kmykeyspace;Output &gt;CREATE TABLE test ( aid int, column1 text, column2 text, column3 text, column4 text, value blob, PRIMARY KEY (aid, column1, column2, column3, column4)) WITH COMPACT STORAGE AND bloom_filter_fp_chance=0.010000 AND caching='KEYS_ONLY' AND comment='' AND dclocal_read_repair_chance=0.100000 AND gc_grace_seconds=864000 AND read_repair_chance=0.100000 AND replicate_on_write='true' AND populate_io_cache_on_flush='false' AND compaction={'class': 'SizeTieredCompactionStrategy'} AND compression={'sstable_compression': 'SnappyCompressor'};This is quite annoying in production. If it is happening to you: UPDATE system.schema_columnfamilies SET column_aliases = '&amp;#91;"period","event","viewer"&amp;#93;' WHERE keyspace_name='mykeyspace' AND columnfamily_name='test'; should help restoring the table. (Thanks Sylvain for this information.)</description>
      <version>1.2.12</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraServer.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>
