<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="CASSANDRA">
  <bug id="9119" opendate="2015-4-3 00:00:00" fixdate="2015-6-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Nodetool rebuild creates an additional rebuild session even if there is one already running</summary>
      <description>If a nodetool rebuild session is started and the shell session is finished for whatever reason, a second nodetool rebuild will spawn a second rebuild filestreamDC2-S1-100-29:~ # ps aux | grep nodetool root 10304 0.0 0.0 4532 560 pts/3 S+ 05:23 0:00 grep nodetool dds-user 20946 0.0 0.0 21180 1880 ? S 04:39 0:00 /bin/sh /usr/share/dse/resources/cassandra/bin/nodetool rebuild group10 &lt;---- there is only one rebuild runningDC2-S1-100-29:~ # nodetool netstats | grep -v /var/local/cassandra Mode: NORMAL Rebuild 818307b0-d9ba-11e4-8d4c-7bce93ffad70 &lt;------ does this represent one rebuild? /10.96.100.22 Receiving 63 files, 221542605741 bytes total /10.96.100.26 Receiving 48 files, 47712285610 bytes total /10.96.100.25 /10.96.100.23 Receiving 57 files, 127515362783 bytes total /10.96.100.27 /10.96.100.24 Rebuild 7bf9fcd0-d9bb-11e4-8d4c-7bce93ffad70 &lt;------- does this represent a second rebuild? /10.96.100.25 /10.96.100.26 Receiving 56 files, 47717905924 bytes total /10.96.100.24 /10.96.100.22 Receiving 61 files, 221558642440 bytes total /10.96.100.23 Receiving 62 files, 127528841272 bytes total /10.96.100.27 Read Repair Statistics: Attempted: 0 Mismatch (Blocking): 0 Mismatch (Background): 0 Pool Name Active Pending Completed Commands n/a 0 2151322 Responses n/a 0 3343981</description>
      <version>2.1.7,2.2.0rc2</version>
      <fixedVersion>Tool/nodetool</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9529" opendate="2015-6-2 00:00:00" fixdate="2015-6-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Standardize quoting in Unix scripts</summary>
      <description>$CLASSPATH and $JAVA are quoted in some scripts and not quoted in other scripts. Since it's best practice to use quotes, we should update the scripts without quotes around these variables.</description>
      <version>2.0.16,2.1.7,2.2.0rc2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.bin.sstableofflinerelevel</file>
      <file type="M">tools.bin.sstablemetadata</file>
      <file type="M">tools.bin.sstablelevelreset</file>
      <file type="M">tools.bin.cassandra-stressd</file>
      <file type="M">tools.bin.cassandra-stress</file>
      <file type="M">examples.hadoop.word.count.bin.word.count.setup</file>
      <file type="M">examples.hadoop.word.count.bin.word.count.counters</file>
      <file type="M">examples.hadoop.word.count.bin.word.count</file>
      <file type="M">examples.hadoop.cql3.word.count.bin.word.count.setup</file>
      <file type="M">examples.hadoop.cql3.word.count.bin.word.count.counters</file>
      <file type="M">examples.hadoop.cql3.word.count.bin.word.count</file>
      <file type="M">examples.client.only.bin.client.only</file>
      <file type="M">bin.sstableupgrade</file>
      <file type="M">bin.sstablesplit</file>
      <file type="M">bin.cassandra</file>
    </fixedFiles>
  </bug>
  <bug id="9565" opendate="2015-6-8 00:00:00" fixdate="2015-6-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>&amp;#39;WITH WITH&amp;#39; in alter keyspace statements causes NPE</summary>
      <description>Running any of these statements:ALTER KEYSPACE WITH WITH DURABLE_WRITES = true;ALTER KEYSPACE ks WITH WITH DURABLE_WRITES = true;CREATE KEYSPACE WITH WITH DURABLE_WRITES = true;CREATE KEYSPACE ks WITH WITH DURABLE_WRITES = true;Fails, raising a SyntaxException and giving a NullPointerException as the reason for failure. This happens in all versions I tried, including 2.0.15, 2.1.5, and HEAD on cassandra-2.0, cassandra-2.1, cassandra-2.2, and trunk.EDIT: A dtest is here, but it would probably be more appropriate to test with unit tests.</description>
      <version>2.0.17,2.1.7,2.2.0rc2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.Cql.g</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9569" opendate="2015-6-9 00:00:00" fixdate="2015-6-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>nodetool should exit with status code != 0 if NodeProbe fails</summary>
      <description>in 2.0 we exit with status code &gt; 0 if NodeProbe.failed is set, in 2.1+ we ignore it.Also, dtest (or, ccm) ignore the exit code of nodetool.</description>
      <version>2.1.7,2.2.0rc2,3.0alpha1</version>
      <fixedVersion>Tool/nodetool</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeTool.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9572" opendate="2015-6-10 00:00:00" fixdate="2015-6-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>DateTieredCompactionStrategy fails to combine SSTables correctly when TTL is used.</summary>
      <description>DateTieredCompaction works correctly when data is dumped for a certain time period in short SSTables in time manner and then compacted together. However, if TTL is applied to the data columns the DTCS fails to compact files correctly in timely manner. In our opinion the problem is caused by two issues:A) During the DateTieredCompaction process the getFullyExpiredSStables is called twice. First from the DateTieredCompactionStrategy class and second time from the CompactionTask class. On the first time the target is to find out fully expired SStables that are not overlapping with any non-fully expired SSTables. That works correctly. When the getFullyExpiredSSTables is called second time from CompactionTask class the selection of fully expired SSTables is modified compared to the first selection.B) The minimum timestamp of the new SSTables created by combining together fully expired SSTable and files from the most interesting bucket is not correct.These two issues together cause problems for the DTCS process when it combines together SSTables having overlap in time and TTL for the column. This is demonstrated by generating test data first without compactions and showing the timely distribution of files. When the compaction is enabled the DCTS combines files together, but the end result is not something to be expected. This is demonstrated in the file motivation_jira.txtAttachments contain following material: Motivation_jira.txt: Practical examples how the DTCS behaves with TTL Explanation_jira.txt: gives more details, explains test cases and demonstrates the problems in the compaction process Logfile file for the compactions in the first test case (compaction_stage_test01_jira.log) Logfile file for the compactions in the seconnd test case (compaction_stage_test02_jira.log) source code zip file for version 2.1.5 with additional comment statements (src_2.1.5_with_debug.zip) Python script to generate test data (datagen.py) Python script to read metadata from SStables (cassandra_sstable_metadata_reader.py) Python script to generate timeline representation of SSTables (cassandra_sstable_timespan_graph.py)</description>
      <version>2.0.16,2.1.7,2.2.0rc2,3.0alpha1</version>
      <fixedVersion>Local/Compaction</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionController.java</file>
    </fixedFiles>
  </bug>
  <bug id="9592" opendate="2015-6-12 00:00:00" fixdate="2015-6-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>`Periodically attempt to submit background compaction tasks</summary>
      <description>There's more race conditions affecting compaction task submission than CASSANDRA-7745, so to prevent some of these problems stalling compactions, I propose simply submitting background compactions once every minute, if possible. This will typically be a no-op, but there's no harm in that, since it's very cheap to do.</description>
      <version>2.1.7</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.CassandraDaemon.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>
