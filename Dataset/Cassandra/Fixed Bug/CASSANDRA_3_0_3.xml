<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="CASSANDRA">
  <bug id="10025" opendate="2015-8-8 00:00:00" fixdate="2015-1-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow compaction throttle to be real time</summary>
      <description>We should allow compaction throttle to be set while compaction is going on. Currently, it takes effect on the next compaction. This is bad for large compactions.</description>
      <version>2.2.5,3.0.3,3.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10140" opendate="2015-8-20 00:00:00" fixdate="2015-1-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable GC logging by default</summary>
      <description>Overhead for the gc logging is very small (with cycling logs in 7+) and it provides a ton of useful information. This will open up more for C* diagnostic tools to provide feedback as well without requiring restarts.</description>
      <version>2.2.5,3.0.3,3.3</version>
      <fixedVersion>Local/Config</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">NEWS.txt</file>
      <file type="M">debian.patches.002cassandra.logdir.fix.dpatch</file>
      <file type="M">conf.jvm.options</file>
      <file type="M">conf.cassandra-env.sh</file>
      <file type="M">conf.cassandra-env.ps1</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10653" opendate="2015-11-4 00:00:00" fixdate="2015-12-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove dependency on jgrapht for UDT resolution</summary>
      <description>Now that the java-driver no longer pulls it as a dependency, it is silly to pull a whole library for resolving UDTs dependencies.Should rewrite the resolution code without jgrapht (maybe reuse whatever code java-driver ended up writing).</description>
      <version>3.0.3,3.2</version>
      <fixedVersion>Legacy/DistributedMetadata</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.schema.Types.java</file>
      <file type="M">NOTICE.txt</file>
      <file type="M">lib.licenses.jgrapht-core-0.9.1.txt</file>
      <file type="M">lib.jgrapht-core-0.9.1.jar</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="10701" opendate="2015-11-13 00:00:00" fixdate="2015-12-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>stop referring to batches as atomic</summary>
      <description>We still refer to logged batches as atomic, we should remove those references.</description>
      <version>2.1.13,2.2.5,3.0.3,3.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">doc.cql3.CQL.textile</file>
    </fixedFiles>
  </bug>
  <bug id="10743" opendate="2015-11-20 00:00:00" fixdate="2015-1-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Failed upgradesstables (upgrade from 2.2.2 to 3.0.0)</summary>
      <description>[cassandra@dc01-rack01-cass01 ~]$ /home/cassandra/dsc-cassandra-3.0.0/bin/nodetool upgradesstableserror: null-- StackTrace --java.lang.UnsupportedOperationException at org.apache.cassandra.db.rows.CellPath$EmptyCellPath.get(CellPath.java:143) at org.apache.cassandra.db.marshal.CollectionType$CollectionPathSerializer.serializedSize(CollectionType.java:226) at org.apache.cassandra.db.rows.BufferCell$Serializer.serializedSize(BufferCell.java:325) at org.apache.cassandra.db.rows.UnfilteredSerializer.sizeOfComplexColumn(UnfilteredSerializer.java:297) at org.apache.cassandra.db.rows.UnfilteredSerializer.serializedRowBodySize(UnfilteredSerializer.java:282) at org.apache.cassandra.db.rows.UnfilteredSerializer.serialize(UnfilteredSerializer.java:163) at org.apache.cassandra.db.rows.UnfilteredSerializer.serialize(UnfilteredSerializer.java:108) at org.apache.cassandra.db.ColumnIndex$Builder.add(ColumnIndex.java:144) at org.apache.cassandra.db.ColumnIndex$Builder.build(ColumnIndex.java:112) at org.apache.cassandra.db.ColumnIndex.writeAndBuildIndex(ColumnIndex.java:52) at org.apache.cassandra.io.sstable.format.big.BigTableWriter.append(BigTableWriter.java:149) at org.apache.cassandra.io.sstable.SSTableRewriter.append(SSTableRewriter.java:121) at org.apache.cassandra.db.compaction.writers.DefaultCompactionWriter.realAppend(DefaultCompactionWriter.java:57) at org.apache.cassandra.db.compaction.writers.CompactionAwareWriter.append(CompactionAwareWriter.java:110) at org.apache.cassandra.db.compaction.CompactionTask.runMayThrow(CompactionTask.java:182) at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) at org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:78) at org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:60) at org.apache.cassandra.db.compaction.CompactionManager$5.execute(CompactionManager.java:397) at org.apache.cassandra.db.compaction.CompactionManager$2.call(CompactionManager.java:292) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745)</description>
      <version>3.0.3,3.3</version>
      <fixedVersion>Legacy/LocalWrite-ReadPaths</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.rows.BTreeRow.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10762" opendate="2015-11-23 00:00:00" fixdate="2015-2-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>select_distinct_with_deletions_test failing in mixed version cluster</summary>
      <description>The dtests upgrade_tests.cql_tests.TestCQLNodes3RF3.select_distinct_with_deletions_test and upgrade_tests.cql_tests.TestCQLNodes2RF1.select_distinct_with_deletions_test are failing. While in a mixed node state, they do 'SELECT DISTINCT k FROM t1' on this tableCREATE TABLE t1 (k int PRIMARY KEY, c int, v int)More rows than expected are returned. Here is the sample output of one of those queries. As you can see, there are duplicate values of k returned in a DISTINCT k query. Seems like a bug when communicating between the 2.2 and 3.0 node.[Row(k=5), Row(k=1), Row(k=1), Row(k=8), Row(k=8), Row(k=2), Row(k=2), Row(k=4), Row(k=4), Row(k=7), Row(k=7), Row(k=6), Row(k=6), Row(k=9), Row(k=9), Row(k=3), Row(k=3)]</description>
      <version>3.0.3,3.3</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.service.DataResolverTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.SinglePartitionSliceCommandTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.rows.DigestBackwardCompatibilityTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.ReadResponseTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.PartitionTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cache.CacheProviderTest.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.service.DigestResolver.java</file>
      <file type="M">src.java.org.apache.cassandra.service.DataResolver.java</file>
      <file type="M">src.java.org.apache.cassandra.repair.Validator.java</file>
      <file type="M">src.java.org.apache.cassandra.db.rows.UnfilteredRowIterators.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ReadResponse.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ReadCommandVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ReadCommand.java</file>
      <file type="M">src.java.org.apache.cassandra.db.partitions.UnfilteredPartitionIterators.java</file>
      <file type="M">src.java.org.apache.cassandra.db.partitions.PartitionUpdate.java</file>
      <file type="M">src.java.org.apache.cassandra.db.LegacyLayout.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.DataLimits.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10797" opendate="2015-12-2 00:00:00" fixdate="2015-12-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bootstrap new node fails with OOM when streaming nodes contains thousands of sstables</summary>
      <description>When adding a new node to an existing DC, it runs OOM after 25-45 minutesUpon heapdump revision, it is found the sending nodes are streaming thousands of sstables which in turns blows the bootstrapping node heap ERROR [RMI Scheduler(0)] 2015-11-24 10:10:44,585 JVMStabilityInspector.java:94 - JVM state determined to be unstable. Exiting forcefully due to:java.lang.OutOfMemoryError: Java heap spaceERROR [STREAM-IN-/173.36.28.148] 2015-11-24 10:10:44,585 StreamSession.java:502 - [Stream #0bb13f50-92cb-11e5-bc8d-f53b7528ffb4] Streaming error occurredjava.lang.IllegalStateException: Shutdown in progress at java.lang.ApplicationShutdownHooks.remove(ApplicationShutdownHooks.java:82) ~[na:1.8.0_65] at java.lang.Runtime.removeShutdownHook(Runtime.java:239) ~[na:1.8.0_65] at org.apache.cassandra.service.StorageService.removeShutdownHook(StorageService.java:747) ~[cassandra-all-2.1.8.621.jar:2.1.8.621] at org.apache.cassandra.utils.JVMStabilityInspector$Killer.killCurrentJVM(JVMStabilityInspector.java:95) ~[cassandra-all-2.1.8.621.jar:2.1.8.621] at org.apache.cassandra.utils.JVMStabilityInspector.inspectThrowable(JVMStabilityInspector.java:64) ~[cassandra-all-2.1.8.621.jar:2.1.8.621] at org.apache.cassandra.streaming.messages.IncomingFileMessage$1.deserialize(IncomingFileMessage.java:66) ~[cassandra-all-2.1.8.621.jar:2.1.8.621] at org.apache.cassandra.streaming.messages.IncomingFileMessage$1.deserialize(IncomingFileMessage.java:38) ~[cassandra-all-2.1.8.621.jar:2.1.8.621] at org.apache.cassandra.streaming.messages.StreamMessage.deserialize(StreamMessage.java:55) ~[cassandra-all-2.1.8.621.jar:2.1.8.621] at org.apache.cassandra.streaming.ConnectionHandler$IncomingMessageHandler.run(ConnectionHandler.java:250) ~[cassandra-all-2.1.8.621.jar:2.1.8.621] at java.lang.Thread.run(Thread.java:745) [na:1.8.0_65]ERROR [RMI TCP Connection(idle)] 2015-11-24 10:10:44,585 JVMStabilityInspector.java:94 - JVM state determined to be unstable. Exiting forcefully due to:java.lang.OutOfMemoryError: Java heap spaceERROR [OptionalTasks:1] 2015-11-24 10:10:44,585 CassandraDaemon.java:223 - Exception in thread Thread[OptionalTasks:1,5,main]java.lang.IllegalStateException: Shutdown in progressAttached is the Eclipse MAT report as a zipped web page</description>
      <version>3.0.3,3.2</version>
      <fixedVersion>Legacy/StreamingandMessaging</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.io.sstable.SSTableRewriterTest.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamReceiveTask.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10806" opendate="2015-12-2 00:00:00" fixdate="2015-12-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>sstableloader can&amp;#39;t handle upper case keyspace</summary>
      <description>sstableloader can't handle upper case keyspace. The following shows the endpoint is missingcassandra/bin/sstableloader /var/folders/zz/zyxvpxvq6csfxvn_n0000000000000/T/bulk-write-to-Test1-Words-a9343a5f-62f3-4901-a9c8-ab7dc42a458e/Test1/Words-5 -d 127.0.0.1objc[7818]: Class JavaLaunchHelper is implemented in both /Library/Java/JavaVirtualMachines/jdk1.8.0_66.jdk/Contents/Home/bin/java and /Library/Java/JavaVirtualMachines/jdk1.8.0_66.jdk/Contents/Home/jre/lib/libinstrument.dylib. One of the two will be used. Which one is undefined.Established connection to initial hostsOpening sstables and calculating sections to streamStreaming relevant part of /var/folders/zz/zyxvpxvq6csfxvn_n0000000000000/T/bulk-write-to-Test1-Words-a9343a5f-62f3-4901-a9c8-ab7dc42a458e/Test1/Words-5/ma-1-big-Data.db to []Summary statistics: Connections per host: : 1 Total files transferred: : 0 Total bytes transferred: : 0 Total duration (ms): : 923 Average transfer rate (MB/s): : 0 Peak transfer rate (MB/s): : 0</description>
      <version>3.0.3,3.2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.cassandra.utils.NativeSSTableLoaderClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="10817" opendate="2015-12-4 00:00:00" fixdate="2015-1-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>DROP USER is not case-sensitive</summary>
      <description>As per the summary DROP USER is not case sensitive, so:CREATE USER 'Test';LIST USERS; name | super-----------+------- Test | False cassandra | TrueDROP USER 'Test';InvalidRequest: code=2200 [Invalid query] message="test doesn't exist"DROP ROLE is case-sensitive and will drop the above user.</description>
      <version>2.2.5,3.0.3,3.3</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.cassandra.cql3.Cql.g</file>
    </fixedFiles>
  </bug>
  <bug id="10837" opendate="2015-12-10 00:00:00" fixdate="2015-12-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cluster/session should be closed in Cassandra Hadoop Input/Output classes</summary>
      <description>See a lot of following warnings during Hadoop job runningERROR 11:37:45 LEAK: You are creating too many HashedWheelTimer instances. HashedWheelTimer is a shared resource that must be reused across the JVM,so that only a few instances are created.Each cluster/session needs be closed and a shared HashedWheelTimer may reduce the resource leakage.</description>
      <version>3.0.3,3.2</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.hadoop.cql3.CqlRecordWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.hadoop.cql3.CqlInputFormat.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10847" opendate="2015-12-11 00:00:00" fixdate="2015-1-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Log a message when refusing a major compaction due to incremental repairedAt status</summary>
      <description>When you do a major compaction, but have some repaired sstables and some that are not, it will correctly not compact them together. However, it can be somewhat confusing the operator as to why they aren't compacting together. It would be beneficial, specifically when doing a major, to log that we aren't going to do a full major because of this.</description>
      <version>2.1.13,2.2.5,3.0.3,3.3</version>
      <fixedVersion>Local/Compaction</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10854" opendate="2015-12-13 00:00:00" fixdate="2015-12-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh COPY FROM csv having line with more than one consecutive &amp;#39;,&amp;#39; delimiter is throwing &amp;#39;list index out of range&amp;#39;</summary>
      <description>cqlsh COPY FROM csv having line with more than one consecutive ',' delimiter is throwing 'list index out of range'Steps to re-produce:CREATE TABLE tracks_by_album ( album_title TEXT, album_year INT, performer TEXT STATIC, album_genre TEXT STATIC, track_number INT, track_title TEXT, PRIMARY KEY ((album_title, album_year), track_number));Create a file: tracks_by_album.csv having following 2 lines :album,year,performer,genre,number,titlea,2015,b c d,e f g,,cqlsh&gt; COPY music.tracks_by_album (album_title, album_year, performer, album_genre, track_number, track_title)FROM '~/tracks_by_album.csv'WITH HEADER = 'true';Error :Starting copy of music.tracks_by_album with columns ['album_title', 'album_year', 'performer', 'album_genre', 'track_number', 'track_title'].list index out of rangeAborting import at record #1. Previously inserted records are still present, and some records after that may be present as well.</description>
      <version>2.1.13,2.2.5,3.0.3,3.2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.copyutil.py</file>
    </fixedFiles>
  </bug>
  <bug id="10880" opendate="2015-12-16 00:00:00" fixdate="2015-1-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Paging state between 2.2 and 3.0 are incompatible on protocol v4</summary>
      <description>In CASSANDRA-10254, the paging states generated by 3.0 for the native protocol v4 were made 3.0 specific. This was done because the paging state in pre-3.0 versions contains a serialized cell name, but 3.0 doesn't talk in term of cells internally (at least not the pre-3.0 ones) and so using an old-format cell name when we only have 3.0 nodes is inefficient and inelegant.Unfortunately that change was made on the assumption than the protocol v4 was 3.0 only but it's not, it ended up being released with 2.2 and that completely slipped my mind. So in practice, you can't properly have a mixed 2.2/3.0 cluster if your driver is using the protocol v4.And unfortunately, I don't think there is an easy way to fix that without breaking something. Concretely, I can see 3 choices: we change 3.0 so that it generates old-format paging states on the v4 protocol. The 2 main downsides are that 1) this breaks 3.0 upgrades if the driver is using the v4 protocol, and at least on the java side the only driver versions that support 3.0 will use v4 by default and 2) we're signing off on having sub-optimal paging state until the protocol v5 ships (probably not too soon). we remove the v4 protocol from 2.2. This means 2.2 will have to use v3 before upgrade at the risk of breaking upgrade. This is also bad, but I'm not sure the driver version using the v4 protocol are quite ready yet (at least the java driver is not GA yet) so if we work with the drivers teams to make sure the v3 protocol gets prefered by default on 2.2 in the GA versions of these driver, this might be somewhat transparent to users. we don't change anything code-wise, but we document clearly that you can't upgrade from 2.2 to 3.0 if your clients use protocol v4 (so we leave upgrade broken if the v4 protocol is used as it is currently). This is not great, but we can work with the drivers teams here again to make sure drivers prefer the v3 version for 2.2 nodes so most people don't notice in practice.I think I'm leaning towards solution 3). It's not great but at least we break no minor upgrades (neither on 2.2, nor on 3.0) which is probably the most important. We'd basically be just adding a new condition on 2.2-&gt;3.0 upgrades. We could additionally make 3.0 node completely refuse v4 connections if they know a 2.2 nodes is in the cluster for extra safety.Ping omichallat, adutra and aholmber as you might want to be aware of that ticket.</description>
      <version>3.0.3,3.2</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">NEWS.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10902" opendate="2015-12-17 00:00:00" fixdate="2015-1-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Skip saved cache directory when checking SSTables at startup</summary>
      <description>The SSTable StartupCheck looks for all files which end with "*.db" and compares the version. This causes problems if saved_cache_directory is a subdirectory of a data_file_directories. We should make sure that we are not checking any subdirectory where we might be writing *.db files.This is the cause of not being able to restart in CASSANDRA-10821.</description>
      <version>2.2.5,3.0.3,3.3</version>
      <fixedVersion>Local/Config</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StartupChecks.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10910" opendate="2015-12-21 00:00:00" fixdate="2015-2-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Materialized view remained rows</summary>
      <description>I've created a table and a materialized view.&gt; CREATE TABLE test (id text PRIMARY KEY, key text, value int);&gt; CREATE MATERIALIZED VIEW test_view AS SELECT * FROM test WHERE key IS NOT NULL PRIMARY KEY(key, id);I've put a value into the table:&gt; update test set key='key', value=1 where id='id';&gt; select * from test; select * from test_view ; id | key | value----+-----+------- id | key | 1(1 rows) key | id | value-----+----+------- key | id | 1(1 rows)I've updated the value without specified the key of the materialized view:&gt; update test set value=2 where id='id';&gt; select * from test; select * from test_view ; id | key | value----+-----+------- id | key | 2(1 rows) key | id | value-----+----+------- key | id | 2(1 rows)It works as I think......but I've updated the key of the materialized view:&gt; update test set key='newKey' where id='id';&gt; select * from test; select * from test_view ; id | key | value----+--------+------- id | newKey | 2(1 rows) key | id | value--------+----+------- key | id | 2 newKey | id | 2(2 rows)...I've updated the value of the row:&gt; update test set key='newKey', value=3 where id='id';&gt; select * from test; select * from test_view ; id | key | value----+--------+------- id | newKey | 3(1 rows) key | id | value--------+----+------- key | id | 2 newKey | id | 3(2 rows)...I've deleted the row by the id key:&gt; delete from test where id='id';&gt; select * from test; select * from test_view ; id | key | value----+-----+-------(0 rows) key | id | value-----+----+------- key | id | 2(1 rows)Is it a bug?</description>
      <version>3.0.3,3.3</version>
      <fixedVersion>Feature/MaterializedViews,Legacy/Coordination</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.ViewTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.view.TemporalRow.java</file>
    </fixedFiles>
  </bug>
  <bug id="10938" opendate="2015-12-24 00:00:00" fixdate="2015-2-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>test_bulk_round_trip_blogposts is failing occasionally</summary>
      <description>We get timeouts occasionally that cause the number of records to be incorrect:http://cassci.datastax.com/job/trunk_dtest/858/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_bulk_round_trip_blogposts/</description>
      <version>2.1.13,2.2.5,3.0.3,3.3</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.transport.ServerConnection.java</file>
      <file type="M">pylib.cqlshlib.copyutil.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10942" opendate="2015-12-25 00:00:00" fixdate="2015-12-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>guard against npe if no thrift supercolumn data</summary>
      <description></description>
      <version>3.0.3</version>
      <fixedVersion>Legacy/LocalWrite-ReadPaths</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.thrift.ThriftResultsMerger.java</file>
    </fixedFiles>
  </bug>
  <bug id="10946" opendate="2015-12-28 00:00:00" fixdate="2015-12-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>jemalloc detection fails due to quoting issues in regex</summary>
      <description>When creating the list of paths where to search for jemalloc, we parse ldconfig output to get more directories. The current pattern used to filter out indented rows from ldconfig does not work because of quoting issues of the involved dollar sign.I found just changing the regex to '^\s' works and seems less error prone.</description>
      <version>None</version>
      <fixedVersion>Legacy/Tools,Local/Config</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cassandra</file>
    </fixedFiles>
  </bug>
  <bug id="10949" opendate="2015-12-29 00:00:00" fixdate="2015-12-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>SSTableMultiWriter streaming bug</summary>
      <description>SSTableMultiWriter can create several sstables, if we do create more than one during streaming, the streaming operation will hang</description>
      <version>3.0.3,3.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamReceiveTask.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10955" opendate="2015-12-30 00:00:00" fixdate="2015-1-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Multi-partitions queries with ORDER BY can result in a NPE</summary>
      <description>In the case of a table with static columns, if only the static columns have been set for some partitions, a multi-partitions query with an ORDER BY can cause a NPE.The following unit test can be used to reproduce the problem: @Test public void testOrderByForInClauseWithNullValue() throws Throwable { createTable("CREATE TABLE %s (a int, b int, c int, s int static, d int, PRIMARY KEY (a, b, c))"); execute("INSERT INTO %s (a, b, c, d) VALUES (1, 1, 1, 1)"); execute("INSERT INTO %s (a, b, c, d) VALUES (1, 1, 2, 1)"); execute("INSERT INTO %s (a, b, c, d) VALUES (2, 2, 1, 1)"); execute("INSERT INTO %s (a, b, c, d) VALUES (2, 2, 2, 1)"); execute("UPDATE %s SET s = 1 WHERE a = 1"); execute("UPDATE %s SET s = 2 WHERE a = 2"); execute("UPDATE %s SET s = 3 WHERE a = 3"); assertRows(execute("SELECT a, b, c, d, s FROM %s WHERE a IN (1, 2, 3) ORDER BY b DESC"), row(2, 2, 2, 1, 2), row(2, 2, 1, 1, 2), row(1, 1, 2, 1, 1), row(1, 1, 1, 1, 1), row(3, null, null, null, 3)); }</description>
      <version>2.2.5,3.0.3,3.3</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.SelectOrderByTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10975" opendate="2016-1-6 00:00:00" fixdate="2016-1-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Histogram buckets exposed in jmx are sorted by count</summary>
      <description>The estimated histogram snapshot lets its parent provide the getValues implementation which sorts the bucket array:https://github.com/dropwizard/metrics/blob/3.1-maintenance/metrics-core/src/main/java/com/codahale/metrics/UniformSnapshot.java#L25making it hard to determine what count belonged to what bucket. Along with removal of the pre 2.2 deprecated metrics this makes it nearly impossible to track latencies over time.</description>
      <version>2.2.5,3.0.3,3.3</version>
      <fixedVersion>Legacy/Observability</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.metrics.EstimatedHistogramReservoir.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10980" opendate="2016-1-7 00:00:00" fixdate="2016-1-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>nodetool scrub NPEs when keyspace isn&amp;#39;t specified</summary>
      <description>I've attached logs of what I saw. Running nodetool scrub without anything else specified resulted in the NPE. Running with the keyspace specified saw successful termination.</description>
      <version>2.2.5,3.0.3,3.3</version>
      <fixedVersion>Local/Compaction,Tool/nodetool</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11026" opendate="2016-1-18 00:00:00" fixdate="2016-2-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>OOM due to HeapByteBuffer instances</summary>
      <description>Cassandra 3.0.2 fails with OOM. The heapdump shows large number of HeapByteBuffer instances, each retaining 1Mb (see the details on the screenshot). Overall retained size is ~2Gb.We can provide the additional info and the whole heapdump if necessary.</description>
      <version>3.0.3,3.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.sstable.metadata.MetadataCollector.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11046" opendate="2016-1-20 00:00:00" fixdate="2016-1-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Existing indexes are always rebuilt on upgrade to 3.0</summary>
      <description>CASSANDRA-10127 made the naming of secondary indexes consistent internally. Previously some places used just the index name, whilst others required the name in the format table.index. One place including the additional table name was the system.IndexInfo table, which records whether or not the index has been built. On upgrade to 3.0, as the node restarts and initialises and index, it checks this table to determine whether an initial build task is necessary. Since 10127, this check expects the row to include just the index name, but the actual row will still be in the old table.index format, causing the index manager to assume the index is not built and submit a build task.</description>
      <version>3.0.3,3.3</version>
      <fixedVersion>Legacy/DistributedMetadata</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.schema.LegacySchemaMigratorTest.java</file>
      <file type="M">src.java.org.apache.cassandra.schema.LegacySchemaMigrator.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11054" opendate="2016-1-21 00:00:00" fixdate="2016-1-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Added support for IBM zSystems architecture (s390x)</summary>
      <description>Added support for IBM zSystems architecture (s390x). These code changes are required to make few test cases 'pass' for zSystems.</description>
      <version>3.0.3,3.3,3.4</version>
      <fixedVersion>Legacy/Observability,Legacy/Testing</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.utils.FastByteOperations.java</file>
      <file type="M">src.java.org.apache.cassandra.io.util.Memory.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11087" opendate="2016-1-28 00:00:00" fixdate="2016-2-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Queries on compact storage tables in mixed version clusters can return incorrect results</summary>
      <description>Whilst writing a dtest for CASSANDRA-11045, it becomes apparent that queries on compact storage tables are broken during the 3.0 upgrade (and this has probably been the case since day 1). tl;dr In a cluster with a mix of &lt; 3.0 and 3.0 nodes, reads on COMPACT STORAGE tables may not include all results. To repro: tables are created and data written before any nodes are upgraded to 3.0+, some nodes are then upgraded putting the cluster into a mixed state.Now, when a query is run where the coordinator is a &lt; 3.0 node, any 3.0+ replica which has not yet run upgradesstables always returns 0 results. Once upgradesstables is run, the replica returns the correct results. Likewise, if the data is inserted after the node is upgraded, the results are correct. If the 3.0 node acts as the coordinator, the results are also correct and so once all nodes are upgraded, the problem goes away.The behaviour can be seen for both single partition and range requests as this dtest demonstrates.</description>
      <version>3.0.3,3.3</version>
      <fixedVersion>Legacy/Coordination</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.ReadCommand.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11102" opendate="2016-2-1 00:00:00" fixdate="2016-2-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Data lost during compaction</summary>
      <description>We have experienced data loses in some tables during few weeks since update to cassandra 3.0. I thing I successfully found test case now. Step one - test table:CREATE TABLE aaa ( r int, c1 int, c2 ascii, PRIMARY KEY (r, c1, c2));Step two - run few queries: insert into aaa (r, c1, c2) values (1,2,'A'); delete from aaa where r=1 and c1=2 and c2='B'; insert into aaa (r, c1, c2) values (2,3,'A'); delete from aaa where r=2 and c1=3 and c2='B'; insert into aaa (r, c1, c2) values (3,4,'A'); delete from aaa where r=3 and c1=4 and c2='B'; insert into aaa (r, c1, c2) values (4,5,'A'); delete from aaa where r=4 and c1=5 and c2='B';It creates 4 rows (select count says 4) and 4 tombstones.Step 3 - Restart CassandraYou will see new files written into C* data folder. I tried sstable-tools to print table structure, it shows 4 rows, data and tombstones are there.Step 4 - set GC grace to 1 to force tombstone removing during compaction.alter table aaa with GC_GRACE_SECONDS = 1;Step 5 - Compact tables./nodetool compactaaa files dissapeares during compaction. select count says 0compaction history says... aaa 2016-02-01T14:24:01.433 329 0 {}</description>
      <version>3.0.3,3.3</version>
      <fixedVersion>Local/Compaction</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.compaction.TTLExpiryTest.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.metadata.MetadataCollector.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.DeleteTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="7925" opendate="2014-9-13 00:00:00" fixdate="2014-1-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TimeUUID LSB should be unique per process, not just per machine</summary>
      <description>as pointed out in CASSANDRA-7919 lsb collisions are also possible serverside.a sufficient solution would be to include references to pid and classloader within lsb.</description>
      <version>2.2.5,3.0.3,3.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.utils.UUIDGen.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.SigarLibrary.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StartupChecks.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9179" opendate="2015-4-13 00:00:00" fixdate="2015-12-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unable to "point in time" restore if table/cf has been recreated</summary>
      <description>With Cassandra 2.1, and the addition of the CF UUID, the ability to do a "point in time" restore by restoring a snapshot and replaying commitlogs is lost if the table has been dropped and recreated.When the table is recreated, the cf_id changes, and the commitlog replay mechanism skips the desired mutations as the cf_id no longer matches what's present in the schema.There should exist a way to inform the replay that you want the mutations replayed even if the cf_id doesn't match.</description>
      <version>2.1.13,2.2.5,3.0.3,3.2</version>
      <fixedVersion>Legacy/CQL,Legacy/DistributedMetadata</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateTableStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CFPropDefs.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.AlterTableStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9294" opendate="2015-5-4 00:00:00" fixdate="2015-12-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Streaming errors should log the root cause</summary>
      <description>Currently, when a streaming error occurs all you get is something like:java.util.concurrent.ExecutionException: org.apache.cassandra.streaming.StreamException: Stream failedInstead, we should log the root cause. Was the connection reset by peer, did it timeout, etc?</description>
      <version>2.1.13,2.2.5,3.0.3,3.2</version>
      <fixedVersion>Legacy/StreamingandMessaging</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamSession.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9302" opendate="2015-5-5 00:00:00" fixdate="2015-12-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Optimize cqlsh COPY FROM, part 3</summary>
      <description>We've had some discussion moving to Spark CSV import for bulk load in 3.x, but people need a good bulk load tool now. One option is to add a separate Java bulk load tool (CASSANDRA-9048), but if we can match that performance from cqlsh I would prefer to leave COPY FROM as the preferred option to which we point people, rather than adding more tools that need to be supported indefinitely.Previous work on COPY FROM optimization was done in CASSANDRA-7405 and CASSANDRA-8225.</description>
      <version>2.1.13,2.2.5,3.0.3,3.2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.util.py</file>
      <file type="M">pylib.cqlshlib.copyutil.py</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug id="9303" opendate="2015-5-5 00:00:00" fixdate="2015-1-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Match cassandra-loader options in COPY FROM</summary>
      <description>https://github.com/brianmhess/cassandra-loader added a bunch of options to handle real world requirements, we should match those.</description>
      <version>2.1.13,2.2.5,3.0.3,3.2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.service.ClientWarningsTest.java</file>
      <file type="M">bin.cqlsh.py</file>
      <file type="M">tools.bin.cassandra-stress.bat</file>
      <file type="M">src.java.org.apache.cassandra.transport.ServerConnection.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.BatchStatement.java</file>
      <file type="M">pylib.cqlshlib.formatting.py</file>
      <file type="M">pylib.cqlshlib.copyutil.py</file>
      <file type="M">NEWS.txt</file>
      <file type="M">conf.cqlshrc.sample</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug id="9428" opendate="2015-5-19 00:00:00" fixdate="2015-12-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement hints compression</summary>
      <description>CASSANDRA-6230 is being implemented with compression in mind, but it's not going to be implemented by the original ticket.Adding it on top should be relatively straight-forward, and important, since there are several users in the wild that use compression interface for encryption purposes. DSE is one of them (but isn't the only one). Losing encryption capabilities would be a regression.</description>
      <version>3.0.3,3.2</version>
      <fixedVersion>Legacy/Coordination</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.hints.LegacyHintsMigratorTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.hints.HintsCatalogTest.java</file>
      <file type="M">src.java.org.apache.cassandra.hints.HintsWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.hints.HintsWriteExecutor.java</file>
      <file type="M">src.java.org.apache.cassandra.hints.HintsStore.java</file>
      <file type="M">src.java.org.apache.cassandra.hints.HintsService.java</file>
      <file type="M">src.java.org.apache.cassandra.hints.HintsReader.java</file>
      <file type="M">src.java.org.apache.cassandra.hints.HintsDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.hints.HintsCatalog.java</file>
      <file type="M">src.java.org.apache.cassandra.hints.ChecksummedDataInput.java</file>
      <file type="M">src.java.org.apache.cassandra.config.ParameterizedClass.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9465" opendate="2015-5-22 00:00:00" fixdate="2015-1-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>No client warning on tombstone threshold</summary>
      <description>It appears that a client warning is not coming back for the tombstone threshold case. The batch warning works.Repro:Create a data condition with tombstone_warn_threshold &lt; tombstones &lt; tombstone_failure_thresholdQuery the rowExpected:Warning in server log, warning returned to clientI'm basing this expectation on what I see hereObserved:Warning in server log, no warning flag in response message.</description>
      <version>2.2.5,3.0.3,3.3</version>
      <fixedVersion>Legacy/Observability</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.service.ClientWarningsTest.java</file>
      <file type="M">src.java.org.apache.cassandra.transport.RequestThreadPoolExecutor.java</file>
      <file type="M">src.java.org.apache.cassandra.transport.Message.java</file>
      <file type="M">src.java.org.apache.cassandra.tracing.Tracing.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.service.ClientWarn.java</file>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.SliceQueryFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.BatchStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.concurrent.TracingAwareExecutorService.java</file>
      <file type="M">src.java.org.apache.cassandra.concurrent.StageManager.java</file>
      <file type="M">src.java.org.apache.cassandra.concurrent.SharedExecutorPool.java</file>
      <file type="M">src.java.org.apache.cassandra.concurrent.SEPExecutor.java</file>
      <file type="M">src.java.org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.java</file>
      <file type="M">src.java.org.apache.cassandra.concurrent.AbstractTracingAwareExecutorService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9556" opendate="2015-6-5 00:00:00" fixdate="2015-12-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add newer data types to cassandra stress</summary>
      <description>Currently you can't define a data model with decimal types and use Cassandra stress with it. Also, I imagine that holds true with other newer data types such as the new date and time types. Besides that, now that data models are including user defined types, we should allow users to create those structures with stress as well. Perhaps we could split out the UDTs into a different ticket if it holds the other types up.</description>
      <version>2.2.5,3.0.3</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.util.JavaDriverClient.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.StressProfile.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.operations.userdefined.SchemaStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9949" opendate="2015-7-31 00:00:00" fixdate="2015-1-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>maxPurgeableTimestamp needs to check memtables too</summary>
      <description>overlapIterator/maxPurgeableTimestamp don't include the memtables, so a very-out-of-order write could be ignored</description>
      <version>2.2.5,3.0.3,3.3</version>
      <fixedVersion>Legacy/LocalWrite-ReadPaths</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.Memtable.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LazilyCompactedRow.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionController.java</file>
      <file type="M">src.java.org.apache.cassandra.db.AtomicBTreeColumns.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9977" opendate="2015-8-4 00:00:00" fixdate="2015-1-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support counter-columns for native aggregates (sum,avg,max,min)</summary>
      <description>When trying to SUM a column of type COUNTER, this error is returned:InvalidRequest: code=2200 [Invalid query] message="Invalid call to function sum, none of its type signatures match (known type signatures: system.sum : (tinyint) -&gt; tinyint, system.sum : (smallint) -&gt; smallint, system.sum : (int) -&gt; int, system.sum : (bigint) -&gt; bigint, system.sum : (float) -&gt; float, system.sum : (double) -&gt; double, system.sum : (decimal) -&gt; decimal, system.sum : (varint) -&gt; varint)"This might be relevant for other agg. functions.CQL for reproduction:CREATE TABLE test ( key INT, ctr COUNTER, PRIMARY KEY ( key ));UPDATE test SET ctr = ctr + 1 WHERE key = 1;SELECT SUM(ctr) FROM test;</description>
      <version>2.2.5,3.0.3</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.AggregationTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.UFTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.functions.Functions.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.functions.AggregateFcts.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>
