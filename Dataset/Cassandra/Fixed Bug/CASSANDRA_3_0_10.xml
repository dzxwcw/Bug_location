<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="CASSANDRA">
  <bug id="11039" opendate="2016-1-20 00:00:00" fixdate="2016-11-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>SegFault in Cassandra</summary>
      <description>This occurred under quite heavy load.Attached is the dump that was spit out by Cassandra, and my cassandra.yamlhs_err_1453233896.log:https://s3-us-west-1.amazonaws.com/channelmeter-misc/hs_err_1453233896.logcassandra.yamlhttps://s3-us-west-1.amazonaws.com/channelmeter-misc/cassandra.yamlProcess Options:java -ea -Xms16G -Xmx16G -Xss256k -XX:+UseG1GC -XX:G1RSetUpdatingPauseTimePercent=5 -XX:MaxGCPauseMillis=500 -XX:InitiatingHeapOccupancyPercent=70 -XX:+AlwaysPreTouch -XX:-UseBiasedLocking -XX:StringTableSize=1000003 -XX:+UseTLAB -XX:+ResizeTLAB -XX:+PerfDisableSharedMem -XX:CompileCommandFile=/etc/cassandra/hotspot_compiler -javaagent:/usr/share/cassandra/lib/jamm-0.3.0.jar -XX:+UseThreadPriorities -XX:ThreadPriorityPolicy=42 -XX:+HeapDumpOnOutOfMemoryError -Djava.net.preferIPv4Stack=true -Dcassandra.jmx.local.port=7199 -XX:+DisableExplicitGC -Djava.library.path=/usr/share/cassandra/lib/sigar-bin -Dcassandra.metricsReporterConfigFile=/etc/cassandra-metrics-graphite.yaml -Dcassandra.libjemalloc=- -Dlogback.configurationFile=logback.xml -Dcassandra.logdir=/var/log/cassandra -Dcassandra.storagedir=/var/lib/cassandra -Dcassandra-pidfile=/var/run/cassandra/cassandra.pid -cp /etc/cassandra:/usr/share/cassandra/lib/ST4-4.0.8.jar:/usr/share/cassandra/lib/airline-0.6.jar:/usr/share/cassandra/lib/antlr-runtime-3.5.2.jar:/usr/share/cassandra/lib/asm-5.0.4.jar:/usr/share/cassandra/lib/cassandra-driver-core-3.0.0-beta1-bb1bce4-SNAPSHOT-shaded.jar:/usr/share/cassandra/lib/commons-cli-1.1.jar:/usr/share/cassandra/lib/commons-codec-1.2.jar:/usr/share/cassandra/lib/commons-lang3-3.1.jar:/usr/share/cassandra/lib/commons-math3-3.2.jar:/usr/share/cassandra/lib/compress-lzf-0.8.4.jar:/usr/share/cassandra/lib/concurrentlinkedhashmap-lru-1.4.jar:/usr/share/cassandra/lib/disruptor-3.0.1.jar:/usr/share/cassandra/lib/ecj-4.4.2.jar:/usr/share/cassandra/lib/guava-18.0.jar:/usr/share/cassandra/lib/high-scale-lib-1.0.6.jar:/usr/share/cassandra/lib/jackson-core-asl-1.9.2.jar:/usr/share/cassandra/lib/jackson-mapper-asl-1.9.2.jar:/usr/share/cassandra/lib/jamm-0.3.0.jar:/usr/share/cassandra/lib/javax.inject.jar:/usr/share/cassandra/lib/jbcrypt-0.3m.jar:/usr/share/cassandra/lib/jcl-over-slf4j-1.7.7.jar:/usr/share/cassandra/lib/jna-4.0.0.jar:/usr/share/cassandra/lib/joda-time-2.4.jar:/usr/share/cassandra/lib/json-simple-1.1.jar:/usr/share/cassandra/lib/libthrift-0.9.2.jar:/usr/share/cassandra/lib/log4j-over-slf4j-1.7.7.jar:/usr/share/cassandra/lib/logback-classic-1.1.3.jar:/usr/share/cassandra/lib/logback-core-1.1.3.jar:/usr/share/cassandra/lib/lz4-1.3.0.jar:/usr/share/cassandra/lib/metrics-core-3.1.0.jar:/usr/share/cassandra/lib/metrics-core-3.1.2.jar:/usr/share/cassandra/lib/metrics-graphite-2.2.0.jar:/usr/share/cassandra/lib/metrics-graphite-3.1.2.jar:/usr/share/cassandra/lib/metrics-logback-3.1.0.jar:/usr/share/cassandra/lib/netty-all-4.0.23.Final.jar:/usr/share/cassandra/lib/ohc-core-0.4.2.jar:/usr/share/cassandra/lib/ohc-core-j8-0.4.2.jar:/usr/share/cassandra/lib/reporter-config-base-3.0.0.jar:/usr/share/cassandra/lib/reporter-config3-3.0.0.jar:/usr/share/cassandra/lib/sigar-1.6.4.jar:/usr/share/cassandra/lib/slf4j-api-1.7.7.jar:/usr/share/cassandra/lib/snakeyaml-1.11.jar:/usr/share/cassandra/lib/snappy-java-1.1.1.7.jar:/usr/share/cassandra/lib/stream-2.5.2.jar:/usr/share/cassandra/lib/thrift-server-0.3.7.jar:/usr/share/cassandra/apache-cassandra-3.2.jar:/usr/share/cassandra/apache-cassandra-thrift-3.2.jar:/usr/share/cassandra/apache-cassandra.jar:/usr/share/cassandra/stress.jar: -XX:HeapDumpPath=/var/lib/cassandra/java_1453248542.hprof -XX:ErrorFile=/var/lib/cassandra/hs_err_1453248542.log org.apache.cassandra.service.CassandraDaemon</description>
      <version>3.0.10</version>
      <fixedVersion>Local/Config</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11117" opendate="2016-2-3 00:00:00" fixdate="2016-10-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ColUpdateTimeDeltaHistogram histogram overflow</summary>
      <description>getting attribute Mean of org.apache.cassandra.metrics:type=ColumnFamily,name=ColUpdateTimeDeltaHistogram threw an exceptionjavax.management.RuntimeMBeanException: java.lang.IllegalStateException: Unable to compute ceiling for max when histogram overflowedAlthough the fact that this histogram has 164 buckets already, I wonder if there is something weird with the computation thats causing this to be so large? It appears to be coming from updates to system.localorg.apache.cassandra.metrics:type=Table,keyspace=system,scope=local,name=ColUpdateTimeDeltaHistogram</description>
      <version>2.2.9,3.0.10,3.10,4.0-alpha1,4.0</version>
      <fixedVersion>Legacy/Observability</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.ColumnFamilyMetricTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11363" opendate="2016-3-16 00:00:00" fixdate="2016-9-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>High Blocked NTR When Connecting</summary>
      <description>When upgrading from 2.1.9 to 2.1.13, we are witnessing an issue where the machine load increases to very high levels (&gt; 120 on an 8 core machine) and native transport requests get blocked in tpstats.I was able to reproduce this in both CMS and G1GC as well as on JVM 7 and 8.The issue does not seem to affect the nodes running 2.1.9.The issue seems to coincide with the number of connections OR the number of total requests being processed at a given time (as the latter increases with the former in our system)Currently there is between 600 and 800 client connections on each machine and each machine is handling roughly 2000-3000 client requests per second.Disabling the binary protocol fixes the issue for this node but isn't a viable option cluster-wide.Here is the output from tpstats:Pool Name Active Pending Completed Blocked All time blockedMutationStage 0 8 8387821 0 0ReadStage 0 0 355860 0 0RequestResponseStage 0 7 2532457 0 0ReadRepairStage 0 0 150 0 0CounterMutationStage 32 104 897560 0 0MiscStage 0 0 0 0 0HintedHandoff 0 0 65 0 0GossipStage 0 0 2338 0 0CacheCleanupExecutor 0 0 0 0 0InternalResponseStage 0 0 0 0 0CommitLogArchiver 0 0 0 0 0CompactionExecutor 2 190 474 0 0ValidationExecutor 0 0 0 0 0MigrationStage 0 0 10 0 0AntiEntropyStage 0 0 0 0 0PendingRangeCalculator 0 0 310 0 0Sampler 0 0 0 0 0MemtableFlushWriter 1 10 94 0 0MemtablePostFlush 1 34 257 0 0MemtableReclaimMemory 0 0 94 0 0Native-Transport-Requests 128 156 387957 16 278451Message type DroppedREAD 0RANGE_SLICE 0_TRACE 0MUTATION 0COUNTER_MUTATION 0BINARY 0REQUEST_RESPONSE 0PAGED_RANGE 0READ_REPAIR 0Attached is the jstack output for both CMS and G1GC.Flight recordings are here:https://s3.amazonaws.com/simple-logs/cassandra-102-cms.jfrhttps://s3.amazonaws.com/simple-logs/cassandra-102-g1gc.jfrIt is interesting to note that while the flight recording was taking place, the load on the machine went back to healthy, and when the flight recording finished the load went back to &gt; 100.</description>
      <version>2.1.16,2.2.8,3.0.10,3.10</version>
      <fixedVersion>Legacy/Coordination</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.transport.RequestThreadPoolExecutor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11803" opendate="2016-5-13 00:00:00" fixdate="2016-10-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Creating a materialized view on a table with "token" column breaks the cluster</summary>
      <description>On a new Cassandra cluster, if we create a table with a field called "token" (with quotes) and then create a materialized view that uses "token", the cluster breaks. A ServerError is returned, and no further nodetool operations on the sstables work. Restarting the Cassandra server will also fail. It seems like the entire cluster is hosed.We tried this on Cassandra 3.3 and 3.5. Here's how to produce (on an new, empty cassandra 3.5 docker container):[cqlsh 5.0.1 | Cassandra 3.5 | CQL spec 3.4.0 | Native protocol v4]Use HELP for help.cqlsh&gt; CREATE KEYSPACE account WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 };cqlsh&gt; CREATE TABLE account.session ( ... "token" blob, ... account_id uuid, ... PRIMARY KEY("token") ... )WITH compaction={'class': 'LeveledCompactionStrategy'} AND ... compression={'sstable_compression': 'LZ4Compressor'};cqlsh&gt; CREATE MATERIALIZED VIEW account.account_session AS ... SELECT account_id,"token" FROM account.session ... WHERE "token" IS NOT NULL and account_id IS NOT NULL ... PRIMARY KEY (account_id, "token");ServerError: &lt;ErrorMessage code=0000 [Server error] message="java.lang.RuntimeException: java.util.concurrent.ExecutionException: org.apache.cassandra.exceptions.SyntaxException: line 1:25 no viable alternative at input 'FROM' (SELECT account_id, token [FROM]...)"&gt;cqlsh&gt; drop table account.session;ServerError: &lt;ErrorMessage code=0000 [Server error] message="java.lang.RuntimeException: java.util.concurrent.ExecutionException: org.apache.cassandra.exceptions.SyntaxException: line 1:25 no viable alternative at input 'FROM' (SELECT account_id, token [FROM]...)"&gt;When any sstable*, nodetool, or when the Cassandra process is restarted, this is emitted on startup and Cassandra exits (copied from a server w/ data):INFO [main] 2016-05-12 23:25:30,074 ColumnFamilyStore.java:395 - Initializing system_schema.indexesDEBUG [SSTableBatchOpen:1] 2016-05-12 23:25:30,075 SSTableReader.java:480 - Opening /mnt/cassandra/data/system_schema/indexes-0feb57ac311f382fba6d9024d305702f/ma-4-big (91 bytes)ERROR [main] 2016-05-12 23:25:30,143 CassandraDaemon.java:697 - Exception encountered during startuporg.apache.cassandra.exceptions.SyntaxException: line 1:59 no viable alternative at input 'FROM' (..., expire_at, last_used, token [FROM]...) at org.apache.cassandra.cql3.ErrorCollector.throwFirstSyntaxError(ErrorCollector.java:101) ~[apache-cassandra-3.5.0.jar:3.5.0] at org.apache.cassandra.cql3.CQLFragmentParser.parseAnyUnhandled(CQLFragmentParser.java:80) ~[apache-cassandra-3.5.0.jar:3.5.0] at org.apache.cassandra.cql3.QueryProcessor.parseStatement(QueryProcessor.java:512) ~[apache-cassandra-3.5.0.jar:3.5.0] at org.apache.cassandra.schema.SchemaKeyspace.fetchView(SchemaKeyspace.java:1128) ~[apache-cassandra-3.5.0.jar:3.5.0] at org.apache.cassandra.schema.SchemaKeyspace.fetchViews(SchemaKeyspace.java:1092) ~[apache-cassandra-3.5.0.jar:3.5.0] at org.apache.cassandra.schema.SchemaKeyspace.fetchKeyspace(SchemaKeyspace.java:903) ~[apache-cassandra-3.5.0.jar:3.5.0] at org.apache.cassandra.schema.SchemaKeyspace.fetchKeyspacesWithout(SchemaKeyspace.java:879) ~[apache-cassandra-3.5.0.jar:3.5.0] at org.apache.cassandra.schema.SchemaKeyspace.fetchNonSystemKeyspaces(SchemaKeyspace.java:867) ~[apache-cassandra-3.5.0.jar:3.5.0] at org.apache.cassandra.config.Schema.loadFromDisk(Schema.java:134) ~[apache-cassandra-3.5.0.jar:3.5.0] at org.apache.cassandra.config.Schema.loadFromDisk(Schema.java:124) ~[apache-cassandra-3.5.0.jar:3.5.0] at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:229) [apache-cassandra-3.5.0.jar:3.5.0] at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:551) [apache-cassandra-3.5.0.jar:3.5.0] at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:680) [apache-cassandra-3.5.0.jar:3.5.0]</description>
      <version>3.0.10,3.10,4.0-alpha1,4.0</version>
      <fixedVersion>Feature/MaterializedViews,Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.ReservedKeywords.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.ColumnFamilyStoreCQLHelperTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.ViewTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.Cql.g</file>
      <file type="M">src.java.org.apache.cassandra.cql3.ColumnIdentifier.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12060" opendate="2016-6-22 00:00:00" fixdate="2016-9-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Establish consistent distinction between non-existing partition and NULL value for LWTs on static columns</summary>
      <description>When executing following CQL commands: CREATE KEYSPACE test WITH replication = {'class': 'NetworkTopologyStrategy', 'datacenter1': '1' };USE test;CREATE TABLE testtable (a int, b int, s1 int static, s2 int static, v int, PRIMARY KEY (a, b));INSERT INTO testtable (a,b,s1,s2,v) VALUES (2,2,2,null,2);DELETE s1 FROM testtable WHERE a = 2 IF s2 IN (10,20,30);The output is different between 2.x and 3.x:2.x:cqlsh:test&gt; DELETE s1 FROM testtable WHERE a = 2 IF s2 = 5; [applied] | s2-----------+------ False | null3.x:cqlsh:test&gt; DELETE s1 FROM testtable WHERE a = 2 IF s2 = 5; [applied]----------- False2.x would although return same result if executed on a partition that does not exist at all:cqlsh:test&gt; DELETE s1 FROM testtable WHERE a = 5 IF s2 = 5; [applied]----------- FalseIt might be related to static column LWTs, as I could not reproduce same behaviour with non-static column LWTs. The most recent change was CASSANDRA-10532, which enabled LWT operations on static columns with partition keys only. Another possible relation is CASSANDRA-9842, which removed distinction between null column and non-existing row. (striked through since same happens on pre-CASSANDRA-9842 code.</description>
      <version>3.0.10,3.10</version>
      <fixedVersion>Feature/LightweightTransactions</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.InsertUpdateIfConditionTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CQL3CasRequest.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12268" opendate="2016-7-21 00:00:00" fixdate="2016-10-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make MV Index creation robust for wide referent rows</summary>
      <description>When creating an index for a materialized view for extant data, heap pressure is very dependent on the cardinality of of rows associated with each index value. With the way that per-index value rows are created within the index, this can cause unbounded heap pressure, which can cause OOM. This appears to be a side-effect of how each index row is applied atomically as with batches.The commit logs can accumulate enough during the process to prevent the node from being restarted. Given that this occurs during global index creation, this can happen on multiple nodes, making stable recovery of a node set difficult, as co-replicas become unavailable to assist in back-filling data from commitlogs.While it is understandable that you want to avoid having relatively wide rows even in materialized views, this represents a particularly difficult scenario for triage.The basic recommendation for improving this is to sub-group the index creation into smaller chunks internally, providing a maximal bound against the heap pressure when it is needed.</description>
      <version>3.0.10,3.10,4.0-alpha1,4.0</version>
      <fixedVersion>Feature/MaterializedViews,Legacy/Core</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.view.ViewUpdateGenerator.java</file>
      <file type="M">src.java.org.apache.cassandra.db.view.ViewBuilder.java</file>
      <file type="M">src.java.org.apache.cassandra.db.view.TableViews.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12296" opendate="2016-7-26 00:00:00" fixdate="2016-11-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Better error message when streaming with insufficient sources in DC</summary>
      <description>This came up in discussion of CASSANDRA-11687. nodetool rebuild was failing in a dtest. pauloricardomg explained:before CASSANDRA-11848 the local node could be considered a source, while now sources are restricted only to dc2, so since system_auth uses SimpleStrategy depending on the token arrangement there could or not be sources from dc2. Fix is to either use -Dcassandra.consistent.rangemovement=false or update system_auth to use NetworkTopologyStrategy with 2 dcs..This is, at the very least, a UX bug. When rebuild fails, it fails withnodetool: Unable to find sufficient sources for streaming range (-3287869951390391138,-1624006824486474209] in keyspace system_auth with RF=1.If you want to ignore this, consider using system property -Dcassandra.consistent.rangemovement=false.which suggests that a user should give up consistency guarantees when it's not necessary.</description>
      <version>3.0.10,3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.dht.RangeStreamer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12384" opendate="2016-8-4 00:00:00" fixdate="2016-10-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Include info about sstable on "Compacting large row” message</summary>
      <description>On a message like this one, it would be helpful to understand which sstable this large row is going inCompacting large row abc/xyz:38956kjhawf (xyz bytes) incrementally</description>
      <version>3.0.10,3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.sstable.format.big.BigTableWriter.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12417" opendate="2016-8-9 00:00:00" fixdate="2016-10-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Built-in AVG aggregate is much less useful than it should be</summary>
      <description>For fixed-size integer types overflow is all but guaranteed to happen, yielding incorrect result. While for sum it is somewhat acceptable as the result cannot fit the type, this is not the case for average.As the result of average is always within the scope of the source type, failing to produce it only signifies a bad implementation. Yes, one can solve this by type-casting, but do we really want to always have to be telling people that the correct spelling of the average function is cast(avg(cast(value as bigint))) as int), especially if this is so trivial to fix?Additionally, the straightforward addition we use for floating point versions is not a good choice numerically for larger numbers of values. We should switch to a more stable version, e.g. iterative mean using avg = avg + (value - avg) / count.</description>
      <version>3.0.10,3.10</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.AggregationTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.functions.AggregateFcts.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12478" opendate="2016-8-17 00:00:00" fixdate="2016-10-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cassandra stress still uses CFMetaData.compile()</summary>
      <description>Using CFMetaData.compile() on a client tool causes permission problems. To reproduce: Start cassandra under user cassandra Run chmod -R go-rwx /var/lib/cassandra to deny access to other users. Use a non-root user to run cassandra-stressThis produces an access denied message on /var/lib/cassandra/commitlog.The attached fix uses client-mode functionality.</description>
      <version>3.0.10,3.10</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.StressProfile.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12499" opendate="2016-8-19 00:00:00" fixdate="2016-9-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Row cache does not cache partitions on tables without clustering keys</summary>
      <description>MLSEA-JJIRSA01:~ jjirsa$ ccm startMLSEA-JJIRSA01:~ jjirsa$ echo "DESCRIBE TABLE test.test; " | ccm node1 cqlshCREATE TABLE test.test ( id int PRIMARY KEY, v text) WITH bloom_filter_fp_chance = 0.01 AND caching = {'keys': 'ALL', 'rows_per_partition': '100'} AND comment = '' AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'} AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'} AND crc_check_chance = 1.0 AND dclocal_read_repair_chance = 0.1 AND default_time_to_live = 0 AND gc_grace_seconds = 864000 AND max_index_interval = 2048 AND memtable_flush_period_in_ms = 0 AND min_index_interval = 128 AND read_repair_chance = 0.0 AND speculative_retry = '99PERCENTILE';MLSEA-JJIRSA01:~ jjirsa$ ccm node1 nodetool info | grep RowRow Cache : entries 0, size 0 bytes, capacity 100 MiB, 0 hits, 0 requests, NaN recent hit rate, 0 save period in secondsMLSEA-JJIRSA01:~ jjirsa$ echo "INSERT INTO test.test(id,v) VALUES(1, 'a'); " | ccm node1 cqlshMLSEA-JJIRSA01:~ jjirsa$ echo "SELECT * FROM test.test WHERE id=1; " | ccm node1 cqlsh id | v----+--- 1 | a(1 rows)MLSEA-JJIRSA01:~ jjirsa$ ccm node1 nodetool info | grep RowRow Cache : entries 0, size 0 bytes, capacity 100 MiB, 0 hits, 0 requests, NaN recent hit rate, 0 save period in secondsMLSEA-JJIRSA01:~ jjirsa$ echo "SELECT * FROM test.test WHERE id=1; " | ccm node1 cqlsh id | v----+--- 1 | a(1 rows)MLSEA-JJIRSA01:~ jjirsa$ ccm node1 nodetool info | grep RowRow Cache : entries 0, size 0 bytes, capacity 100 MiB, 0 hits, 0 requests, NaN recent hit rate, 0 save period in secondsMLSEA-JJIRSA01:~ jjirsa$</description>
      <version>3.0.10,3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.SchemaLoader.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.RowCacheTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.SinglePartitionReadCommand.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12582" opendate="2016-8-31 00:00:00" fixdate="2016-10-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Removing static column results in ReadFailure due to CorruptSSTableException</summary>
      <description>We ran into an issue on production where reads began to fail for certain queries, depending on the range within the relation for those queries. Cassandra system log showed an unhandled CorruptSSTableException exception.CQL read failure:ReadFailure: code=1300 [Replica(s) failed to execute read] message="Operation failed - received 0 responses and 1 failures" info={'failures': 1, 'received_responses': 0, 'required_responses': 1, 'consistency': 'ONE'}Cassandra exception:WARN [SharedPool-Worker-2] 2016-08-31 12:49:27,979 AbstractLocalAwareExecutorService.java:169 - Uncaught exception on thread Thread[SharedPool-Worker-2,5,main]: {}java.lang.RuntimeException: org.apache.cassandra.io.sstable.CorruptSSTableException: Corrupted: /usr/local/apache-cassandra-3.0.8/data/data/issue309/apples_by_tree-006748a06fa311e6a7f8ef8b642e977b/mb-1-big-Data.db at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:2453) ~[apache-cassandra-3.0.8.jar:3.0.8] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_72] at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:164) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$LocalSessionFutureTask.run(AbstractLocalAwareExecutorService.java:136) [apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:105) [apache-cassandra-3.0.8.jar:3.0.8] at java.lang.Thread.run(Thread.java:745) [na:1.8.0_72]Caused by: org.apache.cassandra.io.sstable.CorruptSSTableException: Corrupted: /usr/local/apache-cassandra-3.0.8/data/data/issue309/apples_by_tree-006748a06fa311e6a7f8ef8b642e977b/mb-1-big-Data.db at org.apache.cassandra.io.sstable.format.big.BigTableScanner$KeyScanningIterator$1.initializeIterator(BigTableScanner.java:343) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.rows.LazilyInitializedUnfilteredRowIterator.maybeInit(LazilyInitializedUnfilteredRowIterator.java:48) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.rows.LazilyInitializedUnfilteredRowIterator.isReverseOrder(LazilyInitializedUnfilteredRowIterator.java:65) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.rows.LazilyInitializedUnfilteredRowIterator.isReverseOrder(LazilyInitializedUnfilteredRowIterator.java:66) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.partitions.PurgeFunction.applyToPartition(PurgeFunction.java:62) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.partitions.PurgeFunction.applyToPartition(PurgeFunction.java:24) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.transform.BasePartitions.hasNext(BasePartitions.java:96) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.partitions.UnfilteredPartitionIterators$Serializer.serialize(UnfilteredPartitionIterators.java:295) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.ReadResponse$LocalDataResponse.build(ReadResponse.java:134) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.ReadResponse$LocalDataResponse.&lt;init&gt;(ReadResponse.java:127) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.ReadResponse$LocalDataResponse.&lt;init&gt;(ReadResponse.java:123) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.ReadResponse.createDataResponse(ReadResponse.java:65) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.ReadCommand.createResponse(ReadCommand.java:289) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.service.StorageProxy$LocalReadRunnable.runMayThrow(StorageProxy.java:1796) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:2449) ~[apache-cassandra-3.0.8.jar:3.0.8] ... 5 common frames omittedCaused by: org.apache.cassandra.io.sstable.CorruptSSTableException: Corrupted: /usr/local/apache-cassandra-3.0.8/data/data/issue309/apples_by_tree-006748a06fa311e6a7f8ef8b642e977b/mb-1-big-Data.db at org.apache.cassandra.db.columniterator.AbstractSSTableIterator.&lt;init&gt;(AbstractSSTableIterator.java:130) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.columniterator.SSTableIterator.&lt;init&gt;(SSTableIterator.java:46) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.io.sstable.format.big.BigTableReader.iterator(BigTableReader.java:69) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.io.sstable.format.big.BigTableScanner$KeyScanningIterator$1.initializeIterator(BigTableScanner.java:338) ~[apache-cassandra-3.0.8.jar:3.0.8] ... 19 common frames omittedCaused by: java.io.IOException: Corrupt (negative) value length encountered at org.apache.cassandra.db.marshal.AbstractType.readValue(AbstractType.java:399) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.rows.BufferCell$Serializer.deserialize(BufferCell.java:302) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.rows.UnfilteredSerializer.readSimpleColumn(UnfilteredSerializer.java:462) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.rows.UnfilteredSerializer.deserializeRowBody(UnfilteredSerializer.java:440) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.rows.UnfilteredSerializer.deserializeStaticRow(UnfilteredSerializer.java:381) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.columniterator.AbstractSSTableIterator.readStaticRow(AbstractSSTableIterator.java:179) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.columniterator.AbstractSSTableIterator.&lt;init&gt;(AbstractSSTableIterator.java:103) ~[apache-cassandra-3.0.8.jar:3.0.8] ... 22 common frames omittedAfter debugging, it appears that a previously dropped static column (weeks prior) was the instigator of the issue. As a workaround we added back the column, restarted all cassandra processes within the cluster, and the read error and corruption exception went away.Attached is a script to reproduce with a simple schema.Also noteworthy (and shown in the script) is that when in this state, compaction silently failed (exit 0) to remove the dropped static columns from the "corrupted" sstable.</description>
      <version>3.0.10,3.10</version>
      <fixedVersion>Legacy/LocalWrite-ReadPaths</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.SerializationHeader.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12720" opendate="2016-9-28 00:00:00" fixdate="2016-10-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Permissions on aggregate functions are not removed on drop</summary>
      <description>When a user defined aggregate is dropped, either directly or when it's enclosing keyspace is dropped, permissions granted on it are not cleaned up.</description>
      <version>2.2.9,3.0.10,3.10</version>
      <fixedVersion>Legacy/DistributedMetadata</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.auth.AuthMigrationListener.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12740" opendate="2016-10-3 00:00:00" fixdate="2016-10-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh copy tests hang in case of no answer from the server or driver</summary>
      <description>If we bundle the driver to cqlsh using the 3.6.0 tag or cassandra_test head, some cqlsh copy tests hang, for example test_bulk_round_trip_blogposts. See CASSANDRA-12736 and CASSANDRA-11534 for some sample failures.If the driver fails to invoke a callback (either error or success), or if the server never answers to the driver, then the copy parent process will wait forever to receive an answer from child processes. We should put a cap to this. We should also use a very high timeout rather than None, so that the driver will notify us if there is no answer from the server.</description>
      <version>3.0.10,3.10</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.copyutil.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12754" opendate="2016-10-6 00:00:00" fixdate="2016-10-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change cassandra.wait_for_tracing_events_timeout_secs default to -1 so C* doesn&amp;#39;t wait on trace events to be written before responding to request by default</summary>
      <description>CASSANDRA-11465 introduces a new system property cassandra.wait_for_tracing_events_timeout_secs that controls whether or not C* waits for events to be written before responding to client. The current default behavior is to wait up to 1 second and then respond and timeout. If using probabilistic tracing this can cause queries to be randomly delayed up to 1 second.Changing the default to -1 (disabled and enabling it explicitly in cql_tracing_test.TestCqlTracing.tracing_unknown_impl_test.Ideally it would be nice to be able to control this behavior on a per request basis (which would require native protocol changes).</description>
      <version>2.2.9,3.0.10,3.10</version>
      <fixedVersion>Legacy/Observability</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tracing.TraceState.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12765" opendate="2016-10-10 00:00:00" fixdate="2016-10-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>SSTable ignored incorrectly with partition level tombstone</summary>
      <description>CREATE TABLE test.payload( bucket_id TEXT, name TEXT, data TEXT, PRIMARY KEY (bucket_id, name));insert into test.payload (bucket_id, name, data) values ('8772618c9009cf8f5a5e0c18', 'test', 'hello');Flush nodes (nodetool flush)insert into test.payload (bucket_id, name, data) values ('8772618c9009cf8f5a5e0c19', 'test2', 'hello');delete from test.payload where bucket_id = '8772618c9009cf8f5a5e0c18';Flush nodes (nodetool flush)select * from test.payload where bucket_id = '8772618c9009cf8f5a5e0c18' and name = 'test';Expected 0 rows but get 1 row back.</description>
      <version>2.1.17,2.2.9,3.0.10,3.10,4.0-alpha1,4.0</version>
      <fixedVersion>Legacy/LocalWrite-ReadPaths</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.CollationController.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12776" opendate="2016-10-12 00:00:00" fixdate="2016-10-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>when memtable flush Statistics thisOffHeap error</summary>
      <description>if (largest != null) { float usedOnHeap = Memtable.MEMORY_POOL.onHeap.usedRatio(); float usedOffHeap = Memtable.MEMORY_POOL.offHeap.usedRatio(); float flushingOnHeap = Memtable.MEMORY_POOL.onHeap.reclaimingRatio(); float flushingOffHeap = Memtable.MEMORY_POOL.offHeap.reclaimingRatio(); float thisOnHeap = largest.getAllocator().onHeap().ownershipRatio(); float thisOffHeap = largest.getAllocator().onHeap().ownershipRatio(); logger.info("Flushing largest {} to free up room. Used total: {}, live: {}, flushing: {}, this: {}", largest.cfs, ratio(usedOnHeap, usedOffHeap), ratio(liveOnHeap, liveOffHeap), ratio(flushingOnHeap, flushingOffHeap), ratio(thisOnHeap, thisOffHeap)); largest.cfs.switchMemtableIfCurrent(largest); }Should:float thisOffHeap = largest.getAllocator().onHeap().ownershipRatio();Be:offHeap().ownershipRatio();</description>
      <version>3.0.10,3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12786" opendate="2016-10-13 00:00:00" fixdate="2016-10-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix a bug in CASSANDRA-11005(Split consisten range movement flag)</summary>
      <description>I missed a place in the code where we need to split this flag for bootstrap</description>
      <version>2.2.9,3.0.10,3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12863" opendate="2016-10-31 00:00:00" fixdate="2016-11-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh COPY FROM cannot parse timestamp in partition key if table contains a counter value</summary>
      <description>This sample table:CREATE TABLE test (columnname text, day timestamp, israndom boolean, columnvalue text, counter counter, PRIMARY KEY ((columnname, day, israndom), columnvalue));with this sample data:origins|2016-10-01 00:00:00+0000|False|ACTUAL|6origins|2016-10-01 00:00:00+0000|False|ADGMOB|4origins|2016-10-01 00:00:00+0000|False|ANONPM|4origins|2016-10-01 00:00:00+0000|False|CSRT2L|76origins|2016-10-01 00:00:00+0000|False|DIAGOP|18origins|2016-10-01 00:00:00+0000|False|E-SOFT|17origins|2016-10-01 00:00:00+0000|False|E-TASK|10when imported withCOPY ks.test FROM 'test.csv' WITH DELIMITER = '|';will generate a parse error:Failed to import 7 rows: ParseError - can't interpret u"'2016-10-01 00:00:00+0000'" as a date with this format: %Y-%m-%d %H:%M:%S%z, given up without retriesThe problem is that when a counter value is present, we don't use prepared statements and so we typically don't convert values unless they are part of the partition key. We also add quotes for certain types, such as timestamps. The problem is that we do not remove such quotes before parsing the partition key values, therefore ending up with a parse error.</description>
      <version>2.2.9,3.0.10,3.10</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.copyutil.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12889" opendate="2016-11-9 00:00:00" fixdate="2016-11-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Pass root cause to CorruptBlockException when uncompression failed</summary>
      <description>When reading compressed SSTable failed, CorruptBlockException is thrown without root cause. It is nice to have when investigating uncompression error.</description>
      <version>3.0.10,3.10</version>
      <fixedVersion>Legacy/LocalWrite-ReadPaths</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.compress.CompressedSequentialWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.io.compress.CompressedRandomAccessReader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>
