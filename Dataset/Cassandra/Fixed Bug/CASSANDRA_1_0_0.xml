<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="CASSANDRA">
  <bug id="1610" opendate="2010-10-12 00:00:00" fixdate="2010-6-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Pluggable Compaction</summary>
      <description>In CASSANDRA-1608, I proposed some changes on how compaction works. I think it also makes sense to allow the ability to have pluggable compaction per CF. There could be many types of workloads where this makes sense. One example we had at Digg was to completely throw away certain SSTables after N days.This ticket addresses making compaction pluggable only.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.io.sstable.SSTableReaderTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.TableTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.RemoveSuperColumnTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.compaction.OneCompactionTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionTask.java</file>
      <file type="M">test.unit.org.apache.cassandra.streaming.StreamingTransferTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.DefsTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.compaction.CompactionsTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.compaction.CompactionsPurgeTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cli.CliTest.java</file>
      <file type="M">test.long.org.apache.cassandra.db.compaction.LongCompactionSpeedTest.java</file>
      <file type="M">src.java.org.apache.cassandra.service.AbstractCassandraDaemon.java</file>
      <file type="M">src.java.org.apache.cassandra.db.HintedHandOffManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.DataTracker.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">src.java.org.apache.cassandra.cli.CliClient.java</file>
      <file type="M">src.avro.internode.genavro</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.KsDef.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.CqlRow.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.CqlResult.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.CfDef.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.Cassandra.java</file>
      <file type="M">interface.cassandra.thrift</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1717" opendate="2010-11-6 00:00:00" fixdate="2010-8-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cassandra cannot detect corrupt-but-readable column data</summary>
      <description>Most corruptions of on-disk data due to bitrot render the column (or row) unreadable, so the data can be replaced by read repair or anti-entropy. But if the corruption keeps column data readable we do not detect it, and if it corrupts to a higher timestamp value can even resist being overwritten by newer values.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.Util.java</file>
      <file type="M">test.unit.org.apache.cassandra.io.util.BufferedRandomAccessFileTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.io.compress.CompressedRandomAccessReaderTest.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.FBUtilities.java</file>
      <file type="M">src.java.org.apache.cassandra.io.compress.CompressionMetadata.java</file>
      <file type="M">src.java.org.apache.cassandra.io.compress.CompressedSequentialWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.io.compress.CompressedRandomAccessReader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1902" opendate="2010-12-24 00:00:00" fixdate="2010-5-24 01:00:00" resolution="Won&amp;#39;t Fix">
    <buginformation>
      <summary>Migrate cached pages during compaction</summary>
      <description>Post CASSANDRA-1470 there is an opportunity to migrate cached pages from a pre-compacted CF during the compaction process. This is now important since CASSANDRA-1470 caches effectively nothing. For example an active CF being compacted hurts reads since nothing is cached in the new SSTable. The purpose of this ticket then is to make sure SOME data is cached from active CFs. This can be done my monitoring which Old SSTables are in the page cache and caching active rows in the New SStable.A simpler yet similar approach is described here: http://insights.oetiker.ch/linux/fadvise/</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.service.AntiEntropyServiceTest.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.CLibrary.java</file>
      <file type="M">src.java.org.apache.cassandra.io.util.DataOutputBuffer.java</file>
      <file type="M">src.java.org.apache.cassandra.io.util.BufferedRandomAccessFile.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableScanner.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableReader.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableIdentityIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.KeyIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.CacheWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.io.PrecompactedRow.java</file>
      <file type="M">src.java.org.apache.cassandra.io.LazilyCompactedRow.java</file>
      <file type="M">src.java.org.apache.cassandra.io.CompactionIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.io.AbstractCompactedRow.java</file>
      <file type="M">src.java.org.apache.cassandra.db.SuperColumn.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowMutation.java</file>
      <file type="M">src.java.org.apache.cassandra.db.IColumn.java</file>
      <file type="M">src.java.org.apache.cassandra.db.CompactionManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLogSegment.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLog.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilySerializer.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamily.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Column.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">conf.cassandra.yaml</file>
    </fixedFiles>
  </bug>
  <bug id="1966" opendate="2011-1-11 00:00:00" fixdate="2011-7-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Option to control how many items are read on cache load</summary>
      <description>CASSANDRA-1417 added an option to save the key and/or row cache keys which is cool. However, for a row large cache it can take a long time to read all of the rows. For example I have a 400,000 item row cache, and loading that on restart takes a little under an hour.In addition to configuring the size of the row cache, and how often it should be saved to disk, I propose an option to control how many items are loaded on startup (or alternately only saving n items out of the full row cache to begin with).</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.RowCacheTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.KeyCacheTest.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.migration.Migration.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStoreMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">src.java.org.apache.cassandra.cli.CliClient.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.SerializingCache.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.InstrumentingCache.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.ICache.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.ConcurrentLinkedHashCache.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.AutoSavingCache.java</file>
      <file type="M">src.avro.internode.genavro</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.Constants.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.CfDef.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.Cassandra.java</file>
      <file type="M">interface.cassandra.thrift</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2034" opendate="2011-1-22 00:00:00" fixdate="2011-8-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make Read Repair unnecessary when Hinted Handoff is enabled</summary>
      <description>Currently, HH is purely an optimization &amp;#8211; if a machine goes down, enabling HH means RR/AES will have less work to do, but you can't disable RR entirely in most situations since HH doesn't kick in until the FailureDetector does.Let's add a scheduled task to the mutate path, such that we return to the client normally after ConsistencyLevel is achieved, but after RpcTimeout we check the responseHandler write acks and write local hints for any missing targets.This would making disabling RR when HH is enabled a much more reasonable option, which has a huge impact on read throughput.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.service.RemoveTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.service.ConsistencyLevelTest.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.FBUtilities.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.ExpiringMap.java</file>
      <file type="M">src.java.org.apache.cassandra.service.WriteResponseHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxyMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.service.IWriteResponseHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.service.DatacenterWriteResponseHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.service.DatacenterSyncWriteResponseHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.service.AbstractWriteResponseHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.net.ResponseVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
      <file type="M">src.java.org.apache.cassandra.locator.AbstractReplicationStrategy.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowMutationVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowMutation.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2045" opendate="2011-1-24 00:00:00" fixdate="2011-8-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Simplify HH to decrease read load when nodes come back</summary>
      <description>Currently when HH is enabled, hints are stored, and when a node comes back, we begin sending that node data. We do a lookup on the local node for the row to send. To help reduce read load (if a node is offline for long period of time) we should store the data we want forward the node locally instead. We wouldn't have to do any lookups, just take byte[] and send to the destination.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.RowMutationVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowMutation.java</file>
      <file type="M">src.java.org.apache.cassandra.db.HintedHandOffManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2061" opendate="2011-1-27 00:00:00" fixdate="2011-8-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Missing logging for some exceptions</summary>
      <description>Since you are using ScheduledThreadPoolExecutor.schedule(), the exception was swallowed by the FutureTask.You will have to perform a get() method on the ScheduledFuture, and you will get ExecutionException if there was any exception occured in run().</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">test.unit.org.apache.cassandra.locator.DynamicEndpointSnitchTest.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.Gossiper.java</file>
      <file type="M">src.java.org.apache.cassandra.concurrent.RetryingScheduledThreadPoolExecutor.java</file>
      <file type="M">src.java.org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2062" opendate="2011-1-27 00:00:00" fixdate="2011-6-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Better control of iterator consumption</summary>
      <description>The core reason for this ticket is to gain control over the consumption of the lazy nested iterators in the read path.We survive now because we write the size of the row at the front of the row (via some serious acrobatics at write time), which gives us hasNext() for rows for free. But it became apparent while working on the block-based format that hasNext() will not be cheap unless the current item has been consumed. "Consumption" of the row is easy, and blocks will be framed so that they can be very easily skipped, but you don't want to have to seek to the end of the row to answer hasNext, and then seek back to the beginning to consume the row, which is what CollatingIterator would have forced us to do.While we're at it, we can also improve efficiency: for M iterators containing N total items, commons.collections.CollatingIterator performs a O(M*N) merge, and calls hasNext multiple times per returned value. We can do better.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.utils.ReducingIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.FBUtilities.java</file>
      <file type="M">src.java.org.apache.cassandra.service.RowRepairResolver.java</file>
      <file type="M">src.java.org.apache.cassandra.service.RangeSliceResponseResolver.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableScanner.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.ReducingKeyIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.KeyIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowIteratorFactory.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.QueryFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LazilyCompactedRow.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.db.columniterator.IColumnIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2082" opendate="2011-1-31 00:00:00" fixdate="2011-7-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Saved row cache continues to be read past max cache size</summary>
      <description>Scenario: Node has a saved row cache of size n node OOMs Make row cache size = .5n to prevent OOM while we debug, restart node. n items are still read from the row cache, making startup take twice as long as needed.(This is intended as a straightforward bug, not as a hackish CASSANDRA-1966.)</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.RowCacheTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="2247" opendate="2011-2-25 00:00:00" fixdate="2011-9-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cleanup unused imports and generics</summary>
      <description>In current cassandra trunk are many classes which import packages which are never used. The same is true for Loggers which are often instanced and then not used. Beside this I see many warnings related to generic usage. Would be nice to clean this up a bit.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.RowRepairResolver.java</file>
      <file type="M">src.java.org.apache.cassandra.service.MigrationManager.java</file>
      <file type="M">src.java.org.apache.cassandra.service.EmbeddedCassandraService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.DigestMismatchException.java</file>
      <file type="M">src.java.org.apache.cassandra.service.AbstractRowResolver.java</file>
      <file type="M">src.java.org.apache.cassandra.net.MessageDeliveryTask.java</file>
      <file type="M">src.java.org.apache.cassandra.net.Header.java</file>
      <file type="M">src.java.org.apache.cassandra.net.AsyncResult.java</file>
      <file type="M">src.java.org.apache.cassandra.locator.AbstractEndpointSnitch.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableScanner.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableIdentityIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.ReducingKeyIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.KeyIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.IndexSummary.java</file>
      <file type="M">src.java.org.apache.cassandra.db.migration.Migration.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.SliceQueryFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.QueryFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.NamesQueryFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.IFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.PrecompactedRow.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.AbstractCompactedRow.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.StatusLogger.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.obs.ArrayUtil.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.LegacyBloomFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.GuidGenerator.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.ExpiringMap.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.EstimatedHistogram.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.BloomFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraServer.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamOut.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamInSession.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamingService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Table.java</file>
      <file type="M">src.java.org.apache.cassandra.db.SuperColumn.java</file>
      <file type="M">src.java.org.apache.cassandra.db.SliceFromReadCommand.java</file>
      <file type="M">src.java.org.apache.cassandra.db.SliceByNamesReadCommand.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowMutationVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Row.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ReadRepairVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.db.IMutation.java</file>
      <file type="M">src.java.org.apache.cassandra.db.HintedHandOffManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ExpiringColumn.java</file>
      <file type="M">src.java.org.apache.cassandra.db.DeletedColumn.java</file>
      <file type="M">src.java.org.apache.cassandra.db.context.CounterContext.java</file>
      <file type="M">src.java.org.apache.cassandra.concurrent.RetryingScheduledThreadPoolExecutor.java</file>
      <file type="M">src.java.org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.java</file>
      <file type="M">src.java.org.apache.cassandra.client.RingCache.java</file>
    </fixedFiles>
  </bug>
  <bug id="2252" opendate="2011-2-26 00:00:00" fixdate="2011-8-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>arena allocation for memtables</summary>
      <description>The memtable design practically actively fights Java's GC design. Todd Lipcon gave a good explanation over on HBASE-3455.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.TimeSortTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.ReadMessageTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.CounterMutationTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.CounterColumnTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.context.CounterContextTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.ColumnFamilyTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.ArrayBackedSortedColumnsTest.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.ByteBufferUtil.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.IncomingStreamReader.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.io.util.ColumnSortedMap.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableSimpleUnsortedWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableIdentityIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.io.IColumnSerializer.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ThreadSafeSortedColumns.java</file>
      <file type="M">src.java.org.apache.cassandra.db.SuperColumn.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowMutation.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Row.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Memtable.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.CounterColumnType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ISortedColumns.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.keys.KeysSearcher.java</file>
      <file type="M">src.java.org.apache.cassandra.db.IColumnContainer.java</file>
      <file type="M">src.java.org.apache.cassandra.db.IColumn.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ExpiringColumn.java</file>
      <file type="M">src.java.org.apache.cassandra.db.DeletedColumn.java</file>
      <file type="M">src.java.org.apache.cassandra.db.CounterUpdateColumn.java</file>
      <file type="M">src.java.org.apache.cassandra.db.CounterMutation.java</file>
      <file type="M">src.java.org.apache.cassandra.db.CounterColumn.java</file>
      <file type="M">src.java.org.apache.cassandra.db.context.IContext.java</file>
      <file type="M">src.java.org.apache.cassandra.db.context.CounterContext.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.PrecompactedRow.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnSerializer.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilySerializer.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamily.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Column.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ArrayBackedSortedColumns.java</file>
      <file type="M">src.java.org.apache.cassandra.db.AbstractColumnContainer.java</file>
      <file type="M">lib.jamm-0.2.2.jar</file>
      <file type="M">conf.cassandra-env.sh</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="2317" opendate="2011-3-12 00:00:00" fixdate="2011-7-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Column family deletion time is not always reseted after gc_grace</summary>
      <description>Follow up of CASSANDRA-2305.Reproducible (thanks to Jeffrey Wang) by: Create a CF with gc_grace_seconds = 0 and no row cache.Insert row X, col A with timestamp 0.Insert row X, col B with timestamp 2.Remove row X with timestamp 1 (expect col A to disappear, col B to stay).Wait 1 second.Force flush and compaction.Insert row X, col A with timestamp 0.Read row X, col A (see nothing).</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.service.RowResolverTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.RowTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.compaction.CompactionsPurgeTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.SuperColumn.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowMutation.java</file>
      <file type="M">src.java.org.apache.cassandra.db.IColumnContainer.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.QueryFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilySerializer.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamily.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2427" opendate="2011-4-6 00:00:00" fixdate="2011-6-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Heuristic or hard cap to prevent fragmented commit logs from bringing down the server</summary>
      <description>Widely divergent write rates on column families can cause the commit log segments to fragment. In some cases we have seen the commit log partition overrun.One solution here would be to create a heuristic for segment fragmentation to trigger a flush (commit log segments/memtable) or simply track the free disk space and force a global flush when the disk gets to 80% capacity.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.Table.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.DefsTest.java</file>
      <file type="M">src.resources.org.apache.cassandra.cli.CliHelp.yaml</file>
      <file type="M">src.java.org.apache.cassandra.thrift.ThriftValidation.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.AbstractCommitLogExecutorService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.BatchCommitLogExecutorService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.BatchCommitLogExecutorServiceMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLog.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLogSegment.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.ICommitLogExecutorService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.PeriodicCommitLogExecutorService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.PeriodicCommitLogExecutorServiceMBean.java</file>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.AuthenticationException.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.AuthenticationRequest.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.AuthorizationException.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.Cassandra.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.CfDef.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.Column.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.ColumnDef.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.ColumnOrSuperColumn.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.ColumnParent.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.ColumnPath.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.CounterColumn.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.CounterSuperColumn.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.CqlResult.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.CqlRow.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.Deletion.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.IndexClause.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.IndexExpression.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.InvalidRequestException.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.KeyCount.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.KeyRange.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.KeySlice.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.KsDef.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.Mutation.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.NotFoundException.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.SchemaDisagreementException.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.SlicePredicate.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.SliceRange.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.SuperColumn.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.TimedOutException.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.TokenRange.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.UnavailableException.java</file>
      <file type="M">src.avro.internode.genavro</file>
      <file type="M">src.java.org.apache.cassandra.cli.CliClient.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.CreateColumnFamilyStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStoreMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Memtable.java</file>
    </fixedFiles>
  </bug>
  <bug id="2447" opendate="2011-4-11 00:00:00" fixdate="2011-8-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove auto-bootstrap option</summary>
      <description>We already optimize auto-bootstrap to be no-op if there are no non-system tables.Given that, the only penalty imposed by autobootstrap is a 30s sleep waiting for gossip. Feels worth it to avoid the confusion this option causes, and the problems if you don't turn it on when it should be.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2449" opendate="2011-4-11 00:00:00" fixdate="2011-9-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Deprecate or modify per-cf memtable sizes in favor of the global threshold</summary>
      <description>The new memtable_total_space_in_mb setting is an excellent way to cap memory usage for memtables, and one could argue that it should replace the per-cf memtable sizes entirely. On the other hand, people may still want a knob to tune to flush certain cfs less frequently.I think a best of both worlds approach might be to deprecate the memtable_(throughput|operations) settings, and replace them with a preference value, which controls the relative memory usage of one CF versus another (all CFs at 1 would mean equal preference). For backwards compatibility, we could continue to read from the _throughput value and treat it as the preference value, while logging a warning.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.DefsTest.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Table.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Memtable.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.SecondaryIndexManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.SecondaryIndex.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.keys.KeysIndex.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStoreMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.CreateColumnFamilyStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">src.avro.internode.genavro</file>
      <file type="M">NEWS.txt</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.Constants.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.CfDef.java</file>
      <file type="M">interface.cassandra.thrift</file>
      <file type="M">conf.cassandra.yaml</file>
    </fixedFiles>
  </bug>
  <bug id="2452" opendate="2011-4-11 00:00:00" fixdate="2011-7-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>New EC2 Snitch to use public ip and hence natively support for EC2 mult-region&amp;#39;s.</summary>
      <description>Make cassandra talk identify itself using the public ip (To avoid any future conflicts of private ips).1) Split the logic of identification vs listen Address in the code.2) Move the logic to assign IP address to the node into EndPointSnitch.3) Make EC2 Snitch query for its public ip and use it for identification.4) Make EC2 snitch to use InetAddress.getLocal to listen to the private ip.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.net.OutboundTcpConnectionPool.java</file>
      <file type="M">src.java.org.apache.cassandra.net.OutboundTcpConnection.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.VersionedValue.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.ApplicationState.java</file>
    </fixedFiles>
  </bug>
  <bug id="2468" opendate="2011-4-13 00:00:00" fixdate="2011-6-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up after failed compaction</summary>
      <description>(Started in CASSANDRA-2088.)</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.io.sstable.SSTableTest.java</file>
      <file type="M">src.java.org.apache.cassandra.io.util.FileUtils.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableReader.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableDeletingReference.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTable.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.Descriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Memtable.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionTask.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2494" opendate="2011-4-17 00:00:00" fixdate="2011-8-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Quorum reads are not monotonically consistent</summary>
      <description>As discussed in this thread,http://www.mail-archive.com/user@cassandra.apache.org/msg12421.htmlQuorum reads should be consistent. Assume we have a cluster of 3 nodes (X,Y,Z) and a replication factor of 3. If a write of N is committed to X, but not Y and Z, then a read from X should not return N unless the read is committed to at least two nodes. To ensure this, a read from X should wait for an ack of the read repair write from either Y or Z before returning.Are there system tests for cassandra? If so, there should be a test similar to the original post in the email thread. One thread should write 1,2,3... at consistency level ONE. Another thread should read at consistency level QUORUM from a random host, and verify that each read is &gt;= the last read.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.utils.FBUtilities.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.service.RowRepairResolver.java</file>
      <file type="M">src.java.org.apache.cassandra.service.RepairCallback.java</file>
      <file type="M">src.java.org.apache.cassandra.service.RangeSliceResponseResolver.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2589" opendate="2011-5-2 00:00:00" fixdate="2011-6-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>row deletes do not remove columns</summary>
      <description>When a row delete is issued CF.delete() sets the localDeletetionTime and markedForDeleteAt values but does not remove columns which have a lower time stamp. As a result: Memory which could be freed is held on to (prob not too bad as it's already counted) The deleted columns are serialised to disk, along with the CF info to say they are no longer valid. NamesQueryFilter and SliceQueryFilter have to do more work as they filter out the irrelevant columns using QueryFilter.isRelevant() Also columns written with a lower time stamp after the deletion are added to the CF without checking markedForDeletionAt.This can cause RR to fail, will create another ticket for that and link. This ticket is for a fix to removing the columns. Two options I could think of: Check for deletion when serialising to SSTable and ignore columns if the have a lower timestamp. Otherwise leave as is so dead columns stay in memory. Ensure at all times if the CF is deleted all columns it contains have a higher timestamp. I think this would include all column types (DeletedColumn as well) as the CF deletion has the same effect. But not sure. Deleting (potentially) all columns in delete() will take time. Could track the highest timestamp in the CF so the normal case of deleting all cols does not need to iterate.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.Memtable.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2594" opendate="2011-5-3 00:00:00" fixdate="2011-8-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>run cassandra under numactl --interleave=all</summary>
      <description>By default, Linux attempts to be smart about memory allocations such that data is close to the NUMA node on which it runs. For big database type of applications, this is not the best thing to do if the priority is to avoid disk I/O. In particular with Cassandra, we're heavily multi-threaded anyway and there is no particular reason to believe that one NUMA node is "better" than another.Consequences of allocating unevenly among NUMA nodes can include excessive page cache eviction when the kernel tries to allocate memory - such as when restarting the JVM.With that briefly stated background, I propse the following patch to make the Cassandra script run Cassandra with numactl --interleave=all if numactl seems to be available.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.cassandra</file>
    </fixedFiles>
  </bug>
  <bug id="2606" opendate="2011-5-4 00:00:00" fixdate="2011-9-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expose through JMX the ability to repair only the primary range</summary>
      <description>CASSANDRA-2324 introduces the ability to do a repair only on a given range. This ticket proposes to add a nodetool repairPrimaryRange to trigger the repair of only the primary range of a node. This allows to repair a full cluster without any work duplication (or at least make it much simpler). This also introdude a global_repair command to clustertool to trigger the primary range repair on each node of the cluster one after another (we could do all in parallel, but that's probably not nice on the cluster).</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeProbe.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageServiceMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2610" opendate="2011-5-5 00:00:00" fixdate="2011-9-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Have the repair of a range repair *all* the replica for that range</summary>
      <description>Say you have a range R whose replica for that range are A, B and C. If you run repair on node A for that range R, when the repair end you only know that A is fully repaired. B and C are not. That is B and C are up to date with A before the repair, but are not up to date with one another.It makes it a pain to schedule "optimal" cluster repairs, that is repairing a full cluster without doing work twice (because you would have still have to run a repair on B or C, which will make A, B and C redo a validation compaction on R, and with more replica it's even more annoying).However it is fairly easy during the first repair on A to have him compare all the merkle trees, i.e the ones for B and C, and ask to B or C to stream between them whichever the differences they have.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.service.AntiEntropyServiceTestAbstract.java</file>
      <file type="M">test.unit.org.apache.cassandra.io.CompactSerializerTest.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.UUIDGen.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.AntiEntropyService.java</file>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2630" opendate="2011-5-10 00:00:00" fixdate="2011-8-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CLI - &amp;#39;describe column family&amp;#39; would be nice</summary>
      <description>I end up verifying column families a lot and using 'describe keyspace &lt;keyspace&gt;;' spits out a whole bunch of data since our keyspace has a lot of metadata. It would be really useful to have a 'describe &lt;column family&gt;;' for a given column family in the currently authenticated keyspace.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cli.CliTest.java</file>
      <file type="M">src.resources.org.apache.cassandra.cli.CliHelp.yaml</file>
      <file type="M">src.java.org.apache.cassandra.cli.CliUtils.java</file>
      <file type="M">src.java.org.apache.cassandra.cli.CliClient.java</file>
      <file type="M">src.java.org.apache.cassandra.cli.Cli.g</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2677" opendate="2011-5-20 00:00:00" fixdate="2011-7-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Optimize streaming to be single-pass</summary>
      <description>Streaming currently is a two-pass operation: one to write the Data component do disk from the socket, then another to build the index and bloom filter from it. This means we do about 2x the i/o we would if we created the index and BF during the original write.For node movement this was not considered to be a Big Deal because the stream target is not a member of the ring, so we can be inefficient without hurting live queries. But optimizing node movement to not require un/rebootstrap (CASSANDRA-1427) and bulk load (CASSANDRA-1278) mean we can stream to live nodes too.The main obstacle here is we don't know how many keys will be in the new sstable ahead of time, which we need to size the bloom filter correctly. We can solve this by including that information (or a close approximation) in the stream setup &amp;#8211; the source node can calculate that without hitting disk from the in-memory index summary.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamOut.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamInSession.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.PendingFile.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.IncomingStreamReader.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableReader.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableIdentityIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.IndexHelper.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilySerializer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2679" opendate="2011-5-20 00:00:00" fixdate="2011-6-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move some column creation logic into Column factory functions</summary>
      <description>Expiring and Counter columns have extra creation logic that is better encapsulated when implemented inside a factory function.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.ExpiringColumn.java</file>
      <file type="M">src.java.org.apache.cassandra.db.CounterColumn.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnSerializer.java</file>
    </fixedFiles>
  </bug>
  <bug id="2692" opendate="2011-5-23 00:00:00" fixdate="2011-6-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Nuke BMT from orbit</summary>
      <description>Now that we have CASSANDRA-1278, let's remove BMT since it often confuses people in the config, is not used or tested very much, and is suboptimal.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Table.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowMutation.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Memtable.java</file>
      <file type="M">src.java.org.apache.cassandra.db.IFlushable.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">src.java.org.apache.cassandra.db.BinaryVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.db.BinaryMemtable.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">examples.bmt.README.txt</file>
      <file type="M">examples.bmt.CassandraBulkLoader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2764" opendate="2011-6-13 00:00:00" fixdate="2011-6-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>generate-eclipse-files still referencing drivers/ source</summary>
      <description>In trunk, running ant generate-eclipse-files will reference the old drivers top-level directory. The result is that the generated project, once loaded into Eclipse causes errors about the non-existent source directories.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="2771" opendate="2011-6-14 00:00:00" fixdate="2011-6-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove commitlog_rotation_threshold_in_mb</summary>
      <description>Remove the commitlog segment size config setting, nobody has ever changed it.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLog.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2806" opendate="2011-6-21 00:00:00" fixdate="2011-8-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expose gossip/FD info to JMX</summary>
      <description></description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeProbe.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.Gossiper.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.FailureDetectorMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.FailureDetector.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2820" opendate="2011-6-24 00:00:00" fixdate="2011-8-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Re-introduce FastByteArrayInputStream (and Output equivalent)</summary>
      <description>In https://issues.apache.org/jira/browse/CASSANDRA-37 FastByteArrayInputStream and FastByteArrayOutputStream were removed due to being code copied from the JDK and then subsequently modified. The JDK license is incompatible with Apache 2 license so the code had to go.I have since had a look at the performance of the JDK ByteArrayInputStream and a FastByteArrayInputStream (i.e. one with synchronized methods made un-synchronized) and seen the difference is significant.After a warmup-period of &gt;10000 loops I get the following for 10000 loops through a 128000 byte array:bais : 3513msfbais: 72msThis varies depending on the OS, machine and Java version, but it's always in favour of the FastByteArrayInputStream as you might expect.Then, at Jonathan Ellis' suggestion, I tried this using a modified Apache Harmony ByteArrayInputStream - i.e. one whose license is compatible - and the results were the same. A significant boost.I will attach a patch with changes for the 0.8.0 tag.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraServer.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamRequestVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamRequestMessage.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamReplyVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamReply.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.service.MigrationManager.java</file>
      <file type="M">src.java.org.apache.cassandra.service.AntiEntropyService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.AbstractRowResolver.java</file>
      <file type="M">src.java.org.apache.cassandra.net.IncomingTcpConnection.java</file>
      <file type="M">src.java.org.apache.cassandra.io.util.OutputBuffer.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.Gossiper.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.GossipDigestSynVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.GossipDigestAckVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.GossipDigestAck2VerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.db.WriteResponse.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Truncation.java</file>
      <file type="M">src.java.org.apache.cassandra.db.TruncateVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.db.TruncateResponse.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowMutationVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowMutation.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ReadVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ReadRepairVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ReadCommand.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RangeSliceReply.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RangeSliceCommand.java</file>
      <file type="M">src.java.org.apache.cassandra.db.IndexScanCommand.java</file>
      <file type="M">src.java.org.apache.cassandra.db.CounterMutationVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.db.CounterMutation.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLog.java</file>
    </fixedFiles>
  </bug>
  <bug id="2883" opendate="2011-7-12 00:00:00" fixdate="2011-9-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add Support for BigDecimal Java data type as the "DecimalType" AbstractType</summary>
      <description>The JDBC Driver suite needs support for BigDecimal to complete it's data type support for ResultSet and PreparedStatement. This datatype could also be used to represent numeric (non-integer) counter values. This is a very simple addition to the collection of data types supported by Cassandra. It is quite versatile like BigInteger. It can represent decimal numbers of virtually any precision and scale. It is represented in Java as an arbitrary precision integer unscaled value ( think IntegerType )and a 32-bit integer scale factor, which could be represented as a IntegerType as well. This could share much of the logic from the BigInteger (IntegerType) implementation. CQL would need to add a datatype (decimal?). Decimal literal support is already provided in CQL.This is low hanging fruit.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql.CreateColumnFamilyStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.Cql.g</file>
    </fixedFiles>
  </bug>
  <bug id="2901" opendate="2011-7-15 00:00:00" fixdate="2011-9-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow taking advantage of multiple cores while compacting a single CF</summary>
      <description>Moved from CASSANDRA-1876:There are five stages: read, deserialize, merge, serialize, and write. We probably want to continue doing read+deserialize and serialize+write together, or you waste a lot copying to/from buffers.So, what I would suggest is: one thread per input sstable doing read + deserialize (a row at a time). A thread pool (one per core?) merging corresponding rows from each input sstable. One thread doing serialize + writing the output (this has to wait for the merge threads to complete in-order, obviously). This should take us from being CPU bound on SSDs (since only one core is compacting) to being I/O bound.This will require roughly 2x the memory, to allow the reader threads to work ahead of the merge stage. (I.e. for each input sstable you will have up to one row in a queue waiting to be merged, and the reader thread working on the next.) Seems quite reasonable on that front. You'll also want a small queue size for the serialize-merged-rows executor.Multithreaded compaction should be either on or off. It doesn't make sense to try to do things halfway (by doing the reads with athreadpool whose size you can grow/shrink, for instance): we still have compaction threads tuned to low priority, by default, so the impact on the rest of the system won't be very different. Nor do we expect to have so many input sstables that we lose a lot in context switching between reader threads.IMO it's acceptable to punt completely on rows that are larger than memory, and fall back to the old non-parallel code there. I don't see any sane way to parallelize large-row compactions.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.EchoedRow.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionIterable.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.AbstractCompactedRow.java</file>
      <file type="M">src.java.org.apache.cassandra.db.columniterator.IColumnIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">test.unit.org.apache.cassandra.service.AntiEntropyServiceTestAbstract.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.PrecompactedRow.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LazilyCompactedRow.java</file>
      <file type="M">src.java.org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.java</file>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">test.unit.org.apache.cassandra.io.LazilyCompactedRowTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionTask.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionIterator.java</file>
      <file type="M">test.unit.org.apache.cassandra.utils.BytesReadTrackerTest.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.BytesReadTracker.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.IncomingStreamReader.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableIdentityIterator.java</file>
    </fixedFiles>
  </bug>
  <bug id="2914" opendate="2011-7-18 00:00:00" fixdate="2011-7-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Simplify HH to always store hints on the coordinator</summary>
      <description>Moved from CASSANDRA-2045:Since we're storing the full mutation post-2045, there's no benefit to be gained from storing the hint on the replica node, only an increase in complexity. Let's switch it to always store hints on the coordinator instead.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.locator.AbstractReplicationStrategy.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowMutation.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2916" opendate="2011-7-18 00:00:00" fixdate="2011-7-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Streaming estimatedKey calculation should never be 0</summary>
      <description>The new in-streaming SSTable rebuild uses the sender's estimated key calculation to determine which codepath to take: in some cases, samples can result in an estimated key count of 0.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.streaming.StreamingTransferTest.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.IncomingStreamReader.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableReader.java</file>
    </fixedFiles>
  </bug>
  <bug id="292" opendate="2009-7-14 00:00:00" fixdate="2009-8-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cassandra should be runnable as a Windows service</summary>
      <description>In addition to the tarballs already distributed, Cassandra should distribute an exe installer that can install the Cassandra daemon as a Windows service.Tomcat's NSIS scripts can be used as a reference for the installer: http://svn.apache.org/repos/asf/tomcat/trunk/res/Apache Commons Daemon's procrun would probably be used to create the Win32 service: http://commons.apache.org/daemon/procrun.html</description>
      <version>1.0.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraDaemon.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cassandra.bat</file>
    </fixedFiles>
  </bug>
  <bug id="2936" opendate="2011-7-21 00:00:00" fixdate="2011-9-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>improve dependency situation between JDBC driver and Cassandra</summary>
      <description>The JDBC jar currently depends on the apache-cassandra-$version jar, despite the fact that it only (directly) uses a handful of Cassandra's classes. In a perfect world, we'd break those classes out into their own jar which both the JDBC driver and Cassandra (ala apache-cassandra-$version.jar) could depend on. However, the classes used directly don't fall out to anything that makes much sense organizationally (short of creating a apache-cassandra-misc-$version.jar), and the situation only gets worse when you take into account all of the transitive dependencies.See CASSANDRA-2761 for more background, in particular (this and this)</description>
      <version>1.0.0</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.marshal.RoundTripTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.CounterColumnType.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.term.CounterColumnTerm.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.term.AbstractTerm.java</file>
      <file type="M">build.xml</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.ReversedType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.LocalByPartionerType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.AbstractUUIDType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.AbstractType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.AbstractCompositeType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.AbstractCommutativeType.java</file>
      <file type="M">drivers.java.test.org.apache.cassandra.cql.JdbcDriverTest.java</file>
      <file type="M">drivers.java.src.org.apache.cassandra.cql.jdbc.TypedColumn.java</file>
      <file type="M">drivers.java.src.org.apache.cassandra.cql.jdbc.CResultSet.java</file>
      <file type="M">drivers.java.src.org.apache.cassandra.cql.jdbc.ColumnDecoder.java</file>
      <file type="M">drivers.java.src.org.apache.cassandra.cql.jdbc.CassandraPreparedStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.UUIDType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.UTF8Type.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.TimeUUIDType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.LongType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.LexicalUUIDType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.IntegerType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.FloatType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.DoubleType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.DateType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.BytesType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.BooleanType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.AsciiType.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.term.DateTerm.java</file>
    </fixedFiles>
  </bug>
  <bug id="2942" opendate="2011-7-23 00:00:00" fixdate="2011-8-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Dropped columnfamilies can leave orphaned data files that do not get cleared on restart</summary>
      <description>Bring up 3 node cluster From node1: Run Stress Tool stress --num-keys=10 --columns=10 --consistency-level=ALL --average-size-values --replication-factor=3 --nodes=node1,node2 Shutdown node3 From node1: drop the Standard1 CF in Keyspace1 Shutdown node2 and node3 Bring up node1 and node2. Check that the Standard1 files are gone.ls -al /var/lib/cassandra/data/Keyspace1/ Bring up node3. The log file shows the drop column family occurs INFO 00:51:25,742 Applying migration 9a76f880-b4c5-11e0-0000-8901a7c5c9ce Drop column family: Keyspace1.Standard1 Restart node3 to clear out dropped tables from the filesystemroot@cathy3:~/cass-0.8/bin# ls -al /var/lib/cassandra/data/Keyspace1/total 36drwxr-xr-x 3 root root 4096 Jul 23 00:51 .drwxr-xr-x 6 root root 4096 Jul 23 00:48 ..-rw-r--r-- 1 root root 0 Jul 23 00:51 Standard1-g-1-Compacted-rw-r--r-- 2 root root 5770 Jul 23 00:51 Standard1-g-1-Data.db-rw-r--r-- 2 root root 32 Jul 23 00:51 Standard1-g-1-Filter.db-rw-r--r-- 2 root root 120 Jul 23 00:51 Standard1-g-1-Index.db-rw-r--r-- 2 root root 4276 Jul 23 00:51 Standard1-g-1-Statistics.dbdrwxr-xr-x 3 root root 4096 Jul 23 00:51 snapshotsBug: The files for Standard1 are orphaned on node3</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.io.util.FileUtils.java</file>
      <file type="M">src.java.org.apache.cassandra.io.DeletionService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLog.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2945" opendate="2011-7-25 00:00:00" fixdate="2011-7-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add test for counter merge shard path</summary>
      <description>This is a relevant test and this happens to have a corner case for CASSANDRA-2843.</description>
      <version>1.0.0</version>
      <fixedVersion>Legacy/Testing</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.SchemaLoader.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.NodeId.java</file>
    </fixedFiles>
  </bug>
  <bug id="3001" opendate="2011-8-8 00:00:00" fixdate="2011-8-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make the compression algorithm and chunk length configurable</summary>
      <description></description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.Session.java</file>
      <file type="M">test.unit.org.apache.cassandra.SchemaLoader.java</file>
      <file type="M">test.unit.org.apache.cassandra.io.compress.CompressedRandomAccessReaderTest.java</file>
      <file type="M">src.resources.org.apache.cassandra.cli.CliHelp.yaml</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.io.compress.CompressionMetadata.java</file>
      <file type="M">src.java.org.apache.cassandra.io.compress.CompressedSequentialWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.io.compress.CompressedRandomAccessReader.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">src.java.org.apache.cassandra.cli.CliClient.java</file>
      <file type="M">src.avro.internode.genavro</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.UnavailableException.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.TokenRange.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.TimedOutException.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.SuperColumn.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.SliceRange.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.SlicePredicate.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.SchemaDisagreementException.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.NotFoundException.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.Mutation.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.KsDef.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.KeySlice.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.KeyRange.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.KeyCount.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.InvalidRequestException.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.IndexExpression.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.IndexClause.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.Deletion.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.CqlRow.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.CqlResult.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.CounterSuperColumn.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.CounterColumn.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.ColumnPath.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.ColumnParent.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.ColumnOrSuperColumn.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.ColumnDef.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.Column.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.CfDef.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.Cassandra.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.AuthorizationException.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.AuthenticationRequest.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.AuthenticationException.java</file>
      <file type="M">interface.cassandra.thrift</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3003" opendate="2011-8-8 00:00:00" fixdate="2011-9-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Trunk single-pass streaming doesn&amp;#39;t handle large row correctly</summary>
      <description>For normal column family, trunk streaming always buffer the whole row into memory. In uses ColumnFamily.serializer().deserializeColumns(in, cf, true, true);on the input bytes.We must avoid this for rows that don't fit in the inMemoryLimit.Note that for regular column families, for a given row, there is actually no need to even recreate the bloom filter of column index, nor to deserialize the columns. It is enough to filter the key and row size to feed the index writer, but then simply dump the rest on disk directly. This would make streaming more efficient, avoid a lot of object creation and avoid the pitfall of big rows.Counters column family are unfortunately trickier, because each column needs to be deserialized (to mark them as 'fromRemote'). However, we don't need to do the double pass of LazilyCompactedRow for that. We can simply use a SSTableIdentityIterator and deserialize/reserialize input as it comes.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.streaming.IncomingStreamReader.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.db.CounterColumn.java</file>
      <file type="M">src.java.org.apache.cassandra.db.context.CounterContext.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3015" opendate="2011-8-10 00:00:00" fixdate="2011-9-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Streams Compression</summary>
      <description>Although we have CASSANDRA-47 for on-disk the code used for streaming actually sends un-compressed blocks over the wire. I propose we compress this data.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.streaming.IncomingStreamReader.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.FileStreamTask.java</file>
      <file type="M">src.java.org.apache.cassandra.net.IncomingTcpConnection.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3031" opendate="2011-8-13 00:00:00" fixdate="2011-9-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add 4 byte integer type</summary>
      <description>Cassandra currently lacks support for 4byte fixed size integer data type. Java API Hector and C libcassandra likes to serialize integers as 4 bytes in network order. Problem is that you cant use cassandra-cli to manipulate stored rows. Compatibility with other applications using api following cassandra integer encoding standard is problematic too.Because adding new datatype/validator is fairly simple I recommend to add int4 data type. Compatibility with hector is important because it is most used Java cassandra api and lot of applications are using it.This problem was discussed several times already http://comments.gmane.org/gmane.comp.db.hector.user/2125https://issues.apache.org/jira/browse/CASSANDRA-2585It would be nice to have compatibility with cassandra-cli and other applications without rewriting hector apps.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.Util.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.TableTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.RemoveSuperColumnTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.RemoveSubColumnTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.marshal.TypeValidationTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.marshal.TypeCompareTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.marshal.RoundTripTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.ColumnFamilyStoreTest.java</file>
      <file type="M">src.resources.org.apache.cassandra.cli.CliHelp.yaml</file>
      <file type="M">src.java.org.apache.cassandra.cql.jdbc.TypesMap.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.jdbc.JdbcLong.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.CreateColumnFamilyStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cli.CliClient.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">doc.cql.CQL.textile</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3032" opendate="2011-8-14 00:00:00" fixdate="2011-8-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>clean up KSMetadata, CFMetadata</summary>
      <description>There are too many conversion methods between Thrift and Avro and Native, which is a potential source of bugs.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">test.unit.org.apache.cassandra.thrift.ThriftValidationTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.SchemaLoader.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.DefsTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.config.DatabaseDescriptorTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.config.ColumnDefinitionTest.java</file>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraServer.java</file>
      <file type="M">src.java.org.apache.cassandra.db.migration.UpdateKeyspace.java</file>
      <file type="M">src.java.org.apache.cassandra.db.migration.UpdateColumnFamily.java</file>
      <file type="M">src.java.org.apache.cassandra.db.migration.Migration.java</file>
      <file type="M">src.java.org.apache.cassandra.db.migration.AddKeyspace.java</file>
      <file type="M">src.java.org.apache.cassandra.db.migration.AddColumnFamily.java</file>
      <file type="M">src.java.org.apache.cassandra.db.DefsTable.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.QueryProcessor.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.DropIndexStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.AlterTableStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.config.KSMetaData.java</file>
      <file type="M">src.java.org.apache.cassandra.config.ColumnDefinition.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3033" opendate="2011-8-14 00:00:00" fixdate="2011-8-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[patch] ensure full read of chuck</summary>
      <description>code ignores result of RandomAccessFile.read which could potentially return less bytes than was requested. Code loops to read all bytes desired.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.compress.CompressedSequentialWriter.java</file>
    </fixedFiles>
  </bug>
  <bug id="3034" opendate="2011-8-14 00:00:00" fixdate="2011-8-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[patch] BufferedInputStream.skip only skips bytes that are in the buffer, so keep skipping until done</summary>
      <description>code calls skip(remaining) without checking result. Skip isn't guaranteed to skip what you requested, especially BufferedInputStream, so keep skipping until the remaining bytes is 0.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.net.IncomingTcpConnection.java</file>
    </fixedFiles>
  </bug>
  <bug id="3046" opendate="2011-8-17 00:00:00" fixdate="2011-8-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[patch] No need to use .equals on enums, just opens up chance of NPE</summary>
      <description>pretty trivial patch that change enum1.equals(enum2) into enum1 == enum2, as .equals isn't needed, and just opens up the possibility of NPEs where == handles them correctly.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.thrift.ThriftValidation.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.FloatType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.SecondaryIndex.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.keys.KeysSearcher.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.WhereClause.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.Relation.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.QueryProcessor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.ColumnDefinition.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.AutoSavingCache.java</file>
    </fixedFiles>
  </bug>
  <bug id="3063" opendate="2011-8-19 00:00:00" fixdate="2011-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[patch] fix some obvious javadoc problems</summary>
      <description>bad tags, invalid parms, etc.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.utils.MerkleTree.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.EstimatedHistogram.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageServiceMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.service.AntiEntropyService.java</file>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
      <file type="M">src.java.org.apache.cassandra.locator.AbstractNetworkTopologySnitch.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.AbstractSSTableSimpleWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.IPartitioner.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Table.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.AbstractType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.context.IContext.java</file>
      <file type="M">src.java.org.apache.cassandra.db.context.CounterContext.java</file>
      <file type="M">src.java.org.apache.cassandra.db.columniterator.SSTableSliceIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="3064" opendate="2011-8-19 00:00:00" fixdate="2011-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add query-by-column mode to stress.java</summary>
      <description>This is necessary to be able to demonstrate CASSANDRA-2498 as well as any other differences in slice-based vs name-based queries.</description>
      <version>1.0.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.Session.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.operations.Reader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3068" opendate="2011-8-22 00:00:00" fixdate="2011-9-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix count()</summary>
      <description>count() has been broken since it was introduced in CASSANDRA-1704.</description>
      <version>1.0.0</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.system.test.cql.py</file>
      <file type="M">src.java.org.apache.cassandra.cql.QueryProcessor.java</file>
      <file type="M">doc.cql.CQL.textile</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3080" opendate="2011-8-25 00:00:00" fixdate="2011-9-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add throttling for internode streaming</summary>
      <description>Cassandra does (mostly) sequential reads from disk to send data to other nodes, which means that it is easily possible to stream upwards of 100 MB/s per source node.To avoid affecting service, we should add streaming throttling across all streams in the outbound direction, preferably configurable from JMX, and with `nodetool netstats` integration.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.streaming.FileStreamTask.java</file>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionIterable.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionController.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3081" opendate="2011-8-26 00:00:00" fixdate="2011-8-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cassandra cli strategy options should be a hash not an array of hashes</summary>
      <description>Currently strategy options are specified as an array of hashes:create keyspace Keyspace2 with placement_strategy = 'org.apache.cassandra.locator.SimpleStrategy' and strategy_options = [{replication_factor:4}];this should be:create keyspace Keyspace2 with placement_strategy = 'org.apache.cassandra.locator.SimpleStrategy' and strategy_options = {replication_factor:4};Also, for column_metadata we need sub hashes for CASSANDRA-3078</description>
      <version>1.0.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cli.CliTest.java</file>
      <file type="M">src.resources.org.apache.cassandra.cli.CliHelp.yaml</file>
      <file type="M">src.java.org.apache.cassandra.cli.CliClient.java</file>
      <file type="M">src.java.org.apache.cassandra.cli.Cli.g</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3085" opendate="2011-8-26 00:00:00" fixdate="2011-8-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Race condition in sstable reference counting</summary>
      <description>DataTracker gives us an atomic View of memtable/sstables, but acquiring references is not atomic. So it is possible to acquire references to an SSTableReader object that is no longer valid, as in this example:View V contains sstables {A, B}. We attempt a read in thread T using this View.Meanwhile, A and B are compacted to {C}, yielding View W. No references exist to A or B so they are cleaned up.Back in thread T we acquire references to A and B. This does not cause an error, but it will when we attempt to read from them next.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.RowIteratorFactory.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">src.java.org.apache.cassandra.db.CollationController.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3104" opendate="2011-8-30 00:00:00" fixdate="2011-8-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>remove compaction_thread_priority setting</summary>
      <description>compaction_throughput_mb_per_sec is a more effective throttle on compaction.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.HintedHandOffManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3106" opendate="2011-8-30 00:00:00" fixdate="2011-8-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>getRangeToEndpointMap() method removed</summary>
      <description>When getRangeToRPCAddress was added, getRangeToEndpointMap was removed, however, both are useful. We should add it back.</description>
      <version>1.0.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageServiceMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
    </fixedFiles>
  </bug>
  <bug id="3119" opendate="2011-9-1 00:00:00" fixdate="2011-9-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cli syntax for creating keyspace is inconsistent in 1.0</summary>
      <description>In 0.8, to create a keyspace you could do:create keyspace test with placement_strategy = 'org.apache.cassandra.locator.SimpleStrategy' and strategy_options = [{replication_factor:3}]In current trunk, if you try that, you get back "null". Turns out this is because the syntax for strategy_options has changed and you should not use the brackets, i.e:strategy_options = {replication_factor:3}(and note that reversely, this syntax doesn't work in 0.8).I'm not sure what motivated that change but this is very user unfriendly. The help does correctly mention the new syntax, but it is the kind of changes that takes you 5 minutes to notice. It will also break people scripts for no good reason that I can see.We should either: revert to the old syntax support both the new and old syntax at least print a meaningful error message when the old syntax is usedImho, the last solution is by far the worst solution.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cli.CliTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cli.CliClient.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3137" opendate="2011-9-5 00:00:00" fixdate="2011-10-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement wrapping intersections for ConfigHelper&amp;#39;s InputKeyRange</summary>
      <description>Before there was no support for multiple intersections between the split's range and the job's configured range.After CASSANDRA-3108 it is now possible.</description>
      <version>0.8.7,1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.hadoop.ColumnFamilyInputFormat.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3144" opendate="2011-9-6 00:00:00" fixdate="2011-9-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>trunk is unable to participate with an 0.8 ring, again</summary>
      <description>Title pretty much says it all, looks like a rehash of CASSANDRA-2818 to some degree.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.net.OutboundTcpConnection.java</file>
    </fixedFiles>
  </bug>
  <bug id="3148" opendate="2011-9-7 00:00:00" fixdate="2011-9-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use TreeMap backed column families for the SSTable simple writers</summary>
      <description>SSTable*SimpleWriter classes are not intended to be used concurrently (and indeed they are not thread safe), so there is no point in using CLSM backed column families.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.ArrayBackedSortedColumnsTest.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableSimpleWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableSimpleUnsortedWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ThreadSafeSortedColumns.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowMutation.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Row.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ReadResponse.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilySerializer.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ArrayBackedSortedColumns.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3156" opendate="2011-9-8 00:00:00" fixdate="2011-9-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>assertion error in RowRepairResolver</summary>
      <description>Only seems to happen on a coordinator who does not have a copy of the data:DEBUG 03:15:59,866 Processing response on a callback from 3840@/10.179.64.227DEBUG 03:15:59,866 Preprocessed data responseDEBUG 03:15:59,866 Processing response on a callback from 3841@/10.179.111.137DEBUG 03:15:59,866 Preprocessed digest responseDEBUG 03:15:59,865 Processing response on a callback from 3837@/10.179.111.137DEBUG 03:15:59,865 Preprocessed data responseDEBUG 03:15:59,865 Preprocessed data responseDEBUG 03:15:59,867 Preprocessed digest responseDEBUG 03:15:59,867 resolving 2 responsesERROR 03:15:59,866 Fatal exception in thread Thread&amp;#91;ReadRepairStage:526,5,main&amp;#93;java.lang.AssertionError at org.apache.cassandra.service.RowRepairResolver.resolve(RowRepairResolver.java:77) at org.apache.cassandra.service.AsyncRepairCallback$1.runMayThrow(AsyncRepairCallback.java:54) at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:662)ERROR 03:15:59,866 Fatal exception in thread Thread&amp;#91;ReadRepairStage:525,5,main&amp;#93;java.lang.AssertionError at org.apache.cassandra.service.RowRepairResolver.resolve(RowRepairResolver.java:77) at org.apache.cassandra.service.AsyncRepairCallback$1.runMayThrow(AsyncRepairCallback.java:54) at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:662)ERROR 03:15:59,867 Fatal exception in thread Thread&amp;#91;ReadRepairStage:528,5,main&amp;#93;java.lang.AssertionError at org.apache.cassandra.service.RowRepairResolver.resolve(RowRepairResolver.java:77) at org.apache.cassandra.service.AsyncRepairCallback$1.runMayThrow(AsyncRepairCallback.java:54) at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:662)DEBUG 03:15:59,867 resolving 2 responsesDEBUG 03:15:59,867 resolving 2 responsesDEBUG 03:15:59,867 resolving 2 responses</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.ReadVerbHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="3157" opendate="2011-9-8 00:00:00" fixdate="2011-9-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>After a "short read", the wrong read command may be used</summary>
      <description>In fetchRows, there is this code: for (int i = 0; i &lt; commandsToSend.size(); i++) { ReadCallback&lt;Row&gt; handler = readCallbacks.get(i); ReadCommand command = commands.get(i);On the first iteration of fetchRows, commands == commandsToSend so this is ok, but on a short read, commandsToSend will only contain the command to retry so we'll pick up the wrong command on the last line.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3159" opendate="2011-9-8 00:00:00" fixdate="2011-9-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Multiple classpath entries in the cassandra-all.jar</summary>
      <description>from CASSANDRA-2936Sep 8, 2011 8:47:45 AM java.util.jar.Attributes readWARNING: Duplicate name in Manifest: Class-Path.Ensure that the manifest does not have duplicate entries, andthat blank lines separate individual sections in both yourmanifest and in the META-INF/MANIFEST.MF entry in the jar file.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3160" opendate="2011-9-8 00:00:00" fixdate="2011-9-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>PIG_OPTS bash variable interpolation doesn&amp;#39;t work correctly when PIG_OPTS is set in the environment.</summary>
      <description>PIG_OPTS bash variable interpolation doesn't work correctly when PIG_OPTS is set in the environment due to variable preceding quotes.</description>
      <version>0.8.6,1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">contrib.pig.bin.pig.cassandra</file>
    </fixedFiles>
  </bug>
  <bug id="3161" opendate="2011-9-8 00:00:00" fixdate="2011-9-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>clean up read path</summary>
      <description>As CASSANDRA-3156, CASSANDRA-3158, CASSANDRA-3157 show, the read path has gotten a little crufty, especially with the introduction of short read protection. Time for some cleanup to reduce the chance of bugs and to make troubleshooting easier when we do have one.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.service.RowRepairResolver.java</file>
      <file type="M">src.java.org.apache.cassandra.service.RowDigestResolver.java</file>
      <file type="M">src.java.org.apache.cassandra.service.RangeSliceResponseResolver.java</file>
    </fixedFiles>
  </bug>
  <bug id="3163" opendate="2011-9-8 00:00:00" fixdate="2011-9-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>SlabAllocator OOMs much faster than HeapAllocator</summary>
      <description>SlabAllocator will OOM with stress at around 5.5M rows, which in this configuration is roughly 3.3M rows per node. Reverting to the HeapAllocator allowed all 10M rows to finish. Examining the SA heap dump in MAT just shows ~98% of the heap is in 'remainder'</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableReader.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTable.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.IndexSummary.java</file>
      <file type="M">src.java.org.apache.cassandra.db.MeteredFlusher.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3179" opendate="2011-9-12 00:00:00" fixdate="2011-9-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>JVM segfaults</summary>
      <description>Both with and without compressed OOPs enabled. Seems to mostly happen during compaction+reads. I'll attach some hs_err files shortly.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.util.MappedFileDataInput.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3181" opendate="2011-9-12 00:00:00" fixdate="2011-9-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compaction fails to occur</summary>
      <description>Compaction just stops running at some point. To repro, insert like 20M rows with a 1G heap and you'll get around 1k sstables. Restarting doesn't help, you have to invoke a major to get anything to happen.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.HintedHandOffManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.AutoSavingCache.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LeveledCompactionStrategy.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.AbstractCompactionStrategy.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3182" opendate="2011-9-12 00:00:00" fixdate="2011-9-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove special-cased maximum on sstables-to-compact for leveled strategy</summary>
      <description>With CASSANDRA-3171 fixed we don't need to be scared of large numbers of compaction candidates anymore.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LeveledManifest.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3184" opendate="2011-9-12 00:00:00" fixdate="2011-9-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update the versions that are referenced in the generated POMs so that they match the versions in svn&amp;#39;s lib folder</summary>
      <description>Update the versions before the release so that the release uses the same dependencies for Maven downloaded dependencies</description>
      <version>1.0.0</version>
      <fixedVersion>Packaging</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3190" opendate="2011-9-12 00:00:00" fixdate="2011-9-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix backwards compatibilty for cql memtable properties</summary>
      <description>Removed memtable_flush_after_mins in CASSANDRA-2183 instead of making it a no-op.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql.CreateColumnFamilyStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3193" opendate="2011-9-13 00:00:00" fixdate="2011-9-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Gossip teardown causes test failures</summary>
      <description>Just look at any recent jenkins or buildbot attempt for the semi-nonsensical NBHM.remove NPE</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.net.IncomingTcpConnection.java</file>
      <file type="M">src.java.org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.java</file>
    </fixedFiles>
  </bug>
  <bug id="3201" opendate="2011-9-13 00:00:00" fixdate="2011-9-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>When a mmap fails, Cassandra should exit.</summary>
      <description>When a mmap fails, Cassandra should exit. See https://wiki.apache.org/cassandra/ArchitectureInternals#line-60Here is an example stack trace:ERROR 17:11:36,258 Fatal exception in thread Thread&amp;#91;FlushWriter:2003,5,main&amp;#93;java.io.IOError: java.io.IOException: Map failed at org.apache.cassandra.io.util.MmappedSegmentedFile$Builder.createSegments(MmappedSegmentedFile.java:170) at org.apache.cassandra.io.util.MmappedSegmentedFile$Builder.complete(MmappedSegmentedFile.java:147) at org.apache.cassandra.io.sstable.SSTableWriter.closeAndOpenReader(SSTableWriter.java:194) at org.apache.cassandra.io.sstable.SSTableWriter.closeAndOpenReader(SSTableWriter.java:173) at org.apache.cassandra.db.Memtable.writeSortedContents(Memtable.java:253) at org.apache.cassandra.db.Memtable.access$400(Memtable.java:49) at org.apache.cassandra.db.Memtable$3.runMayThrow(Memtable.java:270) at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:662)Caused by: java.io.IOException: Map failed at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:748) at org.apache.cassandra.io.util.MmappedSegmentedFile$Builder.createSegments(MmappedSegmentedFile.java:162) ... 10 moreCaused by: java.lang.OutOfMemoryError: Map failed at sun.nio.ch.FileChannelImpl.map0(Native Method) at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:745) ... 11 more</description>
      <version>0.8.7,1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.AbstractCassandraDaemon.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3204" opendate="2011-9-14 00:00:00" fixdate="2011-9-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>stress cannot set the compaction strategy</summary>
      <description>stress can't set the compaction strategy, so testing leveldb-style compaction is more difficult than it should be, especially with lots of cluster setup/teardown.</description>
      <version>1.0.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.Session.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3216" opendate="2011-9-16 00:00:00" fixdate="2011-9-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>A streamOutSession keeps sstables references forever if the remote end dies</summary>
      <description>A streamOutSession acquire a reference on the sstable it will stream and release them as soon as each sstable has been fully streamed. However, since a stream session has currently no means to know when it failed, we'll keep references indefinitely (meaning until next restart) if their is a failure. One way a stream session could very easily fail is if the remote end dies. We must make sure we correctly release sstable references when that happens.Note that it won't be bulletproof, there is probably other means by which a streaming could fail: a bug in the code throwing an exception, no space left on the receiving end, etc... But those are unlikely enough that I propose to care only for the case of a node dying for now and leave the bullet-proofing to CASSANDRA-3112.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamOutSession.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3219" opendate="2011-9-16 00:00:00" fixdate="2011-9-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Nodes started at the same time end up with the same token</summary>
      <description>Since autoboostrap is defaulted to on when you start a cluster at once (http://screenr.com/5G6) you can end up with nodes being assigned the same token.INFO 17:34:55,688 Node /67.23.43.14 is now part of the cluster INFO 17:34:55,698 InetAddress /67.23.43.14 is now UP INFO 17:34:55,698 Nodes /67.23.43.14 and tjake2/67.23.43.15 have the same token 8823900603000512634329811229926543166. Ignoring /67.23.43.14 INFO 17:34:55,698 Node /98.129.220.182 is now part of the cluster INFO 17:34:55,698 InetAddress /98.129.220.182 is now UP INFO 17:34:55,698 Nodes /98.129.220.182 and tjake2/67.23.43.15 have the same token 8823900603000512634329811229926543166. Ignoring /98.129.220.182</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.BootStrapper.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3229" opendate="2011-9-19 00:00:00" fixdate="2011-9-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove ability to disable dynamic snitch entirely</summary>
      <description>We've moved dynamic snitch from "new, default to off" to "well tested, default to true," and it's time now to take the next step to "there is no reason to disable it, and keeping the option around just lets people shoot their foot off."</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3230" opendate="2011-9-19 00:00:00" fixdate="2011-9-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>clientutil jar missing from artifacts</summary>
      <description>The new clientutil jar is not being included in binary release artifacts</description>
      <version>1.0.0</version>
      <fixedVersion>Packaging</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3234" opendate="2011-9-20 00:00:00" fixdate="2011-9-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LeveledCompaction has several performance problems</summary>
      <description>Two main problems: BF size calculation doesn't take into account LCS breaking the output apart into "bite sized" sstables, so memory use is much higher than predicted ManyToMany merging is slow. At least part of this is from running the full reducer machinery against single input sources, which can be optimized away.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableIdentityIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionTask.java</file>
      <file type="M">src.java.org.apache.cassandra.db.IColumnContainer.java</file>
      <file type="M">src.java.org.apache.cassandra.db.IColumn.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.PrecompactedRow.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Column.java</file>
      <file type="M">src.java.org.apache.cassandra.db.AbstractColumnContainer.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LeveledManifest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LeveledCompactionStrategy.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionController.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.AbstractCompactionStrategy.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">test.unit.org.apache.cassandra.utils.MergeIteratorTest.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.MergeIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.service.RangeSliceResponseResolver.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.ReducingKeyIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowIteratorFactory.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.QueryFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.ParallelCompactionIterable.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LazilyCompactedRow.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionIterable.java</file>
    </fixedFiles>
  </bug>
  <bug id="3245" opendate="2011-9-23 00:00:00" fixdate="2011-9-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Don&amp;#39;t fail when numactl is installed, but NUMA policies are not supported</summary>
      <description>When numactl is installed but NUMA policies are not supported, trying to run cassandra gives only:numactl: This system does not support NUMA policy..and the startup script fails there.We should probably fail a little more gracefully. Possibly the best way to tell if numactl will work is by using:numactl --hardwarebut I don't have ready access to a machine with proper NUMA support at the moment so I can't check how easy it is to tell the difference in the output.It looks just as reliable (if possibly a bit more brittle) to check for the existence of the directory /sys/devices/system/node. If that directory doesn't exist, we shouldn't even try to use or run numactl.</description>
      <version>1.0.0</version>
      <fixedVersion>Packaging</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cassandra</file>
    </fixedFiles>
  </bug>
  <bug id="3247" opendate="2011-9-23 00:00:00" fixdate="2011-9-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>sstableloader ignores option doesn&amp;#39;t work correctly</summary>
      <description>The --ignores option is supposed to take an argument but it doesn't.</description>
      <version>0.8.7,1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.BulkLoader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3257" opendate="2011-9-25 00:00:00" fixdate="2011-9-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enabling SSL on a fairly light cluster leaks Open files.</summary>
      <description>To reproduce:Enable SSL encryption and let the server be idle for a day or so you will see the below....&amp;#91;vijay_tcasstest@vijay_tcass--1c-i-1568885c ~&amp;#93;$ /usr/sbin/lsof |grep -i cassandra-app.jks |wc -l ;date16333Sun Sep 25 17:23:29 UTC 2011&amp;#91;vijay_tcasstest@vijay_tcass--1c-i-1568885c ~&amp;#93;$ java -jar cmdline-jmxclient-0.10.3.jar - localhost:7501 java.lang:type=Memory gc&amp;#91;vijay_tcasstest@vijay_tcass--1c-i-1568885c ~&amp;#93;$ /usr/sbin/lsof |grep -i cassandra-app.jks |wc -l ;date64Sun Sep 25 17:23:53 UTC 2011&amp;#91;vijay_tcasstest@vijay_tcass--1c-i-1568885c ~&amp;#93;$ After running GC manually the issue goes away.</description>
      <version>0.8.7,1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.security.SSLFactory.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3259" opendate="2011-9-26 00:00:00" fixdate="2011-9-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace token leaves the old node state in tact causing problems in cli</summary>
      <description>in the replace token patch we dont evict the node from the Gossip which will leave the node lingering around and causes issues in cli (UNReachable nodes)As a part of the replace token if the token is replaced with another token we should remove the old nodes Gossip states.</description>
      <version>0.8.7,1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.Gossiper.java</file>
    </fixedFiles>
  </bug>
  <bug id="3266" opendate="2011-9-27 00:00:00" fixdate="2011-9-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>missed CQL term rename</summary>
      <description>The CQL grammar was missed in the rename of bytea to blob.</description>
      <version>1.0.0</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql.Cql.g</file>
    </fixedFiles>
  </bug>
  <bug id="3269" opendate="2011-9-28 00:00:00" fixdate="2011-10-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>possible early deletion of commit logs</summary>
      <description>I ran my cluster for about 2 days. the cluster has 2 nodes. I restarted one box several times, and the other one was always running. the one always running ended up accumulating 100GB of commit logs.this is 1.0.0 code from about Sept 15 in github. I kept the original setting for #commitlog_total_space_in_mb: 4096i.e. commented outhere is some sample of the output:rw-rr- 1 yyang yyang 134217857 2011-09-28 03:51 CommitLog-1317181834810.logrw-rr- 1 yyang yyang 134217869 2011-09-28 03:50 CommitLog-1317181764105.logrw-rr- 1 yyang yyang 134217783 2011-09-28 03:49 CommitLog-1317181694633.logrw-rr- 1 yyang yyang 134217750 2011-09-28 02:39 CommitLog-1317176955102.logyyang@ip-10-71-21-46:/mnt/cass/log/cassandra$ ls -lt /mnt/cass/lib//cassandra/commitlog/|wc -l727yyang@ip-10-71-21-46:/mnt/cass/log/cassandra$ du -s /mnt/cass/lib/cassandra/commitlog/ 95095316 /mnt/cass/lib/cassandra/commitlog/</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLogSegment.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="327" opendate="2009-7-30 00:00:00" fixdate="2009-8-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thrift interface needs a Ruby namespace</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">interface.cassandra.thrift</file>
    </fixedFiles>
  </bug>
  <bug id="3282" opendate="2011-9-30 00:00:00" fixdate="2011-9-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CLI does not support removing compression options from a ColumnFamily</summary>
      <description>This may be an issue with ThriftValidator as well - not accepting a null or empty compression properties map as a disable flag.</description>
      <version>1.0.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.resources.org.apache.cassandra.cli.CliHelp.yaml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3284" opendate="2011-9-30 00:00:00" fixdate="2011-9-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>help create column family refers to outdated fields</summary>
      <description>help create column family in cassandra-cli refers to old, unsupported options. memtable_operations: Number of operations in millions before the memtable is flushed. Default is memtable_throughput / 64 * 0.3 memtable_throughput: Maximum size in MB to let a memtable get to before it is flushed. Default is to use 1/16 the JVM heap size.</description>
      <version>1.0.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.resources.org.apache.cassandra.cli.CliHelp.yaml</file>
    </fixedFiles>
  </bug>
  <bug id="3285" opendate="2011-9-30 00:00:00" fixdate="2011-9-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bootstrap is broken in 1.0.0-rc1</summary>
      <description>The commit of #3219 introduced two bugs: the condition to bootstrap is that there are non-system tables instead, a not is missing, and the setToken() was wrongly push up into the "I'm not bootstrapping" block so a boostrapping node was left in the joining state.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3288" opendate="2011-9-30 00:00:00" fixdate="2011-10-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CfDef can default to an invalid id and fail during system_add_column_family</summary>
      <description>The line from this commit:https://github.com/apache/cassandra/commit/38e3e85b121ba6308ba3ceb26312d12ed0d609ec#L1R683Introduced an issue in that some clients, particularly Hector, will send a CfDef with an ID having been set to 0. Done via the CfDef#setId, the isSetId bit is flipped to true, causing error if schemaId of 0 already exists, which given the use case, is likely. Since we know the context of a system_create_column_family, this can be sidestepped by just stepping on whatever ID is there (irrelevant on a create anyway) with the value returned from: Schema.instance.nextCFId()</description>
      <version>1.0.0</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraServer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3289" opendate="2011-9-30 00:00:00" fixdate="2011-10-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>assert err on ArrayBackedSortedColumns.addColumn(ArrayBackedSortedColumns.java:126)</summary>
      <description>I have the following in trunk:RowKey: b=&gt; (column=a, value=38383838383838383838, timestamp=1317421952793000)=&gt; (column=d, value=617364646661736466, timestamp=1317420968944000)=&gt; (column=e, value=38383838383838383838, timestamp=1317421096152000)=&gt; (column=f, value=33343334333433343334, timestamp=1317422838818000)=&gt; (column=g, value=33343334333433343334, timestamp=1317422565130000)=&gt; (column=i, value=33343334333433343334, timestamp=1317422879258000)=&gt; (column=j, value=33343334333433343334, timestamp=1317422814873000)=&gt; (column=o, value=33343334333433343334, timestamp=1317422867106000)=&gt; (column=x, value=33343334333433343334, timestamp=1317422394097000)=&gt; (column=z, value=38383838383838383838, timestamp=1317421982057000)Keyspace: testks: Replication Strategy: org.apache.cassandra.locator.NetworkTopologyStrategy Durable Writes: true Options: &amp;#91;168:1&amp;#93; Column Families: ColumnFamily: testcf Key Validation Class: org.apache.cassandra.db.marshal.BytesType Default column value validator: org.apache.cassandra.db.marshal.BytesType Columns sorted by: org.apache.cassandra.db.marshal.BytesType Row cache size / save period in seconds / keys to save : 0.0/0/all Key cache size / save period in seconds: 200000.0/14400 GC grace seconds: 864000 Compaction min/max thresholds: 4/32 Read repair chance: 1.0 Replicate on write: true Built indexes: [] Compaction Strategy: org.apache.cassandra.db.compaction.SizeTieredCompactionStrategyevery thing is flushed to the sstables, but not in the same sstables, and the columns are in some what 'random' form:/var/lib/cassandra/data/testks/testcf-h-10-Data.db{"61": [&amp;#91;"0c","76",1317405903119000&amp;#93;, &amp;#91;"0d","76",1317405977002000&amp;#93;, &amp;#91;"7a","38383838383838383838",1317422276322000&amp;#93;],"62": [&amp;#91;"61","38383838383838383838",1317421952793000&amp;#93;, &amp;#91;"63","4e864303",1317421827329000,"d"&amp;#93;, &amp;#91;"64","617364646661736466",1317420968944000&amp;#93;, &amp;#91;"65","38383838383838383838",1317421096152000&amp;#93;, &amp;#91;"67","33343334333433343334",1317422565130000&amp;#93;, &amp;#91;"78","33343334333433343334",1317422394097000&amp;#93;, &amp;#91;"7a","38383838383838383838",1317421982057000&amp;#93;]}/var/lib/cassandra/data/testks/testcf-h-12-Data.db{"62": [&amp;#91;"6a","33343334333433343334",1317422814873000&amp;#93;]}/var/lib/cassandra/data/testks/testcf-h-13-Data.db{"62": [&amp;#91;"66","33343334333433343334",1317422838818000&amp;#93;]}/var/lib/cassandra/data/testks/testcf-h-14-Data.db{"62": [&amp;#91;"6f","33343334333433343334",1317422867106000&amp;#93;]}/var/lib/cassandra/data/testks/testcf-h-15-Data.db{"62": [&amp;#91;"69","33343334333433343334",1317422879258000&amp;#93;]}then i basically make a call to get key=b with all the column names (yes included column names that didn't exist to save time):ColumnFamilyResult&lt;String, String&gt; queryColumns = template.queryColumns("b", Arrays.asList("a","b","c","d","e","f","g","h","i","j","k","l","m","n","o","p","q","r","s","t","u","v","w","x","y","z"));(let me know if it would be easier to just upload the sstables to the ticket)</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">src.java.org.apache.cassandra.db.CollationController.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3291" opendate="2011-10-1 00:00:00" fixdate="2011-10-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>1.0 needs to clean out old-style hints</summary>
      <description>(Only marking this Minor because the manual workaround of deleting hint files is trivial.)</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.SystemTable.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3295" opendate="2011-10-3 00:00:00" fixdate="2011-10-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>reduce default heap size</summary>
      <description>With off-heap caching now the default and with auto-flushed memtables demonstrated to do a good job with smaller heaps, I think it's time to reduce heap sizes to decrease GC pause times.How does this sound? half the ram, up to 512MB, or 1/4 the ram, up to 4 GBi.e.:max(min(1/2 ram, 512MB), min(1/4 ram, 4GB))</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.cassandra-env.sh</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3297" opendate="2011-10-3 00:00:00" fixdate="2011-10-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>truncate can still result in data being replayed after a restart</summary>
      <description>Our first stab at fixing this was CASSANDRA-2950.</description>
      <version>0.8.8,1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.RecoveryManagerTruncateTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Truncation.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLogSegment.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLog.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3301" opendate="2011-10-4 00:00:00" fixdate="2011-10-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Java Stress Tool: COUNTER_GET reads from CounterSuper1 instead of SuperCounter1</summary>
      <description>Output from stress tool - COUNTER_ADD works fine bug COUNTER_GET does not./stress --operation=COUNTER_ADD --family-type=Super --num-keys=1 --consistency-level=TWO --replication-factor=3 --nodes=cathy1Unable to create stress keyspace: Keyspace already exists.total,interval_op_rate,interval_key_rate,avg_latency,elapsed_time1,0,0,0.0060,0END./stress --operation=COUNTER_GET --family-type=Super --num-keys=1 --consistency-level=QUORUM --nodes=cathy1total,interval_op_rate,interval_key_rate,avg_latency,elapsed_timeOperation [0] retried 10 times - error reading counter key 0 ((InvalidRequestException): unconfigured columnfamily CounterSuper1)0,0,0,NaN,0ENDThe CF created is called SuperCounter1 and not CounterSuper1 INFO 00:34:21,344 ColumnFamilyStore(table='Keyspace1', columnFamily='SuperCounter1') liveRatio is 9.167798032786886 (just-counted was 9.167798032786886). calculation took 1281ms for 9883 columns</description>
      <version>0.8.7,1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.operations.CounterGetter.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3304" opendate="2011-10-4 00:00:00" fixdate="2011-10-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Missing fields in show schema output</summary>
      <description>if you compare output of these 2 commands:show keyspacesKeyspace: test: Replication Strategy: org.apache.cassandra.locator.SimpleStrategy Durable Writes: true Options: &amp;#91;replication_factor:1&amp;#93; Column Families: ColumnFamily: sipdb "phone calls routing information" Key Validation Class: org.apache.cassandra.db.marshal.IntegerType Default column value validator: org.apache.cassandra.db.marshal.BytesType Columns sorted by: org.apache.cassandra.db.marshal.AsciiType Row cache size / save period in seconds / keys to save : 0.0/0/all Key cache size / save period in seconds: 0.0/0 GC grace seconds: 0 Compaction min/max thresholds: 4/32 Read repair chance: 0.0 Replicate on write: false Built indexes: [] Column Metadata: Column Name: kam Validation Class: org.apache.cassandra.db.marshal.AsciiType Compaction Strategy: org.apache.cassandra.db.compaction.SizeTieredCompactishow schemacreate column family sipdb with column_type = 'Standard' and comparator = 'AsciiType' and default_validation_class = 'BytesType' and key_validation_class = 'IntegerType' and rows_cached = 0.0 and row_cache_save_period = 0 and keys_cached = 0.0 and key_cache_save_period = 0 and read_repair_chance = 0.0 and gc_grace = 0 and min_compaction_threshold = 4 and max_compaction_threshold = 32 and replicate_on_write = false and row_cache_provider = 'ConcurrentLinkedHashCacheProvider' and comment = 'phone calls routing information' and column_metadata = [ {column_name : 'kam', validation_class : AsciiType}];You will discover that show schema is missing: 1. compaction strategy. 2. how many keys to save</description>
      <version>1.0.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cli.CliUtils.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.cassandra.cli.CliClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="3308" opendate="2011-10-4 00:00:00" fixdate="2011-10-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add compaction_thread_priority back</summary>
      <description>In CASSANDRA-3104, this was removed with the following reasoning:compaction_throughput_mb_per_sec is a more effective throttle on compaction.This turns out to be false in the majority of deployments. In many (if not most) situations, compaction is actually CPU bound, not IO bound, so multithreaded compaction is generally helpful, but the priority needs to be lowered in order to prevent it from stealing CPU used for reads/writes.Compaction is always CPU bound on both real hardware (sw raid0 with two SATA disks) and on a rackspace cloud server (though my understanding is they are back by a raid10 array underneath) however I suspect even a single drive is fast enough to handle the ~20MB/s that compaction is currently performing when unthrottled.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.HintedHandOffManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3309" opendate="2011-10-4 00:00:00" fixdate="2011-10-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Nodetool Doesnt close the open JMX connection causing it to leak Threads</summary>
      <description>When nodetool is used intensively we will see 1000's of "JMX server connection timeout"Fix is to close the connections when no longer needed.</description>
      <version>0.8.7,1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3318" opendate="2011-10-5 00:00:00" fixdate="2011-10-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unable to delete after running scrub</summary>
      <description>Another problem with sstable deletions on 1.0. Running scrub produces lot of unable to delete messages on windows.ERROR 16:16:37,562 Unable to delete \var\lib\cassandra\data\test\sipdb-h-711-Data.db (it will be removed on server restart; we'll also retry after GC) INFO 16:16:37,577 Scrub of SSTableReader(path='\var\lib\cassandra\data\test\sipdb-h-711-Data.db') complete: 48396 rows in new sstable and 0 empty (tombstoned)rows dropped</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3325" opendate="2011-10-6 00:00:00" fixdate="2011-10-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compaction degrades key cache stats</summary>
      <description>When "compaction_preheat_key_cache" is set to true, then during compaction, it keep tracks of cached keys to to re-cache their new position.It does this by calling the following method on every key of the compacted sstable :sstable.getCachedPosition(row.key)which also update cache stats, thus lowering hit rateBelow is an attached patch allowing to know if the key is cached, but without updating the stats.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableReader.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionTask.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3329" opendate="2011-10-7 00:00:00" fixdate="2011-10-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>make HSHA the default Thrift server</summary>
      <description>HSHA has been an option since 0.8.3 (CASSANDRA-1405) and has been stable. Besides making possible lots of unpooled connections such as are common in some environments (cough PHP), we've seen EC2 in particular have trouble with lots of threads (CASSANDRA-2170).</description>
      <version>1.0.0</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3338" opendate="2011-10-10 00:00:00" fixdate="2011-10-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Uncompressed sizes are used to estimate space for compaction of compressed sstables</summary>
      <description>We are using the uncompressed data size when estimating if we have enough to compact sstables. This means we can easily refuse compaction when there is clearly enough room to compact.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.util.SegmentedFile.java</file>
      <file type="M">src.java.org.apache.cassandra.io.util.CompressedSegmentedFile.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableReader.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTable.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3345" opendate="2011-10-11 00:00:00" fixdate="2011-10-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Repair still streams unnecessary sstables</summary>
      <description>Through rebases, CASSANDRA-2610 unfortunately got committed with the use of the wrong streaming method, the one that stream all the sstables of the keyspace.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamingRepairTask.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3913" opendate="2012-2-15 00:00:00" fixdate="2012-2-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Incorrect InetAddress equality test</summary>
      <description>CASSANDRA-3485 introduced some InetAddress checks using == instead of .equals.</description>
      <version>1.0.0,1.0.8</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.gms.Gossiper.java</file>
      <file type="M">src.java.org.apache.cassandra.db.SystemTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="4089" opendate="2012-3-27 00:00:00" fixdate="2012-3-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Typo fix: key_valiation_class -&gt; key_validation_class</summary>
      <description>There is a typo in the Cli help docs for the update column family command.</description>
      <version>1.0.0</version>
      <fixedVersion>Legacy/DocumentationandWebsite</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.resources.org.apache.cassandra.cli.CliHelp.yaml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="957" opendate="2010-4-5 00:00:00" fixdate="2010-9-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>convenience workflow for replacing dead node</summary>
      <description>Replacing a dead node with a new one is a common operation, but "nodetool removetoken" followed by bootstrap is inefficient (re-replicating data first to the remaining nodes, then to the new one) and manually bootstrapping to a token "just less than" the old one's, followed by "nodetool removetoken" is slightly painful and prone to manual errors.First question: how would you expose this in our tool ecosystem? It needs to be a startup-time option to the new node, so it can't be nodetool, and messing with the config xml definitely takes the "convenience" out. A one-off -DreplaceToken=XXY argument?</description>
      <version>1.0.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.service.MigrationManager.java</file>
      <file type="M">src.java.org.apache.cassandra.service.LoadBroadcaster.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.VersionedValue.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.Gossiper.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.EndpointState.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.BootStrapper.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowMutation.java</file>
      <file type="M">src.java.org.apache.cassandra.db.HintedHandOffManager.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">NEWS.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>
