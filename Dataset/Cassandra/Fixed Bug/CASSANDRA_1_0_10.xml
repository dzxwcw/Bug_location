<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="CASSANDRA">
  <bug id="3665" opendate="2011-12-23 00:00:00" fixdate="2011-4-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[patch] allow for clientutil.jar to be used without the base cassandra.jar for client applications</summary>
      <description>clientutil.jar can't be run from a client by itself without the presence of cassandra.jar which seems wrong. Added needed classes to run by itself.</description>
      <version>1.0.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.utils.UUIDGen.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.ByteBufferUtil.java</file>
      <file type="M">build.xml</file>
      <file type="M">test.unit.org.apache.cassandra.cql.jdbc.ClientUtilsTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="3732" opendate="2012-1-12 00:00:00" fixdate="2012-4-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update POM generation after migration to git</summary>
      <description></description>
      <version>1.0.10,1.1.0</version>
      <fixedVersion>Packaging</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3946" opendate="2012-2-22 00:00:00" fixdate="2012-4-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>BulkRecordWriter shouldn&amp;#39;t stream any empty data/index files that might be created at end of flush</summary>
      <description>If by chance, we flush sstables during BulkRecordWriter (we have seen it happen), I want to make sure we don't try to stream them.</description>
      <version>1.0.10,1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableSimpleWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableSimpleUnsortedWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.AbstractSSTableSimpleWriter.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4078" opendate="2012-3-23 00:00:00" fixdate="2012-4-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>StackOverflowError when upgrading to 1.0.8 from 0.8.10</summary>
      <description>HelloI am trying to upgrade our 1-node setup from 0.8.10 to 1.0.8 and seeing the following exception when starting up 1.0.8. We have been running 0.8.10 without any issues.Attached is the entire log file during startup of 1.0.8. There are 2 exceptions:1. StackOverflowError (line 2599)2. InstanceAlreadyExistsException (line 3632)I tried "run scrub" under 0.8.10 first, it did not help. Also, I tried dropping the column family which caused the exception, it just got the same exceptions from another column family.Thanks</description>
      <version>1.0.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.utils.IntervalTree.IntervalNode.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableReader.java</file>
    </fixedFiles>
  </bug>
  <bug id="4129" opendate="2012-4-6 00:00:00" fixdate="2012-4-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cannot create keyspace with specific keywords through cli</summary>
      <description>Keyspaces cannot be create when the keyspace name which are used as keywords in the cli, such as 'keyspace', 'family' etc., through CLI. Even when surrounding the keyspace with quotation does not solve the problem. However, such keyspaces can be created through other client such as Hector.This is similar to the issue CASSANDRA-3195, in which the column families could not be created. Similar to the solution of CASSANDRA-3195, using String keyspaceName = CliUtil.unescapeSQLString(statement.getChild(0).getText()) in executeAddKeySpace would solve the problem.</description>
      <version>1.0.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cli.CliCompiler.java</file>
      <file type="M">src.java.org.apache.cassandra.cli.CliClient.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4130" opendate="2012-4-6 00:00:00" fixdate="2012-4-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>update snitch documentation</summary>
      <description></description>
      <version>1.0.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.net.OutboundTcpConnectionPool.java</file>
      <file type="M">src.java.org.apache.cassandra.locator.Ec2MultiRegionSnitch.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4168" opendate="2012-4-18 00:00:00" fixdate="2012-5-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>"Setup" section of tools/stress/README.txt needs update</summary>
      <description>The README.txt file states "Run `ant` from the Cassandra source directory, then Run `ant` from the contrib/stress directory."The file needs to reflect the changes in the way stress is built.</description>
      <version>1.0.10,1.1.1</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="4188" opendate="2012-4-25 00:00:00" fixdate="2012-5-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>stress tool return a non-zero value when it fails</summary>
      <description>I'm using of stress in the dtests, and it would be great if I could tell based on the return code if stress succeeded or failed.</description>
      <version>1.0.10</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.StressAction.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.Stress.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4190" opendate="2012-4-25 00:00:00" fixdate="2012-4-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Apparent data loss using super columns and row cache via ConcurrentLinkedHashCacheProvider</summary>
      <description>Tested on a vanilla single-node cassandra 1.0.9 installation.When using super columns along with row caching via ConcurrentLinkedHashCacheProvider (default if no JNA available, or explicitly configured even if JNA available), there's what appears as transient data loss.Given this script executed in cassandra-cli:create keyspace Test;use Test;create column family Users with column_type='Super' and key_validation_class='UTF8Type' and comparator='UTF8Type' and subcomparator='UTF8Type' and default_validation_class='UTF8Type' and rows_cached=75000 and row_cache_provider='ConcurrentLinkedHashCacheProvider';set Users&amp;#91;&amp;#39;mina&amp;#39;&amp;#93;&amp;#91;&amp;#39;attrs&amp;#39;&amp;#93;&amp;#91;&amp;#39;name&amp;#39;&amp;#93; = 'Mina';get Users&amp;#91;&amp;#39;mina&amp;#39;&amp;#93;;set Users&amp;#91;&amp;#39;mina&amp;#39;&amp;#93;&amp;#91;&amp;#39;attrs&amp;#39;&amp;#93;&amp;#91;&amp;#39;country&amp;#39;&amp;#93; = 'Canada';get Users&amp;#91;&amp;#39;mina&amp;#39;&amp;#93;;set Users&amp;#91;&amp;#39;mina&amp;#39;&amp;#93;&amp;#91;&amp;#39;attrs&amp;#39;&amp;#93;&amp;#91;&amp;#39;region&amp;#39;&amp;#93; = 'Quebec';get Users&amp;#91;&amp;#39;mina&amp;#39;&amp;#93;;The output from the 3 gets above is as follows:=&gt; (super_column=attrs, (column=name, value=Mina, timestamp=1335377788441000))Returned 1 results.=&gt; (super_column=attrs, (column=name, value=Mina, timestamp=1335377788441000))Returned 1 results.=&gt; (super_column=attrs, (column=name, value=Mina, timestamp=1335377788441000))Returned 1 results.It's clear that the second and third set commands (country, region) are missing in the returned results.If the row cache is explicitly invalidated (in a second terminal, via `nodetool -h localhost invalidaterowcache Test Users`), the missing data springs to life on next 'get':&amp;#91;default@Test&amp;#93; get Users&amp;#91;&amp;#39;mina&amp;#39;&amp;#93;;=&gt; (super_column=attrs, (column=country, value=Canada, timestamp=1335377839592000) (column=name, value=Mina, timestamp=1335377788441000) (column=region, value=Quebec, timestamp=1335377871353000))Returned 1 results.From cursory checks, this does not to appear to happen with regular columns, nor with JNA enabled + SerializingCacheProvider.</description>
      <version>1.0.10,1.1.1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamily.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4205" opendate="2012-5-1 00:00:00" fixdate="2012-5-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>SSTables are not updated with max timestamp on upgradesstables/compaction leading to non-optimal performance.</summary>
      <description>We upgraded from 0.7.9 to 1.0.7 on a cluster with a heavy update load. After converting all the reads to named column reads instead of get_slice calls, we noticed that we still weren't getting the performance improvements implemented in CASSANDRA-2498. A single named column read was still touching multiple SSTables according to nodetool cfhistograms. To verify whether or not this was a reporting issue or a real issue, we ran multiple tests with stress and noticed that it worked as expected. After changing stress so that it ran the read/write test directly in the CF having issues (3 times stress &amp; flush), we noticed that stress also touched multiple SSTables (according to cfhistograms).So, the root of the problem is "something" left over from our pre-1.0 days. All SSTables were upgraded with upgradesstables, and have been written and compacted many times since the upgrade (4 months ago). The usage pattern for this CF is that it is constantly read and updated (overwritten), but no deletes. After discussing the problem with Brandon Williams on #cassandra, it seems the problem might be because a max timestamp has never been written for the old SSTables that were upgraded from pre 1.0. They have only been compacted, and the max timestamp is not recorded during compactions. A suggested fix is to special case this in upgradesstables so that a max timestamp always exists for all SSTables. 06:08 &lt; driftx&gt; thorkild_: tx. The thing is we don't record the max timestamp on compactions, but we can do it specially for upgradesstables.06:08 &lt; driftx&gt; so, nothing in... nothing out.06:10 &lt; thorkild_&gt; driftx: ah, so when you upgrade from before the metadata was written, and that data is only feed through upgradesstables and compactions -&gt; never properly written?06:10 &lt; thorkild_&gt; that makes sense.06:11 &lt; driftx&gt; right, we never create it, we just reuse it</description>
      <version>1.0.10,1.1.1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableMetadata.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.Descriptor.java</file>
    </fixedFiles>
  </bug>
</bugrepository>
