<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="CASSANDRA">
  <bug id="1143" opendate="2010-5-28 00:00:00" fixdate="2010-2-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Nodetool gives cryptic errors when given a nonexistent keyspace arg</summary>
      <description>I typoed the keyspace arg to 'nodetool repair', and got the following exception:/usr/local/src/cassandra/bin/nodetool --host node4 repair DocDbException in thread "main" java.lang.RuntimeException: No replica strategy configured for DocDb at org.apache.cassandra.service.StorageService.getReplicationStrategy(StorageService.java:246) at org.apache.cassandra.service.StorageService.constructRangeToEndPointMap(StorageService.java:466) at org.apache.cassandra.service.StorageService.getRangeToAddressMap(StorageService.java:452) at org.apache.cassandra.service.AntiEntropyService.getNeighbors(AntiEntropyService.java:145) at org.apache.cassandra.service.StorageService.forceTableRepair(StorageService.java:1075) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:93) at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:27) at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:208) at com.sun.jmx.mbeanserver.PerInterface.invoke(PerInterface.java:120) at com.sun.jmx.mbeanserver.MBeanSupport.invoke(MBeanSupport.java:262) at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.invoke(DefaultMBeanServerInterceptor.java:836) at com.sun.jmx.mbeanserver.JmxMBeanServer.invoke(JmxMBeanServer.java:761) at javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1427) at javax.management.remote.rmi.RMIConnectionImpl.access$200(RMIConnectionImpl.java:72) at javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1265) at javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1360) at javax.management.remote.rmi.RMIConnectionImpl.invoke(RMIConnectionImpl.java:788) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:305) at sun.rmi.transport.Transport$1.run(Transport.java:159) at java.security.AccessController.doPrivileged(Native Method) at sun.rmi.transport.Transport.serviceCall(Transport.java:155) at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:535) at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:790) at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:649) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:619)It would be better to report that the keyspace doesn't exist, rather than the keyspace doesn't have a replication strategy.</description>
      <version>0.7.3</version>
      <fixedVersion>Tool/nodetool</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
    </fixedFiles>
  </bug>
  <bug id="2020" opendate="2011-1-20 00:00:00" fixdate="2011-2-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>stress.java performance falls off heavily towards the end</summary>
      <description>This is due to threads completing towards the end, such that there aren't enough to fully stress the cluster. The main problem here is that stress.java is a straight port of stress.py, where each thread runs through some range until it's done, and the threads finish at different times (probably offset by jvm warmup time.) Instead, a producer/consumer model would work better.</description>
      <version>0.7.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">contrib.stress.src.org.apache.cassandra.contrib.stress.util.Range.java</file>
      <file type="M">contrib.stress.src.org.apache.cassandra.contrib.stress.util.OperationThread.java</file>
      <file type="M">contrib.stress.src.org.apache.cassandra.contrib.stress.Stress.java</file>
      <file type="M">contrib.stress.src.org.apache.cassandra.contrib.stress.Session.java</file>
      <file type="M">contrib.stress.src.org.apache.cassandra.contrib.stress.operations.Reader.java</file>
      <file type="M">contrib.stress.src.org.apache.cassandra.contrib.stress.operations.RangeSlicer.java</file>
      <file type="M">contrib.stress.src.org.apache.cassandra.contrib.stress.operations.MultiGetter.java</file>
      <file type="M">contrib.stress.src.org.apache.cassandra.contrib.stress.operations.Inserter.java</file>
      <file type="M">contrib.stress.src.org.apache.cassandra.contrib.stress.operations.IndexedRangeSlicer.java</file>
    </fixedFiles>
  </bug>
  <bug id="2047" opendate="2011-1-25 00:00:00" fixdate="2011-2-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Stress --keep-going should become --keep-trying</summary>
      <description>The --keep-going flag makes the stress tool drop messages that time out on the floor.I think it's more realistic (esp for a stress tool) to keep trying till this read/write succeeds.</description>
      <version>0.7.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">contrib.stress.src.org.apache.cassandra.contrib.stress.Session.java</file>
      <file type="M">contrib.stress.src.org.apache.cassandra.contrib.stress.operations.Reader.java</file>
      <file type="M">contrib.stress.src.org.apache.cassandra.contrib.stress.operations.RangeSlicer.java</file>
      <file type="M">contrib.stress.src.org.apache.cassandra.contrib.stress.operations.MultiGetter.java</file>
      <file type="M">contrib.stress.src.org.apache.cassandra.contrib.stress.operations.Inserter.java</file>
      <file type="M">contrib.stress.src.org.apache.cassandra.contrib.stress.operations.IndexedRangeSlicer.java</file>
    </fixedFiles>
  </bug>
  <bug id="2069" opendate="2011-1-27 00:00:00" fixdate="2011-2-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Read repair causes tremendous GC pressure</summary>
      <description>To reproduce: start a three node cluster, insert 1M rows with stress.java and rf=2. Take one down, delete its data, then bring it back up and issue 1M reads against it. After the run is done you will see at least 1 STW long enough to mark the node as dead, often 4 or 5.</description>
      <version>0.7.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.service.ReadResponseResolverTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.service.ConsistencyLevelTest.java</file>
      <file type="M">src.java.org.apache.cassandra.service.WriteResponseHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.service.TruncateResponseHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.service.RepairCallback.java</file>
      <file type="M">src.java.org.apache.cassandra.service.ReadResponseResolver.java</file>
      <file type="M">src.java.org.apache.cassandra.service.ReadCallback.java</file>
      <file type="M">src.java.org.apache.cassandra.service.RangeSliceResponseResolver.java</file>
      <file type="M">src.java.org.apache.cassandra.service.DatacenterSyncWriteResponseHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.service.DatacenterReadCallback.java</file>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
      <file type="M">src.java.org.apache.cassandra.net.IMessageCallback.java</file>
      <file type="M">src.java.org.apache.cassandra.net.AsyncResult.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.BootStrapper.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ReadCommand.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RangeSliceCommand.java</file>
      <file type="M">src.java.org.apache.cassandra.concurrent.StageManager.java</file>
      <file type="M">src.java.org.apache.cassandra.concurrent.Stage.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2100" opendate="2011-2-2 00:00:00" fixdate="2011-2-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Restart required to change cache_save_period</summary>
      <description>The cache_save_period is set in the schema for each column family. However this value is only checked when a node starts up so changing this value isn't really dynamic.We should actually change this when the schema changes instead of having to restart.</description>
      <version>0.7.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStoreMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2107" opendate="2011-2-4 00:00:00" fixdate="2011-2-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>MessageDigests are created in several places, centralize the creation and error handling</summary>
      <description>MessageDigest.getInstance("SomeAlg") throws NoSuchAlgorithm exception (a checked exception). This is annoying as it causes everyone that uses standard algs like MD5 to surround their code in try/catch. We should concentrate the creation in one method that doesn't raise an exception (i.e. catches NoSuchAlgorithm and raises a RuntimeException) just to clean the code up a little.</description>
      <version>0.7.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.utils.UUIDGen.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.GuidGenerator.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.FBUtilities.java</file>
      <file type="M">src.java.org.apache.cassandra.service.AntiEntropyService.java</file>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamily.java</file>
      <file type="M">src.java.org.apache.cassandra.auth.SimpleAuthenticator.java</file>
      <file type="M">contrib.stress.src.org.apache.cassandra.contrib.stress.util.OperationThread.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2115" opendate="2011-2-5 00:00:00" fixdate="2011-2-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Keep endpoint state until aVeryLongTime</summary>
      <description>In CASSANDRA-2072 we changed the gossiper so it holds onto endpoint state until QUARANTINE_DELAY has elapsed. However, if node X is leaving and node Y goes down and stays down longer than QUARANTINE_DELAY after X has left, Y will return thinking X is still a member of the cluster. Instead, let's hold onto the endpoint state even longer, until aVeryLongTime which is currently set to 3 days.</description>
      <version>0.7.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.gms.Gossiper.java</file>
    </fixedFiles>
  </bug>
  <bug id="2137" opendate="2011-2-8 00:00:00" fixdate="2011-2-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>stress.java should have a way to specify the replication strategy</summary>
      <description>It would be nice to have stress.java be a one stop shop when you need to test something other than SimpleStrategy.</description>
      <version>0.7.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">contrib.stress.src.org.apache.cassandra.contrib.stress.Session.java</file>
    </fixedFiles>
  </bug>
  <bug id="2147" opendate="2011-2-9 00:00:00" fixdate="2011-2-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>stress.java doesn&amp;#39;t read more unique rows than 2x the number of threads</summary>
      <description>This can be observed by watching how much the row/key cache grows on each run. I'm not sure when this started or if it was always the case, but it's actually useful behavior when you want to benchmark just the cache, so it'd be nice to preserve as an option.</description>
      <version>0.7.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">contrib.stress.src.org.apache.cassandra.contrib.stress.util.OperationThread.java</file>
      <file type="M">contrib.stress.src.org.apache.cassandra.contrib.stress.Session.java</file>
    </fixedFiles>
  </bug>
  <bug id="2162" opendate="2011-2-14 00:00:00" fixdate="2011-2-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cassandra-cli --keyspace option doesn&amp;#39;t work properly when used with authentication</summary>
      <description>The logic to select the keyspace is applied before authentication credentials are processed in cassandra-cli. This leads to a "Keyspace FOO not found" message at login for a keyspace that exists.</description>
      <version>0.7.3</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cli.CliMain.java</file>
    </fixedFiles>
  </bug>
  <bug id="2172" opendate="2011-2-16 00:00:00" fixdate="2011-2-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Saved-cache files are created for empty caches</summary>
      <description>This results in a harmless EOFException on startup.</description>
      <version>0.7.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.sstable.CacheWriter.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2173" opendate="2011-2-16 00:00:00" fixdate="2011-2-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unit test for row cache</summary>
      <description>We have a test for key cache (split out recently into KeyCacheTest) but nothing for row cache.</description>
      <version>0.7.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.conf.cassandra.yaml</file>
      <file type="M">src.java.org.apache.cassandra.db.RowMutation.java</file>
    </fixedFiles>
  </bug>
  <bug id="2174" opendate="2011-2-16 00:00:00" fixdate="2011-2-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>saved caches written with BufferedRandomAccessFile cannot be read by ObjectInputStream</summary>
      <description>The CacheWriter is currently writing with BufferedRandomAccessFile which is incompatible with ObjectInputStream resulting in stack traces about corrupted stream headers when loading a saved cache.</description>
      <version>0.7.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2178" opendate="2011-2-17 00:00:00" fixdate="2011-2-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Memtable Flush writers doesn&amp;#39;t actually flush in parallel</summary>
      <description>The flushWriter JMXEnabledThreadPoolExecutor sets the core pool min to 1, and sets the LBQ to DatabaseDescriptor.getFlushWriters(). Increasing memtable_flush_writers should allow us to flush more in parallel. The pool will not grow until LBQ fills up to DatabaseDescriptor.getFlushWriters().</description>
      <version>0.7.3,0.8beta1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="2187" opendate="2011-2-18 00:00:00" fixdate="2011-3-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cassandra Cli hangs forever if schema does not settle within timeout window</summary>
      <description>validateSchemaIsSettled will hang in the while loop since we never update start if migrations never settle.</description>
      <version>0.7.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.cli.CliClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="2188" opendate="2011-2-18 00:00:00" fixdate="2011-2-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>sstable2json generates invalid json for "paged" rows</summary>
      <description>I have a json file created with sstable2json for a column family of super column type. But json2sstable failed to create sstable from the file. It's because file format is wrong. WARN 11:41:55,141 Schema definitions were defined both locally and in cassandra.yaml. Definitions in cassandra.yaml were ignored.org.codehaus.jackson.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate OBJECT entries at &amp;#91;Source: dump.json; line: 2, column: 739439661&amp;#93; at org.codehaus.jackson.JsonParser._constructError(JsonParser.java:929) at org.codehaus.jackson.impl.JsonParserBase._reportError(JsonParserBase.java:632) at org.codehaus.jackson.impl.JsonParserBase._reportUnexpectedChar(JsonParserBase.java:565) at org.codehaus.jackson.impl.Utf8StreamParser.nextToken(Utf8StreamParser.java:128) at org.codehaus.jackson.map.deser.UntypedObjectDeserializer.mapObject(UntypedObjectDeserializer.java:93) at org.codehaus.jackson.map.deser.UntypedObjectDeserializer.deserialize(UntypedObjectDeserializer.java:65) at org.codehaus.jackson.map.deser.MapDeserializer._readAndBind(MapDeserializer.java:197) at org.codehaus.jackson.map.deser.MapDeserializer.deserialize(MapDeserializer.java:145) at org.codehaus.jackson.map.deser.MapDeserializer.deserialize(MapDeserializer.java:23) at org.codehaus.jackson.map.ObjectMapper._readValue(ObjectMapper.java:1261) at org.codehaus.jackson.map.ObjectMapper.readValue(ObjectMapper.java:517) at org.codehaus.jackson.JsonParser.readValueAs(JsonParser.java:897) at org.apache.cassandra.tools.SSTableImport.importUnsorted(SSTableImport.java:208) at org.apache.cassandra.tools.SSTableImport.importJson(SSTableImport.java:197) at org.apache.cassandra.tools.SSTableImport.main(SSTableImport.java:421)ERROR: Unexpected character ('"' (code 34)): was expecting comma to separate OBJECT entries at &amp;#91;Source: dump.json; line: 2, column: 739439661&amp;#93;When I looked at the file, I found that a comma is missing between super columns. The part of data is like this: ["756e697473", "32", 1297926692097000, false]]}"32303036303830373135303030302f313030303030303030302d32303036313030322d303030303030303639382d612f30": {"deletedAt": -9223372036854775808, "subColumns": [["5f64656c", "", 1297926692097000, false],You'll see no comma between } and ".</description>
      <version>0.7.3,0.8beta1</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.SSTableExport.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2196" opendate="2011-2-18 00:00:00" fixdate="2011-2-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hyphenated index names cause problems</summary>
      <description>When inserting a large number of entries with batch_insert (100000) using thrift compiled into C# there's a NumberFormatException that occurs.The first logged entry that tipped me off was this: INFO 10:53:52,171 Writing Memtable-TransactionLogs.client-hostname@350930888(1171371 bytes, 32787 operations)ERROR 10:53:52,171 Error in ThreadPoolExecutorjava.lang.RuntimeException: java.lang.NumberFormatException: For input string: "tmp" at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:662)Caused by: java.lang.NumberFormatException: For input string: "tmp" at java.lang.NumberFormatException.forInputString(NumberFormatException.java:48) at java.lang.Integer.parseInt(Integer.java:449) at java.lang.Integer.parseInt(Integer.java:499) at org.apache.cassandra.io.sstable.Descriptor.fromFilename(Descriptor.java:154) at org.apache.cassandra.io.sstable.Descriptor.fromFilename(Descriptor.java:119) at org.apache.cassandra.io.sstable.SSTableWriter.&lt;init&gt;(SSTableWriter.java:67) at org.apache.cassandra.db.Memtable.writeSortedContents(Memtable.java:156) at org.apache.cassandra.db.Memtable.access$000(Memtable.java:49) at org.apache.cassandra.db.Memtable$1.runMayThrow(Memtable.java:174) at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30) ... 3 more Which points to the suspect piece of code in Descriptor.java:154 (browse at https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/io/sstable/Descriptor.java) The file I believe it's trying to parse is mentioned in my logs as:INFO 10:51:31,231 Compacted to C:\cassandra\apache-cassandra-0.7.2\bin\..\Storage\data\system\IndexInfo-tmp-f-6-Data.db. 384 to 225 (~58% of original) bytes for 1 keys. Time: 281ms. I'm new here, so I'm not sure what needs fixing here (the filename, or the parsing of it).</description>
      <version>0.7.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.migration.AddColumnFamily.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.cassandra.db.migration.UpdateColumnFamily.java</file>
    </fixedFiles>
  </bug>
  <bug id="2206" opendate="2011-2-21 00:00:00" fixdate="2011-2-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Startup fails due to cassandra trying to delete nonexisting file</summary>
      <description>Hi,On one of our nodes, startup fails due to cassandra trying to delete a nonexistant "Data" file (see below).Why that file is missing is another mistery... The log file entries don't show any ERROR messages before cassandra restarted (for reasons I don't know) and this error occured.Directory listing:total 109Mrw-rr- 1 root root 51M 2011-02-21 05:25 table_task-f-1666-Data.dbrw-rr- 1 root root 243K 2011-02-21 05:25 table_task-f-1666-Filter.dbrw-rr- 1 root root 6.1M 2011-02-21 05:25 table_task-f-1666-Index.dbrw-rr- 1 root root 4.2K 2011-02-21 05:25 table_task-f-1666-Statistics.dbrw-rr- 1 root root 9.8M 2011-02-21 11:36 table_task-f-1703-Data.dbrw-rr- 1 root root 57K 2011-02-21 11:36 table_task-f-1703-Filter.dbrw-rr- 1 root root 1.3M 2011-02-21 11:36 table_task-f-1703-Index.dbrw-rr- 1 root root 4.2K 2011-02-21 11:36 table_task-f-1703-Statistics.dbrw-rr- 1 root root 292K 2011-02-21 11:42 table_task-f-1704-Data.dbrw-rr- 1 root root 1.7K 2011-02-21 11:42 table_task-f-1704-Filter.dbrw-rr- 1 root root 42K 2011-02-21 11:42 table_task-f-1704-Index.dbrw-rr- 1 root root 4.2K 2011-02-21 11:42 table_task-f-1704-Statistics.dbrw-rr- 1 root root 364K 2011-02-21 11:52 table_task-f-1705-Data.dbrw-rr- 1 root root 2.0K 2011-02-21 11:52 table_task-f-1705-Filter.dbrw-rr- 1 root root 50K 2011-02-21 11:52 table_task-f-1705-Index.dbrw-rr- 1 root root 4.2K 2011-02-21 11:52 table_task-f-1705-Statistics.dbrw-rr- 1 root root 535K 2011-02-21 12:10 table_task-f-1706-Data.dbrw-rr- 1 root root 2.8K 2011-02-21 12:10 table_task-f-1706-Filter.dbrw-rr- 1 root root 70K 2011-02-21 12:10 table_task-f-1706-Index.dbrw-rr- 1 root root 4.2K 2011-02-21 12:10 table_task-f-1706-Statistics.dbrw-rr- 1 root root 11M 2011-02-21 12:11 table_task-f-1707-Data.dbrw-rr- 1 root root 18M 2011-02-21 09:47 table_task_meta-f-417-Data.dbrw-rr- 1 root root 271K 2011-02-21 09:47 table_task_meta-f-417-Filter.dbrw-rr- 1 root root 6.7M 2011-02-21 09:47 table_task_meta-f-417-Index.dbrw-rr- 1 root root 4.2K 2011-02-21 09:47 table_task_meta-f-417-Statistics.dbrw-rr- 1 root root 1.2M 2011-02-21 10:47 table_task_meta-f-418-Data.dbrw-rr- 1 root root 18K 2011-02-21 10:47 table_task_meta-f-418-Filter.dbrw-rr- 1 root root 460K 2011-02-21 10:47 table_task_meta-f-418-Index.dbrw-rr- 1 root root 4.2K 2011-02-21 10:47 table_task_meta-f-418-Statistics.dbrw-rr- 1 root root 791K 2011-02-21 11:47 table_task_meta-f-419-Data.dbrw-rr- 1 root root 13K 2011-02-21 11:47 table_task_meta-f-419-Filter.dbrw-rr- 1 root root 311K 2011-02-21 11:47 table_task_meta-f-419-Index.dbrw-rr- 1 root root 4.2K 2011-02-21 11:47 table_task_meta-f-419-Statistics.dbrw-rr- 1 root root 57K 2011-02-21 12:11 table_task-tmp-f-1707-Filter.dbrw-rr- 1 root root 1.4M 2011-02-21 12:11 table_task-tmp-f-1707-Index.dbrw-rr- 1 root root 4.2K 2011-02-21 12:11 table_task-tmp-f-1707-Statistics.dbCassandra log:/software/cassandra/bin/cassandrarm: cannot remove `/software/cassandra/lib/jna.jar': No such file or directoryroot@intr1n3:/cassandra/data/table_task# INFO 12:47:29,020 Logging initialized INFO 12:47:29,030 Heap size: 2614493184/2614493184 INFO 12:47:29,031 JNA not found. Native methods will be disabled. INFO 12:47:29,038 Loading settings from file:/software/cassandra/conf/cassandra.yaml INFO 12:47:29,320 DiskAccessMode is standard, indexAccessMode is mmap INFO 12:47:29,332 Creating new commitlog segment /hd1/cassandra_md5/commitlog/CommitLog-1298288849332.log INFO 12:47:29,422 Opening /cassandra/data/system/Schema-f-244 INFO 12:47:29,434 Opening /cassandra/data/system/Migrations-f-244 INFO 12:47:29,437 Opening /cassandra/data/system/LocationInfo-f-137 INFO 12:47:29,440 Opening /cassandra/data/system/HintsColumnFamily-f-352 INFO 12:47:29,441 Opening /cassandra/data/system/HintsColumnFamily-f-353 INFO 12:47:29,465 Loading schema version 54bc134e-2229-11e0-9159-fdf0b6b4b562 WARN 12:47:29,623 Schema definitions were defined both locally and in cassandra.yaml. Definitions in cassandra.yaml were ignored.ERROR 12:47:29,638 Exception encountered during startup.java.io.IOError: java.io.IOException: Failed to delete /cassandra/data/table_task/table_task-tmp-f-1707-Data.db at org.apache.cassandra.io.sstable.SSTable.delete(SSTable.java:145) at org.apache.cassandra.db.ColumnFamilyStore.scrubDataDirectories(ColumnFamilyStore.java:468) at org.apache.cassandra.service.AbstractCassandraDaemon.setup(AbstractCassandraDaemon.java:153) at org.apache.cassandra.service.AbstractCassandraDaemon.activate(AbstractCassandraDaemon.java:316) at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:79)Caused by: java.io.IOException: Failed to delete /cassandra/data/table_task/table_task-tmp-f-1707-Data.db at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:51) at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:41) at org.apache.cassandra.io.sstable.SSTable.delete(SSTable.java:133) ... 4 moreException encountered during startup.java.io.IOError: java.io.IOException: Failed to delete /cassandra/data/table_task/table_task-tmp-f-1707-Data.db at org.apache.cassandra.io.sstable.SSTable.delete(SSTable.java:145) at org.apache.cassandra.db.ColumnFamilyStore.scrubDataDirectories(ColumnFamilyStore.java:468) at org.apache.cassandra.service.AbstractCassandraDaemon.setup(AbstractCassandraDaemon.java:153) at org.apache.cassandra.service.AbstractCassandraDaemon.activate(AbstractCassandraDaemon.java:316) at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:79)Caused by: java.io.IOException: Failed to delete /cassandra/data/table_task/table_task-tmp-f-1707-Data.db at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:51) at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:41) at org.apache.cassandra.io.sstable.SSTable.delete(SSTable.java:133) ... 4 more</description>
      <version>0.7.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableWriter.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2211" opendate="2011-2-21 00:00:00" fixdate="2011-2-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cleanup can create sstables whose contents do not match their advertised version</summary>
      <description>Since cleanup switched to per-sstable operation (CASSANDRA-1916), the main loop looks like this: if (Range.isTokenInRanges(row.getKey().token, ranges)) { writer = maybeCreateWriter(sstable, compactionFileLocation, expectedBloomFilterSize, writer); writer.append(new EchoedRow(row)); totalkeysWritten++; } else { while (row.hasNext()) { IColumn column = row.next(); if (indexedColumns.contains(column.name())) Table.cleanupIndexEntry(cfs, row.getKey().key, column); } }... that is, rows that haven't changed we copy to the new sstable without deserializing, with EchoedRow. But, the new sstable is created with CURRENT_VERSION which may not be what the old data consisted of.(This could cause symptoms similar to CASSANDRA-2195 but I do not think it is the cause of that bug; IIRC the cluster in question there was not upgraded from an older Cassandra.)</description>
      <version>0.7.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.CompactionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2212" opendate="2011-2-22 00:00:00" fixdate="2011-2-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cannot get range slice of super columns in reversed order</summary>
      <description>I cannot get range slice of super columns in reversed order. These data are stored in Cassandra in advance. On the other hand, range slice of these data in normal order can be acquired.You can reproduce the bug by executing attached programs. 1. Start Cassandra daemon on localhost (number of thrift port is 9160) 2. Create keyspace and column family, according to "create_table.cli", 3. Execute "cassandra_sample_insert.py", storing pairs of row keys and super columns 4. Execute "cassandra_sample_rangeslice.py" and get range slice of stored super columns"cassandra_sample_insert.py" and "cassandra_sample_rangeslice.py" require pycassa. You will need to execute 4."cassandra_sample_rangeslice.py" with following options so that you get range slice of super columns in reversed order. % python cassandra_sample_rangeslice.py -r 00082 00083On the other hand, to get range slice in normal order, you will need to use following options. % python cassandra_sample_rangeslice.py -f 00082 0008300082 and 00083 are the specified key range. Range slice can be acquired in normal order but, I cannot get it in reversed order. I assume that there may be a bug within the code for acquiring the index block of specified range. In fact, 00083 is included in gap between lastName of index block and firstName of next index block.</description>
      <version>0.6.13,0.7.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.sstable.IndexHelper.java</file>
      <file type="M">src.java.org.apache.cassandra.db.columniterator.SSTableNamesIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.db.columniterator.IndexedSliceReader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2216" opendate="2011-2-22 00:00:00" fixdate="2011-2-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compaction can echo data which breaks upon sstable format changes</summary>
      <description>While compaction, if for a row we have only 1 sstable holding data, we echo this data. This breaks when we change the data format, creating mixed (corrupted) sstable.(I suspect this is the cause of CASSANDRA-2195, but opening a new ticket until we can confirm that hunch)</description>
      <version>0.7.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.PrecompactedRow.java</file>
      <file type="M">src.java.org.apache.cassandra.io.LazilyCompactedRow.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2217" opendate="2011-2-22 00:00:00" fixdate="2011-3-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>nodetool scrub</summary>
      <description>this is the force-deserialization tool to repair CASSANDRA-2211 and CASSANDRA-2216.</description>
      <version>0.7.3</version>
      <fixedVersion>Tool/nodetool</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.io.LazilyCompactedRowTest.java</file>
      <file type="M">test.conf.cassandra.yaml</file>
      <file type="M">src.java.org.apache.cassandra.utils.CLibrary.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeProbe.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageServiceMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.io.util.BufferedRandomAccessFile.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableIdentityIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.io.PrecompactedRow.java</file>
      <file type="M">src.java.org.apache.cassandra.io.LazilyCompactedRow.java</file>
      <file type="M">src.java.org.apache.cassandra.io.CompactionIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.db.CompactionManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="2218" opendate="2011-2-22 00:00:00" fixdate="2011-2-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Performance regression caused by cache-avoiding code in BRAF</summary>
      <description>As reported by Ivan Georgiev on the mailing list, BRAF.reBuffer unnecessarily does extra read + fadvise when seeking to the end of the file.</description>
      <version>0.7.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.util.BufferedRandomAccessFile.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2222" opendate="2011-2-22 00:00:00" fixdate="2011-2-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make it less easy for user to aim the schema change gun at his foot</summary>
      <description></description>
      <version>0.7.3</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraServer.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2223" opendate="2011-2-22 00:00:00" fixdate="2011-2-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ClientOnly mode is creating directories</summary>
      <description></description>
      <version>0.7.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.MigrationManager.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.Gossiper.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Table.java</file>
      <file type="M">src.java.org.apache.cassandra.db.migration.Migration.java</file>
      <file type="M">src.java.org.apache.cassandra.db.HintedHandOffManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLog.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">contrib.client.only.src.ClientOnlyExample.java</file>
      <file type="M">contrib.client.only.conf.cassandra.yaml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2241" opendate="2011-2-24 00:00:00" fixdate="2011-2-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>BRAF read can loop infinitely instead of detecting EOF</summary>
      <description>(marking this Minor since normally we never try to read past the end of an SSTable, but CASSANDRA-2240 is running into it.)</description>
      <version>0.7.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.io.util.BufferedRandomAccessFileTest.java</file>
      <file type="M">src.java.org.apache.cassandra.io.util.BufferedRandomAccessFile.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.Descriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLog.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2243" opendate="2011-2-24 00:00:00" fixdate="2011-2-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>fix "ant codecoverage"</summary>
      <description></description>
      <version>0.7.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="2248" opendate="2011-2-25 00:00:00" fixdate="2011-2-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ant javadoc fails on windows</summary>
      <description>When try to run "ant javadoc" (or any task that include javadoc) on windows it fails with the error:Javadoc failed: java.io.IOException: Cannot run program "c:\Program Files\Java\jdk1.6.0_17\bin\javadoc.exe": CreateProcess error=87, The parameter is incorrect</description>
      <version>0.7.3</version>
      <fixedVersion>Packaging</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="2255" opendate="2011-2-28 00:00:00" fixdate="2011-3-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ColumnFamilyOutputFormat drops mutations when batches fill up.</summary>
      <description>queue.poll() takes a mutation,but then the batch is already full,so the while loop exits, ant the mutation we just got is dropped.</description>
      <version>0.7.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.hadoop.ColumnFamilyRecordWriter.java</file>
    </fixedFiles>
  </bug>
</bugrepository>
