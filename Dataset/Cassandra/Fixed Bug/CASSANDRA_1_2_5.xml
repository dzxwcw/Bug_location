<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="CASSANDRA">
  <bug id="5229" opendate="2013-2-7 00:00:00" fixdate="2013-5-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>after a IOException is thrown during streaming, streaming tasks hang in netstats</summary>
      <description>After an IOExcpetion, streaming tasks marked as "successful" in the logs are hung in netstatsWith TRACE debugging on streaming on the receiving node everything about the sstable in the log (not very much) INFO [AntiEntropyStage:1] 2013-02-07 11:23:44,717 StreamOut.java (line 151) Stream context metadata [/data/cassandra/evidence/fingerprints/evidence-fingerprints-ib-5-Data.db sections=3068 progress=0/2785204713 - 0%, /data2/cassandra/evidence/fingerprints/evidence-fingerprints-ib-25-Data.db sections=2696 progress=0/758409465 - 0%, /data/cassandra/evidence/fingerprints/evidence-fingerprints-ib-60-Data.db sections=3099 progress=0/238876436 - 0%, /data2/cassandra/evidence/fingerprints/evidence-fingerprints-ib-63-Data.db sections=1166 progress=0/2125323 - 0%, /data2/cassandra/evidence/fingerprints/evidence-fingerprints-ib-38-Data.db sections=2507 progress=0/515992757 - 0%, /data2/cassandra/evidence/fingerprints/evidence-fingerprints-ib-26-Data.db sections=3153 progress=0/994857654 - 0%, /data2/cassandra/evidence/fingerprints/evidence-fingerprints-ib-57-Data.db sections=3116 progress=0/129398170 - 0%, /data2/cassandra/evidence/fingerprints/evidence-fingerprints-ib-58-Data.db sections=217 progress=0/72286 - 0%, /data/cassandra/evidence/fingerprints/evidence-fingerprints-ib-59-Data.db sections=3146 progress=0/3357709019 - 0%], 27 sstables. INFO [AntiEntropyStage:1] 2013-02-07 11:23:52,964 StreamOut.java (line 151) Stream context metadata [/data/cassandra/evidence/fingerprints/evidence-fingerprints-ib-5-Data.db sections=2930 progress=0/2799914560 - 0%, /data2/cassandra/evidence/fingerprints/evidence-fingerprints-ib-25-Data.db sections=2590 progress=0/761266059 - 0%, /data/cassandra/evidence/fingerprints/evidence-fingerprints-ib-60-Data.db sections=2956 progress=0/241362497 - 0%, /data2/cassandra/evidence/fingerprints/evidence-fingerprints-ib-63-Data.db sections=1153 progress=0/2125323 - 0%, /data2/cassandra/evidence/fingerprints/evidence-fingerprints-ib-38-Data.db sections=2422 progress=0/522126371 - 0%, /data2/cassandra/evidence/fingerprints/evidence-fingerprints-ib-26-Data.db sections=3004 progress=0/998401202 - 0%, /data2/cassandra/evidence/fingerprints/evidence-fingerprints-ib-57-Data.db sections=2974 progress=0/129722346 - 0%, /data2/cassandra/evidence/fingerprints/evidence-fingerprints-ib-58-Data.db sections=220 progress=0/72286 - 0%, /data/cassandra/evidence/fingerprints/evidence-fingerprints-ib-59-Data.db sections=2998 progress=0/3375554099 - 0%], 27 sstables.node that is streaming out thinks that the streaming session was successful INFO [MiscStage:1] 2013-02-07 11:23:38,022 StreamOut.java (line 151) Stream context metadata [/data/cassandra/evidence/fingerprints/evidence-fingerprints-ia-472-Data.db sections=1727 progress=0/210208515 - 0%, /var/lib/cassandra/data2/evidence/fingerprints/evidence-fingerprints-ib-919-Data.db sections=1746 progress=0/119438030 - 0%, /data/cassandra/evidence/fingerprints/evidence-fingerprints-ib-920-Data.db sections=1681 progress=0/54498226 - 0%, /var/lib/cassandra/data2/evidence/fingerprints/evidence-fingerprints-ib-922-Data.db sections=16 progress=0/13490 - 0%, /var/lib/cassandra/data2/evidence/fingerprints/evidence-fingerprints-ib-918-Data.db sections=632 progress=0/70019542 - 0%, /var/lib/cassandra/data2/evidence/fingerprints/evidence-fingerprints-ib-921-Data.db sections=1644 progress=0/39870238 - 0%, /data/cassandra/evidence/fingerprints/evidence-fingerprints-ib-497-Data.db sections=1569 progress=0/208331077 - 0%, /var/lib/cassandra/data2/evidence/fingerprints/evidence-fingerprints-ib-923-Data.db sections=1572 progress=0/30870478 - 0%, /var/lib/cassandra/data2/evidence/fingerprints/evidence-fingerprints-ib-925-Data.db sections=167 progress=0/1845123 - 0%, /var/lib/cassandra/data2/evidence/fingerprints/evidence-fingerprints-ib-703-Data.db sections=1574 progress=0/287386471 - 0%, /var/lib/cassandra/data2/evidence/fingerprints/evidence-fingerprints-ib-913-Data.db sections=811 progress=0/103776521 - 0%, /var/lib/cassandra/data2/evidence/fingerprints/evidence-fingerprints-ib-915-Data.db sections=1539 progress=0/141864261 - 0%], 12 sstables. INFO [MiscStage:1] 2013-02-07 11:23:49,938 StreamOut.java (line 151) Stream context metadata [/var/lib/cassandra/data2/evidence/fingerprints/evidence-fingerprints-ib-919-Data.db sections=3153 progress=0/994857654 - 0%, /var/lib/cassandra/data2/evidence/fingerprints/evidence-fingerprints-ib-918-Data.db sections=2507 progress=0/515992757 - 0%, /var/lib/cassandra/data2/evidence/fingerprints/evidence-fingerprints-ib-923-Data.db sections=3153 progress=0/131969347 - 0%, /var/lib/cassandra/data2/evidence/fingerprints/evidence-fingerprints-ib-703-Data.db sections=3068 progress=0/2784807967 - 0%, /var/lib/cassandra/data2/evidence/fingerprints/evidence-fingerprints-ib-913-Data.db sections=2696 progress=0/758409465 - 0%, /data/cassandra/evidence/fingerprints/evidence-fingerprints-ia-472-Data.db sections=3150 progress=0/1792868996 - 0%, /data/cassandra/evidence/fingerprints/evidence-fingerprints-ib-920-Data.db sections=3123 progress=0/240094510 - 0%, /var/lib/cassandra/data2/evidence/fingerprints/evidence-fingerprints-ib-929-Data.db sections=18 progress=0/29468 - 0%, /var/lib/cassandra/data2/evidence/fingerprints/evidence-fingerprints-ib-922-Data.db sections=217 progress=0/13490 - 0%, /var/lib/cassandra/data2/evidence/fingerprints/evidence-fingerprints-ib-921-Data.db sections=3124 progress=0/130320291 - 0%, /data/cassandra/evidence/fingerprints/evidence-fingerprints-ib-497-Data.db sections=3055 progress=0/1749539598 - 0%, /var/lib/cassandra/data2/evidence/fingerprints/evidence-fingerprints-ib-925-Data.db sections=1608 progress=0/13357410 - 0%, /var/lib/cassandra/data2/evidence/fingerprints/evidence-fingerprints-ib-915-Data.db sections=3096 progress=0/1241397203 - 0%], 13 sstables. INFO [Streaming to /10.8.25.132:2] 2013-02-07 11:24:18,780 StreamReplyVerbHandler.java (line 44) Successfully sent /var/lib/cassandra/data2/evidence/fingerprints/evidence-fingerprints-ib-919-Data.db to /10.8.25.132node that is being streamed to has nothing in the logs about this particular sstableStreaming from: /10.8.30.13evidence: /var/lib/cassandra/data2/evidence/fingerprints/evidence-fingerprints-ib-919-Data.db sections=3153 progress=218225400/994857654 - 21%_______Streaming from: /10.138.12.10evidence: /data2/cassandra/evidence/fingerprints/evidence-fingerprints-ib-26-Data.db sections=3153 progress=218225400/994857654 - 21%</description>
      <version>1.2.5</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.streaming.IncomingStreamReader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5393" opendate="2013-3-27 00:00:00" fixdate="2013-4-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add retry mechanism to OTC for non-droppable_verbs</summary>
      <description>Can we add an Ack/Retry around passing merle tree's around in repair? If the following fails, the repair hangs for ever on the coordinating node.https://github.com/apache/cassandra/blob/cassandra-1.1.10/src/java/org/apache/cassandra/service/AntiEntropyService.java#L242 Message message = TreeResponseVerbHandler.makeVerb(local, validator); if (!validator.request.endpoint.equals(FBUtilities.getBroadcastAddress())) logger.info(String.format("[repair #%s] Sending completed merkle tree to %s for %s", validator.request.sessionid, validator.request.endpoint, validator.request.cf)); ms.sendOneWay(message, validator.request.endpoint);If the message asking for merkle tree's gets lost, coordinating node hangs for ever as well.</description>
      <version>1.1.12,1.2.5,2.0beta1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.net.OutboundTcpConnection.java</file>
    </fixedFiles>
  </bug>
  <bug id="5447" opendate="2013-4-9 00:00:00" fixdate="2013-4-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Include fatal errors in trace events</summary>
      <description>This would help tracking down which query is causing errors.</description>
      <version>1.2.5</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.CassandraDaemon.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5452" opendate="2013-4-10 00:00:00" fixdate="2013-4-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow empty blob literals in CQL3</summary>
      <description>The current grammar don't allow empty blob literals (so '0x'). The goal here is to allow the following syntax for that:INSERT INTO test(k, b) VALUES (0, 0x)I'll admit that '0x' is not the most beautiful syntax ever, but I think that's the only thing that make sense.I'll note that currently there is 2 workaround to insert empty blobs: you can either use prepared statement (not a bad idea when using blobs anyway) or, because we've deprecated but still support until 2.0 using strings as blob (to allow upgrade from 1.2.0 to 1.2.1), you can use an empty string. I'll note that this latter workaround will trigger a deprecation warning in the log however and will stop working in 2.0.</description>
      <version>1.2.5</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.Cql.g</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5468" opendate="2013-4-14 00:00:00" fixdate="2013-4-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Prepared statements from default keyspace are broken</summary>
      <description>Tested under CQL 3 binary protocol.Preparing a statement from the default keyspace of the connection (statement scoped with keyspace) and then running it will always throw the error "no keyspace has been specified".Exec: CREATE KEYSPACE Tests WITH replication = {'class': 'SimpleStrategy', 'replication_factor' : 1}Exec: CREATE TABLE Tests.AllTypes (a int, b int, primary key (a))Prepare: insert into Tests.AllTypes (a, b) values (?, ?)Exec prepared statement and exception "no keyspace has been specified" is thrown.Doing a use Tests before preparing the statement solves the issue.This used to work in 1.2.3.</description>
      <version>1.2.5</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.QueryProcessor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5474" opendate="2013-4-15 00:00:00" fixdate="2013-4-15 01:00:00" resolution="Invalid">
    <buginformation>
      <summary>failure when passing null parameter to prepared statement</summary>
      <description>I have a failure when passing a null parameter to the prepared statement bellow when going through the cql 3 bin protocol:Exec: CREATE KEYSPACE Tests WITH replication = {'class': 'SimpleStrategy', 'replication_factor' : 1}Exec: CREATE TABLE Tests.AllTypes (a int, b int, primary key (a))Prepare: insert into Tests.AllTypes (a, b) values (?, ?)Passing a=1 and b=null cause the following error:DEBUG 23:07:23,315 Responding: RESULT PREPARED 59b3d6baed67d5c0a3ced29ebb4277c5 [a(tests, alltypes), org.apache.cassandra.db.marshal.Int32Type][b(tests, alltypes), org.apache.cassandra.db.marshal.Int32Type]DEBUG 23:07:23,292 Compaction buckets are []DEBUG 23:07:23,336 Received: EXECUTE 59b3d6baed67d5c0a3ced29ebb4277c5 with 2 values at consistency QUORUMERROR 23:07:23,338 Unexpected exception during requestjava.lang.NullPointerException at org.apache.cassandra.db.marshal.Int32Type.validate(Int32Type.java:95) at org.apache.cassandra.cql3.Constants$Marker.bindAndGet(Constants.java:257) at org.apache.cassandra.cql3.Constants$Setter.execute(Constants.java:282) at org.apache.cassandra.cql3.statements.UpdateStatement.mutationForKey(UpdateStatement.java:250) at org.apache.cassandra.cql3.statements.UpdateStatement.getMutations(UpdateStatement.java:133) at org.apache.cassandra.cql3.statements.ModificationStatement.execute(ModificationStatement.java:92) at org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:132) at org.apache.cassandra.cql3.QueryProcessor.processPrepared(QueryProcessor.java:254) at org.apache.cassandra.transport.messages.ExecuteMessage.execute(ExecuteMessage.java:122) at org.apache.cassandra.transport.Message$Dispatcher.messageReceived(Message.java:287) at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:75) at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:565) at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:793) at org.jboss.netty.handler.execution.ChannelUpstreamEventRunnable.doRun(ChannelUpstreamEventRunnable.java:45) at org.jboss.netty.handler.execution.ChannelEventRunnable.run(ChannelEventRunnable.java:69) at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) at java.lang.Thread.run(Unknown Source)DEBUG 23:07:23,337 No tasks availableDEBUG 23:07:23,341 request completeDEBUG 23:07:23,343 Responding: ERROR SERVER_ERROR: java.lang.NullPointerExceptionWhen serializing value for b, a bytes array of len -1 is transmitted (accordingly to the spec):[bytes] A [int] n, followed by n bytes if n &gt;= 0. If n &lt; 0, no byte should follow and the value represented is `null`.CASSANDRA-5081 added support for null params. Am I doing something wrong there ? Thanks.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.utils.obs.ArrayUtil.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.FBUtilities.java</file>
      <file type="M">src.java.org.apache.cassandra.concurrent.CreationTimeAwareFuture.java</file>
    </fixedFiles>
  </bug>
  <bug id="5487" opendate="2013-4-17 00:00:00" fixdate="2013-4-17 01:00:00" resolution="Invalid">
    <buginformation>
      <summary>Promote row-level tombstones to index file</summary>
      <description>The idea behind promoted indexes (CASSANDRA-2319) was we could skip a seek to the row header by keeping the column index in the index file. But, we skip writing the row-level tombstone to the index file unless it also has some column data. So unless we read the tombstone from the data file (where it is guaranteed to exist) we can return incorrect results.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.IndexHelper.java</file>
      <file type="M">src.java.org.apache.cassandra.db.DeletionInfo.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.RangeTombstoneTest.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.FilterFactory.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.AlwaysPresentFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableReader.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.Descriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowIndexEntry.java</file>
      <file type="M">src.java.org.apache.cassandra.db.columniterator.SSTableNamesIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.db.columniterator.SimpleSliceReader.java</file>
      <file type="M">src.java.org.apache.cassandra.db.columniterator.IndexedSliceReader.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnIndex.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="5507" opendate="2013-4-23 00:00:00" fixdate="2013-4-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The native protocol server is not correctly stopped on shutdown</summary>
      <description></description>
      <version>1.2.5</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5512" opendate="2013-4-24 00:00:00" fixdate="2013-4-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>forceTablePrimaryRange fails with nullpointer exception</summary>
      <description>Running JMX operation forceTableRepairRange fails with nullpointer exception.Three node cluster with one keyspace and one large columnfamily.Works when running nodetool -pr but not over JMX.Stacktrace:ERROR &amp;#91;MiscStage:1&amp;#93; 2013-04-24 09:53:02,884 CassandraDaemon.java (line 164) Exception in thread Thread&amp;#91;MiscStage:1,5,main&amp;#93;java.lang.NullPointerException at org.apache.cassandra.service.SnapshotVerbHandler.doVerb(SnapshotVerbHandler.java:38) at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:56) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918) at java.lang.Thread.run(Thread.java:662)</description>
      <version>1.2.5</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5528" opendate="2013-4-30 00:00:00" fixdate="2013-5-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CLUSTERING ORDER BY support for cqlsh&amp;#39;s DESCRIBE</summary>
      <description>cqlsh currently does not output any sort of CLUSTERING ORDER BY options with DESCRIBE and, furthermore, DESC orderings will result in bad column type definitions.</description>
      <version>1.2.5</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.streaming.BootstrapTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.io.LazilyCompactedRowTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.compaction.LeveledCompactionStrategyTest.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.SSTableMetadataViewer.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.IncomingStreamReader.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableMetadata.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.Descriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.ColumnStats.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.Scrubber.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LazilyCompactedRow.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionTask.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionController.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.AbstractCompactionStrategy.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamily.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug id="5531" opendate="2013-5-1 00:00:00" fixdate="2013-5-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Disallow renaming columns one at a time when when the table don&amp;#39;t have CQL3 metadata yet</summary>
      <description>As noted in CASSANDRA-5489, if you have a "thrift" CF, say:[default@ks] create column family test with comparator='CompositeType(Int32Type, Int32Type, Int32Type)' and key_validation_class=UTF8Type and default_validation_class=UTF8Type;And that trying to use it in CQL3 you rename the columns one at a time, you can get:cqlsh:ks&gt; DESC COLUMNFAMILY test;CREATE TABLE test ( key text, column1 int, column2 int, column3 int, value text, PRIMARY KEY (key, column1, column2, column3)) WITH COMPACT STORAGE ...cqlsh:ks&gt; ALTER TABLE test RENAME column2 TO foo;TSocket read 0 bytesNo, it happens that renaming the columns one at a time is a bad idea anyway as it can confuse the CQL3 code in some cases. So I suggest to disallow that and to force renaming all columns in one request the first you use a thrift CF from CQL3.To be clear, you will still be able to rename columns one at a time in general, it's just for the first time you rename on a metadata-less CF. So overall that's a very small limitation and it simplify our lives code-wise.See CASSANDRA-5489 for a bit more context here.</description>
      <version>1.2.5</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.AlterTableStatement.java</file>
      <file type="M">pylib.cqlshlib.cql3handling.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5535" opendate="2013-5-3 00:00:00" fixdate="2013-5-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Manifest file not fsynced</summary>
      <description>We had several cases where the the manifest file would get corrupted when doing power reset tests or iLO resets to mimic power failure scenarios, ungraceful resets, kernel panics etc. It wasn't clear at the time where the problem was, but I think the data below shows that Cassandra is missing an fsync call to the manifest file prior to closing it. This particular stack trace from below is on Cassandra 1.2.4.The trace was captured using strace options:strace -f -p 2200 -e trace=open,close,write,fsync,fdatasync,rename&amp;#91;pid 9710&amp;#93; open("/opt/mp/storage/persistent/cassandra/cassandra-lib/data/MSA/subinfo/subinfo-tmp.json", O_WRONLY|O_CREAT|O_TRUNC, 0666) = 238&amp;#91;pid 9710&amp;#93; write(238, "{\n \"generations\" : [ {\n \"gen"..., 3996) = 3996&amp;#91;pid 9710&amp;#93; write(238, "14, 263161, 263484, 270816, 2593"..., 3996) = 3996&amp;#91;pid 9710&amp;#93; write(238, "275136, 275137, 275138, 275139, "..., 1173) = 1173&amp;#91;pid 9710&amp;#93; close(238) = 0&amp;#91;pid 9710&amp;#93; rename("/opt/mp/storage/persistent/cassandra/cassandra-lib/data/MSA/subinfo/subinfo.json", "/opt/mp/storage/persistent/cassandra/cassandra-lib/data/MSA/subinfo/subinfo-old.json") = 0&amp;#91;pid 9710&amp;#93; rename("/opt/mp/storage/persistent/cassandra/cassandra-lib/data/MSA/subinfo/subinfo-tmp.json", "/opt/mp/storage/persistent/cassandra/cassandra-lib/data/MSA/subinfo/subinfo.json") = 0</description>
      <version>1.1.12,1.2.5</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LeveledManifest.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5540" opendate="2013-5-6 00:00:00" fixdate="2013-5-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Concurrent secondary index updates remove rows from the index</summary>
      <description>Existing rows disappear from secondary index when doing simultaneous updates of a row with the same secondary index value.Here is a little pycassa script that reproduces a bug. The script inserts 4 rows with same secondary index value, reads those rows back and check that there are 4 of them.Please run two instances of the script simultaneously in two separate terminals in order to simulate concurrent updates:-----scrpit.py START-----import pycassafrom pycassa.index import *pool = pycassa.ConnectionPool('ks123')cf = pycassa.ColumnFamily(pool, 'cf1')while True: for rowKey in xrange(4): cf.insert(str(rowKey), {'indexedColumn': 'indexedValue'}) index_expression = create_index_expression('indexedColumn', 'indexedValue') index_clause = create_index_clause([index_expression]) rows = cf.get_indexed_slices(index_clause) length = len(list(rows)) if length == 4: pass else: print 'found just %d rows out of 4' % lengthpool.dispose()---script.py FINISH------schema cli start---create keyspace ks123 with placement_strategy = 'NetworkTopologyStrategy' and strategy_options = {datacenter1 : 1} and durable_writes = true;use ks123;create column family cf1 with column_type = 'Standard' and comparator = 'AsciiType' and default_validation_class = 'AsciiType' and key_validation_class = 'AsciiType' and read_repair_chance = 0.1 and dclocal_read_repair_chance = 0.0 and populate_io_cache_on_flush = false and gc_grace = 864000 and min_compaction_threshold = 4 and max_compaction_threshold = 32 and replicate_on_write = true and compaction_strategy = 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy' and caching = 'KEYS_ONLY' and column_metadata = [ {column_name : 'indexedColumn', validation_class : AsciiType, index_name : 'INDEX1', index_type : 0}] and compression_options = {'sstable_compression' : 'org.apache.cassandra.io.compress.SnappyCompressor'};---schema cli finish---Test cluster created with 'ccm create --cassandra-version 1.2.4 --nodes 1 --start testUpdate'</description>
      <version>1.2.5</version>
      <fixedVersion>Feature/2iIndex</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.index.SecondaryIndexManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.PrecompactedRow.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LazilyCompactedRow.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5551" opendate="2013-5-9 00:00:00" fixdate="2013-5-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>intersects the bounds not right</summary>
      <description>intersecs the bound includes the left of bound instead of right</description>
      <version>1.1.12,1.2.5</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.dht.Range.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5556" opendate="2013-5-10 00:00:00" fixdate="2013-5-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enabling/Disabling incremental backup via nodetool</summary>
      <description>Change incremental backup setting via nodetool. In some scenarios, we'd like to control whether the incremental backup is switched on or off without redeploying</description>
      <version>1.2.5</version>
      <fixedVersion>Tool/nodetool</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.resources.org.apache.cassandra.tools.NodeToolHelp.yaml</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeProbe.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5562" opendate="2013-5-13 00:00:00" fixdate="2013-5-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>sstablescrub should respect MAX_HEAP_SIZE</summary>
      <description>sstablescrub has Xmx hardcoded to 256MB. This is not enough in my installation and causes an OOM.Since it's meant to be run offline, the memory usually allocated to the daemon can be safely given to the tool.Attached is a patch that makes it respect $MAX_HEAP_SIZE (with fallback to 256MB if not defined)</description>
      <version>1.2.5</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.sstablescrub</file>
    </fixedFiles>
  </bug>
  <bug id="5564" opendate="2013-5-13 00:00:00" fixdate="2013-5-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>fix memorySize bugs</summary>
      <description></description>
      <version>1.2.5</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.utils.ObjectSizes.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.IndexHelper.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowIndexEntry.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.RowCacheSentinel.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.RowCacheKey.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.KeyCacheKey.java</file>
    </fixedFiles>
  </bug>
</bugrepository>
