<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="CASSANDRA">
  <bug id="2940" opendate="2011-7-22 00:00:00" fixdate="2011-1-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make rpc_timeout_in_ms into a jmx mbean property</summary>
      <description>When using the hadoop integration especially, experimenting with rpc_timeout_in_ms is a pain if you have to restart every server in the cluster for it to take effect. This would be an improvement to make it into a jmx mbean property to set it at runtime. The yaml file could be updated separately so it would be persistent still.</description>
      <version>1.0.7</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxyMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="3155" opendate="2011-9-8 00:00:00" fixdate="2011-12-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Secondary index should report it&amp;#39;s memory consumption</summary>
      <description>Non-CFS backed secondary indexes will consume RAM which should be reported back to Cassandra to be factored into it's flush by RAM amount.</description>
      <version>1.0.7</version>
      <fixedVersion>Feature/2iIndex</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.index.SecondaryIndexManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.SecondaryIndex.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.keys.KeysIndex.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3335" opendate="2011-10-7 00:00:00" fixdate="2011-12-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ThreadPoolExecutor creates threads as non-daemon and will block on shutdown by default</summary>
      <description>This is most obviously visible in OptionalTasks which should not block shutdown, but often does.</description>
      <version>1.0.7</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.service.RemoveTest.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.ExpiringMap.java</file>
      <file type="M">src.java.org.apache.cassandra.thrift.TCustomServerSocket.java</file>
      <file type="M">src.java.org.apache.cassandra.thrift.CustomTThreadPoolServer.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3415" opendate="2011-10-28 00:00:00" fixdate="2011-12-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>show schema fails</summary>
      <description>following command breaks "show schema" cli command with error "A long is exactly 8 bytes: 5"create column family resultcache with column_type = 'Super' and comparator = 'LongType' and key_validation_class = 'UTF8Type' and subcomparator = 'AsciiType' and replicate_on_write = false and rows_cached = 700 and keys_cached = 30000 and key_cache_save_period = 0 and column_metadata = [ {column_name: id, validation_class: LongType}, {column_name: name, validation_class: 'AsciiType'}, {column_name: crc32, validation_class: LongType}, {column_name: size, validation_class: LongType} ];</description>
      <version>0.8.10,1.0.7</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cli.CliClient.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3497" opendate="2011-11-15 00:00:00" fixdate="2011-1-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>BloomFilter FP ratio should be configurable or size-restricted some other way</summary>
      <description>When you have a live dc and purely analytical dc, in many situations you can have less nodes on the analytical side, but end up getting restricted by having the BloomFilters in-memory, even though you have absolutely no use for them. It would be nice if you could reduce this memory requirement by tuning the desired FP ratio, or even just disabling them altogether.</description>
      <version>1.0.7</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.resources.org.apache.cassandra.cli.CliHelp.yaml</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.Constants.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.CfDef.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.Cassandra.java</file>
      <file type="M">interface.cassandra.thrift</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.avro.internode.genavro</file>
      <file type="M">src.java.org.apache.cassandra.cli.CliClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="3554" opendate="2011-12-2 00:00:00" fixdate="2011-12-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hints are not replayed unless node was marked down</summary>
      <description>If B drops a write from A because it is overwhelmed (but not dead), A will hint the write. But it will never get notified that B is back up (since it was never down), so it will never attempt hint delivery.</description>
      <version>1.0.7</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageServiceMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowMutation.java</file>
      <file type="M">src.java.org.apache.cassandra.db.HintedHandOffManagerMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.db.HintedHandOffManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3571" opendate="2011-12-5 00:00:00" fixdate="2011-12-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>make stream throttling configurable at runtime with nodetool</summary>
      <description>Attaching patch that does this, against 1.0.</description>
      <version>1.0.7</version>
      <fixedVersion>Tool/nodetool</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeProbe.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageServiceMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3579" opendate="2011-12-6 00:00:00" fixdate="2011-1-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>AssertionError in hintedhandoff - 1.0.5</summary>
      <description>We are running a 8 node cassandra cluster running cassandra 1.0.5.All our CF use leveled compaction. We ran a test where we did a lotof inserts for 3 days. After that we started to run tests where someof the reads could ask for information that was inserted a while back.In this scenario we are seeing this assertion error in HintedHandoff.ERROR &amp;#91;HintedHandoff:3&amp;#93; 2011-12-05 15:42:04,324AbstractCassandraDaemon.java (line 133) Fatal exception in threadThread&amp;#91;HintedHandoff:3,1,main&amp;#93;java.lang.RuntimeException: java.lang.RuntimeException:java.util.concurrent.ExecutionException: java.lang.AssertionError:originally calculated column size of 470937164 but now it is 470294247 at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:662)Caused by: java.lang.RuntimeException:java.util.concurrent.ExecutionException: java.lang.AssertionError:originally calculated column size of 470937164 but now it is 470294247 at org.apache.cassandra.db.HintedHandOffManager.deliverHintsToEndpoint(HintedHandOffManager.java:330) at org.apache.cassandra.db.HintedHandOffManager.access$100(HintedHandOffManager.java:81) at org.apache.cassandra.db.HintedHandOffManager$2.runMayThrow(HintedHandOffManager.java:353) at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30) ... 3 moreCaused by: java.util.concurrent.ExecutionException:java.lang.AssertionError: originally calculated column size of470937164 but now it is 470294247 at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222) at java.util.concurrent.FutureTask.get(FutureTask.java:83) at org.apache.cassandra.db.HintedHandOffManager.deliverHintsToEndpoint(HintedHandOffManager.java:326) ... 6 moreCaused by: java.lang.AssertionError: originally calculated column sizeof 470937164 but now it is 470294247 at org.apache.cassandra.db.compaction.LazilyCompactedRow.write(LazilyCompactedRow.java:124) at org.apache.cassandra.io.sstable.SSTableWriter.append(SSTableWriter.java:160) at org.apache.cassandra.db.compaction.CompactionTask.execute(CompactionTask.java:158) at org.apache.cassandra.db.compaction.CompactionManager$6.call(CompactionManager.java:275) at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303) at java.util.concurrent.FutureTask.run(FutureTask.java:138) ... 3 moreERROR &amp;#91;HintedHandoff:3&amp;#93; 2011-12-05 15:42:04,333AbstractCassandraDaemon.java (line 133) Fatal exception in threadThread&amp;#91;HintedHandoff:3,1,main&amp;#93;java.lang.RuntimeException: java.lang.RuntimeException:java.util.concurrent.ExecutionException: java.lang.AssertionError:originally calculated column size of 470937164 but now it is 470294247 at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:662)Caused by: java.lang.RuntimeException:java.util.concurrent.ExecutionException: java.lang.AssertionError:originally calculated column size of 470937164 but now it is 470294247 at org.apache.cassandra.db.HintedHandOffManager.deliverHintsToEndpoint(HintedHandOffManager.java:330) at org.apache.cassandra.db.HintedHandOffManager.access$100(HintedHandOffManager.java:81) at org.apache.cassandra.db.HintedHandOffManager$2.runMayThrow(HintedHandOffManager.java:353) at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30) ... 3 moreCaused by: java.util.concurrent.ExecutionException:java.lang.AssertionError: originally calculated column size of470937164 but now it is 470294247 at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222) at java.util.concurrent.FutureTask.get(FutureTask.java:83) at org.apache.cassandra.db.HintedHandOffManager.deliverHintsToEndpoint(HintedHandOffManager.java:326) ... 6 moreCaused by: java.lang.AssertionError: originally calculated column sizeof 470937164 but now it is 470294247 at org.apache.cassandra.db.compaction.LazilyCompactedRow.write(LazilyCompactedRow.java:124) at org.apache.cassandra.io.sstable.SSTableWriter.append(SSTableWriter.java:160) at org.apache.cassandra.db.compaction.CompactionTask.execute(CompactionTask.java:158) at org.apache.cassandra.db.compaction.CompactionManager$6.call(CompactionManager.java:275) at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303) at java.util.concurrent.FutureTask.run(FutureTask.java:138) ... 3 moreERROR &amp;#91;CompactionExecutor:9931&amp;#93; 2011-12-05 15:42:04,333AbstractCassandraDaemon.java (line 133) Fatal exception in threadThread&amp;#91;CompactionExecutor:9931,1,main&amp;#93;java.lang.AssertionError: originally calculated column size of470937164 but now it is 470294247 at org.apache.cassandra.db.compaction.LazilyCompactedRow.write(LazilyCompactedRow.java:124) at org.apache.cassandra.io.sstable.SSTableWriter.append(SSTableWriter.java:160) at org.apache.cassandra.db.compaction.CompactionTask.execute(CompactionTask.java:158) at org.apache.cassandra.db.compaction.CompactionManager$6.call(CompactionManager.java:275) at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303) at java.util.concurrent.FutureTask.run(FutureTask.java:138) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:662)</description>
      <version>1.0.7</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.SystemTable.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.QueryFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ExpiringColumn.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">src.java.org.apache.cassandra.db.AbstractColumnContainer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3629" opendate="2011-12-14 00:00:00" fixdate="2011-12-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bootstrapping nodes don&amp;#39;t ensure schema is ready before continuing</summary>
      <description>A bootstrapping node will assume that after it has slept for RING_DELAY it has all of the schema migrations and can continue the bootstrap process. However, with a large enough amount of migrations this is not sufficient and causes problems.</description>
      <version>1.0.7</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.MigrationManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="3644" opendate="2011-12-18 00:00:00" fixdate="2011-12-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>parsing of chunk_length_kb silently overflows</summary>
      <description>Not likely to trigger for "real" values; I noticed because some other bug caused the chunk length setting to be corrupted somehow and take on some huge value having nothing to do with what I asked for in my schema update (not yet identified why; separate issue).</description>
      <version>1.0.7</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.compress.CompressionParameters.java</file>
    </fixedFiles>
  </bug>
  <bug id="3652" opendate="2011-12-20 00:00:00" fixdate="2011-12-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>correct and improve stream protocol mismatch error</summary>
      <description>The message (and code comment) claims it got a "newer" version despite the fact that the check only determines that it is non-equal.Fix that, and also print the actual version gotten and expected.</description>
      <version>1.0.7</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.net.IncomingTcpConnection.java</file>
    </fixedFiles>
  </bug>
  <bug id="3654" opendate="2011-12-20 00:00:00" fixdate="2011-12-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Warn when the stored Gossip Generation is from the future</summary>
      <description>I had a case where the server was first started with the current time set way in the future. So the gossip generation was initialized with a very high value (background http://thelastpickle.com/2011/12/15/Anatomy-of-a-Cassandra-Partition/)There were some other issues at play, but a log message warning of the high generation would have helped.</description>
      <version>1.0.7</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.SystemTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="3656" opendate="2011-12-21 00:00:00" fixdate="2011-12-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>GC can take 0 ms</summary>
      <description></description>
      <version>0.8.10,1.0.7</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.GCInspector.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3659" opendate="2011-12-22 00:00:00" fixdate="2011-12-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Flush non-cfs backed secondary indexes along with CF</summary>
      <description>Non CFS backed secondary indexes currently don't get flushed alongside CF. Only CFS backed ones do (i.e. KEYS)</description>
      <version>1.0.7</version>
      <fixedVersion>Feature/2iIndex</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.index.SecondaryIndexManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3666" opendate="2011-12-23 00:00:00" fixdate="2011-1-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Changing compaction strategy from Leveled to SizeTiered logs millions of messages about nothing to compact</summary>
      <description>When column family compaction strategy is changed from Leveled to SizeTiered and there're Leveled compaction tasks pending, Cassandra starting to flood in logs with thousands per sec messages:Nothing to compact in ColumnFamily1. Use forceUserDefinedCompaction if you wish to force compaction of single sstables (e.g. for tombstone collection)As a result, log disk is full and system is down.</description>
      <version>1.0.7</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy.java</file>
    </fixedFiles>
  </bug>
  <bug id="3669" opendate="2011-12-23 00:00:00" fixdate="2011-1-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[patch] Word count sample has a flawed addToMutationMap, fix</summary>
      <description>The WordCount example shows how to use client.batch_mutate, and has a helper method for building a mutation map. While the example works properly, the example addToMutationMap is flawed in that it won't allow adding of multiple columns to the same row, as is what is needed to perform a 'sql like insert' operation, which is the most likely example someone learning cassandra will want to do. Fixed the sample addToMutationMap code so that it works correctly for multi column inserts in one 'row'.</description>
      <version>1.0.7</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">examples.hadoop.word.count.src.WordCountSetup.java</file>
    </fixedFiles>
  </bug>
  <bug id="3686" opendate="2011-12-30 00:00:00" fixdate="2011-12-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Streaming retry is no longer performed</summary>
      <description>CASSANDRA-3532 changed exception handling when processing incoming stream, but since it wraps all exception into RuntimeException, streaming retry which had been occurred when IOException is thrown no longer works.</description>
      <version>1.0.7</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.streaming.IncomingStreamReader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3693" opendate="2012-1-4 00:00:00" fixdate="2012-1-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>strange values of pending tasks with compactionstats (below 0)</summary>
      <description>during scrub:Every 2.0s: for i in 1 2 3; do nodetool -h 192.168.2.$i compactionstats; done Wed Jan 4 13:48:13 2012pending tasks: 2147483646 compaction type keyspace column family bytes compacted bytes total progress Compaction Archive Messages 28034971475 72393139120 38.73%pending tasks: -2147483647 compaction type keyspace column family bytes compacted bytes total progress Compaction Archive Messages 24575687282 72385305067 33.95%pending tasks: 0</description>
      <version>1.0.7</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LeveledManifest.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3696" opendate="2012-1-4 00:00:00" fixdate="2012-1-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Adding another datacenter&amp;#39;s node results in 0 rows returned on first datacenter</summary>
      <description>On Cassandra-1.0.5:1. Create a node in C* with a fresh installation and create a keyspace on that node with one column family -CREATE KEYSPACE test WITH placement_strategy = 'SimpleStrategy' and strategy_options={replication_factor:1};use test; create column family cf1;2. Insert values into cf1 -set cf1&amp;#91;ascii(&amp;#39;k&amp;#39;)&amp;#93;&amp;#91;ascii(&amp;#39;c&amp;#39;)&amp;#93; = ascii('v');get cf1&amp;#91;ascii(&amp;#39;k&amp;#39;)&amp;#93;; =&gt; (column=63, value=v, timestamp=1325689630397000) Returned 1 results.3. update the strategy options from simple to networktopology with {Cassandra:1, Backup:1} 4. read from cf1 to make sure the options change doesn't affect anything -consistencylevel as LOCAL_QUORUM; get cf1&amp;#91;ascii(&amp;#39;k&amp;#39;)&amp;#93;; =&gt; (column=63, value=v, timestamp=1325689630397000) Returned 1 results.5. start a second node in the Backup datacenter 6. read from cf1 again (on the first node) -consistencylevel as LOCAL_QUORUM; get cf1&amp;#91;ascii(&amp;#39;k&amp;#39;)&amp;#93;; Returned 0 results.After about 60 seconds, "get cf1&amp;#91;ascii(&amp;#39;k&amp;#39;)&amp;#93;" started to return results again. Also, when running at a CL of ONE on 1.0's head, we were able to see issues as well.But, if more than one node was added to the second datacenter, then replication_strategy is changed, it seems okay.</description>
      <version>0.8.10,1.0.7</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.ReadCallback.java</file>
      <file type="M">src.java.org.apache.cassandra.service.DatacenterReadCallback.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3714" opendate="2012-1-9 00:00:00" fixdate="2012-1-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Show Schema; inserts an extra comma in column_metadata</summary>
      <description>create column family inode with column_type = 'Standard' and comparator = 'DynamicCompositeType(t=&gt;org.apache.cassandra.db.marshal.TimeUUIDType,s=&gt;org.apache.cassandra.db.marshal.UTF8Type,b=&gt;org.apache.cassandra.db.marshal.BytesType)' and default_validation_class = 'BytesType' and key_validation_class = 'BytesType' and rows_cached = 0.0 and row_cache_save_period = 0 and row_cache_keys_to_save = 2147483647 and keys_cached = 1000000.0 and key_cache_save_period = 14400 and read_repair_chance = 1.0 and gc_grace = 60 and min_compaction_threshold = 4 and max_compaction_threshold = 32 and replicate_on_write = true and row_cache_provider = 'ConcurrentLinkedHashCacheProvider' and compaction_strategy = 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy' and comment = 'Stores file meta data' and column_metadata = [ {column_name : 'b@70617468', validation_class : BytesType, index_name : 'path', index_type : 0,}, {column_name : 'b@73656e74696e656c', validation_class : BytesType, index_name : 'sentinel', index_type : 0,}, {column_name : 'b@706172656e745f70617468', validation_class : BytesType, index_name : 'parent_path', index_type : 0,}];That's that was outputted when I ran show schema. When I tried it on a new cluster, it failed since the commas after 'index_type: 0' were present.Proposed fixes:1. Allow trailing commas2. Do not output trailing commas</description>
      <version>1.0.7</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cli.CliClient.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3718" opendate="2012-1-10 00:00:00" fixdate="2012-1-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh missing help for INSERT</summary>
      <description>this must have been overlooked.</description>
      <version>1.0.7</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug id="3733" opendate="2012-1-12 00:00:00" fixdate="2012-1-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Once a host has been hinted to, log messages for it repeat every 10 mins even if no hints are delivered</summary>
      <description>INFO 15:36:03,977 Started hinted handoff for token: 170141183460469231731687303715884105726 with IP: /10.179.111.137 INFO 15:36:03,978 Finished hinted handoff of 0 rows to endpoint /10.179.111.137 INFO 15:46:31,248 Started hinted handoff for token: 170141183460469231731687303715884105726 with IP: /10.179.111.137 INFO 15:46:31,249 Finished hinted handoff of 0 rows to endpoint /10.179.111.137 INFO 15:56:29,448 Started hinted handoff for token: 170141183460469231731687303715884105726 with IP: /10.179.111.137 INFO 15:56:29,449 Finished hinted handoff of 0 rows to endpoint /10.179.111.137 INFO 16:06:09,949 Started hinted handoff for token: 170141183460469231731687303715884105726 with IP: /10.179.111.137 INFO 16:06:09,950 Finished hinted handoff of 0 rows to endpoint /10.179.111.137 INFO 16:16:21,529 Started hinted handoff for token: 170141183460469231731687303715884105726 with IP: /10.179.111.137 INFO 16:16:21,530 Finished hinted handoff of 0 rows to endpoint /10.179.111.137Introduced by CASSANDRA-3554. The problem is that until a compaction on hints occurs, tombstones are present causing the isEmpty() check to be false.</description>
      <version>0.8.10,1.0.7</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.HintedHandOffManager.java</file>
    </fixedFiles>
  </bug>
</bugrepository>
