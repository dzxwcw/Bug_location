<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="CASSANDRA">
  <bug id="10004" opendate="2015-8-6 00:00:00" fixdate="2015-8-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow changing default encoding on cqlsh</summary>
      <description>Currently the encoding option is not exposed as a command line parameter, so users cannot specify a different encoding other than the System's default.</description>
      <version>2.1.9,2.2.1,3.0beta1</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug id="10015" opendate="2015-8-7 00:00:00" fixdate="2015-8-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create tool to debug why expired sstables are not getting dropped</summary>
      <description>Sometimes fully expired sstables are not getting dropped, and it is a real pain to manually find out why.A tool that outputs which sstable blocks (by having older data than the newest tombstone in an expired sstable) expired ones would save a lot of time.</description>
      <version>2.0.17,2.1.9,2.2.1,3.0beta1</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.compaction.TTLExpiryTest.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10043" opendate="2015-8-11 00:00:00" fixdate="2015-8-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>A NullPointerException is thrown if the column name is unknown for an IN relation</summary>
      <description>cqlsh:test&gt; create table newTable (a int, b int, c int, primary key(a, b));cqlsh:test&gt; select * from newTable where d in (1, 2);ServerError: &lt;ErrorMessage code=0000 [Server error] message="java.lang.NullPointerException"&gt;The problem seems to occur only for IN restrictions</description>
      <version>2.2.1,3.0beta2</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.SelectSingleColumnRelationTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.SelectOrderedPartitionerTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.SelectMultiColumnRelationTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.TokenRelation.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.SingleColumnRelation.java</file>
    </fixedFiles>
  </bug>
  <bug id="10048" opendate="2015-8-11 00:00:00" fixdate="2015-8-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cassandra-stress - Decimal is a BigInt not a Double</summary>
      <description>Similar to CASSANDRA-8882I'll provide a patch.com.datastax.driver.core.exceptions.InvalidTypeException: Invalid type for value 26 of CQL type decimal, expecting class java.math.BigDecimal but class java.lang.Double providedcom.datastax.driver.core.exceptions.InvalidTypeException: Invalid type for value 26 of CQL type decimal, expecting class java.math.BigDecimal but class java.lang.Double providedcom.datastax.driver.core.exceptions.InvalidTypeException: Invalid type for value 26 of CQL type decimal, expecting class java.math.BigDecimal but class java.lang.Double provided^Ccom.datastax.driver.core.exceptions.InvalidTypeException: Invalid type for value 26 of CQL type decimal, expecting class java.math.BigDecimal but class java.lang.Double providedcom.datastax.driver.core.exceptions.InvalidTypeException: Invalid type for value 26 of CQL type decimal, expecting class java.math.BigDecimal but class java.lang.Double providedcom.datastax.driver.core.exceptions.InvalidTypeException: Invalid type for value 26 of CQL type decimal, expecting class java.math.BigDecimal but class java.lang.Double providedcom.datastax.driver.core.exceptions.InvalidTypeException: Invalid type for value 26 of CQL type decimal, expecting class java.math.BigDecimal but class java.lang.Double providedcom.datastax.driver.core.exceptions.InvalidTypeException: Invalid type for</description>
      <version>2.1.9,2.2.1,3.0beta2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.StressProfile.java</file>
    </fixedFiles>
  </bug>
  <bug id="10049" opendate="2015-8-11 00:00:00" fixdate="2015-8-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Commitlog initialization failure</summary>
      <description>I've encountered this error locally during some dtests.It looks like a race condition in the commit log code. http://cassci.datastax.com/view/cassandra-3.0/job/cassandra-3.0_dtest/lastCompletedBuild/testReport/consistency_test/TestAccuracy/test_network_topology_strategy_users_2/</description>
      <version>2.2.1,3.0beta1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.CommitLogTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.CQLTester.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLogSegment.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLogDescriptor.java</file>
      <file type="M">test.unit.org.apache.cassandra.SchemaLoader.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.commitlog.CommitLogUpgradeTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.commitlog.CommitLogTestReplayer.java</file>
      <file type="M">test.long.org.apache.cassandra.db.commitlog.CommitLogStressTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLogSegmentManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLogReplayer.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLogArchiver.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLog.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.AbstractCommitLogService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10078" opendate="2015-8-14 00:00:00" fixdate="2015-8-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Windows dtest 2.2: rebuild_test.py:TestRebuild.simple_rebuild_test</summary>
      <description>Error text:concurrent rebuild should not be allowedFile "C:\tools\python2\lib\unittest\case.py", line 329, in run testMethod() File "D:\jenkins\workspace\cassandra-2.2_dtest_win32\cassandra-dtest\rebuild_test.py", line 87, in simple_rebuild_test self.fail("concurrent rebuild should not be allowed") File "C:\tools\python2\lib\unittest\case.py", line 410, in fail raise self.failureException(msg)'concurrent rebuild should not be allowed\n-------------------- &gt;&gt; begin captured logging &lt;&lt; --------------------\ndtest: DEBUG: cluster ccm directory: d:\\temp\\dtest-rltloj\n--------------------- &gt;&gt; end captured logging &lt;&lt; ---------------------'Failure history (Consistent)Env: Both CI and local</description>
      <version>2.2.1</version>
      <fixedVersion>Test/dtest/python</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.nodetool.bat</file>
    </fixedFiles>
  </bug>
  <bug id="10114" opendate="2015-8-18 00:00:00" fixdate="2015-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow count(*) and count(1) to be use as normal aggregation</summary>
      <description>For the following query: SELECT count(*), max(timestamp), min(timestamp) FROM myData WHERE id = ?Cassandra will throw a InvalidSyntaxException.We should allow count(&amp;#42;) and count(1) to be queried with other aggregations or columns</description>
      <version>2.2.1,3.0beta1</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.AggregationTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.selection.Selector.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.selection.AbstractFunctionSelector.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.functions.AggregateFcts.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.Cql.g</file>
      <file type="M">NEWS.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10135" opendate="2015-8-19 00:00:00" fixdate="2015-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Quoting changed for username in GRANT statement</summary>
      <description>We may have uncovered an undocumented api change between cassandra 2.1.x and 2.2.0.When granting permissions to a username containing special characters, 2.1.x needed single quotes around the username and refused doubles.2.2.0 needs doubles and refuses singles.Working example for 2.1.x:GRANT SELECT ON ALL KEYSPACES TO 'vault-readonly-root-79840dbb-917e-ed90-38e0-578226e6c1c6-1440017797';Enclosing the username in double quotes instead of singles fails with the following error message:cassandra@cqlsh&gt; GRANT SELECT ON ALL KEYSPACES TO "vault-readonly-root-79840dbb-917e-ed90-38e0-578226e6c1c6-1440017797";SyntaxException: &lt;ErrorMessage code=2000 &amp;#91;Syntax error in CQL query&amp;#93; message="line 1:33 mismatched input 'vault-readonly-root-79840dbb-917e-ed90-38e0-578226e6c1c6-1440017797' expecting set null (...SELECT ON ALL KEYSPACES TO &amp;#91;"vault-readonly-root-79840dbb-917e-ed90-38e0-578226e6c1c6-144001779&amp;#93;...)"&gt;Singles fail in 2.2.0:cassandra@cqlsh&gt; GRANT SELECT ON ALL KEYSPACES TO 'vault-readonly-root-e04e7a84-a7ba-d84f-f3c0-1e50e7590179-1440019308';SyntaxException: &lt;ErrorMessage code=2000 &amp;#91;Syntax error in CQL query&amp;#93; message="line 1:33 no viable alternative at input 'vault-readonly-root-e04e7a84-a7ba-d84f-f3c0-1e50e7590179-1440019308' (...SELECT ON ALL KEYSPACES TO &amp;#91;&amp;#39;vault-readonly-root-e04e7a84-a7ba-d84f-f3c0-1e50e7590179-144001930&amp;#93;...)"&gt;... whereas double quotes succeed:GRANT SELECT ON ALL KEYSPACES TO "vault-readonly-root-e04e7a84-a7ba-d84f-f3c0-1e50e7590179-1440019308";If this is a deliberate change, I don't think it is reflected in the documentation. I am temped to consider this a bug introduced with the role additions.Motivation for this report: https://github.com/hashicorp/vault/pull/545#issuecomment-132634630</description>
      <version>2.2.1,3.0beta2</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.miscellaneous.RoleSyntaxTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.Cql.g</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10234" opendate="2015-8-31 00:00:00" fixdate="2015-8-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add nodetool gettraceprobability command</summary>
      <description>nodetool has a settraceprobability command but there is no way to get the value from the nodetool command. Attaching patch that adds the gettraceprobability command.</description>
      <version>2.2.1,3.0beta2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeTool.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeProbe.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7342" opendate="2014-6-2 00:00:00" fixdate="2014-8-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CAS writes do not have hint functionality.</summary>
      <description>When a dead node comes up, it gets the last commit but not anything which it has missed. This reduces the durability of those writes compared to other writes.</description>
      <version>2.1.9,2.2.1,3.0beta1</version>
      <fixedVersion>Feature/LightweightTransactions</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.net.WriteCallbackInfo.java</file>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7357" opendate="2014-6-5 00:00:00" fixdate="2014-7-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cleaning up snapshots on startup leftover from repairs that got interrupted</summary>
      <description>When a repair is interrupted, such as a restart, it can leave a snapshot behind on disk. These could be checked for and cleared possibly on startup.</description>
      <version>2.1.9,2.2.1,3.0alpha1</version>
      <fixedVersion>Legacy/StreamingandMessaging</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.ColumnFamilyStoreTest.java</file>
      <file type="M">src.java.org.apache.cassandra.service.CassandraDaemon.java</file>
      <file type="M">src.java.org.apache.cassandra.repair.RepairMessageVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Directories.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="8735" opendate="2015-2-4 00:00:00" fixdate="2015-7-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Batch log replication is not randomized when there are only 2 racks</summary>
      <description>Batch log replication is not randomized and the same 2 nodes can be picked up when there are only 2 racks in the cluster.https://github.com/apache/cassandra/blob/cassandra-2.0.11/src/java/org/apache/cassandra/service/BatchlogEndpointSelector.java#L72-73</description>
      <version>2.1.9,2.2.1,3.0alpha1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.service.BatchlogEndpointFilterTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.BatchlogManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9142" opendate="2015-4-9 00:00:00" fixdate="2015-8-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>DC Local repair or -hosts should only be allowed with -full repair</summary>
      <description>We should not let users mix incremental repair with dc local repair or -host or any repair which does not include all replicas. This will currently cause stables on some replicas to be marked as repaired. The next incremental repair will not work on same set of data.</description>
      <version>2.2.1,3.0beta2</version>
      <fixedVersion>Legacy/StreamingandMessaging</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.repair.LocalSyncTaskTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.compaction.LeveledCompactionStrategyTest.java</file>
      <file type="M">src.java.org.apache.cassandra.service.ActiveRepairService.java</file>
      <file type="M">src.java.org.apache.cassandra.repair.RepairRunnable.java</file>
      <file type="M">src.java.org.apache.cassandra.repair.RepairMessageVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.repair.messages.RepairOption.java</file>
      <file type="M">src.java.org.apache.cassandra.repair.messages.RepairMessage.java</file>
      <file type="M">src.java.org.apache.cassandra.repair.messages.PrepareMessage.java</file>
    </fixedFiles>
  </bug>
  <bug id="9232" opendate="2015-4-23 00:00:00" fixdate="2015-8-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>"timestamp" is considered as a reserved keyword in cqlsh completion</summary>
      <description>cqlsh seems to treat "timestamp" as a reserved keyword when used as an identifier:cqlsh:ks1&gt; create table t1 (int int primary key, ascii ascii, bigint bigint, blob blob, boolean boolean, date date, decimal decimal, double double, float float, inet inet, text text, time time, timestamp timestamp, timeuuid timeuuid, uuid uuid, varchar varchar, varint varint);Leads to the following completion when building an INSERT statement:cqlsh:ks1&gt; insert into t1 (int, "timestamp" ascii bigint blob boolean date decimal double float inet text time timeuuid uuid varchar varint"timestamp" is a keyword but not a reserved one and should therefore not be proposed as a quoted string. It looks like this error happens only for timestamp. Not a big deal of course, but it might be worth reviewing the keywords treated as reserved in cqlsh, especially with the many changes introduced in 3.0.</description>
      <version>2.1.10,2.2.1,3.0beta2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.cqlhandling.py</file>
      <file type="M">pylib.cqlshlib.cql3handling.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9237" opendate="2015-4-24 00:00:00" fixdate="2015-8-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Gossip messages subject to head of line blocking by other intra-cluster traffic</summary>
      <description>Reported as an issue over less than perfect networks like VPNs between data centers.Gossip goes over the small message socket where small is 64k which isn't particularly small. This is done for performance to keep most traffic on one hot socket.</description>
      <version>2.2.1,3.0beta1</version>
      <fixedVersion>Legacy/StreamingandMessaging</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.nodetool.NetStats.java</file>
      <file type="M">src.java.org.apache.cassandra.net.OutboundTcpConnectionPool.java</file>
      <file type="M">src.java.org.apache.cassandra.net.MessagingServiceMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
      <file type="M">src.java.org.apache.cassandra.net.MessageOut.java</file>
      <file type="M">src.java.org.apache.cassandra.metrics.ConnectionMetrics.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9265" opendate="2015-4-29 00:00:00" fixdate="2015-8-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add checksum to saved cache files</summary>
      <description>Saved caches are not covered by a checksum. We should at least emit a checksum. My suggestion is a large checksum of the whole file (convenient offline validation), and then smaller per record checksums after each record is written (possibly a subset of the incrementally maintained larger checksum).I wouldn't go for anything fancy to try to recover from corruption since it is just a saved cache. If corruption is detected while reading I would just have it bail out. I would rather have less code to review and test in this instance.</description>
      <version>2.2.1,3.0beta1</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.util.DataIntegrityMetadata.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.AutoSavingCache.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.cassandra.io.util.ChecksummedRandomAccessReader.java</file>
    </fixedFiles>
  </bug>
  <bug id="9382" opendate="2015-5-14 00:00:00" fixdate="2015-7-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Snapshot file descriptors not getting purged (possible fd leak)</summary>
      <description>OpsCenter has the repair service which does a lot of small range repairs. Each repair would generate a snapshot as per normal. The cluster was showing a steady increase in disk space over the course of a couple of days and the only way to workaround the issue was to restart the node.Upon some further inspection it was seen that a lsof output of the cassandra process was still showing file descriptors for snapshots that no longer existed on the file system. For example:ava 5822 cassandra DEL REG 202,32 7359833 /media/ephemeral1/cassandra/data/somekeyspace/table1/snapshots/669a3a30-f3d3-11e4-bec6-3f6c4fb06498/somekeyspace-table1-jb-897689-Data.dbWe also took a heapdump which basically showed the same thing, lots of references to these file handles. We checked the logs for any errors especially relating to repairs that might have failed but there was nothing observedThe repair service logs in OpsCenter showed also that all repairs (1000s of them) had completed successfully, again showing that there was no repair issue.I have not yet been able to reproduce the issue locally on a test box. The cluster that this original issue appeared on was a production cluster with the following spec:cassandra_versions: 2.0.14.352cluster_cores : 8, cluster_instance_types : i2.2xlargecluster_os : Amazon linux amd64 node count: 4node java version: Oracle Java 1.7.0_51</description>
      <version>2.0.17,2.1.9,2.2.1,3.0alpha1</version>
      <fixedVersion>Legacy/LocalWrite-ReadPaths</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableReader.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9533" opendate="2015-6-2 00:00:00" fixdate="2015-8-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make batch commitlog mode easier to tune</summary>
      <description>As discussed in CASSANDRA-9504, 2.1 changed commitlog_sync_batch_window_in_ms from a maximum time to wait between fsync to the minimum time, so one must be very careful to keep it small enough that most writers aren't kept waiting.</description>
      <version>2.1.9,2.2.1,3.0beta1</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.BatchCommitLogService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.AbstractCommitLogService.java</file>
    </fixedFiles>
  </bug>
  <bug id="9581" opendate="2015-6-11 00:00:00" fixdate="2015-7-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>pig-tests spend time waiting on /dev/random for SecureRandom</summary>
      <description>We don't need secure random numbers (for unit tests) so waiting for entropy doesn't make much sense. Luckily Java makes it easy to point to /dev/urandom for entropy. It also transparently handles it correctly on Windows.</description>
      <version>2.2.1,3.0alpha1</version>
      <fixedVersion>Legacy/Testing</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9615" opendate="2015-6-17 00:00:00" fixdate="2015-8-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Speed up Windows launch scripts</summary>
      <description>Currently the async callback to start C* on Windows from within ccm is taking upwards of 1.5 to 2 seconds per node due to a variety of somewhat expensive process launches we're doing in there (java version check, async port open checking). Contrast this with a crisp 0-1 ms on linux...Some of that stuff can be cleaned up and sped up which should help both speed up our testing environment and iron out an error that pops up on the port check w/IPv6 (note: node still starts, just complains).</description>
      <version>2.2.1</version>
      <fixedVersion>Packaging</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.cassandra-env.ps1</file>
      <file type="M">bin.cassandra.ps1</file>
    </fixedFiles>
  </bug>
  <bug id="9648" opendate="2015-6-24 00:00:00" fixdate="2015-7-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Warn if power profile is not High Performance on Windows</summary>
      <description>Windows' power profiles have a pretty marked impact on application performance and the CPU frequency throttling is fairly aggressive even in balanced mode. As we have a large number of threads with varying work rather than a single busy thread-per-core, the scheduler on Windows sees enough downtime to constantly struggle w/our user-space operations and the frequency on the system will jump up and down even when fully saturated from a stress.I've done some benchmarking of the "Balanced" vs. "High Performance" power profiles - link to performance numbers. Note: reads are not saturating the box (or even impacting resources at all really) as the CPU's on both stress and node are sitting around 4% usage. Still have something to figure out there on 2.2.We have a few ways we can approach this - for the 1st (warn), here's a branch with warning during startup if non-High Performance power profile detected: here.Alternatively we could get more aggressive and actually attempt a powercfg /s to the GUID of the High Performance power profile or refuse to start Cassandra if we're not in the performance profile. I also briefly pursued using Sigar to query this information however the documentation for the library is no longer available (or at least I couldn't find it).</description>
      <version>2.2.1</version>
      <fixedVersion>Packaging</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.cassandra-env.ps1</file>
    </fixedFiles>
  </bug>
  <bug id="9723" opendate="2015-7-3 00:00:00" fixdate="2015-7-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>UDF / UDA execution time in trace</summary>
      <description>I'd like to see how long my UDF/As take in the trace. Checked in 2.2rc1 and doesn't appear to be mentioned.</description>
      <version>2.2.1,3.0alpha1</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.functions.UDFunction.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.functions.UDAggregate.java</file>
      <file type="M">doc.cql3.CQL.textile</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9737" opendate="2015-7-6 00:00:00" fixdate="2015-8-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Log warning when using an aggregate without partition key</summary>
      <description>After a discussion with pmcfadin thought it best to raise this. Aggregates are awesome but they are going to be mis-used. There are very few cases I can think of where we'd want users to use them across partition so maybe we should log a warning like with large batches?</description>
      <version>2.2.1,3.0beta1</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.restrictions.StatementRestrictions.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9765" opendate="2015-7-8 00:00:00" fixdate="2015-7-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>checkForEndpointCollision fails for legitimate collisions</summary>
      <description>Since CASSANDRA-7939, checkForEndpointCollision no longer catches a legitimate collision. Without CASSANDRA-7939, wiping a node and starting it again fails with 'A node with address %s already exists', but with it the node happily enters joining state, potentially streaming from the wrong place and violating consistency.</description>
      <version>2.0.17,2.1.9,2.2.1,3.0alpha1</version>
      <fixedVersion>Legacy/DistributedMetadata</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.Gossiper.java</file>
    </fixedFiles>
  </bug>
  <bug id="9793" opendate="2015-7-13 00:00:00" fixdate="2015-7-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Log when messages are dropped due to cross_node_timeout</summary>
      <description>When a node has clock skew and cross node timeouts are enabled, there's no indication that the messages were dropped due to the cross timeout, just that messages were dropped. This can errantly lead you down a path of troubleshooting a load shedding situation when really you just have clock drift on one node. This is also not simple to troubleshoot, since you have to determine that this node will answer requests, but other nodes won't answer requests from it. If the problem goes away on a reboot (and the machine does one-shot time sync, not continuous) it becomes even harder to detect because you're left with a weird piece of evidence such as "it's fine after a reboot, but comes back in about X days every time."It would help tremendously if there were a log message indicating how many messages (don't need them broken down by type) were eagerly dropped due to the cross node timeout.</description>
      <version>2.0.17,2.1.9,2.2.1</version>
      <fixedVersion>Legacy/StreamingandMessaging</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.net.MessageDeliveryTask.java</file>
      <file type="M">src.java.org.apache.cassandra.net.IncomingTcpConnection.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
    </fixedFiles>
  </bug>
  <bug id="9827" opendate="2015-7-15 00:00:00" fixdate="2015-7-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add consistency level to tracing ouput</summary>
      <description>To help get a better view of expected behavior of queries, it would be helpful if each query's consistency level (and, where applicable, the serial consistency level) were included in the tracing output. The proposed location would be within the session's row in the sessions table as an additional key-value pair included in the parameters column (along with the query string, for example). Having it here would easily allow the user to group each particular query with the actual consistency level used and thus compare it to expectation.</description>
      <version>2.1.9,2.2.1,3.0beta1</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.transport.messages.QueryMessage.java</file>
      <file type="M">src.java.org.apache.cassandra.transport.messages.ExecuteMessage.java</file>
      <file type="M">src.java.org.apache.cassandra.transport.messages.BatchMessage.java</file>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraServer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9849" opendate="2015-7-20 00:00:00" fixdate="2015-7-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Paging changes to 2.1/2.2 for backward compatibilty with 3.0</summary>
      <description>Quoting thobbs from CASSANDRA-9704:I forgot to attach a patch for the required 2.1/2.2 changes as well. Basically, when paging in 2.x, our check to see if a new page contains the same row that the previous page ended on looks for an exact cell name match. This is fine in 2.x because we will return partial rows at the end of the page (just the row marker cell). However, in 3.0, we always return full rows. While we could make some very hacky changes to 3.0 to enable returning a partial row at the end of the page, this seems like the cleanest solution.Tyler's patch is there</description>
      <version>2.1.9,2.2.1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.pager.SliceQueryPager.java</file>
      <file type="M">src.java.org.apache.cassandra.service.pager.RangeSliceQueryPager.java</file>
    </fixedFiles>
  </bug>
  <bug id="9898" opendate="2015-7-24 00:00:00" fixdate="2015-8-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh crashes if it load a utf-8 file.</summary>
      <description>cqlsh crashes when it load a cql script file encoded in utf-8.This is a reproduction procedure.$cat ./test.cql// 日本語のコメントuse system;select * from system.peers;$cqlsh --versioncqlsh 5.0.1$cqlsh -f ./test.cqlTraceback (most recent call last): File "./cqlsh", line 2459, in &lt;module&gt; main(*read_options(sys.argv[1:], os.environ)) File "./cqlsh", line 2451, in main shell.cmdloop() File "./cqlsh", line 940, in cmdloop line = self.get_input_line(self.prompt) File "./cqlsh", line 909, in get_input_line self.lastcmd = self.stdin.readline() File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/codecs.py", line 675, in readline return self.reader.readline(size) File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/codecs.py", line 530, in readline data = self.read(readsize, firstline=True) File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/codecs.py", line 477, in read newchars, decodedbytes = self.decode(data, self.errors)UnicodeDecodeError: 'ascii' codec can't decode byte 0xe6 in position 3: ordinal not in range(128)</description>
      <version>2.1.9,2.2.1,3.0beta2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.util.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9900" opendate="2015-7-25 00:00:00" fixdate="2015-7-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Anticompaction can mix old and new data with DTCS in 2.2+</summary>
      <description>since CASSANDRA-6851 we group sstables before running anticompaction on them to avoid increasing sstable count.We should not do this for DTCS as it can mix new and old data.</description>
      <version>2.2.1,3.0alpha1</version>
      <fixedVersion>Local/Compaction</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.DateTieredCompactionStrategy.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9959" opendate="2015-8-3 00:00:00" fixdate="2015-8-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expected bloom filter size should not be an int</summary>
      <description>We cast the expected number of rows in scrub and cleanup to an int. Seems to have been this way since 0.7 days. Patch here: https://github.com/krummas/cassandra/commits/marcuse/dontcastscrubcleanup</description>
      <version>2.0.17,2.1.9,2.2.1,3.0beta1</version>
      <fixedVersion>Local/Compaction</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.Scrubber.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9963" opendate="2015-8-3 00:00:00" fixdate="2015-8-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compaction not starting for new tables</summary>
      <description>Something committed since 2.1.8 broke cassandra-2.1 HEADcreate keyspace test with replication = {'class': 'SimpleStrategy', 'replication_factor': 1};create table test.stcs ( a int PRIMARY KEY , b int);repeat more than 4 times:insert into test.stcs (a, b) VALUES ( 1, 1);nodetool flush test stcsls &lt;data dir&gt;/test/stcs-*See a bunch of sstables where STCS should have kicked in and compacted them down some.</description>
      <version>2.1.9,2.2.1,3.0beta1</version>
      <fixedVersion>Local/Compaction</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.WrappingCompactionStrategy.java</file>
    </fixedFiles>
  </bug>
  <bug id="9998" opendate="2015-8-6 00:00:00" fixdate="2015-8-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LEAK DETECTED with snapshot/sequential repairs</summary>
      <description>http://cassci.datastax.com/job/cassandra-2.1_dtest/lastCompletedBuild/testReport/repair_test/TestRepair/simple_sequential_repair_test/does not happen if I add -par to the test</description>
      <version>2.1.9,2.2.1,3.0beta1</version>
      <fixedVersion>Legacy/StreamingandMessaging</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>
