<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="CASSANDRA">
  <bug id="3306" opendate="2011-10-4 00:00:00" fixdate="2011-10-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Failed streaming may cause duplicate SSTable reference</summary>
      <description>during stress testing, i always get this error making leveledcompaction strategy unusable. Should be easy to reproduce - just write fast.ERROR &amp;#91;CompactionExecutor:6&amp;#93; 2011-10-04 15:48:52,179 AbstractCassandraDaemon.java (line 133) Fatal exception in thread Thread&amp;#91;CompactionExecutor:6,5,main&amp;#93;java.lang.AssertionError at org.apache.cassandra.db.DataTracker$View.newSSTables(DataTracker.java:580) at org.apache.cassandra.db.DataTracker$View.replace(DataTracker.java:546) at org.apache.cassandra.db.DataTracker.replace(DataTracker.java:268) at org.apache.cassandra.db.DataTracker.replaceCompactedSSTables(DataTracker.java:232) at org.apache.cassandra.db.ColumnFamilyStore.replaceCompactedSSTables(ColumnFamilyStore.java:960) at org.apache.cassandra.db.compaction.CompactionTask.execute(CompactionTask.java:199) at org.apache.cassandra.db.compaction.LeveledCompactionTask.execute(LeveledCompactionTask.java:47) at org.apache.cassandra.db.compaction.CompactionManager$1.call(CompactionManager.java:131) at org.apache.cassandra.db.compaction.CompactionManager$1.call(CompactionManager.java:114) at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303) at java.util.concurrent.FutureTask.run(FutureTask.java:138) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:662)and this is in json data for table:{ "generations" : [ { "generation" : 0, "members" : [ 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484 ] }, { "generation" : 1, "members" : [ ] }, { "generation" : 2, "members" : [ ] }, { "generation" : 3, "members" : [ ] }, { "generation" : 4, "members" : [ ] }, { "generation" : 5, "members" : [ ] }, { "generation" : 6, "members" : [ ] }, { "generation" : 7, "members" : [ ] } ]}</description>
      <version>1.1.7,1.2.0beta2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamInSession.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.IncomingStreamReader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3756" opendate="2012-1-19 00:00:00" fixdate="2012-10-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh: allow configuration of value display formats</summary>
      <description>With CASSANDRA-3726, cqlsh now formats some types of query result data to be more human-readable, such as timestamps and hex data. The format of timestamps and the precision of floating point values should be configurable by cqlshrc and/or command line.see the Shell.display_time_format and Shell.display_float_precision attributes.</description>
      <version>1.1.7</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug id="4664" opendate="2012-9-13 00:00:00" fixdate="2012-10-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Rename permission USE to DESCRIBE.</summary>
      <description>We should change USE permission to DESCRIBE as it better reflects it's meaning.</description>
      <version>1.1.7</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql.QueryProcessor.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.QueryProcessor.java</file>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraServer.java</file>
      <file type="M">src.java.org.apache.cassandra.service.ClientState.java</file>
      <file type="M">src.java.org.apache.cassandra.auth.Permission.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4765" opendate="2012-10-4 00:00:00" fixdate="2012-10-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>StackOverflowError in CompactionExecutor thread</summary>
      <description>Seeing the following error:Exception in thread Thread&amp;#91;CompactionExecutor:21,1,RMI Runtime&amp;#93;java.lang.StackOverflowError at com.google.common.collect.Sets$1.iterator(Sets.java:578) at com.google.common.collect.Sets$1.iterator(Sets.java:578) at com.google.common.collect.Sets$1.iterator(Sets.java:578) at com.google.common.collect.Sets$1.iterator(Sets.java:578) at com.google.common.collect.Sets$1.iterator(Sets.java:578) at com.google.common.collect.Sets$1.iterator(Sets.java:578) at com.google.common.collect.Sets$1.iterator(Sets.java:578) at com.google.common.collect.Sets$1.iterator(Sets.java:578) at com.google.common.collect.Sets$1.iterator(Sets.java:578) at com.google.common.collect.Sets$1.iterator(Sets.java:578) at com.google.common.collect.Sets$1.iterator(Sets.java:578) at com.google.common.collect.Sets$1.iterator(Sets.java:578) at com.google.common.collect.Sets$1.iterator(Sets.java:578) at com.google.common.collect.Sets$1.iterator(Sets.java:578)</description>
      <version>1.1.7,1.2.0beta2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4807" opendate="2012-10-15 00:00:00" fixdate="2012-10-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compaction progress counts more than 100%</summary>
      <description>'nodetool compactionstats' compaction progress counts more than 100%:pending tasks: 74 compaction type keyspace column family bytes compacted bytes total progress Validation KSP CF1 56192578305 84652768917 66.38% Compaction KSP CF2 162018591 119913592 135.11%Hadn't experienced this before 1.1.3. Is it due to changes in 1.1.4-1.1.6 ?</description>
      <version>1.1.7,1.2.0beta2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.compaction.LeveledCompactionStrategyTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LeveledCompactionStrategy.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4811" opendate="2012-10-16 00:00:00" fixdate="2012-10-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Some cqlsh help topics don&amp;#39;t work (select, create, insert and anything else that is a cql statement)</summary>
      <description>cqlsh&gt; help selectImproper help command.Same will happen if you look up a help topic for any other cql statement.38748b43d8de17375c7cc16e7a4969ca4c1a2aa1 broke it (#4198) 5 months ago.</description>
      <version>1.1.7,1.2.0beta2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug id="4816" opendate="2012-10-16 00:00:00" fixdate="2012-10-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Broken get_paged_slice</summary>
      <description>get_paged_slice doesn't reset the start column filter for the second returned row sometimes. So instead of getting a slice:row 0: &lt;start_column&gt;...&lt;last_column_in_row&gt;row 1: &lt;first column in a row&gt;...&lt;last_column_in_row&gt;row 2: &lt;first column in a row&gt;...you sometimes get:row 0: &lt;start_column&gt;...&lt;last_column_in_row&gt;row 1: &lt;start_column&gt;...&lt;last_column_in_row&gt;row 2: &lt;first column in a row&gt;...</description>
      <version>1.1.7,1.2.0beta2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableScanner.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowIteratorFactory.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4820" opendate="2012-10-17 00:00:00" fixdate="2012-10-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a close() method to CRAR to prevent leaking file descriptors.</summary>
      <description>The problem is that under heavy load Finalizer daemon is unable to keep up with number of "source" and "channel" fields from CRAR to finalize (as FileInputStream has custom finalize() which calls close inside) which creates memory/cpu pressure on the machine.</description>
      <version>1.1.7</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.compress.CompressedRandomAccessReader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4828" opendate="2012-10-17 00:00:00" fixdate="2012-10-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>default cache provider does not match default yaml</summary>
      <description>The yaml indicates SerializingCacheProvider is the default, however the default when not present in the yaml is actually ConcurrentLinkedHashCacheProvider.</description>
      <version>1.1.7</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
    </fixedFiles>
  </bug>
  <bug id="4833" opendate="2012-10-18 00:00:00" fixdate="2012-10-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>get_count with &amp;#39;count&amp;#39; param between 1024 and ~actual column count fails</summary>
      <description>If you run get_count() with the 'count' param of the SliceRange set to a number between 1024 and (approximately) the actual number of columns in the row, something seems to silently fail internally, resulting in a client side timeout. Using a 'count' param outside of this range (lower or much higher) works just fine.This seems to affect all of 1.1 and 1.2.0-beta1, but not 1.0.</description>
      <version>1.1.7,1.2.0beta2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.service.CassandraServerTest.java</file>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraServer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4840" opendate="2012-10-19 00:00:00" fixdate="2012-11-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>remnants of removed nodes remain after removal</summary>
      <description>After nodes are removed from the ring and no longer appear in any of the nodes' nodetool ring output, some of the dead nodes show up in the o.a.c.net.FailureDetector SimpleStates metadata. Also, some of the JMX stats are updating for the removed nodes (ie RecentTimeoutsPerHost and ResponsePendingTasks).</description>
      <version>1.1.7</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.Gossiper.java</file>
    </fixedFiles>
  </bug>
  <bug id="4855" opendate="2012-10-24 00:00:00" fixdate="2012-10-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Debian packaging doesn&amp;#39;t do auto-reloading of log4j properties file</summary>
      <description>Cassandra isn't starting the log4j auto-reload thread because it requires -Dlog4j.defaultInitOverride=true on initialization. Is there a reason to not do this when installed from the Debian package?</description>
      <version>1.1.7</version>
      <fixedVersion>Packaging</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">debian.init</file>
    </fixedFiles>
  </bug>
  <bug id="4864" opendate="2012-10-26 00:00:00" fixdate="2012-10-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CQL2 CREATE COLUMNFAMILY checks wrong permission</summary>
      <description>Permission is asked for resource &amp;#91;cassandra, keyspaces, &lt;column family name&gt;&amp;#93; instead of &amp;#91;cassandra, keyspaces, &lt;keyspace name&gt;&amp;#93;</description>
      <version>1.1.7,1.2.0beta2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql.QueryProcessor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4880" opendate="2012-10-30 00:00:00" fixdate="2012-1-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Endless loop flushing+compacting system/schema_keyspaces and system/schema_columnfamilies</summary>
      <description>After upgrading a node from 1.1.2 to 1.1.6, the startup sequence entered a loop as seen here:http://mina.naguib.ca/misc/cassandra_116_startup_loop.txtStopping and starting the node entered the same loop.Reverting back to 1.1.2 started successfully.</description>
      <version>1.1.7,1.2.0beta3</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.MigrationManager.java</file>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowMutation.java</file>
      <file type="M">src.java.org.apache.cassandra.db.DefsTable.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4910" opendate="2012-11-5 00:00:00" fixdate="2012-11-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CQL3 doesn&amp;#39;t allow static CF definition with compact storage in C* 1.1</summary>
      <description>In Cassandra 1.1, the following CQL3 definition:CREATE TABLE user_profiles ( user_id text PRIMARY KEY, first_name text, last_name text, year_of_birth int) WITH COMPACT STORAGE;yields:Bad Request: COMPACT STORAGE requires at least one column part of the clustering key, none foundThis works fine in 1.2 however.</description>
      <version>1.1.7</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateColumnFamilyStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4921" opendate="2012-11-6 00:00:00" fixdate="2012-11-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>improve cqlsh COPY FROM performance</summary>
      <description>Profiling shows that prepare_inline takes the vast majority of cqlsh COPY FROM time, particularly on csv rows with many columns.</description>
      <version>1.1.7</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">lib.cql-internal-only-1.0.10.zip</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
</bugrepository>
