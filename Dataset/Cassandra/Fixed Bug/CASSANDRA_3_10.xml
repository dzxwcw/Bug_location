<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="CASSANDRA">
  <bug id="10368" opendate="2015-9-17 00:00:00" fixdate="2015-7-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support Restricting non-PK Cols in Materialized View Select Statements</summary>
      <description>CASSANDRA-9664 allows materialized views to restrict primary key columns in the select statement. Due to CASSANDRA-10261, the patch did not include support for restricting non-PK columns. Now that the timestamp issue has been resolved, we can add support for this.</description>
      <version>3.10</version>
      <fixedVersion>Feature/MaterializedViews,Legacy/CQL</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.ViewSchemaTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.ViewFilteringTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateViewStatement.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10635" opendate="2015-11-2 00:00:00" fixdate="2015-7-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add metrics for authentication failures</summary>
      <description>There should be no auth failures on a cluster in general. Having metrics around the authentication code would help detect clients that are connecting to the wrong cluster or have auth incorrectly configured.</description>
      <version>3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.transport.messages.CredentialsMessage.java</file>
      <file type="M">src.java.org.apache.cassandra.transport.messages.AuthResponse.java</file>
      <file type="M">src.java.org.apache.cassandra.service.NativeTransportService.java</file>
      <file type="M">src.java.org.apache.cassandra.metrics.ClientMetrics.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10707" opendate="2015-11-14 00:00:00" fixdate="2015-8-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add support for Group By to Select statement</summary>
      <description>Now that Cassandra support aggregate functions, it makes sense to support GROUP BY on the SELECT statements.It should be possible to group either at the partition level or at the clustering column level.SELECT partitionKey, max(value) FROM myTable GROUP BY partitionKey;SELECT partitionKey, clustering0, clustering1, max(value) FROM myTable GROUP BY partitionKey, clustering0, clustering1;</description>
      <version>3.10</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.SelectSingleColumnRelationTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.SelectMultiColumnRelationTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.CQLTester.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.service.pager.SinglePartitionPager.java</file>
      <file type="M">src.java.org.apache.cassandra.service.pager.QueryPager.java</file>
      <file type="M">src.java.org.apache.cassandra.service.pager.PartitionRangeQueryPager.java</file>
      <file type="M">src.java.org.apache.cassandra.service.pager.MultiPartitionPager.java</file>
      <file type="M">src.java.org.apache.cassandra.service.pager.AbstractQueryPager.java</file>
      <file type="M">src.java.org.apache.cassandra.service.DataResolver.java</file>
      <file type="M">src.java.org.apache.cassandra.db.SinglePartitionReadCommand.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ReadQuery.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ReadCommand.java</file>
      <file type="M">src.java.org.apache.cassandra.db.PartitionRangeReadCommand.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.DataLimits.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ClusteringComparator.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.ModificationStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateViewStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.SingleColumnRelation.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.selection.Selection.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.restrictions.TokenRestriction.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.restrictions.TokenFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.restrictions.StatementRestrictions.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.restrictions.SingleColumnRestriction.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.restrictions.RestrictionSetWrapper.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.restrictions.RestrictionSet.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.restrictions.Restrictions.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.restrictions.MultiColumnRestriction.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.MultiColumnRelation.java</file>
      <file type="M">src.antlr.Parser.g</file>
      <file type="M">src.antlr.Lexer.g</file>
      <file type="M">pylib.cqlshlib.cql3handling.py</file>
      <file type="M">NEWS.txt</file>
      <file type="M">doc.source.cql.dml.rst</file>
      <file type="M">doc.source.cql.changes.rst</file>
      <file type="M">doc.cql3.CQL.textile</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11031" opendate="2016-1-19 00:00:00" fixdate="2016-9-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow filtering on partition key columns for queries without secondary indexes</summary>
      <description>Currently, Allow Filtering only works for secondary Index column or clustering columns. And it's slow, because Cassandra will read all data from SSTABLE from hard-disk to memory to filter.But we can support allow filtering on Partition Key, as far as I know, Partition Key is in memory, so we can easily filter them, and then read required data from SSTable.This will similar to "Select * from table" which scan through entire cluster.CREATE TABLE multi_tenant_table ( tenant_id text, pk2 text, c1 text, c2 text, v1 text, v2 text, PRIMARY KEY ((tenant_id,pk2),c1,c2)) ;Select * from multi_tenant_table where tenant_id = "datastax" allow filtering;</description>
      <version>3.10</version>
      <fixedVersion>Feature/2iIndex,Legacy/CQL</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.index.internal.CassandraIndexTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.ViewTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.ViewFilteringTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.SelectTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.SelectSingleColumnRelationTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.SelectOrderedPartitionerTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.SelectMultiColumnRelationTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.SecondaryIndexTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.RowFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.SingleColumnRelation.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.restrictions.TokenRestriction.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.restrictions.TokenFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.restrictions.StatementRestrictions.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.restrictions.RestrictionSetWrapper.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.restrictions.RestrictionSet.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.restrictions.Restrictions.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.restrictions.PartitionKeySingleRestrictionSet.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.restrictions.PartitionKeyRestrictions.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11117" opendate="2016-2-3 00:00:00" fixdate="2016-10-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ColUpdateTimeDeltaHistogram histogram overflow</summary>
      <description>getting attribute Mean of org.apache.cassandra.metrics:type=ColumnFamily,name=ColUpdateTimeDeltaHistogram threw an exceptionjavax.management.RuntimeMBeanException: java.lang.IllegalStateException: Unable to compute ceiling for max when histogram overflowedAlthough the fact that this histogram has 164 buckets already, I wonder if there is something weird with the computation thats causing this to be so large? It appears to be coming from updates to system.localorg.apache.cassandra.metrics:type=Table,keyspace=system,scope=local,name=ColUpdateTimeDeltaHistogram</description>
      <version>2.2.9,3.0.10,3.10,4.0-alpha1,4.0</version>
      <fixedVersion>Legacy/Observability</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.ColumnFamilyMetricTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11126" opendate="2016-2-5 00:00:00" fixdate="2016-9-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>select_distinct_with_deletions_test failing on non-vnode environments</summary>
      <description>Looks like this was fixed in CASSANDRA-10762, but not for non-vnode environments:$ DISABLE_VNODES=yes KEEP_TEST_DIR=yes CASSANDRA_VERSION=git:cassandra-3.0 PRINT_DEBUG=true nosetests -s -v upgrade_tests/cql_tests.py:TestCQLNodes2RF1.select_distinct_with_deletions_testselect_distinct_with_deletions_test (upgrade_tests.cql_tests.TestCQLNodes2RF1) ... cluster ccm directory: /tmp/dtest-UXb0unhttp://git-wip-us.apache.org/repos/asf/cassandra.git git:cassandra-3.0Custom init_config not found. Setting defaults.Done setting configuration options:{ 'num_tokens': None, 'phi_convict_threshold': 5, 'range_request_timeout_in_ms': 10000, 'read_request_timeout_in_ms': 10000, 'request_timeout_in_ms': 10000, 'truncate_request_timeout_in_ms': 10000, 'write_request_timeout_in_ms': 10000}getting default job version for 3.0.3UpgradePath(starting_version='binary:2.2.3', upgrade_version=None)starting from 2.2.3upgrading to {'install_dir': '/home/ryan/.ccm/repository/gitCOLONcassandra-3.0'}Querying upgraded nodeFAIL======================================================================FAIL: select_distinct_with_deletions_test (upgrade_tests.cql_tests.TestCQLNodes2RF1)----------------------------------------------------------------------Traceback (most recent call last): File "/home/ryan/git/datastax/cassandra-dtest/upgrade_tests/cql_tests.py", line 3360, in select_distinct_with_deletions_test self.assertEqual(9, len(rows))AssertionError: 9 != 8-------------------- &gt;&gt; begin captured logging &lt;&lt; --------------------dtest: DEBUG: cluster ccm directory: /tmp/dtest-UXb0undtest: DEBUG: Custom init_config not found. Setting defaults.dtest: DEBUG: Done setting configuration options:{ 'num_tokens': None, 'phi_convict_threshold': 5, 'range_request_timeout_in_ms': 10000, 'read_request_timeout_in_ms': 10000, 'request_timeout_in_ms': 10000, 'truncate_request_timeout_in_ms': 10000, 'write_request_timeout_in_ms': 10000}dtest: DEBUG: getting default job version for 3.0.3dtest: DEBUG: UpgradePath(starting_version='binary:2.2.3', upgrade_version=None)dtest: DEBUG: starting from 2.2.3dtest: DEBUG: upgrading to {'install_dir': '/home/ryan/.ccm/repository/gitCOLONcassandra-3.0'}dtest: DEBUG: Querying upgraded node--------------------- &gt;&gt; end captured logging &lt;&lt; -------------------------------------------------------------------------------------------Ran 1 test in 56.022sFAILED (failures=1)</description>
      <version>3.0.9,3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.pager.PagingState.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ReadCommand.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11332" opendate="2016-3-9 00:00:00" fixdate="2016-9-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>nodes connect to themselves when NTS is used</summary>
      <description>I tested this with both the simple snitch and PFS. It's quite easy to repro, setup a cluster, start it. Mine looks like this:tcp 0 0 10.208.8.123:48003 10.208.8.63:7000 ESTABLISHED 26254/javatcp 0 0 10.208.8.123:7000 10.208.8.63:40215 ESTABLISHED 26254/javatcp 0 0 10.208.8.123:55559 10.208.35.225:7000 ESTABLISHED 26254/javatcp 0 0 10.208.8.123:33498 10.208.8.63:7000 ESTABLISHED 26254/javatcp 0 0 10.208.8.123:7000 10.208.35.225:52530 ESTABLISHED 26254/javatcp 0 0 10.208.8.123:7000 10.208.35.225:53674 ESTABLISHED 26254/javatcp 0 0 10.208.8.123:40846 10.208.35.225:7000 ESTABLISHED 26254/javatcp 0 0 10.208.8.123:7000 10.208.8.63:48880 ESTABLISHED 26254/javaNo problems so far. Now create a keyspace using NTS with an rf of 3, and perform some writes. Now it looks like this:tcp 0 0 10.208.8.123:48003 10.208.8.63:7000 ESTABLISHED 26254/java tcp 0 0 10.208.8.123:7000 10.208.8.123:35024 ESTABLISHED 26254/java tcp 0 0 10.208.8.123:35024 10.208.8.123:7000 ESTABLISHED 26254/java tcp 0 0 10.208.8.123:47212 10.208.8.123:7000 ESTABLISHED 26254/java tcp 0 0 10.208.8.123:7000 10.208.8.63:40215 ESTABLISHED 26254/java tcp 0 0 10.208.8.123:55559 10.208.35.225:7000 ESTABLISHED 26254/java tcp 0 0 10.208.8.123:33498 10.208.8.63:7000 ESTABLISHED 26254/java tcp 0 0 10.208.8.123:7000 10.208.35.225:52530 ESTABLISHED 26254/java tcp 0 0 10.208.8.123:7000 10.208.35.225:53674 ESTABLISHED 26254/java tcp 0 0 10.208.8.123:7000 10.208.8.123:47212 ESTABLISHED 26254/java tcp 0 0 10.208.8.123:40846 10.208.35.225:7000 ESTABLISHED 26254/java tcp 0 0 10.208.8.123:7000 10.208.8.63:48880 ESTABLISHED 26254/java I can't think of any reason for a node to connect to itself, and this can cause problems with PFS where you might only define the broadcast addresses, but now you need the internal addresses too because the node will need to look itself up when connecting to itself.</description>
      <version>2.2.8,3.0.9,3.10</version>
      <fixedVersion>Legacy/Core</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.locator.PropertyFileSnitch.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11363" opendate="2016-3-16 00:00:00" fixdate="2016-9-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>High Blocked NTR When Connecting</summary>
      <description>When upgrading from 2.1.9 to 2.1.13, we are witnessing an issue where the machine load increases to very high levels (&gt; 120 on an 8 core machine) and native transport requests get blocked in tpstats.I was able to reproduce this in both CMS and G1GC as well as on JVM 7 and 8.The issue does not seem to affect the nodes running 2.1.9.The issue seems to coincide with the number of connections OR the number of total requests being processed at a given time (as the latter increases with the former in our system)Currently there is between 600 and 800 client connections on each machine and each machine is handling roughly 2000-3000 client requests per second.Disabling the binary protocol fixes the issue for this node but isn't a viable option cluster-wide.Here is the output from tpstats:Pool Name Active Pending Completed Blocked All time blockedMutationStage 0 8 8387821 0 0ReadStage 0 0 355860 0 0RequestResponseStage 0 7 2532457 0 0ReadRepairStage 0 0 150 0 0CounterMutationStage 32 104 897560 0 0MiscStage 0 0 0 0 0HintedHandoff 0 0 65 0 0GossipStage 0 0 2338 0 0CacheCleanupExecutor 0 0 0 0 0InternalResponseStage 0 0 0 0 0CommitLogArchiver 0 0 0 0 0CompactionExecutor 2 190 474 0 0ValidationExecutor 0 0 0 0 0MigrationStage 0 0 10 0 0AntiEntropyStage 0 0 0 0 0PendingRangeCalculator 0 0 310 0 0Sampler 0 0 0 0 0MemtableFlushWriter 1 10 94 0 0MemtablePostFlush 1 34 257 0 0MemtableReclaimMemory 0 0 94 0 0Native-Transport-Requests 128 156 387957 16 278451Message type DroppedREAD 0RANGE_SLICE 0_TRACE 0MUTATION 0COUNTER_MUTATION 0BINARY 0REQUEST_RESPONSE 0PAGED_RANGE 0READ_REPAIR 0Attached is the jstack output for both CMS and G1GC.Flight recordings are here:https://s3.amazonaws.com/simple-logs/cassandra-102-cms.jfrhttps://s3.amazonaws.com/simple-logs/cassandra-102-g1gc.jfrIt is interesting to note that while the flight recording was taking place, the load on the machine went back to healthy, and when the flight recording finished the load went back to &gt; 100.</description>
      <version>2.1.16,2.2.8,3.0.10,3.10</version>
      <fixedVersion>Legacy/Coordination</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.transport.RequestThreadPoolExecutor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11424" opendate="2016-3-24 00:00:00" fixdate="2016-7-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Option to leave omitted columns in INSERT JSON unset</summary>
      <description>CASSANDRA-7304 introduced the ability to distinguish between NULL and UNSET prepared statement parameters.When inserting JSON objects it is not possible to profit from this as a prepared statement only has one parameter that is bound to the JSON object as a whole. There is no way to control NULL vs UNSET behavior for columns omitted from the JSON object.Please extend on CASSANDRA-7304 to include JSON support.(My personal requirement is to be able to insert JSON objects with optional fields without incurring the overhead of creating a tombstone of every column not covered by the JSON object upon initial insert.)</description>
      <version>3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.JsonTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.UpdateStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.Json.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.Constants.java</file>
      <file type="M">src.antlr.Parser.g</file>
      <file type="M">src.antlr.Lexer.g</file>
      <file type="M">NEWS.txt</file>
      <file type="M">doc.source.cql.json.rst</file>
      <file type="M">doc.source.cql.dml.rst</file>
      <file type="M">doc.source.cql.changes.rst</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11594" opendate="2016-4-18 00:00:00" fixdate="2016-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Too many open files on directories</summary>
      <description>I have a 6 nodes cluster in prod in 3 racks.each node : 4Gb commitlogs on 343 files 275Gb data on 504 filesOn saturday, 1 node in each rack crash with with too many open files (seems to be the similar node in each rack).lsof -n -p $PID give me 66899 out of 65826 maxit contains 64527 open directories (2371 uniq)a part of the list :java 19076 root 2140r DIR 8,17 143360 4386718705 /opt/stage2/pod-cassandra-aci-cassandra/rootfs/data/keyspaces/email_logs_query/emails-2d4abd00e9ea11e591199d740e07bd95java 19076 root 2141r DIR 8,17 143360 4386718705 /opt/stage2/pod-cassandra-aci-cassandra/rootfs/data/keyspaces/email_logs_query/emails-2d4abd00e9ea11e591199d740e07bd95java 19076 root 2142r DIR 8,17 143360 4386718705 /opt/stage2/pod-cassandra-aci-cassandra/rootfs/data/keyspaces/email_logs_query/emails-2d4abd00e9ea11e591199d740e07bd95java 19076 root 2143r DIR 8,17 143360 4386718705 /opt/stage2/pod-cassandra-aci-cassandra/rootfs/data/keyspaces/email_logs_query/emails-2d4abd00e9ea11e591199d740e07bd95java 19076 root 2144r DIR 8,17 143360 4386718705 /opt/stage2/pod-cassandra-aci-cassandra/rootfs/data/keyspaces/email_logs_query/emails-2d4abd00e9ea11e591199d740e07bd95java 19076 root 2145r DIR 8,17 143360 4386718705 /opt/stage2/pod-cassandra-aci-cassandra/rootfs/data/keyspaces/email_logs_query/emails-2d4abd00e9ea11e591199d740e07bd95java 19076 root 2146r DIR 8,17 143360 4386718705 /opt/stage2/pod-cassandra-aci-cassandra/rootfs/data/keyspaces/email_logs_query/emails-2d4abd00e9ea11e591199d740e07bd95java 19076 root 2147r DIR 8,17 143360 4386718705 /opt/stage2/pod-cassandra-aci-cassandra/rootfs/data/keyspaces/email_logs_query/emails-2d4abd00e9ea11e591199d740e07bd95java 19076 root 2148r DIR 8,17 143360 4386718705 /opt/stage2/pod-cassandra-aci-cassandra/rootfs/data/keyspaces/email_logs_query/emails-2d4abd00e9ea11e591199d740e07bd95java 19076 root 2149r DIR 8,17 143360 4386718705 /opt/stage2/pod-cassandra-aci-cassandra/rootfs/data/keyspaces/email_logs_query/emails-2d4abd00e9ea11e591199d740e07bd95java 19076 root 2150r DIR 8,17 143360 4386718705 /opt/stage2/pod-cassandra-aci-cassandra/rootfs/data/keyspaces/email_logs_query/emails-2d4abd00e9ea11e591199d740e07bd95java 19076 root 2151r DIR 8,17 143360 4386718705 /opt/stage2/pod-cassandra-aci-cassandra/rootfs/data/keyspaces/email_logs_query/emails-2d4abd00e9ea11e591199d740e07bd95java 19076 root 2152r DIR 8,17 143360 4386718705 /opt/stage2/pod-cassandra-aci-cassandra/rootfs/data/keyspaces/email_logs_query/emails-2d4abd00e9ea11e591199d740e07bd95java 19076 root 2153r DIR 8,17 143360 4386718705 /opt/stage2/pod-cassandra-aci-cassandra/rootfs/data/keyspaces/email_logs_query/emails-2d4abd00e9ea11e591199d740e07bd95java 19076 root 2154r DIR 8,17 143360 4386718705 /opt/stage2/pod-cassandra-aci-cassandra/rootfs/data/keyspaces/email_logs_query/emails-2d4abd00e9ea11e591199d740e07bd95java 19076 root 2155r DIR 8,17 143360 4386718705 /opt/stage2/pod-cassandra-aci-cassandra/rootfs/data/keyspaces/email_logs_query/emails-2d4abd00e9ea11e591199d740e07bd95The 3 others nodes crashes 4 hours later</description>
      <version>3.0.9,3.10</version>
      <fixedVersion>Legacy/Core</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.lifecycle.LogTransaction.java</file>
      <file type="M">src.java.org.apache.cassandra.db.lifecycle.LogReplicaSet.java</file>
      <file type="M">src.java.org.apache.cassandra.db.lifecycle.LogReplica.java</file>
      <file type="M">src.java.org.apache.cassandra.db.lifecycle.LogFile.java</file>
      <file type="M">src.java.org.apache.cassandra.db.lifecycle.LogAwareFileLister.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11803" opendate="2016-5-13 00:00:00" fixdate="2016-10-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Creating a materialized view on a table with "token" column breaks the cluster</summary>
      <description>On a new Cassandra cluster, if we create a table with a field called "token" (with quotes) and then create a materialized view that uses "token", the cluster breaks. A ServerError is returned, and no further nodetool operations on the sstables work. Restarting the Cassandra server will also fail. It seems like the entire cluster is hosed.We tried this on Cassandra 3.3 and 3.5. Here's how to produce (on an new, empty cassandra 3.5 docker container):[cqlsh 5.0.1 | Cassandra 3.5 | CQL spec 3.4.0 | Native protocol v4]Use HELP for help.cqlsh&gt; CREATE KEYSPACE account WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 };cqlsh&gt; CREATE TABLE account.session ( ... "token" blob, ... account_id uuid, ... PRIMARY KEY("token") ... )WITH compaction={'class': 'LeveledCompactionStrategy'} AND ... compression={'sstable_compression': 'LZ4Compressor'};cqlsh&gt; CREATE MATERIALIZED VIEW account.account_session AS ... SELECT account_id,"token" FROM account.session ... WHERE "token" IS NOT NULL and account_id IS NOT NULL ... PRIMARY KEY (account_id, "token");ServerError: &lt;ErrorMessage code=0000 [Server error] message="java.lang.RuntimeException: java.util.concurrent.ExecutionException: org.apache.cassandra.exceptions.SyntaxException: line 1:25 no viable alternative at input 'FROM' (SELECT account_id, token [FROM]...)"&gt;cqlsh&gt; drop table account.session;ServerError: &lt;ErrorMessage code=0000 [Server error] message="java.lang.RuntimeException: java.util.concurrent.ExecutionException: org.apache.cassandra.exceptions.SyntaxException: line 1:25 no viable alternative at input 'FROM' (SELECT account_id, token [FROM]...)"&gt;When any sstable*, nodetool, or when the Cassandra process is restarted, this is emitted on startup and Cassandra exits (copied from a server w/ data):INFO [main] 2016-05-12 23:25:30,074 ColumnFamilyStore.java:395 - Initializing system_schema.indexesDEBUG [SSTableBatchOpen:1] 2016-05-12 23:25:30,075 SSTableReader.java:480 - Opening /mnt/cassandra/data/system_schema/indexes-0feb57ac311f382fba6d9024d305702f/ma-4-big (91 bytes)ERROR [main] 2016-05-12 23:25:30,143 CassandraDaemon.java:697 - Exception encountered during startuporg.apache.cassandra.exceptions.SyntaxException: line 1:59 no viable alternative at input 'FROM' (..., expire_at, last_used, token [FROM]...) at org.apache.cassandra.cql3.ErrorCollector.throwFirstSyntaxError(ErrorCollector.java:101) ~[apache-cassandra-3.5.0.jar:3.5.0] at org.apache.cassandra.cql3.CQLFragmentParser.parseAnyUnhandled(CQLFragmentParser.java:80) ~[apache-cassandra-3.5.0.jar:3.5.0] at org.apache.cassandra.cql3.QueryProcessor.parseStatement(QueryProcessor.java:512) ~[apache-cassandra-3.5.0.jar:3.5.0] at org.apache.cassandra.schema.SchemaKeyspace.fetchView(SchemaKeyspace.java:1128) ~[apache-cassandra-3.5.0.jar:3.5.0] at org.apache.cassandra.schema.SchemaKeyspace.fetchViews(SchemaKeyspace.java:1092) ~[apache-cassandra-3.5.0.jar:3.5.0] at org.apache.cassandra.schema.SchemaKeyspace.fetchKeyspace(SchemaKeyspace.java:903) ~[apache-cassandra-3.5.0.jar:3.5.0] at org.apache.cassandra.schema.SchemaKeyspace.fetchKeyspacesWithout(SchemaKeyspace.java:879) ~[apache-cassandra-3.5.0.jar:3.5.0] at org.apache.cassandra.schema.SchemaKeyspace.fetchNonSystemKeyspaces(SchemaKeyspace.java:867) ~[apache-cassandra-3.5.0.jar:3.5.0] at org.apache.cassandra.config.Schema.loadFromDisk(Schema.java:134) ~[apache-cassandra-3.5.0.jar:3.5.0] at org.apache.cassandra.config.Schema.loadFromDisk(Schema.java:124) ~[apache-cassandra-3.5.0.jar:3.5.0] at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:229) [apache-cassandra-3.5.0.jar:3.5.0] at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:551) [apache-cassandra-3.5.0.jar:3.5.0] at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:680) [apache-cassandra-3.5.0.jar:3.5.0]</description>
      <version>3.0.10,3.10,4.0-alpha1,4.0</version>
      <fixedVersion>Feature/MaterializedViews,Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.ReservedKeywords.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.ColumnFamilyStoreCQLHelperTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.ViewTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.Cql.g</file>
      <file type="M">src.java.org.apache.cassandra.cql3.ColumnIdentifier.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11841" opendate="2016-5-18 00:00:00" fixdate="2016-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add keep-alive to stream protocol</summary>
      <description></description>
      <version>3.10</version>
      <fixedVersion>Legacy/StreamingandMessaging</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.utils.CassandraVersionTest.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.CassandraVersion.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamSession.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamReader.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.messages.StreamMessage.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.ConnectionHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
      <file type="M">src.java.org.apache.cassandra.net.IncomingStreamingConnection.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.Gossiper.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11873" opendate="2016-5-23 00:00:00" fixdate="2016-10-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add duration type</summary>
      <description>For CASSANDRA-11871 or to allow queries with WHERE clause like:... WHERE reading_time &lt; now() - 2h, we need to support some duration type.In my opinion, it should be represented internally as a number of microseconds.</description>
      <version>3.10</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.ViewTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.CreateTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.BatchTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.JsonTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.CollectionsTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.CQLTester.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.CQL3TypeLiteralTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.config.CFMetaDataTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.UserType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.TupleType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.MapType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.ListType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.AbstractType.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateViewStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateTableStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.SingleColumnRelation.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.CQL3Type.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.Constants.java</file>
      <file type="M">src.antlr.Parser.g</file>
      <file type="M">src.antlr.Lexer.g</file>
      <file type="M">pylib.cqlshlib.formatting.py</file>
      <file type="M">pylib.cqlshlib.displaying.py</file>
      <file type="M">pylib.cqlshlib.cql3handling.py</file>
      <file type="M">NEWS.txt</file>
      <file type="M">doc.source.cql.types.rst</file>
      <file type="M">doc.source.cql.changes.rst</file>
      <file type="M">doc.cql3.CQL.textile</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11880" opendate="2016-5-23 00:00:00" fixdate="2016-6-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Display number of tables in cfstats</summary>
      <description>We should display the number of tables in a Cassandra cluster in nodetool cfstats. This would be useful for monitoring.</description>
      <version>3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.nodetool.TableStats.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.nodetool.stats.TableStatsPrinter.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.nodetool.stats.StatsHolder.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeProbe.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxyMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Schema.java</file>
    </fixedFiles>
  </bug>
  <bug id="11914" opendate="2016-5-28 00:00:00" fixdate="2016-8-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Provide option for cassandra-stress to dump all settings</summary>
      <description>cassandra-stress has quite a lot of default settings and settings that are derived as side effects of explicit options. For people learning the tool and saving a clear record of what was run, I think it would be useful if there was an option to have the tool print all its settings at the start of a run.</description>
      <version>3.10</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.StressYaml.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.StressProfile.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.Stress.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.StressSettings.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.SettingsTransport.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.SettingsTokenRange.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.SettingsSchema.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.SettingsRate.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.SettingsPort.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.SettingsPopulation.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.SettingsNode.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.SettingsMode.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.SettingsLog.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.SettingsInsert.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.SettingsGraph.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.SettingsErrors.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.SettingsCommandUser.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.SettingsCommandPreDefinedMixed.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.SettingsCommandPreDefined.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.SettingsCommand.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.SettingsColumn.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.OptionSimple.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.OptionRatioDistribution.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.OptionMulti.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.OptionDistribution.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.OptionAnyProbabilities.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.Option.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.GroupedOptions.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.generate.values.GeneratorConfig.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.generate.RatioDistributionFactory.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.generate.DistributionFactory.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12035" opendate="2016-6-20 00:00:00" fixdate="2016-7-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Structure for tpstats output (JSON, YAML)</summary>
      <description>In CASSANDRA-5977, some extra output formats such as JSON and YAML were added for nodetool tablestats. Similarly, I would like to add the output formats in nodetool tpstats.Also, I tried to refactor the tablestats's code about the output formats to integrate the existing code with my code.Please review the attached patch.</description>
      <version>3.10</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.nodetool.TpStats.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.nodetool.TableStats.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.nodetool.stats.TableStatsPrinter.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.nodetool.stats.StatsPrinter.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.nodetool.stats.StatsHolder.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12060" opendate="2016-6-22 00:00:00" fixdate="2016-9-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Establish consistent distinction between non-existing partition and NULL value for LWTs on static columns</summary>
      <description>When executing following CQL commands: CREATE KEYSPACE test WITH replication = {'class': 'NetworkTopologyStrategy', 'datacenter1': '1' };USE test;CREATE TABLE testtable (a int, b int, s1 int static, s2 int static, v int, PRIMARY KEY (a, b));INSERT INTO testtable (a,b,s1,s2,v) VALUES (2,2,2,null,2);DELETE s1 FROM testtable WHERE a = 2 IF s2 IN (10,20,30);The output is different between 2.x and 3.x:2.x:cqlsh:test&gt; DELETE s1 FROM testtable WHERE a = 2 IF s2 = 5; [applied] | s2-----------+------ False | null3.x:cqlsh:test&gt; DELETE s1 FROM testtable WHERE a = 2 IF s2 = 5; [applied]----------- False2.x would although return same result if executed on a partition that does not exist at all:cqlsh:test&gt; DELETE s1 FROM testtable WHERE a = 5 IF s2 = 5; [applied]----------- FalseIt might be related to static column LWTs, as I could not reproduce same behaviour with non-static column LWTs. The most recent change was CASSANDRA-10532, which enabled LWT operations on static columns with partition keys only. Another possible relation is CASSANDRA-9842, which removed distinction between null column and non-existing row. (striked through since same happens on pre-CASSANDRA-9842 code.</description>
      <version>3.0.10,3.10</version>
      <fixedVersion>Feature/LightweightTransactions</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.InsertUpdateIfConditionTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CQL3CasRequest.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12074" opendate="2016-6-22 00:00:00" fixdate="2016-6-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Faster check for open JMX port on startup</summary>
      <description>Since CASSANDRA-7254, we check whether the JMX port is available before starting Cassandra in order to provide a better error message when another Cassandra process is already running. The current check starts a Java process to do this, which takes ~3 seconds. Instead, we can use lsof, which is basically instantaneous.By my estimate, this will shave about 40 minutes off our dtest runs.</description>
      <version>3.10</version>
      <fixedVersion>Local/StartupandShutdown</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cassandra</file>
    </fixedFiles>
  </bug>
  <bug id="12076" opendate="2016-6-23 00:00:00" fixdate="2016-7-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add username to AuthenticationException messages</summary>
      <description>When an AuthenticationException is thrown, there are a few places where the user that initiated the request is not included in the exception message. It can be useful to have this information included for logging purposes.</description>
      <version>3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.auth.PasswordAuthenticator.java</file>
      <file type="M">src.java.org.apache.cassandra.auth.CassandraLoginModule.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12142" opendate="2016-7-5 00:00:00" fixdate="2016-7-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add "beta" version native protocol flag</summary>
      <description>As discussed in CASSANDRA-10786, we'd like to add a new flag to the native protocol to allow drivers to connect using a "beta" native protocol version. This would be used for native protocol versions that are still in development and may not have all of the final features. Without the "beta" flag, drivers will be prevented from using the protocol version.This is primarily useful for driver authors to start work against a new protocol version when the work on that spans multiple releases. Users would not generally be expected to utilize this flag, although it could potentially be used to offer early feedback on new protocol features.It seems like the STARTUP message body is the best place for the new beta flag. We may also considering adding protocol information to the SUPPORTED message as well.</description>
      <version>3.10</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.transport.ProtocolErrorTest.java</file>
      <file type="M">src.java.org.apache.cassandra.transport.SimpleClient.java</file>
      <file type="M">src.java.org.apache.cassandra.transport.Server.java</file>
      <file type="M">src.java.org.apache.cassandra.transport.ProtocolException.java</file>
      <file type="M">src.java.org.apache.cassandra.transport.messages.BatchMessage.java</file>
      <file type="M">src.java.org.apache.cassandra.transport.Message.java</file>
      <file type="M">src.java.org.apache.cassandra.transport.Frame.java</file>
      <file type="M">src.java.org.apache.cassandra.transport.Event.java</file>
      <file type="M">src.java.org.apache.cassandra.transport.CBUtil.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.ResultSet.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12149" opendate="2016-7-8 00:00:00" fixdate="2016-10-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>NullPointerException on SELECT using index with token restrictions fully overriden by other PK restrictions</summary>
      <description>If I execute the sequence of queries (see the attached file), Cassandra aborts a connection reporting NPE on server side. SELECT query without token range filter works, but does not work when token range filter is specified. My intent was to issue multiple SELECT queries targeting the same single partition, filtered by a column indexed by SASI, partitioning results by different token ranges.Output from cqlsh on SELECT is the following:cqlsh&gt; SELECT namespace, entity, timestamp, feature1, feature2 FROM mykeyspace.myrecordtable WHERE namespace = 'ns2' AND entity = 'entity2' AND feature1 &gt; 11 AND feature1 &lt; 31 AND token(namespace, entity) &lt;= 9223372036854775807;ServerError: &lt;ErrorMessage code=0000 [Server error] message="java.lang.NullPointerException"&gt;</description>
      <version>3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.SelectOrderedPartitionerTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.restrictions.TokenFilter.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12154" opendate="2016-7-8 00:00:00" fixdate="2016-8-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>"SELECT * FROM foo LIMIT ;" does not error out</summary>
      <description>We found out that SELECT * FROM foo LIMIT ; is unanimously accepted and executed but it should not.Have not dug deeper why that is possible (it's not a big issue IMO) but it is strange. Seems it doesn't parse LIMIT as K_LIMIT because otherwise it would require an int argument.</description>
      <version>3.10</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.antlr.Parser.g</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12174" opendate="2016-7-12 00:00:00" fixdate="2016-7-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>COPY FROM should raise error for non-existing input files</summary>
      <description>Currently the CSV COPY FROM command will not raise any error for non-existing paths. Instead only "0 rows imported" will be shown as result. As the COPY FROM command is often used for tutorials and getting started guides, I'd suggest to give a clear error message in case of a missing input file. Without such error it can be confusing for the user to see the command actually finish, without any clues why no rows have been imported.CREATE KEYSPACE test WITH REPLICATION = { 'class' : 'NetworkTopologyStrategy', 'datacenter1' : 1 };USE test;CREATE TABLE airplanes ( name text PRIMARY KEY, manufacturer ascii, year int, mach float);COPY airplanes (name, manufacturer, year, mach) FROM '/tmp/1234-doesnotexist';Using 3 child processesStarting copy of test.airplanes with columns [name, manufacturer, year, mach].Processed: 0 rows; Rate: 0 rows/s; Avg. rate: 0 rows/s0 rows imported from 0 files in 0.216 seconds (0 skipped).</description>
      <version>3.10</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.copyutil.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12178" opendate="2016-7-12 00:00:00" fixdate="2016-7-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add prefixes to the name of snapshots created before a truncate or drop</summary>
      <description>It would be useful to be able to identify snapshots that are taken because a table was truncated or dropped. We can do this by prepending a prefix to snapshot names for snapshots that are created before a truncate/drop.</description>
      <version>3.10</version>
      <fixedVersion>Legacy/Observability</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.Keyspace.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Schema.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12192" opendate="2016-7-13 00:00:00" fixdate="2016-8-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Retry all internode messages once after reopening connections</summary>
      <description>example failure:http://cassci.datastax.com/job/upgrade_tests-all/59/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_3_0_x_To_head_trunk/map_keys_indexing_testFailed on CassCI build upgrade_tests-all #59Stacktrace File "/usr/lib/python2.7/unittest/case.py", line 329, in run testMethod() File "/home/automaton/cassandra-dtest/tools.py", line 290, in wrapped f(obj) File "/home/automaton/cassandra-dtest/upgrade_tests/cql_tests.py", line 3668, in map_keys_indexing_test cursor.execute("TRUNCATE test") File "cassandra/cluster.py", line 1941, in cassandra.cluster.Session.execute (cassandra/cluster.c:33642) return self.execute_async(query, parameters, trace, custom_payload, timeout, execution_profile).result() File "cassandra/cluster.py", line 3629, in cassandra.cluster.ResponseFuture.result (cassandra/cluster.c:69369) raise self._final_exception'&lt;Error from server: code=1003 [Error during truncate] message="Error during truncate: Truncate timed out - received only 2 responses"&gt;Related failure: http://cassci.datastax.com/job/upgrade_tests-all/59/testReport/upgrade_tests.cql_tests/TestCQLNodes2RF1_Upgrade_current_3_0_x_To_head_trunk/map_keys_indexing_test/</description>
      <version>3.10</version>
      <fixedVersion>Legacy/Core</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.net.OutboundTcpConnectionPool.java</file>
      <file type="M">src.java.org.apache.cassandra.net.OutboundTcpConnection.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12208" opendate="2016-7-14 00:00:00" fixdate="2016-8-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Estimated droppable tombstones given by sstablemetadata counts tombstones that aren&amp;#39;t actually "droppable"</summary>
      <description>=&gt; "Estimated droppable tombstones" given by sstablemetadata counts tombstones that aren't actually "droppable"To be clear, the "Estimated droppable tombstones" calculation counts tombstones that have not yet passed gc_grace_seconds as droppable tombstones, which is unexpected, since such tombstones aren't droppable.To observe the problem:Create a table using the default gc_grace_seconds (default gc_grace_seconds is 86400 is 1 day).Populate the table with a couple of records.Do a delete.Do a "nodetool flush" to flush the memtable to disk.Do an "sstablemetadata &lt;sstable&gt;" to get the metadata of the sstable you just created by doing the flush, and observe that the Estimated droppable tombstones is greater than 0.0 (actual value depends on the total number inserts/updates/deletes that you did before triggered the flush)</description>
      <version>3.0.9,3.10</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.SSTableMetadataViewer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12216" opendate="2016-7-15 00:00:00" fixdate="2016-8-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TTL Reading And Writing is Asymmetric</summary>
      <description>There is an inherent asymmetry in the way TTL's are read and Written. An `TTL` of 0 when written becomes a `null` in C*When read, this `TTL` becomes a `null` The `null` cannot be written back to C* as `TTL`This means that end users attempting to copy tables with TTL have to do manual mapping of the null TTL values to 0 to avoid NPE. This is a bit onerous when C* seems to have an internal logic that 0 == NULL. I don't think C* should return values which are not directly insertable back to C*. Even with the advent CASSANDRA-7304 this still remains a problem that the User needs to be aware of and take care of.The following prepared statementINSERT INTO test.table2 (k,v) (?,?) USING TTL: ? Will throw NPEs unless we specifically check that the value to be bound to TTL is not null.I think we should discuss whether `null` should be treated as 0 in TTL for prepared statements.</description>
      <version>3.10</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.UpdateTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.InsertTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.QueryProcessor.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.Attributes.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">doc.source.cql.dml.rst</file>
      <file type="M">doc.source.cql.changes.rst</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12223" opendate="2016-7-18 00:00:00" fixdate="2016-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>SASI Indexes querying incorrectly return 0 rows</summary>
      <description>I just started working with the SASI index on Cassandra 3.7.0 and I encountered a problem which as I suspected was a bug. I had hardly tracked down the situation in which the bug showed up, here is what I found:When querying with a SASI index, it may incorrectly return 0 rows, and changing a little conditions, it works again, like the following CQL code:CQL CREATE TABLE IF NOT EXISTS roles ( name text, a int, b int, PRIMARY KEY ((name, a), b) ) WITH CLUSTERING ORDER BY (b DESC); insert into roles (name,a,b) values ('Joe',1,1); insert into roles (name,a,b) values ('Joe',2,2); insert into roles (name,a,b) values ('Joe',3,3); insert into roles (name,a,b) values ('Joe',4,4); CREATE TABLE IF NOT EXISTS roles2 ( name text, a int, b int, PRIMARY KEY ((name, a), b) ) WITH CLUSTERING ORDER BY (b ASC); insert into roles2 (name,a,b) values ('Joe',1,1); insert into roles2 (name,a,b) values ('Joe',2,2); insert into roles2 (name,a,b) values ('Joe',3,3); insert into roles2 (name,a,b) values ('Joe',4,4); CREATE CUSTOM INDEX ON roles (b) USING 'org.apache.cassandra.index.sasi.SASIIndex' WITH OPTIONS = { 'mode': 'SPARSE' }; CREATE CUSTOM INDEX ON roles2 (b) USING 'org.apache.cassandra.index.sasi.SASIIndex' WITH OPTIONS = { 'mode': 'SPARSE' };Noticing that I only change table roles2 from table roles's 'CLUSTERING ORDER BY (b DESC)' into 'CLUSTERING ORDER BY (b ASC)'.When querying with statement select * from roles2 where b&lt;3, the rusult is two rows:CQL name | a | b ------+---+--- Joe | 1 | 1 Joe | 2 | 2 (2 rows)However, if querying with select * from roles where b&lt;3, it returned no rows at all:CQL name | a | b ------+---+--- (0 rows)This is not the only situation where the bug would show up, one time I created a SASI index with specific name like 'end_idx' on column 'end', the bug showed up, when I didn't specify the index name, it gone.</description>
      <version>3.10</version>
      <fixedVersion>Feature/SASI</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.index.sasi.SASIIndexTest.java</file>
      <file type="M">src.java.org.apache.cassandra.index.sasi.plan.Expression.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12232" opendate="2016-7-19 00:00:00" fixdate="2016-9-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add +=/-= shortcut syntax</summary>
      <description>For collections and counters, the current syntax to add/remove elements is:UPDATE foo SET myCollection = myCollection + ...;which is fine, though it's already tad annoying to have to repeat myCollection. But moving forward, with tickets CASSANDRA-7826, we'll start being able to add to nested collections and we'll end up with queries like:UPDATE foo SET myCollection['someElement']['otherElemnt'] = myCollection['someElement']['otherElemnt'] + ...;where the repetition is starting to be really annoying and it makes the query less readable.It's trivial however to add a +=/-= shortcut syntax which would read instead:UPDATE foo SET myCollection['someElement']['otherElemnt'] += ...;As this would just be syntactic sugar, it only requires a few minor addition to the grammar and this would be completely optional: if some users prefer the verbose syntax, that's fine.Also note that while this will be even more useful after things like CASSANDRA-7826, it's already a nice to have today so it's not dependent on that latter ticket in any way.</description>
      <version>3.10</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.CountersTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.CollectionsTest.java</file>
      <file type="M">src.antlr.Parser.g</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12248" opendate="2016-7-20 00:00:00" fixdate="2016-9-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow tuning compaction thread count at runtime</summary>
      <description>While bootstrapping new nodes it can take a significant amount of time to catch up on compaction or 2i builds. In these cases it would be convenient to have a nodetool command that allows changing the number of concurrent compaction jobs to the amount of cores on the machine.Alternatively, an even better variant of this would be to have a setting "bootstrap_max_concurrent_compactors" which overrides the normal setting during bootstrap only. Saves me from having to write a script that does it.</description>
      <version>3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeTool.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeProbe.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageServiceMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">test.unit.org.apache.cassandra.db.compaction.CompactionsTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="12258" opendate="2016-7-21 00:00:00" fixdate="2016-8-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Casandra stress version option</summary>
      <description>I install cassandra stress to multiple machines in different environments and would like an easy way (with out looking at jar files etc) to see the version of stress running.</description>
      <version>3.10</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.SettingsMisc.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.Command.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12268" opendate="2016-7-21 00:00:00" fixdate="2016-10-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make MV Index creation robust for wide referent rows</summary>
      <description>When creating an index for a materialized view for extant data, heap pressure is very dependent on the cardinality of of rows associated with each index value. With the way that per-index value rows are created within the index, this can cause unbounded heap pressure, which can cause OOM. This appears to be a side-effect of how each index row is applied atomically as with batches.The commit logs can accumulate enough during the process to prevent the node from being restarted. Given that this occurs during global index creation, this can happen on multiple nodes, making stable recovery of a node set difficult, as co-replicas become unavailable to assist in back-filling data from commitlogs.While it is understandable that you want to avoid having relatively wide rows even in materialized views, this represents a particularly difficult scenario for triage.The basic recommendation for improving this is to sub-group the index creation into smaller chunks internally, providing a maximal bound against the heap pressure when it is needed.</description>
      <version>3.0.10,3.10,4.0-alpha1,4.0</version>
      <fixedVersion>Feature/MaterializedViews,Legacy/Core</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.view.ViewUpdateGenerator.java</file>
      <file type="M">src.java.org.apache.cassandra.db.view.ViewBuilder.java</file>
      <file type="M">src.java.org.apache.cassandra.db.view.TableViews.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12279" opendate="2016-7-22 00:00:00" fixdate="2016-8-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>nodetool repair hangs on non-existant table</summary>
      <description>If nodetool repair is called with a table that does not exist, ist hangs infinitely without any error message or logs.E.g.nodetool repair foo barKeyspace foo exists but table bar does not</description>
      <version>2.2.8,3.0.9,3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.repair.RepairRunnable.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12296" opendate="2016-7-26 00:00:00" fixdate="2016-11-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Better error message when streaming with insufficient sources in DC</summary>
      <description>This came up in discussion of CASSANDRA-11687. nodetool rebuild was failing in a dtest. pauloricardomg explained:before CASSANDRA-11848 the local node could be considered a source, while now sources are restricted only to dc2, so since system_auth uses SimpleStrategy depending on the token arrangement there could or not be sources from dc2. Fix is to either use -Dcassandra.consistent.rangemovement=false or update system_auth to use NetworkTopologyStrategy with 2 dcs..This is, at the very least, a UX bug. When rebuild fails, it fails withnodetool: Unable to find sufficient sources for streaming range (-3287869951390391138,-1624006824486474209] in keyspace system_auth with RF=1.If you want to ignore this, consider using system property -Dcassandra.consistent.rangemovement=false.which suggests that a user should give up consistency guarantees when it's not necessary.</description>
      <version>3.0.10,3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.dht.RangeStreamer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12343" opendate="2016-7-29 00:00:00" fixdate="2016-8-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make &amp;#39;static final boolean&amp;#39; easier to optimize for Hotspot</summary>
      <description>Hotspot is able to optimize condition checks on `static final` fields. But the compiler can only optimize if the referenced "constant" is the first condition to check. (If I understood the optimization in Hotspot correctly.)I.e. the first if block can be "eliminated" whereas the second cannot:class Foo { static final boolean CONST = /* some fragment evaluating to false */; public void doSomeStuff(boolean param) { if (!CONST) { // this code block can be eliminated } if (!CONST &amp;&amp; param) { // this code block can be eliminated } if (param &amp;&amp; !CONST) { // this code block cannot be eliminated due to some compiler logic } }}Linked patch changes the order in some if statements and migrates a few methods to static final fields.trunkbranchtestalldtest</description>
      <version>3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.Stress.java</file>
      <file type="M">test.unit.org.apache.cassandra.utils.NanoTimeToCurrentTimeMillisTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.service.StorageServiceServerTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.repair.messages.RepairOptionTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.io.sstable.SSTableWriterTestBase.java</file>
      <file type="M">test.unit.org.apache.cassandra.io.sstable.SSTableWriterTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.SystemKeyspaceTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.commitlog.SnapshotDeletingTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.ColumnFamilyStoreTest.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.SigarLibrary.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.FBUtilities.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StartupChecks.java</file>
      <file type="M">src.java.org.apache.cassandra.service.CassandraDaemon.java</file>
      <file type="M">src.java.org.apache.cassandra.repair.messages.RepairOption.java</file>
      <file type="M">src.java.org.apache.cassandra.io.util.MmappedRegions.java</file>
      <file type="M">src.java.org.apache.cassandra.io.util.FileUtils.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.metadata.MetadataSerializer.java</file>
      <file type="M">src.java.org.apache.cassandra.index.sasi.utils.MappedBuffer.java</file>
      <file type="M">src.java.org.apache.cassandra.db.view.ViewManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Directories.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionController.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.MemoryMappedSegment.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="12358" opendate="2016-8-2 00:00:00" fixdate="2016-8-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Slow PostFlush execution due to 2i flushing can cause near OOM to OOM</summary>
      <description>2i can be slow to flush for a variety of reasons. Potentially slower than the rate at which Memtables can ingest and flush data. If this occurs the heap fills up with Memtables that are waiting for PostFlush to run.This occurs because reclaiming the memory is done before PostFlush runs.I will post a branch that has the reclaim memory task run after PostFlush has completed. As far as I can tell this is safe and correct since the memory is committed up until that point.It's not clear to me if PostFlush has to bind the Memtables or not. I suspect it does, but I'm not sure if that is a route I should go down.</description>
      <version>3.10</version>
      <fixedVersion>Legacy/Core</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12366" opendate="2016-8-2 00:00:00" fixdate="2016-8-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix compaction throttle</summary>
      <description>Compaction throttling is broken in the following ways: It throttles bytes read after being decompressed Compaction creates multiple scanners which share the rate limiter causing too much throttling It bears no resemblance to the reported compaction time remaining calculation (Bytes of source sstables processed since start of compaction)To fix this we need to simplify the throttling to be only at the CompactionIterator level.</description>
      <version>3.10</version>
      <fixedVersion>Local/Compaction</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.compaction.CompactionIteratorTest.java</file>
      <file type="M">src.java.org.apache.cassandra.metrics.TableMetrics.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.ISSTableScanner.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.format.big.BigTableScanner.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LeveledCompactionStrategy.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionTask.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionController.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.AbstractCompactionStrategy.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12384" opendate="2016-8-4 00:00:00" fixdate="2016-10-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Include info about sstable on "Compacting large row” message</summary>
      <description>On a message like this one, it would be helpful to understand which sstable this large row is going inCompacting large row abc/xyz:38956kjhawf (xyz bytes) incrementally</description>
      <version>3.0.10,3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.sstable.format.big.BigTableWriter.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12385" opendate="2016-8-4 00:00:00" fixdate="2016-8-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Disk failure policy should not be invoked on out of space</summary>
      <description>If a node fills up temporarily due to compaction the disk failure policy may be invoked. Weuse stop, so the node will be disabled. This leaves the node down even though it recovers from thisfailure by aborting the compaction.</description>
      <version>3.0.9,3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.Directories.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.AbstractCompactionTask.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12413" opendate="2016-8-8 00:00:00" fixdate="2016-9-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CompactionsCQLTest.testTriggerMinorCompactionDTCS fails</summary>
      <description>LinkError MessageNo minor compaction triggered in 5000msStacktracejunit.framework.AssertionFailedError: No minor compaction triggered in 5000ms at org.apache.cassandra.db.compaction.CompactionsCQLTest.waitForMinor(CompactionsCQLTest.java:247) at org.apache.cassandra.db.compaction.CompactionsCQLTest.testTriggerMinorCompactionDTCS(CompactionsCQLTest.java:72)</description>
      <version>3.10</version>
      <fixedVersion>Legacy/Testing</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionLogger.java</file>
    </fixedFiles>
  </bug>
  <bug id="12417" opendate="2016-8-9 00:00:00" fixdate="2016-10-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Built-in AVG aggregate is much less useful than it should be</summary>
      <description>For fixed-size integer types overflow is all but guaranteed to happen, yielding incorrect result. While for sum it is somewhat acceptable as the result cannot fit the type, this is not the case for average.As the result of average is always within the scope of the source type, failing to produce it only signifies a bad implementation. Yes, one can solve this by type-casting, but do we really want to always have to be telling people that the correct spelling of the average function is cast(avg(cast(value as bigint))) as int), especially if this is so trivial to fix?Additionally, the straightforward addition we use for floating point versions is not a good choice numerically for larger numbers of values. We should switch to a more stable version, e.g. iterative mean using avg = avg + (value - avg) / count.</description>
      <version>3.0.10,3.10</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.AggregationTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.functions.AggregateFcts.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12423" opendate="2016-8-10 00:00:00" fixdate="2016-9-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cells missing from compact storage table after upgrading from 2.1.9 to 3.7</summary>
      <description>Schema:create table ks1.test ( id int, c1 text, c2 text, v int, primary key (id, c1, c2)) with compact storage and compression = {'sstable_compression': ''};sstable2json before upgrading:[{"key": "1", "cells": [["","0",1470761440040513], ["a","asd",2470761440040513,"t",1470764842], ["asd:","0",1470761451368658], ["asd:asd","0",1470761449416613]]}]Query result with 2.1.9:cqlsh&gt; select * from ks1.test; id | c1 | c2 | v----+-----+------+--- 1 | | null | 0 1 | asd | | 0 1 | asd | asd | 0(3 rows)Query result with 3.7:cqlsh&gt; select * from ks1.test; id | 6331 | 6332 | v----+------+------+--- 1 | | null | 0(1 rows)</description>
      <version>3.0.9,3.10</version>
      <fixedVersion>Legacy/LocalWrite-ReadPaths</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.marshal.CompositeType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.LegacyLayout.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12425" opendate="2016-8-10 00:00:00" fixdate="2016-8-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Log at DEBUG when running unit tests</summary>
      <description>patch heresample run here - looks like the logs are 13MB gzipped vs about 1.5MB with only INFO logging</description>
      <version>3.0.9,3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.CQLTester.java</file>
      <file type="M">test.conf.logback-test.xml</file>
    </fixedFiles>
  </bug>
  <bug id="12443" opendate="2016-8-11 00:00:00" fixdate="2016-1-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove alter type support</summary>
      <description>Currently, we allow altering of types. However, because we no longer store the length for all types anymore, switching from a fixed-width to variable-width type causes issues. commitlog playback breaking startup, queries currently in flight getting back bad results, and special casing required to handle the changes. In addition, this would solve CASSANDRA-10309, as there is no possibility of the types changing while an SSTableReader is open.For fixed-length, compatible types, the alter also doesn't add much over a cast, so users could use that in order to retrieve the altered type.</description>
      <version>3.0.11,3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.ViewSchemaTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.UpdateTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.AlterTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.UserTypesTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.TypeTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.FrozenCollectionsTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.AlterTypeStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.AlterTableStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">pylib.cqlshlib.cql3handling.py</file>
      <file type="M">NEWS.txt</file>
      <file type="M">doc.cql3.CQL.textile</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12473" opendate="2016-8-17 00:00:00" fixdate="2016-9-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Errors in cassandra-stress print settings output</summary>
      <description>A few errors in stress settings output: mean and stdev transposed for gaussian distribution output no-settings setting mislabled "Print settings" typo "ration" instead of "ratio"</description>
      <version>3.10</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.SettingsLog.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.OptionRatioDistribution.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.OptionDistribution.java</file>
    </fixedFiles>
  </bug>
  <bug id="12476" opendate="2016-8-17 00:00:00" fixdate="2016-8-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>SyntaxException when COPY FROM Counter Table with Null value</summary>
      <description>I have a simple counter table CREATE TABLE test ( a int PRIMARY KEY, b counter, c counter) ;I have updated b column value with UPDATE test SET b = b + 1 WHERE a = 1;Now I have export the data with COPY test TO 'test.csv';And Import it with COPY test FROM 'test.csv';I get this ErrorFailed to import 1 rows: SyntaxException - line 1:34 no viable alternative at input 'WHERE' (...=b+1,c=c+ [WHERE]...) - will retry later, attempt 1 of 5</description>
      <version>2.2.8,3.0.9,3.10</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.copyutil.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12478" opendate="2016-8-17 00:00:00" fixdate="2016-10-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cassandra stress still uses CFMetaData.compile()</summary>
      <description>Using CFMetaData.compile() on a client tool causes permission problems. To reproduce: Start cassandra under user cassandra Run chmod -R go-rwx /var/lib/cassandra to deny access to other users. Use a non-root user to run cassandra-stressThis produces an access denied message on /var/lib/cassandra/commitlog.The attached fix uses client-mode functionality.</description>
      <version>3.0.10,3.10</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.StressProfile.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12481" opendate="2016-8-17 00:00:00" fixdate="2016-9-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>dtest failure in cqlshlib.test.test_cqlsh_output.TestCqlshOutput.test_describe_keyspace_output</summary>
      <description>example failure:http://cassci.datastax.com/job/cassandra-3.0_cqlsh_tests/29/testReport/cqlshlib.test.test_cqlsh_output/TestCqlshOutput/test_describe_keyspace_outputError Messageerrors={'127.0.0.1': 'Client request timeout. See Session.execute[_async](timeout)'}, last_host=127.0.0.1http://cassci.datastax.com/job/cassandra-3.0_cqlsh_tests/lastCompletedBuild/cython=no,label=ctool-lab/testReport/cqlshlib.test.test_cqlsh_output/TestCqlshOutput/test_describe_keyspace_output/</description>
      <version>2.2.8,3.0.9,3.10</version>
      <fixedVersion>Test/dtest/python</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.test.cassconnect.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12486" opendate="2016-8-18 00:00:00" fixdate="2016-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Structure for compactionhistory output (JSON, YAML)</summary>
      <description>As with nodetool tpstats and tablestats (CASSANDRA-12035), nodetool compactionhistory should also support useful output formats such as JSON or YAML, so we implemented it. Please review the attached patch.</description>
      <version>3.10</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.nodetool.CompactionHistory.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12490" opendate="2016-8-18 00:00:00" fixdate="2016-10-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add sequence distribution type to cassandra stress</summary>
      <description>When using the write command, cassandra stress sequentially generates seeds. This ensures generated values don't overlap (unless the sequence wraps) providing more predictable number of inserted records (and generating a base set of data without wasted writes).When using a yaml stress spec there is no sequenced distribution available. It think it would be useful to have this for doing initial load of data for testing</description>
      <version>3.10</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">tools.stress.test.unit.org.apache.cassandra.stress.generate.DistributionSequenceTest.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.OptionDistribution.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.generate.DistributionSequence.java</file>
      <file type="M">tools.cqlstress-insanity-example.yaml</file>
      <file type="M">tools.cqlstress-example.yaml</file>
      <file type="M">tools.cqlstress-counter-example.yaml</file>
    </fixedFiles>
  </bug>
  <bug id="12499" opendate="2016-8-19 00:00:00" fixdate="2016-9-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Row cache does not cache partitions on tables without clustering keys</summary>
      <description>MLSEA-JJIRSA01:~ jjirsa$ ccm startMLSEA-JJIRSA01:~ jjirsa$ echo "DESCRIBE TABLE test.test; " | ccm node1 cqlshCREATE TABLE test.test ( id int PRIMARY KEY, v text) WITH bloom_filter_fp_chance = 0.01 AND caching = {'keys': 'ALL', 'rows_per_partition': '100'} AND comment = '' AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'} AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'} AND crc_check_chance = 1.0 AND dclocal_read_repair_chance = 0.1 AND default_time_to_live = 0 AND gc_grace_seconds = 864000 AND max_index_interval = 2048 AND memtable_flush_period_in_ms = 0 AND min_index_interval = 128 AND read_repair_chance = 0.0 AND speculative_retry = '99PERCENTILE';MLSEA-JJIRSA01:~ jjirsa$ ccm node1 nodetool info | grep RowRow Cache : entries 0, size 0 bytes, capacity 100 MiB, 0 hits, 0 requests, NaN recent hit rate, 0 save period in secondsMLSEA-JJIRSA01:~ jjirsa$ echo "INSERT INTO test.test(id,v) VALUES(1, 'a'); " | ccm node1 cqlshMLSEA-JJIRSA01:~ jjirsa$ echo "SELECT * FROM test.test WHERE id=1; " | ccm node1 cqlsh id | v----+--- 1 | a(1 rows)MLSEA-JJIRSA01:~ jjirsa$ ccm node1 nodetool info | grep RowRow Cache : entries 0, size 0 bytes, capacity 100 MiB, 0 hits, 0 requests, NaN recent hit rate, 0 save period in secondsMLSEA-JJIRSA01:~ jjirsa$ echo "SELECT * FROM test.test WHERE id=1; " | ccm node1 cqlsh id | v----+--- 1 | a(1 rows)MLSEA-JJIRSA01:~ jjirsa$ ccm node1 nodetool info | grep RowRow Cache : entries 0, size 0 bytes, capacity 100 MiB, 0 hits, 0 requests, NaN recent hit rate, 0 save period in secondsMLSEA-JJIRSA01:~ jjirsa$</description>
      <version>3.0.10,3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.SchemaLoader.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.RowCacheTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.SinglePartitionReadCommand.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12508" opendate="2016-8-19 00:00:00" fixdate="2016-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>nodetool repair returns status code 0 for some errors</summary>
      <description>For instance, when specifying hosts that don’t exist, an error message is logged, but the return code is zero.</description>
      <version>3.0.9,3.10</version>
      <fixedVersion>Tool/nodetool</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.RepairRunner.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12528" opendate="2016-8-24 00:00:00" fixdate="2016-8-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix eclipse-warning problems</summary>
      <description>The ant eclipse-warning target has accumulated some failures again. Locally, I'm seeing 3 errors on 2.2, 5 errors on 3.0, 23 errors on 3.9, and 33 errors on trunk.Depending on the amount of overlap between these errors, it may make sense to split this into sub-issues.</description>
      <version>2.2.8,3.0.9,3.10</version>
      <fixedVersion>Legacy/Core</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.SSTableExport.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.TimeWindowCompactionStrategy.java</file>
      <file type="M">src.java.org.apache.cassandra.security.EncryptionUtils.java</file>
      <file type="M">src.java.org.apache.cassandra.net.MessageOut.java</file>
      <file type="M">src.java.org.apache.cassandra.metrics.TableMetrics.java</file>
      <file type="M">src.java.org.apache.cassandra.io.util.DataOutputBuffer.java</file>
      <file type="M">src.java.org.apache.cassandra.io.util.ChecksummedRebufferer.java</file>
      <file type="M">src.java.org.apache.cassandra.io.util.ChecksummedRandomAccessReader.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableTxnWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.IndexSummaryBuilder.java</file>
      <file type="M">src.java.org.apache.cassandra.index.sasi.plan.QueryController.java</file>
      <file type="M">src.java.org.apache.cassandra.index.sasi.disk.StaticTokenTreeBuilder.java</file>
      <file type="M">src.java.org.apache.cassandra.index.sasi.disk.PerSSTableIndexWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.hints.HintsWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.db.SystemKeyspace.java</file>
      <file type="M">src.java.org.apache.cassandra.db.rows.UnfilteredSerializer.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LeveledCompactionStrategy.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLogSegmentReader.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLog.java</file>
    </fixedFiles>
  </bug>
  <bug id="12532" opendate="2016-8-24 00:00:00" fixdate="2016-9-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Include repair id in repair start message</summary>
      <description>Currently its not really possible to map the repairs command id that is returned from JMX to the id used tables in in system_traces, and system_distributed keyspaces. In the START we can just include it in the message to make it possible.</description>
      <version>3.10</version>
      <fixedVersion>Legacy/StreamingandMessaging</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.repair.RepairRunnable.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12535" opendate="2016-8-24 00:00:00" fixdate="2016-11-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Prevent reloading of logback.xml from UDF sandbox</summary>
      <description>I have defined a UDA to implement standard deviation:cqlsh:mykeyspace&gt; CREATE OR REPLACE FUNCTION sdState ( state tuple&lt;int,double,double&gt;, val double ) CALLED ON NULL INPUT RETURNS tuple&lt;int,double,double&gt; LANGUAGE java AS ... 'int n = state.getInt(0); double mean = state.getDouble(1); double m2 = state.getDouble(2); n++; double delta = val - mean; mean += delta / n; m2 += delta * (val - mean); state.setInt(0, n); state.setDouble(1, mean); state.setDouble(2, m2); return state;'; cqlsh:mykeyspace&gt; CREATE OR REPLACE FUNCTION sdFinal ( state tuple&lt;int,double,double&gt; ) CALLED ON NULL INPUT RETURNS double LANGUAGE java AS ... 'int n = state.getInt(0); double m2 = state.getDouble(2); if (n &lt; 1) { return null; } return Math.sqrt(m2 / (n - 1));';cqlsh:mykeyspace&gt; CREATE AGGREGATE IF NOT EXISTS stdev ( double ) ... SFUNC sdState STYPE tuple&lt;int,double,double&gt; FINALFUNC sdFinal INITCOND (0,0,0);My table:CREATE TABLE readings ( sensor_id int, time timestamp, temperature double, status text, PRIMARY KEY (sensor_id, time)) WITH CLUSTERING ORDER BY (time ASC);I'm inserting a row every 0.1 seconds. The data looks like this:cqlsh:mykeyspace&gt; select * from readings limit 10; sensor_id | time | status | temperature-----------+---------------------------------+--------+------------- 5 | 2016-08-24 19:11:34.896000+0000 | OK | 9.97 5 | 2016-08-24 19:11:43.933000+0000 | OK | 10.28 5 | 2016-08-24 19:11:49.958000+0000 | OK | 7.65 5 | 2016-08-24 19:11:51.968000+0000 | OK | 10.11 5 | 2016-08-24 19:12:58.512000+0000 | Fault | 10.41 5 | 2016-08-24 19:13:04.542000+0000 | OK | 9.66 5 | 2016-08-24 19:13:16.593000+0000 | OK | 10.9 5 | 2016-08-24 19:13:37.692000+0000 | OK | 11.2 5 | 2016-08-24 19:13:46.738000+0000 | OK | 10.34 5 | 2016-08-24 19:13:49.757000+0000 | OK | 10.6I'm running a query every few seconds with my UDA - like this (timestamps are different each time):select avg(temperature), stdev(temperature) from readings where sensor_id = 1 and time &gt; 1472066523193;Most of the time, this works just fine:cqlsh:mykeyspace&gt; select avg(temperature), stdev(temperature) from readings where sensor_id = 1 and time &gt; 1472066523193; system.avg(temperature) | mykeyspace.stdev(temperature)-------------------------+------------------------------- 9.9291 | 0.94179(1 rows)But, occasionally, it fails with one of two exceptions:cqlsh:mykeyspace&gt; select avg(temperature), stdev(temperature) from readings where sensor_id = 1 and time &gt; 1472066523193;Traceback (most recent call last): File "/usr/local/Cellar/cassandra/3.7/libexec/bin/cqlsh.py", line 1277, in perform_simple_statement result = future.result() File "cassandra/cluster.py", line 3629, in cassandra.cluster.ResponseFuture.result (cassandra/cluster.c:69369) raise self._final_exceptionFunctionFailure: Error from server: code=1400 [User Defined Function failure] message="execution of 'mykeyspace.sdstate[frozen&lt;tuple&lt;int, double, double&gt;&gt;, double]' failed: java.security.AccessControlException: access denied ("java.io.FilePermission" "/usr/local/etc/cassandra/logback.xml" "read")"orcqlsh:mykeyspace&gt; select count(*), avg(temperature), stdev(temperature) from readings where sensor_id = 1 and time &gt; '2016-08-24 15:00:00.000+0000';Traceback (most recent call last): File "/usr/local/Cellar/cassandra/3.7/libexec/bin/cqlsh.py", line 1277, in perform_simple_statement result = future.result() File "cassandra/cluster.py", line 3629, in cassandra.cluster.ResponseFuture.result (cassandra/cluster.c:69369) raise self._final_exceptionFunctionFailure: Error from server: code=1400 [User Defined Function failure] message="execution of 'mykeyspace.sdstate[frozen&lt;tuple&lt;int, double, double&gt;&gt;, double]' failed: com.datastax.driver.core.exceptions.CodecNotFoundException"The next query usually works ok.I don't see any clues in /usr/local/var/log/cassandra/system.logIf I can pin it down more, I'll post follow-up comments.</description>
      <version>3.0.11,3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.AggregationTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.functions.ThreadAwareSecurityManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12563" opendate="2016-8-30 00:00:00" fixdate="2016-1-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Stress daemon help is incorrect</summary>
      <description>It says provide the option -sendToDaemon where as only -send-to and -sendto workFix here:https://github.com/chbatey/cassandra-1/tree/stress-daemon</description>
      <version>3.0.11,3.10,4.0-alpha1,4.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.SettingsMisc.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12564" opendate="2016-8-30 00:00:00" fixdate="2016-8-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Stress daemon mode no longer works</summary>
      <description>All of settings are no longer Serializable. I intend to fix this but if anyone gets there before me feel free to take the issue.</description>
      <version>3.10</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.SettingsTokenRange.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.Option.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.GroupedOptions.java</file>
    </fixedFiles>
  </bug>
  <bug id="12582" opendate="2016-8-31 00:00:00" fixdate="2016-10-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Removing static column results in ReadFailure due to CorruptSSTableException</summary>
      <description>We ran into an issue on production where reads began to fail for certain queries, depending on the range within the relation for those queries. Cassandra system log showed an unhandled CorruptSSTableException exception.CQL read failure:ReadFailure: code=1300 [Replica(s) failed to execute read] message="Operation failed - received 0 responses and 1 failures" info={'failures': 1, 'received_responses': 0, 'required_responses': 1, 'consistency': 'ONE'}Cassandra exception:WARN [SharedPool-Worker-2] 2016-08-31 12:49:27,979 AbstractLocalAwareExecutorService.java:169 - Uncaught exception on thread Thread[SharedPool-Worker-2,5,main]: {}java.lang.RuntimeException: org.apache.cassandra.io.sstable.CorruptSSTableException: Corrupted: /usr/local/apache-cassandra-3.0.8/data/data/issue309/apples_by_tree-006748a06fa311e6a7f8ef8b642e977b/mb-1-big-Data.db at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:2453) ~[apache-cassandra-3.0.8.jar:3.0.8] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_72] at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:164) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$LocalSessionFutureTask.run(AbstractLocalAwareExecutorService.java:136) [apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:105) [apache-cassandra-3.0.8.jar:3.0.8] at java.lang.Thread.run(Thread.java:745) [na:1.8.0_72]Caused by: org.apache.cassandra.io.sstable.CorruptSSTableException: Corrupted: /usr/local/apache-cassandra-3.0.8/data/data/issue309/apples_by_tree-006748a06fa311e6a7f8ef8b642e977b/mb-1-big-Data.db at org.apache.cassandra.io.sstable.format.big.BigTableScanner$KeyScanningIterator$1.initializeIterator(BigTableScanner.java:343) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.rows.LazilyInitializedUnfilteredRowIterator.maybeInit(LazilyInitializedUnfilteredRowIterator.java:48) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.rows.LazilyInitializedUnfilteredRowIterator.isReverseOrder(LazilyInitializedUnfilteredRowIterator.java:65) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.rows.LazilyInitializedUnfilteredRowIterator.isReverseOrder(LazilyInitializedUnfilteredRowIterator.java:66) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.partitions.PurgeFunction.applyToPartition(PurgeFunction.java:62) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.partitions.PurgeFunction.applyToPartition(PurgeFunction.java:24) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.transform.BasePartitions.hasNext(BasePartitions.java:96) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.partitions.UnfilteredPartitionIterators$Serializer.serialize(UnfilteredPartitionIterators.java:295) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.ReadResponse$LocalDataResponse.build(ReadResponse.java:134) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.ReadResponse$LocalDataResponse.&lt;init&gt;(ReadResponse.java:127) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.ReadResponse$LocalDataResponse.&lt;init&gt;(ReadResponse.java:123) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.ReadResponse.createDataResponse(ReadResponse.java:65) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.ReadCommand.createResponse(ReadCommand.java:289) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.service.StorageProxy$LocalReadRunnable.runMayThrow(StorageProxy.java:1796) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:2449) ~[apache-cassandra-3.0.8.jar:3.0.8] ... 5 common frames omittedCaused by: org.apache.cassandra.io.sstable.CorruptSSTableException: Corrupted: /usr/local/apache-cassandra-3.0.8/data/data/issue309/apples_by_tree-006748a06fa311e6a7f8ef8b642e977b/mb-1-big-Data.db at org.apache.cassandra.db.columniterator.AbstractSSTableIterator.&lt;init&gt;(AbstractSSTableIterator.java:130) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.columniterator.SSTableIterator.&lt;init&gt;(SSTableIterator.java:46) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.io.sstable.format.big.BigTableReader.iterator(BigTableReader.java:69) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.io.sstable.format.big.BigTableScanner$KeyScanningIterator$1.initializeIterator(BigTableScanner.java:338) ~[apache-cassandra-3.0.8.jar:3.0.8] ... 19 common frames omittedCaused by: java.io.IOException: Corrupt (negative) value length encountered at org.apache.cassandra.db.marshal.AbstractType.readValue(AbstractType.java:399) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.rows.BufferCell$Serializer.deserialize(BufferCell.java:302) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.rows.UnfilteredSerializer.readSimpleColumn(UnfilteredSerializer.java:462) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.rows.UnfilteredSerializer.deserializeRowBody(UnfilteredSerializer.java:440) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.rows.UnfilteredSerializer.deserializeStaticRow(UnfilteredSerializer.java:381) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.columniterator.AbstractSSTableIterator.readStaticRow(AbstractSSTableIterator.java:179) ~[apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.columniterator.AbstractSSTableIterator.&lt;init&gt;(AbstractSSTableIterator.java:103) ~[apache-cassandra-3.0.8.jar:3.0.8] ... 22 common frames omittedAfter debugging, it appears that a previously dropped static column (weeks prior) was the instigator of the issue. As a workaround we added back the column, restarted all cassandra processes within the cluster, and the read error and corruption exception went away.Attached is a script to reproduce with a simple schema.Also noteworthy (and shown in the script) is that when in this state, compaction silently failed (exit 0) to remove the dropped static columns from the "corrupted" sstable.</description>
      <version>3.0.10,3.10</version>
      <fixedVersion>Legacy/LocalWrite-ReadPaths</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.SerializationHeader.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12598" opendate="2016-9-2 00:00:00" fixdate="2016-10-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>BailErrorStragery alike for ANTLR grammar parsing</summary>
      <description>CQL parsing is missing a mechanism similar to http://www.antlr.org/api/Java/org/antlr/v4/runtime/BailErrorStrategy.htmlThis solves: Stopping parsing instead of continuing when we've got already an error which is wasteful. Any skipped java code tied to 'recovered' missing tokens might later cause java exceptions (think non-init variables, non incremented integers (div by zero), etc.) which will bubble up directly and will hide properly formatted error messages to the user with no indication on what went wrong at all. Just a cryptic NPE i.e</description>
      <version>3.10</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.AggregationTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.CqlParserTest.java</file>
      <file type="M">src.antlr.Parser.g</file>
      <file type="M">src.antlr.Cql.g</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12620" opendate="2016-9-8 00:00:00" fixdate="2016-12-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Resurrected rows with expired TTL on update to 3.x</summary>
      <description>We had the below table on C* 2.x (dse 4.8.4, we assume was 2.1.15.1423 according to documentation), and were entering TTLs at write-time using the DataStax C# Driver (using the POCO mapper).Upon upgrade to 3.0.8.1293 (DSE 5.0.2), we are seeing a lot of rows that: should have been TTL'd have no non-primary-key column dataCREATE TABLE applicationservices.aggregate_bucket_event_v3 ( bucket_type int, bucket_id text, date timestamp, aggregate_id text, event_type int, event_id text, entities list&lt;frozen&lt;tuple&lt;int, text&gt;&gt;&gt;, identity_sid text, PRIMARY KEY ((bucket_type, bucket_id), date, aggregate_id, event_type, event_id)) WITH CLUSTERING ORDER BY (date DESC, aggregate_id ASC, event_type ASC, event_id ASC) AND bloom_filter_fp_chance = 0.1 AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'} AND comment = '' AND compaction = {'class': 'org.apache.cassandra.db.compaction.LeveledCompactionStrategy'} AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'} AND crc_check_chance = 1.0 AND dclocal_read_repair_chance = 0.1 AND default_time_to_live = 0 AND gc_grace_seconds = 864000 AND max_index_interval = 2048 AND memtable_flush_period_in_ms = 0 AND min_index_interval = 128 AND read_repair_chance = 0.0 AND speculative_retry = '99PERCENTILE';{ "partition" : { "key" : [ "0", "26492" ], "position" : 54397932 }, "rows" : [ { "type" : "row", "position" : 54397961, "clustering" : [ "2016-09-07 23:33Z", "3651664", "0", "773665449947099136" ], "liveness_info" : { "tstamp" : "2016-09-07T23:34:09.758Z", "ttl" : 172741, "expires_at" : "2016-09-09T23:33:10Z", "expired" : false }, "cells" : [ { "name" : "identity_sid", "value" : "p_tw_zahidana" }, { "name" : "entities", "deletion_info" : { "marked_deleted" : "2016-09-07T23:34:09.757999Z", "local_delete_time" : "2016-09-07T23:34:09Z" } }, { "name" : "entities", "path" : [ "936e17e1-7553-11e6-9b92-29a33b5827c3" ], "value" : "0:https\\://www.youtube.com/watch?v=pwAJAssv6As" }, { "name" : "entities", "path" : [ "936e17e2-7553-11e6-9b92-29a33b5827c3" ], "value" : "2:youtube" } ] }, { "type" : "row", }, { "type" : "row", "position" : 54397177, "clustering" : [ "2016-08-17 10:00Z", "6387376", "0", "765850666296225792" ], "liveness_info" : { "tstamp" : "2016-08-17T11:26:15.917001Z" }, "cells" : [ ] }, { "type" : "row", "position" : 54397227, "clustering" : [ "2016-08-17 07:00Z", "6387376", "0", "765805367347601409" ], "liveness_info" : { "tstamp" : "2016-08-17T08:11:17.587Z" }, "cells" : [ ] }, { "type" : "row", "position" : 54397276, "clustering" : [ "2016-08-17 04:00Z", "6387376", "0", "765760069858365441" ], "liveness_info" : { "tstamp" : "2016-08-17T05:58:11.228Z" }, "cells" : [ ] },</description>
      <version>3.0.11,3.10</version>
      <fixedVersion>Legacy/LocalWrite-ReadPaths</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.LegacyLayout.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12651" opendate="2016-9-16 00:00:00" fixdate="2016-11-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Failure in SecondaryIndexTest.testAllowFilteringOnPartitionKeyWithSecondaryIndex</summary>
      <description>This has failed with/without compression.Stacktrace:junit.framework.AssertionFailedError: Got less rows than expected. Expected 2 but got 0 at org.apache.cassandra.cql3.CQLTester.assertRows(CQLTester.java:909) at org.apache.cassandra.cql3.validation.entities.SecondaryIndexTest.lambda$testAllowFilteringOnPartitionKeyWithSecondaryIndex$78(SecondaryIndexTest.java:1228) at org.apache.cassandra.cql3.validation.entities.SecondaryIndexTest$$Lambda$293/218688965.apply(Unknown Source) at org.apache.cassandra.cql3.CQLTester.beforeAndAfterFlush(CQLTester.java:1215) at org.apache.cassandra.cql3.validation.entities.SecondaryIndexTest.testAllowFilteringOnPartitionKeyWithSecondaryIndex(SecondaryIndexTest.java:1218)Examples:http://cassci.datastax.com/job/trunk_testall/1176/testReport/org.apache.cassandra.cql3.validation.entities/SecondaryIndexTest/testAllowFilteringOnPartitionKeyWithSecondaryIndex/http://cassci.datastax.com/job/trunk_testall/1176/testReport/org.apache.cassandra.cql3.validation.entities/SecondaryIndexTest/testAllowFilteringOnPartitionKeyWithSecondaryIndex_compression/http://cassci.datastax.com/job/trunk_testall/1219/testReport/org.apache.cassandra.cql3.validation.entities/SecondaryIndexTest/testAllowFilteringOnPartitionKeyWithSecondaryIndex/http://cassci.datastax.com/job/trunk_testall/1216/testReport/org.apache.cassandra.cql3.validation.entities/SecondaryIndexTest/testAllowFilteringOnPartitionKeyWithSecondaryIndex/http://cassci.datastax.com/job/trunk_testall/1208/testReport/org.apache.cassandra.cql3.validation.entities/SecondaryIndexTest/testAllowFilteringOnPartitionKeyWithSecondaryIndex/http://cassci.datastax.com/job/trunk_testall/1176/testReport/org.apache.cassandra.cql3.validation.entities/SecondaryIndexTest/testAllowFilteringOnPartitionKeyWithSecondaryIndex/http://cassci.datastax.com/job/trunk_testall/1175/testReport/org.apache.cassandra.cql3.validation.entities/SecondaryIndexTest/testAllowFilteringOnPartitionKeyWithSecondaryIndex/May or may not be related, but there's a test failure (index duplicate):http://cassci.datastax.com/view/Dev/view/carlyeks/job/carlyeks-ticket-11803-3.X-testall/lastCompletedBuild/testReport/org.apache.cassandra.index.internal/CassandraIndexTest/indexOnFirstClusteringColumn_compression/http://cassci.datastax.com/job/ifesdjeen-11803-test-fix-trunk-testall/1/testReport/junit/org.apache.cassandra.index.internal/CassandraIndexTest/indexOnFirstClusteringColumn_compression/</description>
      <version>3.0.11,3.10</version>
      <fixedVersion>Legacy/Testing</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.dht.LocalPartitioner.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12664" opendate="2016-9-19 00:00:00" fixdate="2016-1-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>GCCompactionTest is flaky</summary>
      <description>GCCompactionTest was introduced by CASSANDRA-7019 and appears to be flaky, see for example here. I think it's the same root cause as CASSANDRA-12282: the tables in the test keyspace are dropped asynchronously after each test, and this might cause additional flush operations for all dirty tables in the keyspace. See the callstack in 12282. A possible solution is to use KEYSPACE_PER_TEST, which is instead dropped synchronously.</description>
      <version>3.10</version>
      <fixedVersion>Legacy/LocalWrite-ReadPaths</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.GcCompactionTest.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12666" opendate="2016-9-19 00:00:00" fixdate="2016-11-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>dtest failure in paging_test.TestPagingData.test_paging_with_filtering_on_partition_key</summary>
      <description>example failure:http://cassci.datastax.com/job/trunk_novnode_dtest/480/testReport/paging_test/TestPagingData/test_paging_with_filtering_on_partition_keyStandard OutputUnexpected error in node3 log, error: ERROR [Native-Transport-Requests-3] 2016-09-17 00:50:11,543 Message.java:622 - Unexpected exception during request; channel = [id: 0x467a4afe, L:/127.0.0.3:9042 - R:/127.0.0.1:59115]java.lang.AssertionError: null at org.apache.cassandra.dht.IncludingExcludingBounds.split(IncludingExcludingBounds.java:45) ~[main/:na] at org.apache.cassandra.service.StorageProxy.getRestrictedRanges(StorageProxy.java:2368) ~[main/:na] at org.apache.cassandra.service.StorageProxy$RangeIterator.&lt;init&gt;(StorageProxy.java:1951) ~[main/:na] at org.apache.cassandra.service.StorageProxy.getRangeSlice(StorageProxy.java:2235) ~[main/:na] at org.apache.cassandra.db.PartitionRangeReadCommand.execute(PartitionRangeReadCommand.java:184) ~[main/:na] at org.apache.cassandra.service.pager.AbstractQueryPager.fetchPage(AbstractQueryPager.java:66) ~[main/:na] at org.apache.cassandra.service.pager.PartitionRangeQueryPager.fetchPage(PartitionRangeQueryPager.java:36) ~[main/:na] at org.apache.cassandra.cql3.statements.SelectStatement$Pager$NormalPager.fetchPage(SelectStatement.java:328) ~[main/:na] at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:375) ~[main/:na] at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:250) ~[main/:na] at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:78) ~[main/:na] at org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:216) ~[main/:na] at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:247) ~[main/:na] at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:232) ~[main/:na] at org.apache.cassandra.transport.messages.QueryMessage.execute(QueryMessage.java:115) ~[main/:na] at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:516) [main/:na] at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:409) [main/:na] at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105) [netty-all-4.0.39.Final.jar:4.0.39.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:366) [netty-all-4.0.39.Final.jar:4.0.39.Final] at io.netty.channel.AbstractChannelHandlerContext.access$600(AbstractChannelHandlerContext.java:35) [netty-all-4.0.39.Final.jar:4.0.39.Final] at io.netty.channel.AbstractChannelHandlerContext$7.run(AbstractChannelHandlerContext.java:357) [netty-all-4.0.39.Final.jar:4.0.39.Final] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_45] at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:162) [main/:na] at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:109) [main/:na] at java.lang.Thread.run(Thread.java:745) [na:1.8.0_45]Related failures:http://cassci.datastax.com/job/trunk_novnode_dtest/480/testReport/paging_test/TestPagingData/test_paging_with_filtering_on_partition_key_on_clustering_columns/http://cassci.datastax.com/job/trunk_novnode_dtest/480/testReport/paging_test/TestPagingData/test_paging_with_filtering_on_partition_key_on_clustering_columns_with_contains/http://cassci.datastax.com/job/trunk_novnode_dtest/480/testReport/paging_test/TestPagingData/test_paging_with_filtering_on_partition_key_on_counter_columns/</description>
      <version>3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.restrictions.StatementRestrictions.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12693" opendate="2016-9-22 00:00:00" fixdate="2016-10-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add the JMX metrics about the total number of hints we have delivered</summary>
      <description>I find there are no metrics about the number of hints we have delivered, I think it would be great to have the metrics, so that we have better estimation about the progress of hints replay.</description>
      <version>3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.metrics.HintsServiceMetrics.java</file>
      <file type="M">src.java.org.apache.cassandra.hints.HintsDispatcher.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12695" opendate="2016-9-23 00:00:00" fixdate="2016-11-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Truncate ALWAYS not applied</summary>
      <description>If truncate is set to ALWAYS and rate sets a specific thread count, the stress table is not actually truncated. E.g.truncate=always -rate threads=4This can cause an unexpected number of rows to be left in the table.</description>
      <version>3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.StressAction.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12696" opendate="2016-9-23 00:00:00" fixdate="2016-9-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow to change logging levels based on components</summary>
      <description>Currently users are able to dynamically change logging configuration by using nodetool setlogginglevel &lt;class&gt; &lt;level&gt;. Unfortunately this requires to know a bit about the Cassandra package hierarchy and gathering all the involved packages/classes can be tedious, especially in troubleshooting situations. What I'd like to have is a way to tell a user to "when X happens, enable debug logs for bootstrapping/repair/compactions/.." by simply running e.g. nodetool setlogginglevel bootstrap DEBUG.</description>
      <version>None</version>
      <fixedVersion>Legacy/Observability</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.nodetool.SetLoggingLevel.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12712" opendate="2016-9-26 00:00:00" fixdate="2016-10-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update Debian Install Doc</summary>
      <description>CASSANDRA-12239 added a key to the KEYS file, so deb repo install intsructions need to be update in the doc source (wiki page is updated).</description>
      <version>3.10</version>
      <fixedVersion>Legacy/DocumentationandWebsite</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">doc.source.getting.started.installing.rst</file>
    </fixedFiles>
  </bug>
  <bug id="12719" opendate="2016-9-28 00:00:00" fixdate="2016-3-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>typo in cql examples</summary>
      <description>Data Definition example use wrong definition</description>
      <version>None</version>
      <fixedVersion>Legacy/DocumentationandWebsite</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">doc.source.cql.ddl.rst</file>
    </fixedFiles>
  </bug>
  <bug id="12720" opendate="2016-9-28 00:00:00" fixdate="2016-10-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Permissions on aggregate functions are not removed on drop</summary>
      <description>When a user defined aggregate is dropped, either directly or when it's enclosing keyspace is dropped, permissions granted on it are not cleaned up.</description>
      <version>2.2.9,3.0.10,3.10</version>
      <fixedVersion>Legacy/DistributedMetadata</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.auth.AuthMigrationListener.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12729" opendate="2016-9-28 00:00:00" fixdate="2016-10-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cassandra-Stress: Use single seed in UUID generation</summary>
      <description>While testing the new sequence distribution for the user module of cassandra-stress I noticed that half of the expected rows (848 / 1696) were produced when using a single uuid primary key.table: player_info_by_uuidtable_definition: | CREATE TABLE player_info_by_uuid ( player_uuid uuid, player_full_name text, team_name text, weight double, height double, position text, PRIMARY KEY (player_uuid) )columnspec: - name: player_uuid size: fixed(32) # no. of chars of UUID population: seq(1..1696) # 53 active players per team, 32 teams = 1696 playersinsert: partitions: fixed(1) # 1 partition per batch batchtype: UNLOGGED # use unlogged batches select: fixed(1)/1 # no chance of skipping a row when generating insertsThe following debug output showed that we were over-incrementing the seedSeedManager.next.index: 341824SeriesGenerator.Seed.next: 0SeriesGenerator.Seed.start: 1SeriesGenerator.Seed.totalCount: 20SeriesGenerator.Seed.next % totalCount: 0SeriesGenerator.Seed.start + (next % totalCount): 1PartitionOperation.ready.seed: org.apache.cassandra.stress.generate.Seed@1DistributionSequence.nextWithWrap.next: 0DistributionSequence.nextWithWrap.start: 1DistributionSequence.nextWithWrap.totalCount: 20DistributionSequence.nextWithWrap.next % totalCount: 0DistributionSequence.nextWithWrap.start + (next % totalCount): 1DistributionSequence.nextWithWrap.next: 1DistributionSequence.nextWithWrap.start: 1DistributionSequence.nextWithWrap.totalCount: 20DistributionSequence.nextWithWrap.next % totalCount: 1DistributionSequence.nextWithWrap.start + (next % totalCount): 2Generated uuid: 00000000-0000-0001-0000-000000000002This patch fixes this issue by calling identityDistribution.next() once instead of twice when generating UUID's</description>
      <version>3.10</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.generate.values.UUIDs.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12739" opendate="2016-9-30 00:00:00" fixdate="2016-12-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Nodetool uses cassandra-env.sh MAX_HEAP_SIZE if set</summary>
      <description>Nodetool and other bash startup scripts load cassandra-env.sh variables including MAX_HEAP_SIZE as part of CASSANDRA-10679. If cassandra-env.sh has MAX_HEAP_SIZE set to any value the default heap size needed for the cassandra tool to run is overridden. This is a problem if the using a large heap in C* i.e. 16-32G due to each instance of nodetool or other tool will allocate large heap regardless of need and could exceed the total RAM available on the system.Patch removes the check for MAX_HEAP_SIZE being set and uses the default heap size needed for each tool.</description>
      <version>3.0.11,3.10</version>
      <fixedVersion>Tool/nodetool</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.nodetool</file>
    </fixedFiles>
  </bug>
  <bug id="12740" opendate="2016-10-3 00:00:00" fixdate="2016-10-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh copy tests hang in case of no answer from the server or driver</summary>
      <description>If we bundle the driver to cqlsh using the 3.6.0 tag or cassandra_test head, some cqlsh copy tests hang, for example test_bulk_round_trip_blogposts. See CASSANDRA-12736 and CASSANDRA-11534 for some sample failures.If the driver fails to invoke a callback (either error or success), or if the server never answers to the driver, then the copy parent process will wait forever to receive an answer from child processes. We should put a cap to this. We should also use a very high timeout rather than None, so that the driver will notify us if there is no answer from the server.</description>
      <version>3.0.10,3.10</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.copyutil.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12754" opendate="2016-10-6 00:00:00" fixdate="2016-10-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change cassandra.wait_for_tracing_events_timeout_secs default to -1 so C* doesn&amp;#39;t wait on trace events to be written before responding to request by default</summary>
      <description>CASSANDRA-11465 introduces a new system property cassandra.wait_for_tracing_events_timeout_secs that controls whether or not C* waits for events to be written before responding to client. The current default behavior is to wait up to 1 second and then respond and timeout. If using probabilistic tracing this can cause queries to be randomly delayed up to 1 second.Changing the default to -1 (disabled and enabling it explicitly in cql_tracing_test.TestCqlTracing.tracing_unknown_impl_test.Ideally it would be nice to be able to control this behavior on a per request basis (which would require native protocol changes).</description>
      <version>2.2.9,3.0.10,3.10</version>
      <fixedVersion>Legacy/Observability</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tracing.TraceState.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12759" opendate="2016-10-7 00:00:00" fixdate="2016-10-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cassandra-stress shows the incorrect JMX port in settings output</summary>
      <description>CASSANDRA-11914 introduces settings output for cassandra-stress; in that output, the JMX port is incorrectly reported. The attached patch fixes this.</description>
      <version>3.10</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.SettingsPort.java</file>
    </fixedFiles>
  </bug>
  <bug id="12765" opendate="2016-10-10 00:00:00" fixdate="2016-10-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>SSTable ignored incorrectly with partition level tombstone</summary>
      <description>CREATE TABLE test.payload( bucket_id TEXT, name TEXT, data TEXT, PRIMARY KEY (bucket_id, name));insert into test.payload (bucket_id, name, data) values ('8772618c9009cf8f5a5e0c18', 'test', 'hello');Flush nodes (nodetool flush)insert into test.payload (bucket_id, name, data) values ('8772618c9009cf8f5a5e0c19', 'test2', 'hello');delete from test.payload where bucket_id = '8772618c9009cf8f5a5e0c18';Flush nodes (nodetool flush)select * from test.payload where bucket_id = '8772618c9009cf8f5a5e0c18' and name = 'test';Expected 0 rows but get 1 row back.</description>
      <version>2.1.17,2.2.9,3.0.10,3.10,4.0-alpha1,4.0</version>
      <fixedVersion>Legacy/LocalWrite-ReadPaths</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.CollationController.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12776" opendate="2016-10-12 00:00:00" fixdate="2016-10-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>when memtable flush Statistics thisOffHeap error</summary>
      <description>if (largest != null) { float usedOnHeap = Memtable.MEMORY_POOL.onHeap.usedRatio(); float usedOffHeap = Memtable.MEMORY_POOL.offHeap.usedRatio(); float flushingOnHeap = Memtable.MEMORY_POOL.onHeap.reclaimingRatio(); float flushingOffHeap = Memtable.MEMORY_POOL.offHeap.reclaimingRatio(); float thisOnHeap = largest.getAllocator().onHeap().ownershipRatio(); float thisOffHeap = largest.getAllocator().onHeap().ownershipRatio(); logger.info("Flushing largest {} to free up room. Used total: {}, live: {}, flushing: {}, this: {}", largest.cfs, ratio(usedOnHeap, usedOffHeap), ratio(liveOnHeap, liveOffHeap), ratio(flushingOnHeap, flushingOffHeap), ratio(thisOnHeap, thisOffHeap)); largest.cfs.switchMemtableIfCurrent(largest); }Should:float thisOffHeap = largest.getAllocator().onHeap().ownershipRatio();Be:offHeap().ownershipRatio();</description>
      <version>3.0.10,3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12777" opendate="2016-10-12 00:00:00" fixdate="2016-10-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Optimize the vnode allocation for single replica per DC</summary>
      <description>The new vnode allocation algorithm introduced in CASSANDRA-7032 is optimized for the situation that there are multiple replicas per DC.In our production environment, most cluster only has one replica, in this case, the algorithm does not work perfectly. It always tries to split token ranges by half, so that the ownership of "min" node could go as low as ~60% compared to avg.So for single replica case, I'm working on a new algorithm, which is based on Branimir's previous commit, to split token ranges by "some" percentage, instead of always by half. In this way, we can get a very small variation of the ownership among different nodes.</description>
      <version>3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.dht.RandomPartitionerTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.dht.PartitionerTestCase.java</file>
      <file type="M">test.unit.org.apache.cassandra.dht.Murmur3PartitionerTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.dht.LengthPartitioner.java</file>
      <file type="M">test.long.org.apache.cassandra.dht.tokenallocator.AbstractReplicationAwareTokenAllocatorTest.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.tokenallocator.TokenAllocator.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.tokenallocator.TokenAllocation.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.tokenallocator.ReplicationAwareTokenAllocator.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.RandomPartitioner.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.OrderPreservingPartitioner.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.Murmur3Partitioner.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.LocalPartitioner.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.IPartitioner.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.ByteOrderedPartitioner.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12781" opendate="2016-10-12 00:00:00" fixdate="2016-12-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Disable RPC_READY gossip flag when shutting down client servers</summary>
      <description>example failure:http://cassci.datastax.com/job/cassandra-3.X_dtest/4/testReport/pushed_notifications_test/TestPushedNotifications/restart_node_testError Message[{'change_type': u'DOWN', 'address': ('127.0.0.2', 9042)}, {'change_type': u'UP', 'address': ('127.0.0.2', 9042)}, {'change_type': u'DOWN', 'address': ('127.0.0.2', 9042)}]Stacktrace File "/usr/lib/python2.7/unittest/case.py", line 329, in run testMethod() File "/home/automaton/cassandra-dtest/pushed_notifications_test.py", line 181, in restart_node_test self.assertEquals(expected_notifications, len(notifications), notifications) File "/usr/lib/python2.7/unittest/case.py", line 513, in assertEqual assertion_func(first, second, msg=msg) File "/usr/lib/python2.7/unittest/case.py", line 506, in _baseAssertEqual raise self.failureException(msg)</description>
      <version>3.0.11,3.10</version>
      <fixedVersion>Legacy/DistributedMetadata</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.Gossiper.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12786" opendate="2016-10-13 00:00:00" fixdate="2016-10-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix a bug in CASSANDRA-11005(Split consisten range movement flag)</summary>
      <description>I missed a place in the code where we need to split this flag for bootstrap</description>
      <version>2.2.9,3.0.10,3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12794" opendate="2016-10-16 00:00:00" fixdate="2016-1-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>COPY FROM with NULL=&amp;#39;&amp;#39; fails when inserting empty row in primary key</summary>
      <description>Using this table:CREATE TABLE testtab ( a_id text, b_id text, c_id text, d_id text, order_id uuid, acc_id bigint, bucket bigint, r_id text, ts bigint, PRIMARY KEY ((a_id, b_id, c_id, d_id), order_id));insert one row:INSERT INTO testtab (a_id, b_id , c_id , d_id , order_id, r_id ) VALUES ( '', '', '', 'a1', 645e7d3c-aef7-4e3c-b834-24b792cf2e55, 'r1');Use COPY to dump the row to temp.csv:copy testtab TO 'temp.csv';Which creates this file:$ cat temp.csv ,,,a1,645e7d3c-aef7-4e3c-b834-24b792cf2e55,,,r1,Truncate the testtab table and then use copy from with NULL='' to insert the row:cqlsh:sbkeyspace&gt; COPY testtab FROM 'temp.csv' with NULL='';Using 1 child processesStarting copy of sbkeyspace.testtab with columns ['a_id', 'b_id', 'c_id', 'd_id', 'order_id', 'acc_id', 'bucket', 'r_id', 'ts'].Failed to import 1 rows: ParseError - Cannot insert null value for primary key column 'a_id'. If you want to insert empty strings, consider using the WITH NULL=&lt;marker&gt; option for COPY., given up without retriesFailed to process 1 rows; failed rows written to import_sbkeyspace_testtab.errProcessed: 1 rows; Rate: 2 rows/s; Avg. rate: 3 rows/s1 rows imported from 1 files in 0.398 seconds (0 skipped).It shows 1 rows inserted, but the table is empty:select * from testtab ; a_id | b_id | c_id | d_id | order_id | acc_id | bucket | r_id | ts------+------+------+------+----------+--------+--------+------+----(0 rows)The same error is returned even without the with NULL=''. Is it actually possible for copy from to insert an empty row into the primary key? The insert command shown above inserts the empty row for the primary key without any problems.Is this related to https://issues.apache.org/jira/browse/CASSANDRA-7792?</description>
      <version>3.0.11,3.10</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.copyutil.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12803" opendate="2016-10-18 00:00:00" fixdate="2016-10-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>PER PARTITION LIMIT not recognized by cqlsh auto completion</summary>
      <description>cqlsh's syntax definition does not know about PER PARTITION LIMIT and therefore does not propose it for auto-completion.</description>
      <version>3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.cql3handling.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12805" opendate="2016-10-18 00:00:00" fixdate="2016-4-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Website documentation for commitlog</summary>
      <description>Updated Storage Engine page for commitlogsCommit: https://github.com/nothau/cassandra/commit/f90038e9f35281bdd58dabb25f21836a690e56f5</description>
      <version>None</version>
      <fixedVersion>Legacy/DocumentationandWebsite</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">doc.source.architecture.storage.engine.rst</file>
    </fixedFiles>
  </bug>
  <bug id="12812" opendate="2016-10-19 00:00:00" fixdate="2016-10-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>testall failure in org.apache.cassandra.dht.tokenallocator.RandomReplicationAwareTokenAllocatorTest.testExistingCluster</summary>
      <description>example failure:http://cassci.datastax.com/job/trunk_testall/1239/testReport/org.apache.cassandra.dht.tokenallocator/RandomReplicationAwareTokenAllocatorTest/testExistingCluster/Error MessageExpected max unit size below 1.2500, was 1.2564Stacktracejunit.framework.AssertionFailedError: Expected max unit size below 1.2500, was 1.2564 at org.apache.cassandra.dht.tokenallocator.AbstractReplicationAwareTokenAllocatorTest.grow(AbstractReplicationAwareTokenAllocatorTest.java:657) at org.apache.cassandra.dht.tokenallocator.RandomReplicationAwareTokenAllocatorTest.grow(RandomReplicationAwareTokenAllocatorTest.java:26) at org.apache.cassandra.dht.tokenallocator.AbstractReplicationAwareTokenAllocatorTest.testExistingCluster(AbstractReplicationAwareTokenAllocatorTest.java:545) at org.apache.cassandra.dht.tokenallocator.AbstractReplicationAwareTokenAllocatorTest.testExistingCluster(AbstractReplicationAwareTokenAllocatorTest.java:518) at org.apache.cassandra.dht.tokenallocator.RandomReplicationAwareTokenAllocatorTest.testExistingCluster(RandomReplicationAwareTokenAllocatorTest.java:38)</description>
      <version>3.10</version>
      <fixedVersion>Legacy/Testing</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.utils.GuidGenerator.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.RandomPartitioner.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12829" opendate="2016-10-21 00:00:00" fixdate="2016-1-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>DELETE query with an empty IN clause can delete more than expected</summary>
      <description>When deleting from a table with a certain structure and using an in clause with an empty list, the in clause with an empty list can be ignored, resulting in deleting more than is expected.Setup:cqlsh&gt; create table test (a text, b text, id uuid, primary key ((a, b), id));cqlsh&gt; insert into test (a, b, id) values ('a', 'b', 00000000-0000-0000-0000-000000000000);cqlsh&gt; insert into test (a, b, id) values ('b', 'c', 00000000-0000-0000-0000-000000000000);cqlsh&gt; insert into test (a, b, id) values ('a', 'c', 00000000-0000-0000-0000-000000000000);cqlsh&gt; select * from test; a | b | id---+---+-------------------------------------- a | c | 00000000-0000-0000-0000-000000000000 b | c | 00000000-0000-0000-0000-000000000000 a | b | 00000000-0000-0000-0000-000000000000(3 rows)Expected:cqlsh&gt; delete from test where a = 'a' and b in ('a', 'b', 'c') and id in ();cqlsh&gt; select * from test; a | b | id---+---+-------------------------------------- a | c | 00000000-0000-0000-0000-000000000000 b | c | 00000000-0000-0000-0000-000000000000 a | b | 00000000-0000-0000-0000-000000000000(3 rows)Actual:cqlsh&gt; delete from test where a = 'a' and b in ('a', 'b', 'c') and id in ();cqlsh&gt; select * from test; a | b | id---+---+-------------------------------------- b | c | 00000000-0000-0000-0000-000000000000(1 rows)Instead of deleting nothing, as the final empty in clause would imply, it instead deletes everything that matches the first two clauses, acting as if the following query had been issued instead:cqlsh&gt; delete from test where a = 'a' and b in ('a', 'b', 'c');This seems to be related to the presence of a tuple clustering key, as I could not reproduce it without one.</description>
      <version>3.0.11,3.10</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.UpdateTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.InsertUpdateIfConditionTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.InsertTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.DeleteTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.BatchTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.CQLTester.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.ModificationStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.BatchStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.restrictions.StatementRestrictions.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12836" opendate="2016-10-24 00:00:00" fixdate="2016-10-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Set JOINING mode before executing the pre-join index callback</summary>
      <description>The pre-join index callback introduced by CASSANDRA-12039 might perform long running tasks, and given it's blocking, it would be good to set the node in JOINING mode, which currently only happens in case of bootstrap, so that:1) The mode can be properly read by tools.2) Async callback implementation can read the mode themselves to verify at which point of the startup process they are executing.</description>
      <version>3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12850" opendate="2016-10-27 00:00:00" fixdate="2016-1-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add the duration type to the protocol V5</summary>
      <description>The Duration type need to be added to the protocol specifications.</description>
      <version>3.10</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.transport.DataTypeTest.java</file>
      <file type="M">src.java.org.apache.cassandra.transport.OptionCodec.java</file>
      <file type="M">src.java.org.apache.cassandra.transport.DataType.java</file>
      <file type="M">doc.native.protocol.v5.spec</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12856" opendate="2016-10-28 00:00:00" fixdate="2016-1-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>dtest failure in replication_test.SnitchConfigurationUpdateTest.test_cannot_restart_with_different_rack</summary>
      <description>example failure:http://cassci.datastax.com/job/cassandra-2.1_novnode_dtest/280/testReport/replication_test/SnitchConfigurationUpdateTest/test_cannot_restart_with_different_rackError MessageProblem stopping node node1Stacktrace File "/usr/lib/python2.7/unittest/case.py", line 329, in run testMethod() File "/home/automaton/cassandra-dtest/replication_test.py", line 630, in test_cannot_restart_with_different_rack node1.stop(wait_other_notice=True) File "/usr/local/lib/python2.7/dist-packages/ccmlib/node.py", line 727, in stop raise NodeError("Problem stopping node %s" % self.name)</description>
      <version>2.1.17,2.2.9,3.0.11,3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.thrift.CustomTThreadPoolServer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12863" opendate="2016-10-31 00:00:00" fixdate="2016-11-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh COPY FROM cannot parse timestamp in partition key if table contains a counter value</summary>
      <description>This sample table:CREATE TABLE test (columnname text, day timestamp, israndom boolean, columnvalue text, counter counter, PRIMARY KEY ((columnname, day, israndom), columnvalue));with this sample data:origins|2016-10-01 00:00:00+0000|False|ACTUAL|6origins|2016-10-01 00:00:00+0000|False|ADGMOB|4origins|2016-10-01 00:00:00+0000|False|ANONPM|4origins|2016-10-01 00:00:00+0000|False|CSRT2L|76origins|2016-10-01 00:00:00+0000|False|DIAGOP|18origins|2016-10-01 00:00:00+0000|False|E-SOFT|17origins|2016-10-01 00:00:00+0000|False|E-TASK|10when imported withCOPY ks.test FROM 'test.csv' WITH DELIMITER = '|';will generate a parse error:Failed to import 7 rows: ParseError - can't interpret u"'2016-10-01 00:00:00+0000'" as a date with this format: %Y-%m-%d %H:%M:%S%z, given up without retriesThe problem is that when a counter value is present, we don't use prepared statements and so we typically don't convert values unless they are part of the partition key. We also add quotes for certain types, such as timestamps. The problem is that we do not remove such quotes before parsing the partition key values, therefore ending up with a parse error.</description>
      <version>2.2.9,3.0.10,3.10</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.copyutil.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12868" opendate="2016-11-2 00:00:00" fixdate="2016-12-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reject default_time_to_live option when creating or altering MVs</summary>
      <description>Hi,By default, materialized views are using the TTL of primary table, irrespective of the configured value provided in materialized view creation.For eg:table:CREATE TABLE test2(id text, date text, col1 text,col2 text, PRIMARY KEY(id,date)) WITH default_time_to_live = 60 AND CLUSTERING ORDER BY (date DESC);CREATE MATERIALIZED VIEW test3_view ASSELECT id, date, col1FROM test3 WHERE id IS NOT NULL AND date IS NOT NULLPRIMARY KEY(id,date) WITH default_time_to_live = 30;The queries are accepted in CQL. As per the detail, it should use 30 seconds for Materialized view and 60 seconds for parent table.But, it is always 60 seconds (as the parent table)case 1: parent table and materialized view with different TTLMV will always have the TTL of parent.case 2:Parent table without TTL but materialized view with TTLMV does not have the TTL even though the configuration has been accepted in the table creation.Expected:Either the TTL configuration should not be accepted in the materialized view creation, if it is of no value.OrTTL has to be applied differently for both Materialized View and Table if the configuration is added.If no configuration, TTL has to be taken from the parent table.</description>
      <version>3.0.11,3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.ViewTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateViewStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.AlterViewStatement.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12883" opendate="2016-11-5 00:00:00" fixdate="2016-1-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove support for non-JavaScript UDFs</summary>
      <description>As recently reported in the user mailing list, JSR-223 languages other than JavaScript no longer work since version 3.0.The reason is that the sandbox implemented in CASSANDRA-9402 restricts the use of "evil" packages, classes and functions. Unfortunately, even "non-evil" packages from JSR-223 providers are blocked.In order to get a JSR-223 provider working fine, we need to allow JSR-223 provider specific packages and also allow specific runtime permissions.The fact that "arbitrary" JSR-223 providers no longer work since 3.0 has just been reported recently, means that this functionality (i.e. non-JavaSCript JSR-223 UDFs) is obviously not used.Therefore I propose to remove support for UDFs that do not use Java or JavaScript in 4.0. This will also allow to specialize scripted UDFs on Nashorn and allow to use its security features, although these are limited, more extensively. (Clarification: this ticket is just about to remove that support)Also want to point out that we never "officially" supported UDFs that are not Java or JavaScript.Sample error message:Traceback (most recent call last): File "/usr/bin/cqlsh.py", line 1264, in perform_simple_statement result = future.result() File "/usr/share/cassandra/lib/cassandra-driver-internal-only-3.5.0.post0-d8d0456.zip/cassandra-driver-3.5.0.post0-d8d0456/cassandra/cluster.py", line 3650, in result raise self._final_exceptionFunctionFailure: Error from server: code=1400 [User Defined Function failure] message="execution of 'e.test123[bigint]' failed: java.security.AccessControlException: access denied: ("java.lang.RuntimePermission" "accessClassInPackage.org.python.jline.console")</description>
      <version>2.2.9,3.0.11,3.10</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.functions.ScriptBasedUDF.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">conf.cassandra-env.ps1</file>
    </fixedFiles>
  </bug>
  <bug id="12889" opendate="2016-11-9 00:00:00" fixdate="2016-11-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Pass root cause to CorruptBlockException when uncompression failed</summary>
      <description>When reading compressed SSTable failed, CorruptBlockException is thrown without root cause. It is nice to have when investigating uncompression error.</description>
      <version>3.0.10,3.10</version>
      <fixedVersion>Legacy/LocalWrite-ReadPaths</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.compress.CompressedSequentialWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.io.compress.CompressedRandomAccessReader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12901" opendate="2016-11-10 00:00:00" fixdate="2016-11-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Repair can hang if node dies during sync or anticompaction</summary>
      <description>Since the repair coordinator unregisters from the FD after validation (CASSANDRA-3569), if the initiator of a RemoteSyncTask fails, the coordinator will never know the sync task failed and hang.</description>
      <version>2.2.9,3.0.11,3.10</version>
      <fixedVersion>Legacy/StreamingandMessaging</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.ActiveRepairService.java</file>
      <file type="M">src.java.org.apache.cassandra.repair.RepairSession.java</file>
      <file type="M">src.java.org.apache.cassandra.repair.AnticompactionTask.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12909" opendate="2016-11-14 00:00:00" fixdate="2016-12-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh copy cannot parse strings when counters are present</summary>
      <description>We get parse error Failed to import 1 rows: ParseError - argument for 's' must be a string when using the following table and data:CREATE TABLE ks.test ( object_id ascii, user_id timeuuid, counter_id ascii, count counter, PRIMARY KEY ((object_id, user_id), counter_id))EVT:be3bd2d0-a68d-11e6-90d4-1b2a65b8a28a,f7ce3ac0-a66e-11e6-b58e-4e29450fd577,SA,2The problem is this line here, strings are serialized as unicode rather than ordinary strings but only for non-prepared statements (unsure why).</description>
      <version>2.2.9,3.0.11,3.10</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.copyutil.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12916" opendate="2016-11-16 00:00:00" fixdate="2016-11-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Broken UDT muitations loading from CommitLog</summary>
      <description>UDT mutatitions seems to be broken. Simple example is attached. After steps from it, restart cassandra and during commit log reading it will fail with error:ERROR 09:34:46 Exiting due to error while processing commit log during initialization.org.apache.cassandra.db.commitlog.CommitLogReadHandler$CommitLogReadException: Unexpected error deserializing mutation; saved to /tmp/mutation6087238241614604390dat. This may be caused by replaying a mutation against a table with the same name but incompatible schema. Exception follows: org.apache.cassandra.serializers.MarshalException: Not enough bytes to read 0th field dataI resolved this problem, so my patch is in attachment.</description>
      <version>3.10</version>
      <fixedVersion>Legacy/LocalWrite-ReadPaths</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.CellTest.java</file>
      <file type="M">src.java.org.apache.cassandra.thrift.ThriftValidation.java</file>
      <file type="M">src.java.org.apache.cassandra.db.rows.AbstractRow.java</file>
      <file type="M">src.java.org.apache.cassandra.db.rows.AbstractCell.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.UserType.java</file>
      <file type="M">src.java.org.apache.cassandra.config.ColumnDefinition.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12919" opendate="2016-11-17 00:00:00" fixdate="2016-11-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix inconsistencies in cassandra-stress load balancing policy</summary>
      <description>The default load balancing policy in cassandra-stress is null, which means that the driver will currently wrap DCAwareRoundRobinPolicy with TokenAwarePolicy. However, when a white list of nodes or a data center are specified in the command line options, then either WhiteListPolicy or DCAwareRoundRobinPolicy are used respectively, without wrapping them in a TokenAwarePolicy.This means that in the default case token aware routing is applied, but in some cases it is not. Token aware routing could give a performance boost of up to 2.5 times on bare metal, making comparisons of workloads problematic, if it is applied inconsistently.</description>
      <version>3.10</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.util.JavaDriverClient.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12925" opendate="2016-11-17 00:00:00" fixdate="2016-1-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>AssertionError executing authz stmt on UDF without keyspace</summary>
      <description>Performing a GRANT or REVOKE on a user defined function requires the function name to be qualified by its keyspace. Unlike GRANT/REVOKE on a table, the keyspace cannot be inferred from the ClientState as it's needed by the parser to either lookup the function (in 2.2), or convert the function arguments from CQL types to their corresponding AbstractType (in 3.0+).Currently, performing such a statement results in an unhandled assert error and a ServerError response to the client.</description>
      <version>3.0.11,3.10</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.UFAuthTest.java</file>
      <file type="M">src.java.org.apache.cassandra.auth.FunctionResource.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12945" opendate="2016-11-22 00:00:00" fixdate="2016-11-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Resolve unit testing without JCE security libraries installed</summary>
      <description>Running unit tests can fail on encryption-related tests if you don't have something like the Oracle JCE libraries installed in your jdk. We can't redistribute the Oracle JCE due to export laws, then we'd need to somehow get it into the &lt;jdk&gt;/jre/lib/security.One possibility is to ignore encryption-related tests if there is no encryption lib available. Another is to ship something like bouncycastle.jar in the test directory.</description>
      <version>3.10,4.0-alpha1,4.0</version>
      <fixedVersion>Legacy/Core</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.data.legacy-commitlog.3.4-encrypted.hash.txt</file>
      <file type="M">test.data.legacy-commitlog.3.4-encrypted.CommitLog-6-1452918948163.log</file>
      <file type="M">test.conf.cassandra.keystore</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12959" opendate="2016-11-27 00:00:00" fixdate="2016-12-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>copy from csv import wrong values with udt having set when fields are not specified in correct order in csv</summary>
      <description>create KEYSPACE test WITH replication = { 'class': 'SimpleStrategy', 'replication_factor': 1};CREATE TYPE test.my_udt ( first_field text, second_field frozen&lt;set&lt;text&gt;&gt;);CREATE TABLE test.test ( key text, value my_udt, PRIMARY KEY (key));The following works as expected : INSERT INTO test.test (key , value ) VALUES ( 'key1', {second_field: {'test1', 'test2'}, first_field: 'first_field'}); key | value-----+--------------------------------------------------------------- key1 | {first_field: 'first_field', second_field: {'test1', 'test2'}}but when inserted using a .csv the result is wrong:"key1","{second_field: {'test1', 'test2'}, first_field: 'first_field'}"COPY test.test FROM '~/test.csv'; key | value-----+--------------------------------------------------------------------- key1 | {first_field: '{''test1'', ''test2''}', second_field: {'irst_fiel'}}it works as expected if the keys are in order: "key1","{first_field: 'first_field', second_field: {'test1', 'test2'}}")</description>
      <version>2.1.17,2.2.9,3.0.11,3.10</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.copyutil.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12979" opendate="2016-11-30 00:00:00" fixdate="2016-1-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>checkAvailableDiskSpace doesn&amp;#39;t update expectedWriteSize when reducing thread scope</summary>
      <description>If a compaction occurs that looks like it'll take up more space than remaining disk available, the compaction manager attempts to reduce the scope of the compaction by calling reduceScopeForLimitedSpace() repeatedly. Unfortunately, the while loop passes the estimatedWriteSize calculated from the original call to hasAvailableDiskSpace, so the comparisons that are done will always be against the size of the original compaction, rather than the reduced scope one.Full method below: protected void checkAvailableDiskSpace(long estimatedSSTables, long expectedWriteSize) { if(!cfs.isCompactionDiskSpaceCheckEnabled() &amp;&amp; compactionType == OperationType.COMPACTION) { logger.info("Compaction space check is disabled"); return; } while (!getDirectories().hasAvailableDiskSpace(estimatedSSTables, expectedWriteSize)) { if (!reduceScopeForLimitedSpace()) throw new RuntimeException(String.format("Not enough space for compaction, estimated sstables = %d, expected write size = %d", estimatedSSTables, expectedWriteSize)); } }I'm proposing to recalculate the estimatedSSTables and expectedWriteSize after each iteration of reduceScopeForLimitedSpace.</description>
      <version>2.2.9,3.0.11,3.10,4.0-alpha1,4.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionTask.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12984" opendate="2016-12-2 00:00:00" fixdate="2016-12-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>MVs are built unnecessarily again after bootstrap</summary>
      <description>After bootstrap MVs are enqueued to be built but they have been already created by the bootstrap.Simply adding them to system.built_views after a successful bootstrap should fix that issue.</description>
      <version>3.0.11,3.10</version>
      <fixedVersion>Legacy/Core</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12989" opendate="2016-12-3 00:00:00" fixdate="2016-12-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Correct function doc to clear up statement isolation</summary>
      <description>Documentation arguably implies that 'now()' returns 'a unique' result 'per statement'. This is not true it returns a unique result per call.</description>
      <version>3.10</version>
      <fixedVersion>Legacy/DocumentationandWebsite</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">doc.source.cql.functions.rst</file>
    </fixedFiles>
  </bug>
  <bug id="13013" opendate="2016-12-7 00:00:00" fixdate="2016-1-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Potential regression from CASSANDRA-6377</summary>
      <description>As noted by thobbs in CASSANDRA-12768, in 3.0 (and prior) we return static results for a partition if it is the only results when the query is a 2ndary index query. This doesn't seem to happen anymore in 3.X and that was removed by CASSANDRA-6377 (see the merge commit, but that removal is actually part of the original trunk patch for CASSANDRA-6377).The removal looks intentional but it's unclear to thobbs and myself why it's not a potentially breaking change, and even if it's a legit change, why it was done in 3.X (then trunk) but not 3.0?blerer, can you enlighten us?</description>
      <version>3.10</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.SecondaryIndexTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.ModificationStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.restrictions.StatementRestrictions.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.restrictions.RestrictionSet.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13033" opendate="2016-12-12 00:00:00" fixdate="2016-12-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thread local pools never cleaned up</summary>
      <description>Netty 4.x uses (Fast)ThreadLocal instances to provide a pool of (direct) buffers per thread (io.netty.buffer.PooledByteBufAllocator.PoolThreadLocalCache. However, these per-thread pools need to be cleaned up when a thread terminates (FastThreadLocal.removeAll()) - which is missing.Although the possibility that such per-thread pools ever need to be cleaned up, since we rarely terminate threads, it still may actually happen and manifest in a late and hard to detect out-of-memory situation. One possibility to raise such a scenario is to regularly stop and restart the native protocol service.</description>
      <version>3.0.11,3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.streaming.ConnectionHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.compress.CompressedInputStream.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.scheduler.RoundRobinScheduler.java</file>
      <file type="M">src.java.org.apache.cassandra.repair.RepairRunnable.java</file>
      <file type="M">src.java.org.apache.cassandra.net.OutboundTcpConnection.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLogSegmentManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.AbstractCommitLogService.java</file>
      <file type="M">src.java.org.apache.cassandra.concurrent.NamedThreadFactory.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13058" opendate="2016-12-19 00:00:00" fixdate="2016-1-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>dtest failure in hintedhandoff_test.TestHintedHandoff.hintedhandoff_decom_test</summary>
      <description>example failure:http://cassci.datastax.com/job/cassandra-3.X_novnode_dtest/16/testReport/hintedhandoff_test/TestHintedHandoff/hintedhandoff_decom_test/Error MessageSubprocess ['nodetool', '-h', 'localhost', '-p', '7100', ['decommission']] exited with non-zero status; exit status: 2; stderr: error: Error while decommissioning node: Failed to transfer all hints to 59f20b4f-0215-4e18-be1b-7e00f2901629Stacktrace File "/usr/lib/python2.7/unittest/case.py", line 329, in run testMethod() File "/home/automaton/cassandra-dtest/hintedhandoff_test.py", line 167, in hintedhandoff_decom_test node1.decommission() File "/usr/local/lib/python2.7/dist-packages/ccmlib/node.py", line 1314, in decommission self.nodetool("decommission") File "/usr/local/lib/python2.7/dist-packages/ccmlib/node.py", line 783, in nodetool return handle_external_tool_process(p, ['nodetool', '-h', 'localhost', '-p', str(self.jmx_port), cmd.split()]) File "/usr/local/lib/python2.7/dist-packages/ccmlib/node.py", line 1993, in handle_external_tool_process raise ToolError(cmd_args, rc, out, err)java.lang.RuntimeException: Error while decommissioning node: Failed to transfer all hints to 59f20b4f-0215-4e18-be1b-7e00f2901629 at org.apache.cassandra.service.StorageService.decommission(StorageService.java:3924) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275) at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:112) at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:46) at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237) at com.sun.jmx.mbeanserver.PerInterface.invoke(PerInterface.java:138) at com.sun.jmx.mbeanserver.MBeanSupport.invoke(MBeanSupport.java:252) at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.invoke(DefaultMBeanServerInterceptor.java:819) at com.sun.jmx.mbeanserver.JmxMBeanServer.invoke(JmxMBeanServer.java:801) at javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1466) at javax.management.remote.rmi.RMIConnectionImpl.access$300(RMIConnectionImpl.java:76) at javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1307) at javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1399) at javax.management.remote.rmi.RMIConnectionImpl.invoke(RMIConnectionImpl.java:828) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:323) at sun.rmi.transport.Transport$1.run(Transport.java:200) at sun.rmi.transport.Transport$1.run(Transport.java:197) at java.security.AccessController.doPrivileged(Native Method) at sun.rmi.transport.Transport.serviceCall(Transport.java:196) at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:568) at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:826) at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.lambda$run$241(TCPTransport.java:683) at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler$$Lambda$284/1694175644.run(Unknown Source) at java.security.AccessController.doPrivileged(Native Method) at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:682) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745)</description>
      <version>3.10</version>
      <fixedVersion>Test/dtest/python</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.hints.HintVerbHandler.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13143" opendate="2017-1-20 00:00:00" fixdate="2017-1-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cassandra can accept invalid durations</summary>
      <description>A duration can be positive or negative. If the duration is positive the months, days and nanoseconds must be greater or equals to zero. If the duration is negative the months, days and nanoseconds must be smaller or equals to zero.Currently, it is possible to send to C* a duration which does not respect that rule and the data will not be reject.</description>
      <version>3.10</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.CreateTest.java</file>
      <file type="M">src.java.org.apache.cassandra.serializers.DurationSerializer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6216" opendate="2013-10-18 00:00:00" fixdate="2013-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Level Compaction should persist last compacted key per level</summary>
      <description>Level compaction does not persist the last compacted key per level. This is important for higher levels. The sstables with higher token and in higher levels wont get a chance to compact as the last compacted key will get reset after a restart.</description>
      <version>3.0.9,3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LeveledManifest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LeveledCompactionStrategy.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7019" opendate="2014-4-10 00:00:00" fixdate="2014-8-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve tombstone compactions</summary>
      <description>When there are no other compactions to do, we trigger a single-sstable compaction if there is more than X% droppable tombstones in the sstable.In this ticket we should try to include overlapping sstables in those compactions to be able to actually drop the tombstones. Might only be doable with LCS (with STCS we would probably end up including all sstables)</description>
      <version>3.10</version>
      <fixedVersion>Local/Compaction</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.rows.UnfilteredRowIteratorsMergeTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.selection.SelectionColumnMappingTest.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeTool.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeProbe.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageServiceMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.schema.CompactionParams.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableSimpleIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableIdentityIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.format.SSTableReader.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.format.big.BigTableScanner.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.format.big.BigTableReader.java</file>
      <file type="M">src.java.org.apache.cassandra.index.sasi.SASIIndexBuilder.java</file>
      <file type="M">src.java.org.apache.cassandra.db.rows.UnfilteredSerializer.java</file>
      <file type="M">src.java.org.apache.cassandra.db.rows.Rows.java</file>
      <file type="M">src.java.org.apache.cassandra.db.rows.Cells.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.Verifier.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.TimeWindowCompactionStrategy.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.Scrubber.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.OperationType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LeveledCompactionStrategy.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.DateTieredCompactionStrategy.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionController.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.AbstractCompactionStrategy.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7190" opendate="2014-5-7 00:00:00" fixdate="2014-8-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add schema to snapshot manifest</summary>
      <description>followup from CASSANDRA-6326</description>
      <version>3.0.9,3.10</version>
      <fixedVersion>Feature/MaterializedViews,Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.antlr.Parser.g</file>
      <file type="M">test.unit.org.apache.cassandra.schema.LegacySchemaMigratorTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.SchemaLoader.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.AlterTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Directories.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.AlterTableStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.Cql.g</file>
      <file type="M">src.java.org.apache.cassandra.cql3.ColumnIdentifier.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7384" opendate="2014-6-12 00:00:00" fixdate="2014-8-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Collect metrics on queries by consistency level</summary>
      <description>We had cases where cassandra client users thought that they were doing queries at one consistency level but turned out to be not correct. It will be good to collect metrics on number of queries done at various consistency level on the server. See the equivalent JIRA on java driver: https://datastax-oss.atlassian.net/browse/JAVA-354</description>
      <version>3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="8523" opendate="2014-12-19 00:00:00" fixdate="2014-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Writes should be sent to a replacement node which has a new IP while it is streaming in data</summary>
      <description>In our operations, we make heavy use of replace_address (or replace_address_first_boot) in order to replace broken nodes. We now realize that writes are not sent to the replacement nodes while they are in hibernate state and streaming in data. This runs counter to what our expectations were, especially since we know that writes ARE sent to nodes when they are bootstrapped into the ring.It seems like cassandra should arrange to send writes to a node that is in the process of replacing another node, just like it does for a nodes that are bootstraping. I hesitate to phrase this as "we should send writes to a node in hibernate" because the concept of hibernate may be useful in other contexts, as per CASSANDRA-8336. Maybe a new state is needed here?Among other things, the fact that we don't get writes during this period makes subsequent repairs more expensive, proportional to the number of writes that we miss (and depending on the amount of data that needs to be streamed during replacement and the time it may take to rebuild secondary indexes, we could miss many many hours worth of writes). It also leaves us more exposed to consistency violations.</description>
      <version>2.2.8,3.0.9,3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.LoadBroadcaster.java</file>
      <file type="M">src.java.org.apache.cassandra.locator.TokenMetadata.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.VersionedValue.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.Gossiper.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">doc.source.operating.topo.changes.rst</file>
    </fixedFiles>
  </bug>
  <bug id="8616" opendate="2015-1-13 00:00:00" fixdate="2015-12-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>sstable tools may result in commit log segments be written</summary>
      <description>There was a report of sstable2json causing commitlog segments to be written out when run. I haven't attempted to reproduce this yet, so that's all I know for now. Since sstable2json loads the conf and schema, I'm thinking that it may inadvertently be triggering the commitlog code.sstablescrub, sstableverify, and other sstable tools have the same issue.</description>
      <version>2.2.9,3.0.11,3.10</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.service.StorageServiceServerTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.SchemaLoader.java</file>
      <file type="M">test.unit.org.apache.cassandra.locator.GoogleCloudSnitchTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.locator.EC2SnitchTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.locator.CloudstackSnitchTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.io.sstable.CQLSSTableWriterTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.gms.GossiperTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.gms.FailureDetectorTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.dht.StreamStateStoreTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.SystemKeyspaceTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.NativeCellTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.lifecycle.TrackerTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.lifecycle.LifecycleTransactionTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.CounterCellTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.context.CounterContextTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.config.DatabaseDescriptorTest.java</file>
      <file type="M">test.long.org.apache.cassandra.io.sstable.CQLSSTableWriterLongTest.java</file>
      <file type="M">src.java.org.apache.cassandra.service.EmbeddedCassandraService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.CassandraDaemon.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.format.SSTableReader.java</file>
      <file type="M">src.java.org.apache.cassandra.db.lifecycle.Tracker.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionTask.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.cassandra.tools.StandaloneUpgrader.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.StandaloneSplitter.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.StandaloneScrubber.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.SSTableImport.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.SSTableExport.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="8831" opendate="2015-2-19 00:00:00" fixdate="2015-7-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create a system table to expose prepared statements</summary>
      <description>Because drivers abstract from users the handling of up/down nodes, they have to deal with the fact that when a node is restarted (or join), it won't know any prepared statement. Drivers could somewhat ignore that problem and wait for a query to return an error (that the statement is unknown by the node) to re-prepare the query on that node, but it's relatively inefficient because every time a node comes back up, you'll get bad latency spikes due to some queries first failing, then being re-prepared and then only being executed. So instead, drivers (at least the java driver but I believe others do as well) pro-actively re-prepare statements when a node comes up. It solves the latency problem, but currently every driver instance blindly re-prepare all statements, meaning that in a large cluster with many clients there is a lot of duplication of work (it would be enough for a single client to prepare the statements) and a bigger than necessary load on the node that started.An idea to solve this it to have a (cheap) way for clients to check if some statements are prepared on the node. There is different options to provide that but what I'd suggest is to add a system table to expose the (cached) prepared statements because: it's reasonably straightforward to implement: we just add a line to the table when a statement is prepared and remove it when it's evicted (we already have eviction listeners). We'd also truncate the table on startup but that's easy enough). We can even switch it to a "virtual table" if/when CASSANDRA-7622 lands but it's trivial to do with a normal table in the meantime. it doesn't require a change to the protocol or something like that. It could even be done in 2.1 if we wish to. exposing prepared statements feels like a genuinely useful information to have (outside of the problem exposed here that is), if only for debugging/educational purposes.The exposed table could look something like:CREATE TABLE system.prepared_statements ( keyspace_name text, table_name text, prepared_id blob, query_string text, PRIMARY KEY (keyspace_name, table_name, prepared_id))</description>
      <version>3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.utils.MD5Digest.java</file>
      <file type="M">src.java.org.apache.cassandra.service.CassandraDaemon.java</file>
      <file type="M">src.java.org.apache.cassandra.db.SystemKeyspace.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.QueryProcessor.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9613" opendate="2015-6-17 00:00:00" fixdate="2015-7-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Omit (de)serialization of state variable in UDAs</summary>
      <description>Currently the result of each UDA's state function call is serialized and then deserialized for the next state-function invocation and optionally final function invocation.</description>
      <version>3.10</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.AggregationTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.udfverify.UsingMapEntry.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.udfverify.UseOfSynchronizedWithWaitLI.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.udfverify.UseOfSynchronizedWithWaitL.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.udfverify.UseOfSynchronizedWithWait.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.udfverify.UseOfSynchronizedWithNotifyAll.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.udfverify.UseOfSynchronizedWithNotify.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.udfverify.UseOfSynchronized.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.udfverify.GoodClass.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.udfverify.ClassWithStaticInnerClass.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.udfverify.ClassWithStaticInitializer.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.udfverify.ClassWithInnerClass2.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.udfverify.ClassWithInnerClass.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.udfverify.ClassWithInitializer3.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.udfverify.ClassWithInitializer2.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.udfverify.ClassWithInitializer.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.udfverify.ClassWithField.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.udfverify.CallOrgApache.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.udfverify.CallFinalize.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.udfverify.CallComDatastax.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.udfverify.CallClone.java</file>
      <file type="M">src.resources.org.apache.cassandra.cql3.functions.JavaSourceUDF.txt</file>
      <file type="M">src.java.org.apache.cassandra.cql3.functions.UDFunction.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.functions.UDFByteCodeVerifier.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.functions.UDAggregate.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.functions.ScriptBasedUDFunction.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.functions.JavaUDF.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.functions.JavaBasedUDFunction.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9876" opendate="2015-7-23 00:00:00" fixdate="2015-8-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>One way targeted repair</summary>
      <description>Many applications use C* by writing to one local DC. The other DC is used when the local DC is unavailable. When the local DC becomes available, we want to run a targeted repair b/w one endpoint from each DC to minimize the data transfer over WAN. In this case, it will be helpful to do a one way repair in which data will only be streamed from other DC to local DC instead of streaming the data both ways. This will further minimize the traffic over WAN. This feature should only be supported if a targeted repair is run involving 2 hosts.</description>
      <version>3.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.repair.RepairSessionTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.repair.messages.RepairOptionTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.repair.LocalSyncTaskTest.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.nodetool.Repair.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.ActiveRepairService.java</file>
      <file type="M">src.java.org.apache.cassandra.repair.RepairSession.java</file>
      <file type="M">src.java.org.apache.cassandra.repair.RepairRunnable.java</file>
      <file type="M">src.java.org.apache.cassandra.repair.RepairJob.java</file>
      <file type="M">src.java.org.apache.cassandra.repair.messages.RepairOption.java</file>
      <file type="M">src.java.org.apache.cassandra.repair.LocalSyncTask.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>
