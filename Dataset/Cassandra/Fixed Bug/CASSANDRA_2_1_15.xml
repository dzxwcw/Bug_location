<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="CASSANDRA">
  <bug id="10532" opendate="2015-10-15 00:00:00" fixdate="2015-6-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow LWT operation on static column with only partition keys</summary>
      <description>SchemaCREATE TABLE IF NOT EXISTS achilles_embedded.entity_with_static_column(id bigint,uuid uuid,static_col text static,value text,PRIMARY KEY(id, uuid));When trying to prepare the following queryDELETE static_col FROM achilles_embedded.entity_with_static_column WHERE id=:id_Eq IF static_col=:static_col;I got the error DELETE statements must restrict all PRIMARY KEY columns with equality relations in order to use IF conditions, but column 'uuid' is not restrictedSince the mutation only impacts the static column and the CAS check is on the static column, it makes sense to provide only partition key</description>
      <version>2.1.15,2.2.7,3.0.8,3.8</version>
      <fixedVersion>Feature/LightweightTransactions,Legacy/CQL</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.InsertUpdateIfConditionTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.ModificationStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.DeleteStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10828" opendate="2015-12-8 00:00:00" fixdate="2015-5-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow usage of multiplier in the start value of cassandra-stress population sequence</summary>
      <description>Sometimes it would be useful to also use the multipliers M/B/K in the start value of a population sequence, such as in the below example:cassandra-stress write n=100 -pop seq=1M..10M</description>
      <version>2.1.15,2.2.7,3.0.7,3.7</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.SettingsPopulation.java</file>
    </fixedFiles>
  </bug>
  <bug id="10853" opendate="2015-12-12 00:00:00" fixdate="2015-4-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>deb package migration to dh_python2</summary>
      <description>I'm working on a deb job in jenkins, and I had forgotten to open a bug for this. There is no urgent need, since python-support is in Jessie, but this package is currently in transition to be removed.http://deb.li/dhs2pDuring deb build:dh_pysupport: This program is deprecated, you should use dh_python2 instead. Migration guide: http://deb.li/dhs2p</description>
      <version>2.1.15,2.2.7,3.0.6,3.6</version>
      <fixedVersion>Packaging</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">debian.rules</file>
      <file type="M">src.java.org.apache.cassandra.utils.Interval.java</file>
      <file type="M">debian.control</file>
    </fixedFiles>
  </bug>
  <bug id="11152" opendate="2016-2-10 00:00:00" fixdate="2016-6-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>SOURCE command in CQLSH 3.2 requires that "use keyspace" is in the cql file that you are sourcing</summary>
      <description>a difference in behaviour between SOURCE command in CQLSH 3.1 and 3.2. In CQLSH 3.1 SOURCE will NOT require "use keyspace" in the cql file that you execute: the "keyspace" directive in the qlshrc file will work and the cql file will be executed.In CQLSH 3.2.1, SOURCE command requires that "use keyspace" is in the cql file that you are sourcing, otherwise it throws this error:"No keyspace has been specified. USE a keyspace, or explicitly specify keyspace.tablename". The "keyspace" directive in cqlshrc is overridden by source command.steps to reproduce:create a file called select.cql in your home directory:echo "CONSISTENCY ONE;" &gt; select.cqlecho "select * from tab;" &gt;&gt; select.cqlin cqlsh:create KEYSPACE kspace WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1};create TABLE tab ( id int primary key);insert into tab (id) VALUES ( 1);Add this to cqlsgrc:[authentication]keyspace = kspaceThen exit cqlsh and rerun cqlsh using the cqlshrc just modified.Note that you are in keyspace "kspace".execute:source 'select.cql' this will have different behaviour in CQLSH 3.2 and 3.1</description>
      <version>2.1.15,2.2.7,3.0.7,3.7</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug id="11549" opendate="2016-4-12 00:00:00" fixdate="2016-4-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh: COPY FROM ignores NULL values in conversion</summary>
      <description>COPY FROM fails to import empty values. For example:$ cat test.csva,10,20b,30,c,50,60$ cqlshcqlsh&gt; create keyspace if not exists test with replication = {'class': 'SimpleStrategy', 'replication_factor':1};cqlsh&gt; create table if not exists test.test (t text primary key, i1 int, i2 int);cqlsh&gt; copy test.test (t,i1,i2) from 'test.csv';Imports:select * from test.test"; t | i1 | i2---+----+---- a | 10 | 20 c | 50 | 60(2 rows)and generates a ParseError - invalid literal for int() with base 10: '', given up without retries for the row with an empty value.It should import the empty value as a null and there should be no error:cqlsh&gt; select * from test.test"; t | i1 | i2---+----+------ a | 10 | 20 c | 50 | 60 b | 30 | null(3 rows)</description>
      <version>2.1.15,2.2.7,3.0.6,3.6</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.copyutil.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11574" opendate="2016-4-14 00:00:00" fixdate="2016-4-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>clqsh: COPY FROM throws TypeError with Cython extensions enabled</summary>
      <description>Any COPY FROM command in cqlsh is throwing the following error:"get_num_processes() takes no keyword arguments"Example command: COPY inboxdata (to_user_id,to_user_network,created_time,attachments,from_user_id,from_user_name,from_user_network,id,message,to_user_name,updated_time) FROM 'inbox.csv';Similar commands worked parfectly in the previous versions such as 3.0.4</description>
      <version>2.1.15,2.2.7,3.0.6,3.6</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.copyutil.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11631" opendate="2016-4-22 00:00:00" fixdate="2016-4-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh COPY FROM fails for null values with non-prepared statements</summary>
      <description>cqlsh's COPY FROM ... WITH PREPAREDSTATEMENTS = False fails if the row contains null values. Reason is that the ','.join(r) in make_non_prepared_batch_statement doesn't seem to handle None, which results in this error message.Failed to import 1 rows: TypeError - sequence item 2: expected string, NoneType found, given up without retriesAttached patch should fix the problem.</description>
      <version>2.1.15,2.2.7,3.0.6,3.6</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.copyutil.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11661" opendate="2016-4-26 00:00:00" fixdate="2016-5-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cassandra 2.0 and later require Java 7u25 or later - jdk 101</summary>
      <description>We have been running the cassandr server version 2.1.5. Friday, we applied the latest java patch, Java(TM) SE Runtime Environment (build 1.7.0_101-b14). Cassandra cannot start with this patch. The cassandra log states: Cassandra 2.0 and later require Java 7u25 or later.</description>
      <version>2.1.15,2.2.7,3.0.7,3.7</version>
      <fixedVersion>Legacy/Testing</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.cassandra-env.sh</file>
    </fixedFiles>
  </bug>
  <bug id="11679" opendate="2016-4-28 00:00:00" fixdate="2016-5-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cassandra Driver returns different number of results depending on fetchsize</summary>
      <description>I'm trying to fetch all distinct keys from a CF using cassandra-driver (2.1.7.1) and I observed some strange behavior :-The total distinct rows are 498 so If I perform a query get All distinctKeys It returns 503 instead of 498(five keys twice).But If I define the fetch size in select statement more than 498 then it returns exact 498 rows. And If I execute same statement on Dev-center it returns 498 rows (because the default fetch size is 5000). In `cqlsh` it returns 503 rows (because cqlsh uses fetch size=100).Some Additional and useful information :- -------------------------------------------------------Cassandra-2.1.13 (C)* versionConsistency level: ONE local machine(ubuntu 14.04)Table Schema:-----------------------CREATE TABLE sample ( pk1 text, pk2 text, row_id uuid, value blob, PRIMARY KEY (( pk1, pk2))) WITH bloom_filter_fp_chance = 0.01 AND caching = '{"keys":"ALL", "rows_per_partition":"NONE"}' AND comment = '' AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy'} AND compression = {'sstable_compression': 'org.apache.cassandra.io.compress.LZ4Compressor'} AND dclocal_read_repair_chance = 0.1 AND default_time_to_live = 0 AND gc_grace_seconds = 864000 AND max_index_interval = 2048 AND memtable_flush_period_in_ms = 0 AND min_index_interval = 128 AND read_repair_chance = 0.0 AND speculative_retry = '99.0PERCENTILE';query :-------------SELECT DISTINCT pk2, pk1 FROM sample LIMIT 2147483647;</description>
      <version>2.1.15</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.pager.RangeSliceQueryPager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11696" opendate="2016-5-2 00:00:00" fixdate="2016-6-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Incremental repairs can mark too many ranges as repaired</summary>
      <description>Incremental repairs are tracked using a parent session - a subordinate repair session is created for each range in the repair. When a node participating in the repair receives a validation request, it will reference the sstables in the parent repair session. When all subordinate sessions conclude, each node anticompacts SSTables based on the parent repair session for the whole range of the repair, but these referenced SSTables may have only been present for the validation of some subset of the ranges because the SSTables were created concurrent with the parent repair session.</description>
      <version>2.1.15,2.2.7,3.0.8,3.8</version>
      <fixedVersion>Legacy/StreamingandMessaging</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.service.ActiveRepairServiceTest.java</file>
      <file type="M">src.java.org.apache.cassandra.service.ActiveRepairService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11739" opendate="2016-5-9 00:00:00" fixdate="2016-5-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cache key references might cause OOM on incremental repair</summary>
      <description>We keep SSTableReader references for the duration of the repair to anti-compact later, and their tidier keep references to cache keys to be invalidated which are only cleaned up by GC after repair is finished. These cache keys can accumulate while repair is being executed leading to OOM for large tables/keyspaces.Heap dump attached.</description>
      <version>2.1.15,2.2.7,3.0.7,3.7</version>
      <fixedVersion>Legacy/StreamingandMessaging</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.ActiveRepairService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11749" opendate="2016-5-11 00:00:00" fixdate="2016-6-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CQLSH gets SSL exception following a COPY FROM</summary>
      <description>When running Cassandra and cqlsh with SSL, the following command occasionally results in the exception below:cqlsh --ssl -f kv.cqlERROR [SharedPool-Worker-2] 2016-05-11 12:41:03,583 Message.java:538 - Unexpected exception during request; channel = [id: 0xeb75e05d, /127.0.0.1:51083 =&gt; /127.0.0.1:9042]io.netty.handler.codec.DecoderException: javax.net.ssl.SSLException: bad record MAC at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:280) ~[netty-all-4.0.23.Final.jar:4.0.23.Final] at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:149) ~[netty-all-4.0.23.Final.jar:4.0.23.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:333) ~[netty-all-4.0.23.Final.jar:4.0.23.Final] at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:319) ~[netty-all-4.0.23.Final.jar:4.0.23.Final] at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:787) ~[netty-all-4.0.23.Final.jar:4.0.23.Final] at io.netty.channel.epoll.EpollSocketChannel$EpollSocketUnsafe.epollInReady(EpollSocketChannel.java:722) ~[netty-all-4.0.23.Final.jar:4.0.23.Final] at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:326) ~[netty-all-4.0.23.Final.jar:4.0.23.Final] at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:264) ~[netty-all-4.0.23.Final.jar:4.0.23.Final] at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116) ~[netty-all-4.0.23.Final.jar:4.0.23.Final] at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137) ~[netty-all-4.0.23.Final.jar:4.0.23.Final] at java.lang.Thread.run(Thread.java:745) [na:1.8.0_91]Caused by: javax.net.ssl.SSLException: bad record MAC at sun.security.ssl.Alerts.getSSLException(Alerts.java:208) ~[na:1.8.0_91] at sun.security.ssl.SSLEngineImpl.fatal(SSLEngineImpl.java:1728) ~[na:1.8.0_91] at sun.security.ssl.SSLEngineImpl.readRecord(SSLEngineImpl.java:981) ~[na:1.8.0_91] at sun.security.ssl.SSLEngineImpl.readNetRecord(SSLEngineImpl.java:907) ~[na:1.8.0_91] at sun.security.ssl.SSLEngineImpl.unwrap(SSLEngineImpl.java:781) ~[na:1.8.0_91] at javax.net.ssl.SSLEngine.unwrap(SSLEngine.java:624) ~[na:1.8.0_91] at io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:982) ~[netty-all-4.0.23.Final.jar:4.0.23.Final] at io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:908) ~[netty-all-4.0.23.Final.jar:4.0.23.Final] at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:854) ~[netty-all-4.0.23.Final.jar:4.0.23.Final] at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:249) ~[netty-all-4.0.23.Final.jar:4.0.23.Final] ... 10 common frames omittedCaused by: javax.crypto.BadPaddingException: bad record MAC at sun.security.ssl.InputRecord.decrypt(InputRecord.java:219) ~[na:1.8.0_91] at sun.security.ssl.EngineInputRecord.decrypt(EngineInputRecord.java:177) ~[na:1.8.0_91] at sun.security.ssl.SSLEngineImpl.readRecord(SSLEngineImpl.java:974) ~[na:1.8.0_91] ... 17 common frames omittedwherecat kv.cql create keyspace if not exists cvs_copy_ks with replication = {'class': 'SimpleStrategy', 'replication_factor':1};create table if not exists cvs_copy_ks.kv (key int primary key, value text);truncate cvs_copy_ks.kv;copy cvs_copy_ks.kv (key, value) from 'kv.csv' with header='true';select * from cvs_copy_ks.kv;drop keyspace cvs_copy_ks;stefi@cuoricina:~/git/cstar/cassandra$ cat kv.ckv.cql kv.csv cat kv.csv key,value1,'a'2,'b'3,'c'The COPY FROM succeeds, however the following select does not. The easiest way to reproduce this is to restart the Cassandra process, it seems to happen in preference after a restart.</description>
      <version>2.1.15,2.2.7,3.0.8,3.8</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.copyutil.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11755" opendate="2016-5-11 00:00:00" fixdate="2016-6-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>nodetool info should run with "readonly" jmx access</summary>
      <description>nodetool info crash when granted with readonly jmx accessIn the example given in attachment, the jmxremote.access file gives readonly access to the cassandra jmx role.When the role is granted to readwrite access, everything works.The main reason is that node datacenter and rack info are fetched by an operation invocation instead of by an attribute read. The former one is not allowed to the role with readonly access.This is a security concern because nodetool info could be called by a monitoring agent (Nagios for instance) and enterprise policy often don't allow these agents to connect to JMX with higher privileges than "readonly".</description>
      <version>2.1.15,3.0.8,3.8</version>
      <fixedVersion>Legacy/Observability</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeProbe.java</file>
      <file type="M">src.java.org.apache.cassandra.locator.EndpointSnitchInfoMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.locator.EndpointSnitchInfo.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11834" opendate="2016-5-18 00:00:00" fixdate="2016-5-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Don&amp;#39;t compute expensive MaxPurgeableTimestamp until we&amp;#39;ve verified there&amp;#39;s an expired tombstone</summary>
      <description>In LCR's get reduced, we currently do this: if (t.timestamp() &lt; getMaxPurgeableTimestamp() &amp;&amp; t.data.isGcAble(controller.gcBefore))Should call the expensive getMaxPurgeableTimestamp only after we have called the cheap isGcAble.Marking this as a bug since it can cause pathological performance problems (CASSANDRA-11831).Have verified that this is not a problem in 3.0 (CompactionIterator does the check in the correct order).</description>
      <version>2.1.15,2.2.7</version>
      <fixedVersion>Local/Compaction</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LazilyCompactedRow.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11840" opendate="2016-5-18 00:00:00" fixdate="2016-5-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Set a more conservative default to streaming_socket_timeout_in_ms</summary>
      <description></description>
      <version>2.1.15,2.2.7,3.0.7,3.7</version>
      <fixedVersion>Legacy/StreamingandMessaging</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamSession.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11855" opendate="2016-5-20 00:00:00" fixdate="2016-5-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>MessagingService#getCommandDroppedTasks should be displayed in netstats</summary>
      <description>MessagingService#getCommandDroppedTasks should be displayed in netstats along with the pending and completed.</description>
      <version>2.1.15,2.2.7,3.0.7,3.7</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeTool.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11991" opendate="2016-6-10 00:00:00" fixdate="2016-6-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>On clock skew, paxos may "corrupt" the node clock</summary>
      <description>W made a mistake in CASSANDRA-9649 so that a temporal clock skew on one node can "corrupt" other node clocks through Paxos. That wasn't intended and we should fix that. I'll attach a patch later.</description>
      <version>2.1.15,2.2.7,3.0.8,3.8</version>
      <fixedVersion>Feature/LightweightTransactions</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.utils.UUIDGen.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.service.ClientState.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12077" opendate="2016-6-23 00:00:00" fixdate="2016-6-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>NPE when trying to get sstables for anticompaction</summary>
      <description>This was introduced in CASSANDRA-11739 - we need to avoid trying to get sstables for tables we are not repairing</description>
      <version>2.1.15,2.2.7,3.0.8,3.8</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.ActiveRepairService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9842" opendate="2015-7-18 00:00:00" fixdate="2015-6-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Inconsistent behavior for &amp;#39;= null&amp;#39; conditions on static columns</summary>
      <description>Both inserting a row (in a non-existent partition) and updating a static column in the same LWT fails. Creating the partition before performing the LWT works.Table Definitioncreate table txtable(pcol bigint, ccol bigint, scol bigint static, ncol text, primary key((pcol), ccol));Inserting row in non-existent partition and updating static column in one LWTbegin batch insert into txtable (pcol, ccol, ncol) values (1, 1, 'A'); update txtable set scol = 1 where pcol = 1 if scol = null;apply batch;[applied]----------- FalseCreating partition before LWTinsert into txtable (pcol, scol) values (1, null) if not exists;begin batch insert into txtable (pcol, ccol, ncol) values (1, 1, 'A'); update txtable set scol = 1 where pcol = 1 if scol = null;apply batch;[applied]----------- True</description>
      <version>2.1.15,2.2.7,3.0.8,3.8</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.InsertUpdateIfConditionTest.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.ModificationStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9935" opendate="2015-7-30 00:00:00" fixdate="2015-4-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Repair fails with RuntimeException</summary>
      <description>We had problems with slow repair in 2.1.7 (CASSANDRA-9702) but after upgrade to 2.1.8 it started to work faster but now it fails with:...[2015-07-29 20:44:03,956] Repair session 23a811b0-3632-11e5-a93e-4963524a8bde for range (-5474076923322749342,-5468600594078911162] finished[2015-07-29 20:44:03,957] Repair session 336f8740-3632-11e5-a93e-4963524a8bde for range (-8631877858109464676,-8624040066373718932] finished[2015-07-29 20:44:03,957] Repair session 4ccd8430-3632-11e5-a93e-4963524a8bde for range (-5372806541854279315,-5369354119480076785] finished[2015-07-29 20:44:03,957] Repair session 59f129f0-3632-11e5-a93e-4963524a8bde for range (8166489034383821955,8168408930184216281] finished[2015-07-29 20:44:03,957] Repair session 6ae7a9a0-3632-11e5-a93e-4963524a8bde for range (6084602890817326921,6088328703025510057] finished[2015-07-29 20:44:03,957] Repair session 8938e4a0-3632-11e5-a93e-4963524a8bde for range (-781874602493000830,-781745173070807746] finished[2015-07-29 20:44:03,957] Repair command #4 finishederror: nodetool failed, check server logs-- StackTrace --java.lang.RuntimeException: nodetool failed, check server logs at org.apache.cassandra.tools.NodeTool$NodeToolCmd.run(NodeTool.java:290) at org.apache.cassandra.tools.NodeTool.main(NodeTool.java:202)After running:nodetool repair --partitioner-range --parallel --in-local-dc syncLast records in logs regarding repair are:INFO [Thread-173887] 2015-07-29 20:44:03,956 StorageService.java:2952 - Repair session 09ff9e40-3632-11e5-a93e-4963524a8bde for range (-7695808664784761779,-7693529816291585568] finishedINFO [Thread-173887] 2015-07-29 20:44:03,956 StorageService.java:2952 - Repair session 17d8d860-3632-11e5-a93e-4963524a8bde for range (8063716953988492222,8065203836608925992] finishedINFO [Thread-173887] 2015-07-29 20:44:03,956 StorageService.java:2952 - Repair session 23a811b0-3632-11e5-a93e-4963524a8bde for range (-5474076923322749342,-5468600594078911162] finishedINFO [Thread-173887] 2015-07-29 20:44:03,956 StorageService.java:2952 - Repair session 336f8740-3632-11e5-a93e-4963524a8bde for range (-8631877858109464676,-8624040066373718932] finishedINFO [Thread-173887] 2015-07-29 20:44:03,957 StorageService.java:2952 - Repair session 4ccd8430-3632-11e5-a93e-4963524a8bde for range (-5372806541854279315,-5369354119480076785] finishedINFO [Thread-173887] 2015-07-29 20:44:03,957 StorageService.java:2952 - Repair session 59f129f0-3632-11e5-a93e-4963524a8bde for range (8166489034383821955,8168408930184216281] finishedINFO [Thread-173887] 2015-07-29 20:44:03,957 StorageService.java:2952 - Repair session 6ae7a9a0-3632-11e5-a93e-4963524a8bde for range (6084602890817326921,6088328703025510057] finishedINFO [Thread-173887] 2015-07-29 20:44:03,957 StorageService.java:2952 - Repair session 8938e4a0-3632-11e5-a93e-4963524a8bde for range (-781874602493000830,-781745173070807746] finishedbut a bit above I see (at least two times in attached log):ERROR [Thread-173887] 2015-07-29 20:44:03,853 StorageService.java:2959 - Repair session 1b07ea50-3608-11e5-a93e-4963524a8bde for range (5765414319217852786,5781018794516851576] failed with error org.apache.cassandra.exceptions.RepairException: [repair #1b07ea50-3608-11e5-a93e-4963524a8bde on sync/entity_by_id2, (5765414319217852786,5781018794516851576]] Validation failed in /10.195.15.162java.util.concurrent.ExecutionException: java.lang.RuntimeException: org.apache.cassandra.exceptions.RepairException: [repair #1b07ea50-3608-11e5-a93e-4963524a8bde on sync/entity_by_id2, (5765414319217852786,5781018794516851576]] Validation failed in /10.195.15.162 at java.util.concurrent.FutureTask.report(FutureTask.java:122) [na:1.7.0_80] at java.util.concurrent.FutureTask.get(FutureTask.java:188) [na:1.7.0_80] at org.apache.cassandra.service.StorageService$4.runMayThrow(StorageService.java:2950) ~[apache-cassandra-2.1.8.jar:2.1.8] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) [apache-cassandra-2.1.8.jar:2.1.8] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_80] at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_80] at java.lang.Thread.run(Thread.java:745) [na:1.7.0_80]Caused by: java.lang.RuntimeException: org.apache.cassandra.exceptions.RepairException: [repair #1b07ea50-3608-11e5-a93e-4963524a8bde on sync/entity_by_id2, (5765414319217852786,5781018794516851576]] Validation failed in /10.195.15.162 at com.google.common.base.Throwables.propagate(Throwables.java:160) ~[guava-16.0.jar:na] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:32) [apache-cassandra-2.1.8.jar:2.1.8] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_80] at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) ~[na:1.7.0_80] ... 1 common frames omittedCaused by: org.apache.cassandra.exceptions.RepairException: [repair #1b07ea50-3608-11e5-a93e-4963524a8bde on sync/entity_by_id2, (5765414319217852786,5781018794516851576]] Validation failed in /10.195.15.162 at org.apache.cassandra.repair.RepairSession.validationComplete(RepairSession.java:166) ~[apache-cassandra-2.1.8.jar:2.1.8] at org.apache.cassandra.service.ActiveRepairService.handleMessage(ActiveRepairService.java:406) ~[apache-cassandra-2.1.8.jar:2.1.8] at org.apache.cassandra.repair.RepairMessageVerbHandler.doVerb(RepairMessageVerbHandler.java:134) ~[apache-cassandra-2.1.8.jar:2.1.8] at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:62) ~[apache-cassandra-2.1.8.jar:2.1.8] ... 3 common frames omittedINFO [Thread-173887] 2015-07-29 20:44:03,854 StorageService.java:2952 - Repair session 846d9300-3608-11e5-a93e-4963524a8bde for range (-6705935742755245856,-6704072966568763453] finished</description>
      <version>2.1.15,2.2.7,3.0.6,3.6</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.long.org.apache.cassandra.db.compaction.LongLeveledCompactionStrategyTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LeveledManifest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LeveledCompactionStrategy.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>
