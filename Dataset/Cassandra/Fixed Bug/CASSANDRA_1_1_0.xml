<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="CASSANDRA">
  <bug id="1740" opendate="2010-11-13 00:00:00" fixdate="2010-11-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Nodetool commands to query and stop compaction, repair, cleanup and scrub</summary>
      <description>The only way to stop compaction, repair, cleanup, or scrub in progress is to stop and restart the entire Cassandra server. Please provide nodetool commands to query whether such things are running, and stop them if they are.</description>
      <version>1.1.0</version>
      <fixedVersion>Tool/nodetool</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.utils.WrappedRunnable.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeProbe.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.SecondaryIndexBuilder.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionTask.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManagerMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionInfo.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.AbstractCompactionIterable.java</file>
      <file type="M">src.java.org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.AutoSavingCache.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1805" opendate="2010-12-2 00:00:00" fixdate="2010-1-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>refactor and remove contrib/</summary>
      <description>Contrib is a mix of examples, tools, and miscellanea that probably doesn't belong in our source tree.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowMutationVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowMutation.java</file>
      <file type="M">contrib.maven.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="2407" opendate="2011-3-31 00:00:00" fixdate="2011-11-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compaction thread should try to empty a bucket before moving on</summary>
      <description>As suggested by Aaron Morton (1), a compaction thread should attempt to empty a bucket before moving on to a larger bucket. This would change the submitMinorIfNeeded for loop into a while loop that regenerated the buckets and started from the bottom after each successful compaction.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.compaction.CompactionsTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.DataTracker.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LeveledCompactionStrategy.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.AbstractCompactionStrategy.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2475" opendate="2011-4-14 00:00:00" fixdate="2011-2-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Prepared statements</summary>
      <description></description>
      <version>1.1.0</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.Constants.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.Cassandra.java</file>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraServer.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.WhereClause.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.UpdateStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.SelectStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.SelectExpression.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.DeleteStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.CreateColumnFamilyStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.BatchStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.AbstractModification.java</file>
      <file type="M">interface.cassandra.thrift</file>
      <file type="M">src.java.org.apache.cassandra.cql.CQLStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.Cql.g</file>
      <file type="M">src.java.org.apache.cassandra.cql.Term.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.QueryProcessor.java</file>
      <file type="M">src.java.org.apache.cassandra.service.ClientState.java</file>
    </fixedFiles>
  </bug>
  <bug id="2477" opendate="2011-4-14 00:00:00" fixdate="2011-5-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CQL support for describing keyspaces / column familes</summary>
      <description></description>
      <version>1.1.0</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.service.StorageServiceServerTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.service.AntiEntropyServiceTestAbstract.java</file>
      <file type="M">test.unit.org.apache.cassandra.dht.BootStrapperTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.CleanupTest.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.LoadBroadcaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="2503" opendate="2011-4-19 00:00:00" fixdate="2011-11-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Eagerly re-write data at read time ("superseding / defragmenting")</summary>
      <description>Oncdsed. This basic approach would improve read performance considerably, but would cause a lot of duplicate data to be written, and would make compaction's work more necessary.Augmenting the basic idea, if when we superseded data in a file we marked it as superseded somehow, the next compaction that touched that file could remove the data. Since our file format is immutable, the values that a particular sstable superseded could be recorded in a component of that sstable. If we always supersede at the "block" level (as defined by CASSANDRA-674 or CASSANDRA-47), then the list of superseded blocks could be represented using a generation number and a bitmap of block numbers. Since 2498 would already allow for sstables to be eliminated due to timestamps, this information would probably only be used at compaction time (by loading all superseding information in the system for the sstables that are being compacted).Initially described on 1608.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">doc.cql.CQL.textile</file>
      <file type="M">src.java.org.apache.cassandra.db.Table.java</file>
      <file type="M">src.java.org.apache.cassandra.db.CollationController.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2749" opendate="2011-6-8 00:00:00" fixdate="2011-1-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>fine-grained control over data directories</summary>
      <description>Currently Cassandra supports multiple data directories but no way to control what sstables are placed where. Particularly for systems with mixed SSDs and rotational disks, it would be nice to pin frequently accessed columnfamilies to the SSDs.Postgresql does this with tablespaces (http://www.postgresql.org/docs/9.0/static/manage-ag-tablespaces.html) but we should probably avoid using that name because of confusing similarity to "keyspaces."</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.streaming.BootstrapTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.Util.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.CreateColumnFamilyStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.CreateKeyspaceStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionTask.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LeveledManifest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy.java</file>
      <file type="M">src.java.org.apache.cassandra.db.DataTracker.java</file>
      <file type="M">src.java.org.apache.cassandra.db.DefsTable.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Table.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.Descriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.service.AbstractCassandraDaemon.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageServiceMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.thrift.ThriftValidation.java</file>
      <file type="M">test.data.corrupt-sstables.Super5-f-2-Data.db</file>
      <file type="M">test.data.corrupt-sstables.Super5-f-2-Filter.db</file>
      <file type="M">test.data.corrupt-sstables.Super5-f-2-Index.db</file>
      <file type="M">test.data.corrupt-sstables.Super5-f-2-Statistics.db</file>
      <file type="M">test.data.legacy-sstables.b.Keyspace1.Standard1-b-0-Data.db</file>
      <file type="M">test.data.legacy-sstables.b.Keyspace1.Standard1-b-0-Filter.db</file>
      <file type="M">test.data.legacy-sstables.b.Keyspace1.Standard1-b-0-Index.db</file>
      <file type="M">test.data.legacy-sstables.e.Keyspace1.Standard1-e-0-Data.db</file>
      <file type="M">test.data.legacy-sstables.e.Keyspace1.Standard1-e-0-Filter.db</file>
      <file type="M">test.data.legacy-sstables.e.Keyspace1.Standard1-e-0-Index.db</file>
      <file type="M">test.data.legacy-sstables.e.Keyspace1.Standard1-e-0-Statistics.db</file>
      <file type="M">test.data.legacy-sstables.hb.Keyspace1.Indexed1-hb-1-Data.db</file>
      <file type="M">test.data.legacy-sstables.hb.Keyspace1.Indexed1-hb-1-Digest.sha1</file>
      <file type="M">test.data.legacy-sstables.hb.Keyspace1.Indexed1-hb-1-Filter.db</file>
      <file type="M">test.data.legacy-sstables.hb.Keyspace1.Indexed1-hb-1-Index.db</file>
      <file type="M">test.data.legacy-sstables.hb.Keyspace1.Indexed1-hb-1-Statistics.db</file>
      <file type="M">test.data.legacy-sstables.hb.Keyspace1.Indexed1.626972746864617465-hb-1-Data.db</file>
      <file type="M">test.data.legacy-sstables.hb.Keyspace1.Indexed1.626972746864617465-hb-1-Digest.sha1</file>
      <file type="M">test.data.legacy-sstables.hb.Keyspace1.Indexed1.626972746864617465-hb-1-Filter.db</file>
      <file type="M">test.data.legacy-sstables.hb.Keyspace1.Indexed1.626972746864617465-hb-1-Index.db</file>
      <file type="M">test.data.legacy-sstables.hb.Keyspace1.Indexed1.626972746864617465-hb-1-Statistics.db</file>
      <file type="M">test.data.legacy-sstables.hb.Keyspace1.Standard1-hb-0-Data.db</file>
      <file type="M">test.data.legacy-sstables.hb.Keyspace1.Standard1-hb-0-Digest.sha1</file>
      <file type="M">test.data.legacy-sstables.hb.Keyspace1.Standard1-hb-0-Filter.db</file>
      <file type="M">test.data.legacy-sstables.hb.Keyspace1.Standard1-hb-0-Index.db</file>
      <file type="M">test.data.legacy-sstables.hb.Keyspace1.Standard1-hb-0-Statistics.db</file>
      <file type="M">test.unit.org.apache.cassandra.db.ColumnFamilyStoreTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.DefsTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.ScrubTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.io.sstable.DescriptorTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.io.sstable.SSTableReaderTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.io.sstable.SSTableSimpleWriterTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="2851" opendate="2011-7-3 00:00:00" fixdate="2011-2-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hex-to-bytes conversion accepts invalid inputs silently</summary>
      <description>FBUtilities.hexToBytes() has a minor bug - it copes with single-character inputs by prepending "0", which is OK - but it does this for any input with an odd number of characters, which is probably incorrect.if (str.length() % 2 == 1) str = "0" + str;Given 'fff' as an input, can we really assume that this should be '0fff'? Isn't this just an error?Add the following to FBUtilitiesTest to demonstrate:String[] badvalues = new String[]{"000", "fff"}; for (int i = 0; i &lt; badvalues.length; i++) try { FBUtilities.hexToBytes(badvalues[i]); fail("Invalid hex value accepted"+badvalues[i]); } catch (Exception e){}</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.utils.HexTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cli.CliTest.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.Hex.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.AbstractByteOrderedPartitioner.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2878" opendate="2011-7-10 00:00:00" fixdate="2011-1-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow map/reduce to use server-side query filters</summary>
      <description>Currently, when running a MapReduce job against data in a Cassandra data store, it reads through all the data for a particular ColumnFamily. This could be optimized to only read through those rows that have to do with the query.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">examples.hadoop.word.count.src.WordCountSetup.java</file>
      <file type="M">examples.hadoop.word.count.src.WordCount.java</file>
      <file type="M">src.java.org.apache.cassandra.thrift.ThriftValidation.java</file>
      <file type="M">src.java.org.apache.cassandra.hadoop.ConfigHelper.java</file>
      <file type="M">src.java.org.apache.cassandra.hadoop.ColumnFamilyRecordReader.java</file>
      <file type="M">src.java.org.apache.cassandra.hadoop.ColumnFamilyInputFormat.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2917" opendate="2011-7-18 00:00:00" fixdate="2011-2-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>expose calculate midrange for token in jmx</summary>
      <description>currently there is no easy way to get midrange, especially for OPP. For simplicity, you could call OrderPreservingPartitioner.midpoint(Token, Token), that gives you a rough estimate (and you'd still need to remove non-utf8 characters.)A more accurate but difficult way is to sample the keys in that range and pick the midpoint of those. We should expose that via jmx, because without this, supporting OPP w/o this is quite challenging.</description>
      <version>1.1.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeProbe.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageServiceMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3045" opendate="2011-8-17 00:00:00" fixdate="2011-11-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update ColumnFamilyOutputFormat to use new bulkload API</summary>
      <description>The bulk loading interface added in CASSANDRA-1278 is a great fit for Hadoop jobs.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.BulkLoader.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamReplyVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamInSession.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.IncomingStreamReader.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.FileStreamTask.java</file>
      <file type="M">src.java.org.apache.cassandra.net.OutboundTcpConnection.java</file>
      <file type="M">src.java.org.apache.cassandra.net.Message.java</file>
      <file type="M">src.java.org.apache.cassandra.net.Header.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableLoader.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3116" opendate="2011-9-1 00:00:00" fixdate="2011-10-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compactions can (seriously) delay schema migrations</summary>
      <description>A compaction lock is acquired when dropping keyspaces or column families which will cause the schema migration to block if a compaction is in progress.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.streaming.StreamingTransferTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.KeyCacheTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.compaction.CompactionsTest.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableReader.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Table.java</file>
      <file type="M">src.java.org.apache.cassandra.db.migration.DropKeyspace.java</file>
      <file type="M">src.java.org.apache.cassandra.db.migration.DropColumnFamily.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Memtable.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.SecondaryIndexManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.SecondaryIndex.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.keys.KeysIndex.java</file>
      <file type="M">src.java.org.apache.cassandra.db.DataTracker.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3143" opendate="2011-9-6 00:00:00" fixdate="2011-12-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Global caches (key/row)</summary>
      <description>Caches are difficult to configure well as ColumnFamilies are added, similar to how memtables were difficult pre-CASSANDRA-2006.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.SchemaLoader.java</file>
      <file type="M">test.unit.org.apache.cassandra.io.sstable.SSTableReaderTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.RowCacheTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.KeyCacheTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.DefsTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.CleanupHelper.java</file>
      <file type="M">test.unit.org.apache.cassandra.cache.CacheProviderTest.java</file>
      <file type="M">src.resources.org.apache.cassandra.cli.CliHelp.yaml</file>
      <file type="M">src.java.org.apache.cassandra.utils.StatusLogger.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeProbe.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageServiceMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.GCInspector.java</file>
      <file type="M">src.java.org.apache.cassandra.service.AbstractCassandraDaemon.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableReader.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Table.java</file>
      <file type="M">src.java.org.apache.cassandra.db.DecoratedKey.java</file>
      <file type="M">src.java.org.apache.cassandra.db.DataTracker.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStoreMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.CreateColumnFamilyStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">src.java.org.apache.cassandra.cli.CliClient.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.SerializingCacheProvider.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.SerializingCache.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.IRowCacheProvider.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.InstrumentingCacheMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.InstrumentingCache.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.ICache.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.ConcurrentLinkedHashCacheProvider.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.ConcurrentLinkedHashCache.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.AutoSavingRowCache.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.AutoSavingKeyCache.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.AutoSavingCache.java</file>
      <file type="M">src.avro.internode.genavro</file>
      <file type="M">NEWS.txt</file>
      <file type="M">interface.cassandra.thrift</file>
      <file type="M">doc.cql.CQL.textile</file>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3213" opendate="2011-9-15 00:00:00" fixdate="2011-1-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade Thrift</summary>
      <description></description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">lib.licenses.libthrift-0.5.txt</file>
      <file type="M">lib.libthrift-0.6.jar</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.UnavailableException.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.TokenRange.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.TimedOutException.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.SuperColumn.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.SliceRange.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.SlicePredicate.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.SchemaDisagreementException.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.NotFoundException.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.Mutation.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.KsDef.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.KeySlice.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.KeyRange.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.KeyCount.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.InvalidRequestException.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.IndexType.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.IndexOperator.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.IndexExpression.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.IndexClause.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.EndpointDetails.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.Deletion.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.CqlRow.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.CqlResultType.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.CqlResult.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.CqlPreparedResult.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.CqlMetadata.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.CounterSuperColumn.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.CounterColumn.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.Constants.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.ConsistencyLevel.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.Compression.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.ColumnPath.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.ColumnParent.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.ColumnOrSuperColumn.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.ColumnDef.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.Column.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.CfDef.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.Cassandra.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.AuthorizationException.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.AuthenticationRequest.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.AuthenticationException.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3250" opendate="2011-9-23 00:00:00" fixdate="2011-12-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>fsync the directory after new sstable or commit log segment are created</summary>
      <description>The mannual of fsync said:Calling fsync() does not necessarily ensure that the entry in the directory containing the file has also reached disk. For that an explicit fsync() on a file descriptor for the directory is also needed.At least on ext4, syncing the directory is a must to have step, as described by &amp;#91;1&amp;#93;. Otherwise, the new sstables or commit logs could be missed after crash even if itself is synced. Unfortunately, JVM does not provide an approach to sync the directory...&amp;#91;1&amp;#93; http://www.linuxfoundation.org/news-media/blogs/browse/2009/03/don%E2%80%99t-fear-fsync</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.utils.CLibrary.java</file>
      <file type="M">src.java.org.apache.cassandra.io.util.SequentialWriter.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3271" opendate="2011-9-28 00:00:00" fixdate="2011-10-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>off-heap cache to use sun.misc.Unsafe instead of JNA</summary>
      <description>Instead of requiring JNA for off-heap caches we should try to use sun.misc.Unsafe.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cache.CacheProviderTest.java</file>
      <file type="M">src.resources.org.apache.cassandra.cli.CliHelp.yaml</file>
      <file type="M">src.java.org.apache.cassandra.io.util.MemoryOutputStream.java</file>
      <file type="M">src.java.org.apache.cassandra.io.util.MemoryInputStream.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.SerializingCacheProvider.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.FreeableMemory.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3272" opendate="2011-9-28 00:00:00" fixdate="2011-10-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>READ Operation with CL=EACH_QUORUM succeed when a DC is down (RF=3)</summary>
      <description>"READ EACH_QUORUM: Returns the record with the most recent timestamp once a quorum of replicas in each data center of the cluster has responded."In other words, if a DC is down and the QUORUM could not be reached on that DC, read should fail.test case: Cassandra version 0.8.6:INFO &amp;#91;main&amp;#93; 2011-09-28 22:26:24,297 StorageService.java (line 371) Cassandra version: 0.8.6 6-node cluster with 2 DC and 3 node each. RF=3 in each DC:&amp;#91;default@Keyspace3&amp;#93; describe keyspace;Keyspace: Keyspace3:Replication Strategy: org.apache.cassandra.locator.NetworkTopologyStrategyDurable Writes: trueOptions: &amp;#91;DC2:3, DC1:3&amp;#93;Column Families:ColumnFamily: testKey Validation Class: org.apache.cassandra.db.marshal.BytesTypeDefault column value validator: org.apache.cassandra.db.marshal.BytesTypeColumns sorted by: org.apache.cassandra.db.marshal.BytesTypeRow cache size / save period in seconds: 0.0/0Key cache size / save period in seconds: 200000.0/14400Memtable thresholds: 1.0875/1440/232 (millions of ops/minutes/MB)GC grace seconds: 864000Compaction min/max thresholds: 4/32Read repair chance: 1.0Replicate on write: trueBuilt indexes: []all nodes are up, insert a row:$ nodetool -h localhost ringAddress DC Rack Status State Load Owns Token14178431955039102644307275309657008810610.34.79.179 DC1 RAC1 Up Normal 11.13 KB 16.67% 010.34.70.163 DC2 RAC1 Up Normal 11.14 KB 16.67% 2835686391007820528861455061931401762110.35.81.147 DC1 RAC1 Up Normal 11.14 KB 16.67% 5671372782015641057722910123862803524210.84.233.170 DC2 RAC1 Up Normal 11.14 KB 16.67% 8507059173023461586584365185794205286410.195.201.236 DC1 RAC1 Up Normal 11.14 KB 16.67% 11342745564031282115445820247725607048510.118.147.73 DC2 RAC1 Up Normal 11.14 KB 16.67% 141784319550391026443072753096570088106 insert a value&amp;#91;default@Keyspace3&amp;#93; set test&amp;#91;utf8(&amp;#39;test-key-1&amp;#39;)&amp;#93;&amp;#91;utf8(&amp;#39;test-col&amp;#39;)&amp;#93;=utf8('test-value');Value inserted.sanity check (cli connects to a node in DC1) :&amp;#91;default@Keyspace3&amp;#93; consistencylevel as EACH_QUORUM; Consistency level is set to 'EACH_QUORUM'.&amp;#91;default@Keyspace3&amp;#93; get test&amp;#91;utf8(&amp;#39;test-key-1&amp;#39;)&amp;#93;; =&gt; (column=746573742d636f6c, value=test-value, timestamp=1317249361722000)Returned 1 resultsshut down DC2:$ nodetool -h localhost ringAddress DC Rack Status State Load Owns Token 141784319550391026443072753096570088106 10.34.79.179 DC1 RAC1 Up Normal 51.86 KB 16.67% 0 10.34.70.163 DC2 RAC1 Down Normal 51.88 KB 16.67% 28356863910078205288614550619314017621 10.35.81.147 DC1 RAC1 Up Normal 47.5 KB 16.67% 56713727820156410577229101238628035242 10.84.233.170 DC2 RAC1 Down Normal 51.88 KB 16.67% 85070591730234615865843651857942052864 10.195.201.236 DC1 RAC1 Up Normal 47.5 KB 16.67% 113427455640312821154458202477256070485 10.118.147.73 DC2 RAC1 Down Normal 51.88 KB 16.67% 141784319550391026443072753096570088106 &amp;#91;default@Keyspace3&amp;#93; get test&amp;#91;utf8(&amp;#39;test-key-1&amp;#39;)&amp;#93;; =&gt; (column=746573742d636f6c, value=746573742d76616c7565, timestamp=1317249361722000)Returned 1 results.tried with pycassaShell:&gt;&gt;&gt; col_fam.get('test-key-1',read_consistency_level=pycassa.ConsistencyLevel.EACH_QUORUM)OrderedDict(&amp;#91;(&amp;#39;test-col&amp;#39;, &amp;#39;test-value&amp;#39;)&amp;#93;)</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.thrift.ThriftValidation.java</file>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraServer.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.QueryProcessor.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3410" opendate="2011-10-27 00:00:00" fixdate="2011-11-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>inconsistent rejection of CL.ANY on reads</summary>
      <description></description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.thrift.ThriftValidation.java</file>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraServer.java</file>
      <file type="M">src.java.org.apache.cassandra.service.ReadCallback.java</file>
      <file type="M">NEWS.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3411" opendate="2011-10-27 00:00:00" fixdate="2011-12-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Pre-allocated, Recycled Commitlog Segment Files</summary>
      <description>An approach for improving commitlog performance is to pre-allocate the full 128MB segment files and reuse them once all the mutations have been flushed. Pre-allocation allows writes to be performed without modifying the file size metadata, and should (in theory) allow the filesystem to allocate a contiguous block of space for the file. Recycling the segment files prevents the overhead of pre-allocation from impacting overall performance.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.RecoveryManagerTruncateTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.RecoveryManagerTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.RecoveryManager3Test.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.RecoveryManager2Test.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.CommitLogTest.java</file>
      <file type="M">src.java.org.apache.cassandra.service.AbstractCassandraDaemon.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowMutation.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLogSegment.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLog.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3434" opendate="2011-10-31 00:00:00" fixdate="2011-11-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Explore using Guava (or guava inspired) faster bytes comparison</summary>
      <description>Guava uses un.misc.Unsafe to do a faster byte arrays comparison (on long at a time) as noted in HADOOP-7761.We should probably look into it.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.dht.RangeTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.marshal.ReversedTypeTest.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.FBUtilities.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.ByteBufferUtil.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3452" opendate="2011-11-3 00:00:00" fixdate="2011-12-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create an &amp;#39;infinite bootstrap&amp;#39; mode for sampling live traffic</summary>
      <description>You may want to, for example, test a new compaction strategy with live traffic to see how it will fare. In this mode, the node would follow the bootstrap procedure as normal, but never fully join the ring.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStoreMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="3479" opendate="2011-11-9 00:00:00" fixdate="2011-1-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>add read from/write to file support to cqlsh</summary>
      <description></description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.pylexotron.py</file>
      <file type="M">pylib.cqlshlib.cqlhandling.py</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug id="3483" opendate="2011-11-11 00:00:00" fixdate="2011-1-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support bringing up a new datacenter to existing cluster without repair</summary>
      <description>Was talking to Brandon in irc, and we ran into a case where we want to bring up a new DC to an existing cluster. He suggested from jbellis the way to do it currently was set strategy options of dc2:0, then add the nodes. After the nodes are up, change the RF of dc2, and run repair. I'd like to avoid a repair as it runs AES and is a bit more intense than how bootstrap works currently by just streaming ranges from the SSTables. Would it be possible to improve this functionality (adding a new DC to existing cluster) than the proposed method? We'd be happy to do a patch if we got some input on the best way to go about it.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.dht.BootStrapperTest.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeProbe.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamInSession.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.OperationType.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageServiceMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.BootStrapper.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3509" opendate="2011-11-18 00:00:00" fixdate="2011-3-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cassandra-cli shows org.apache.Cassandra.XXX in example help for replication strategy but it should be cassandra with a lowercase c</summary>
      <description>copying and pasting the example doesn't result in a working example and noticing the "C" v "c" is something easy to overlook</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.resources.org.apache.cassandra.cli.CliHelp.yaml</file>
    </fixedFiles>
  </bug>
  <bug id="351" opendate="2009-8-6 00:00:00" fixdate="2009-8-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>fixes for code review of #332</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.IndexHelper.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.SSTableSliceIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.SSTableNamesIterator.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.TableTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="3538" opendate="2011-11-29 00:00:00" fixdate="2011-12-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove columns shadowed by a deleted container even when we cannot purge</summary>
      <description>During compaction, if shouldPurge == false, we don't do anything with the column family. It is however ok to remove columns for with their container is deleted with a timestamp greater than their own.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.PrecompactedRow.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3543" opendate="2011-11-30 00:00:00" fixdate="2011-12-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Commit Log Allocator deadlock after first start with empty commitlog directory</summary>
      <description>While testing CASSANDRA-3541 at some point stress completely timed out. I proceeded to shut the cluster down and 2/3 JVMs hang infinitely. After a while, one of them logged:WARN 19:07:50,133 Some hints were not written before shutdown. This is not supposed to happen. You should (a) run repair, and (b) file a bug report</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLog.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3545" opendate="2011-11-30 00:00:00" fixdate="2011-12-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix very low Secondary Index performance</summary>
      <description>While performing index search + value filtering over large Index Row ( ~100k keys per index value) with chunks (size of 512-1024 keys) search time is about 8-12 seconds, which is very very low.After profiling I got this picture:60% of search time is calculating MD5 hash with MessageDigester (Of cause it is because of RundomPartitioner).33% of search time (half of all MD5 hash calculating time) is double calculating of MD5 for comparing two row keys while rotating Index row to startKey (when performing search query for next chunk).I see several performance improvements:1) Use good algorithm to search startKey in sorted collection, that is faster then iteration over all keys. This solution is on first place because it simple, need only local code changes and should solve problem (increase search in multiple times).2) Don't calculate MD5 hash for startKey every time. It's optimal to compute it once (so search will be twice faster).Also need local code changes.3) Think about something faster that MD5 for hashing (like TigerRandomPartitioner with Tiger/128 hash).Need research and maybe this research was done.4) Don't use Tokens (with MD5 hash for RandomPartitioner) for comparing and sorting keys in index rows. In index rows, keys can be stored and compared with simple Byte Comparator. This solution requires huge code changes.I'm going to start from first solution. Next improvements can be done with next tickets.</description>
      <version>1.1.0</version>
      <fixedVersion>Feature/2iIndex</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.ArrayBackedSortedColumnsTest.java</file>
      <file type="M">src.java.org.apache.cassandra.service.RowRepairResolver.java</file>
      <file type="M">src.java.org.apache.cassandra.db.TreeMapBackedSortedColumns.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ThreadSafeSortedColumns.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowIteratorFactory.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Memtable.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ISortedColumns.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.keys.KeysSearcher.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.SliceQueryFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.QueryFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.NamesQueryFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.IFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">src.java.org.apache.cassandra.db.CollationController.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ArrayBackedSortedColumns.java</file>
      <file type="M">src.java.org.apache.cassandra.db.AbstractColumnContainer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3557" opendate="2011-12-2 00:00:00" fixdate="2011-12-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Commit Log segments are not recycled</summary>
      <description>Cassandra never recycles segments created after recovery.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.SchemaLoader.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLogSegment.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLogAllocator.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLog.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3561" opendate="2011-12-2 00:00:00" fixdate="2011-12-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make incremental_backups setting mutable via JMX</summary>
      <description>This would be more useful as in the schema as a CF-level setting, but for 1.1 let's at least make it setting it via JMX possible.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageServiceMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.DataTracker.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="3566" opendate="2011-12-2 00:00:00" fixdate="2011-12-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cache saving broken on windows</summary>
      <description>CASSANDRA-1740 broke cache saving on Windows.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManagerMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.AutoSavingCache.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3568" opendate="2011-12-3 00:00:00" fixdate="2011-1-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cassandra-cli and nodetool should connect to localhost by default</summary>
      <description>The command line tools (cassandra-cli and noetool) should connect by default to localhost. This behavior is a bit more user-friendly and reflects somewhat of a convention among command-line database tools for popular open source databases such as MySQL and PostgreSQL.</description>
      <version>1.1.0</version>
      <fixedVersion>Tool/nodetool</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">src.java.org.apache.cassandra.cli.CliOptions.java</file>
      <file type="M">src.java.org.apache.cassandra.cli.CliMain.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3583" opendate="2011-12-7 00:00:00" fixdate="2011-3-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add "rebuild index" JMX command</summary>
      <description>CASSANDRA-1740 allows aborting an index build, but there is no way to re-attempt the build without restarting the server.We've also had requests to allow rebuilding an index that has been built, so it would be nice to kill two birds with one stone here.</description>
      <version>1.1.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeProbe.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageServiceMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Table.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.SecondaryIndexManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.SecondaryIndex.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.QueryFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3602" opendate="2011-12-9 00:00:00" fixdate="2011-12-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove test/distributed</summary>
      <description>Now that we've shifted focus to the new ccm-based distributed tests (https://github.com/riptano/cassandra-dtest) I think it's time to remove the now long-neglected distributed test cruft from our tree.</description>
      <version>1.0.6,1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.distributed.README.txt</file>
      <file type="M">test.distributed.org.apache.cassandra.utils.KeyPair.java</file>
      <file type="M">test.distributed.org.apache.cassandra.utils.BlobUtils.java</file>
      <file type="M">test.distributed.org.apache.cassandra.TestBase.java</file>
      <file type="M">test.distributed.org.apache.cassandra.MutationTest.java</file>
      <file type="M">test.distributed.org.apache.cassandra.MovementTest.java</file>
      <file type="M">test.distributed.org.apache.cassandra.CountersTest.java</file>
      <file type="M">test.distributed.org.apache.cassandra.CassandraServiceController.java</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3611" opendate="2011-12-11 00:00:00" fixdate="2011-12-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make checksum on a compressed blocks optional</summary>
      <description>Currently every uncompressed block is run against checksum algo, there is cpu overhead in doing same... We might want to make it configurable/optional for some use cases which might not require checksum all the time.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.compress.CompressionParameters.java</file>
      <file type="M">src.java.org.apache.cassandra.io.compress.CompressedRandomAccessReader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3612" opendate="2011-12-11 00:00:00" fixdate="2011-3-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CQL inserting blank key.</summary>
      <description>One of our application bug inserted blank key into cluster causing assertion error on key. After checking the root cause, I found it is the bug with CQL and reproducible. Client cassandra-node and cqlsh-1.0.6.Blank key only work when one column provided.{}cqlsh&gt; insert into login (KEY,email)values('','');cqlsh&gt; select * from login;u'' | u'email',u'' cqlsh&gt; insert into login (KEY,email,verified)values('','','');Request did not complete within rpc_timeout.cqlsh&gt; insert into login (KEY,verified)values('','');Request did not complete within rpc_timeout.cqlsh&gt; insert into login (KEY,email)values('','');cqlsh&gt; cqlsh&gt; select * from login;u'' | u'email',u'' | u'uid',Nonecqlsh&gt; select * from login;u'' | u'email',u'' | u'uid',Nonecqlsh&gt; select * from login;u'' | u'email',u'' | u'uid',Nonecqlsh&gt; cqlsh&gt; select * from login;u'' | u'email',u'' | u'uid',Noneu'samalgorai@gmail.com' | u'email',u'samalgorai@gmail.com' | u'password',u'388ad1c312a488ee9e12998fe097f2258fa8d5ee' | u'uid',UUID('05ea41dc-241f-11e1-8521-3da59237b189') | u'verified',u'0'cqlsh&gt; quit;{/}http://pastebin.com/HJn5fHhH</description>
      <version>1.0.9,1.1.0</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.UpdateStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.DeleteStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.QueryProcessor.java</file>
    </fixedFiles>
  </bug>
  <bug id="3634" opendate="2011-12-14 00:00:00" fixdate="2011-1-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>compare string vs. binary prepared statement parameters</summary>
      <description>Perform benchmarks to compare the performance of string and pre-serialized binary parameters to prepared statements.</description>
      <version>1.1.0</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.Cassandra.java</file>
      <file type="M">interface.cassandra.thrift</file>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraServer.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.UpdateStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.Term.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.QueryProcessor.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.DeleteStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.CreateColumnFamilyStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.BatchStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.AbstractModification.java</file>
    </fixedFiles>
  </bug>
  <bug id="3641" opendate="2011-12-15 00:00:00" fixdate="2011-1-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>inconsistent/corrupt counters w/ broken shards never converge</summary>
      <description>We ran into a case (which MIGHT be related to CASSANDRA-3070) whereby we had counters that were corrupt (hopefully due to CASSANDRA-3178). The corruption was that there would exist shards with the same node_id, same clock id, but different counts.The counter column diffing and reconciliation code assumes that this never happens, and ignores the count. The problem with this is that if there is an inconsistency, the result of a reconciliation will depend on the order of the shards.In our case for example, we would see the value of the counter randomly fluctuating on a CL.ALL read, but we would get consistent (whatever the node had) on CL.ONE (submitted to one of the nodes in the replica set for the key).In addition, read repair would not work despite digest mismatches because the diffing algorithm also did not care about the counts when determining the differences to send.I'm attaching patches that fixes this. The first patch is against our 0.8 branch, which is not terribly useful to people, but I include it because it is the well-tested version that we have used on the production cluster which was subject to this corruption.The other patch is against trunk, and contains the same change.What the patch does is: On diffing, treat as DISJOINT if there is a count discrepancy. On reconciliation, look at the count and deterministically pick the higher one, and: log the fact that we detected a corrupt counter increment a JMX observable counter for monitoring purposes A cluster which is subject to such corruption and has this patch, will fix itself with and AES + compact (or just repeated compactions assuming the replicate-on-compact is able to deliver correctly).</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.context.CounterContext.java</file>
    </fixedFiles>
  </bug>
  <bug id="3651" opendate="2011-12-20 00:00:00" fixdate="2011-12-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Truncate shouldn&amp;#39;t rethrow timeouts as UA</summary>
      <description>Truncate is a very easy operation to timeout, but the timeouts rethrow as UnavailableException which is somewhat confusing. Instead it should throw TimedOutException.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraServer.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.Constants.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.Cassandra.java</file>
      <file type="M">interface.cassandra.thrift</file>
    </fixedFiles>
  </bug>
  <bug id="3658" opendate="2011-12-22 00:00:00" fixdate="2011-12-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix smallish problems find by FindBugs</summary>
      <description>I've just run (the newly released) FindBugs 2 out of curiosity. Attaching a number of patches related to issue raised by it. There is nothing major at all so all patches are against trunk.I've tried keep each issue to it's own patch with a self describing title. It far from covers all FindBugs alerts, but it's a picky tool so I've tried to address only what felt at least vaguely useful. Those are still mostly nits (only patch 2 is probably an actual bug).</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.utils.NodeId.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.FBUtilities.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.EstimatedHistogram.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.FileStreamTask.java</file>
      <file type="M">src.java.org.apache.cassandra.service.AntiEntropyService.java</file>
      <file type="M">src.java.org.apache.cassandra.net.ProtocolHeader.java</file>
      <file type="M">src.java.org.apache.cassandra.locator.PropertyFileSnitch.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableLoader.java</file>
      <file type="M">src.java.org.apache.cassandra.io.compress.CompressionMetadata.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.Token.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.LocalToken.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowIteratorFactory.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.ReversedType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.DynamicCompositeType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.AbstractType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.QueryFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ExpiringColumn.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamily.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ArrayBackedSortedColumns.java</file>
      <file type="M">src.java.org.apache.cassandra.config.ReplicationStrategy.java</file>
      <file type="M">src.java.org.apache.cassandra.cli.CliClient.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3664" opendate="2011-12-23 00:00:00" fixdate="2011-12-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[patch] fix some obvious javadoc issues generated via ant javadoc</summary>
      <description></description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.utils.BloomFilterSerializer.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.CassandraDaemon.java</file>
      <file type="M">src.java.org.apache.cassandra.scheduler.IRequestScheduler.java</file>
      <file type="M">src.java.org.apache.cassandra.locator.AbstractReplicationStrategy.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowIteratorFactory.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLogSegment.java</file>
    </fixedFiles>
  </bug>
  <bug id="3667" opendate="2011-12-23 00:00:00" fixdate="2011-1-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>We need a way to deactivate row/key caching on a per-cf basis.</summary>
      <description>Initial idea would be to either have a boolean flag if we only want to allow disabling row cache, or some multi-value caches option that could be "none", "key_only", "row_only" or "all".</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.SchemaLoader.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableReader.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">src.java.org.apache.cassandra.cli.CliClient.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.Constants.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.CfDef.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.Cassandra.java</file>
      <file type="M">interface.cassandra.thrift</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">src.avro.internode.genavro</file>
    </fixedFiles>
  </bug>
  <bug id="3671" opendate="2011-12-24 00:00:00" fixdate="2011-3-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>provide JMX counters for unavailables/timeouts for reads and writes</summary>
      <description>Attaching patch against trunk.</description>
      <version>1.1.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3675" opendate="2011-12-27 00:00:00" fixdate="2011-2-27 01:00:00" resolution="Won&amp;#39;t Fix">
    <buginformation>
      <summary>ship with -XX:+ExplicitGCInvokesConcurrent by default</summary>
      <description>It's so much easier if you can safely tell people to trigger a full GC to discover their live set (see CASSANDRA-3574), instead of explaining the behavior of CMS and what the memory usage graph looks like etc etc. Shipping with -XX:+ExplicitGCInvokesConcurrent means this is by default safe.For people that have special needs like some kind of rolling compacting GC with disablegossip, they are special enough that they can just change the VM options.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.cassandra-env.sh</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3676" opendate="2011-12-27 00:00:00" fixdate="2011-4-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add snaptree dependency to maven central and update pom</summary>
      <description>Snaptree dependency needs to be added to maven before we can release 1.1</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">lib.snaptree-0.1-SNAPSHOT.jar</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3679" opendate="2011-12-28 00:00:00" fixdate="2011-12-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>clean up multithreaded streaming to use a ConcurrentMap instead of explicit locking</summary>
      <description></description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
    </fixedFiles>
  </bug>
  <bug id="3688" opendate="2012-1-2 00:00:00" fixdate="2012-1-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[patch] avoid map lookups in loops by using entrysets</summary>
      <description>code loops over the keySet and does gets for the value, just use entrySet()</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
    </fixedFiles>
  </bug>
  <bug id="3716" opendate="2012-1-10 00:00:00" fixdate="2012-1-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up isMarkedForDelete / getLocalDeletionTime</summary>
      <description>As explained in CASSANDRA-3579, isMarkedForDelete() depends on the current system clock so it can change during a two-pass compaction. Suggested fix is to replace iMFD + gLDT with a getExpirationTime method, so comparison with the compaction's gcBefore will remain constant.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.IColumn.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.QueryFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ExpiringColumn.java</file>
      <file type="M">src.java.org.apache.cassandra.db.DeletedColumn.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Column.java</file>
      <file type="M">src.java.org.apache.cassandra.db.AbstractColumnContainer.java</file>
    </fixedFiles>
  </bug>
  <bug id="3725" opendate="2012-1-11 00:00:00" fixdate="2012-1-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Switch stress tool to using micros</summary>
      <description>The situation encountered is that after deleting the columns for a row in the cli new workloads don't update that columns for the rows. Brandon mentioned that stress uses millis, cli uses micros and therefore row tombstone wins.Test Case: Before Delete// Run: stress --operation=INSERT --num-keys=1 --columns=2 --consistency-level=QUORUM --column-size=1 --threads=1 --replication-factor=1 --nodes=localhost// Run cassandra-cli[default@Keyspace1] list Standard1; Using default limit of 100-------------------RowKey: 30=&gt; (column=C0, value=63, timestamp=1326259090065)=&gt; (column=C1, value=63, timestamp=1326259090065)1 Row Returned.Elapsed time: 2 msec(s).[default@Keyspace1] del Standard1['30']; row removed.[default@Keyspace1] list Standard1; Using default limit of 100-------------------RowKey: 30Test Case: After Delete// Run: stress --operation=INSERT --num-keys=1 --columns=2 --consistency-level=QUORUM --column-size=1 --threads=1 --replication-factor=1 --nodes=localhost// Run cassandra-cli[default@Keyspace1] list Standard1;Using default limit of 100-------------------RowKey: 301 Row Returned.Elapsed time: 1 msec(s).</description>
      <version>1.1.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.operations.Inserter.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3732" opendate="2012-1-12 00:00:00" fixdate="2012-4-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update POM generation after migration to git</summary>
      <description></description>
      <version>1.0.10,1.1.0</version>
      <fixedVersion>Packaging</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3736" opendate="2012-1-13 00:00:00" fixdate="2012-1-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>-Dreplace_token leaves old node (IP) in the gossip with the token.</summary>
      <description>https://issues.apache.org/jira/browse/CASSANDRA-957 introduce a -Dreplace_token,however, the replaced IP keeps on showing up in the Gossiper when starting the replacement node: INFO [Thread-2] 2012-01-12 23:59:35,162 CassandraDaemon.java (line 213) Listening for thrift clients... INFO [GossipStage:1] 2012-01-12 23:59:35,173 Gossiper.java (line 836) Node /50.56.59.68 has restarted, now UP INFO [GossipStage:1] 2012-01-12 23:59:35,174 Gossiper.java (line 804) InetAddress /50.56.59.68 is now UP INFO [GossipStage:1] 2012-01-12 23:59:35,175 StorageService.java (line 988) Node /50.56.59.68 state jump to normal INFO [GossipStage:1] 2012-01-12 23:59:35,176 Gossiper.java (line 836) Node /50.56.58.55 has restarted, now UP INFO [GossipStage:1] 2012-01-12 23:59:35,176 Gossiper.java (line 804) InetAddress /50.56.58.55 is now UP INFO [GossipStage:1] 2012-01-12 23:59:35,177 StorageService.java (line 1016) Nodes /50.56.58.55 and action-quick2/50.56.31.186 have the same token 85070591730234615865843651857942052864. Ignoring /50.56.58.55 INFO [GossipTasks:1] 2012-01-12 23:59:45,048 Gossiper.java (line 818) InetAddress /50.56.58.55 is now dead. INFO [GossipTasks:1] 2012-01-13 00:00:06,062 Gossiper.java (line 632) FatClient /50.56.58.55 has been silent for 30000ms, removing from gossip INFO [GossipStage:1] 2012-01-13 00:01:06,320 Gossiper.java (line 838) Node /50.56.58.55 is now part of the cluster INFO [GossipStage:1] 2012-01-13 00:01:06,320 Gossiper.java (line 804) InetAddress /50.56.58.55 is now UP INFO [GossipStage:1] 2012-01-13 00:01:06,321 StorageService.java (line 1016) Nodes /50.56.58.55 and action-quick2/50.56.31.186 have the same token 85070591730234615865843651857942052864. Ignoring /50.56.58.55 INFO [GossipTasks:1] 2012-01-13 00:01:16,106 Gossiper.java (line 818) InetAddress /50.56.58.55 is now dead. INFO [GossipTasks:1] 2012-01-13 00:01:37,121 Gossiper.java (line 632) FatClient /50.56.58.55 has been silent for 30000ms, removing from gossip INFO [GossipStage:1] 2012-01-13 00:02:37,352 Gossiper.java (line 838) Node /50.56.58.55 is now part of the cluster INFO [GossipStage:1] 2012-01-13 00:02:37,353 Gossiper.java (line 804) InetAddress /50.56.58.55 is now UP INFO [GossipStage:1] 2012-01-13 00:02:37,353 StorageService.java (line 1016) Nodes /50.56.58.55 and action-quick2/50.56.31.186 have the same token 85070591730234615865843651857942052864. Ignoring /50.56.58.55 INFO [GossipTasks:1] 2012-01-13 00:02:47,158 Gossiper.java (line 818) InetAddress /50.56.58.55 is now dead. INFO [GossipStage:1] 2012-01-13 00:02:50,162 Gossiper.java (line 818) InetAddress /50.56.58.55 is now dead. INFO [GossipStage:1] 2012-01-13 00:02:50,163 StorageService.java (line 1156) Removing token 122029383590318827259508597176866581733 for /50.56.58.55in the above, /50.56.58.55 was the replaced IP.tried adding the "Gossiper.instance.removeEndpoint(endpoint);" in the StorageService.java where the message 'Nodes %s and %s have the same token %s. Ignoring %s",' seems only have fixed this temporary. Here is a ring output:riptano@action-quick:~/work/cassandra$ ./bin/nodetool -h localhost ringAddress DC Rack Status State Load Owns Token 85070591730234615865843651857942052864 50.56.59.68 datacenter1 rack1 Up Normal 6.67 KB 85.56% 60502102442797279294142560823234402248 50.56.31.186 datacenter1 rack1 Up Normal 11.12 KB 14.44% 85070591730234615865843651857942052864 gossipinfo:$ ./bin/nodetool -h localhost gossipinfo/50.56.58.55 LOAD:6835.0 SCHEMA:00000000-0000-1000-0000-000000000000 RPC_ADDRESS:50.56.58.55 STATUS:NORMAL,85070591730234615865843651857942052864 RELEASE_VERSION:1.0.7-SNAPSHOT/50.56.59.68 LOAD:6835.0 SCHEMA:00000000-0000-1000-0000-000000000000 RPC_ADDRESS:50.56.59.68 STATUS:NORMAL,60502102442797279294142560823234402248 RELEASE_VERSION:1.0.7-SNAPSHOTaction-quick2/50.56.31.186 LOAD:11387.0 SCHEMA:00000000-0000-1000-0000-000000000000 RPC_ADDRESS:50.56.31.186 STATUS:NORMAL,85070591730234615865843651857942052864 RELEASE_VERSION:1.0.7-SNAPSHOTNote that at 1 point earlier it seems to have been removed:$ ./bin/nodetool -h localhost gossipinfo/50.56.59.68 LOAD:13815.0 SCHEMA:00000000-0000-1000-0000-000000000000 RPC_ADDRESS:50.56.59.68 STATUS:NORMAL,60502102442797279294142560823234402248 RELEASE_VERSION:1.0.7-SNAPSHOTaction-quick2/50.56.31.186 LOAD:13725.0 SCHEMA:00000000-0000-1000-0000-000000000000 RPC_ADDRESS:50.56.31.186 STATUS:NORMAL,85070591730234615865843651857942052864 RELEASE_VERSION:1.0.7-SNAPSHOTriptano@action-quick2:~/work/cassandra$ INFO &amp;#91;GossipStage:1&amp;#93; 2012-01-13 01:03:30,073 Gossiper.java (line 838) Node /50.56.58.55 is now part of the cluster INFO &amp;#91;GossipStage:1&amp;#93; 2012-01-13 01:03:30,073 Gossiper.java (line 804) InetAddress /50.56.58.55 is now UP INFO &amp;#91;GossipStage:1&amp;#93; 2012-01-13 01:03:30,074 StorageService.java (line 1017) Nodes /50.56.58.55 and action-quick2/50.56.31.186 have the same token 85070591730234615865843651857942052864. Ignoring /50.56.58.55</description>
      <version>1.0.8,1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.SystemTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="3743" opendate="2012-1-13 00:00:00" fixdate="2012-1-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Lower memory consumption used by index sampling</summary>
      <description>currently j.o.a.c.io.sstable.indexsummary is implemented as ArrayList of KeyPosition (RowPosition key, long offset)i propose to change it to:RowPosition keys[]long offsets[]and use standard binary search on it. This will lower number of java objects used per entry from 2 (KeyPosition + RowPosition) to 1 (RowPosition).For building these arrays convenient ArrayList class can be used and then call to .toArray() on it.This is very important because index sampling uses a lot of memory on nodes with billions rows</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableReader.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.IndexSummary.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3752" opendate="2012-1-18 00:00:00" fixdate="2012-1-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>bulk loader no longer finds sstables</summary>
      <description>It looks like CASSANDRA-2749 broke it: WARN 13:02:20,107 Invalid file 'Standard1' in data directory /var/lib/cassandra/data/Keyspace1.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.BulkLoader.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableLoader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3754" opendate="2012-1-19 00:00:00" fixdate="2012-2-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add TTL support to BulkOutputFormat</summary>
      <description></description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.hadoop.BulkRecordWriter.java</file>
    </fixedFiles>
  </bug>
  <bug id="3757" opendate="2012-1-19 00:00:00" fixdate="2012-1-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh: update syntax for tab completions</summary>
      <description>Several recent additions to CQL syntax have yet to be reflected in cqlsh's tab completion capability, such as CASSANDRA-3419, CASSANDRA-3374, and CASSANDRA-3523.Update those bits of syntax definition.</description>
      <version>1.1.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.pylexotron.py</file>
      <file type="M">pylib.cqlshlib.cqlhandling.py</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug id="3758" opendate="2012-1-20 00:00:00" fixdate="2012-5-20 01:00:00" resolution="Duplicate">
    <buginformation>
      <summary>parallel compaction hang (on large rows?)</summary>
      <description>it is observed that:nodetool -h 127.0.0.1 -p 8080 compactionstatspending tasks: 1compaction type keyspace column family bytes compacted bytes total progressCompaction SyncCoreComputedContactNetworks 119739938 0 n/aand that is not moving (ie the bytes compacted never increase, the bytes total stay 0).this is probably going to be difficult to reproduce, as the problem is observed when compacting 15 large sstables (total ~300G).attaching the thread dumps (along with logs), when such happen.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.ParallelCompactionIterable.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionIterable.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.AbstractCompactionIterable.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3760" opendate="2012-1-20 00:00:00" fixdate="2012-1-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move the decompose() methods from o.a.c.db.marshal.*Type to o.a.c.cql.jdbc.Jdbc*</summary>
      <description>The PreparedStatement code for 1.1 has been committed to trunk with ByteBuffer as the argument for bound variables. The client side code using the cassandra-clientutil jar file needs access to decompose() methods for the various client supported java types to decompose the java bind variables to ByteBuffer.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.marshal.UUIDType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.UTF8Type.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.TimeUUIDType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.LongType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.LexicalUUIDType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.IntegerType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.Int32Type.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.FloatType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.DoubleType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.DecimalType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.DateType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.CounterColumnType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.BytesType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.BooleanType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.AsciiType.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.jdbc.JdbcUUID.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.jdbc.JdbcUTF8.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.jdbc.JdbcTimeUUID.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.jdbc.JdbcLong.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.jdbc.JdbcLexicalUUID.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.jdbc.JdbcInteger.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.jdbc.JdbcInt32.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.jdbc.JdbcFloat.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.jdbc.JdbcDouble.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.jdbc.JdbcDecimal.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.jdbc.JdbcDate.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.jdbc.JdbcBytes.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.jdbc.JdbcBoolean.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.jdbc.JdbcAscii.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.jdbc.AbstractJdbcType.java</file>
    </fixedFiles>
  </bug>
  <bug id="3766" opendate="2012-1-21 00:00:00" fixdate="2012-1-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>KeysIndex is broken by CASSANDRA-1600</summary>
      <description>CASSANDRA-1600 introduces bug which cause KeySearch throws an Exception during searchKeySearcher:163logger.debug("Skipping {}", baseCfs.getComparator().getString(firstColumn.name()));Here firstColumn is a column from index row, so column name is a key in the baseCf. So the correct version would be:logger.debug("Skipping {}", baseCfs.metadata.getKeyValidator().getString(firstColumn.name()));Right now it is not possible to query KeysIndex.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.index.keys.KeysSearcher.java</file>
    </fixedFiles>
  </bug>
  <bug id="3781" opendate="2012-1-25 00:00:00" fixdate="2012-2-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CQL support for changing row key type in ALTER TABLE</summary>
      <description>There is currently no way to alter the key_validation_class from CQL. jbellis suggested that this could be done by being able to ALTER the type of the KEY alias.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql.AlterTableStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.AlterTableStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3785" opendate="2012-1-25 00:00:00" fixdate="2012-4-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support slice with exclusive start and stop</summary>
      <description>Currently, slices are always start and end inclusive. However, for CQL 3.0, we already differenciate between inclusivity/exclusivity for the row key and for the component of composite columns. It would be nice to always support that distinction.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3786" opendate="2012-1-26 00:00:00" fixdate="2012-1-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[patch] fix bad comparison of IColumn to ByteBuffer</summary>
      <description>Code doesfirstColumn.equals(startKey)changed to firstColumn.name().equals(startKey)</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.index.keys.KeysSearcher.java</file>
    </fixedFiles>
  </bug>
  <bug id="3787" opendate="2012-1-26 00:00:00" fixdate="2012-1-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[patch] fix bad comparison of column name against * or 1</summary>
      <description>code does (!selectClause.get(0).equals("*") &amp;&amp; !selectClause.get(0).equals("1")))which is a ColumnDefinition against a string changed toString columnName = selectClause.get(0).toString();if (!columnName.equals("*") &amp;&amp; !columnName.equals("1"))</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
    </fixedFiles>
  </bug>
  <bug id="3788" opendate="2012-1-26 00:00:00" fixdate="2012-1-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[patch] fix bad comparison in hadoop cf recorder reader</summary>
      <description>code doesrows.get(0).columns.get(0).column.equals(startColumn)which is a Column against a ByteBufferchanged to rows.get(0).columns.get(0).column.name.equals(startColumn)</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.hadoop.ColumnFamilyRecordReader.java</file>
    </fixedFiles>
  </bug>
  <bug id="3791" opendate="2012-1-26 00:00:00" fixdate="2012-2-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support query by names for compact CF</summary>
      <description>Current code don't allow doing a query by names on wide rows (compact CF). I.e. with:CREATE TABLE test1 ( k int, c int, v int, PRIMARY KEY (k, c)) WITH COMPACT STORAGE;you cannot do:SELECT v FROM test1 WHERE k = 0 AND c IN (5, 2, 8)even though this is a simple name query.This ticket proposes to allow it.</description>
      <version>1.1.0</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.CFDefinition.java</file>
    </fixedFiles>
  </bug>
  <bug id="3792" opendate="2012-1-26 00:00:00" fixdate="2012-3-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>add type information to new schema_ columnfamilies</summary>
      <description>Should also fix the quotes that the current Thrift-based serialization embeds in string schema data.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.DefsTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.config.CFMetaDataTest.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.FBUtilities.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.ByteBufferUtil.java</file>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraServer.java</file>
      <file type="M">src.java.org.apache.cassandra.service.MigrationManager.java</file>
      <file type="M">src.java.org.apache.cassandra.io.compress.CompressionParameters.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowMutation.java</file>
      <file type="M">src.java.org.apache.cassandra.db.migration.UpdateKeyspace.java</file>
      <file type="M">src.java.org.apache.cassandra.db.migration.UpdateColumnFamily.java</file>
      <file type="M">src.java.org.apache.cassandra.db.migration.MigrationHelper.java</file>
      <file type="M">src.java.org.apache.cassandra.db.migration.Migration.java</file>
      <file type="M">src.java.org.apache.cassandra.db.migration.DropKeyspace.java</file>
      <file type="M">src.java.org.apache.cassandra.db.migration.DropColumnFamily.java</file>
      <file type="M">src.java.org.apache.cassandra.db.migration.AddKeyspace.java</file>
      <file type="M">src.java.org.apache.cassandra.db.migration.AddColumnFamily.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.DynamicCompositeType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.AbstractType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.DeletedColumn.java</file>
      <file type="M">src.java.org.apache.cassandra.db.DefsTable.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Column.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.QueryProcessor.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.DropIndexStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.CreateColumnFamilyStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.UpdateStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.ModificationStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.DropIndexStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateIndexStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateColumnFamilyStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.AlterTableStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.QueryProcessor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.KSMetaData.java</file>
      <file type="M">src.java.org.apache.cassandra.config.ColumnDefinition.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3797" opendate="2012-1-27 00:00:00" fixdate="2012-2-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>StorageProxy static initialization not triggered until thrift requests come in</summary>
      <description>While plugging in the metrics library for CASSANDRA-3671 I realized (because the metrics library was trying to add a shutdown hook on metric creation) that starting cassandra and simply shutting it down, causes StorageProxy to not be initialized until the drain shutdown hook.Effects: StorageProxy mbean missing in visualvm/jconsole after initial startup (seriously, I thought I was going nuts ) And in general anything that makes assumptions about running early, or at least not during JVM shutdown, such as the metrics library, will be problematic</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3798" opendate="2012-1-27 00:00:00" fixdate="2012-1-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>get_count paging often asks for a page uselessly</summary>
      <description>Current get_count paging stopping condition is:if ((requestedCount == 0) || ((columns.size() == 1) &amp;&amp; (lastName.equals(predicate.slice_range.start)))){ break;}On a "count how many columns this row has" query (arguably the main reason why you'd use get_count), requestedCount will never be 0, and so we'll stop whenever a page has only returned the last column of the preceding page. While this isn't wrong, we could stop as soon as a page returns less element than requested and avoid querying that last 1 column page.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraServer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3803" opendate="2012-1-27 00:00:00" fixdate="2012-2-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>snapshot-before-compaction snapshots entire keyspace</summary>
      <description>Should only snapshot the CF being compacted</description>
      <version>1.0.8,1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionTask.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3804" opendate="2012-1-28 00:00:00" fixdate="2012-2-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>upgrade problems from 1.0 to trunk</summary>
      <description>A 3-node cluster is on version 0.8.9, 1.0.6, or 1.0.7 and then one and only one node is taken down, upgraded to trunk, and started again. An rpc timeout exception happens if counter-add operations are done. It usually takes between 1 and 500 add operations before the failure occurs. The failure seems to happen sooner if the coordinator node is NOT the one that was upgraded. Here is the error: ======================================================================ERROR: counter_upgrade_test.TestCounterUpgrade.counter_upgrade_test----------------------------------------------------------------------Traceback (most recent call last): File "/usr/lib/pymodules/python2.7/nose/case.py", line 187, in runTest self.test(*self.arg) File "/home/tahooie/cassandra-dtest/counter_upgrade_test.py", line 50, in counter_upgrade_test cursor.execute("UPDATE counters SET row = row+1 where key='a'") File "/usr/local/lib/python2.7/dist-packages/cql/cursor.py", line 96, in execute raise cql.OperationalError("Request did not complete within rpc_timeout.")OperationalError: Request did not complete within rpc_timeout.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.MigrationManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.DefsTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="3812" opendate="2012-1-30 00:00:00" fixdate="2012-1-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Can&amp;#39;t start a node with row_cache_size_in_mb=1</summary>
      <description>I consistently get the following error when trying to run 'bin/cassandra':ERROR 12:20:28,144 Fatal exception during initializationorg.apache.cassandra.config.ConfigurationException: Found system table files, but they couldn't be loaded! at org.apache.cassandra.db.SystemTable.checkHealth(SystemTable.java:279) at org.apache.cassandra.service.AbstractCassandraDaemon.setup(AbstractCassandraDaemon.java:174) at org.apache.cassandra.service.AbstractCassandraDaemon.activate(AbstractCassandraDaemon.java:367) at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:107)</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3815" opendate="2012-1-30 00:00:00" fixdate="2012-2-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Alllow compression setting adjustment via JMX</summary>
      <description>As the title says, let's allow enabling/disabling/setting chunk size via JMX.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStoreMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
    </fixedFiles>
  </bug>
  <bug id="3821" opendate="2012-2-1 00:00:00" fixdate="2012-2-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Counters in super columns don&amp;#39;t preserve correct values after cluster restart</summary>
      <description>Set up a 3-node cluster with rf=3. Create a counter super column family and increment a bunch of subcolumns 100 times each, with cf=QUORUM. Then wait a few second, restart the cluster, and read the values back. They almost all come back different (and higher) then they are supposed to be.Here are some extra things I've noticed: Reading back the values before the restart always produces correct results. Doing a nodetool flush before killing the cluster greatly improves the results, though sometimes a value will still be incorrect. You might have to run the test several times to see an incorrect value after a flush. This problem doesn't happen on C* 1.0.7, unless you don't sleep between doing the increments and killing the cluster. Then it sometimes happens to a lesser degree.A dtest has been added to demonstrate this issue. It is called "super_counter_test.py".</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.Memtable.java</file>
      <file type="M">src.java.org.apache.cassandra.db.CollationController.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3823" opendate="2012-2-1 00:00:00" fixdate="2012-2-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[patch] remove bogus assert - never false</summary>
      <description>code asserts that SSTableScanner is Closeable final SSTableScanner scanner = sstable.getScanner(filter); scanner.seekTo(startWith); assert scanner instanceof Closeable; // otherwise we leak FDsalways is, unless null, but of course the line before would throw NPE. Just confusing.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.RowIteratorFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="3824" opendate="2012-2-1 00:00:00" fixdate="2012-2-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[patch] add missing break in nodecmd&amp;#39;s command dispatching for SETSTREAMTHROUGHPUT</summary>
      <description>code falls thru SETSTREAMTHROUGHPUT into REBUILD case.</description>
      <version>1.1.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
    </fixedFiles>
  </bug>
  <bug id="3826" opendate="2012-2-1 00:00:00" fixdate="2012-2-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Pig cannot use output formats other than CFOF</summary>
      <description>Pig has ColumnFamilyOutputFormat hard coded.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.hadoop.pig.CassandraStorage.java</file>
    </fixedFiles>
  </bug>
  <bug id="3828" opendate="2012-2-1 00:00:00" fixdate="2012-2-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>BulkOutputFormat shouldn&amp;#39;t need flags to specify the output type</summary>
      <description>BOF currently requires the IS_SUPER boolean to be set to determine if the output CF is going to be a super or not, and would similarly use a flag to indicate counters (if there was support for that yet.) Instead, it should be able to introspect the mutations to determine what kind of columns to write.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.hadoop.BulkRecordWriter.java</file>
    </fixedFiles>
  </bug>
  <bug id="3831" opendate="2012-2-1 00:00:00" fixdate="2012-2-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>scaling to large clusters in GossipStage impossible due to calculatePendingRanges</summary>
      <description>(most observations below are from 0.8, but I just now tested ontrunk and I can trigger this problem just by bootstrapping a ~180nod cluster concurrently, presumably due to the number of nodes thatare simultaneously in bootstrap state)It turns out that: (1) calculatePendingRanges is not just expensive, it's computationally complex - cubic or worse (2) it gets called NOT just once per node being bootstrapped/leaving etc, but is called repeatedly while nodes are in these statesAs a result, clusters start exploding when you start reading 100-300nodes. The GossipStage will get backed up because a singlecalculdatePenginRanges takes seconds, and depending on what theaverage heartbeat interval is in relation to this, this can lead tomassive cluster-wide flapping.This all started because we hit this in production; several nodeswould start flapping several other nodes as down, with many nodesseeing the entire cluster, or a large portion of it, as down. Loggingin to some of these nodes you would see that they would be constantlyflapping up/down for minutes at a time until one became lucky and itstabilized.In the end we had to perform an emergency full-cluster restart withgossip patched to force-forget certain nodes in bootstrapping state.I can't go into all details here from the post-mortem (just thewrite-up would take a day), but in short: We graphed the number of hosts in the cluster that had more than 5 Down (in a cluster that should have 0 down) on a minutely timeline. We also graphed the number of hosts in the cluster that had GossipStage backed up. The two graphs correlated extremely well jstack sampling showed it being CPU bound doing mostly sorting under calculatePendingRanges We were never able to exactly reproduce it with normal RING_DELAY and gossip intervals, even on a 184 node cluster (the production cluster is around 180). Dropping RING_DELAY and in particular dropping gossip interval to 10 ms instead of 1000 ms, we were able to observe all of the behavior we saw in production.So our steps to reproduce are: Launch 184 node cluster w/ gossip interval at 10ms and RING_DELAY at 1 second. Do something like: while [ 1 ] ; do date ; echo decom ; nodetool decommission ; date ; echo done leaving decommed for a while ; sleep 3 ; date ; echo done restarting; sudo rm -rf /data/disk1/commitlog/* ; sudo rm -rf /data/diskarray/tables/* ; sudo monit restart cassandra ;date ; echo restarted waiting for a while ; sleep 40; done (or just do a manual decom/bootstrap once, it triggers every time) Watch all nodes flap massively and not recover at all, or maybe after a long time.I observed the flapping using a python script that every 5 second(randomly spread out) asked for unreachable nodes from all nodes inthe cluster, and printed any nodes and their counts when they hadunreachables &gt; 5. The cluster can be observed instantly going intomassive flapping when leaving/bootstrap is initiated. Script needsCassandra running with Jolokia enabled for http/json access toJMX. Can provide scrit if needed after cleanup.The phi conviction, based on logging I added, was legitimate. Usingthe 10 ms interval the average heartbeat interval ends up being like 25ms or something like that. As a result, a single ~ 2 second delay ingossip stage is huge in comparison to those 25 ms, and so we go pastthe phi conviction threshold. This is much more sensitive than inproduction, but it's the same effect, even if it triggers lesseasily for real.The best work around currently internally is to memoizecalculatePendingRanges so that we don't re-calculate if token metadata, list of moving, list of bootstrapping and list of leaving areall the same as on prior calculation. It's not entirely clear at thispoint whether there is a clean fix to avoid executingcalculatePendingRanges more than once per unique node in this state.It should be noted though that even if that is fixed, it is notacceptable to spend several seconds doing these calculations on a ~200 node cluster and it needs to be made fundamentally more efficient.Here is a dump of thoughts by me in an internal JIRA ticket (notexhaustive, I just went as far as to show that there is an issue;there might be worse things I missed, but worse than cubic is badenough that I stopped):(Comment uses 0.8 source.)Okay, so let's break down the computational complexity here.Suppose ring size is n and number of bootstrapping/leaving tokens is m. One of two places that take time (by measurement) is this part of calculatePendingRanges(): // At this stage pendingRanges has been updated according to leave operations. We can // now continue the calculation by checking bootstrapping nodes. // For each of the bootstrapping nodes, simply add and remove them one by one to // allLeftMetadata and check in between what their ranges would be. for (Map.Entry&lt;Token, InetAddress&gt; entry : bootstrapTokens.entrySet()) { InetAddress endpoint = entry.getValue(); allLeftMetadata.updateNormalToken(entry.getKey(), endpoint); for (Range range : strategy.getAddressRanges(allLeftMetadata).get(endpoint)) pendingRanges.put(range, endpoint); allLeftMetadata.removeEndpoint(endpoint); }I'll ignore stuff that's log or better.The outer loops is O(m). The inner loop is O, making aggregate so far O(nm).We have a call in there to updateNormalTokens() which implies a sorting, which his O(n log). So now we're at O(n log m).Next up we call getAddressRanges() which immediately does another O(n log sort. we're still at O(n log m. It then iterates (linear) and: calls getPrimaryRangeFor() for each. calls calculateNaturalEndpoints for each.The former ends up sorting again, so now we're at O(n log n log m (worse than quadratic).NTS.calculateNaturalEndpoints starts by collecting token meta data for nodes in the DC, by using updateNormalToken, which implies sorting. Woha woha. Now we're at O(n log n log n log m).I might have missed things that are even worse, but this is bad enough to warrant this ticket. To put into perspective, 168 ^ 3 is 4.7 million.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.locator.TokenMetadata.java</file>
      <file type="M">src.java.org.apache.cassandra.locator.NetworkTopologyStrategy.java</file>
    </fixedFiles>
  </bug>
  <bug id="3862" opendate="2012-2-6 00:00:00" fixdate="2012-2-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RowCache misses Updates</summary>
      <description>While performing stress tests to find any race problems for CASSANDRA-2864 I guess I (re-)found one for the standard on-heap row cache.During my stress test I hava lots of threads running with some of them only reading other writing and re-reading the value.This seems to happen: Reader tries to read row A for the first time doing a getTopLevelColumns Row A which is not in the cache yet is updated by Writer. The row is not eagerly read during write (because we want fast writes) so the writer cannot perform a cache update Reader puts the row in the cache which is now missing the updateI already asked this some time ago on the mailing list but unfortunately didn't dig after I got no answer since I assumed that I just missed something. In a way I still do but haven't found any locking mechanism that makes sure that this should not happen.The problem can be reproduced with every run of my stress test. When I restart the server the expected column is there. It's just missing from the cache.To test I have created a patch that merges memtables with the row cache. With the patch the problem is gone.I can also reproduce in 0.8. Haven't checked 1.1 but I haven't found any relevant change their either so I assume the same aplies there.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.RowCacheTest.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.StatusLogger.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.IncomingStreamReader.java</file>
      <file type="M">src.java.org.apache.cassandra.service.CacheService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RowIteratorFactory.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.ParallelCompactionIterable.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionIterable.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamily.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.SerializingCacheProvider.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.SerializingCache.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.IRowCacheProvider.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.InstrumentingCache.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.ICache.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.ConcurrentLinkedHashCacheProvider.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.ConcurrentLinkedHashCache.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionController.java</file>
    </fixedFiles>
  </bug>
  <bug id="3869" opendate="2012-2-7 00:00:00" fixdate="2012-2-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[patch] don&amp;#39;t duplicate ByteBuffers when hashing</summary>
      <description>given how often hashing of ByteBuffers occurs, don't duplicate the ByteBuffer when hashing. (trivial - as the byte array was never copied just the BB wrapper &amp;#8211; but still).</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.utils.FBUtilities.java</file>
    </fixedFiles>
  </bug>
  <bug id="3871" opendate="2012-2-7 00:00:00" fixdate="2012-2-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Turn compression on by default</summary>
      <description>Compression has been available but off by default since 1.0.0. It's enabled in a lot of production environments now, with no major problems found. (Some problems with customizing the block size were found and fixed in the 1.0 releases.)</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.compress.CompressionParameters.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.CFPropDefs.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.CFPropDefs.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3872" opendate="2012-2-7 00:00:00" fixdate="2012-2-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Sub-columns removal is broken in 1.1</summary>
      <description>CASSANDRA-3716 actually broke sub-columns deletion. The reason is that in QueryFilter.isRelevant, we've switched in checking getLocalDeletionTime() only (without looking for isMarkedForDelete). But for columns containers (in this case SuperColumn), the default local deletion time when not deleted is Integer.MIN_VALUE. In other words, a SC with only non-gcable tombstones will be considered as not relevant (while it should).This is caught by two unit tests (RemoveSuperColumnTest and RemoveSubColumnTest) that are failing currently.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.ISortedColumns.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">src.java.org.apache.cassandra.db.AtomicSortedColumns.java</file>
      <file type="M">src.java.org.apache.cassandra.db.AbstractThreadUnsafeSortedColumns.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3873" opendate="2012-2-8 00:00:00" fixdate="2012-2-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh: tab-complete key alias along with column names for ALTER COLUMNFAMILY [name] ALTER</summary>
      <description>This change is appropriate after CASSANDRA-3781.</description>
      <version>1.1.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.cqlhandling.py</file>
      <file type="M">doc.cql.CQL.textile</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug id="3877" opendate="2012-2-8 00:00:00" fixdate="2012-2-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make secondary indexes inherit compression (and maybe other properties) from their base CFS</summary>
      <description>Secondary indexes currently use the defaults for most properties and only inherit a few properties from their base CFS (namely gc_grace and the min/max compaction thresholds currently). It would make sense to have them inherit more properties. At least compression makes sense, but the compaction parameters probably do too (and maybe bf_filter_chance?).In any case, making secondary indexes inherit those probably is trivial, but I think we should also make it so that if the base CF is modified, we mirror the changes to it's secondary indexes.</description>
      <version>1.1.0</version>
      <fixedVersion>Feature/2iIndex</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.index.SecondaryIndexManager.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3879" opendate="2012-2-9 00:00:00" fixdate="2012-2-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[patch] fix typo in cql-selectstatement assert</summary>
      <description>code doesassert keyRestriction != null || keyRestriction.isEquality();where an &amp;&amp; should be used.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.gms.Gossiper.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
    </fixedFiles>
  </bug>
  <bug id="3883" opendate="2012-2-9 00:00:00" fixdate="2012-4-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CFIF WideRowIterator only returns batch size columns</summary>
      <description>Most evident with the word count, where there are 1250 'word1' items in two rows (1000 in one, 250 in another) and it counts 198 with the batch size set to 99.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.thrift.ThriftValidation.java</file>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraServer.java</file>
      <file type="M">src.java.org.apache.cassandra.hadoop.ColumnFamilyRecordReader.java</file>
      <file type="M">src.java.org.apache.cassandra.hadoop.ColumnFamilyInputFormat.java</file>
    </fixedFiles>
  </bug>
  <bug id="3891" opendate="2012-2-12 00:00:00" fixdate="2012-2-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[patch] reduce duplicate lookups, allocations, interaction with threadlocals</summary>
      <description>some trivial reduction of duplicate code for eliminating map lookups, and threadlocal interactions. etc.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraServer.java</file>
      <file type="M">src.java.org.apache.cassandra.db.SystemTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="3904" opendate="2012-2-13 00:00:00" fixdate="2012-2-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>do not generate NPE on aborted stream-out sessions</summary>
      <description>https://issues.apache.org/jira/browse/CASSANDRA-3569?focusedCommentId=13207189&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13207189Attaching patch to make this a friendlier log entry.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamOutSession.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.FileStreamTask.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3907" opendate="2012-2-14 00:00:00" fixdate="2012-2-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support compression using BulkWriter</summary>
      <description>Currently there is no way to enable compression using BulkWriter.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableSimpleUnsortedWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.hadoop.ConfigHelper.java</file>
      <file type="M">src.java.org.apache.cassandra.hadoop.BulkRecordWriter.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3917" opendate="2012-2-15 00:00:00" fixdate="2012-2-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>System test failures in 1.1</summary>
      <description>On branch 1.1, I currently see two system test failures:======================================================================FAIL: system.test_thrift_server.TestMutations.test_get_range_slice_after_deletion----------------------------------------------------------------------Traceback (most recent call last): File "/usr/lib/pymodules/python2.7/nose/case.py", line 187, in runTest self.test(*self.arg) File "/home/mcmanus/Git/cassandra/test/system/test_thrift_server.py", line 1937, in test_get_range_slice_after_deletion assert len(result[0].columns) == 1AssertionErrorand======================================================================FAIL: Test that column ttled expires from KEYS index----------------------------------------------------------------------Traceback (most recent call last): File "/usr/lib/pymodules/python2.7/nose/case.py", line 187, in runTest self.test(*self.arg) File "/home/mcmanus/Git/cassandra/test/system/test_thrift_server.py", line 1908, in test_index_scan_expiring assert len(result) == 1, resultAssertionError: []----------------------------------------------------------------------</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.SuperColumn.java</file>
    </fixedFiles>
  </bug>
  <bug id="3921" opendate="2012-2-15 00:00:00" fixdate="2012-2-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compaction doesn&amp;#39;t clear out expired tombstones from SerializingCache</summary>
      <description>Compaction calls removeDeletedInCache, which looks like this:. public void removeDeletedInCache(DecoratedKey key) { ColumnFamily cachedRow = cfs.getRawCachedRow(key); if (cachedRow != null) ColumnFamilyStore.removeDeleted(cachedRow, gcBefore); }For the SerializingCache, this means it calls removeDeleted on a temporary, deserialized copy, which leaves the cache contents unaffected.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionController.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3922" opendate="2012-2-16 00:00:00" fixdate="2012-2-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>streaming from all (not one) neighbors during rebuild/bootstrap</summary>
      <description>The last round of changes that happened in CASSANDRA-3483 before it went in actually changed behavior - we now stream from ALL neighbors that have a range, rather than just one. This leads to data size explosion.Attaching patch to revert to intended behavior.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.dht.RangeStreamer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3925" opendate="2012-2-16 00:00:00" fixdate="2012-2-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ORDER BY syntax</summary>
      <description>I think we should switch to standard ORDER BY x &amp;#91;DESC&amp;#93; syntax, for several reasons.First, because ORDER &amp;#91;DESC&amp;#93; is not very readable. By that I mean, you have no idea what it means unless you cross reference with the CF definition.Second, because it's not a sufficiently better fit than the SQL syntax to justify inventing our own.Third (and this is the big one) I strongly suspect that we're going to start supporting at least limited run-time ordering in the near future, and this gives us some future proofing while working reasonably well in the meantime: we can simply reject with IRE ORDER BY requests that aren't compatible with the comparator, similarly to what we used to do with unindexed WHERE expressions. (Which is also a good example of us being dragged kicking and screaming into being more flexible at query time...)</description>
      <version>1.1.0</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.Cql.g</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3926" opendate="2012-2-16 00:00:00" fixdate="2012-3-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>all column validator options are not represented in cli help</summary>
      <description>The options added to column validators from CASSANDRA-2530 are not shown as options in the CLI help. I was going to create a column family with a float validator and double checked the help and it wasn't shown. So I just had to double check that I could. Would be nice to have those added to those docs, even though CQL is the way forward.</description>
      <version>1.1.0</version>
      <fixedVersion>Legacy/DocumentationandWebsite</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.resources.org.apache.cassandra.cli.CliHelp.yaml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3931" opendate="2012-2-19 00:00:00" fixdate="2012-2-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>gossipers notion of schema differs from reality as reported by the nodes in question</summary>
      <description>On a 1.1 cluster we happened to notice that nodetool gossipinfo | grep SCHEMA reported disagreement: SCHEMA:59adb24e-f3cd-3e02-97f0-5b395827453f SCHEMA:59adb24e-f3cd-3e02-97f0-5b395827453f SCHEMA:b0d7bab7-c13c-37d9-9adb-8ab8a5b7215d SCHEMA:59adb24e-f3cd-3e02-97f0-5b395827453f SCHEMA:59adb24e-f3cd-3e02-97f0-5b395827453f SCHEMA:59adb24e-f3cd-3e02-97f0-5b395827453f SCHEMA:59adb24e-f3cd-3e02-97f0-5b395827453f SCHEMA:59adb24e-f3cd-3e02-97f0-5b395827453f SCHEMA:59adb24e-f3cd-3e02-97f0-5b395827453f SCHEMA:59adb24e-f3cd-3e02-97f0-5b395827453f SCHEMA:bcdbd318-82df-3518-89e3-6b72227b3f66 SCHEMA:59adb24e-f3cd-3e02-97f0-5b395827453f SCHEMA:59adb24e-f3cd-3e02-97f0-5b395827453f SCHEMA:59adb24e-f3cd-3e02-97f0-5b395827453f SCHEMA:bcdbd318-82df-3518-89e3-6b72227b3f66 SCHEMA:59adb24e-f3cd-3e02-97f0-5b395827453f SCHEMA:59adb24e-f3cd-3e02-97f0-5b395827453f SCHEMA:59adb24e-f3cd-3e02-97f0-5b395827453f SCHEMA:59adb24e-f3cd-3e02-97f0-5b395827453f SCHEMA:59adb24e-f3cd-3e02-97f0-5b395827453fHowever, the result of a thrift describe_ring on the cluster claims they all agree and that b0d7bab7-c13c-37d9-9adb-8ab8a5b7215d is the schema they have.The schemas seem to "actually" propagate; e.g. dropping a keyspace actually drops the keyspace.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.MigrationManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.DefsTable.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Schema.java</file>
    </fixedFiles>
  </bug>
  <bug id="3934" opendate="2012-2-20 00:00:00" fixdate="2012-2-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Short read protection is broken</summary>
      <description>When a read needs to do more than one retry (due to short reads), the originalCount is not preserved by the retry leading to returning more than the requested number of columns.Moreover, when a retried read checks whether more retry is needed, it doesn't compare the number of live column retrieved against the original number of columns requested by the user, but against the number of columns requested during the retry, making it much more likely to actually do one more retry.This catch by the two tests 'short_read_test' and 'short_read_reversed_test' at https://github.com/riptano/cassandra-dtest/blob/master/consistency_test.py that are failing intermittently.</description>
      <version>1.0.8,1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.SliceFromReadCommand.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RetriedSliceFromReadCommand.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3937" opendate="2012-2-21 00:00:00" fixdate="2012-3-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>nodetool describering should report the schema version</summary>
      <description>Specifically to aid in debugging things like CASSANDRA-3931, now that you can't just decode the UUIDs to see which one has the higher timestamp.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeProbe.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageServiceMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
    </fixedFiles>
  </bug>
  <bug id="3940" opendate="2012-2-21 00:00:00" fixdate="2012-2-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>mergeShardsChance deprecated; remove from thrift?</summary>
      <description>Or at least it should be marked deprecated somehow.</description>
      <version>1.1.0</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.SchemaLoader.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.DefsTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.CreateColumnFamilyStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateColumnFamilyStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.CfDef.java</file>
      <file type="M">interface.thrift.gen-java.org.apache.cassandra.thrift.Cassandra.java</file>
      <file type="M">interface.cassandra.thrift</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3946" opendate="2012-2-22 00:00:00" fixdate="2012-4-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>BulkRecordWriter shouldn&amp;#39;t stream any empty data/index files that might be created at end of flush</summary>
      <description>If by chance, we flush sstables during BulkRecordWriter (we have seen it happen), I want to make sure we don't try to stream them.</description>
      <version>1.0.10,1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableSimpleWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableSimpleUnsortedWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.AbstractSSTableSimpleWriter.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3950" opendate="2012-2-23 00:00:00" fixdate="2012-2-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>support trickling fsync() on writes</summary>
      <description>Attaching a patch to support fsync():ing every N megabytes of data written using sequential writers. The motivation is to avoid the kernel flushing out pages in bulk.It makes sense for both platters and SSD:s, but it's particularly good for SSD:s because the negative consequences of fsync():ing more often are much more limited than with platters, and the need is to some extent greater because of the fact that with SSD:s you're much more likely to be e.g. streaming data quickly or compacting quickly, since you're not having to throttle everything as extremely as with platters, and you easily write fast enough for this to be a problem if you're targetting good latency at the outliers.I'm nominating it for 1.1.0 because, if disabled, the probability of this being a regression seems very low.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.util.SequentialWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3954" opendate="2012-2-24 00:00:00" fixdate="2012-3-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Exceptions during start up after schema disagreement</summary>
      <description>Hi,i`ve got schema disaggreement after dropping down keyspace,i`ve switched off one nodes in cluster, after starting i`ve got bunch of these exceptions:ERROR [SSTableBatchOpen:1] 2012-02-24 14:21:00,759 AbstractCassandraDaemon.java (line 134) Fatal exception in thread Thread[SSTableBatchOpen:1,5,main]java.lang.ClassCastException: java.math.BigInteger cannot be cast to java.nio.ByteBuffer at org.apache.cassandra.db.marshal.UTF8Type.compare(UTF8Type.java:27) at org.apache.cassandra.dht.LocalToken.compareTo(LocalToken.java:45) at org.apache.cassandra.db.DecoratedKey.compareTo(DecoratedKey.java:89) at org.apache.cassandra.db.DecoratedKey.compareTo(DecoratedKey.java:38) at java.util.TreeMap.getEntry(TreeMap.java:328) at java.util.TreeMap.containsKey(TreeMap.java:209) at java.util.TreeSet.contains(TreeSet.java:217) at org.apache.cassandra.io.sstable.SSTableReader.load(SSTableReader.java:393) at org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:189) at org.apache.cassandra.io.sstable.SSTableReader$1.run(SSTableReader.java:227) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441) at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303) at java.util.concurrent.FutureTask.run(FutureTask.java:138) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:662)and this one on the end of start up:ERROR [MigrationStage:1] 2012-02-24 14:37:22,750 AbstractCassandraDaemon.java (line 134) Fatal exception in thread Thread[MigrationStage:1,5,main]java.lang.NullPointerException at org.apache.cassandra.db.migration.MigrationHelper.addColumnFamily(MigrationHelper.java:282) at org.apache.cassandra.db.migration.MigrationHelper.addColumnFamily(MigrationHelper.java:216) at org.apache.cassandra.db.DefsTable.mergeColumnFamilies(DefsTable.java:330) at org.apache.cassandra.db.DefsTable.mergeRemoteSchema(DefsTable.java:240) at org.apache.cassandra.service.MigrationManager$1.runMayThrow(MigrationManager.java:124) at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441) at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303) at java.util.concurrent.FutureTask.run(FutureTask.java:138) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:662)Any ideas why they`ve appeared?</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3955" opendate="2012-2-24 00:00:00" fixdate="2012-2-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HintedHandoff won&amp;#39;t compact a single sstable, resulting in repeated log messages</summary>
      <description>First introduced by CASSANDRA-3554, and then mostly solved in CASSANDRA-3733, there is still one special case where the HH log message will repeat every 10 mins for 0 rows: when there have previously been hints delivered to the node, but now only a single sstable exists. Because the we refused to compact a single sstable, and it contains tombstones for the hints, the message repeats.</description>
      <version>1.0.9,1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.HintedHandOffManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3956" opendate="2012-2-24 00:00:00" fixdate="2012-2-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[patch] minor javadoc fixes</summary>
      <description>minor fixes against trunk</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.CassandraDaemon.java</file>
      <file type="M">src.java.org.apache.cassandra.hadoop.pig.CassandraStorage.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Table.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStoreMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.UpdateStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateColumnFamilyStatement.java</file>
    </fixedFiles>
  </bug>
  <bug id="3958" opendate="2012-2-24 00:00:00" fixdate="2012-2-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove random HH delay</summary>
      <description>. // sleep a random amount to stagger handoff delivery from different replicas. // (if we had to wait, then gossiper randomness took care of that for us already.) if (waited == 0) { // use a 'rounded' sleep interval because of a strange bug with windows: CASSANDRA-3375 int sleep = FBUtilities.threadLocalRandom().nextInt(2000) * 30; logger_.debug("Sleeping {}ms to stagger hint delivery", sleep); Thread.sleep(sleep); }This is obsolete now that we have the per-hint configurable delay. And large hint loads (which are the ones that matter most) are going to overlap anyway even with the maximum 60s difference.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.HintedHandOffManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3959" opendate="2012-2-26 00:00:00" fixdate="2012-2-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[patch] report bad meta data field in cli instead of silently ignoring</summary>
      <description>If cli is parsing an^(ARRAY ^(HASH ^(PAIR .. ..) ^(PAIR .. ..)) ^(HASH ...))and a hash pair has a key that is unrecognized, it just ignores and continues.. better to reportpatch does this.for instanceupdate column family cf with column_metadata = [{comparator_type:UTF8Type,column_name:idx,validation_class:IntegerType,index_type:0,index_name:idxname}];comparator_type is not processed, just ignored.(patch against trunk)</description>
      <version>1.1.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cli.CliClient.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3972" opendate="2012-2-28 00:00:00" fixdate="2012-2-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HintedHandoff fails to deliver any hints</summary>
      <description>Summary says it all. Whether in a memtable or sstable, no hints are delivered.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.HintedHandOffManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="3976" opendate="2012-2-29 00:00:00" fixdate="2012-3-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[patch[ don&amp;#39;t compare byte arrays with ==</summary>
      <description>code compares byte arrays with ==, use Arrays.equalspatch against trunk</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.hadoop.ColumnFamilyRecordReader.java</file>
    </fixedFiles>
  </bug>
  <bug id="3986" opendate="2012-3-1 00:00:00" fixdate="2012-3-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cli shouldn&amp;#39;t call FBU.getBroadcastAddress needlessly</summary>
      <description>The cli is calling this, which causes yaml to be loaded, but the broadcast address isn't needed. // adding default data center from SimpleSnitch if (currentStrategyOptions == null || currentStrategyOptions.isEmpty()) { SimpleSnitch snitch = new SimpleSnitch(); Map&lt;String, String&gt; options = new HashMap&lt;String, String&gt;(); options.put(snitch.getDatacenter(FBUtilities.getBroadcastAddress()), "1"); ksDef.setStrategy_options(options); }because SimpleSnitch always returns 'datacenter1'</description>
      <version>1.0.9,1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cli.CliClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="3996" opendate="2012-3-4 00:00:00" fixdate="2012-3-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Keys index skips results</summary>
      <description>While scanning results page if range index meets result already seen in previous result set it decreases columnsRead that causes next iteration to treat columsRead&lt;rowsPerQuery as if last page was not full and scan is done.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.ColumnFamilyStoreTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.keys.KeysSearcher.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4017" opendate="2012-3-8 00:00:00" fixdate="2012-3-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unify migrations</summary>
      <description>Now that we can send a schema as a RowMutation, there's no need to keep separate add/drop/update migration classes around. Let's just send the schema to our counterparts and let them figure out what changed. Currently we have "figure out what changed" code to both generate migrations on the sender, and for application on the target, which adds complexity.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.marshal.DynamicCompositeTypeTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.thrift.ThriftValidationTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.streaming.StreamingTransferTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.service.StorageServiceServerTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.service.StorageServiceClientTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.service.StorageProxyTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.service.RemoveTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.service.MoveTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.service.LeaveAndBootstrapTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.service.EmbeddedCassandraServiceTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.service.CassandraServerTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.service.AntiEntropyServiceTestAbstract.java</file>
      <file type="M">test.unit.org.apache.cassandra.SchemaLoader.java</file>
      <file type="M">test.unit.org.apache.cassandra.locator.SimpleStrategyTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.io.sstable.SSTableTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.io.sstable.SSTableSimpleWriterTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.io.sstable.SSTableReaderTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.io.sstable.LegacySSTableTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.io.LazilyCompactedRowTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.io.CompactSerializerTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.io.BloomFilterTrackerTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.EmbeddedServer.java</file>
      <file type="M">test.unit.org.apache.cassandra.dht.BootStrapperTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.TimeSortTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.TableTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.ScrubTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.RowIterationTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.RowCacheTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.RemoveSuperColumnTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.RemoveSubColumnTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.RemoveColumnTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.RemoveColumnFamilyWithFlush2Test.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.RemoveColumnFamilyWithFlush1Test.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.RemoveColumnFamilyTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.RecoveryManagerTruncateTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.RecoveryManagerTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.RecoveryManager3Test.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.RecoveryManager2Test.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.NameSortTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.MultitableTest.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">src.java.org.apache.cassandra.config.ColumnDefinition.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.KSMetaData.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Schema.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.AlterTableStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateColumnFamilyStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateIndexStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateKeyspaceStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.DropColumnFamilyStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.DropIndexStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.DropKeyspaceStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SchemaAlteringStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.DropIndexStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.QueryProcessor.java</file>
      <file type="M">src.java.org.apache.cassandra.db.DefsTable.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Directories.java</file>
      <file type="M">src.java.org.apache.cassandra.db.migration.AddColumnFamily.java</file>
      <file type="M">src.java.org.apache.cassandra.db.migration.AddKeyspace.java</file>
      <file type="M">src.java.org.apache.cassandra.db.migration.DropColumnFamily.java</file>
      <file type="M">src.java.org.apache.cassandra.db.migration.DropKeyspace.java</file>
      <file type="M">src.java.org.apache.cassandra.db.migration.Migration.java</file>
      <file type="M">src.java.org.apache.cassandra.db.migration.MigrationHelper.java</file>
      <file type="M">src.java.org.apache.cassandra.db.migration.UpdateColumnFamily.java</file>
      <file type="M">src.java.org.apache.cassandra.db.migration.UpdateKeyspace.java</file>
      <file type="M">src.java.org.apache.cassandra.db.SystemTable.java</file>
      <file type="M">src.java.org.apache.cassandra.service.MigrationManager.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraServer.java</file>
      <file type="M">src.java.org.apache.cassandra.thrift.ThriftValidation.java</file>
      <file type="M">test.long.org.apache.cassandra.db.compaction.LongCompactionSpeedTest.java</file>
      <file type="M">test.long.org.apache.cassandra.db.LongTableTest.java</file>
      <file type="M">test.long.org.apache.cassandra.db.MeteredFlusherTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.AbstractSerializationsTester.java</file>
      <file type="M">test.unit.org.apache.cassandra.CleanupHelper.java</file>
      <file type="M">test.unit.org.apache.cassandra.cli.CliTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.config.CFMetaDataTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.config.DatabaseDescriptorTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.config.DefsTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.CleanupTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.ColumnFamilyStoreTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.CommitLogTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.compaction.CompactionsPurgeTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.compaction.CompactionsTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.compaction.OneCompactionTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.CounterMutationTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.KeyCacheTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.KeyCollisionTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.marshal.CompositeTypeTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="4023" opendate="2012-3-8 00:00:00" fixdate="2012-3-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve BloomFilter deserialization performance</summary>
      <description>The difference of startup times between a 0.8.7 cluster and 1.0.7 cluster with the same amount of data is 4x greater in 1.0.7.It seems as though 1.0.7 loads the BloomFilter through a series of reading longs out in a multithreaded process while 0.8.7 reads the entire object.Perhaps we should update the new BloomFilter to do reading in batch as well?</description>
      <version>1.0.9,1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.RowIndexEntry.java</file>
      <file type="M">test.unit.org.apache.cassandra.io.sstable.SSTableReaderTest.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.ByteBufferUtil.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableReader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4033" opendate="2012-3-9 00:00:00" fixdate="2012-3-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh: double wide unicode chars cause incorrect padding in select output</summary>
      <description>CREATE COLUMNFAMILY cf3 (KEY text primary key);INSERT INTO cf3 (KEY, col1, col2) VALUES ('a', '1234 1234 1234 1234', 'abcd');INSERT INTO cf3 (KEY, col1, col2) VALUES ('b', '   ', 'abcd');SELECT * FROM cf3 WHERE key in ('a', 'b');produces this output: KEY | col1 | col2-----+-----------------------------------------------------+------ a | 1234 1234 1234 1234 | abcd b |     | abcdnote the extra spaces before the "love" glyphs.</description>
      <version>1.0.9,1.1.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug id="4042" opendate="2012-3-13 00:00:00" fixdate="2012-3-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>add "caching" to CQL CF options</summary>
      <description>"Caching" option is missing from CQL ColumnFamily options.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql.CreateColumnFamilyStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.CFPropDefs.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.AlterTableStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateColumnFamilyStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.AlterTableStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.CFPropDefs.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Avro.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4067" opendate="2012-3-20 00:00:00" fixdate="2012-3-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Report lifetime compaction throughput</summary>
      <description>Would be useful to be able to monitor total compaction throughput without having to poll frequently enough to make sure we get every CompactionInfo object.</description>
      <version>1.1.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManagerMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="4086" opendate="2012-3-27 00:00:00" fixdate="2012-3-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>decom should shut thrift down</summary>
      <description>If you decom a node an then try to use it, you get nothing but timeouts. Instead let's just kill thrift so intelligent clients can move along.</description>
      <version>1.0.9,1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
    </fixedFiles>
  </bug>
  <bug id="4087" opendate="2012-3-27 00:00:00" fixdate="2012-3-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve out-of-the-box cache settings</summary>
      <description>The default key cache of 2MB is significantly smaller than &lt;= 1.0 (200 rows per CF) and much smaller than most production uses. How about min(5% of the heap, 100MB)?</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">conf.cassandra.yaml</file>
    </fixedFiles>
  </bug>
  <bug id="4088" opendate="2012-3-27 00:00:00" fixdate="2012-3-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Respect 1.0 cache settings as much as possible when upgrading</summary>
      <description>When converting a 1.0 schema to 1.1, we should look at the key and row caches (just whether they are en- or dis-abled) and set the caching setting accordingly. I think right now upgrading means all your row caching is gone until you update it manually.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.config.Avro.java</file>
      <file type="M">src.avro.internode.genavro</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4096" opendate="2012-3-28 00:00:00" fixdate="2012-3-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>mlockall() returned code is ignored w/o assertions</summary>
      <description>We log that mlockall() was successful only based on the lack of an assertion failure, so for anyone running w/o -ea we are lying about mlockall() succeeding.</description>
      <version>1.0.9,1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.utils.CLibrary.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4099" opendate="2012-3-28 00:00:00" fixdate="2012-6-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>IncomingTCPConnection recognizes from by doing socket.getInetAddress() instead of BroadCastAddress</summary>
      <description>change "this.from = socket.getInetAddress()" to understand the broad cast IP, but the problem is we dont know until the first packet is received, this ticket is to work around the problem until it reads the first packet.</description>
      <version>1.0.9,1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.net.IncomingTcpConnection.java</file>
    </fixedFiles>
  </bug>
  <bug id="4110" opendate="2012-4-2 00:00:00" fixdate="2012-4-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Relax path length requirement for non-Windows platforms</summary>
      <description>As described at the bottom of CASSANDRA-2749, we only need to worry about total path length on Windows. For other platforms we only need to check the filename length.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.Directories.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4111" opendate="2012-4-2 00:00:00" fixdate="2012-4-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Serializing cache can cause Segfault in 1.1</summary>
      <description>Rare but this can happen per sure, looks like this issue is after CASSANDRA-3862 hence affectes only 1.1 FreeableMemory old = map.get(key); if (old == null) return false; // see if the old value matches the one we want to replace FreeableMemory mem = serialize(value); if (mem == null) return false; // out of memory. never mind. V oldValue = deserialize(old); boolean success = oldValue.equals(oldToReplace) &amp;&amp; map.replace(key, old, mem); if (success) old.unreference(); else mem.unreference(); return success;in the above code block we deserialize(old) without taking reference to the old memory, this can case seg faults when the old is reclaimed (free is called)Fix is to get the reference just for deserialization V oldValue; // reference old guy before de-serializing old.reference(); try { oldValue = deserialize(old); } finally { old.unreference(); }</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cache.SerializingCache.java</file>
    </fixedFiles>
  </bug>
  <bug id="4128" opendate="2012-4-5 00:00:00" fixdate="2012-4-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>stress tool hangs forever on timeout or error</summary>
      <description>The stress tool hangs forever if it encounters a timeout or exception. CTRL-C will kill it if run from a terminal, but when running it from a script (like a dtest) it hangs the script forever. It would be great for scripting it if a reasonable error code was returned when things go wrong.To duplicate, clear out /var/lib/cassandra and then run "stress --operation=READ".</description>
      <version>1.1.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.StressAction.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.Stress.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4136" opendate="2012-4-10 00:00:00" fixdate="2012-4-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>get_paged_slices doesn&amp;#39;t reset startColumn after first row</summary>
      <description>As an example, consider the WordCount example (see CASSANDRA-3883). WordCountSetup inserts 1000 rows, each with three columns: text3, text4, int1. (Some other miscellaneous columns are inserted in a few rows, but we can ignore them here.)Paging through with get_paged_slice calls with a count of 99, CFRecordReader will first retrieve 33 rows, the last of which we will call K. Then it will attempt to fetch 99 more columns, starting with row K column text4.The bug is that it will only fetch text4 for each subsequent row K+i, instead of returning (K, text4), (K+1, int1), (K+1, int3), (K+1, text4), etc.</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.ColumnFamilyStoreTest.java</file>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraServer.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.service.RangeSliceVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RangeSliceCommand.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.keys.KeysSearcher.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.SliceQueryFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.ExtendedFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4156" opendate="2012-4-16 00:00:00" fixdate="2012-4-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CQL should support CL.TWO</summary>
      <description>CL.TWO was overlooked in creating the CQL language spec. It should probably be added.</description>
      <version>1.1.0</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql.Cql.g</file>
      <file type="M">src.java.org.apache.cassandra.cql3.Cql.g</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4157" opendate="2012-4-16 00:00:00" fixdate="2012-4-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow KS + CF names up to 48 characters</summary>
      <description>CASSANDRA-2749 imposed a 32-character limit on KS and CF names. We can be a little more lenient than that and still be safe for path names (see CASSANDRA-4110).</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.Directories.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateKeyspaceStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateColumnFamilyStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Schema.java</file>
      <file type="M">src.java.org.apache.cassandra.config.KSMetaData.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4161" opendate="2012-4-17 00:00:00" fixdate="2012-4-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CQL 3.0 does not work in cqlsh with uppercase SELECT</summary>
      <description>Uppercase SELECT prevents usage of CQL 3.0 features like ORDER BYExample:select * from test ORDER BY number; # worksSELECT * from test ORDER BY number; # fails</description>
      <version>1.1.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug id="4163" opendate="2012-4-17 00:00:00" fixdate="2012-4-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CQL3 ALTER TABLE command causes NPE</summary>
      <description>To reproduce the problem:./cqlsh --cql3Connected to Test Cluster at localhost:9160.&amp;#91;cqlsh 2.2.0 | Cassandra 1.1.0-rc1-SNAPSHOT | CQL spec 3.0.0 | Thrift protocol 19.30.0&amp;#93;Use HELP for help.cqlsh&gt; CREATE KEYSPACE test34 WITH strategy_class = 'org.apache.cassandra.locator.SimpleStrategy' AND strategy_options:replication_factor='1';cqlsh&gt; USE test34;cqlsh:test34&gt; CREATE TABLE users ( ... password varchar, ... gender varchar, ... session_token varchar, ... state varchar, ... birth_year bigint, ... pk varchar, ... PRIMARY KEY (pk) ... );cqlsh:test34&gt; ALTER TABLE users ADD coupon_code varchar;TSocket read 0 bytes</description>
      <version>1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.AlterTableStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.Cql.g</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="4167" opendate="2012-4-18 00:00:00" fixdate="2012-4-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>nodetool compactionstats displays the compaction&amp;#39;s remaining time</summary>
      <description>nodetool compactionstats allows to display active compactions with their progress (a percentage of their completion).For big compactions (up to a few hundreds of GB), it is sometimes "difficult" to know how much time is left before the compactions ends.The attached patch allows to display the remaining time of active compactions based on the "compaction_througput" parameter.</description>
      <version>1.1.0</version>
      <fixedVersion>Tool/nodetool</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeProbe.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4170" opendate="2012-4-18 00:00:00" fixdate="2012-4-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cql3 ALTER TABLE ALTER TYPE has no effect</summary>
      <description>running the following with cql3:CREATE TABLE test (foo text PRIMARY KEY, bar int);ALTER TABLE test ALTER bar TYPE float;does not actually change the column type of bar. It does under cql2.Note that on the current cassandra-1.1.0 HEAD, this causes an NPE, fixed by CASSANDRA-4163. But even with that applied, the ALTER shown here has no effect.</description>
      <version>1.1.0</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.AlterTableStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4171" opendate="2012-4-18 00:00:00" fixdate="2012-4-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cql3 ALTER TABLE foo WITH default_validation=int has no effect</summary>
      <description>running the following with cql3:CREATE TABLE test (foo text PRIMARY KEY) WITH default_validation=timestamp;ALTER TABLE test WITH default_validation=int;does not actually change the default validation type of the CF. It does under cql2.No error is thrown. Some properties can be successfully changed using ALTER WITH, such as comment and gc_grace_seconds, but I haven't tested all of them. It seems probable that default_validation is the only problematic one, since it's the only (changeable) property which accepts CQL typenames.</description>
      <version>1.1.0</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.CFPropDefs.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>
