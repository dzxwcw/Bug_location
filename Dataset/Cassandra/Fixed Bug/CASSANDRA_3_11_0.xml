<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="CASSANDRA">
  <bug id="12213" opendate="2016-7-15 00:00:00" fixdate="2016-4-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>dtest failure in write_failures_test.TestWriteFailures.test_paxos_any</summary>
      <description>example failure:http://cassci.datastax.com/job/cassandra-3.9_dtest/10/testReport/write_failures_test/TestWriteFailures/test_paxos_anyand:http://cassci.datastax.com/job/cassandra-3.9_dtest/10/testReport/write_failures_test/TestWriteFailures/test_mutation_v3/Failed on CassCI build cassandra-3.9_dtest #10</description>
      <version>3.0.13,3.11.0</version>
      <fixedVersion>Legacy/DistributedMetadata</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">src.java.org.apache.cassandra.schema.SchemaKeyspace.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12233" opendate="2016-7-19 00:00:00" fixdate="2016-2-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cassandra stress should obfuscate password in cmd in graph</summary>
      <description>The graph currently has the entire cmd which will could contain a user / password</description>
      <version>3.11.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.StressGraph.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12235" opendate="2016-7-19 00:00:00" fixdate="2016-7-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>dtest failure in bootstrap_test.TestBootstrap.consistent_range_movement_true_with_ks_rf1_should_succeed_test</summary>
      <description>example failure:http://cassci.datastax.com/job/cassandra-3.8_novnode_dtest/5/testReport/bootstrap_test/TestBootstrap/consistent_range_movement_true_with_ks_rf1_should_succeed_testFailed on CassCI build cassandra-3.8_novnode_dtest #5</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.LegacyLayout.java</file>
    </fixedFiles>
  </bug>
  <bug id="12539" opendate="2016-8-25 00:00:00" fixdate="2016-2-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Empty CommitLog prevents restart</summary>
      <description>A node just crashed (known cause: CASSANDRA-11594) but to my surprise (unlike other time) restarting simply fails.Checking the logs showed:ERROR [main] 2016-08-25 17:05:22,611 JVMStabilityInspector.java:82 - Exiting due to error while processing commit log during initialization.org.apache.cassandra.db.commitlog.CommitLogReplayer$CommitLogReplayException: Could not read commit log descriptor in file /data/cassandra/commitlog/CommitLog-6-1468235564433.log at org.apache.cassandra.db.commitlog.CommitLogReplayer.handleReplayError(CommitLogReplayer.java:650) [apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.commitlog.CommitLogReplayer.recover(CommitLogReplayer.java:327) [apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.commitlog.CommitLogReplayer.recover(CommitLogReplayer.java:148) [apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.commitlog.CommitLog.recover(CommitLog.java:181) [apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.db.commitlog.CommitLog.recover(CommitLog.java:161) [apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:289) [apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:557) [apache-cassandra-3.0.8.jar:3.0.8] at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:685) [apache-cassandra-3.0.8.jar:3.0.8]INFO [main] 2016-08-25 17:08:56,944 YamlConfigurationLoader.java:85 - Configuration location: file:/etc/cassandra/cassandra.yamlDeleting the empty file fixes the problem.</description>
      <version>2.2.9,3.0.11,3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.MemoryMappedSegment.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12676" opendate="2016-9-20 00:00:00" fixdate="2016-3-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Message coalescing regression</summary>
      <description>The default in 2.2+ was to enable TIMEHORIZON message coalescing. After reports of performance regressions after upgrading from 2.1 to 2.2/3.0 we have discovered the issue to be this default.We need to re-test our assumptions on this feature but in the meantime we should default back to disabled.Here is a performance run with and without message coalescing</description>
      <version>3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">NEWS.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12773" opendate="2016-10-11 00:00:00" fixdate="2016-3-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cassandra-stress error for one way SSL</summary>
      <description>CASSANDRA-9325 added keystore/truststore configuration into cassandra-stress. However, for one way ssl (require_client_auth=false), there is no need to pass keystore info into ssloptions. Cassadra-stress errored out:java.lang.RuntimeException: java.io.IOException: Error creating the initializing the SSL Context at org.apache.cassandra.stress.settings.StressSettings.getJavaDriverClient(StressSettings.java:200) at org.apache.cassandra.stress.settings.SettingsSchema.createKeySpacesNative(SettingsSchema.java:79) at org.apache.cassandra.stress.settings.SettingsSchema.createKeySpaces(SettingsSchema.java:69) at org.apache.cassandra.stress.settings.StressSettings.maybeCreateKeyspaces(StressSettings.java:207) at org.apache.cassandra.stress.StressAction.run(StressAction.java:55) at org.apache.cassandra.stress.Stress.main(Stress.java:117) Caused by: java.io.IOException: Error creating the initializing the SSL Context at org.apache.cassandra.security.SSLFactory.createSSLContext(SSLFactory.java:151) at org.apache.cassandra.stress.util.JavaDriverClient.connect(JavaDriverClient.java:128) at org.apache.cassandra.stress.settings.StressSettings.getJavaDriverClient(StressSettings.java:191) ... 5 more Caused by: java.io.IOException: Keystore was tampered with, or password was incorrect at sun.security.provider.JavaKeyStore.engineLoad(JavaKeyStore.java:772) at sun.security.provider.JavaKeyStore$JKS.engineLoad(JavaKeyStore.java:55) at java.security.KeyStore.load(KeyStore.java:1445) at org.apache.cassandra.security.SSLFactory.createSSLContext(SSLFactory.java:129) ... 7 more Caused by: java.security.UnrecoverableKeyException: Password verification failed at sun.security.provider.JavaKeyStore.engineLoad(JavaKeyStore.java:770) ... 10 moreIt's a bug from CASSANDRA-9325. When the keystore is absent, the keystore is assigned to the path of the truststore, but the password isn't taken care.</description>
      <version>2.2.10,3.0.13,3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.SettingsTransport.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12847" opendate="2016-10-27 00:00:00" fixdate="2016-5-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh DESCRIBE output doesn&amp;#39;t properly quote index names</summary>
      <description>CASSANDRA-8365 fixed the CQL grammar so that quoting index names preserves case. The output of DESCRIBE in cqlsh wasn't updated however so this doesn't round-trip properly.</description>
      <version>3.0.14,3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">lib.cassandra-driver-internal-only-3.5.0.post0-d8d0456.zip</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">lib.cassandra-driver-internal-only-3.7.0.post0-2481531.zip</file>
    </fixedFiles>
  </bug>
  <bug id="12876" opendate="2016-11-3 00:00:00" fixdate="2016-2-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Negative mean write latency</summary>
      <description>The mean write latency returned by JMX turns negative every 30 minutes. As the attached screenshots show, the value turns negative every 30 minutes after the startup of the node.We did not experience this behavior in 2.1.16.</description>
      <version>2.2.9,3.0.11,3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>Legacy/Observability</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.metrics.DecayingEstimatedHistogramReservoirTest.java</file>
      <file type="M">src.java.org.apache.cassandra.metrics.DecayingEstimatedHistogramReservoir.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12954" opendate="2016-11-24 00:00:00" fixdate="2016-12-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>system_distributed.view_build_status uses gc_gs of 0, but issues distributed deletes</summary>
      <description>The definition uses CFMetaData.compile() method, intended for non-replicated system-keyspace tables, and doesn't override gc_grace_seconds from 0, but does issue deletes. This can lead to entries in the table not being cleaned up.</description>
      <version>3.11.0</version>
      <fixedVersion>Legacy/DistributedMetadata</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.repair.SystemDistributedKeyspace.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12956" opendate="2016-11-25 00:00:00" fixdate="2016-12-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CL is not replayed on custom 2i exception</summary>
      <description>If during the node shutdown / drain the custom (non-cf) 2i throws an exception, CommitLog will get correctly preserved (segments won't get discarded because segment tracking is correct). However, when it gets replayed on node startup, we're making a decision whether or not to replay the commit log. CL segment starts getting replayed, since there are non-discarded segments and during this process we're checking whether there every individual mutation in commit log is already committed or no. Information about the sstables is taken from live sstables on disk.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.Memtable.java</file>
      <file type="M">test.unit.org.apache.cassandra.index.CustomIndexTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12983" opendate="2016-12-2 00:00:00" fixdate="2016-12-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>NoReplicationTokenAllocator should work with zero replication factor as well.</summary>
      <description>In our production env, when we expand an existing cluster to a new DC, we are doing following steps:1. set replication factor to be 0 for the new DC.2. bootstrap all nodes in the new DC.3. set the replication factor to be 1 and start the rebuild.I find the NoReplicationTokenAllocator does not work with replication factor 0, and this patch will fix it.</description>
      <version>3.11.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.long.org.apache.cassandra.dht.tokenallocator.NoReplicationTokenAllocatorTest.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.tokenallocator.TokenAllocatorFactory.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13004" opendate="2016-12-6 00:00:00" fixdate="2016-6-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Corruption while adding/removing a column to/from the table</summary>
      <description>We had the following schema in production. CREATE TYPE IF NOT EXISTS discord_channels.channel_recipient ( nick text);CREATE TYPE IF NOT EXISTS discord_channels.channel_permission_overwrite ( id bigint, type int, allow_ int, deny int);CREATE TABLE IF NOT EXISTS discord_channels.channels ( id bigint, guild_id bigint, type tinyint, name text, topic text, position int, owner_id bigint, icon_hash text, recipients map&lt;bigint, frozen&lt;channel_recipient&gt;&gt;, permission_overwrites map&lt;bigint, frozen&lt;channel_permission_overwrite&gt;&gt;, bitrate int, user_limit int, last_pin_timestamp timestamp, last_message_id bigint, PRIMARY KEY (id));And then we executed the following alter.ALTER TABLE discord_channels.channels ADD application_id bigint;And one row (that we can tell) got corrupted at the same time and could no longer be read from the Python driver. [E 161206 01:56:58 geventreactor:141] Error decoding response from Cassandra. ver(4); flags(0000); stream(27); op(8); offset(9); len(887); buffer: '\x84\x00\x00\x1b\x08\x00\x00\x03w\x00\x00\x00\x02\x00\x00\x00\x01\x00\x00\x00\x0f\x00\x10discord_channels\x00\x08channels\x00\x02id\x00\x02\x00\x0eapplication_id\x00\x02\x00\x07bitrate\x00\t\x00\x08guild_id\x00\x02\x00\ticon_hash\x00\r\x00\x0flast_message_id\x00\x02\x00\x12last_pin_timestamp\x00\x0b\x00\x04name\x00\r\x00\x08owner_id\x00\x02\x00\x15permission_overwrites\x00!\x00\x02\x000\x00\x10discord_channels\x00\x1cchannel_permission_overwrite\x00\x04\x00\x02id\x00\x02\x00\x04type\x00\t\x00\x06allow_\x00\t\x00\x04deny\x00\t\x00\x08position\x00\t\x00\nrecipients\x00!\x00\x02\x000\x00\x10discord_channels\x00\x11channel_recipient\x00\x01\x00\x04nick\x00\r\x00\x05topic\x00\r\x00\x04type\x00\x14\x00\nuser_limit\x00\t\x00\x00\x00\x01\x00\x00\x00\x08\x03\x8a\x19\x8e\xf8\x82\x00\x01\xff\xff\xff\xff\x00\x00\x00\x04\x00\x00\xfa\x00\x00\x00\x00\x08\x00\x00\xfa\x00\x00\xf8G\xc5\x00\x00\x00\x00\x00\x00\x00\x08\x03\x8b\xc0\xb5nB\x00\x02\x00\x00\x00\x08G\xc5\xffI\x98\xc4\xb4(\x00\x00\x00\x03\x8b\xc0\xa8\xff\xff\xff\xff\x00\x00\x01&lt;\x00\x00\x00\x06\x00\x00\x00\x08\x03\x81L\xea\xfc\x82\x00\n\x00\x00\x00$\x00\x00\x00\x08\x03\x81L\xea\xfc\x82\x00\n\x00\x00\x00\x04\x00\x00\x00\x01\x00\x00\x00\x04\x00\x00\x08\x00\x00\x00\x00\x04\x00\x00\x00\x00\x00\x00\x00\x08\x03\x8a\x1e\xe6\x8b\x80\x00\n\x00\x00\x00$\x00\x00\x00\x08\x03\x8a\x1e\xe6\x8b\x80\x00\n\x00\x00\x00\x04\x00\x00\x00\x00\x00\x00\x00\x040\x07\xf8Q\x00\x00\x00\x04\x00\x00\x00\x00\x00\x00\x00\x08\x03\x8a\x1f\x1b{\x82\x00\x00\x00\x00\x00$\x00\x00\x00\x08\x03\x8a\x1f\x1b{\x82\x00\x00\x00\x00\x00\x04\x00\x00\x00\x00\x00\x00\x00\x04\x00\x07\xf8Q\x00\x00\x00\x04\x10\x00\x00\x00\x00\x00\x00\x08\x03\x8a\x1fH6\x82\x00\x01\x00\x00\x00$\x00\x00\x00\x08\x03\x8a\x1fH6\x82\x00\x01\x00\x00\x00\x04\x00\x00\x00\x00\x00\x00\x00\x04\x00\x05\xe8A\x00\x00\x00\x04\x10\x02\x00\x00\x00\x00\x00\x08\x03\x8a+=\xca\xc0\x00\n\x00\x00\x00$\x00\x00\x00\x08\x03\x8a+=\xca\xc0\x00\n\x00\x00\x00\x04\x00\x00\x00\x00\x00\x00\x00\x04\x00\x00\x08\x00\x00\x00\x00\x04\x00\x00\x00\x00\x00\x00\x00\x08\x03\x8a\x8f\x979\x80\x00\n\x00\x00\x00$\x00\x00\x00\x08\x03\x8a\x8f\x979\x80\x00\n\x00\x00\x00\x04\x00\x00\x00\x00\x00\x00\x00\x04\x00\x00\x00\x00\x00\x00\x00\x04\x00 \x08\x01\x00\x00\x00\x04\xc4\xb4(\x00\xff\xff\xff\xff\x00\x00\x00O[f\x80Q\x07general\x05\xf8G\xc5\xffI\x98\xc4\xb4(\x00\xf8O[f\x80Q\x00\x00\x00\x02\x04\xf8O[f\x80Q\x00\xf8G\xc5\xffI\x98\x01\x00\x00\xf8O[f\x80Q\x00\x00\x00\x00\xf8G\xc5\xffI\x97\xc4\xb4(\x06\x00\xf8O\x7fe\x1fm\x08\x03\x00\x00\x00\x01\x00\x00\x00\x00\x04\x00\x00\x00\x00'And then in cqlsh when trying to read the row we got this. /usr/bin/cqlsh.py:632: DateOverFlowWarning: Some timestamps are larger than Python datetime can represent. Timestamps are displayed in milliseconds from epoch.Traceback (most recent call last): File "/usr/bin/cqlsh.py", line 1301, in perform_simple_statement result = future.result() File "/usr/share/cassandra/lib/cassandra-driver-internal-only-3.5.0.post0-d8d0456.zip/cassandra-driver-3.5.0.post0-d8d0456/cassandra/cluster.py", line 3650, in result raise self._final_exceptionUnicodeDecodeError: 'utf8' codec can't decode byte 0x80 in position 2: invalid start byteWe tried to read the data and it would refuse to read the name column (the UTF8 error) and the last_pin_timestamp column had an absurdly large value.We ended up rewriting the whole row as we had the data in another place and it fixed the problem. However there is clearly a race condition in the schema change sub-system.Any ideas?</description>
      <version>3.0.14,3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>Legacy/DistributedMetadata</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.net.MessageIn.java</file>
      <file type="M">src.java.org.apache.cassandra.service.MigrationManager.java</file>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ReadResponse.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.ColumnFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLogDescriptor.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13008" opendate="2016-12-6 00:00:00" fixdate="2016-2-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add vm.max_map_count StartupCheck</summary>
      <description>It's recommended to set vm.max_map_count to 1048575 (CASSANDRA-3563)When the max_map_count is low, it throws OOM exception, which is hard to link to the real issue of vm.max_map_count.The problem happened when we tried to remove one node, all the other nodes in cluster crashed. As each node was trying to load more local SSTable files for streaming.I would suggest to add a StartupCheck for max_map_count, at least it could give a warning message to help the debug.ERROR [STREAM-IN-] JVMStabilityInspector.java:140 - JVM state determined to be unstable. Exiting forcefully due to:java.lang.OutOfMemoryError: Map failed at sun.nio.ch.FileChannelImpl.map0(Native Method) ~[na:1.8.0_112] at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:937) ~[na:1.8.0_112] at org.apache.cassandra.io.util.ChannelProxy.map(ChannelProxy.java:152) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.io.util.MmappedRegions$State.add(MmappedRegions.java:280) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.io.util.MmappedRegions$State.access$400(MmappedRegions.java:216) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.io.util.MmappedRegions.updateState(MmappedRegions.java:173) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.io.util.MmappedRegions.&lt;init&gt;(MmappedRegions.java:70) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.io.util.MmappedRegions.&lt;init&gt;(MmappedRegions.java:58) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.io.util.MmappedRegions.map(MmappedRegions.java:96) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.io.util.CompressedSegmentedFile.&lt;init&gt;(CompressedSegmentedFile.java:47) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.io.util.CompressedSegmentedFile$Builder.complete(CompressedSegmentedFile.java:132) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.io.util.SegmentedFile$Builder.complete(SegmentedFile.java:177) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.io.util.SegmentedFile$Builder.buildData(SegmentedFile.java:193) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.io.sstable.format.big.BigTableWriter.openFinal(BigTableWriter.java:276) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.io.sstable.format.big.BigTableWriter.access$600(BigTableWriter.java:50) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.io.sstable.format.big.BigTableWriter$TransactionalProxy.doPrepare(BigTableWriter.java:313) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.utils.concurrent.Transactional$AbstractTransactional.prepareToCommit(Transactional.java:173) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.utils.concurrent.Transactional$AbstractTransactional.finish(Transactional.java:184) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.io.sstable.format.SSTableWriter.finish(SSTableWriter.java:213) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.io.sstable.SimpleSSTableMultiWriter.finish(SimpleSSTableMultiWriter.java:56) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.streaming.StreamReceiveTask.received(StreamReceiveTask.java:109) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.streaming.StreamSession.receive(StreamSession.java:599) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.streaming.StreamSession.messageReceived(StreamSession.java:482) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.streaming.ConnectionHandler$IncomingMessageHandler.run(ConnectionHandler.java:296) ~[apache-cassandra-3.0.10.jar:3.0.10] at java.lang.Thread.run(Thread.java:745) [na:1.8.0_112]</description>
      <version>3.0.11,3.11.0</version>
      <fixedVersion>Local/Config</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.service.StartupChecksTest.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StartupChecks.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13034" opendate="2016-12-12 00:00:00" fixdate="2016-12-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move to FastThreadLocalThread and FastThreadLocal</summary>
      <description>(Supersedes/includes CASSANDRA-13033 for 3.X &amp; trunk)We still use ThreadLocal in a couple of places, so I was curious how much faster FastThreadLocal is compared to ThreadLocal. A micro bench tells, that FastThreadLocal has a runtime of ~2.7ns and ThreadLocal of ~4.7ns - about 2ns slower (EDIT: subtracted baseline).However, looking at the implementations it seems that ThreadLocal has more dependent pointer gets than FastThreadLocal. This (CPU cache misses) is not reflected in the artificial benchmark below.The patch migrates all Thread instances (except a few in tests) and all ThreadLocal instances.FastThreadLocalBench with 4 threads on 4 core CPU [java] FastThreadLocalBench.baseline 2 avgt 5 3.023 ± 0.081 ns/op [java] FastThreadLocalBench.fastThreadLocal 2 avgt 5 5.610 ± 0.154 ns/op [java] FastThreadLocalBench.fastThreadLocal 4 avgt 5 5.653 ± 0.042 ns/op [java] FastThreadLocalBench.fastThreadLocal 8 avgt 5 5.763 ± 0.588 ns/op [java] FastThreadLocalBench.fastThreadLocal 12 avgt 5 5.673 ± 0.117 ns/op [java] FastThreadLocalBench.threadLocal 2 avgt 5 7.708 ± 0.723 ns/op [java] FastThreadLocalBench.threadLocal 4 avgt 5 7.604 ± 0.059 ns/op [java] FastThreadLocalBench.threadLocal 8 avgt 5 7.629 ± 0.080 ns/op [java] FastThreadLocalBench.threadLocal 12 avgt 5 7.858 ± 0.483 ns/op</description>
      <version>3.11.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.StressServer.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.operations.userdefined.TokenRangeQuery.java</file>
      <file type="M">test.unit.org.apache.cassandra.utils.TopKSamplerTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.service.RemoveTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.io.sstable.SSTableRewriterTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.io.sstable.IndexSummaryManagerTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.hints.HintsBufferTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.RecoveryManagerTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.concurrent.WaitQueueTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cache.CacheProviderTest.java</file>
      <file type="M">test.microbench.org.apache.cassandra.test.microbench.FastThreadExecutor.java</file>
      <file type="M">test.long.org.apache.cassandra.cql3.ViewLongTest.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.FBUtilities.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.CoalescingStrategies.java</file>
      <file type="M">src.java.org.apache.cassandra.thrift.ThriftSessionManager.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.serializers.TimestampSerializer.java</file>
      <file type="M">src.java.org.apache.cassandra.security.EncryptionUtils.java</file>
      <file type="M">src.java.org.apache.cassandra.security.CipherFactory.java</file>
      <file type="M">src.java.org.apache.cassandra.scheduler.RoundRobinScheduler.java</file>
      <file type="M">src.java.org.apache.cassandra.repair.RepairRunnable.java</file>
      <file type="M">src.java.org.apache.cassandra.net.OutboundTcpConnection.java</file>
      <file type="M">src.java.org.apache.cassandra.io.compress.DeflateCompressor.java</file>
      <file type="M">src.java.org.apache.cassandra.index.sasi.TermIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.hints.EncryptedChecksummedDataInput.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.AsciiType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.AbstractCommitLogService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.AbstractCommitLogSegmentManager.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.functions.ThreadAwareSecurityManager.java</file>
      <file type="M">src.java.org.apache.cassandra.concurrent.NamedThreadFactory.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13053" opendate="2016-12-16 00:00:00" fixdate="2016-3-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>GRANT/REVOKE on table without keyspace performs permissions check incorrectly</summary>
      <description>When a GRANT or REVOKE statement is executed on a table without specifying the keyspace, we attempt to use the client session's keyspace to qualify the resource. This is done when validating the statement, which occurs after checking that the user executing the statement has sufficient permissions. This means that the permissions checking uses an incorrect resource, namely a table with a null keyspace. If that user is a superuser, then no error is encountered as superuser privs implicitly grants all permissions. If the user is not a superuser, then the GRANT or REVOKE fails with an ugly error, regardless of which keyspace the client session is bound to:Unauthorized: Error from server: code=2100 [Unauthorized] message="User admin has no AUTHORIZE permission on &lt;table null.t1&gt; or any of its parents"</description>
      <version>2.2.10,3.0.13,3.11.0</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.PermissionsManagementStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13071" opendate="2016-12-22 00:00:00" fixdate="2016-3-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh copy-from should error out when csv contains invalid data for collections</summary>
      <description>If the csv file contains invalid data for collection types, at the moment the data is imported incorrectly, an error would be a better behavior.For example this table:CREATE TABLE test.test (key text, value frozen&lt;set&lt;text&gt;&gt;, PRIMARY KEY (key)); with this data:"key1","{'test1', 'test2'}""Key2","not_a_set"will be imported by COPY test.test FROM 'test.csv'; without errors but will result in the following data:cqlsh&gt; select * from test.test; key | value------+-------------------- key1 | {'test1', 'test2'} Key2 | {'ot_a_se'}(2 rows)The second row should have been rejected. The reason is that the split function assumes that the first and last characters of the string passed in are parentheses, without actually checking it.</description>
      <version>3.0.12,3.11.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.copyutil.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13090" opendate="2017-1-3 00:00:00" fixdate="2017-2-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Coalescing strategy sleeps too much</summary>
      <description>With the current code maybeSleep is called even if we managed to take maxItems out of the backlog. In this case we should really avoid sleeping because it means that backlog is building up.I'll send a patch shortly.</description>
      <version>2.2.10,3.0.12,3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>Legacy/StreamingandMessaging</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.utils.CoalescingStrategiesTest.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.CoalescingStrategies.java</file>
      <file type="M">src.java.org.apache.cassandra.net.OutboundTcpConnection.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13109" opendate="2017-1-6 00:00:00" fixdate="2017-2-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Lightweight transactions temporarily fail after upgrade from 2.1 to 3.0</summary>
      <description>We've observed this upgrading from 2.1.15 to 3.0.8 and from 2.1.16 to 3.0.10: some lightweight transactions executed on upgraded nodes fail with a read failure. The following conditions seem relevant to this occurring: The transaction must be conditioned on the current value of at least one column, e.g., IF NOT EXISTS transactions don't seem to be affected. There should be a collection column (in our case, a map) defined on the table on which the transaction is executed. The transaction should be executed before sstables on the node are upgraded. The failure does not occur after the sstables have been upgraded (whether via nodetool upgradesstables or effectively via compaction). Upgraded nodes seem to be able to participate in lightweight transactions as long as they're not the coordinator. The values in the row being manipulated by the transaction must have been consistently manipulated by lightweight transactions (perhaps the existence of Paxos state for the partition is somehow relevant?). In 3.0.10, it seems to be necessary to have the partition split across multiple legacy sstables. This was not necessary to reproduce the bug in 3.0.8 or .9.For applications affected by this bug, a possible workaround is to prevent nodes being upgraded from coordinating requests until sstables have been upgraded.We're able to reproduce this when upgrading from 2.1.16 to 3.0.10 with the following steps on a single-node cluster using a mostly pristine cassandra.yaml from the source distribution. Start Cassandra-2.1.16 on the node. Create a table with a collection column and insert some data into it.CREATE KEYSPACE test WITH REPLICATION = {'class': 'SimpleStrategy', 'replication_factor': 1};CREATE TABLE test.test (key TEXT PRIMARY KEY, cas_target TEXT, some_collection MAP&lt;TEXT, TEXT&gt;);INSERT INTO test.test (key, cas_target, some_collection) VALUES ('key', 'value', {}) IF NOT EXISTS; Flush the row to an sstable: nodetool flush. Update the row:UPDATE test.test SET cas_target = 'newvalue', some_collection = {} WHERE key = 'key' IF cas_target = 'value'; Drain the node: nodetool drain Stop the node, upgrade to 3.0.10, and start the node. Attempt to update the row again:UPDATE test.test SET cas_target = 'lastvalue' WHERE key = 'key' IF cas_target = 'newvalue';Using cqlsh, if the error is reproduced, the following output will be returned:$ ./cqlsh &lt;&lt;&lt; "UPDATE test.test SET cas_target = 'newvalue', some_collection = {} WHERE key = 'key' IF cas_target = 'value';"(start: 2016-12-22 10:14:27 EST)&lt;stdin&gt;:2:ReadFailure: Error from server: code=1300 [Replica(s) failed to execute read] message="Operation failed - received 0 responses and 1 failures" info={'failures': 1, 'received_responses': 0, 'required_responses': 1, 'consistency': 'QUORUM'}and the following stack trace will be present in the system log:WARN 15:14:28 Uncaught exception on thread Thread[SharedPool-Worker-10,10,main]: {}java.lang.RuntimeException: java.lang.NullPointerException at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:2476) ~[main/:na] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_101] at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:164) ~[main/:na] at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$LocalSessionFutureTask.run(AbstractLocalAwareExecutorService.java:136) [main/:na] at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:105) [main/:na] at java.lang.Thread.run(Thread.java:745) [na:1.8.0_101]Caused by: java.lang.NullPointerException: null at org.apache.cassandra.db.rows.Row$Merger$ColumnDataReducer.getReduced(Row.java:617) ~[main/:na] at org.apache.cassandra.db.rows.Row$Merger$ColumnDataReducer.getReduced(Row.java:569) ~[main/:na] at org.apache.cassandra.utils.MergeIterator$ManyToOne.consume(MergeIterator.java:220) ~[main/:na] at org.apache.cassandra.utils.MergeIterator$ManyToOne.computeNext(MergeIterator.java:159) ~[main/:na] at org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47) ~[main/:na] at org.apache.cassandra.db.rows.Row$Merger.merge(Row.java:546) ~[main/:na] at org.apache.cassandra.db.rows.UnfilteredRowIterators$UnfilteredRowMergeIterator$MergeReducer.getReduced(UnfilteredRowIterators.java:563) ~[main/:na] at org.apache.cassandra.db.rows.UnfilteredRowIterators$UnfilteredRowMergeIterator$MergeReducer.getReduced(UnfilteredRowIterators.java:527) ~[main/:na] at org.apache.cassandra.utils.MergeIterator$ManyToOne.consume(MergeIterator.java:220) ~[main/:na] at org.apache.cassandra.utils.MergeIterator$ManyToOne.computeNext(MergeIterator.java:159) ~[main/:na] at org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47) ~[main/:na] at org.apache.cassandra.db.rows.UnfilteredRowIterators$UnfilteredRowMergeIterator.computeNext(UnfilteredRowIterators.java:509) ~[main/:na] at org.apache.cassandra.db.rows.UnfilteredRowIterators$UnfilteredRowMergeIterator.computeNext(UnfilteredRowIterators.java:369) ~[main/:na] at org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47) ~[main/:na] at org.apache.cassandra.db.partitions.AbstractBTreePartition.build(AbstractBTreePartition.java:334) ~[main/:na] at org.apache.cassandra.db.partitions.ImmutableBTreePartition.create(ImmutableBTreePartition.java:111) ~[main/:na] at org.apache.cassandra.db.partitions.ImmutableBTreePartition.create(ImmutableBTreePartition.java:94) ~[main/:na] at org.apache.cassandra.db.SinglePartitionReadCommand.add(SinglePartitionReadCommand.java:810) ~[main/:na] at org.apache.cassandra.db.SinglePartitionReadCommand.queryMemtableAndSSTablesInTimestampOrder(SinglePartitionReadCommand.java:760) ~[main/:na] at org.apache.cassandra.db.SinglePartitionReadCommand.queryMemtableAndDiskInternal(SinglePartitionReadCommand.java:519) ~[main/:na] at org.apache.cassandra.db.SinglePartitionReadCommand.queryMemtableAndDisk(SinglePartitionReadCommand.java:496) ~[main/:na] at org.apache.cassandra.db.SinglePartitionReadCommand.queryStorage(SinglePartitionReadCommand.java:358) ~[main/:na] at org.apache.cassandra.db.ReadCommand.executeLocally(ReadCommand.java:394) ~[main/:na] at org.apache.cassandra.service.StorageProxy$LocalReadRunnable.runMayThrow(StorageProxy.java:1794) ~[main/:na] at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:2472) ~[main/:na] ... 5 common frames omittedUnder both 3.0.8 and .9, the nodetool flush and additional UPDATE statement before upgrading to 3.0 are not necessary to reproduce this. In that case (when Cassandra only has to read the data from one sstable?), a different stack trace appears in the log. Here's a sample from 3.0.8: WARN [SharedPool-Worker-3] 2016-12-13 15:19:48,863 AbstractLocalAwareExecutorService.java (line 169) Uncaught exception on thread Thread[SharedPool-Worker-3,5,main]: {}java.lang.RuntimeException: java.lang.IllegalStateException: [ColumnDefinition{name=REDACTED, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=REDACTED2, type=org.apache.cassandra.db.marshal.MapType(org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.UTF8Type), kind=REGULAR, position=-1}] is not a subset of [REDACTED] at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:2453) ~[main/:na] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_101] at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:164) ~[main/:na] at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$LocalSessionFutureTask.run(AbstractLocalAwareExecutorService.java:136) [main/:na] at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:105) [main/:na] at java.lang.Thread.run(Thread.java:745) [na:1.8.0_101]Caused by: java.lang.IllegalStateException: [ColumnDefinition{name=REDACTED, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=REDACTED2, type=org.apache.cassandra.db.marshal.MapType(org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.UTF8Type), kind=REGULAR, position=-1}] is not a subset of [REDACTED] at org.apache.cassandra.db.Columns$Serializer.encodeBitmap(Columns.java:531) ~[main/:na] at org.apache.cassandra.db.Columns$Serializer.serializeSubset(Columns.java:465) ~[main/:na] at org.apache.cassandra.db.rows.UnfilteredSerializer.serialize(UnfilteredSerializer.java:178) ~[main/:na] at org.apache.cassandra.db.rows.UnfilteredSerializer.serialize(UnfilteredSerializer.java:108) ~[main/:na] at org.apache.cassandra.db.rows.UnfilteredSerializer.serialize(UnfilteredSerializer.java:96) ~[main/:na] at org.apache.cassandra.db.rows.UnfilteredRowIteratorSerializer.serialize(UnfilteredRowIteratorSerializer.java:132) ~[main/:na] at org.apache.cassandra.db.rows.UnfilteredRowIteratorSerializer.serialize(UnfilteredRowIteratorSerializer.java:87) ~[main/:na] at org.apache.cassandra.db.rows.UnfilteredRowIteratorSerializer.serialize(UnfilteredRowIteratorSerializer.java:77) ~[main/:na] at org.apache.cassandra.db.partitions.UnfilteredPartitionIterators$Serializer.serialize(UnfilteredPartitionIterators.java:300) ~[main/:na] at org.apache.cassandra.db.ReadResponse$LocalDataResponse.build(ReadResponse.java:134) ~[main/:na] at org.apache.cassandra.db.ReadResponse$LocalDataResponse.&lt;init&gt;(ReadResponse.java:127) ~[main/:na] at org.apache.cassandra.db.ReadResponse$LocalDataResponse.&lt;init&gt;(ReadResponse.java:123) ~[main/:na] at org.apache.cassandra.db.ReadResponse.createDataResponse(ReadResponse.java:65) ~[main/:na] at org.apache.cassandra.db.ReadCommand.createResponse(ReadCommand.java:289) ~[main/:na] at org.apache.cassandra.service.StorageProxy$LocalReadRunnable.runMayThrow(StorageProxy.java:1796) ~[main/:na] at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:2449) ~[main/:na] ... 5 common frames omitted WARN [SharedPool-Worker-1] 2016-12-13 15:19:48,943 AbstractLocalAwareExecutorService.java (line 169) Uncaught exception on thread Thread[SharedPool-Worker-1,5,main]: {}java.lang.IllegalStateException: [ColumnDefinition{name=REDACTED, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=REDACTED2, type=org.apache.cassandra.db.marshal.MapType(org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.UTF8Type), kind=REGULAR, position=-1}] is not a subset of [REDACTED] at org.apache.cassandra.db.Columns$Serializer.encodeBitmap(Columns.java:531) ~[main/:na] at org.apache.cassandra.db.Columns$Serializer.serializeSubset(Columns.java:465) ~[main/:na] at org.apache.cassandra.db.rows.UnfilteredSerializer.serialize(UnfilteredSerializer.java:178) ~[main/:na] at org.apache.cassandra.db.rows.UnfilteredSerializer.serialize(UnfilteredSerializer.java:108) ~[main/:na] at org.apache.cassandra.db.rows.UnfilteredSerializer.serialize(UnfilteredSerializer.java:96) ~[main/:na] at org.apache.cassandra.db.rows.UnfilteredRowIteratorSerializer.serialize(UnfilteredRowIteratorSerializer.java:132) ~[main/:na] at org.apache.cassandra.db.rows.UnfilteredRowIteratorSerializer.serialize(UnfilteredRowIteratorSerializer.java:87) ~[main/:na] at org.apache.cassandra.db.rows.UnfilteredRowIteratorSerializer.serialize(UnfilteredRowIteratorSerializer.java:77) ~[main/:na] at org.apache.cassandra.db.partitions.UnfilteredPartitionIterators$Serializer.serialize(UnfilteredPartitionIterators.java:300) ~[main/:na] at org.apache.cassandra.db.ReadResponse$LocalDataResponse.build(ReadResponse.java:134) ~[main/:na] at org.apache.cassandra.db.ReadResponse$LocalDataResponse.&lt;init&gt;(ReadResponse.java:127) ~[main/:na] at org.apache.cassandra.db.ReadResponse$LocalDataResponse.&lt;init&gt;(ReadResponse.java:123) ~[main/:na] at org.apache.cassandra.db.ReadResponse.createDataResponse(ReadResponse.java:65) ~[main/:na] at org.apache.cassandra.db.ReadCommand.createResponse(ReadCommand.java:289) ~[main/:na] at org.apache.cassandra.db.ReadCommandVerbHandler.doVerb(ReadCommandVerbHandler.java:47) ~[main/:na] at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:67) ~[main/:na] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_101] at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:164) ~[main/:na] at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$LocalSessionFutureTask.run(AbstractLocalAwareExecutorService.java:136) [main/:na] at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:105) [main/:na] at java.lang.Thread.run(Thread.java:745) [na:1.8.0_101]It's not clear to us what changed in 3.0.10 to make this behavior somewhat more difficult to reproduce.We spent some time trying to track down the cause in 3.0.8, and we've identified a very small patch (which I will attach to this issue) that seems to fix it. The problem appears to be that the logic that reads data from legacy sstables can pull range tombstones covering collection columns that weren't requested, which then breaks downstream logic that doesn't expect those tombstones to be present in the data. The patch attempts to include those tombstones only if they're explicitly requested. However, there's enough going on in that logic that it's not clear to us whether the change is safe, so it is definitely in need of review from someone knowledgable about what that area of the code is intended to do.</description>
      <version>3.0.11,3.11.0</version>
      <fixedVersion>Feature/LightweightTransactions</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.LegacyLayout.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13114" opendate="2017-1-9 00:00:00" fixdate="2017-2-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade netty to 4.0.44 to fix memory leak with client encryption</summary>
      <description>https://issues.apache.org/jira/browse/CASSANDRA-12032 updated netty for Cassandra 3.8, but this wasn't backported. Netty 4.0.23, which ships with Cassandra 3.0.x, has some serious bugs around memory handling for SSL connections.It would be nice if both were updated to 4.0.42, a version released this year.4.0.23 makes it impossible for me to run SSL, because nodes run out of memory every ~30 minutes. This was fixed in 4.0.27.</description>
      <version>2.1.17,2.2.9,3.0.11,3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.transport.Message.java</file>
      <file type="M">lib.netty-all-4.0.23.Final.jar</file>
      <file type="M">lib.licenses.netty-all-4.0.23.Final.txt</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="13117" opendate="2017-1-11 00:00:00" fixdate="2017-2-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Dump threads when unit test times out</summary>
      <description>It would be nice to get a thread dump when unit tests time out</description>
      <version>3.0.11,3.11.0</version>
      <fixedVersion>Legacy/Testing</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="13125" opendate="2017-1-16 00:00:00" fixdate="2017-2-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Duplicate rows after upgrading from 2.1.16 to 3.0.10/3.9</summary>
      <description>I found that rows are splitting and duplicated after upgrading the cluster from 2.1.x to 3.0.x.I found the way to reproduce the problem as below.$ ccm create test -v 2.1.16 -n 3 -s Current cluster is now: test$ ccm node1 cqlsh -e "CREATE KEYSPACE test WITH replication = {'class':'SimpleStrategy', 'replication_factor':3}"$ ccm node1 cqlsh -e "CREATE TABLE test.test (id text PRIMARY KEY, value1 set&lt;text&gt;, value2 set&lt;text&gt;);"# Upgrade node1$ for i in 1; do ccm node${i} stop; ccm node${i} setdir -v3.0.10; ccm node${i} start;ccm node${i} nodetool upgradesstables; done# Insert a row through node1(3.0.10)$ ccm node1 cqlsh -e "INSERT INTO test.test (id, value1, value2) values ('aaa', {'aaa', 'bbb'}, {'ccc', 'ddd'});" # Insert a row through node2(2.1.16)$ ccm node2 cqlsh -e "INSERT INTO test.test (id, value1, value2) values ('bbb', {'aaa', 'bbb'}, {'ccc', 'ddd'});" # The row inserted from node1 is splitting$ ccm node1 cqlsh -e "SELECT * FROM test.test ;" id | value1 | value2-----+----------------+---------------- aaa | null | null aaa | {'aaa', 'bbb'} | {'ccc', 'ddd'} bbb | {'aaa', 'bbb'} | {'ccc', 'ddd'}$ for i in 1 2; do ccm node${i} nodetool flush; done# Results of sstable2json of node2. The row inserted from node1(3.0.10) is different from the row inserted from node2(2.1.16).$ ccm node2 json -k test -c testrunning['/home/zzheng/.ccm/test/node2/data0/test/test-5406ee80dbdb11e6a175f57c4c7c85f3/test-test-ka-1-Data.db']-- test-test-ka-1-Data.db -----[{"key": "aaa", "cells": [["","",1484564624769577], ["value1","value2:!",1484564624769576,"t",1484564624], ["value1:616161","",1484564624769577], ["value1:626262","",1484564624769577], ["value2:636363","",1484564624769577], ["value2:646464","",1484564624769577]]},{"key": "bbb", "cells": [["","",1484564634508029], ["value1:_","value1:!",1484564634508028,"t",1484564634], ["value1:616161","",1484564634508029], ["value1:626262","",1484564634508029], ["value2:_","value2:!",1484564634508028,"t",1484564634], ["value2:636363","",1484564634508029], ["value2:646464","",1484564634508029]]}]# Upgrade node2,3$ for i in `seq 2 3`; do ccm node${i} stop; ccm node${i} setdir -v3.0.10; ccm node${i} start;ccm node${i} nodetool upgradesstables; done# After upgrade node2,3, the row inserted from node1 is splitting in node2,3$ ccm node2 cqlsh -e "SELECT * FROM test.test ;" id | value1 | value2-----+----------------+---------------- aaa | null | null aaa | {'aaa', 'bbb'} | {'ccc', 'ddd'} bbb | {'aaa', 'bbb'} | {'ccc', 'ddd'}(3 rows)# Results of sstabledump# node1[ { "partition" : { "key" : [ "aaa" ], "position" : 0 }, "rows" : [ { "type" : "row", "position" : 17, "liveness_info" : { "tstamp" : "2017-01-16T11:03:44.769577Z" }, "cells" : [ { "name" : "value1", "deletion_info" : { "marked_deleted" : "2017-01-16T11:03:44.769576Z", "local_delete_time" : "2017-01-16T11:03:44Z" } }, { "name" : "value1", "path" : [ "aaa" ], "value" : "" }, { "name" : "value1", "path" : [ "bbb" ], "value" : "" }, { "name" : "value2", "deletion_info" : { "marked_deleted" : "2017-01-16T11:03:44.769576Z", "local_delete_time" : "2017-01-16T11:03:44Z" } }, { "name" : "value2", "path" : [ "ccc" ], "value" : "" }, { "name" : "value2", "path" : [ "ddd" ], "value" : "" } ] } ] }, { "partition" : { "key" : [ "bbb" ], "position" : 48 }, "rows" : [ { "type" : "row", "position" : 65, "liveness_info" : { "tstamp" : "2017-01-16T11:03:54.508029Z" }, "cells" : [ { "name" : "value1", "deletion_info" : { "marked_deleted" : "2017-01-16T11:03:54.508028Z", "local_delete_time" : "2017-01-16T11:03:54Z" } }, { "name" : "value1", "path" : [ "aaa" ], "value" : "" }, { "name" : "value1", "path" : [ "bbb" ], "value" : "" }, { "name" : "value2", "deletion_info" : { "marked_deleted" : "2017-01-16T11:03:54.508028Z", "local_delete_time" : "2017-01-16T11:03:54Z" } }, { "name" : "value2", "path" : [ "ccc" ], "value" : "" }, { "name" : "value2", "path" : [ "ddd" ], "value" : "" } ] } ] }] # node2[ { "partition" : { "key" : [ "aaa" ], "position" : 0 }, "rows" : [ { "type" : "row", "position" : 17, "liveness_info" : { "tstamp" : "2017-01-16T11:03:44.769577Z" }, "cells" : [ ] }, { "type" : "row", "position" : 22, "deletion_info" : { "marked_deleted" : "2017-01-16T11:03:44.769576Z", "local_delete_time" : "2017-01-16T11:03:44Z" }, "cells" : [ { "name" : "value1", "path" : [ "aaa" ], "value" : "", "tstamp" : "2017-01-16T11:03:44.769577Z" }, { "name" : "value1", "path" : [ "bbb" ], "value" : "", "tstamp" : "2017-01-16T11:03:44.769577Z" }, { "name" : "value2", "path" : [ "ccc" ], "value" : "", "tstamp" : "2017-01-16T11:03:44.769577Z" }, { "name" : "value2", "path" : [ "ddd" ], "value" : "", "tstamp" : "2017-01-16T11:03:44.769577Z" } ] } ] }, { "partition" : { "key" : [ "bbb" ], "position" : 57 }, "rows" : [ { "type" : "row", "position" : 74, "liveness_info" : { "tstamp" : "2017-01-16T11:03:54.508029Z" }, "cells" : [ { "name" : "value1", "deletion_info" : { "marked_deleted" : "2017-01-16T11:03:54.508028Z", "local_delete_time" : "2017-01-16T11:03:54Z" } }, { "name" : "value1", "path" : [ "aaa" ], "value" : "" }, { "name" : "value1", "path" : [ "bbb" ], "value" : "" }, { "name" : "value2", "deletion_info" : { "marked_deleted" : "2017-01-16T11:03:54.508028Z", "local_delete_time" : "2017-01-16T11:03:54Z" } }, { "name" : "value2", "path" : [ "ccc" ], "value" : "" }, { "name" : "value2", "path" : [ "ddd" ], "value" : "" } ] } ] }]Another example of row splitting is as follows.$ ccm create test2 -v 2.1.16 -n 3 -s Current cluster is now: test2$ ccm node1 cqlsh -e "CREATE KEYSPACE test WITH replication = {'class':'SimpleStrategy', 'replication_factor':3}" $ ccm node1 cqlsh -e "CREATE TABLE test.text_set_set (id text PRIMARY KEY, value1 text, value2 set&lt;text&gt;, value3 set&lt;text&gt;);" $ for i in `seq 1`; do ccm node${i} stop; ccm node${i} setdir -v3.0.10; ccm node${i} start;ccm node${i} nodetool upgradesstables; done $ ccm node1 cqlsh -e "INSERT INTO test.text_set_set (id, value1, value2, value3) values ('aaa', 'aaa', {'aaa', 'bbb'}, {'ccc', 'ddd'});"$ ccm node1 cqlsh -e "SELECT * FROM test.text_set_set;" id | value1 | value2 | value3-----+--------+----------------+---------------- aaa | aaa | null | null aaa | null | {'aaa', 'bbb'} | {'ccc', 'ddd'}(2 rows)As far as I investigated, the occurrence conditions are as follows. Table schema contains multiple collections. Insert a row, which values of the collection column are not null through 3.x node while both 2.1 and 3.x nodes exist in a cluster. Rows in sstables of node which version was 2.1 at the time the row was inserted is splitting after upgrading to 3.x.Thanks.</description>
      <version>3.0.11,3.11.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.LegacyLayout.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13130" opendate="2017-1-17 00:00:00" fixdate="2017-3-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Strange result of several list updates in a single request</summary>
      <description>Let's assume that we have a row with the 'listColumn' column and value {1,2,3,4}.For me it looks logical to expect that the following two pieces of code will ends up with the same result but it isn't so.Code1:UPDATE t SET listColumn[2] = 7, listColumn[2] = 8 WHERE id = 1;Expected result: listColumn={1,2,8,4} Actual result: listColumn={1,2,7,8,4}Code2:UPDATE t SET listColumn[2] = 7 WHERE id = 1;UPDATE t SET listColumn[2] = 8 WHERE id = 1;Expected result: listColumn={1,2,8,4} Actual result: listColumn={1,2,8,4}So the question is why Code1 and Code2 give different results?Looks like Code1 should give the same result as Code2.</description>
      <version>2.2.10,3.0.13,3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.CollectionsTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.UpdateParameters.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.Lists.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13147" opendate="2017-1-24 00:00:00" fixdate="2017-4-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Secondary index query on partition key columns might not return all the rows.</summary>
      <description>A secondary index query on a partition key column will, apparently, not return the empty partitions with static data.The following unit test can be used to reproduce the problem. public void testIndexOnPartitionKeyWithStaticColumnAndNoRows() throws Throwable { createTable("CREATE TABLE %s (pk1 int, pk2 int, c int, s int static, v int, PRIMARY KEY((pk1, pk2), c))"); createIndex("CREATE INDEX ON %s (pk2)"); execute("INSERT INTO %s (pk1, pk2, c, s, v) VALUES (?, ?, ?, ?, ?)", 1, 1, 1, 9, 1); execute("INSERT INTO %s (pk1, pk2, c, s, v) VALUES (?, ?, ?, ?, ?)", 1, 1, 2, 9, 2); execute("INSERT INTO %s (pk1, pk2, s) VALUES (?, ?, ?)", 2, 1, 9); execute("INSERT INTO %s (pk1, pk2, c, s, v) VALUES (?, ?, ?, ?, ?)", 3, 1, 1, 9, 1); assertRows(execute("SELECT * FROM %s WHERE pk2 = ?", 1), row(1, 1, 1, 9, 1), row(1, 1, 2, 9, 2), row(2, 1, null, 9, null), &lt;-- is not returned row(3, 1, 1, 9, 1)); }</description>
      <version>2.1.18,2.2.10,3.0.13,3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>Feature/2iIndex</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.SecondaryIndexTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13152" opendate="2017-1-25 00:00:00" fixdate="2017-2-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>UPDATE on counter columns with empty list as argument in IN disables cluster</summary>
      <description>On a 3 node clusterwith this table (replication factor of 2):CREATE TABLE tracking.item_items_rec_history ( reference_id bigint, country text, portal text, app_name text, recommended_id bigint, counter counter, PRIMARY KEY (reference_id, country, portal, app_name, recommended_id));If I execute UPDATE user_items_rec_history SET counter = counter + 1 WHERE reference_id = 1 AND country = '' AND portal = '' AND app_name = '' AND recommended_id IN ();Take note that the IN is emptyThe cluster starts to malfunction and responds a lot of timeouts to any query.After resetting some of the nodes, the cluster starts to function normally again.</description>
      <version>3.0.11,3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>CQL/Interpreter,Local/SSTable</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.UpdateTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.DeleteTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.ModificationStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13153" opendate="2017-1-25 00:00:00" fixdate="2017-3-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reappeared Data when Mixing Incremental and Full Repairs</summary>
      <description>This happens for both LeveledCompactionStrategy and SizeTieredCompactionStrategy. I've only tested it on Cassandra version 2.2 but it most likely also affects all Cassandra versions after 2.2, if they have anticompaction with full repair.When mixing incremental and full repairs, there are a few scenarios where the Data SSTable is marked as unrepaired and the Tombstone SSTable is marked as repaired. Then if it is past gc_grace, and the tombstone and data has been compacted out on other replicas, the next incremental repair will push the Data to other replicas without the tombstone.Simplified scenario:3 node cluster with RF=3Intial config: Node 1 has data and tombstone in separate SSTables. Node 2 has data and no tombstone. Node 3 has data and tombstone in separate SSTables.Incremental repair (nodetool repair -pr) is run every day so now we have tombstone on each node.Some minor compactions have happened since so data and tombstone get merged to 1 SSTable on Nodes 1 and 3. Node 1 had a minor compaction that merged data with tombstone. 1 SSTable with tombstone. Node 2 has data and tombstone in separate SSTables. Node 3 had a minor compaction that merged data with tombstone. 1 SSTable with tombstone.Incremental repairs keep running every day.Full repairs run weekly (nodetool repair -full -pr). Now there are 2 scenarios where the Data SSTable will get marked as "Unrepaired" while Tombstone SSTable will get marked as "Repaired".Scenario 1: Since the Data and Tombstone SSTable have been marked as "Repaired" and anticompacted, they have had minor compactions with other SSTables containing keys from other ranges. During full repair, if the last node to run it doesn't own this particular key in it's partitioner range, the Data and Tombstone SSTable will get anticompacted and marked as "Unrepaired". Now in the next incremental repair, if the Data SSTable is involved in a minor compaction during the repair but the Tombstone SSTable is not, the resulting compacted SSTable will be marked "Unrepaired" and Tombstone SSTable is marked "Repaired".Scenario 2: Only the Data SSTable had minor compaction with other SSTables containing keys from other ranges after being marked as "Repaired". The Tombstone SSTable was never involved in a minor compaction so therefore all keys in that SSTable belong to 1 particular partitioner range. During full repair, if the last node to run it doesn't own this particular key in it's partitioner range, the Data SSTable will get anticompacted and marked as "Unrepaired". The Tombstone SSTable stays marked as Repaired.Then it’s past gc_grace. Since Node’s #1 and #3 only have 1 SSTable for that key, the tombstone will get compacted out. Node 1 has nothing. Node 2 has data (in unrepaired SSTable) and tombstone (in repaired SSTable) in separate SSTables. Node 3 has nothing.Now when the next incremental repair runs, it will only use the Data SSTable to build the merkle tree since the tombstone SSTable is flagged as repaired and data SSTable is marked as unrepaired. And the data will get repaired against the other two nodes. Node 1 has data. Node 2 has data and tombstone in separate SSTables. Node 3 has data.If a read request hits Node 1 and 3, it will return data. If it hits 1 and 2, or 2 and 3, however, it would return no data.Tested this with single range tokens for simplicity.</description>
      <version>2.2.10,3.0.13,3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>Legacy/Tools,Local/Compaction</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13160" opendate="2017-1-27 00:00:00" fixdate="2017-1-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>batch documentation should note the single partition optimization</summary>
      <description></description>
      <version>3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>Legacy/DocumentationandWebsite</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">doc.source.cql.dml.rst</file>
    </fixedFiles>
  </bug>
  <bug id="13173" opendate="2017-1-31 00:00:00" fixdate="2017-2-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reloading logback.xml does not work</summary>
      <description>Regression of CASSANDRA-12535Reloading of logback.xml is broken by CASSANDRA-12535 because the delegate ReconfigureOnChangeFilter is not properly initialized.(Broken in 3.0.11 + 3.10)</description>
      <version>3.0.11,3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.functions.ThreadAwareSecurityManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13177" opendate="2017-2-2 00:00:00" fixdate="2017-2-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>sstabledump doesn&amp;#39;t handle non-empty partitions with a partition-level deletion correctly</summary>
      <description>If a partition has a partition-level deletion, but still contains rows (with timestamps higher than the deletion), sstabledump will only show the deletion and not the rows.</description>
      <version>3.0.11,3.11.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.JsonTransformer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13180" opendate="2017-2-2 00:00:00" fixdate="2017-2-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Better handling of missing entries in system_schema.columns during startup</summary>
      <description>Like the error in CASSANDRA-12213 and CASSANDRA-12165, it's possible for system_schema.keyspaces and tables to contain entries for a table while system_schema.columns has none. This produces an error during startup, and there's no way for a user to recover from this without restoring from backups.Although this has been seen in the wild on one occasion, the cause is still not entirely known. (It may be due to a concurrent DROP TABLE and ALTER TABLE where a table property is altered.) Until we know the root cause, it makes sense to give users a way to recover from that situation.</description>
      <version>3.0.11,3.11.0</version>
      <fixedVersion>Legacy/DistributedMetadata</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.schema.SchemaKeyspace.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13185" opendate="2017-2-3 00:00:00" fixdate="2017-2-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh COPY doesn&amp;#39;t support dates before 1900 or after 9999</summary>
      <description>Although we fixed this problem for standard queries in CASSANDRA-10625, it still exists for COPY. In CASSANDRA-10625, we replaced datetimes outside of the supported time range with a simple milliseconds-since-epoch long. We may not want to use the same solution for COPY, because we wouldn't be able to load the same data back in through COPY. Having consistency in the format of values and support for loading exported data seems more important for COPY.</description>
      <version>3.0.12,3.11.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.formatting.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13205" opendate="2017-2-9 00:00:00" fixdate="2017-2-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hint related logging should include the IP address of the destination in addition to host ID</summary>
      <description>After the hint rewrite in 3.0, many of the hint related logs now use hostId UUIDs rather than endpoint addresses. This complicates debugging unnecessarily. We should include both.</description>
      <version>3.0.11,3.11.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.hints.HintVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.hints.HintsReader.java</file>
      <file type="M">src.java.org.apache.cassandra.hints.HintsDispatchExecutor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13209" opendate="2017-2-10 00:00:00" fixdate="2017-6-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>test failure in cqlsh_tests.cqlsh_copy_tests.CqlshCopyTest.test_bulk_round_trip_blogposts_with_max_connections</summary>
      <description>example failure:http://cassci.datastax.com/job/cassandra-2.1_dtest/528/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_bulk_round_trip_blogposts_with_max_connectionsError Messageerrors={'127.0.0.4': 'Client request timeout. See Session.execute[_async](timeout)'}, last_host=127.0.0.4-------------------- &gt;&gt; begin captured logging &lt;&lt; --------------------dtest: DEBUG: cluster ccm directory: /tmp/dtest-792s6jdtest: DEBUG: Done setting configuration options:{ 'initial_token': None, 'num_tokens': '32', 'phi_convict_threshold': 5, 'range_request_timeout_in_ms': 10000, 'read_request_timeout_in_ms': 10000, 'request_timeout_in_ms': 10000, 'truncate_request_timeout_in_ms': 10000, 'write_request_timeout_in_ms': 10000}dtest: DEBUG: removing ccm cluster test at: /tmp/dtest-792s6jdtest: DEBUG: clearing ssl stores from [/tmp/dtest-792s6j] directorydtest: DEBUG: cluster ccm directory: /tmp/dtest-uNMsuWdtest: DEBUG: Done setting configuration options:{ 'initial_token': None, 'num_tokens': '32', 'phi_convict_threshold': 5, 'range_request_timeout_in_ms': 10000, 'read_request_timeout_in_ms': 10000, 'request_timeout_in_ms': 10000, 'truncate_request_timeout_in_ms': 10000, 'write_request_timeout_in_ms': 10000}cassandra.policies: INFO: Using datacenter 'datacenter1' for DCAwareRoundRobinPolicy (via host '127.0.0.1'); if incorrect, please specify a local_dc to the constructor, or limit contact points to local cluster nodescassandra.cluster: INFO: New Cassandra host &lt;Host: 127.0.0.3 datacenter1&gt; discoveredcassandra.cluster: INFO: New Cassandra host &lt;Host: 127.0.0.2 datacenter1&gt; discoveredcassandra.cluster: INFO: New Cassandra host &lt;Host: 127.0.0.5 datacenter1&gt; discoveredcassandra.cluster: INFO: New Cassandra host &lt;Host: 127.0.0.4 datacenter1&gt; discovereddtest: DEBUG: Running stress with user profile /home/automaton/cassandra-dtest/cqlsh_tests/blogposts.yaml--------------------- &gt;&gt; end captured logging &lt;&lt; ---------------------Stacktrace File "/usr/lib/python2.7/unittest/case.py", line 329, in run testMethod() File "/home/automaton/cassandra-dtest/dtest.py", line 1090, in wrapped f(obj) File "/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py", line 2571, in test_bulk_round_trip_blogposts_with_max_connections copy_from_options={'NUMPROCESSES': 2}) File "/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py", line 2500, in _test_bulk_round_trip num_records = create_records() File "/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py", line 2473, in create_records ret = rows_to_list(self.session.execute(count_statement))[0][0] File "/home/automaton/src/cassandra-driver/cassandra/cluster.py", line 1998, in execute return self.execute_async(query, parameters, trace, custom_payload, timeout, execution_profile, paging_state).result() File "/home/automaton/src/cassandra-driver/cassandra/cluster.py", line 3784, in result raise self._final_exception"errors={'127.0.0.4': 'Client request timeout. See Session.execute[_async](timeout)'}, last_host=127.0.0.4\n-------------------- &gt;&gt; begin captured logging &lt;&lt; --------------------\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-792s6j\ndtest: DEBUG: Done setting configuration options:\n{ 'initial_token': None,\n 'num_tokens': '32',\n 'phi_convict_threshold': 5,\n 'range_request_timeout_in_ms': 10000,\n 'read_request_timeout_in_ms': 10000,\n 'request_timeout_in_ms': 10000,\n 'truncate_request_timeout_in_ms': 10000,\n 'write_request_timeout_in_ms': 10000}\ndtest: DEBUG: removing ccm cluster test at: /tmp/dtest-792s6j\ndtest: DEBUG: clearing ssl stores from [/tmp/dtest-792s6j] directory\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-uNMsuW\ndtest: DEBUG: Done setting configuration options:\n{ 'initial_token': None,\n 'num_tokens': '32',\n 'phi_convict_threshold': 5,\n 'range_request_timeout_in_ms': 10000,\n 'read_request_timeout_in_ms': 10000,\n 'request_timeout_in_ms': 10000,\n 'truncate_request_timeout_in_ms': 10000,\n 'write_request_timeout_in_ms': 10000}\ncassandra.policies: INFO: Using datacenter 'datacenter1' for DCAwareRoundRobinPolicy (via host '127.0.0.1'); if incorrect, please specify a local_dc to the constructor, or limit contact points to local cluster nodes\ncassandra.cluster: INFO: New Cassandra host &lt;Host: 127.0.0.3 datacenter1&gt; discovered\ncassandra.cluster: INFO: New Cassandra host &lt;Host: 127.0.0.2 datacenter1&gt; discovered\ncassandra.cluster: INFO: New Cassandra host &lt;Host: 127.0.0.5 datacenter1&gt; discovered\ncassandra.cluster: INFO: New Cassandra host &lt;Host: 127.0.0.4 datacenter1&gt; discovered\ndtest: DEBUG: Running stress with user profile /home/automaton/cassandra-dtest/cqlsh_tests/blogposts.yaml\n--------------------- &gt;&gt; end captured logging &lt;&lt; ---------------------"</description>
      <version>2.2.10,3.0.14,3.11.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.copyutil.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13218" opendate="2017-2-14 00:00:00" fixdate="2017-5-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Duration validation error is unclear in case of overflow.</summary>
      <description>If a user try to insert a duration with a number of months or days that cannot fit in an int (for example: 9223372036854775807mo1d), the error message is confusing.</description>
      <version>3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.CreateTest.java</file>
      <file type="M">src.java.org.apache.cassandra.serializers.DurationSerializer.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.DurationType.java</file>
      <file type="M">doc.source.cql.types.rst</file>
      <file type="M">doc.native.protocol.v5.spec</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13236" opendate="2017-2-17 00:00:00" fixdate="2017-5-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>corrupt flag error after upgrade from 2.2 to 3.0.10</summary>
      <description>After upgrade from 2.2.5 to 3.0.9/10 we're getting a bunch of errors like this:ERROR [SharedPool-Worker-1] 2017-02-17 12:58:43,859 Message.java:617 - Unexpected exception during request; channel = [id: 0xa8b98684, /10.0.70.104:56814 =&gt; /10.0.80.24:9042]java.io.IOError: java.io.IOException: Corrupt flags value for unfiltered partition (isStatic flag set): 160 at org.apache.cassandra.db.rows.UnfilteredRowIteratorSerializer$1.computeNext(UnfilteredRowIteratorSerializer.java:222) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.db.rows.UnfilteredRowIteratorSerializer$1.computeNext(UnfilteredRowIteratorSerializer.java:210) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.db.transform.BaseRows.hasNext(BaseRows.java:129) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.cql3.statements.SelectStatement.processPartition(SelectStatement.java:749) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.cql3.statements.SelectStatement.process(SelectStatement.java:711) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.cql3.statements.SelectStatement.processResults(SelectStatement.java:400) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:265) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:224) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:76) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:206) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.cql3.QueryProcessor.processPrepared(QueryProcessor.java:487) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.cql3.QueryProcessor.processPrepared(QueryProcessor.java:464) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.transport.messages.ExecuteMessage.execute(ExecuteMessage.java:130) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:513) [apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:407) [apache-cassandra-3.0.10.jar:3.0.10] at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105) [netty-all-4.0.23.Final.jar:4.0.23.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:333) [netty-all-4.0.23.Final.jar:4.0.23.Final] at io.netty.channel.AbstractChannelHandlerContext.access$700(AbstractChannelHandlerContext.java:32) [netty-all-4.0.23.Final.jar:4.0.23.Final] at io.netty.channel.AbstractChannelHandlerContext$8.run(AbstractChannelHandlerContext.java:324) [netty-all-4.0.23.Final.jar:4.0.23.Final] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_72] at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:164) [apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:105) [apache-cassandra-3.0.10.jar:3.0.10] at java.lang.Thread.run(Thread.java:745) [na:1.8.0_72]Caused by: java.io.IOException: Corrupt flags value for unfiltered partition (isStatic flag set): 160 at org.apache.cassandra.db.rows.UnfilteredSerializer.deserialize(UnfilteredSerializer.java:374) ~[apache-cassandra-3.0.10.jar:3.0.10] at org.apache.cassandra.db.rows.UnfilteredRowIteratorSerializer$1.computeNext(UnfilteredRowIteratorSerializer.java:217) ~[apache-cassandra-3.0.10.jar:3.0.10] ... 23 common frames omitted</description>
      <version>3.0.14,3.11.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.columniterator.AbstractSSTableIterator.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13238" opendate="2017-2-17 00:00:00" fixdate="2017-3-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add actual row output to assertEmpty error message</summary>
      <description>We have several issues popping up every now and then that are hard to debug and the test failure messages aren't entirely helpful, for example: java.lang.AssertionError: Expected empty result but got 1 rows:It could be much better if we could have an actual output (what exactly the row that got returned appended to it:java.lang.AssertionError: Expected empty result but got 1 rows: [row(value=null)]The nice side-effect of this change is that now we will have a helper method that can nicely turn an UntypedResultSet into String (I apologise if I did overlooked one).</description>
      <version>3.0.13,3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.CQLTester.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13247" opendate="2017-2-22 00:00:00" fixdate="2017-3-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>index on udt built failed and no data could be inserted</summary>
      <description>index on udt built failed and no data could be insertedsteps to reproduce:CREATE KEYSPACE ks1 WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '2'} AND durable_writes = true;CREATE TYPE ks1.address ( street text, city text, zip_code int, phones set&lt;text&gt;);CREATE TYPE ks1.fullname ( firstname text, lastname text);CREATE TABLE ks1.users ( id uuid PRIMARY KEY, addresses map&lt;text, frozen&lt;address&gt;&gt;, age int, direct_reports set&lt;frozen&lt;fullname&gt;&gt;, name fullname) WITH bloom_filter_fp_chance = 0.01 AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'} AND comment = '' AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'} AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'} AND crc_check_chance = 1.0 AND dclocal_read_repair_chance = 0.1 AND default_time_to_live = 0 AND gc_grace_seconds = 864000 AND max_index_interval = 2048 AND memtable_flush_period_in_ms = 0 AND min_index_interval = 128 AND read_repair_chance = 0.0 AND speculative_retry = '99PERCENTILE';SELECT * FROM users where name = { firstname : 'first' , lastname : 'last'} allow filtering;ReadFailure: Error from server: code=1300 &amp;#91;Replica(s) failed to execute read&amp;#93; message="Operation failed - received 0 responses and 1 failures" info={'failures': 1, 'received_responses': 0, 'required_responses': 1, 'consistency': 'ONE'}WARN &amp;#91;ReadStage-2&amp;#93; 2017-02-22 16:59:33,392 AbstractLocalAwareExecutorService.java:169 - Uncaught exception on thread Thread&amp;#91;ReadStage-2,5,main&amp;#93;: {}java.lang.AssertionError: Only CONTAINS and CONTAINS_KEY are supported for 'complex' types at org.apache.cassandra.db.filter.RowFilter$SimpleExpression.isSatisfiedBy(RowFilter.java:683) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.filter.RowFilter$CQLFilter$1IsSatisfiedFilter.applyToRow(RowFilter.java:303) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.transform.BaseRows.applyOne(BaseRows.java:120) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.transform.BaseRows.add(BaseRows.java:110) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.transform.UnfilteredRows.add(UnfilteredRows.java:41) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.transform.Transformation.add(Transformation.java:162) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.transform.Transformation.apply(Transformation.java:128) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.filter.RowFilter$CQLFilter$1IsSatisfiedFilter.applyToPartition(RowFilter.java:292) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.filter.RowFilter$CQLFilter$1IsSatisfiedFilter.applyToPartition(RowFilter.java:281) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.transform.BasePartitions.hasNext(BasePartitions.java:96) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.partitions.UnfilteredPartitionIterators$Serializer.serialize(UnfilteredPartitionIterators.java:289) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.ReadResponse$LocalDataResponse.build(ReadResponse.java:145) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.ReadResponse$LocalDataResponse.&lt;init&gt;(ReadResponse.java:138) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.ReadResponse$LocalDataResponse.&lt;init&gt;(ReadResponse.java:134) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.ReadResponse.createDataResponse(ReadResponse.java:76) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.ReadCommand.createResponse(ReadCommand.java:323) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.service.StorageProxy$LocalReadRunnable.runMayThrow(StorageProxy.java:1803) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:2486) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~&amp;#91;na:1.8.0_121&amp;#93; at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:164) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$LocalSessionFutureTask.run(AbstractLocalAwareExecutorService.java:136) &amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:109) &amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at java.lang.Thread.run(Thread.java:745) &amp;#91;na:1.8.0_121&amp;#93;CREATE INDEX users_name_idx ON ks1.users (name);ERROR &amp;#91;CompactionExecutor:776&amp;#93; 2017-02-22 16:49:41,934 CassandraDaemon.java:226 - Exception in thread Thread&amp;#91;CompactionExecutor:776,1,main&amp;#93;java.lang.RuntimeException: null for ks: ks1, table: users.users_name_idx at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1316) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.index.internal.CassandraIndex.insert(CassandraIndex.java:531) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.index.internal.CassandraIndex.access$100(CassandraIndex.java:72) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.index.internal.CassandraIndex$1.indexCell(CassandraIndex.java:444) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.index.internal.CassandraIndex$1.indexCells(CassandraIndex.java:436) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.index.internal.CassandraIndex$1.insertRow(CassandraIndex.java:386) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.index.SecondaryIndexManager.lambda$indexPartition$17(SecondaryIndexManager.java:552) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at java.lang.Iterable.forEach(Iterable.java:75) ~&amp;#91;na:1.8.0_121&amp;#93; at org.apache.cassandra.index.SecondaryIndexManager.indexPartition(SecondaryIndexManager.java:552) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.Keyspace.indexPartition(Keyspace.java:566) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.index.internal.CollatedViewIndexBuilder.build(CollatedViewIndexBuilder.java:70) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.compaction.CompactionManager$12.run(CompactionManager.java:1468) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~&amp;#91;na:1.8.0_121&amp;#93; at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~&amp;#91;na:1.8.0_121&amp;#93; at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~&amp;#91;na:1.8.0_121&amp;#93; at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) &amp;#91;na:1.8.0_121&amp;#93; at java.lang.Thread.run(Thread.java:745) &amp;#91;na:1.8.0_121&amp;#93;Caused by: java.nio.BufferUnderflowException: null at java.nio.Buffer.nextGetIndex(Buffer.java:506) ~&amp;#91;na:1.8.0_121&amp;#93; at java.nio.HeapByteBuffer.getInt(HeapByteBuffer.java:361) ~&amp;#91;na:1.8.0_121&amp;#93; at org.apache.cassandra.db.marshal.TupleType.compareCustom(TupleType.java:109) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.marshal.AbstractType.compare(AbstractType.java:159) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.dht.LocalPartitioner$LocalToken.compareTo(LocalPartitioner.java:139) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.dht.LocalPartitioner$LocalToken.compareTo(LocalPartitioner.java:120) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.DecoratedKey.compareTo(DecoratedKey.java:85) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.DecoratedKey.compareTo(DecoratedKey.java:39) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at java.util.concurrent.ConcurrentSkipListMap.cpr(ConcurrentSkipListMap.java:655) ~&amp;#91;na:1.8.0_121&amp;#93; at java.util.concurrent.ConcurrentSkipListMap.doGet(ConcurrentSkipListMap.java:794) ~&amp;#91;na:1.8.0_121&amp;#93; at java.util.concurrent.ConcurrentSkipListMap.get(ConcurrentSkipListMap.java:1546) ~&amp;#91;na:1.8.0_121&amp;#93; at org.apache.cassandra.db.Memtable.put(Memtable.java:234) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1303) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; ... 16 common frames omittedERROR &amp;#91;SecondaryIndexManagement:3&amp;#93; 2017-02-22 16:49:41,934 CassandraDaemon.java:226 - Exception in thread Thread&amp;#91;SecondaryIndexManagement:3,5,main&amp;#93;java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.RuntimeException: null for ks: ks1, table: users.users_name_idx at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:403) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.index.internal.CassandraIndex.buildBlocking(CassandraIndex.java:715) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.index.internal.CassandraIndex.lambda$getBuildIndexTask$5(CassandraIndex.java:685) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~&amp;#91;na:1.8.0_121&amp;#93; at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~&amp;#91;na:1.8.0_121&amp;#93; at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) &amp;#91;na:1.8.0_121&amp;#93; at java.lang.Thread.run(Thread.java:745) &amp;#91;na:1.8.0_121&amp;#93;Caused by: java.util.concurrent.ExecutionException: java.lang.RuntimeException: null for ks: ks1, table: users.users_name_idx at java.util.concurrent.FutureTask.report(FutureTask.java:122) ~&amp;#91;na:1.8.0_121&amp;#93; at java.util.concurrent.FutureTask.get(FutureTask.java:192) ~&amp;#91;na:1.8.0_121&amp;#93; at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:399) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; ... 6 common frames omittedCaused by: java.lang.RuntimeException: null for ks: ks1, table: users.users_name_idx at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1316) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.index.internal.CassandraIndex.insert(CassandraIndex.java:531) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.index.internal.CassandraIndex.access$100(CassandraIndex.java:72) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.index.internal.CassandraIndex$1.indexCell(CassandraIndex.java:444) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.index.internal.CassandraIndex$1.indexCells(CassandraIndex.java:436) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.index.internal.CassandraIndex$1.insertRow(CassandraIndex.java:386) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.index.SecondaryIndexManager.lambda$indexPartition$17(SecondaryIndexManager.java:552) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at java.lang.Iterable.forEach(Iterable.java:75) ~&amp;#91;na:1.8.0_121&amp;#93; at org.apache.cassandra.index.SecondaryIndexManager.indexPartition(SecondaryIndexManager.java:552) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.Keyspace.indexPartition(Keyspace.java:566) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.index.internal.CollatedViewIndexBuilder.build(CollatedViewIndexBuilder.java:70) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.compaction.CompactionManager$12.run(CompactionManager.java:1468) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~&amp;#91;na:1.8.0_121&amp;#93; ... 4 common frames omittedCaused by: java.nio.BufferUnderflowException: null at java.nio.Buffer.nextGetIndex(Buffer.java:506) ~&amp;#91;na:1.8.0_121&amp;#93; at java.nio.HeapByteBuffer.getInt(HeapByteBuffer.java:361) ~&amp;#91;na:1.8.0_121&amp;#93; at org.apache.cassandra.db.marshal.TupleType.compareCustom(TupleType.java:109) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.marshal.AbstractType.compare(AbstractType.java:159) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.dht.LocalPartitioner$LocalToken.compareTo(LocalPartitioner.java:139) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.dht.LocalPartitioner$LocalToken.compareTo(LocalPartitioner.java:120) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.DecoratedKey.compareTo(DecoratedKey.java:85) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.DecoratedKey.compareTo(DecoratedKey.java:39) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at java.util.concurrent.ConcurrentSkipListMap.cpr(ConcurrentSkipListMap.java:655) ~&amp;#91;na:1.8.0_121&amp;#93; at java.util.concurrent.ConcurrentSkipListMap.doGet(ConcurrentSkipListMap.java:794) ~&amp;#91;na:1.8.0_121&amp;#93; at java.util.concurrent.ConcurrentSkipListMap.get(ConcurrentSkipListMap.java:1546) ~&amp;#91;na:1.8.0_121&amp;#93; at org.apache.cassandra.db.Memtable.put(Memtable.java:234) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1303) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; ... 16 common frames omittedSELECT * FROM users where name = { firstname : 'first' , lastname : 'last'};ReadFailure: Error from server: code=1300 &amp;#91;Replica(s) failed to execute read&amp;#93; message="Operation failed - received 0 responses and 1 failures" info={'failures': 1, 'received_responses': 0, 'required_responses': 1, 'consistency': 'ONE'}WARN &amp;#91;ReadStage-2&amp;#93; 2017-02-22 16:55:43,139 AbstractLocalAwareExecutorService.java:169 - Uncaught exception on thread Thread&amp;#91;ReadStage-2,5,main&amp;#93;: {}java.lang.RuntimeException: org.apache.cassandra.index.IndexNotAvailableException: The secondary index 'users_name_idx' is not yet available at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:2490) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~&amp;#91;na:1.8.0_121&amp;#93; at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:164) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$LocalSessionFutureTask.run(AbstractLocalAwareExecutorService.java:136) &amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:109) &amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at java.lang.Thread.run(Thread.java:745) &amp;#91;na:1.8.0_121&amp;#93;Caused by: org.apache.cassandra.index.IndexNotAvailableException: The secondary index 'users_name_idx' is not yet available at org.apache.cassandra.db.ReadCommand.executeLocally(ReadCommand.java:390) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.service.StorageProxy$LocalReadRunnable.runMayThrow(StorageProxy.java:1801) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:2486) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; ... 5 common frames omittedinsert into users (id, name) values (uuid(), {firstname: 'a', lastname: 'b'});WriteFailure: Error from server: code=1500 &amp;#91;Replica(s) failed to execute write&amp;#93; message="Operation failed - received 0 responses and 1 failures" info={'failures': 1, 'received_responses': 0, 'required_responses': 1, 'consistency': 'ONE'}ERROR &amp;#91;MutationStage-2&amp;#93; 2017-02-22 17:04:34,355 StorageProxy.java:1353 - Failed to apply mutation locally : {}java.lang.RuntimeException: null for ks: ks1, table: users.users_name_idx for ks: ks1, table: users at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1316) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.Keyspace.apply(Keyspace.java:526) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.Keyspace.apply(Keyspace.java:396) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.Mutation.applyFuture(Mutation.java:215) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.Mutation.apply(Mutation.java:227) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.Mutation.apply(Mutation.java:241) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.service.StorageProxy$8.runMayThrow(StorageProxy.java:1347) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.service.StorageProxy$LocalMutationRunnable.run(StorageProxy.java:2539) &amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) &amp;#91;na:1.8.0_121&amp;#93; at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:164) &amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$LocalSessionFutureTask.run(AbstractLocalAwareExecutorService.java:136) &amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:109) &amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at java.lang.Thread.run(Thread.java:745) &amp;#91;na:1.8.0_121&amp;#93;Caused by: java.lang.RuntimeException: null for ks: ks1, table: users.users_name_idx at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1316) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.index.internal.CassandraIndex.insert(CassandraIndex.java:531) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.index.internal.CassandraIndex.access$100(CassandraIndex.java:72) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.index.internal.CassandraIndex$1.indexCell(CassandraIndex.java:444) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.index.internal.CassandraIndex$1.indexCells(CassandraIndex.java:436) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.index.internal.CassandraIndex$1.insertRow(CassandraIndex.java:386) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.index.SecondaryIndexManager$WriteTimeTransaction.onInserted(SecondaryIndexManager.java:808) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.partitions.AtomicBTreePartition$RowUpdater.apply(AtomicBTreePartition.java:335) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.partitions.AtomicBTreePartition$RowUpdater.apply(AtomicBTreePartition.java:295) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.utils.btree.BTree.buildInternal(BTree.java:137) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.utils.btree.BTree.build(BTree.java:119) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.utils.btree.BTree.update(BTree.java:175) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.partitions.AtomicBTreePartition.addAllWithSizeDelta(AtomicBTreePartition.java:156) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.Memtable.put(Memtable.java:258) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1303) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; ... 12 common frames omittedCaused by: java.nio.BufferUnderflowException: null at java.nio.Buffer.nextGetIndex(Buffer.java:506) ~&amp;#91;na:1.8.0_121&amp;#93; at java.nio.HeapByteBuffer.getInt(HeapByteBuffer.java:361) ~&amp;#91;na:1.8.0_121&amp;#93; at org.apache.cassandra.db.marshal.TupleType.compareCustom(TupleType.java:109) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.marshal.AbstractType.compare(AbstractType.java:159) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.dht.LocalPartitioner$LocalToken.compareTo(LocalPartitioner.java:139) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.dht.LocalPartitioner$LocalToken.compareTo(LocalPartitioner.java:120) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.DecoratedKey.compareTo(DecoratedKey.java:85) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.DecoratedKey.compareTo(DecoratedKey.java:39) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at java.util.concurrent.ConcurrentSkipListMap.cpr(ConcurrentSkipListMap.java:655) ~&amp;#91;na:1.8.0_121&amp;#93; at java.util.concurrent.ConcurrentSkipListMap.doGet(ConcurrentSkipListMap.java:794) ~&amp;#91;na:1.8.0_121&amp;#93; at java.util.concurrent.ConcurrentSkipListMap.get(ConcurrentSkipListMap.java:1546) ~&amp;#91;na:1.8.0_121&amp;#93; at org.apache.cassandra.db.Memtable.put(Memtable.java:234) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1303) ~&amp;#91;apache-cassandra-3.9.jar:3.9&amp;#93; ... 26 common frames omitted</description>
      <version>3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.SelectSingleColumnRelationTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.entities.SecondaryIndexTest.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateIndexStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.SingleColumnRelation.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13253" opendate="2017-2-22 00:00:00" fixdate="2017-3-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>include a search on the doc home</summary>
      <description>Current doc homepage doesn't have a search. http://cassandra.apache.org/doc/latest/</description>
      <version>None</version>
      <fixedVersion>Legacy/DocumentationandWebsite</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">doc.source..templates.indexcontent.html</file>
    </fixedFiles>
  </bug>
  <bug id="13274" opendate="2017-2-27 00:00:00" fixdate="2017-3-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix code to not exchange schema across major versions</summary>
      <description>A rolling upgrade from 3.* to 4.0 (messaging version 11) unveils a regression caused by CASSANDRA-11128.Generally, we store all possible options/attributes including the default values in the schema. This causes (expected) schema-version-mismatches during rolling upgrades and therefore we prevent schema pulls/pushes in this situation, which has been broken by CASSANDRA-11128.</description>
      <version>3.0.13,3.11.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13276" opendate="2017-2-27 00:00:00" fixdate="2017-4-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Regression on CASSANDRA-11416: can&amp;#39;t load snapshots of tables with dropped columns</summary>
      <description>I'm running Cassandra 3.10 and running into the exact same issue described in CASSANDRA-11416: 1. A table is created with columns 'a' and 'b'2. Data is written to the table3. Drop column 'b'4. Take a snapshot5. Drop the table6. Run the snapshot schema.cql to recreate the table and the run the alter7. Try to restore the snapshot data using sstableloadersstableloader yields the error:java.lang.RuntimeException: Unknown column b during deserialization</description>
      <version>3.0.14,3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.utils.NativeSSTableLoaderClient.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13277" opendate="2017-2-27 00:00:00" fixdate="2017-3-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Duplicate results with secondary index on static column</summary>
      <description>As a follow up of http://www.mail-archive.com/user@cassandra.apache.org/msg50816.html Duplicate results appear with secondary index on static column with RF &gt; 1.Number of results vary depending on consistency level.Here is a CCM session to reproduce the issue:romain@debian:~$ ccm create 39 -n 3 -v 3.9 -sCurrent cluster is now: 39romain@debian:~$ ccm node1 cqlshConnected to 39 at 127.0.0.1:9042.[cqlsh 5.0.1 | Cassandra 3.9 | CQL spec 3.4.2 | Native protocol v4]Use HELP for help.cqlsh&gt; CREATE KEYSPACE test WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 2};cqlsh&gt; CREATE TABLE test.idx_static (id text, id2 bigint static, added timestamp, source text static, dest text, primary key (id, added));cqlsh&gt; CREATE index ON test.idx_static (id2);cqlsh&gt; INSERT INTO test.idx_static (id, id2, added, source, dest) values ('id1', 22,'2017-01-28', 'src1', 'dst1');cqlsh&gt; SELECT * FROM test.idx_static where id2=22; id | added | id2 | source | dest-----+---------------------------------+-----+--------+------ id1 | 2017-01-27 23:00:00.000000+0000 | 22 | src1 | dst1 id1 | 2017-01-27 23:00:00.000000+0000 | 22 | src1 | dst1(2 rows)cqlsh&gt; CONSISTENCY ALL Consistency level set to ALL.cqlsh&gt; SELECT * FROM test.idx_static where id2=22; id | added | id2 | source | dest-----+---------------------------------+-----+--------+------ id1 | 2017-01-27 23:00:00.000000+0000 | 22 | src1 | dst1 id1 | 2017-01-27 23:00:00.000000+0000 | 22 | src1 | dst1 id1 | 2017-01-27 23:00:00.000000+0000 | 22 | src1 | dst1(3 rows)When RF matches the number of nodes, it works as expected.Example with RF=3 and 3 nodes:romain@debian:~$ ccm create 39 -n 3 -v 3.9 -sCurrent cluster is now: 39romain@debian:~$ ccm node1 cqlshConnected to 39 at 127.0.0.1:9042.[cqlsh 5.0.1 | Cassandra 3.9 | CQL spec 3.4.2 | Native protocol v4]Use HELP for help.cqlsh&gt; CREATE KEYSPACE test WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 3};cqlsh&gt; CREATE TABLE test.idx_static (id text, id2 bigint static, added timestamp, source text static, dest text, primary key (id, added));cqlsh&gt; CREATE index ON test.idx_static (id2);cqlsh&gt; INSERT INTO test.idx_static (id, id2, added, source, dest) values ('id1', 22,'2017-01-28', 'src1', 'dst1');cqlsh&gt; SELECT * FROM test.idx_static where id2=22; id | added | id2 | source | dest-----+---------------------------------+-----+--------+------ id1 | 2017-01-27 23:00:00.000000+0000 | 22 | src1 | dst1(1 rows)cqlsh&gt; CONSISTENCY allConsistency level set to ALL.cqlsh&gt; SELECT * FROM test.idx_static where id2=22; id | added | id2 | source | dest-----+---------------------------------+-----+--------+------ id1 | 2017-01-27 23:00:00.000000+0000 | 22 | src1 | dst1(1 rows)Example with RF = 2 and 2 nodes:romain@debian:~$ ccm create 39 -n 2 -v 3.9 -sCurrent cluster is now: 39romain@debian:~$ ccm node1 cqlshConnected to 39 at 127.0.0.1:9042.[cqlsh 5.0.1 | Cassandra 3.9 | CQL spec 3.4.2 | Native protocol v4]Use HELP for help.cqlsh&gt; CREATE KEYSPACE test WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 2};cqlsh&gt; CREATE TABLE test.idx_static (id text, id2 bigint static, added timestamp, source text static, dest text, primary key (id, added));cqlsh&gt; INSERT INTO test.idx_static (id, id2, added, source, dest) values ('id1', 22,'2017-01-28', 'src1', 'dst1');cqlsh&gt; CREATE index ON test.idx_static (id2);cqlsh&gt; INSERT INTO test.idx_static (id, id2, added, source, dest) values ('id1', 22,'2017-01-28', 'src1', 'dst1');cqlsh&gt; SELECT * FROM test.idx_static where id2=22; id | added | id2 | source | dest-----+---------------------------------+-----+--------+------ id1 | 2017-01-27 23:00:00.000000+0000 | 22 | src1 | dst1(1 rows)cqlsh&gt; CONSISTENCY ALL Consistency level set to ALL.cqlsh&gt; SELECT * FROM test.idx_static where id2=22; id | added | id2 | source | dest-----+---------------------------------+-----+--------+------ id1 | 2017-01-27 23:00:00.000000+0000 | 22 | src1 | dst1(1 rows)</description>
      <version>3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>Feature/2iIndex,Legacy/LocalWrite-ReadPaths</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.index.internal.CassandraIndexTest.java</file>
      <file type="M">src.java.org.apache.cassandra.index.internal.composites.CompositesSearcher.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13282" opendate="2017-3-1 00:00:00" fixdate="2017-3-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Commitlog replay may fail if last mutation is within 4 bytes of end of segment</summary>
      <description>Following CASSANDRA-9749 , stricter correctness checks on commitlog replay can incorrectly detect "corrupt segments" and stop commitlog replay (and potentially stop cassandra, depending on the configured policy). In CommitlogReplayer#replaySyncSection we try to read a 4 byte int serializedSize, and if it's 0 (which will happen due to zeroing when the segment was created), we continue on to the next segment. However, it appears that if a mutation is sized such that it ends with 1, 2, or 3 bytes remaining in the segment, we'll pass the isEOF on the while loop but fail to read the serializedSize int, and fail.</description>
      <version>2.2.10,3.0.13,3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>Legacy/Core</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.commitlog.CommitLogTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLogReplayer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13294" opendate="2017-3-3 00:00:00" fixdate="2017-3-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Possible data loss on upgrade 2.1 - 3.0</summary>
      <description>After finishing a compaction we delete the compacted away files. This is done here which uses this to get the files - we get all files starting with absoluteFilePath. Absolute file path is generated here. For 3.0 version files the filename looks like this: /blabla/keyspace1/standard1-bdb031c0ff7b11e6940fdd0479dd8912/mc-1332-big but for 2.1 version files, they look like this: /blabla/keyspace1/standard1-bdb031c0ff7b11e6940fdd0479dd8912/keyspace1-standard1-ka-2.The problem is then that if we were to finish a compaction including the legacy file, we would actually delete all legacy files having a generation starting with '2'</description>
      <version>3.0.12,3.11.0</version>
      <fixedVersion>Legacy/LocalWrite-ReadPaths</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.lifecycle.LogTransactionTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.lifecycle.LogRecord.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13317" opendate="2017-3-9 00:00:00" fixdate="2017-3-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Default logging we ship will incorrectly print "?:?" for "%F:%L" pattern due to includeCallerData being false by default no appender</summary>
      <description>We specify the logging pattern as "%-5level &amp;#91;%thread&amp;#93; %date{ISO8601} %F:%L - %msg%n". %F:%L is intended to print the Filename:Line Number. For performance reasons logback (like log4j2) disables tracking line numbers as it requires the entire stack to be materialized every time.This causes logs to look like:WARN &amp;#91;main&amp;#93; 2017-03-09 13:27:11,272 ?:? - Protocol Version 5/v5-beta not supported by java driverINFO &amp;#91;main&amp;#93; 2017-03-09 13:27:11,813 ?:? - No commitlog files found; skipping replayINFO &amp;#91;main&amp;#93; 2017-03-09 13:27:12,477 ?:? - Initialized prepared statement caches with 14 MBINFO &amp;#91;main&amp;#93; 2017-03-09 13:27:12,727 ?:? - Initializing system.IndexInfoWhen instead you'd expect something like:INFO &amp;#91;main&amp;#93; 2017-03-09 13:23:44,204 ColumnFamilyStore.java:419 - Initializing system.available_rangesINFO &amp;#91;main&amp;#93; 2017-03-09 13:23:44,210 ColumnFamilyStore.java:419 - Initializing system.transferred_rangesINFO &amp;#91;main&amp;#93; 2017-03-09 13:23:44,215 ColumnFamilyStore.java:419 - Initializing system.views_builds_in_progressThe fix is to add "&lt;includeCallerData&gt;true&lt;/includeCallerData&gt;" to the appender config to enable the line number and stack tracing.</description>
      <version>3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>Legacy/Core</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.conf.logback-test.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13326" opendate="2017-3-14 00:00:00" fixdate="2017-3-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support unaligned memory access for AArch64</summary>
      <description>ARMv8 (AArch64) supports unaligned memory access. The patch will enable it and will improve performance on AArch64</description>
      <version>3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>Legacy/Observability,Legacy/Testing</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.utils.Architecture.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13340" opendate="2017-3-16 00:00:00" fixdate="2017-3-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bugs handling range tombstones in the sstable iterators</summary>
      <description>There is 2 bugs in the way sstable iterators handle range tombstones: empty range tombstones can be returned due to a strict comparison that shouldn't be. the sstable reversed iterator can actually return completely bogus results when range tombstones are spanning multiple index blocks.The 2 bugs are admittedly separate but as they both impact the same area of code and are both range tombstones related, I suggest just fixing both here (unless something really really mind).Marking the ticket critical mostly for the 2nd bug: it can truly make use return bad results on reverse queries.</description>
      <version>3.0.13,3.11.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.DeleteTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.UnfilteredDeserializer.java</file>
      <file type="M">src.java.org.apache.cassandra.db.columniterator.SSTableReversedIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.db.columniterator.SSTableIterator.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ClusteringPrefix.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13341" opendate="2017-3-16 00:00:00" fixdate="2017-3-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Legacy deserializer can create empty range tombstones</summary>
      <description>Range tombstones in the 2.x file format is a bit far-westy so you can actually get sequences of range tombstones like [1, 4]@3 [1, 10]@5. But the current legacy deserializer doesn't handle this correctly. On the first range, it will generate a INCL_START(1)@3 open marker, but upon seeing the next tombstone it will decide to close the previously opened range and re-open with deletion time 5, so will generate EXCL_END_INCL_START(1)@3-5. That result in the first range being empty, which break future assertions in the code.</description>
      <version>3.0.13,3.11.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.OldFormatDeserializerTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.UnfilteredDeserializer.java</file>
      <file type="M">src.java.org.apache.cassandra.db.rows.RangeTombstoneMarker.java</file>
      <file type="M">src.java.org.apache.cassandra.db.rows.RangeTombstoneBoundMarker.java</file>
      <file type="M">src.java.org.apache.cassandra.db.rows.RangeTombstoneBoundaryMarker.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13367" opendate="2017-3-22 00:00:00" fixdate="2017-3-22 01:00:00" resolution="Duplicate">
    <buginformation>
      <summary>CASSANDRA-10855 breaks authentication: throws server error instead of bad credentials on cache load failure</summary>
      <description>Click to add description</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.auth.RolesCache.java</file>
      <file type="M">src.java.org.apache.cassandra.auth.PermissionsCache.java</file>
      <file type="M">src.java.org.apache.cassandra.auth.PasswordAuthenticator.java</file>
      <file type="M">src.java.org.apache.cassandra.auth.jmx.AuthorizationProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.auth.CassandraRoleManager.java</file>
      <file type="M">src.java.org.apache.cassandra.auth.CassandraAuthorizer.java</file>
      <file type="M">src.java.org.apache.cassandra.auth.AuthCache.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13369" opendate="2017-3-22 00:00:00" fixdate="2017-5-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>If there are multiple values for a key, CQL grammar choses last value. This should not be silent or should not be allowed.</summary>
      <description>If through CQL, multiple values are specified for a key, grammar parses the map and last value for the key wins. This behavior is bad.e.g. CREATE KEYSPACE Excalibur WITH REPLICATION = {'class': 'NetworkTopologyStrategy', 'dc1': 2, 'dc1': 5};Parsing this statement, 'dc1' gets RF = 5. This can be catastrophic, may even result in loss of data. This behavior should not be silent or not be allowed at all.</description>
      <version>3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.CreateTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.AlterTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.CqlParserTest.java</file>
      <file type="M">src.antlr.Parser.g</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13382" opendate="2017-3-27 00:00:00" fixdate="2017-3-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cdc column addition strikes again</summary>
      <description>This is a followup of CASSANDRA-12697, where the patch mistakenly only handled the system_schema.tables table, while the cdc column has been added to system_schema.views table.The patch is pretty trivial, though this highlight that we don't seem to have upgrade tests for materialized views.</description>
      <version>3.11.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.schema.SchemaKeyspace.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13384" opendate="2017-3-28 00:00:00" fixdate="2017-3-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Legacy caching options can prevent 3.0 upgrade</summary>
      <description>In 2.1, we wrote caching options as a JSONified map, but we tolerated raw strings "ALL", "KEYS_ONLY", "ROWS_ONLY", and "NONE".If a 2.1 node with any of these strings is upgraded to 3.0, the legacy schema migration will fail.</description>
      <version>3.0.13,3.11.0</version>
      <fixedVersion>Legacy/DistributedMetadata</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.schema.LegacySchemaMigratorTest.java</file>
      <file type="M">src.java.org.apache.cassandra.schema.LegacySchemaMigrator.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13399" opendate="2017-4-3 00:00:00" fixdate="2017-5-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>UDA fails without input rows</summary>
      <description>When creating the following user defined AGGREGATION and FUNCTION:init.cqlCREATE FUNCTION state_group_and_total(state map&lt;uuid, int&gt;, type uuid) RETURNS NULL ON NULL INPUT RETURNS map&lt;uuid, int&gt; LANGUAGE java AS ' Integer count = (Integer) state.get(type); count = (count == null ? 1 : count + 1); state.put(type, count); return state; ';CREATE OR REPLACE AGGREGATE group_and_total(uuid) SFUNC state_group_and_total STYPE map&lt;uuid, int&gt; INITCOND {};And creating a statement like:SELECT group_and_total("id") FROM mytable;When mytable is empty, it throws the following null assertionERROR [Native-Transport-Requests-1] 2017-04-03 07:25:09,787 Message.java:623 - Unexpected exception during request; channel = [id: 0xd7d9159b, L:/172.19.0.2:9042 - R:/172.19.0.3:43444]java.lang.AssertionError: null at org.apache.cassandra.cql3.functions.UDAggregate$2.compute(UDAggregate.java:189) ~[apache-cassandra-3.10.jar:3.10] at org.apache.cassandra.cql3.selection.AggregateFunctionSelector.getOutput(AggregateFunctionSelector.java:53) ~[apache-cassandra-3.10.jar:3.10] at org.apache.cassandra.cql3.selection.Selection$SelectionWithProcessing$1.getOutputRow(Selection.java:592) ~[apache-cassandra-3.10.jar:3.10] at org.apache.cassandra.cql3.selection.Selection$ResultSetBuilder.getOutputRow(Selection.java:430) ~[apache-cassandra-3.10.jar:3.10] at org.apache.cassandra.cql3.selection.Selection$ResultSetBuilder.build(Selection.java:424) ~[apache-cassandra-3.10.jar:3.10] at org.apache.cassandra.cql3.statements.SelectStatement.process(SelectStatement.java:763) ~[apache-cassandra-3.10.jar:3.10] at org.apache.cassandra.cql3.statements.SelectStatement.processResults(SelectStatement.java:400) ~[apache-cassandra-3.10.jar:3.10] at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:378) ~[apache-cassandra-3.10.jar:3.10] at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:251) ~[apache-cassandra-3.10.jar:3.10] at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:79) ~[apache-cassandra-3.10.jar:3.10] at org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:217) ~[apache-cassandra-3.10.jar:3.10] at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:248) ~[apache-cassandra-3.10.jar:3.10] at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:233) ~[apache-cassandra-3.10.jar:3.10] at org.apache.cassandra.transport.messages.QueryMessage.execute(QueryMessage.java:116) ~[apache-cassandra-3.10.jar:3.10] at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:517) [apache-cassandra-3.10.jar:3.10] at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:410) [apache-cassandra-3.10.jar:3.10] at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105) [netty-all-4.0.39.Final.jar:4.0.39.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:366) [netty-all-4.0.39.Final.jar:4.0.39.Final] at io.netty.channel.AbstractChannelHandlerContext.access$600(AbstractChannelHandlerContext.java:35) [netty-all-4.0.39.Final.jar:4.0.39.Final] at io.netty.channel.AbstractChannelHandlerContext$7.run(AbstractChannelHandlerContext.java:357) [netty-all-4.0.39.Final.jar:4.0.39.Final] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_121] at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:162) [apache-cassandra-3.10.jar:3.10] at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:109) [apache-cassandra-3.10.jar:3.10] at java.lang.Thread.run(Thread.java:745) [na:1.8.0_121]Even if my FUNCTION only returns state, it creates that assertion null.Thank you in advance.</description>
      <version>3.11.0</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.validation.operations.AggregationTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="13410" opendate="2017-4-4 00:00:00" fixdate="2017-4-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>nodetool upgradesstables/scrub/compact ignores system tables</summary>
      <description>CASSANDRA-11627 changed the behavior of nodetool commands that work across all keyspaces. Sometimes it's OK (not compacting system.peers when you call compact probably isn't going to anger anyone), but sometimes it's not (disableautocompaction, flush, upgradesstables, etc).</description>
      <version>3.0.13,3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeTool.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13417" opendate="2017-4-5 00:00:00" fixdate="2017-4-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Illegal unicode character breaks compilation on Chinese env OS</summary>
      <description>Creating JIRA for tracking GH issue https://github.com/apache/cassandra/pull/104Fix is contained within a comment block, so skipping CI.</description>
      <version>3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.index.sasi.analyzer.StandardTokenizerImpl.jflex</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13434" opendate="2017-4-12 00:00:00" fixdate="2017-4-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add PID file directive in /etc/init.d/cassandra</summary>
      <description>As mentioned in CASSANDRA-10920, we should add directive for pid file in header that allows creating a unit file with the correct PIDFile=.. entry. Else systemd won't be able to tell if Cassandra is still running.# pidfile: /var/run/cassandra/cassandra.pid</description>
      <version>2.2.10,3.0.14,3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>Packaging</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">redhat.cassandra</file>
    </fixedFiles>
  </bug>
  <bug id="13435" opendate="2017-4-12 00:00:00" fixdate="2017-4-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Incorrect status check use when stopping Cassandra</summary>
      <description>Function status from /etc/rc.d/init.d/functions will delegate to systemctl status and we can't keep using the output to determine the status result. This should be changed to match the return value instead, which is supposed to return 3 for non-running processes</description>
      <version>2.2.10,3.0.14,3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>Packaging</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">redhat.cassandra</file>
    </fixedFiles>
  </bug>
  <bug id="13441" opendate="2017-4-12 00:00:00" fixdate="2017-4-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Schema version changes for each upgraded node in a rolling upgrade, causing migration storms</summary>
      <description>In versions &lt; 3.0, during a rolling upgrade (say 2.0 -&gt; 2.1), the first node to upgrade to 2.1 would add the new tables, setting the new 2.1 version ID, and subsequently upgraded hosts would settle on that version.When a 3.0 node upgrades and writes its own new-in-3.0 system tables, it'll write the same tables that exist in the schema with brand new timestamps. As written, this will cause all nodes in the cluster to change schema (to the version with the newest timestamp). On a sufficiently large cluster with a non-trivial schema, this could cause (literally) millions of migration tasks to needlessly bounce across the cluster.</description>
      <version>3.0.14,3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>Legacy/DistributedMetadata</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.MigrationManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13493" opendate="2017-5-3 00:00:00" fixdate="2017-5-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RPM Init: Service startup ordering</summary>
      <description>Currently, Cassandra is setup to start before network and name services come up, and setup to be town down after them, dangerously close to the final shutdown call.A service daemon which may use network-based storage, and serves requests over a network needs to start clearly after network and network mounts, and come down clearly after.</description>
      <version>2.2.10,3.0.14,3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>Packaging</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">redhat.cassandra</file>
    </fixedFiles>
  </bug>
  <bug id="13518" opendate="2017-5-10 00:00:00" fixdate="2017-5-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>sstableloader doesn&amp;#39;t support non default storage_port and ssl_storage_port.</summary>
      <description>Currently these 2 ports are using hardcoded default ports: https://github.com/apache/cassandra/blob/8b3a60b9a7dbefeecc06bace617279612ec7092d/src/java/org/apache/cassandra/config/Config.java#L128-L129The proposed fix is to add command line option for these two ports like what NATIVE_PORT_OPTION currently does</description>
      <version>3.0.14,3.11.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.BulkLoader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13525" opendate="2017-5-11 00:00:00" fixdate="2017-5-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ReverseIndexedReader may drop rows during 2.1 to 3.0 upgrade</summary>
      <description>During an upgrade from 2.1 (or 2.2) to 3.0 (or 3.x) queries which perform reverse iteration may silently drop rows from their results. This can happen before sstableupgrade is run and when the sstables are indexed.</description>
      <version>3.0.14,3.11.0</version>
      <fixedVersion>Legacy/LocalWrite-ReadPaths</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.io.sstable.LegacySSTableTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.UnfilteredDeserializer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13542" opendate="2017-5-22 00:00:00" fixdate="2017-6-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>nodetool scrub/cleanup/upgradesstables exit code</summary>
      <description>We exit nodetool with success if we fail marking sstables as compacting</description>
      <version>3.0.14,3.11.0,4.0-alpha1,4.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeProbe.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>
