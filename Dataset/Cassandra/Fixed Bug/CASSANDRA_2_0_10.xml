<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="CASSANDRA">
  <bug id="5481" opendate="2013-4-16 00:00:00" fixdate="2013-7-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CQLSH exception handling could leave a session in a bad state</summary>
      <description>Playing with CTRL+C in a cqlsh session can leave the (Thrift|Native) connection in a bad state.To reproduce :1) Run a long running COPY FROM command (COPY test (k, v) FROM '/tmp/test.csv')2) Interrupt the importer with CTRL+CRepeat step 1 and 2 until you start seeing weird things in the cql shell (see attached screenshot)The reason is, I believe, the connection (and the cursor) is not correclty closed and reopened on interruption.I am working to propose a fix.Jordan</description>
      <version>1.2.19,2.0.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug id="6596" opendate="2014-1-16 00:00:00" fixdate="2014-7-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Split out outgoing stream throughput within a DC and inter-DC</summary>
      <description>Currently the outgoing stream throughput setting doesn't differentiate between when it goes to another node in the same DC and when it goes to another DC across a potentially bandwidth limited link. It would be nice to have that split out so that it could be tuned for each type of link.</description>
      <version>2.0.10,2.1beta1</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamManager.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6612" opendate="2014-1-22 00:00:00" fixdate="2014-8-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Query failing due to AssertionError</summary>
      <description>I am trying out Cassandra for the first time and running it locally for simple session management db. &amp;#91;Cassandra-2.0.4, CQL3, datastax driver 2.0.0-rc2&amp;#93;The following count query works fine when there is no data in the table:select count(*) from session_data where app_name=? and account=? and last_access &gt; ?But after even a single row is inserted into the table, the query fails with the following error: java.lang.AssertionError at org.apache.cassandra.db.filter.ExtendedFilter$WithClauses.getExtraFilter(ExtendedFilter.java:258) at org.apache.cassandra.db.ColumnFamilyStore.filter(ColumnFamilyStore.java:1719) at org.apache.cassandra.db.ColumnFamilyStore.getRangeSlice(ColumnFamilyStore.java:1674) at org.apache.cassandra.db.PagedRangeCommand.executeLocally(PagedRangeCommand.java:111) at org.apache.cassandra.service.StorageProxy$LocalRangeSliceRunnable.runMayThrow(StorageProxy.java:1418) at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:1931) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:744)Here is the schema I am using: CREATE KEYSPACE session WITH replication= {'class': 'SimpleStrategy', 'replication_factor': 1}; CREATE TABLE session_data ( username text, session_id text, app_name text, account text, last_access timestamp, created_on timestamp, PRIMARY KEY (username, session_id, app_name, account) ); create index sessionIndex ON session_data (session_id); create index sessionAppName ON session_data (app_name); create index lastAccessIndex ON session_data (last_access);</description>
      <version>2.0.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.index.SecondaryIndexManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.SecondaryIndex.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.AbstractSimplePerColumnSecondaryIndex.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6621" opendate="2014-1-26 00:00:00" fixdate="2014-7-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add flag to disable STCS in L0</summary>
      <description>The initial discussion started in (closed) CASSANDRA-5371. I've rewritten my last comment here...After streaming (e.g. during boostrap) Cassandra places all sstables at L0. At the end of the process we end up with huge number of sstables at the lowest level. Currently, Cassandra falls back to STCS until the number of sstables at L0 reaches the reasonable level (32 or something).I'm not sure if falling back to STCS is the best way to handle this particular situation. I've read the comment in the code and I'm aware why it is a good thing to do if we have to many sstables at L0 as a result of too many random inserts. We have a lot of sstables, each of them covers the whole ring, there's simply no better option.However, after the bootstrap situation looks a bit different. The loaded sstables already have very small ranges! We just have to tidy up a bit and everything should be OK. STCS ignores that completely and after a while we have a bit less sstables but each of them covers the whole ring instead of just a small part. I believe that in that case letting LCS do the job is a better option that allowing STCS mix everything up before.Is there a way to disable STCS fallback? I'd like to test that scenario in practice during our next bootstrap...Does Cassandra really have to put streamed sstables at L0? The only thing we have to assure is that sstables at any given level do not overlap. If we stream different regions from different nodes how can we get any overlaps?</description>
      <version>2.0.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LeveledManifest.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6905" opendate="2014-3-21 00:00:00" fixdate="2014-7-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>commitlog archive replay should attempt to replay all mutations</summary>
      <description>Currently when you do a point-in-time recovery using archived commitlogs, the replay stops when the time is encountered, but since timestamps are supplied by the client we can't guarantee the segment is ordered by timestamp, so some mutations can be lost. Instead we could continue past the given timestamp, and just filter out any mutations greater than it.</description>
      <version>2.0.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.RecoveryManagerTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="6930" opendate="2014-3-25 00:00:00" fixdate="2014-7-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Dynamic Snitch isWorthMergingForRangeQuery Doesn&amp;#39;t Handle Some Cases Optimally</summary>
      <description>I was investigating slow responses for queries like select * from system.peers and noticed that the dynamic endpoint snitch was reporting that the query was not worth merging. In this case, the local host had a score of 0, so return maxMerged &lt; maxL1 + maxL2 was returning false. I believe using a &lt;= condition is the proper fix there.Additionally, because scores are looked up three separate times, this method is a prone to race conditions. I don't think it's worth fixing the race condition for a multi-node scenario, but at least in the single-node case, we can immediately return true and avoid any race conditions that would cause it to erroneously return false.</description>
      <version>2.0.10,2.1rc5</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.locator.DynamicEndpointSnitch.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7200" opendate="2014-5-9 00:00:00" fixdate="2014-7-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>word count broken</summary>
      <description>word_count_setup hangs forever, and word_count loops forever with this exception:DEBUG 17:52:42,875 java.io.IOException: config(config) at org.apache.hadoop.conf.Configuration.&lt;init&gt;(Configuration.java:260) at org.apache.hadoop.mapred.JobConf.&lt;init&gt;(JobConf.java:341) at org.apache.hadoop.mapreduce.JobContext.&lt;init&gt;(JobContext.java:76) at org.apache.hadoop.mapreduce.TaskAttemptContext.&lt;init&gt;(TaskAttemptContext.java:35) at org.apache.hadoop.mapreduce.TaskInputOutputContext.&lt;init&gt;(TaskInputOutputContext.java:44) at org.apache.hadoop.mapreduce.MapContext.&lt;init&gt;(MapContext.java:43) at org.apache.hadoop.mapreduce.Mapper$Context.&lt;init&gt;(Mapper.java:105) at sun.reflect.GeneratedConstructorAccessor14.newInstance(Unknown Source) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:526) at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:759) at org.apache.hadoop.mapred.MapTask.run(MapTask.java:370) at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:212)</description>
      <version>2.0.10,2.1rc4</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">examples.hadoop.word.count.src.WordCountCounters.java</file>
      <file type="M">examples.hadoop.word.count.src.WordCount.java</file>
      <file type="M">examples.hadoop.word.count.src.WordCountSetup.java</file>
      <file type="M">examples.hadoop.word.count.README.txt</file>
      <file type="M">examples.hadoop.word.count.conf.log4j.properties</file>
      <file type="M">examples.hadoop.cql3.word.count.src.WordCountSetup.java</file>
      <file type="M">examples.hadoop.cql3.word.count.README.txt</file>
      <file type="M">examples.hadoop.cql3.word.count.conf.log4j.properties</file>
    </fixedFiles>
  </bug>
  <bug id="7229" opendate="2014-5-14 00:00:00" fixdate="2014-8-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hadoop2 jobs throw java.lang.IncompatibleClassChangeError</summary>
      <description>Hadoop2 jobs throw java.lang.IncompatibleClassChangeError when cassandra is build against hadoop2 libraries. Attached patch fixes this issue for me.</description>
      <version>2.0.10,2.1.1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.cassandra.hadoop.cql3.CqlInputFormat.java</file>
    </fixedFiles>
  </bug>
  <bug id="7345" opendate="2014-6-3 00:00:00" fixdate="2014-6-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unfinished or inflight CAS are always done at QUORUM</summary>
      <description>The problem here is that we don't know which consistency level was used to perform the operation. We might want to store this in paxos cf or use the consistency level of the current call. This is important because calls being done at LOCAL_SERIAL will become slow.</description>
      <version>2.0.10,2.1rc3</version>
      <fixedVersion>Feature/LightweightTransactions</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7414" opendate="2014-6-18 00:00:00" fixdate="2014-6-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>After cleanup we can end up with non-compacting high level sstables</summary>
      <description>If we run cleanup (or increase sstable size) on a node with LCS, we could end up with a bunch of sstables in higher levels that are "never" compacted.</description>
      <version>2.0.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LeveledManifest.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7416" opendate="2014-6-18 00:00:00" fixdate="2014-6-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow cassandra-stress to set timestamp for writes</summary>
      <description>This is just a convenience for testing and bulk loading prior to a mixed workload.</description>
      <version>None</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.settings.SettingsColumn.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.operations.ThriftInserter.java</file>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.operations.CqlInserter.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7432" opendate="2014-6-21 00:00:00" fixdate="2014-8-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add new CMS GC flags to cassandra_env.sh for JVM later than 1.7.0_60</summary>
      <description>The new flags in question are as follows:-XX:+CMSParallelInitialMarkEnabled-XX:+CMSEdenChunksRecordAlwaysGiven we already haveJVM_OPTS="$JVM_OPTS -XX:+UseParNewGC" JVM_OPTS="$JVM_OPTS -XX:+UseConcMarkSweepGC" JVM_OPTS="$JVM_OPTS -XX:+CMSParallelRemarkEnabled" JVM_OPTS="$JVM_OPTS -XX:+UseTLAB"if [ "$JVM_ARCH" = "64-Bit" ] ; then JVM_OPTS="$JVM_OPTS -XX:+UseCondCardMark"fiThe assumption would be that people are at least running on large number CPU cores/threadsI would therefore recommend defaulting these flags if available - the only two possible downsides for +CMSEdenChunksRecordAlways:1) There is a new very short (probably un-contended) lock in the "slow" (non TLAB) eden allocation path with +CMSEdenChunksRecordAlways. I haven't detected this timing wise - this is the "slow" path after all2) If you are running with -XX:-UseCMSCompactAtFullCollection (not the default) and you call System.gc() then +CMSEdenChunksRecordAlways will expose you to a possible seg fault: (seehttp://bugs.java.com/bugdatabase/view_bug.do?bug_id=8021809)</description>
      <version>2.0.10,2.1.1</version>
      <fixedVersion>Packaging</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.cassandra-env.sh</file>
    </fixedFiles>
  </bug>
  <bug id="7490" opendate="2014-7-3 00:00:00" fixdate="2014-7-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Static columns mess up selects with ordering and clustering column ranges</summary>
      <description>Starts off ok:cqlsh:test&gt; create table test (p text, c text, v text, s text static, PRIMARY KEY (p, c));cqlsh:test&gt; insert into test (p, c, v, s) values ('p1', 'k1', 'v1', 'sv1');cqlsh:test&gt; select * from test where p = 'p1'; p | c | s | v----+----+-----+---- p1 | k1 | sv1 | v1(1 rows)But try ordering, and we appear to get the static row instead:cqlsh:test&gt; select * from test where p = 'p1' order by c desc; p | c | s | v----+------+-----+------ p1 | null | sv1 | null(1 rows)Now we add a clustering key range constraint, again works ok:cqlsh:test&gt; select * from test where p = 'p1' and c &gt;= 'a'; p | c | s | v----+----+-----+---- p1 | k1 | sv1 | v1(1 rows)But, this causes assertion failure (which has a very nice comment explaining exactly why that might happen!):cqlsh:test&gt; select * from test where p = 'p1' and c &gt;= 'a' order by c desc;Request did not complete within rpc_timeout.Cause:java.lang.AssertionError: Added column does not sort as the first column at org.apache.cassandra.db.ArrayBackedSortedColumns.addColumn(ArrayBackedSortedColumns.java:115) at org.apache.cassandra.db.ColumnFamily.addColumn(ColumnFamily.java:116) at org.apache.cassandra.db.ColumnFamily.addIfRelevant(ColumnFamily.java:110) at org.apache.cassandra.db.filter.SliceQueryFilter.collectReducedColumns(SliceQueryFilter.java:205) at org.apache.cassandra.db.filter.QueryFilter.collateColumns(QueryFilter.java:122) at org.apache.cassandra.db.filter.QueryFilter.collateOnDiskAtom(QueryFilter.java:80) at org.apache.cassandra.db.filter.QueryFilter.collateOnDiskAtom(QueryFilter.java:72) at org.apache.cassandra.db.CollationController.collectAllData(CollationController.java:297) at org.apache.cassandra.db.CollationController.getTopLevelColumns(CollationController.java:53) at org.apache.cassandra.db.ColumnFamilyStore.getTopLevelColumns(ColumnFamilyStore.java:1547) at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:1376) at org.apache.cassandra.db.Keyspace.getRow(Keyspace.java:333) at org.apache.cassandra.db.SliceFromReadCommand.getRow(SliceFromReadCommand.java:65) at org.apache.cassandra.service.StorageProxy$LocalReadRunnable.runMayThrow(StorageProxy.java:1363) at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:1927) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:744)</description>
      <version>2.0.10</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7499" opendate="2014-7-6 00:00:00" fixdate="2014-8-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unable to update list element by index using CAS condition</summary>
      <description>While running IT tests for Achilles, I ran into a strange bug:With CQLSHcqlsh:test&gt; CREATE TABLE cas_update(id int PRIMARY KEY,name text,friends list&lt;text&gt;);cqlsh:test&gt; INSERT INTO cas_update (id, name , friends ) VALUES ( 10,'John',['Paul','George']);cqlsh:test&gt; SELECT * FROM cas_update WHERE id=10; id | friends | name----+--------------------+------ 10 | ['Paul', 'George'] | Johncqlsh:test&gt; UPDATE cas_update SET friends[0]='Helen' WHERE id=10 IF name='John';Bad Request: List index 0 out of bound, list has size 0cqlsh:test&gt; UPDATE cas_update SET friends[0]='Helen' WHERE id=10;cqlsh:test&gt; SELECT * FROM cas_update WHERE id=10; id | friends | name----+---------------------+------ 10 | ['Helen', 'George'] | JohnIt seems that we cannot update list element by index with a CAS condition.With Java driver 2.0.2 or 2.0.3 ACHILLES_DML_STATEMENT@:writeDMLStatementLog Prepared statement : [INSERT INTO CompleteBean(id,followers,friends,name,preferences) VALUES (:id,:followers,:friends,:name,:preferences) USING TTL :ttl;] with CONSISTENCY LEVEL [ONE] ACHILLES_DML_STATEMENT@:writeDMLStatementLog bound values : [621309709026375591, [], [Paul, Andrew], John, {}, 0] ACHILLES_DML_STATEMENT@:writeDMLStartBatch ACHILLES_DML_STATEMENT@:writeDMLStartBatch ACHILLES_DML_STATEMENT@:writeDMLStartBatch ****** BATCH UNLOGGED START ****** ACHILLES_DML_STATEMENT@:writeDMLStartBatch ACHILLES_DML_STATEMENT@:writeDMLStatementLog Parameterized statement : [UPDATE CompleteBean USING TTL 100 SET friends[0]=? WHERE id=621309709026375591 IF name=?;] with CONSISTENCY LEVEL [ONE] ACHILLES_DML_STATEMENT@:writeDMLStatementLog bound values : [100, 0, Helen, 621309709026375591, John] ACHILLES_DML_STATEMENT@:writeDMLStatementLog Parameterized statement : [UPDATE CompleteBean USING TTL 100 SET friends[1]=null WHERE id=621309709026375591 IF name=?;] with CONSISTENCY LEVEL [ONE] ACHILLES_DML_STATEMENT@:writeDMLStatementLog bound values : [100, 1, null, 621309709026375591, John] ACHILLES_DML_STATEMENT@:writeDMLEndBatch ACHILLES_DML_STATEMENT@:writeDMLEndBatch ****** BATCH UNLOGGED END with CONSISTENCY LEVEL [DEFAULT] ****** ACHILLES_DML_STATEMENT@:writeDMLEndBatch ACHILLES_DML_STATEMENT@:writeDMLEndBatch ACHILLES_DML_STATEMENT@:truncateTable Simple query : [TRUNCATE entity_with_enum] with CONSISTENCY LEVEL [ALL] ACHILLES_DML_STATEMENT@:truncateTable Simple query : [TRUNCATE CompleteBean] with CONSISTENCY LEVEL [ALL] com.datastax.driver.core.exceptions.InvalidQueryException: List index 0 out of bound, list has size 0 at com.datastax.driver.core.exceptions.InvalidQueryException.copy(InvalidQueryException.java:35) at com.datastax.driver.core.DefaultResultSetFuture.extractCauseFromExecutionException(DefaultResultSetFuture.java:256) at com.datastax.driver.core.DefaultResultSetFuture.getUninterruptibly(DefaultResultSetFuture.java:172) at com.datastax.driver.core.AbstractSession.execute(AbstractSession.java:52)With Cassandra 2.0.8 and Java Driver 2.0.2 or 2.0.3, the test passed so it seems that there is a regression somewhere in the CAS update code</description>
      <version>2.0.10,2.1.1</version>
      <fixedVersion>Feature/LightweightTransactions,Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraServer.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.service.CASConditions.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.ModificationStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CQL3CasConditions.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.BatchStatement.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7506" opendate="2014-7-7 00:00:00" fixdate="2014-8-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>querying secondary index using complete collection should warn/error</summary>
      <description>Cassandra does not seem to support querying a set literal like so:select * from testtable where pkey='foo' and mycollection = {'one', 'two'};We currently don't let the user know this query is problematic, rather we just return no rows.To reproduce:create keyspace test with replication = {'class': 'SimpleStrategy', 'replication_factor':1} ;use test ;create table testtable (pkey text PRIMARY KEY, mycollection set&lt;text&gt;);create index on testtable (mycollection);insert into testtable (pkey, mycollection) VALUES ( 'foo', {'one','two'};cqlsh:test&gt; select * from testtable where pkey='foo' and mycollection = {'one', 'two'};(0 rows)</description>
      <version>2.0.10,2.1.1</version>
      <fixedVersion>Feature/2iIndex</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7528" opendate="2014-7-9 00:00:00" fixdate="2014-7-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>certificate not validated for internode SSL encryption.</summary>
      <description>An expired certificate may be used to encrypt internode communication.To reproduce, set the server_encryption_options to enable internode encryption. Add the private key to the specified .keystore, and an expired certificate generated using the private key to the specified truststore. The same keys are used far all cassandra nodes in the cluster. When cassandra is started, it is able to communicate with other cassandra nodes even though the certificate is expired.</description>
      <version>2.0.10,2.1rc4</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.security.SSLFactory.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="753" opendate="2010-2-2 00:00:00" fixdate="2010-2-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>r/m SSTR.openedFiles</summary>
      <description>this is a remnant of when we passed around date file names and did SSTR.open(fname) constantly. Now we use CFS.sstables instead almost exclusively which is much cleaner. time to clean out the rest of this.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.io.SSTableTest.java</file>
      <file type="M">src.java.org.apache.cassandra.service.AntiEntropyService.java</file>
      <file type="M">src.java.org.apache.cassandra.io.SSTableTracker.java</file>
      <file type="M">src.java.org.apache.cassandra.io.SSTableReader.java</file>
      <file type="M">src.java.org.apache.cassandra.io.SSTable.java</file>
      <file type="M">test.unit.org.apache.cassandra.service.AntiEntropyServiceTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.io.SSTableUtils.java</file>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraServer.java</file>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraDaemon.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamOut.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Table.java</file>
      <file type="M">src.java.org.apache.cassandra.db.CompactionManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.avro.CassandraDaemon.java</file>
    </fixedFiles>
  </bug>
  <bug id="7535" opendate="2014-7-11 00:00:00" fixdate="2014-7-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Coverage analysis for range queries</summary>
      <description>This is a regression related to CASSANDRA-4858Range queries are taking orders of magnitude more time to complete than before because the query planner is frequently unable to calculate the correct intersection of contiguous ranges for a given node.For example, SELECT * FROM TBL should result in exactly one scan at CL.ONE when RF = #nodes when in fact it can result in several hundred scans (sometimes thousands). The problem is exasperated with vnodes.The regression occurred at some point between 2.0.4 (which works fine) and 2.0.9.</description>
      <version>2.0.10,2.1rc4</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.locator.DynamicEndpointSnitch.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7541" opendate="2014-7-14 00:00:00" fixdate="2014-7-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Windows: IOException when repairing a range of tokens</summary>
      <description>Looks like we missed this in CASSANDRA-6907 - range-based repair still defaults to snapshot-based on Windows.</description>
      <version>2.0.10,2.1rc4</version>
      <fixedVersion>Legacy/StreamingandMessaging</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7585" opendate="2014-7-22 00:00:00" fixdate="2014-8-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cassandra sstableloader connection refused with inter_node_encryption</summary>
      <description>cassandra sstableloader connection refused with inter_node_encryptionWhen using sstableloader to import tables (cassandra 2.0.5) with inter-node encryption and client encryption enabled, I get a connection refused errorI am usingsstableloader -d $myhost -p 9160 -u cassandra -pw cassandra -ciphers TLS_RSA_WITH_AES_128_CBC_SHA,TLS_DHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA -st JKS -tf org.apache.cassandra.thrift.SSLTransportFactory -ts /path/to/truststore -tspw &lt;passwd&gt; $fullpath/$tableErrors out withStreaming session ID: 1bc395c0-fbb2-11e3-9812-73da15121373 WARN 17:13:34,147 Failed attempt 1 to connect toSimilar problem reported in cassandra 2.0.8 by another userhttp://stackoverflow.com/questions/24390604/cassandra-sstableloader-connection-refused-with-inter-node-encryption==================Relevant cassandra.yaml snippet (with obfuscation)server_encryption_options: internode_encryption: all keystore:/path/to/keystore keystore_password: &lt;passwd&gt; truststore:/path/to/truststore truststore_password:&lt;passwd&gt; More advanced defaults below: protocol: TLS algorithm: SunX509 store_type: JKS cipher_suites: &amp;#91;TLS_RSA_WITH_AES_128_CBC_SHA,TLS_DHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA&amp;#93; require_client_auth: true enable or disable client/server encryption.client_encryption_options: enabled: true keystore: /path/to/keystore keystore_password: &lt;truststorepasswd&gt; #require_client_auth: true Set trustore and truststore_password if require_client_auth is true truststore:/path/to/truststore truststore_password: &lt;truststorepasswd&gt; More advanced defaults below: protocol: TLS algorithm: SunX509 store_type: JKS cipher_suites: &amp;#91;TLS_RSA_WITH_AES_128_CBC_SHA,TLS_DHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA&amp;#93; ======================Note that by setting inter-node encryption to "none" sstableloader works.. but setting it to "all" fails... It seems like sstableloader uses 7000 is my guess instead of using the ssl port 7001 for streaming/gossip.</description>
      <version>2.0.10,2.1.1</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.streaming.StreamTransferTaskTest.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.BulkLoader.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamSession.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamResultFuture.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamPlan.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.ConnectionHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableLoader.java</file>
      <file type="M">src.java.org.apache.cassandra.config.YamlConfigurationLoader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7600" opendate="2014-7-23 00:00:00" fixdate="2014-8-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Schema change notifications sent for no-op DDL statements</summary>
      <description>When schema changes are made with IF [NOT] EXISTS conditions, we return schema change messages (and push out schema change notifications) even if the IF [NOT] EXISTS condition makes it a no-op.This results in extra work for native protocol drivers, which typically wait for schema agreement and refresh their schema metadata when schema changes occur.</description>
      <version>2.0.10,2.1.1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SchemaAlteringStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.DropTriggerStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.DropTableStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.DropKeyspaceStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.DropIndexStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateTriggerStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateTableStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateKeyspaceStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateIndexStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.AlterTableStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.AlterKeyspaceStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7601" opendate="2014-7-23 00:00:00" fixdate="2014-9-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Data loss after nodetool taketoken</summary>
      <description>The dtest consistent_bootstrap_test.py:TestBootstrapConsistency.consistent_reads_after_relocate_test is failing on HEAD of the git branches 2.1 and 2.1.0.The test performs the following actions: Create a cluster of 3 nodes Create a keyspace with RF 2 Take node 3 down Write 980 rows to node 2 with CL ONE Flush node 2 Bring node 3 back up Run nodetool taketoken on node 3 to transfer 80% of node 1's tokens to node 3 Check for data lossWhen the check for data loss is performed, only ~725 rows can be read via CL ALL.</description>
      <version>1.2.19,2.0.10,2.1rc5</version>
      <fixedVersion>Legacy/Testing</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeTool.java</file>
      <file type="M">test.unit.org.apache.cassandra.service.RelocateTest.java</file>
      <file type="M">src.resources.org.apache.cassandra.tools.NodeToolHelp.yaml</file>
      <file type="M">src.java.org.apache.cassandra.tools.Shuffle.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeProbe.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageServiceMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.ScheduledRangeTransferExecutorService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.PendingRangeCalculatorService.java</file>
      <file type="M">src.java.org.apache.cassandra.locator.TokenMetadata.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.VersionedValue.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">debian.cassandra.install</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cassandra-shuffle</file>
    </fixedFiles>
  </bug>
  <bug id="7611" opendate="2014-7-24 00:00:00" fixdate="2014-7-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>incomplete CREATE/DROP USER help and tab completion</summary>
      <description>IF NOT EXISTS/IF EXISTS doesn't appear in the online help and tab completion.</description>
      <version>2.0.10,2.1.1</version>
      <fixedVersion>Legacy/DocumentationandWebsite</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.cql3handling.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7635" opendate="2014-7-29 00:00:00" fixdate="2014-8-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make hinted_handoff_throttle_in_kb configurable via nodetool</summary>
      <description>Transfer of stored hints can peg the CPU of the node performing the sending of the hints. We have a throttle "hinted_handoff_throttle_delay_in_ms", but it requires a restart. It would be helpful if this were configurable via nodetool to avoid the reboot.</description>
      <version>2.0.10,2.1.0</version>
      <fixedVersion>Tool/nodetool</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeTool.java</file>
      <file type="M">src.resources.org.apache.cassandra.tools.NodeToolHelp.yaml</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeProbe.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageServiceMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7641" opendate="2014-7-29 00:00:00" fixdate="2014-8-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh should automatically disable tracing when selecting from system_traces</summary>
      <description>Nobody needs to trace their traces while they're tracing.</description>
      <version>2.0.10,2.1.1</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug id="7647" opendate="2014-7-30 00:00:00" fixdate="2014-7-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Track min/max timestamps of range tombstones</summary>
      <description>When compacting etc. we don't track min/max timestamps of range tombstones, meaning a compacted sstable with only RTs will get bad values.End result can be that we drop the sstable since it might look like it only contains tombstones and is older than all other sstables, and we lose the valid RT.</description>
      <version>2.0.10,2.1rc5</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LazilyCompactedRow.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamily.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7649" opendate="2014-7-30 00:00:00" fixdate="2014-7-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>remove ability to change num_tokens</summary>
      <description>Post CASSANDRA-7601, we should also remove the ability to jump from one token to 256, since this leaves you in a meaningless, somewhat broken, state.</description>
      <version>2.0.10,2.1rc5</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
    </fixedFiles>
  </bug>
  <bug id="7650" opendate="2014-7-30 00:00:00" fixdate="2014-9-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expose auto_bootstrap as a system property override</summary>
      <description>This one-line change gives the auto_bootstrap config parameter the ability to be overridden by a system property.As I understand things, setting this false is generally a one-time initial set-up item, and providing this will be potentially easier than swapping out yaml file items when the need to set this false arises.The handling is the same as was already implemented for replace_address and the like, look to the system property, and default that to the yaml config value.This also will also allow a start-up agent (like Priam) to influence the setting from within it's control over Cassandra's start-up behaviourPatch was generated against 1.2 branch but applies ok to 2.0 as well. (It would be great if this could be applied to both code lines)</description>
      <version>2.0.10,2.1.0</version>
      <fixedVersion>Local/Config</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7663" opendate="2014-7-31 00:00:00" fixdate="2014-8-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Removing a seed causes previously removed seeds to reappear</summary>
      <description>When you remove a seed from a cluster, Gossiper.removeEndpoint ensures it is removed from the seed list. However, it also resets the seed list to be the original list, which would bring back any previously removed seeds. What is the reasoning for having the call to buildSeedsList()? If it wasnâ€™t there then I think the problem would be solved.</description>
      <version>1.2.19,2.0.10,2.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.cassandra.locator.SimpleSeedProvider.java</file>
    </fixedFiles>
  </bug>
  <bug id="7668" opendate="2014-8-1 00:00:00" fixdate="2014-8-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make gc_grace_seconds 7 days for system tables</summary>
      <description>The system tables have had a gc_grace_seconds of 8640 since CASSANDRA-4018. This was probably a typo and was intended to be 10 days. In CASSANDRA-6717 we will set gc_grace to seven days, so that would be a reasonable value to use here.</description>
      <version>1.2.19,2.0.10,2.1rc5</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7694" opendate="2014-8-5 00:00:00" fixdate="2014-8-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expected Compaction Interruption is logged as ERROR</summary>
      <description>As seen in the attached log, occasionally a major compaction will interrupt other running compactions. This is not an error and is expected behavior. However this is logged at ERROR.</description>
      <version>2.0.10,2.1.0</version>
      <fixedVersion>Local/Compaction</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">src.java.org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7707" opendate="2014-8-6 00:00:00" fixdate="2014-8-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>blobAs() function results not validated</summary>
      <description>The results of the blobAs*() functions are not validated.Here are some examples:Non-type1 UUID inserted into timeuuid column:create table foo (k int primary key, v timeuuid);insert into foo (0, blobAsTimeuuid(0x00000000000000000000000000000000));Blob with length &gt; 4 inserted into an int column:create table bar (k int primary key, v int);insert into bar (k, v) VALUES (0, blobAsInt(0x0000000000));Non-ascii characters inserted into an ascii column:create table baz (k int primary key, v ascii);insert into baz (k, v) VALUES (0, blobAsAscii(0xFFFFFFFF));Some of these (like the int column) could cause issues that look like corruption.</description>
      <version>2.0.10,2.1.0</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.functions.FunctionCall.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.functions.BytesConversionFcts.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7730" opendate="2014-8-9 00:00:00" fixdate="2014-8-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>altering a table to add a static column bypasses clustering column requirement check</summary>
      <description>cqlsh:test_ks&gt; create TABLE foo ( bar int, primary key (bar));cqlsh:test_ks&gt; alter table foo add bar2 text static;cqlsh:test_ks&gt; describe table foo;CREATE TABLE foo ( bar int, bar2 text static, PRIMARY KEY ((bar))) cqlsh:test_ks&gt; select * from foo;TSocket read 0 bytesERROR &amp;#91;Thrift:12&amp;#93; 2014-08-09 15:08:22,518 CassandraDaemon.java (line 199) Exception in thread Thread&amp;#91;Thrift:12,5,main&amp;#93;java.lang.AssertionError at org.apache.cassandra.config.CFMetaData.getStaticColumnNameBuilder(CFMetaData.java:2142) at org.apache.cassandra.cql3.statements.SelectStatement.makeFilter(SelectStatement.java:454) at org.apache.cassandra.cql3.statements.SelectStatement.getRangeCommand(SelectStatement.java:360) at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:206) at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:61) at org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:158)</description>
      <version>2.0.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.AlterTableStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7733" opendate="2014-8-10 00:00:00" fixdate="2014-8-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix supercolumn range deletion from Thrift (+ a few tests)</summary>
      <description>There is a trivial bug with full supercolumn range deletion in Thrift</description>
      <version>2.0.10,2.1rc6</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.system.test.thrift.server.py</file>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraServer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7744" opendate="2014-8-11 00:00:00" fixdate="2014-8-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Dropping the last collection column turns CompoundSparseCellNameType$WithCollection into CompoundDenseCellNameType</summary>
      <description>Dropping the last collection column turns CompoundSparseCellNameType$WithCollection into CompoundDenseCellNameTypeTo reproducecqlsh:test&gt; create table test (id int primary key, col map&lt;int,int&gt;);cqlsh:test&gt; alter table test drop col;cqlsh:test&gt; alter table test add col list&lt;int&gt;;code=2200 [Invalid query] message="Cannot add new column to a COMPACT STORAGE table"</description>
      <version>2.0.10,2.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateTableStatement.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
    </fixedFiles>
  </bug>
  <bug id="7745" opendate="2014-8-11 00:00:00" fixdate="2014-8-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Background LCS compactions stall with pending compactions remaining</summary>
      <description>We've hit a scenario where background LCS compactions will stall. compactionstats output shows hundreds of pending compactions but none active. The thread dumps show no CompactionExecutor threads running, and no compaction activity is being logged to system.log. This seems to happen when there are no writes to the node. There are no flushes logged either, and when writes resume, compactions seem to resume as well, but still don't ever get to 0.</description>
      <version>1.2.19,2.0.10,2.1.0</version>
      <fixedVersion>Local/Compaction</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7750" opendate="2014-8-11 00:00:00" fixdate="2014-8-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Do not flush on truncate if "durable_writes" is false.</summary>
      <description>CASSANDRA-7511 changed truncate so it will always flush to fix commit log issues. If durable_writes is false, then there will not be able data in the commit log for the table, so we can safely just drop the memtables and not flush.</description>
      <version>2.0.10,2.1rc6</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.CommitLogTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.DataTracker.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7752" opendate="2014-8-11 00:00:00" fixdate="2014-8-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix expiring map time for CAS messages</summary>
      <description>CAS PrepareCallback is kept in expiring map for 10 seconds which is more than the timeout. I found this while analyzing a heap dump and saw a lot of Commit and PrepareCallback objects referenced by expiring map.</description>
      <version>2.0.10</version>
      <fixedVersion>Feature/LightweightTransactions</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7753" opendate="2014-8-11 00:00:00" fixdate="2014-8-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Level compaction for Paxos table</summary>
      <description>Paxos table uses size tiered compaction which causes stable per read to be high. Converting to level has improved the performance. I think we should consider making this as default or to change the default setting of size tiered.</description>
      <version>2.0.10,2.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7796" opendate="2014-8-19 00:00:00" fixdate="2014-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Stop inheriting liveRatio/computedAt from previous memtables</summary>
      <description>CASSANDRA-6945 helped to reduce the risk of calculating an outlier liveRatio value, and having to stick with it for a long time, by making liveRatio per-memtable and not per-cf.The added optimization of inheriting liveRatio/calculatedAt to minimize recalculations, however, took us a step back to before CASSANDRA-6945.I suggest we get rid of inheriting the old values altogether, but reduce the rate of recalculation by demanding 10x increase in ops to trigger recalc, instead of the previous 2x.</description>
      <version>2.0.10</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.Memtable.java</file>
      <file type="M">src.java.org.apache.cassandra.db.DataTracker.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7798" opendate="2014-8-19 00:00:00" fixdate="2014-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Empty clustering column not caught for CQL3 update to compact storage counter table</summary>
      <description>If you update a compact storage counter column through cql3 you can set an empty column name, which is invalid. The server catches this for normal tables, but misses it for counters, and you end up with an assertion when the mutation gets serialized.CREATE TABLE nullcoltest ( key text, column1 text, value counter, PRIMARY KEY (key, column1)) WITH COMPACT STORAGE;UPDATE nullcoltest SET value = value + 1 WHERE key = 'k1' AND column1 = '';ERROR [COMMIT-LOG-WRITER] 2014-08-19 16:11:12,179 CassandraDaemon.java (line 199) Exception in thread Thread[COMMIT-LOG-WRITER,5,main]java.lang.AssertionError at org.apache.cassandra.db.ColumnSerializer.serialize(ColumnSerializer.java:56) at org.apache.cassandra.db.ColumnFamilySerializer.serialize(ColumnFamilySerializer.java:77) at org.apache.cassandra.db.RowMutation$RowMutationSerializer.serialize(RowMutation.java:278) at org.apache.cassandra.db.commitlog.CommitLogSegment.write(CommitLogSegment.java:264) at org.apache.cassandra.db.commitlog.CommitLog$LogRecordAdder.run(CommitLog.java:357) at org.apache.cassandra.db.commitlog.PeriodicCommitLogExecutorService$1.runMayThrow(PeriodicCommitLogExecutorService.java:51) at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) at java.lang.Thread.run(Thread.java:744)</description>
      <version>1.2.19,2.0.10,2.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.UpdateParameters.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.Constants.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>
