<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="CASSANDRA">
  <bug id="4959" opendate="2012-11-14 00:00:00" fixdate="2012-10-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CQLSH insert help has typo</summary>
      <description>&amp;#91;cqlsh 2.3.0 | Cassandra 1.2.0-beta2-SNAPSHOT | CQL spec 3.0.0 | Thrift protocol 19.35.0&amp;#93;Use HELP for help.cqlsh&gt; help INSERT INSERT INTO &amp;#91;&lt;keyspace&gt;.&amp;#93;&lt;tablename&gt; ( &lt;colname1&gt;, &lt;colname2&gt; [, &lt;colname3&gt; &amp;#91;, ...&amp;#93;] ) VALUES ( &lt;colval1&gt;, &lt;colval2&gt; [, &lt;colval3&gt; &amp;#91;, ...&amp;#93;] ) &amp;#91;USING TIMESTAMP &lt;timestamp&gt;&amp;#93; &amp;#91;AND TTL &lt;timeToLive&amp;#93;];Should be. &amp;#91;AND TTL &lt;timeToLive&gt;&amp;#93;];Also it was not clear to me initially that you could just do:USING TTL &lt;timeToLive&gt;But maybe that is just me.</description>
      <version>2.0.12,2.1.2</version>
      <fixedVersion>Legacy/DocumentationandWebsite</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.helptopics.py</file>
    </fixedFiles>
  </bug>
  <bug id="6482" opendate="2013-12-12 00:00:00" fixdate="2013-11-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add junitreport to ant test target</summary>
      <description>Adding junitreport XML output for the unit tests will allow detailed reporting and historical tracking in Jenkins.</description>
      <version>2.1.2</version>
      <fixedVersion>Legacy/Testing</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7510" opendate="2014-7-8 00:00:00" fixdate="2014-11-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Notify clients that bootstrap is finished over binary protocol</summary>
      <description>Currently, Cassandra will notify clients when a new node is added to a cluster. However, that node is typically not usable yet. It first needs to gossip its key range and finish loading all its assigned data before it allows clients to connect. Depending on the amount of data this may take quite a while. The clients in the mean time have no clue about the bootstrap status of that node. The only thing they can do is periodically check if it will accept a connection. My proposal would be to send an additional UP event when the bootstrap is done, this allows clients to mark the node initially as down/unavailable and simply wait for the UP event to arrive.Kind regards,Joost</description>
      <version>2.0.12,2.1.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7579" opendate="2014-7-21 00:00:00" fixdate="2014-10-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>File descriptor exhaustion can lead to unreliable state in exception condition</summary>
      <description>If the JVM runs out of file descriptors we can get into an unreliable state (similar to CASSANDRA-7507 on OOM) where we cannot trust our shutdown hook to run successfully to completion. We need to check IOExceptions and appropriate Throwable to see if we have a FileNotFoundException w/message "Too many files open" and forcefully shutdown the Daemon in these cases.</description>
      <version>2.1.2</version>
      <fixedVersion>Legacy/Observability</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.utils.KillerForTests.java</file>
      <file type="M">test.unit.org.apache.cassandra.utils.JVMStabilityInspectorTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.CommitLogTest.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.JVMStabilityInspector.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.Hex.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.FBUtilities.java</file>
      <file type="M">src.java.org.apache.cassandra.utils.CLibrary.java</file>
      <file type="M">src.java.org.apache.cassandra.transport.messages.QueryMessage.java</file>
      <file type="M">src.java.org.apache.cassandra.transport.messages.PrepareMessage.java</file>
      <file type="M">src.java.org.apache.cassandra.transport.messages.ExecuteMessage.java</file>
      <file type="M">src.java.org.apache.cassandra.transport.messages.BatchMessage.java</file>
      <file type="M">src.java.org.apache.cassandra.transport.FrameCompressor.java</file>
      <file type="M">src.java.org.apache.cassandra.transport.Client.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.StandaloneUpgrader.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.StandaloneSplitter.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.StandaloneScrubber.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.SSTableImport.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeTool.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.BulkLoader.java</file>
      <file type="M">src.java.org.apache.cassandra.thrift.CustomTThreadPoolServer.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamSession.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamLockfile.java</file>
      <file type="M">src.java.org.apache.cassandra.service.ClientState.java</file>
      <file type="M">src.java.org.apache.cassandra.net.OutboundTcpConnection.java</file>
      <file type="M">src.java.org.apache.cassandra.locator.CloudstackSnitch.java</file>
      <file type="M">src.java.org.apache.cassandra.io.util.MmappedSegmentedFile.java</file>
      <file type="M">src.java.org.apache.cassandra.io.compress.SnappyCompressor.java</file>
      <file type="M">src.java.org.apache.cassandra.hadoop.pig.CqlStorage.java</file>
      <file type="M">src.java.org.apache.cassandra.hadoop.pig.CassandraStorage.java</file>
      <file type="M">src.java.org.apache.cassandra.hadoop.cql3.CqlRecordWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.hadoop.ColumnFamilyRecordWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.Gossiper.java</file>
      <file type="M">src.java.org.apache.cassandra.db.HintedHandOffManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.AbstractCompactionStrategy.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">src.java.org.apache.cassandra.db.BlacklistedDirectories.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.cli.CliSessionState.java</file>
      <file type="M">src.java.org.apache.cassandra.cli.CliMain.java</file>
      <file type="M">src.java.org.apache.cassandra.cli.CliClient.java</file>
      <file type="M">src.java.org.apache.cassandra.cache.AutoSavingCache.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.cassandra.hadoop.HadoopCompat.java</file>
    </fixedFiles>
  </bug>
  <bug id="798" opendate="2010-2-15 00:00:00" fixdate="2010-12-15 01:00:00" resolution="Won&amp;#39;t Fix">
    <buginformation>
      <summary>Add readme file to contrib/circuit</summary>
      <description>There is no readme file or equivalent in the contrib/circuit directory. This makes it hard to get a quick overview of what the purpose is.</description>
      <version>None</version>
      <fixedVersion>Legacy/DocumentationandWebsite</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">interface.cassandra.genavro</file>
    </fixedFiles>
  </bug>
  <bug id="8031" opendate="2014-9-30 00:00:00" fixdate="2014-10-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Custom Index describe broken again</summary>
      <description>Since we switched over to the python driver for cqlsh, describe of custom indexes is broken again. Previously added in CASSANDRA-5760Driver bug: https://datastax-oss.atlassian.net/browse/PYTHON-165</description>
      <version>2.1.2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">lib.cassandra-driver-internal-only-2.1.1.post.zip</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="8084" opendate="2014-10-8 00:00:00" fixdate="2014-10-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>GossipFilePropertySnitch and EC2MultiRegionSnitch when used in AWS/GCE clusters doesnt use the PRIVATE IPS for Intra-DC communications - When running nodetool repair</summary>
      <description>Neither of these snitches(GossipFilePropertySnitch and EC2MultiRegionSnitch ) used the PRIVATE IPS for communication between INTRA-DC nodes in my multi-region multi-dc cluster in cloud(on both AWS and GCE) when I ran "nodetool repair -local". It works fine during regular reads. Here are the various cluster flavors I tried and failed- AWS + Multi-REGION + Multi-DC + GossipPropertyFileSnitch + (Prefer_local=true) in rackdc-properties file. AWS + Multi-REGION + Multi-DC + EC2MultiRegionSnitch + (Prefer_local=true) in rackdc-properties file. GCE + Multi-REGION + Multi-DC + GossipPropertyFileSnitch + (Prefer_local=true) in rackdc-properties file. GCE + Multi-REGION + Multi-DC + EC2MultiRegionSnitch + (Prefer_local=true) in rackdc-properties file. I am expecting with the above setup all of my nodes in a given DC all communicate via private ips since the cloud providers dont charge us for using the private ips and they charge for using public ips.But they can use PUBLIC IPs for INTER-DC communications which is working as expected. Here is a snippet from my log files when I ran the "nodetool repair -local" - Node responding to 'node running repair' INFO &amp;#91;AntiEntropyStage:1&amp;#93; 2014-10-08 14:47:51,628 Validator.java (line 254) repair #1439f290-4efa-11e4-bf3a-df845ecf54f8 Sending completed merkle tree to /54.172.118.222 for system_traces/sessions INFO &amp;#91;AntiEntropyStage:1&amp;#93; 2014-10-08 14:47:51,741 Validator.java (line 254) repair #1439f290-4efa-11e4-bf3a-df845ecf54f8 Sending completed merkle tree to /54.172.118.222 for system_traces/eventsNode running repair - INFO &amp;#91;AntiEntropyStage:1&amp;#93; 2014-10-08 14:47:51,927 RepairSession.java (line 166) repair #1439f290-4efa-11e4-bf3a-df845ecf54f8 Received merkle tree for events from /54.172.118.222Note: The IPs its communicating is all PUBLIC Ips and it should have used the PRIVATE IPs starting with 172.x.x.xYAML file values : The listen address is set to: PRIVATE IPThe broadcast address is set to: PUBLIC IPThe SEEDs address is set to: PUBLIC IPs from both DCsThe SNITCHES tried: GPFS and EC2MultiRegionSnitchRACK-DC: Had prefer_local set to true.</description>
      <version>2.0.11,2.1.2</version>
      <fixedVersion>Local/Config</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.streaming.StreamTransferTaskTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.streaming.StreamingTransferTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.streaming.SessionInfoTest.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamSession.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamResultFuture.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.StreamPlan.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.SessionInfo.java</file>
      <file type="M">src.java.org.apache.cassandra.streaming.management.SessionInfoCompositeData.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.repair.StreamingRepairTask.java</file>
      <file type="M">src.java.org.apache.cassandra.net.OutboundTcpConnectionPool.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.RangeStreamer.java</file>
      <file type="M">src.java.org.apache.cassandra.db.SystemKeyspace.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="8096" opendate="2014-10-9 00:00:00" fixdate="2014-11-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make cache serializers pluggable</summary>
      <description>Make cache serializers configurable via system properties.</description>
      <version>2.1.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cache.AutoSavingCache.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="8125" opendate="2014-10-15 00:00:00" fixdate="2014-11-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>nodetool statusgossip doesn&amp;#39;t exist</summary>
      <description>nodetool supports different checks for status on thrift and for binary but does not support a check for gossip. You can get this information from nodetool info.The ones that exist are:nodetool statusbinarynodetool statusthriftIt would be nice if the following existed:nodetool statusgossip</description>
      <version>2.0.12,2.1.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeTool.java</file>
      <file type="M">src.resources.org.apache.cassandra.tools.NodeToolHelp.yaml</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeProbe.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageServiceMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="8139" opendate="2014-10-18 00:00:00" fixdate="2014-10-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The WRITETIME function returns null for negative timestamp values</summary>
      <description>Insert a column with a negative timestamp value:INSERT INTO my_table (col1, col2, col3)VALUES ('val1', 'val2', 'val3') USING TIMESTAMP -1413614886750020;Then attempt to read the writetime:SELECT WRITETIME(col3) FROM my_table WHERE col1 = 'val1'The result is null.</description>
      <version>2.0.12,2.1.2</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.UpdateParameters.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.Selection.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="8144" opendate="2014-10-20 00:00:00" fixdate="2014-10-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Creating CQL2 tables fails in C* 2.1</summary>
      <description>Although cql2 has been deprecated and removed from cqlsh, the functionality is still accessible using thrift. However, it seems that creation of new tables via cql2 is broken in 2.1.CREATE KEYSPACE test_ks WITH strategy_class='SimpleStrategy' AND replication_factor = '1';CREATE TABLE test_cf (id text PRIMARY KEY, value text, test text);fails with the following stacktrace on the server:ERROR [MigrationStage:1] 2014-10-20 13:53:29,506 CassandraDaemon.java:153 - Exception in thread Thread[MigrationStage:1,5,main]java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 at java.util.ArrayList.rangeCheck(ArrayList.java:635) ~[na:1.7.0_51] at java.util.ArrayList.set(ArrayList.java:426) ~[na:1.7.0_51] at org.apache.cassandra.config.CFMetaData.rebuild(CFMetaData.java:2072) ~[main/:na] at org.apache.cassandra.config.CFMetaData.fromSchemaNoTriggers(CFMetaData.java:1842) ~[main/:na] at org.apache.cassandra.config.CFMetaData.fromSchema(CFMetaData.java:1882) ~[main/:na] at org.apache.cassandra.config.KSMetaData.deserializeColumnFamilies(KSMetaData.java:320) ~[main/:na] at org.apache.cassandra.db.DefsTables.mergeColumnFamilies(DefsTables.java:279) ~[main/:na] at org.apache.cassandra.db.DefsTables.mergeSchemaInternal(DefsTables.java:193) ~[main/:na] at org.apache.cassandra.db.DefsTables.mergeSchema(DefsTables.java:165) ~[main/:na] at org.apache.cassandra.service.MigrationManager$2.runMayThrow(MigrationManager.java:393) ~[main/:na] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[main/:na] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) ~[na:1.7.0_51] at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[na:1.7.0_51] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_51] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_51] at java.lang.Thread.run(Thread.java:744) [na:1.7.0_51]ERROR [Thrift:1] 2014-10-20 13:53:29,506 CustomTThreadPoolServer.java:219 - Error occurred during processing of message.java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:397) ~[main/:na] at org.apache.cassandra.service.MigrationManager.announce(MigrationManager.java:374) ~[main/:na] at org.apache.cassandra.service.MigrationManager.announceNewColumnFamily(MigrationManager.java:249) ~[main/:na] at org.apache.cassandra.service.MigrationManager.announceNewColumnFamily(MigrationManager.java:235) ~[main/:na] at org.apache.cassandra.cql.QueryProcessor.processStatement(QueryProcessor.java:662) ~[main/:na] at org.apache.cassandra.cql.QueryProcessor.process(QueryProcessor.java:802) ~[main/:na] at org.apache.cassandra.thrift.CassandraServer.execute_cql_query(CassandraServer.java:1941) ~[main/:na] at org.apache.cassandra.thrift.Cassandra$Processor$execute_cql_query.getResult(Cassandra.java:4558) ~[thrift/:na] at org.apache.cassandra.thrift.Cassandra$Processor$execute_cql_query.getResult(Cassandra.java:4542) ~[thrift/:na] at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[libthrift-0.9.1.jar:0.9.1] at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[libthrift-0.9.1.jar:0.9.1] at org.apache.cassandra.thrift.CustomTThreadPoolServer$WorkerProcess.run(CustomTThreadPoolServer.java:201) ~[main/:na] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_51] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_51] at java.lang.Thread.run(Thread.java:744) [na:1.7.0_51]Caused by: java.util.concurrent.ExecutionException: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 at java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[na:1.7.0_51] at java.util.concurrent.FutureTask.get(FutureTask.java:188) ~[na:1.7.0_51] at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:393) ~[main/:na] ... 14 common frames omittedCaused by: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 at java.util.ArrayList.rangeCheck(ArrayList.java:635) ~[na:1.7.0_51] at java.util.ArrayList.set(ArrayList.java:426) ~[na:1.7.0_51] at org.apache.cassandra.config.CFMetaData.rebuild(CFMetaData.java:2072) ~[main/:na] at org.apache.cassandra.config.CFMetaData.fromSchemaNoTriggers(CFMetaData.java:1842) ~[main/:na] at org.apache.cassandra.config.CFMetaData.fromSchema(CFMetaData.java:1882) ~[main/:na] at org.apache.cassandra.config.KSMetaData.deserializeColumnFamilies(KSMetaData.java:320) ~[main/:na] at org.apache.cassandra.db.DefsTables.mergeColumnFamilies(DefsTables.java:279) ~[main/:na] at org.apache.cassandra.db.DefsTables.mergeSchemaInternal(DefsTables.java:193) ~[main/:na] at org.apache.cassandra.db.DefsTables.mergeSchema(DefsTables.java:165) ~[main/:na] at org.apache.cassandra.service.MigrationManager$2.runMayThrow(MigrationManager.java:393) ~[main/:na] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[main/:na] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) ~[na:1.7.0_51] at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[na:1.7.0_51] ... 3 common frames omitted</description>
      <version>2.1.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql.CreateColumnFamilyStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="8147" opendate="2014-10-20 00:00:00" fixdate="2014-11-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Secondary indexing of map keys does not work properly when mixing contains and contains_key</summary>
      <description>If you have a table with a map column and an index on the map key selecting data using a contains key and a contains will not return the expected data.The problem can be reproduced using the following unit test: @Test public void testMapKeyContainsAndValueContains() throws Throwable { createTable("CREATE TABLE %s (account text, id int, categories map&lt;text,text&gt;, PRIMARY KEY (account, id))"); createIndex("CREATE INDEX ON %s(keys(categories))"); execute("INSERT INTO %s (account, id , categories) VALUES (?, ?, ?)", "test", 5, map("lmn", "foo")); assertRows(execute("SELECT * FROM %s WHERE account = ? AND id = ? AND categories CONTAINS KEY ? AND categories CONTAINS ? ALLOW FILTERING", "test", 5, "lmn", "foo"), row("test", 5, map("lmn", "foo"))); }</description>
      <version>2.1.2</version>
      <fixedVersion>Feature/2iIndex,Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.cql3.ContainsRelationTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.CollectionType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.SecondaryIndexSearcher.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.SecondaryIndexManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.composites.CompositesIndex.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateIndexStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.config.ColumnDefinition.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">pylib.cqlshlib.cql3handling.py</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">test.unit.org.apache.cassandra.streaming.StreamingTransferTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.io.sstable.SSTableReaderTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.ColumnFamilyStoreTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.CleanupTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.cql3.ColumnConditionTest.java</file>
      <file type="M">src.java.org.apache.cassandra.thrift.ThriftConversion.java</file>
      <file type="M">src.java.org.apache.cassandra.db.RangeSliceCommand.java</file>
      <file type="M">src.java.org.apache.cassandra.db.PagedRangeCommand.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.CompositeType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.SecondaryIndex.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.composites.CompositesIndexOnCollectionValue.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.composites.CompositesIndexOnCollectionKey.java</file>
      <file type="M">src.java.org.apache.cassandra.db.IndexExpression.java</file>
      <file type="M">src.java.org.apache.cassandra.db.filter.ExtendedFilter.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.QueryProcessor.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SingleColumnRestriction.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.Restriction.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.ModificationStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.SingleColumnRelation.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.Relation.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.MultiColumnRelation.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.Cql.g</file>
      <file type="M">src.java.org.apache.cassandra.cql3.ColumnCondition.java</file>
    </fixedFiles>
  </bug>
  <bug id="8166" opendate="2014-10-22 00:00:00" fixdate="2014-10-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Not all data is loaded to Pig using CqlNativeStorage</summary>
      <description>Not all the data from Cassandra table is loaded into Pig using CqlNativeStorage function.Steps to reproduce:cql3 create table statement:CREATE TABLE time_bucket_step ( key varchar, object_id varchar, value varchar, PRIMARY KEY (key, object_id));Loading and saving data to Cassandra ("sorted" file is in the attachment): time_bucket_step = load 'sorted' using PigStorage('\t') as (key:chararray, object_id:chararray, value:chararray);records = foreach time_bucket_step generate TOTUPLE(TOTUPLE('key', key),TOTUPLE('object_id', object_id)), TOTUPLE(value);store records into 'cql://socialdata/time_bucket_step?output_query=UPDATE+socialdata.time_bucket_step+set+value+%3D+%3F' using org.apache.cassandra.hadoop.pig.CqlNativeStorage();Results:Input(s):Successfully read 139026 records (11115817 bytes) from: "hdfs://.../sorted"Output(s):Successfully stored 139026 records in: "cql://socialdata/time_bucket_step?output_query=UPDATE+socialdata.time_bucket_step+set+value+%3D+%3F"Loading data from Cassandra: (note that not all data are read)time_bucket_step_cass = load 'cql://socialdata/time_bucket_step' using org.apache.cassandra.hadoop.pig.CqlNativeStorage();store time_bucket_step_cass into 'time_bucket_step_cass' using PigStorage('\t','-schema');Results:Input(s):Successfully read 80727 records (20068 bytes) from: "cql://socialdata/time_bucket_step"Output(s):Successfully stored 80727 records (2098178 bytes) in: "hdfs://..../time_bucket_step_cass"Actual: only 80727 of 139026 records were loadedExpected: All data should be loaded</description>
      <version>2.0.12,2.1.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.hadoop.cql3.CqlRecordReader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="8171" opendate="2014-10-23 00:00:00" fixdate="2014-11-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up generics</summary>
      <description>Some uses of generics in the code are causing much more harm than good, and in some cases generic types are used unsafely, hiding potential problems in the code.Generics need to be cleaned up to clarify the types, remove unnecessary type specialization when it does not make sense, and significantly reduce the number of unhelpful warnings.</description>
      <version>2.1.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.dht.RangeTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.dht.RandomPartitionerTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.dht.PartitionerTestCase.java</file>
      <file type="M">test.unit.org.apache.cassandra.dht.OrderPreservingPartitionerTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.dht.Murmur3PartitionerTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.dht.ByteOrderedPartitionerTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.dht.BootStrapperTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.KeyCollisionTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.ColumnFamilyStoreTest.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.SSTableImport.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.SSTableExport.java</file>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraServer.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.TokenSerializer.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.Token.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.StringToken.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.RingPosition.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.RangeStreamer.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.Range.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.RandomPartitioner.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.OrderPreservingPartitioner.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.Murmur3Partitioner.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.LongToken.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.LocalToken.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.LocalPartitioner.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.IPartitioner.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.IncludingExcludingBounds.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.ExcludingBounds.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.BytesToken.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.ByteOrderedPartitioner.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.Bounds.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.BigIntegerToken.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.AbstractPartitioner.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.AbstractByteOrderedPartitioner.java</file>
      <file type="M">src.java.org.apache.cassandra.dht.AbstractBounds.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.LocalByPartionerType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.HintedHandOffManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.BatchlogManager.java</file>
      <file type="M">src.java.org.apache.cassandra.cql.QueryProcessor.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.client.RingCache.java</file>
    </fixedFiles>
  </bug>
  <bug id="8178" opendate="2014-10-23 00:00:00" fixdate="2014-11-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Column names are not converted correctly for non-text comparators</summary>
      <description>If a column family is created with a non-text comparator through Thrift (or cassandra-cli) and column metadata is defined, those column names cannot be queried through cql3.For example:[default@ks1] create column family entity_data... with column_type = 'Standard'... and comparator = 'BytesType'... and default_validation_class = 'BytesType'... and key_validation_class = 'UTF8Type'... and column_metadata = [... {column_name : '0008',... validation_class : UTF8Type,... index_name : 'entity_data_0008_idx',... index_type : 0}];When you attempt to query that column through cqlsh, you'll get an error like this:cqlsh:ks1&gt; select "0008" FROM entity_data ;Bad Request: Undefined name 0008 in selection clauseThe problem is that we aren't taking the comparator type into account when converting column names in cql3 statements to their internal (ByteBuffer) representation.</description>
      <version>2.0.12,2.1.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.Selection.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.Selectable.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.RawSelector.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.ModificationStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.DeleteStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateIndexStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.AlterTableStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.SingleColumnRelation.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.Operation.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.MultiColumnRelation.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.Cql.g</file>
      <file type="M">src.java.org.apache.cassandra.cql3.ColumnIdentifier.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.UpdateStatement.java</file>
    </fixedFiles>
  </bug>
  <bug id="8205" opendate="2014-10-29 00:00:00" fixdate="2014-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ColumnFamilyMetrics#totalDiskSpaceUsed gets wrong value when SSTable is deleted</summary>
      <description>ColumnFamilyMetrics#totalDiskSpaceUsed is decremented when actual SSTables files are deleted from disk. The amount of decrement is calculated at the beginning of SSTableReader instantiation(through SSTableDeletionTask).But the size can change because Summary.db file may be re-created after SSTableReader instantiation, and that leads to calculate wrong value for totalDiskSpaceUsed.I attached unit test file for 2.0, but you can also compare the value after doing "TRUNCATE".</description>
      <version>2.0.12,2.1.2</version>
      <fixedVersion>Legacy/Observability</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableDeletingTask.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="8206" opendate="2014-10-29 00:00:00" fixdate="2014-11-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Deleting columns breaks secondary index on clustering column</summary>
      <description>Removing items from a set breaks index for field id:cqlsh:cs&gt; CREATE TABLE buckets ( ... tenant int, ... id int, ... items set&lt;text&gt;, ... PRIMARY KEY (tenant, id) ... );cqlsh:cs&gt; CREATE INDEX buckets_ids ON buckets(id);cqlsh:cs&gt; INSERT INTO buckets (tenant, id, items) VALUES (1, 1, {'foo', 'bar'});cqlsh:cs&gt; SELECT * FROM buckets; tenant | id | items--------+----+---------------- 1 | 1 | {'bar', 'foo'}(1 rows)cqlsh:cs&gt; SELECT * FROM buckets WHERE id = 1; tenant | id | items--------+----+---------------- 1 | 1 | {'bar', 'foo'}(1 rows)cqlsh:cs&gt; UPDATE buckets SET items=items-{'foo'} WHERE tenant=1 AND id=1;cqlsh:cs&gt; SELECT * FROM buckets; tenant | id | items--------+----+--------- 1 | 1 | {'bar'}(1 rows)cqlsh:cs&gt; SELECT * FROM buckets WHERE id = 1;(0 rows)Re-building the index fixes the issue:cqlsh:cs&gt; DROP INDEX buckets_ids;cqlsh:cs&gt; CREATE INDEX buckets_ids ON buckets(id);cqlsh:cs&gt; SELECT * FROM buckets WHERE id = 1; tenant | id | items--------+----+--------- 1 | 1 | {'bar'}(1 rows)Adding items does not cause similar failure, only delete. Also didn't test if other collections are also affected</description>
      <version>2.0.12,2.1.2</version>
      <fixedVersion>Feature/2iIndex</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.index.SecondaryIndexManager.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.SecondaryIndex.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.PerColumnSecondaryIndex.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.composites.CompositesIndexOnPartitionKey.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.composites.CompositesIndexOnClusteringKey.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.AbstractSimplePerColumnSecondaryIndex.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">test.unit.org.apache.cassandra.db.SecondaryIndexColumnSizeTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.RangeTombstoneTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="8240" opendate="2014-11-1 00:00:00" fixdate="2014-11-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Attach existing sources to "Referenced libraries" in Eclipse project</summary>
      <description>At the moment ant generate-eclipse-files adds all necessary jars to "Referenced libraries", but doesn't attach sources to those libraries.I'm attaching a simple patch which does that.</description>
      <version>2.1.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8247" opendate="2014-11-3 00:00:00" fixdate="2014-11-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HHOM creates repeated &amp;#39;No files to compact for user defined compaction&amp;#39; messages</summary>
      <description>HH is a guess because it's every 10m, but it seems likely:INFO 19:16:39 No files to compact for user defined compactionINFO 19:26:39 No files to compact for user defined compactionINFO 19:36:39 No files to compact for user defined compactionINFO 19:46:39 No files to compact for user defined compactionINFO 19:56:39 No files to compact for user defined compaction</description>
      <version>2.0.12,2.1.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.HintedHandOffManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="8248" opendate="2014-11-4 00:00:00" fixdate="2014-12-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Possible memory leak</summary>
      <description>Sometimes during repair cassandra starts to consume more memory than expected.Total amount of data on node is about 20GB.Size of the data directory is 66GC because of snapshots.Top reports: PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND15724 loadbase 20 0 493g 55g 44g S 28 44.2 4043:24 javaAt the /proc/15724/maps there are a lot of deleted file maps7f63a6102000-7f63a6332000 r--s 00000000 08:21 9442763 /ssd/cassandra/data/iss/feedback_history-d32bc7e048c011e49b989bc3e8a5a440/iss-feedback_history-tmplink-ka-328671-Index.db (deleted)7f63a6332000-7f63a6562000 r--s 00000000 08:21 9442763 /ssd/cassandra/data/iss/feedback_history-d32bc7e048c011e49b989bc3e8a5a440/iss-feedback_history-tmplink-ka-328671-Index.db (deleted)7f63a6562000-7f63a6792000 r--s 00000000 08:21 9442763 /ssd/cassandra/data/iss/feedback_history-d32bc7e048c011e49b989bc3e8a5a440/iss-feedback_history-tmplink-ka-328671-Index.db (deleted)7f63a6792000-7f63a69c2000 r--s 00000000 08:21 9442763 /ssd/cassandra/data/iss/feedback_history-d32bc7e048c011e49b989bc3e8a5a440/iss-feedback_history-tmplink-ka-328671-Index.db (deleted)7f63a69c2000-7f63a6bf2000 r--s 00000000 08:21 9442763 /ssd/cassandra/data/iss/feedback_history-d32bc7e048c011e49b989bc3e8a5a440/iss-feedback_history-tmplink-ka-328671-Index.db (deleted)7f63a6bf2000-7f63a6e22000 r--s 00000000 08:21 9442763 /ssd/cassandra/data/iss/feedback_history-d32bc7e048c011e49b989bc3e8a5a440/iss-feedback_history-tmplink-ka-328671-Index.db (deleted)7f63a6e22000-7f63a7052000 r--s 00000000 08:21 9442763 /ssd/cassandra/data/iss/feedback_history-d32bc7e048c011e49b989bc3e8a5a440/iss-feedback_history-tmplink-ka-328671-Index.db (deleted)7f63a7052000-7f63a7282000 r--s 00000000 08:21 9442763 /ssd/cassandra/data/iss/feedback_history-d32bc7e048c011e49b989bc3e8a5a440/iss-feedback_history-tmplink-ka-328671-Index.db (deleted)7f63a7282000-7f63a74b2000 r--s 00000000 08:21 9442763 /ssd/cassandra/data/iss/feedback_history-d32bc7e048c011e49b989bc3e8a5a440/iss-feedback_history-tmplink-ka-328671-Index.db (deleted)7f63a74b2000-7f63a76e2000 r--s 00000000 08:21 9442763 /ssd/cassandra/data/iss/feedback_history-d32bc7e048c011e49b989bc3e8a5a440/iss-feedback_history-tmplink-ka-328671-Index.db (deleted)7f63a76e2000-7f63a7912000 r--s 00000000 08:21 9442763 /ssd/cassandra/data/iss/feedback_history-d32bc7e048c011e49b989bc3e8a5a440/iss-feedback_history-tmplink-ka-328671-Index.db (deleted)7f63a7912000-7f63a7b42000 r--s 00000000 08:21 9442763 /ssd/cassandra/data/iss/feedback_history-d32bc7e048c011e49b989bc3e8a5a440/iss-feedback_history-tmplink-ka-328671-Index.db (deleted)7f63a7b42000-7f63a7d72000 r--s 00000000 08:21 9442763 /ssd/cassandra/data/iss/feedback_history-d32bc7e048c011e49b989bc3e8a5a440/iss-feedback_history-tmplink-ka-328671-Index.db (deleted)7f63a7d72000-7f63a7fa2000 r--s 00000000 08:21 9442763 /ssd/cassandra/data/iss/feedback_history-d32bc7e048c011e49b989bc3e8a5a440/iss-feedback_history-tmplink-ka-328671-Index.db (deleted)7f63a7fa2000-7f63a81d2000 r--s 00000000 08:21 9442763 /ssd/cassandra/data/iss/feedback_history-d32bc7e048c011e49b989bc3e8a5a440/iss-feedback_history-tmplink-ka-328671-Index.db (deleted)7f63a81d2000-7f63a8402000 r--s 00000000 08:21 9442763 /ssd/cassandra/data/iss/feedback_history-d32bc7e048c011e49b989bc3e8a5a440/iss-feedback_history-tmplink-ka-328671-Index.db (deleted)7f63a8402000-7f63a8622000 r--s 00000000 08:21 9442763 /ssd/cassandra/data/iss/feedback_history-d32bc7e048c011e49b989bc3e8a5a440/iss-feedback_history-tmplink-ka-328671-Index.db (deleted)7f63a8622000-7f63a8842000 r--s 00000000 08:21 9442763 /ssd/cassandra/data/iss/feedback_history-d32bc7e048c011e49b989bc3e8a5a440/iss-feedback_history-tmplink-ka-328671-Index.db (deleted)7f63a8842000-7f63a8a62000 r--s 00000000 08:21 9442763 /ssd/cassandra/data/iss/feedback_history-d32bc7e048c011e49b989bc3e8a5a440/iss-feedback_history-tmplink-ka-328671-Index.db (deleted)7f63a8a62000-7f63a8c82000 r--s 00000000 08:21 9442763 /ssd/cassandra/data/iss/feedback_history-d32bc7e048c011e49b989bc3e8a5a440/iss-feedback_history-tmplink-ka-328671-Index.db (deleted)7f63a8c82000-7f63a8ea2000 r--s 00000000 08:21 9442763 /ssd/cassandra/data/iss/feedback_history-d32bc7e048c011e49b989bc3e8a5a440/iss-feedback_history-tmplink-ka-328671-Index.db (deleted)7f63a8ea2000-7f63a90c2000 r--s 00000000 08:21 9442763 /ssd/cassandra/data/iss/feedback_history-d32bc7e048c011e49b989bc3e8a5a440/iss-feedback_history-tmplink-ka-328671-Index.db (deleted)7f63a90c2000-7f63a92e2000 r--s 00000000 08:21 9442763 /ssd/cassandra/data/iss/feedback_history-d32bc7e048c011e49b989bc3e8a5a440/iss-feedback_history-tmplink-ka-328671-Index.db (deleted)$ sudo grep deleted /proc/15724/maps | wc -l640118$ sudo grep -v deleted /proc/15724/maps | wc -l303340</description>
      <version>None</version>
      <fixedVersion>Legacy/StreamingandMessaging</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableWriter.java</file>
    </fixedFiles>
  </bug>
  <bug id="8258" opendate="2014-11-5 00:00:00" fixdate="2014-11-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>SELECT ... TOKEN() function broken in C* 2.1.1</summary>
      <description>Cassandra 2.1.1, Oracle Java 1.7.0_72, Ubuntu 14.04.1 64 bitcqlsh:blink&gt; show version;[cqlsh 5.0.1 | Cassandra 2.1.1 | CQL spec 3.2.0 | Native protocol v3]cqlsh:blink&gt; select token(id) from users limit 1;list index out of rangeversusCassandra 2.1.0, Oracle Java 1.7.0_67, Ubuntu 12.04.5 64 bitcqlsh:blink&gt; show version;[cqlsh 5.0.1 | Cassandra 2.1.0 | CQL spec 3.2.0 | Native protocol v3]cqlsh:blink&gt; select token(id) from users limit 1; token(id)---------------------- -9223237793432919630(1 rows)It also fails with C* 2.1.1, Java 1.7.0_72, Ubuntu 12.04.5.</description>
      <version>2.1.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.test.test.cql.parsing.py</file>
      <file type="M">pylib.cqlshlib.cql3handling.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="8262" opendate="2014-11-5 00:00:00" fixdate="2014-11-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>parse_for_table_meta errors out on queries with undefined grammars</summary>
      <description>CASSANDRA-6910 introduced changes to the cqlsh function parse_for_table_meta that cause an error to be thrown whenever a query does not have its grammar defined in cql3handling.py. However, this is affecting queries that are legitimate cql syntax and are accepted by Cassandra, but aren't defined in cqlsh.</description>
      <version>2.1.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
</bugrepository>
