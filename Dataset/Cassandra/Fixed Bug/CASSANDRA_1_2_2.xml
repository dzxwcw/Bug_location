<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="CASSANDRA">
  <bug id="4295" opendate="2012-5-30 00:00:00" fixdate="2012-2-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement caching of authorization results</summary>
      <description>1.2 will come with default IAuthority implementation that stores permissions in Cassandra, and each permission check will involve at least 1 Cassandra read. Some form of authorization result caching is very important for this scenario.</description>
      <version>1.2.2</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraServer.java</file>
      <file type="M">src.java.org.apache.cassandra.service.ClientState.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.BatchStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">src.java.org.apache.cassandra.auth.AuthenticatedUser.java</file>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4366" opendate="2012-6-21 00:00:00" fixdate="2012-10-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>add UseCondCardMark XX jvm settings on jdk 1.7</summary>
      <description>found by jbellisadding jvm extension setting UseCondCardMark as defined herehttp://bugs.sun.com/bugdatabase/view_bug.do?bug_id=7029167for better lock handling especially on hotspot with multicore processors.</description>
      <version>1.2.2</version>
      <fixedVersion>Packaging</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.cassandra-env.sh</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4554" opendate="2012-8-17 00:00:00" fixdate="2012-2-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Log when a node is down longer than the hint window and we stop saving hints</summary>
      <description>We know that we need to repair whenever we lose a node or disk permanently (since it may have had undelivered hints on it), but without exposing this we don't know when nodes stop saving hints for a temporarily dead node, unless we're paying very close attention to external monitoring.</description>
      <version>1.2.2,2.0beta1</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.HintedHandOffTest.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.db.SystemTable.java</file>
      <file type="M">src.java.org.apache.cassandra.db.HintedHandOffManager.java</file>
      <file type="M">src.java.org.apache.cassandra.config.KSMetaData.java</file>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
    </fixedFiles>
  </bug>
  <bug id="5038" opendate="2012-12-6 00:00:00" fixdate="2012-2-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LZ4Compressor</summary>
      <description>LZ4 is a new compression algo that's ~2x faster than Snappy.jpountz has written a nice java port which includes a misc.Unsafe version that performs &gt;= than our java snappy version.Details at http://blog.jpountz.net/post/28092106032/wow-lz4-is-fastThe nice thing is this should work with java7 and be more portable.We can also fallback the pure java impl</description>
      <version>1.2.2</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">NOTICE.txt</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="5080" opendate="2012-12-20 00:00:00" fixdate="2012-2-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cassandra-cli doesn&amp;#39;t support JMX authentication.</summary>
      <description>It seems that cassandra-cli doesn't support JMX user authentication.Specifically I went about securing our Cassandra cluster slightly &amp;#8211; I've added cassandra-level authentication (which cassandra-cli does support), but then I discovered that nodetool is still completely unprotected. So I went ahead and secured JMX (via -Dcom.sun.management.jmxremote.password.file and -Dcom.sun.management.jmxremote.access.file). Nodetool supports JMX authentication via -u and -pw options.However it seems that cassandra-cli doesn't support JMX authentication, e.g.:apache-cassandra-1.1.6\bin&gt;cassandra-cli -h hostname -u experiment -pw passwordStarting Cassandra ClientConnected to: "db" on hostname/9160Welcome to Cassandra CLI version 1.1.6&amp;#91;experiment@unknown&amp;#93; show keyspaces;WARNING: Could not connect to the JMX on hostname:7199, information won't be shown.Keyspace: system: Replication Strategy: org.apache.cassandra.locator.LocalStrategy Durable Writes: true Options: &amp;#91;replication_factor:1&amp;#93;... (rest of keyspace output snipped)help connect; and cassandra-cli --help do not seem to indicate that there's any way to specify JMX login information.</description>
      <version>1.1.11,1.2.2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cli.CliSessionState.java</file>
      <file type="M">src.java.org.apache.cassandra.cli.CliOptions.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5105" opendate="2013-1-3 00:00:00" fixdate="2013-2-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>repair -pr throws EOFException</summary>
      <description>nodetool repair -pr threw an EOF exceptionnode1ERROR 12:50:18,723 Exception in thread Thread[Streaming to /10.8.25.113:1,5,main]java.lang.RuntimeException: java.io.EOFException at com.google.common.base.Throwables.propagate(Throwables.java:160) at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:32) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:662)Caused by: java.io.EOFException at java.io.DataInputStream.readInt(DataInputStream.java:375) at org.apache.cassandra.streaming.FileStreamTask.receiveReply(FileStreamTask.java:193) at org.apache.cassandra.streaming.compress.CompressedFileStreamTask.stream(CompressedFileStreamTask.java:114) at org.apache.cassandra.streaming.FileStreamTask.runMayThrow(FileStreamTask.java:91) at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)node2 INFO 12:49:45,139 Finished streaming session to /10.8.30.13ERROR 12:50:18,799 Exception in thread Thread[Thread-4031,5,main]java.lang.RuntimeException: Last written key DecoratedKey(167625858728826091814875924785363245309, 6634333531356661643161636636373738353431363162353031376164386339) &gt;= current key DecoratedKey(33957321636818582219838207277782228619, 696c2e636f6d200a3c42523e0a3c42523e0a5472656e7420202020202020202020202020202020422e204d697261636c652020202020202020202020202020202020202020202020202020202020202020202020202020202020200a2020266e62737020266e62737020746d697261636c654073696d6d6f6e736669726d2e636f6d2c206c776f6f74656e4073696d6d6f6e736669726d2e636f6d203c42523e0a3c42523e0a56616e636520202020202020202020202020202020522e20416e64727573202020202020202020202020202020202020202020202020202020202020202020202020202020202020200a2020266e62737020266e627370207672614061622d706c632e636f6d203c42523e0a3c42523e0a5665726e6f6e202020202020202020202020202020462e20476c656e6e20202020202020202020202020202020202020202020202020202020202020202020202020202020202020200a2020266e62737020266e62737020676c656e6e6c6177406c6f77636f756e7472796c61777965722e636f6d203c42523e0a3c42523e0a56696e63656e7420202020202020202020202020204a2e20446573616c766f2020202020202020202020202020202020202020202020202020202020202020202020202020202020200a2020266e62737020266e6273702076646573616c766f40646573616c766f6c61776669726d2e636f6d203c42523e0a3c42523e0a56696e63656e7420202020202020202020202020204a616d657320436172746572202020202020202020202020202020202020202020202020202020202020202020202020202020200a2020202020266e62737020266e627370207663617274657240676972617264696b656573652e636f6d2c207479616d6173616b6940676972617264696b656573652e636f6d203c42523e0a0a3c42523e0a572e202020202020202020202020202020202020204a616d65732053696e676c65746f6e202020202020202020202020202020202020202020202020202020202020202020202020200a2020202020266e627370202...trunkated...324132393239413134333439413834453531394133373431) writing into /data/cassandra/evidence/fingerprints/evidence-fingerprints-tmp-ia-161-Data.db at org.apache.cassandra.io.sstable.SSTableWriter.beforeAppend(SSTableWriter.java:133) at org.apache.cassandra.io.sstable.SSTableWriter.appendFromStream(SSTableWriter.java:209) at org.apache.cassandra.streaming.IncomingStreamReader.streamIn(IncomingStreamReader.java:179) at org.apache.cassandra.streaming.IncomingStreamReader.read(IncomingStreamReader.java:122) at org.apache.cassandra.net.IncomingTcpConnection.stream(IncomingTcpConnection.java:226) at org.apache.cassandra.net.IncomingTcpConnection.handleStream(IncomingTcpConnection.java:166) at org.apache.cassandra.net.IncomingTcpConnection.run(IncomingTcpConnection.java:66)</description>
      <version>1.2.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.compress.CompressionMetadata.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5168" opendate="2013-1-17 00:00:00" fixdate="2013-1-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>word count example fails with InvalidRequestException(why:Start key&amp;#39;s token sorts after end token)</summary>
      <description>Tried with the latest 1.2 branch (commit d64dc2eb3a1a3c3771bbe3218af9ce9629ec67bf) and got this error. Seems related to but different than CASSANDRA-5106.</description>
      <version>1.1.10,1.2.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.thrift.ThriftValidation.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5189" opendate="2013-1-27 00:00:00" fixdate="2013-1-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>compact storage metadata is broken</summary>
      <description>cqlsh:foo&gt; CREATE TABLE bar ( ... id int primary key, ... i int ... ) WItH COMPACT STORAGE;cqlsh:foo&gt; INSERT INTO bar (id, i) VALUES (1, 2);Bad Request: Missing PRIMARY KEY part column1Perhaps you meant to use CQL 2? Try using the -2 option when starting cqlsh.cqlsh:foo&gt; INSERT INTO bar (id, column1) VALUES (1, 2);Bad Request: Missing mandatory column iPerhaps you meant to use CQL 2? Try using the -2 option when starting cqlsh.</description>
      <version>1.2.2</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateColumnFamilyStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5203" opendate="2013-1-30 00:00:00" fixdate="2013-2-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Repair command should report error when replica node is dead</summary>
      <description>CASSANDRA-4767 makes nodetool repair command to print progress, but when replica node is dead and repair cannot be proceeded, nodetool repair just report session finished. Instead, nodetool should report session is failed.Also, it is nice to exit command with status code of 1 when repair failed.</description>
      <version>1.1.10,1.2.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeProbe.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">src.java.org.apache.cassandra.service.AntiEntropyService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5207" opendate="2013-1-31 00:00:00" fixdate="2013-1-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Validate login for USE queries</summary>
      <description>CASSANDRA-5144 added login validation to Thrift set_keyspace method. Same should be done for CQL2 and CQL3 USE queries, otherwise C* will leak keyspace existence to strangers even when the configured authenticator requires login.</description>
      <version>1.2.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql.QueryProcessor.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.UseStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5216" opendate="2013-2-3 00:00:00" fixdate="2013-2-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>fix bug on decommission and removeNode</summary>
      <description>1. If one node decommissioned, the epState.isAlive is always true since it is DEAD_STATES in convict(). 0001 patch fixes that.2. If we removeNode B on A, we should put expireTime of B in expireTimeEndpointMap of A, otherwise the epState of B will never be removed from gossip entirely. 0002 patch fixes that.3. After removeNode B, C reboots and receives epState of B. Since B is not in the tokenMetadata, C just wipes away B without recording B's expireTime. In this case, B will be always in gossip. 0003 patch fixes that.</description>
      <version>1.2.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.Gossiper.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5225" opendate="2013-2-6 00:00:00" fixdate="2013-2-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Missing columns, errors when requesting specific columns from wide rows</summary>
      <description>With Cassandra 1.2.1 (and probably 1.2.0), I'm seeing some problems with Thrift queries that request a set of specific column names when the row is very wide.To reproduce, I'm inserting 10 million columns into a single row and then randomly requesting three columns by name in a loop. It's common for only one or two of the three columns to be returned. I'm also seeing stack traces like the following in the Cassandra log:ERROR 13:12:01,017 Exception in thread Thread[ReadStage:76,5,main]java.lang.RuntimeException: org.apache.cassandra.io.sstable.CorruptSSTableException: org.apache.cassandra.db.ColumnSerializer$CorruptColumnException: invalid column name length 0 (/var/lib/cassandra/data/Keyspace1/CF1/Keyspace1-CF1-ib-5-Data.db, 14035168 bytes remaining) at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:1576) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:662)Caused by: org.apache.cassandra.io.sstable.CorruptSSTableException: org.apache.cassandra.db.ColumnSerializer$CorruptColumnException: invalid column name length 0 (/var/lib/cassandra/data/Keyspace1/CF1/Keyspace1-CF1-ib-5-Data.db, 14035168 bytes remaining) at org.apache.cassandra.db.columniterator.SSTableNamesIterator.&lt;init&gt;(SSTableNamesIterator.java:69) at org.apache.cassandra.db.filter.NamesQueryFilter.getSSTableColumnIterator(NamesQueryFilter.java:81) at org.apache.cassandra.db.filter.QueryFilter.getSSTableColumnIterator(QueryFilter.java:68) at org.apache.cassandra.db.CollationController.collectTimeOrderedData(CollationController.java:133) at org.apache.cassandra.db.CollationController.getTopLevelColumns(CollationController.java:65) at org.apache.cassandra.db.ColumnFamilyStore.getTopLevelColumns(ColumnFamilyStore.java:1358) at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:1215) at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:1127) at org.apache.cassandra.db.Table.getRow(Table.java:355) at org.apache.cassandra.db.SliceByNamesReadCommand.getRow(SliceByNamesReadCommand.java:64) at org.apache.cassandra.service.StorageProxy$LocalReadRunnable.runMayThrow(StorageProxy.java:1052) at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:1572) ... 3 moreThis doesn't seem to happen when the row is smaller, so it might have something to do with incremental large row compaction.</description>
      <version>1.2.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.io.sstable.IndexHelperTest.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.IndexHelper.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5227" opendate="2013-2-7 00:00:00" fixdate="2013-2-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Binary protocol: avoid sending notification for 0.0.0.0</summary>
      <description>Some binary protocol notifications embed the rpc address of a node. However, we allow to use 0.0.0.0 for said rpc address to bind to all interfaces. In that case, we shouldn't send that in the notification as it's useless, and we should send the listen_address instead.</description>
      <version>1.2.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.transport.Server.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5230" opendate="2013-2-7 00:00:00" fixdate="2013-2-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cql3 doesn&amp;#39;t support multiple clauses on primary key components</summary>
      <description>In trying to write a dtest for CASSANDRA-5225, I noticed that given a table such as:CREATE TABLE foo ( key text, c text, v text, PRIMARY KEY (key, c))It is possible to slice the values of 1 or 2 for c:select c from foo where key = 'foo' and c &gt; '0' and c &lt; '3';However, there is no way to get these explicitly by name, even though it should be possible:cqlsh:Keyspace1&gt; select c from foo where key = 'foo' and c in ('1', '2');Bad Request: PRIMARY KEY part c cannot be restricted by IN relation</description>
      <version>1.2.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5231" opendate="2013-2-8 00:00:00" fixdate="2013-2-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add username autocompletion to cqlsh</summary>
      <description>Add cqlsh username autocompletion to grant/revoke/list/drop/alter queries.</description>
      <version>1.2.2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.cql3handling.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5232" opendate="2013-2-8 00:00:00" fixdate="2013-2-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ALTER TABLE ADD - data loss</summary>
      <description>cqlsh:Test&gt; CREATE TABLE t1 (id int PRIMARY KEY, t text);cqlsh:Test&gt; UPDATE t1 SET t = '111' WHERE id = 1;cqlsh:Test&gt; ALTER TABLE t1 ADD l list&lt;text&gt;;cqlsh:Test&gt; SELECT * FROM t1; id | l | t----------- 1 | null | 111cqlsh:Test&gt; ALTER TABLE t1 ADD m map&lt;int, text&gt;;cqlsh:Test&gt; SELECT * FROM t1;cqlsh:Test&gt;Last query doesn't return any data.</description>
      <version>1.2.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.DataTracker.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5233" opendate="2013-2-8 00:00:00" fixdate="2013-2-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add cqlsh help for auth statements</summary>
      <description>Add cqlsh help for CREATE USER/DROP USER/GRANT/REVOKE etc.</description>
      <version>1.2.2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.helptopics.py</file>
    </fixedFiles>
  </bug>
  <bug id="5240" opendate="2013-2-11 00:00:00" fixdate="2013-2-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CQL3 has error with Compund row keys when secondray index involved</summary>
      <description>CREATE TABLE test( interval text, seq int, id int, severity int, PRIMARY KEY ((interval, seq), id)) WITH CLUSTERING ORDER BY (id DESC);&amp;#8211;CREATE INDEX ON test(severity);insert into test(interval, seq, id , severity) values('t',1, 1, 1);insert into test(interval, seq, id , severity) values('t',1, 2, 1);insert into test(interval, seq, id , severity) values('t',1, 3, 2);insert into test(interval, seq, id , severity) values('t',1, 4, 3);insert into test(interval, seq, id , severity) values('t',2, 1, 3);insert into test(interval, seq, id , severity) values('t',2, 2, 3);insert into test(interval, seq, id , severity) values('t',2, 3, 1);insert into test(interval, seq, id , severity) values('t',2, 4, 2);select * from test where severity = 3 and interval = 't' and seq =1;Bad Request: Start key sorts after end key. This is not allowed; you probably should not specify end key at all under random partitionerThe following works fineCREATE TABLE test( interval text, id int, severity int, PRIMARY KEY (interval, id)) WITH CLUSTERING ORDER BY (id DESC);&amp;#8211;CREATE INDEX ON test(severity);insert into test(interval, id , severity) values('t1', 4, 1);insert into test(interval, id , severity) values('t1', 1, 3);insert into test(interval, id , severity) values('t1', 2, 2);insert into test(interval, id , severity) values('t1', 3, 3);insert into test(interval, id , severity) values('t2', 3, 3); insert into test(interval, id , severity) values('t2', 1, 3); insert into test(interval, id , severity) values('t2', 2, 1);select * from test where severity = 3 and interval = 't1';interval | id | severity-------------------- t1 | 3 | 3 t1 | 1 | 3</description>
      <version>1.2.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5241" opendate="2013-2-11 00:00:00" fixdate="2013-2-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix forceBlockingFlush</summary>
      <description>ForceBlockingFlush doesn't guarantee that after the call, every that the thread has written prior to the call will be fully flushed. At least not in the case of concurrent flushes, because if 2 threads flush roughly at the same time, one will have it's forceBlockingFlush call return immediately because the memtable will be clean (even though some of the thread writes may have not be fully flushed yet).I think this is very fragile and make it easy to have hard to find races and so we should fix it. Typically a forceFlush that see a clean memtable could submit a dummy task in the postFlushExecutor and wait for that.</description>
      <version>1.2.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>
