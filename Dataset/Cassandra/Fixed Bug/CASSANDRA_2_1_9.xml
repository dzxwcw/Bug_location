<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="CASSANDRA">
  <bug id="10004" opendate="2015-8-6 00:00:00" fixdate="2015-8-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow changing default encoding on cqlsh</summary>
      <description>Currently the encoding option is not exposed as a command line parameter, so users cannot specify a different encoding other than the System's default.</description>
      <version>2.1.9,2.2.1,3.0beta1</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug id="10015" opendate="2015-8-7 00:00:00" fixdate="2015-8-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create tool to debug why expired sstables are not getting dropped</summary>
      <description>Sometimes fully expired sstables are not getting dropped, and it is a real pain to manually find out why.A tool that outputs which sstable blocks (by having older data than the newest tombstone in an expired sstable) expired ones would save a lot of time.</description>
      <version>2.0.17,2.1.9,2.2.1,3.0beta1</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.compaction.TTLExpiryTest.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10048" opendate="2015-8-11 00:00:00" fixdate="2015-8-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cassandra-stress - Decimal is a BigInt not a Double</summary>
      <description>Similar to CASSANDRA-8882I'll provide a patch.com.datastax.driver.core.exceptions.InvalidTypeException: Invalid type for value 26 of CQL type decimal, expecting class java.math.BigDecimal but class java.lang.Double providedcom.datastax.driver.core.exceptions.InvalidTypeException: Invalid type for value 26 of CQL type decimal, expecting class java.math.BigDecimal but class java.lang.Double providedcom.datastax.driver.core.exceptions.InvalidTypeException: Invalid type for value 26 of CQL type decimal, expecting class java.math.BigDecimal but class java.lang.Double provided^Ccom.datastax.driver.core.exceptions.InvalidTypeException: Invalid type for value 26 of CQL type decimal, expecting class java.math.BigDecimal but class java.lang.Double providedcom.datastax.driver.core.exceptions.InvalidTypeException: Invalid type for value 26 of CQL type decimal, expecting class java.math.BigDecimal but class java.lang.Double providedcom.datastax.driver.core.exceptions.InvalidTypeException: Invalid type for value 26 of CQL type decimal, expecting class java.math.BigDecimal but class java.lang.Double providedcom.datastax.driver.core.exceptions.InvalidTypeException: Invalid type for value 26 of CQL type decimal, expecting class java.math.BigDecimal but class java.lang.Double providedcom.datastax.driver.core.exceptions.InvalidTypeException: Invalid type for</description>
      <version>2.1.9,2.2.1,3.0beta2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.stress.src.org.apache.cassandra.stress.StressProfile.java</file>
    </fixedFiles>
  </bug>
  <bug id="7342" opendate="2014-6-2 00:00:00" fixdate="2014-8-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CAS writes do not have hint functionality.</summary>
      <description>When a dead node comes up, it gets the last commit but not anything which it has missed. This reduces the durability of those writes compared to other writes.</description>
      <version>2.1.9,2.2.1,3.0beta1</version>
      <fixedVersion>Feature/LightweightTransactions</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.net.WriteCallbackInfo.java</file>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7357" opendate="2014-6-5 00:00:00" fixdate="2014-7-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cleaning up snapshots on startup leftover from repairs that got interrupted</summary>
      <description>When a repair is interrupted, such as a restart, it can leave a snapshot behind on disk. These could be checked for and cleared possibly on startup.</description>
      <version>2.1.9,2.2.1,3.0alpha1</version>
      <fixedVersion>Legacy/StreamingandMessaging</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.ColumnFamilyStoreTest.java</file>
      <file type="M">src.java.org.apache.cassandra.service.CassandraDaemon.java</file>
      <file type="M">src.java.org.apache.cassandra.repair.RepairMessageVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Directories.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="8735" opendate="2015-2-4 00:00:00" fixdate="2015-7-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Batch log replication is not randomized when there are only 2 racks</summary>
      <description>Batch log replication is not randomized and the same 2 nodes can be picked up when there are only 2 racks in the cluster.https://github.com/apache/cassandra/blob/cassandra-2.0.11/src/java/org/apache/cassandra/service/BatchlogEndpointSelector.java#L72-73</description>
      <version>2.1.9,2.2.1,3.0alpha1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.service.BatchlogEndpointFilterTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.BatchlogManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9382" opendate="2015-5-14 00:00:00" fixdate="2015-7-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Snapshot file descriptors not getting purged (possible fd leak)</summary>
      <description>OpsCenter has the repair service which does a lot of small range repairs. Each repair would generate a snapshot as per normal. The cluster was showing a steady increase in disk space over the course of a couple of days and the only way to workaround the issue was to restart the node.Upon some further inspection it was seen that a lsof output of the cassandra process was still showing file descriptors for snapshots that no longer existed on the file system. For example:ava 5822 cassandra DEL REG 202,32 7359833 /media/ephemeral1/cassandra/data/somekeyspace/table1/snapshots/669a3a30-f3d3-11e4-bec6-3f6c4fb06498/somekeyspace-table1-jb-897689-Data.dbWe also took a heapdump which basically showed the same thing, lots of references to these file handles. We checked the logs for any errors especially relating to repairs that might have failed but there was nothing observedThe repair service logs in OpsCenter showed also that all repairs (1000s of them) had completed successfully, again showing that there was no repair issue.I have not yet been able to reproduce the issue locally on a test box. The cluster that this original issue appeared on was a production cluster with the following spec:cassandra_versions: 2.0.14.352cluster_cores : 8, cluster_instance_types : i2.2xlargecluster_os : Amazon linux amd64 node count: 4node java version: Oracle Java 1.7.0_51</description>
      <version>2.0.17,2.1.9,2.2.1,3.0alpha1</version>
      <fixedVersion>Legacy/LocalWrite-ReadPaths</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableReader.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9533" opendate="2015-6-2 00:00:00" fixdate="2015-8-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make batch commitlog mode easier to tune</summary>
      <description>As discussed in CASSANDRA-9504, 2.1 changed commitlog_sync_batch_window_in_ms from a maximum time to wait between fsync to the minimum time, so one must be very careful to keep it small enough that most writers aren't kept waiting.</description>
      <version>2.1.9,2.2.1,3.0beta1</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.BatchCommitLogService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.AbstractCommitLogService.java</file>
    </fixedFiles>
  </bug>
  <bug id="9544" opendate="2015-6-3 00:00:00" fixdate="2015-7-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow specification of TLS protocol to use for cqlsh</summary>
      <description>Currently when using cqlsh with --ssl it tries to use TLS 1.0 to connect. I have my server only serving TLS 1.2 which means that I cannot connect.It would be nice if cqlsh allowed the TLS protocol it uses to connect to be configured.</description>
      <version>2.1.9,2.2.0</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.sslhandling.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9601" opendate="2015-6-16 00:00:00" fixdate="2015-7-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow an initial connection timeout to be set in cqlsh</summary>
      <description>PYTHON-206 introduced the ability to change the initial connection timeout on connections from the default of 5s.This change was introduced because some auth providers (kerberos) can take longer than 5s to complete a first time negotiation for a connection. cqlsh should allow this setting to be changed.</description>
      <version>2.1.9,2.2.0rc2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug id="9682" opendate="2015-6-29 00:00:00" fixdate="2015-7-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>setting log4j.logger.org.apache.cassandra=DEBUG causes keyspace username/password to show up in system.log</summary>
      <description>if using a third party log aggregator (which many cloud users use), this causes db credentials to be reproduced offsite, which has potential to be security issue. I would prefer the ability to disable the logging of this information while still setting log4j.logger.org.apache.cassandra=DEBUGexample system.log entry:DEBUG [Native-Transport-Requests:373] 2015-06-21 07:52:44,595 Message.java (line 326) Responding: AUTHENTICATE org.apache.cassandra.auth.PasswordAuthenticator, v=1DEBUG [Native-Transport-Requests:384] 2015-06-21 07:52:44,597 Message.java (line 319) Received: CREDENTIALS {username=redacted, password=redacted}, v=1</description>
      <version>2.0.17,2.1.9,2.2.0,3.0alpha1</version>
      <fixedVersion>Legacy/Observability</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.transport.messages.CredentialsMessage.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9740" opendate="2015-7-6 00:00:00" fixdate="2015-7-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Can&amp;#39;t transition from write survey to normal mode</summary>
      <description>When attempting a transition a node from write survey to normal mode, the "nodetool join" invocation fails as the node is already "joined" (even though it's only bootstrapped).Attached is a trivial patch to fix. Note: I'm more concerned with ensuring correctness here rather than resolving an obscure bug.</description>
      <version>2.0.17,2.1.9,2.2.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9765" opendate="2015-7-8 00:00:00" fixdate="2015-7-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>checkForEndpointCollision fails for legitimate collisions</summary>
      <description>Since CASSANDRA-7939, checkForEndpointCollision no longer catches a legitimate collision. Without CASSANDRA-7939, wiping a node and starting it again fails with 'A node with address %s already exists', but with it the node happily enters joining state, potentially streaming from the wrong place and violating consistency.</description>
      <version>2.0.17,2.1.9,2.2.1,3.0alpha1</version>
      <fixedVersion>Legacy/DistributedMetadata</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.Gossiper.java</file>
    </fixedFiles>
  </bug>
  <bug id="9793" opendate="2015-7-13 00:00:00" fixdate="2015-7-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Log when messages are dropped due to cross_node_timeout</summary>
      <description>When a node has clock skew and cross node timeouts are enabled, there's no indication that the messages were dropped due to the cross timeout, just that messages were dropped. This can errantly lead you down a path of troubleshooting a load shedding situation when really you just have clock drift on one node. This is also not simple to troubleshoot, since you have to determine that this node will answer requests, but other nodes won't answer requests from it. If the problem goes away on a reboot (and the machine does one-shot time sync, not continuous) it becomes even harder to detect because you're left with a weird piece of evidence such as "it's fine after a reboot, but comes back in about X days every time."It would help tremendously if there were a log message indicating how many messages (don't need them broken down by type) were eagerly dropped due to the cross node timeout.</description>
      <version>2.0.17,2.1.9,2.2.1</version>
      <fixedVersion>Legacy/StreamingandMessaging</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.net.MessageDeliveryTask.java</file>
      <file type="M">src.java.org.apache.cassandra.net.IncomingTcpConnection.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
    </fixedFiles>
  </bug>
  <bug id="9827" opendate="2015-7-15 00:00:00" fixdate="2015-7-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add consistency level to tracing ouput</summary>
      <description>To help get a better view of expected behavior of queries, it would be helpful if each query's consistency level (and, where applicable, the serial consistency level) were included in the tracing output. The proposed location would be within the session's row in the sessions table as an additional key-value pair included in the parameters column (along with the query string, for example). Having it here would easily allow the user to group each particular query with the actual consistency level used and thus compare it to expectation.</description>
      <version>2.1.9,2.2.1,3.0beta1</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.transport.messages.QueryMessage.java</file>
      <file type="M">src.java.org.apache.cassandra.transport.messages.ExecuteMessage.java</file>
      <file type="M">src.java.org.apache.cassandra.transport.messages.BatchMessage.java</file>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraServer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9849" opendate="2015-7-20 00:00:00" fixdate="2015-7-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Paging changes to 2.1/2.2 for backward compatibilty with 3.0</summary>
      <description>Quoting thobbs from CASSANDRA-9704:I forgot to attach a patch for the required 2.1/2.2 changes as well. Basically, when paging in 2.x, our check to see if a new page contains the same row that the previous page ended on looks for an exact cell name match. This is fine in 2.x because we will return partial rows at the end of the page (just the row marker cell). However, in 3.0, we always return full rows. While we could make some very hacky changes to 3.0 to enable returning a partial row at the end of the page, this seems like the cleanest solution.Tyler's patch is there</description>
      <version>2.1.9,2.2.1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.pager.SliceQueryPager.java</file>
      <file type="M">src.java.org.apache.cassandra.service.pager.RangeSliceQueryPager.java</file>
    </fixedFiles>
  </bug>
  <bug id="9896" opendate="2015-7-24 00:00:00" fixdate="2015-7-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add ability to disable commitlog recycling</summary>
      <description>See CASSANDRA-9533 for background, specifically the graphs I linked. Benedict suggests this is due the commitlog recycling and I agree, so the simplest solution is to be able to disable that.</description>
      <version>2.1.9</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLogSegmentManager.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">conf.cassandra.yaml</file>
    </fixedFiles>
  </bug>
  <bug id="9898" opendate="2015-7-24 00:00:00" fixdate="2015-8-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh crashes if it load a utf-8 file.</summary>
      <description>cqlsh crashes when it load a cql script file encoded in utf-8.This is a reproduction procedure.$cat ./test.cql// 日本語のコメントuse system;select * from system.peers;$cqlsh --versioncqlsh 5.0.1$cqlsh -f ./test.cqlTraceback (most recent call last): File "./cqlsh", line 2459, in &lt;module&gt; main(*read_options(sys.argv[1:], os.environ)) File "./cqlsh", line 2451, in main shell.cmdloop() File "./cqlsh", line 940, in cmdloop line = self.get_input_line(self.prompt) File "./cqlsh", line 909, in get_input_line self.lastcmd = self.stdin.readline() File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/codecs.py", line 675, in readline return self.reader.readline(size) File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/codecs.py", line 530, in readline data = self.read(readsize, firstline=True) File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/codecs.py", line 477, in read newchars, decodedbytes = self.decode(data, self.errors)UnicodeDecodeError: 'ascii' codec can't decode byte 0xe6 in position 3: ordinal not in range(128)</description>
      <version>2.1.9,2.2.1,3.0beta2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.util.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9959" opendate="2015-8-3 00:00:00" fixdate="2015-8-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expected bloom filter size should not be an int</summary>
      <description>We cast the expected number of rows in scrub and cleanup to an int. Seems to have been this way since 0.7 days. Patch here: https://github.com/krummas/cassandra/commits/marcuse/dontcastscrubcleanup</description>
      <version>2.0.17,2.1.9,2.2.1,3.0beta1</version>
      <fixedVersion>Local/Compaction</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.Scrubber.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9963" opendate="2015-8-3 00:00:00" fixdate="2015-8-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compaction not starting for new tables</summary>
      <description>Something committed since 2.1.8 broke cassandra-2.1 HEADcreate keyspace test with replication = {'class': 'SimpleStrategy', 'replication_factor': 1};create table test.stcs ( a int PRIMARY KEY , b int);repeat more than 4 times:insert into test.stcs (a, b) VALUES ( 1, 1);nodetool flush test stcsls &lt;data dir&gt;/test/stcs-*See a bunch of sstables where STCS should have kicked in and compacted them down some.</description>
      <version>2.1.9,2.2.1,3.0beta1</version>
      <fixedVersion>Local/Compaction</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.WrappingCompactionStrategy.java</file>
    </fixedFiles>
  </bug>
  <bug id="9998" opendate="2015-8-6 00:00:00" fixdate="2015-8-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LEAK DETECTED with snapshot/sequential repairs</summary>
      <description>http://cassci.datastax.com/job/cassandra-2.1_dtest/lastCompletedBuild/testReport/repair_test/TestRepair/simple_sequential_repair_test/does not happen if I add -par to the test</description>
      <version>2.1.9,2.2.1,3.0beta1</version>
      <fixedVersion>Legacy/StreamingandMessaging</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>
