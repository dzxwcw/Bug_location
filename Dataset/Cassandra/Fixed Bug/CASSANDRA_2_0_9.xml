<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="CASSANDRA">
  <bug id="6162" opendate="2013-10-8 00:00:00" fixdate="2013-5-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cassandra does not start on Ubuntu 13.04 RUssian</summary>
      <description>Output just after install:vm.max_map_count = 1048575expr: синтаксическая ошибка^^^^ RU: syntax errorexpr: синтаксическая ошибка^^^^ RU: syntax error/etc/init.d/cassandra: 59: [: Illegal number: /etc/init.d/cassandra: 63: [: Illegal number: /etc/init.d/cassandra: 67: [: Illegal number: expr: синтаксическая ошибка^^^^ RU: syntax error/etc/init.d/cassandra: 81: [: Illegal number: xss = -ea -javaagent:/usr/share/cassandra/lib/jamm-0.2.5.jar -XX:+UseThreadPriorities -XX:ThreadPriorityPolicy=42 -XmsM -XmxM -XmnM -XX:+HeapDumpOnOutOfMemoryError -Xss256k</description>
      <version>2.0.9,2.1rc1</version>
      <fixedVersion>Packaging</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.cassandra-env.sh</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6344" opendate="2013-11-13 00:00:00" fixdate="2013-5-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>When running CQLSH with file input, exit with error status code if script fails</summary>
      <description>Just thought it would be nice if the cqlsh process would exit with an error status code if there are errors in the script, since it is the only thing the cqlsh process does when executing.Preferably a predictable status code could be used for a script error to discern it from some other odd error (i.e., don't use `1` because that could be many things). Maybe `2` or something.</description>
      <version>1.2.17,2.0.9,2.1rc1</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug id="6484" opendate="2013-12-13 00:00:00" fixdate="2013-5-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cassandra-shuffle not working with authentication</summary>
      <description>When enabling authentication for a cassandra cluster the tool cassandra-shuffle is unable to connect.The reason is, that cassandra-shuffle doesn't take any parameter for username and password for the thrift connection.To solve that problem, parameter for username and password should be added, It should also be able to interpret cqlshrc or a separate file file with authentication data.</description>
      <version>2.0.9,2.1rc1</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.Shuffle.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6523" opendate="2013-12-23 00:00:00" fixdate="2013-6-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>"Unable to contact any seeds!" with multi-DC cluster and listen != broadcast address</summary>
      <description>New cluster: Seeds: list of 6 internal IPs listen address: internal ip broadcast: external ipTwo DC cluster, using GPFS where the external IPs are NATed. Clusters fails to start with "Unable to contact any seeds!" Fail: Try to start a seed node Fail: Try to start two seed nodes at the same time in the same DC Success: Start two seed nodes at the same time in different DCs.Presumably related to CASSANDRA-5768</description>
      <version>2.0.9,2.1rc2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.gms.Gossiper.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.GossipDigestSynVerbHandler.java</file>
      <file type="M">src.java.org.apache.cassandra.gms.GossipDigestAckVerbHandler.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6539" opendate="2014-1-2 00:00:00" fixdate="2014-6-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Track metrics at a keyspace level as well as column family level</summary>
      <description>It would be useful to be able to see aggregated metrics (write/read count/latency) at a keyspace level as well as at the individual column family level.</description>
      <version>1.2.17,2.0.9,2.1rc2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.Table.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Keyspace.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6563" opendate="2014-1-9 00:00:00" fixdate="2014-5-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TTL histogram compactions not triggered at high "Estimated droppable tombstones" rate</summary>
      <description>I have several column families in a largish cluster where virtually all columns are written with a (usually the same) TTL. My understanding of CASSANDRA-3442 is that sstables that have a high ( &gt; 20%) estimated percentage of droppable tombstones should be individually compacted. This does not appear to be occurring with size tired compaction.Example from one node:$ ll /data/sstables/data/ks/Cf/*Data.db-rw-rw-r-- 31 cassandra cassandra 26651211757 Nov 26 22:59 /data/sstables/data/ks/Cf/ks-Cf-ic-295562-Data.db-rw-rw-r-- 31 cassandra cassandra 6272641818 Nov 27 02:51 /data/sstables/data/ks/Cf/ks-Cf-ic-296121-Data.db-rw-rw-r-- 31 cassandra cassandra 1814691996 Dec 4 21:50 /data/sstables/data/ks/Cf/ks-Cf-ic-320449-Data.db-rw-rw-r-- 30 cassandra cassandra 10909061157 Dec 11 17:31 /data/sstables/data/ks/Cf/ks-Cf-ic-340318-Data.db-rw-rw-r-- 29 cassandra cassandra 459508942 Dec 12 10:37 /data/sstables/data/ks/Cf/ks-Cf-ic-342259-Data.db-rw-rw-r-- 1 cassandra cassandra 336908 Dec 12 12:03 /data/sstables/data/ks/Cf/ks-Cf-ic-342307-Data.db-rw-rw-r-- 1 cassandra cassandra 2063935 Dec 12 12:03 /data/sstables/data/ks/Cf/ks-Cf-ic-342309-Data.db-rw-rw-r-- 1 cassandra cassandra 409 Dec 12 12:03 /data/sstables/data/ks/Cf/ks-Cf-ic-342314-Data.db-rw-rw-r-- 1 cassandra cassandra 31180007 Dec 12 12:03 /data/sstables/data/ks/Cf/ks-Cf-ic-342319-Data.db-rw-rw-r-- 1 cassandra cassandra 2398345 Dec 12 12:03 /data/sstables/data/ks/Cf/ks-Cf-ic-342322-Data.db-rw-rw-r-- 1 cassandra cassandra 21095 Dec 12 12:03 /data/sstables/data/ks/Cf/ks-Cf-ic-342331-Data.db-rw-rw-r-- 1 cassandra cassandra 81454 Dec 12 12:03 /data/sstables/data/ks/Cf/ks-Cf-ic-342335-Data.db-rw-rw-r-- 1 cassandra cassandra 1063718 Dec 12 12:03 /data/sstables/data/ks/Cf/ks-Cf-ic-342339-Data.db-rw-rw-r-- 1 cassandra cassandra 127004 Dec 12 12:03 /data/sstables/data/ks/Cf/ks-Cf-ic-342344-Data.db-rw-rw-r-- 1 cassandra cassandra 146785 Dec 12 12:03 /data/sstables/data/ks/Cf/ks-Cf-ic-342346-Data.db-rw-rw-r-- 1 cassandra cassandra 697338 Dec 12 12:03 /data/sstables/data/ks/Cf/ks-Cf-ic-342351-Data.db-rw-rw-r-- 1 cassandra cassandra 3921428 Dec 12 12:03 /data/sstables/data/ks/Cf/ks-Cf-ic-342367-Data.db-rw-rw-r-- 1 cassandra cassandra 240332 Dec 12 12:03 /data/sstables/data/ks/Cf/ks-Cf-ic-342370-Data.db-rw-rw-r-- 1 cassandra cassandra 45669 Dec 12 12:03 /data/sstables/data/ks/Cf/ks-Cf-ic-342374-Data.db-rw-rw-r-- 1 cassandra cassandra 53127549 Dec 12 12:03 /data/sstables/data/ks/Cf/ks-Cf-ic-342375-Data.db-rw-rw-r-- 16 cassandra cassandra 12466853166 Dec 25 22:40 /data/sstables/data/ks/Cf/ks-Cf-ic-396473-Data.db-rw-rw-r-- 12 cassandra cassandra 3903237198 Dec 29 19:42 /data/sstables/data/ks/Cf/ks-Cf-ic-408926-Data.db-rw-rw-r-- 7 cassandra cassandra 3692260987 Jan 3 08:25 /data/sstables/data/ks/Cf/ks-Cf-ic-427733-Data.db-rw-rw-r-- 4 cassandra cassandra 3971403602 Jan 6 20:50 /data/sstables/data/ks/Cf/ks-Cf-ic-437537-Data.db-rw-rw-r-- 3 cassandra cassandra 1007832224 Jan 7 15:19 /data/sstables/data/ks/Cf/ks-Cf-ic-440331-Data.db-rw-rw-r-- 2 cassandra cassandra 896132537 Jan 8 11:05 /data/sstables/data/ks/Cf/ks-Cf-ic-447740-Data.db-rw-rw-r-- 1 cassandra cassandra 963039096 Jan 9 04:59 /data/sstables/data/ks/Cf/ks-Cf-ic-449425-Data.db-rw-rw-r-- 1 cassandra cassandra 232168351 Jan 9 10:14 /data/sstables/data/ks/Cf/ks-Cf-ic-450287-Data.db-rw-rw-r-- 1 cassandra cassandra 73126319 Jan 9 11:28 /data/sstables/data/ks/Cf/ks-Cf-ic-450307-Data.db-rw-rw-r-- 1 cassandra cassandra 40921916 Jan 9 12:08 /data/sstables/data/ks/Cf/ks-Cf-ic-450336-Data.db-rw-rw-r-- 1 cassandra cassandra 60881193 Jan 9 12:23 /data/sstables/data/ks/Cf/ks-Cf-ic-450341-Data.db-rw-rw-r-- 1 cassandra cassandra 4746 Jan 9 12:23 /data/sstables/data/ks/Cf/ks-Cf-ic-450350-Data.db-rw-rw-r-- 1 cassandra cassandra 5769 Jan 9 12:23 /data/sstables/data/ks/Cf/ks-Cf-ic-450352-Data.db295562: Estimated droppable tombstones: 0.899035828535183296121: Estimated droppable tombstones: 0.9135080937806197320449: Estimated droppable tombstones: 0.8916766879896414I've checked in on this example node several times and compactionstats has not shown any other activity that would be blocking the tombstone based compaction. The TTL is in the 15-20 day range so an sstable from November should have had ample opportunities by January.</description>
      <version>2.0.9</version>
      <fixedVersion>Local/Compaction</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.compaction.CompactionsTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.AbstractCompactionStrategy.java</file>
      <file type="M">pylib.cqlshlib.cql3handling.py</file>
      <file type="M">doc.cql3.CQL.textile</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6766" opendate="2014-2-25 00:00:00" fixdate="2014-6-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>allow now() -&gt; uuid compatibility</summary>
      <description>Bad Request: Type error: cannot assign result of function now (type timeuuid) to id (type uuid)</description>
      <version>2.0.9,2.1rc2</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.marshal.UUIDType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.TupleType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.TimestampType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.ReversedType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.LongType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.IntegerType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.DateType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.CompositeType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.BytesType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.AbstractType.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.TypeCast.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.Selection.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.functions.Functions.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.functions.FunctionCall.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6877" opendate="2014-3-17 00:00:00" fixdate="2014-5-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>pig tests broken</summary>
      <description>Not sure what happened here, but I get a smorgasbord of errors running the pig tests now, from xml errors in xerces to NotFoundExceptions.</description>
      <version>2.0.9,2.1rc1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.pig.org.apache.cassandra.pig.CqlTableTest.java</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6973" opendate="2014-4-2 00:00:00" fixdate="2014-5-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>timestamp data type does ISO 8601 formats with &amp;#39;Z&amp;#39; as time zone.</summary>
      <description>The timestamp data type does not support format where time zone is specified with 'Z' (as in zulu aka. UTC+0 aka +0000 time zone). Example:create table foo(ts timestamp primary key);insert into foo(ts) values('2014-04-01T20:17:35+0000'); &amp;#8211; this workscqlsh:test&gt; insert into foo(ts) values('2014-04-01T20:17:35Z');Bad Request: unable to coerce '2014-04-01T20:17:35Z' to a formatted date (long)The example date was copied directly from ISO 8601 Wikipedia page. The standard says that "If the time is in UTC, add a Z directly after the time without a space. Z is the zone designator for the zero UTC offset."Tested with cqlsh with 2.0.6 version.</description>
      <version>2.0.9</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.serializers.TimestampSerializer.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.UUIDType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.TimeUUIDType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.TimestampType.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.DateType.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7059" opendate="2014-4-21 00:00:00" fixdate="2014-6-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Range query with strict bound on clustering column can return less results than required for compact tables</summary>
      <description>What's wrong:CREATE TABLE test ( k int, v int, PRIMARY KEY (k, v)) WITH COMPACT STORAGE;INSERT INTO test(k, v) VALUES (0, 0);INSERT INTO test(k, v) VALUES (0, 1);INSERT INTO test(k, v) VALUES (1, 0);INSERT INTO test(k, v) VALUES (1, 1);INSERT INTO test(k, v) VALUES (2, 0);INSERT INTO test(k, v) VALUES (2, 1);SELECT * FROM test WHERE v &gt; 0 LIMIT 3 ALLOW FILTERING; k | v---+--- 1 | 1 0 | 1That last query should return 3 results.The problem lies into how we deal with 'strict greater than' (&gt;) for "wide" compact storage table. Namely, for those tables, we internally only support inclusive bounds (for CQL3 tables this is not a problem as we deal with this using the 'end-of-component' of the CompositeType encoding). So we "compensate" by asking one more result than asked by the user, and we trim afterwards if that was unnecessary. This works fine for per-partition queries, but don't for "range" queries since we potentially would have to ask for X more results where X is the number of partition fetched, but we don't know X beforehand.I'll note that: this has always be there this only (potentially) affect compact tables this only affect range queries that have a strict bound on the clustering column (this means only ALLOW FILTERING) queries in particular. this only matters if a LIMIT is set on the query.As for fixes, it's not entirely trivial. The "right" fix would probably be to start supporting non-inclusive bound internally, but that's far from a small fix and is "at best" a 2.1 fix (since we'll have to make a messaging protocol change to ship some additional info for SliceQueryFilter). Also, this might be a lot of work for something that only affect some ALLOW FILTERING queries on compact tables.Another (somewhat simpler) solution might be to detect when we have this kind of queries and use a pager with no limit. We would then query a first page using the user limit (plus some smudge factor to avoid being inefficient too often) and would continue paging unless either we've exhausted all results or we can prove that post-processing we do have enough results to satisfy the user limit. This does mean in some case we might do 2 or more internal queries, but in practice we can probably make that case very rare, and since the query is an ALLOW FILTERING one, the user is somewhat warned that the query may not be terribly efficient.Lastly, we could always start by disallowing the kind of query that is potentially problematic (until we have a proper fix), knowing that users can work around that by either using non-strict bounds or removing the LIMIT, whichever makes the most sense in their case. In 1.2 in particular, we don't have the query pagers, so the previous solution I describe would be a bit of a mess to implement.</description>
      <version>2.0.9</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.SingleColumnRelation.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7067" opendate="2014-4-22 00:00:00" fixdate="2014-5-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Refuse CAS batch that have a &amp;#39;USING TIMESTAMP&amp;#39;</summary>
      <description>Cassandra must refuse BATCHes with TIMESTAMP, if they contain a CAS statement(s). Like this one:BEGIN BATCH USING TIMESTAMP 1111111111111111INSERT INTO users (id, firstname, lastname) VALUES (999, 'Jack', 'Sparrow') IF NOT EXISTSAPPLY BATCH</description>
      <version>2.0.9</version>
      <fixedVersion>Feature/LightweightTransactions</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.BatchStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7088" opendate="2014-4-24 00:00:00" fixdate="2014-5-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Zero length BigInteger exception causing processing to freeze</summary>
      <description>We attempted to migrate our developers to Cassandra 2.0.7 from 1.2.Everything worked perfectly, but we have experienced a massive drop in developer velocity.We run integration tests with Cucumber BDD and 1000 BDDs went from 7 minutes (Cassandra 1.2) to 15 minutes (2.0.7),This is when we run Cassandra of the ramdisk (/dev/shm) to make it run faster on dev boxes.When we tried pointed to actual drives the difference was dramatic: the entire suite took over 70 minutes vs 15 in Cassandra 1.2.After investigation, we found that most of the time is spent in the truncation logic between every scenario, where we truncate all the column families and start with a clean DB for the next test case.This used to be super fast in 1.2, is now very slow in 2.0.It may not seem important, but upgrading to 2.0 has basically cut down developer velocity by 100%, just by more than doubling the time it takes to run our BDD suite.We truncate the CFs using the Ruby driver: $cassandra.column_families.each do |column_family| name = column_family&amp;#91;0&amp;#93;.to_s $cassandra.truncate! name endI am attaching our cassandra.yaml. Please note we already switched off auto_compaction before truncate, just as we did in 1.2 for dev boxes, Made no difference.</description>
      <version>2.0.9</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.serializers.UUIDSerializer.java</file>
      <file type="M">src.java.org.apache.cassandra.serializers.TimestampSerializer.java</file>
      <file type="M">src.java.org.apache.cassandra.serializers.LongSerializer.java</file>
      <file type="M">src.java.org.apache.cassandra.serializers.IntegerSerializer.java</file>
      <file type="M">src.java.org.apache.cassandra.serializers.InetAddressSerializer.java</file>
      <file type="M">src.java.org.apache.cassandra.db.marshal.AbstractType.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7122" opendate="2014-4-30 00:00:00" fixdate="2014-5-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replacement nodes have null entries in system.peers</summary>
      <description>If a node is replaced with -Dcassandra.replace_address, the new node has mostly null entries in system.peers:&gt; select * from system.peers; peer | data_center | host_id | rack | release_version | rpc_address | schema_version | tokens-----------+-------------+---------+------+-----------------+-------------+----------------+-------------------------- 127.0.0.3 | null | null | null | null | null | null | {'-3074457345618258602'}To reproduce, simply kill a node and replace it. The entries are correctly populated if the replacement node is restarted but they are never populated if it isn't.I can think of at least two bad consequences of this:1. Drivers like Datastax java-driver use the peers table to find the rpc_address and location info of a node. If the entires are null it assumes rpc_address=ip and the node is in the local DC.2. When using GossipingPropertyFileSnitch and node won't persist the DC/rack of another node so may not be able to locate it during restarts.I reproduced in 1.2.15 but from inspection it looks to be present in 1.2.16 and 2.0.7.</description>
      <version>1.2.17,2.0.9,2.1rc1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
    </fixedFiles>
  </bug>
  <bug id="7172" opendate="2014-5-6 00:00:00" fixdate="2014-5-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh: Accept and execute CQL statement(s) from command-line parameter</summary>
      <description>I don't know if there is a workaround for this, but currently, if I want to dump the output of a statement into a file, I need to save the statements into another file and pass it as input to cqlsh. Something like:$ cqlsh -f &amp;#91;statement_file&amp;#93; &gt; &amp;#91;output_file&amp;#93;I am aware of the existence of the cqlsh CAPTURE command but it doesn't work for everything (particularly, for cqlsh-only commands like DESCRIBE)To solve this, I propose that you add an "-e" parameter to cqlsh that accepts a valid CQL statement to execute. This is exactly the same as MySQL CLI's "-e" parameter: http://dev.mysql.com/doc/refman/5.5/en/mysql-command-options.html#option_mysql_execute</description>
      <version>2.0.9,2.1rc1</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug id="7185" opendate="2014-5-7 00:00:00" fixdate="2014-5-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh can&amp;#39;t tab-complete disabling compaction</summary>
      <description>cqlsh can't tab-complete the following case where you want to disable compaction:alter table keys with compaction = {'class': 'SizeTieredCompactionStrategy', 'enabled': 'false'}Specfically it doesn't know 'enabled' is a valid option.</description>
      <version>2.0.9,2.1rc1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.cql3handling.py</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">doc.cql3.CQL.textile</file>
    </fixedFiles>
  </bug>
  <bug id="7191" opendate="2014-5-8 00:00:00" fixdate="2014-5-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>reduce needless garbage/thrashing in pending range calculation</summary>
      <description>code inverts the same multimap in a loop... just pull it out of the loopagainst 1.2</description>
      <version>1.2.17,2.0.9,2.1rc1</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.PendingRangeCalculatorService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7210" opendate="2014-5-12 00:00:00" fixdate="2014-5-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add --resolve-ip option on &amp;#39;nodetool ring&amp;#39;</summary>
      <description>Give nodetool ring the option of either displaying IPs or hostnames for the nodes in a ring.</description>
      <version>2.0.9,2.1rc1</version>
      <fixedVersion>Tool/nodetool</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7211" opendate="2014-5-12 00:00:00" fixdate="2014-5-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Triggers Demo seems incompatible with row markers</summary>
      <description>Added an if statement to skip row markers and a few comments to help people reading the example.</description>
      <version>2.0.9,2.1rc1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">examples.triggers.src.org.apache.cassandra.triggers.InvertedIndex.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7236" opendate="2014-5-14 00:00:00" fixdate="2014-6-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Extend connection backlog for MessageService</summary>
      <description>On restart of a node, which is part of a large cluster (500+ nodes) a lot of connection timeouts occur and a lot of messages in kernel log like kernel: TCP: Possible SYN flooding on port 7000. Sending cookies.and like kernel: net_ratelimit: 232 callbacks suppressedfound that MessageService use default backlog for its serversocket (which is 50 for java)This patch extends connection backlog to 500.</description>
      <version>2.0.9,2.1rc2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.security.SSLFactory.java</file>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
    </fixedFiles>
  </bug>
  <bug id="7264" opendate="2014-5-19 00:00:00" fixdate="2014-5-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add conditional support for the creation/deletion of users</summary>
      <description>Currently attempting to do "drop user if exists tom;" or " create user if exists tom password 'tom' " does not work. Would be a nice feature to add from a test automation standpoint so that we don't error out when attempting to clean up or create the test environment.</description>
      <version>2.0.9,2.1rc1</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.DropUserStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CreateUserStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.Cql.g</file>
      <file type="M">doc.cql3.CQL.textile</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7268" opendate="2014-5-19 00:00:00" fixdate="2014-6-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Secondary Index can miss data without an error</summary>
      <description>Seeing issues with secondary indexes after upgrading from 1.1-&gt;1.2. Using the same thrift code from 1.1, every once in a while a row is inserted that does not show up in the secondary index on a text column.Using sstable2json we can see the row in the regular sstables on every node, but not in the secondary index sstables (even after flushing/taking a snapshot).If we move the snapshot to a test node and rebuild the secondary index, it gets populated correctly and returns the data.Sanitized create statement:create column family test2i with column_type = 'Standard' and comparator = 'UTF8Type' and default_validation_class = 'UTF8Type' and key_validation_class = 'UTF8Type' and read_repair_chance = 1.0 and dclocal_read_repair_chance = 0.0 and populate_io_cache_on_flush = false and gc_grace = 0 and min_compaction_threshold = 4 and max_compaction_threshold = 32 and replicate_on_write = false and compaction_strategy = 'org.apache.cassandra.db.compaction.LeveledCompactionStrategy' and caching = 'KEYS_ONLY' and column_metadata = [ {column_name : 'second', validation_class : UTF8Type, index_name : 'test2i_second_idx', index_type : 0}, {column_name : 'A', validation_class : UTF8Type}, {column_name : 'B', validation_class : UTF8Type}, {column_name : 'C', validation_class : UTF8Type}, {column_name : 'D', validation_class : UTF8Type}, {column_name : 'E', validation_class : UTF8Type}, {column_name : 'F', validation_class : UTF8Type}, {column_name : 'G', validation_class : UTF8Type}, {column_name : 'H', validation_class : UTF8Type}, {column_name : 'I', validation_class : UTF8Type}, {column_name : 'J', validation_class : UTF8Type}, {column_name : 'K', validation_class : UTF8Type}, {column_name : 'L', validation_class : UTF8Type}, {column_name : 'M', validation_class : UTF8Type}] and compression_options = {'sstable_compression' : 'org.apache.cassandra.io.compress.SnappyCompressor'};</description>
      <version>1.2.17,2.0.9,2.1rc2</version>
      <fixedVersion>Feature/2iIndex</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.ColumnFamilyStoreTest.java</file>
      <file type="M">src.java.org.apache.cassandra.db.index.SecondaryIndexManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7273" opendate="2014-5-20 00:00:00" fixdate="2014-6-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>expose global ColumnFamily metrics</summary>
      <description>It would be very useful to have cassandra expose ColumnFamily metrics that span all column families. A general purpose cassandra monitoring system built up around the current ColumnFamily metrics really only has a couple of choices right now: publish metrics for all column families or fetch metrics for all column families, aggregate them and then publish the aggregated metrics. The first can be quite expensive for the downstream monitoring system and the second is a piece of work that it seems is better pushed into cassandra itself.Perhaps these global ColumnFamily metrics could be published under a name of:org.apache.cassandra.metrics:type=(ColumnFamily|IndexColumnFamily),name=(Metric name)(Same as existing ColumnFamily metrics, but with no keyspace or scope.)</description>
      <version>1.2.17,2.0.9,2.1rc2</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.Table.java</file>
      <file type="M">test.unit.org.apache.cassandra.db.KeyspaceTest.java</file>
      <file type="M">src.java.org.apache.cassandra.metrics.LatencyMetrics.java</file>
      <file type="M">src.java.org.apache.cassandra.metrics.KeyspaceMetrics.java</file>
      <file type="M">src.java.org.apache.cassandra.metrics.ColumnFamilyMetrics.java</file>
      <file type="M">src.java.org.apache.cassandra.db.Keyspace.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7274" opendate="2014-5-20 00:00:00" fixdate="2014-5-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Better display table organization on desc table via primary key list</summary>
      <description>In cqlsh, the desc table command does not make it sufficiently clear which columns are part of the row key and which are clustering keys.A simple change to the primary key list, though, would make it easier to tell.Consider the following table definition:create table my_table { first_column text, second_column text, third_column text, primary key (first_column, second_column, third_column)}This table has a row key of first_column and clustering keys of second_column, third_column. But if the user intended for the table to have all three in the row key, the correct definition would be:create table my_table { first_column text, second_column text, third_column text, primary key ((first_column, second_column, third_column))}But this is a sufficiently subtle difference that the first may be mistaken for the second or vice-versa.My suggested solution is to always wrap the row key in parentheses. This is already supported by create table syntax, so it's just a matter of changing desc table to display the create table statement with the primary key always in parentheses, like so:create table my_table { first_column text, second_column text, third_column text, primary key ((first_column), second_column, third_column)}</description>
      <version>2.0.9</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug id="7288" opendate="2014-5-22 00:00:00" fixdate="2014-5-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Exception during compaction</summary>
      <description>Sometimes Cassandra nodes (in a multi datacenter deployment) are throwing errors during compaction. (see attached stack trace)Let me know what additional information I could provide.Thank you.</description>
      <version>2.0.9</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.HintedHandOffManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7294" opendate="2014-5-23 00:00:00" fixdate="2014-5-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>FileCache metrics incorrectly named</summary>
      <description></description>
      <version>2.0.9,2.1rc1</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.metrics.FileCacheMetrics.java</file>
    </fixedFiles>
  </bug>
  <bug id="7305" opendate="2014-5-27 00:00:00" fixdate="2014-6-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CQL3, Static columns not returning rows if values are not set</summary>
      <description>Just a quick note on static columns, if you create some cql rows using clustered columns and don't provide a value for a static column, then selecting the row key with the (null) static column won't return any rows.create table statictest( a int, b text static, c text, PRIMARY KEY (a, c));insert into statictest (a, c) values (1, 'test');select a,b from statictest;(0 rows)</description>
      <version>2.0.9</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7307" opendate="2014-5-27 00:00:00" fixdate="2014-6-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>New nodes mark dead nodes as up for 10 minutes</summary>
      <description>When doing a node replacement when other nodes are down we see the down nodes marked as up for about 10 minutes. This means requests are routed to the dead nodes causing timeouts. It also means replacing a node when multiple nodes from a replica set is extremely difficult - the node usually tries to stream from a dead node and the replacement fails.This isn't limited to host replacement. I did a simple test:1. Create a 2 node cluster2. Kill node 23. Start a 3rd node with a unique token (I used auto_bootstrap=false but I don't think this is significant)The 3rd node lists node 2 (127.0.0.2) as up for almost 10 minutes:INFO [main] 2014-05-27 14:28:24,753 CassandraDaemon.java (line 119) Logging initializedINFO [GossipStage:1] 2014-05-27 14:28:31,492 Gossiper.java (line 843) Node /127.0.0.2 is now part of the clusterINFO [GossipStage:1] 2014-05-27 14:28:31,495 Gossiper.java (line 809) InetAddress /127.0.0.2 is now UPINFO [GossipTasks:1] 2014-05-27 14:37:44,526 Gossiper.java (line 823) InetAddress /127.0.0.2 is now DOWNI reproduced on 1.2.15 and 1.2.16.</description>
      <version>1.2.17,2.0.9,2.1rc2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.gms.FailureDetector.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7320" opendate="2014-5-29 00:00:00" fixdate="2014-5-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Swap local and global default read repair chances</summary>
      <description>See the discussion in CASSANDRA-6887 on why.Sylvain: "instead of having read_repair_chance=0.1 and dclocal_read_repair_chance=0, to switch to read_repair_chance=0 and dclocal_read_repair_chance=0.1. If you have only one DC, then it won't change from the current default, and if you have multiple-DC, I can agree that not crossing DC boundaries for read repair is a better default."Not basing on 1.2 because it's rather late for that. Not too late for the 2.0 cycle though, so setting fixver to 2.0.9.</description>
      <version>2.0.9,2.1rc1</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.config.CFMetaData.java</file>
      <file type="M">NEWS.txt</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7325" opendate="2014-5-29 00:00:00" fixdate="2014-5-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cqlsh counts non-empty lines for "Blank lines" warning</summary>
      <description>[cqlsh 4.1.1 | Cassandra 2.0.8-SNAPSHOT | CQL spec 3.1.1 | Thrift protocol 19.39.0]Use HELP for help.cqlsh&gt; use system;cqlsh:system&gt; select * ... from ... local ... whereStatements are terminated with a ';'. You can press CTRL-C to cancel an imcomplete statement.</description>
      <version>2.0.9,2.1rc2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug id="7333" opendate="2014-5-31 00:00:00" fixdate="2014-6-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>gossipinfo should include the generation</summary>
      <description>As the title says, we should include this information in gossipinfo so it's easier to diagnose the generation-from-future type problems.</description>
      <version>1.2.17,2.0.9,2.1rc2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.gms.FailureDetector.java</file>
    </fixedFiles>
  </bug>
  <bug id="7335" opendate="2014-6-1 00:00:00" fixdate="2014-6-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>GossipingPropertyFileSnitchTest fails on Windows</summary>
      <description>Unable to find source-code formatter for language: failure message. Available languages are: actionscript, ada, applescript, bash, c, c#, c++, cpp, css, erlang, go, groovy, haskell, html, java, javascript, js, json, lua, none, nyan, objc, perl, php, python, r, rainbow, ruby, scala, sh, sql, swift, visualbasic, xml, yaml [junit] Testcase: testAutoReloadConfig(org.apache.cassandra.locator.GossipingPropertyFileSnitchTest): Caused an ERROR [junit] Illegal char &lt;:&gt; at index 2: /C:/vm-shared/src/cassandra/test/conf/cassandra-rackdc.properties [junit] java.nio.file.InvalidPathException: Illegal char &lt;:&gt; at index 2: /C:/vm-shared/src/cassandra/test/conf/cassandra-rackdc.properties [junit] at sun.nio.fs.WindowsPathParser.normalize(WindowsPathParser.java:182) [junit] at sun.nio.fs.WindowsPathParser.parse(WindowsPathParser.java:153) [junit] at sun.nio.fs.WindowsPathParser.parse(WindowsPathParser.java:77) [junit] at sun.nio.fs.WindowsPath.parse(WindowsPath.java:94) [junit] at sun.nio.fs.WindowsFileSystem.getPath(WindowsFileSystem.java:255) [junit] at java.nio.file.Paths.get(Paths.java:84) [junit] at org.apache.cassandra.locator.GossipingPropertyFileSnitchTest.testAutoReloadConfig(GossipingPropertyFileSnitchTest.java:40) [junit] [junit] [junit] Test org.apache.cassandra.locator.GossipingPropertyFileSnitchTest FAILED</description>
      <version>2.0.9,2.1rc2</version>
      <fixedVersion>Legacy/Testing</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.utils.FBUtilities.java</file>
    </fixedFiles>
  </bug>
  <bug id="7337" opendate="2014-6-2 00:00:00" fixdate="2014-6-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Protocol batches wrongly ignores conditions</summary>
      <description>When using protocol batches, we ignore the fact that statements may have conditions and subsequently call the wrong code path. The batches ends up being executed has if there was no conditions (but the ResultSet is empty which should make it clear something is wrong).</description>
      <version>2.0.9,2.1rc2</version>
      <fixedVersion>Legacy/CQL</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.transport.messages.BatchMessage.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.BatchStatement.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.QueryProcessor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7356" opendate="2014-6-5 00:00:00" fixdate="2014-6-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a more ops friendly replace_address flag</summary>
      <description>Doing a host replacement with cassandra.replace_address works well, but it is operationally difficult because the flag needs clearing once the replace is successful. Most people will launch through some scripts so remembering to clear the flag is a pain. Forgetting means the node won't come up on a restart.We should have a flag like cassandra.replace_address_first_boot that works the same as auto_bootstrap/initial_token: it is totally ignored if the node has successfully bootstrapped but on starting from a clean disk it will work as the existing cassandra.replace_address.</description>
      <version>1.2.17,2.0.9,2.1rc2</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7380" opendate="2014-6-11 00:00:00" fixdate="2014-6-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Native protocol needs keepalive, we should add it</summary>
      <description>On clients connecting to C* 1.2.15 using native protocol. We see that when the client is bounced, the old connection is not going awayOn Thrift, there is the rpc_keepalive but there is no similar feature for the native protocol</description>
      <version>1.2.17,2.0.9,2.1rc2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.transport.Server.java</file>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7399" opendate="2014-6-15 00:00:00" fixdate="2014-6-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh: describe table shows wrong data type for CompositeType</summary>
      <description>DESCRIBE for CompositeType produces wrong output.Currently:CREATE TABLE compo.comp ( id int PRIMARY KEY, comp 'org.apache.cassandra.db.marshal.CompositeType'&lt;int, text&gt;)...Correct:CREATE TABLE compo.comp ( id int PRIMARY KEY, comp 'org.apache.cassandra.db.marshal.CompositeType(Int32Type,UTF8Type)')...Means:1. use normal brackets instead of &lt;&gt;1. use C* type names instead of CQL3 names1. move types inside quoted</description>
      <version>1.2.17,2.0.9,2.1rc2</version>
      <fixedVersion>Legacy/Tools</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug id="7407" opendate="2014-6-17 00:00:00" fixdate="2014-6-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>COPY command does not work properly with collections causing failure to import data</summary>
      <description>The COPY command does not properly format collections in the output CSV - to be able to re-import the data.Here is how you can replicate the problem:CREATE TABLE user_colors ( user_id int PRIMARY KEY, colors list&lt;ascii&gt; );UPDATE user_colors SET colors = ['red','blue'] WHERE user_id=5; UPDATE user_colors SET colors = ['purple','yellow'] WHERE user_id=6; UPDATE user_colors SET colors = ['black''] WHERE user_id=7;COPY user_colors (user_id, colors) TO 'output.csv';CREATE TABLE user_colors2 ( user_id int PRIMARY KEY, colors list&lt;ascii&gt; );COPY user_colors2 (user_id, colors ) FROM 'user_colors.csv';Bad Request: line 1:68 no viable alternative at input ']'Aborting import at record #0 (line 1). Previously-inserted values still present.0 rows imported in 0.007 seconds.The CSV file seems to be malformed The single quotes within the collection are missing The double quotes for collection on user_id=7 are missing and causing COPY to fail.5,"[red, blue]"7,[black]6,"[purple, yellow]"Should be like this5,"['red', 'blue']"7,"['black']"6,"['purple', 'yellow']"Once the file is changed, the import worksCOPY user_colors2 (user_id, colors ) FROM 'user_colors.csv';3 rows imported in 0.012 seconds.SELECT * FROM user_colors2; user_id | colors---------+------------------ 5 | [red, blue] 7 | [black] 6 | [purple, yellow](3 rows)</description>
      <version>1.2.17,2.0.9,2.1rc2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pylib.cqlshlib.formatting.py</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>
