<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="CASSANDRA">
  <bug id="4445" opendate="2012-7-18 00:00:00" fixdate="2012-2-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>balance utility for vnodes</summary>
      <description>We need a 'balance' utility similar to move without a token, in the cases where entropy is not your friend and gives you an unbalanced cluster (I've seen up to a 7% discrepancy myself)</description>
      <version>2.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeTool.java</file>
      <file type="M">src.resources.org.apache.cassandra.tools.NodeToolHelp.yaml</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeProbe.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4757" opendate="2012-10-3 00:00:00" fixdate="2012-2-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expose bulk loading progress/status over jmx</summary>
      <description>The bulk loading interface should be exposing some progress or status information over jmx. This shouldn't be too difficult and should be exposed in a way that the information is available whether you are using the separate sstableloader utility or calling the bulkload jmx call.</description>
      <version>2.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.streaming.management.StreamStateCompositeData.java</file>
      <file type="M">test.unit.org.apache.cassandra.io.sstable.SSTableScannerTest.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.BulkLoader.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageServiceMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5631" opendate="2013-6-12 00:00:00" fixdate="2013-2-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>NPE when creating column family shortly after multinode startup</summary>
      <description>I'm testing a 2-node cluster and creating a column family right after the nodes startup. I am using the Astyanax client. Sometimes column family creation fails and I see NPEs on the cassandra server:2013-06-12 14:55:31,773 ERROR CassandraDaemon [MigrationStage:1] - Exception in thread Thread[MigrationStage:1,5,main]java.lang.NullPointerException at org.apache.cassandra.db.DefsTable.addColumnFamily(DefsTable.java:510) at org.apache.cassandra.db.DefsTable.mergeColumnFamilies(DefsTable.java:444) at org.apache.cassandra.db.DefsTable.mergeSchema(DefsTable.java:354) at org.apache.cassandra.db.DefinitionsUpdateVerbHandler$1.runMayThrow(DefinitionsUpdateVerbHandler.java:55) at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334) at java.util.concurrent.FutureTask.run(FutureTask.java:166) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:722)2013-06-12 14:55:31,880 ERROR CassandraDaemon [MigrationStage:1] - Exception in thread Thread[MigrationStage:1,5,main]java.lang.NullPointerException at org.apache.cassandra.db.DefsTable.mergeColumnFamilies(DefsTable.java:475) at org.apache.cassandra.db.DefsTable.mergeSchema(DefsTable.java:354) at org.apache.cassandra.db.DefinitionsUpdateVerbHandler$1.runMayThrow(DefinitionsUpdateVerbHandler.java:55) at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334) at java.util.concurrent.FutureTask.run(FutureTask.java:166) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:722)</description>
      <version>1.2.16,2.0.6,2.1beta1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.MigrationManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6157" opendate="2013-10-7 00:00:00" fixdate="2013-2-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Selectively Disable hinted handoff for a data center</summary>
      <description>Cassandra supports disabling the hints or reducing the window for hints. It would be helpful to have a switch which stops hints to a down data center but continue hints to other DCs.This is helpful during data center fail over as hints will put more unnecessary pressure on the DC taking double traffic. Also since now Cassandra is under reduced reduncany, we don't want to disable hints within the DC.</description>
      <version>2.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeProbe.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxyMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.config.YamlConfigurationLoader.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6360" opendate="2013-11-15 00:00:00" fixdate="2013-2-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make nodetool cfhistograms output easily understandable</summary>
      <description>Almost nobody understands the cfhistograms output without googling it. By default, we shouldn't share an axis across all metrics. We can still provide the current format with a --compact option.</description>
      <version>2.0.6</version>
      <fixedVersion>Tool/nodetool</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6364" opendate="2013-11-16 00:00:00" fixdate="2013-2-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>There should be different disk_failure_policies for data and commit volumes or commit volume failure should always cause node exit</summary>
      <description>We're doing fault testing on a pre-production Cassandra cluster. One of the tests was to simulation failure of the commit volume/disk, which in our case is on a dedicated disk. We expected failure of the commit volume to be handled somehow, but what we found was that no action was taken by Cassandra when the commit volume fail. We simulated this simply by pulling the physical disk that backed the commit volume, which resulted in filesystem I/O errors on the mount point.What then happened was that the Cassandra Heap filled up to the point that it was spending 90% of its time doing garbage collection. No errors were logged in regards to the failed commit volume. Gossip on other nodes in the cluster eventually flagged the node as down. Gossip on the local node showed itself as up, and all other nodes as down.The most serious problem was that connections to the coordinator on this node became very slow due to the on-going GC, as I assume uncommitted writes piled up on the JVM heap. What we believe should have happened is that Cassandra should have caught the I/O error and exited with a useful log message, or otherwise done some sort of useful cleanup. Otherwise the node goes into a sort of Zombie state, spending most of its time in GC, and thus slowing down any transactions that happen to use the coordinator on said node.A limit on in-memory, unflushed writes before refusing requests may also work. Point being, something should be done to handle the commit volume dying as doing nothing results in affecting the entire cluster. I should note, we are using: disk_failure_policy: best_effort</description>
      <version>2.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.db.CommitLogTest.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.io.util.FileUtils.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.PeriodicCommitLogExecutorService.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLogAllocator.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLog.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.BatchCommitLogExecutorService.java</file>
      <file type="M">src.java.org.apache.cassandra.config.DatabaseDescriptor.java</file>
      <file type="M">src.java.org.apache.cassandra.config.Config.java</file>
      <file type="M">conf.cassandra.yaml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6440" opendate="2013-12-3 00:00:00" fixdate="2013-2-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Repair should allow repairing particular endpoints to reduce WAN usage.</summary>
      <description>The way we send out data that does not match over WAN can be improved. Example: Say there are four nodes(A,B,C,D) which are replica of a range we are repairing. A, B is in DC1 and C,D is in DC2. If A does not have the data which other replicas have, then we will have following streams1) A to B and back2) A to C and back(Goes over WAN)3) A to D and back(Goes over WAN)One of the ways of doing it to reduce WAN traffic is this.1) Repair A and B only with each other and C and D with each other starting at same time t. 2) Once these repairs have finished, A,B and C,D are in sync with respect to time t. 3) Now run a repair between A and C, the streams which are exchanged as a result of the diff will also be streamed to B and D via A and C(C and D behaves like a proxy to the streams).For a replication of DC1:2,DC2:2, the WAN traffic will get reduced by 50% and even more for higher replication factors.Another easy way to do this is to have repair command take nodes with which you want to repair with. Then we can do something like this.1) Run repair between (A and B) and (C and D)2) Run repair between (A and C)3) Run repair between (A and B) and (C and D)But this will increase the traffic inside the DC as we wont be doing proxy.</description>
      <version>2.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.service.AntiEntropyServiceTestAbstract.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeProbe.java</file>
      <file type="M">src.java.org.apache.cassandra.tools.NodeCmd.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageServiceMBean.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">src.java.org.apache.cassandra.service.ActiveRepairService.java</file>
      <file type="M">src.java.org.apache.cassandra.repair.RepairSession.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6522" opendate="2013-12-22 00:00:00" fixdate="2013-2-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>DroppableTombstoneRatio JMX value is 0.0 for all CFs</summary>
      <description>We're seeing that the JMX value for DroppableTombstoneRatio for all our CFs is 0.0. On the face of it that seems wrong since we've definitely issued a ton of deletes for row keys to expire some old data that we no longer need (and it definitely hasn't been reclaimed from disk yet). Am I misunderstanding what this means / how to use it? We're on 1.2.8 and using leveled compaction for all our CFs.gc_grace_seconds is set to 1 day and we've issued a series of deletes over a day ago, so gc_grace has elapsed.Cluster is 18 nodes. Two DCs, so 9 nodes in each DC. Each node has capacity for 1.5TB or so and is sitting with about 1TB under management. That's why we wanted to do deletes, obviously. Most of that 1TB is a single CF (called "events") which represents intermediate state for us that we can delete.Happy to provide any more info, just let me know.</description>
      <version>2.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.tools.SSTableMetadataViewer.java</file>
      <file type="M">src.java.org.apache.cassandra.io.sstable.SSTableWriter.java</file>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LazilyCompactedRow.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamily.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6566" opendate="2014-1-10 00:00:00" fixdate="2014-2-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Differencer should not run in AntiEntropy Stage</summary>
      <description>The Differencing currently runs in AntiEntropy stage. When there are lot of ranges which do not match, it takes sometime to compute the diff in ranges. Also with increase in Merkle tree height it will take even more time in case of large diffs. This causes other things to get blocked behind this. Also no other repair messages can be processed. Example: If a node is doing differencing for a repair, and Validation compaction is done for another repair, it needs to block to send the tree over till Differencing is done.</description>
      <version>2.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.repair.RepairSession.java</file>
      <file type="M">src.java.org.apache.cassandra.repair.RepairJob.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6623" opendate="2014-1-27 00:00:00" fixdate="2014-2-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Null in a cell caused by expired TTL does not work with IF clause (in CQL3)</summary>
      <description>IF onecell=null clause does not work if the onecell has got its null value from an expired TTL. If onecell is updated with null value (UPDATE) then IF onecell=null works fine.This bug is not present when you create a table with COMPACT STORAGE directive.</description>
      <version>2.0.6</version>
      <fixedVersion>Legacy/Testing</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.thrift.CassandraServer.java</file>
      <file type="M">src.java.org.apache.cassandra.service.StorageProxy.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.ModificationStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6649" opendate="2014-2-4 00:00:00" fixdate="2014-2-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CQL: disallow counter update with "USING TIMESTAMP" and "USING TTL"</summary>
      <description>Timestamps are not used by counters and TTL are not supported, but it appears we don't reject counter updates that have "USING TIMESTAMP X" or "USING TTL X". We should since both are non-sensical (the value is completely ignored currently).Note: we should also refuse "USING TIMESTAMP" on "DELETE" statements on counters table: even though we kind of do use a timestamp internally, it's more of an implementation detail and in fact may go away with CASSANDRA-6506 (there is also nothing clever you can do with it by providing it client side).Note bis: strictly speaking doing that could break a few users that where setting those thinking it does something. I think that the lack of validation is more of a bug and that user that think it's doing something probably ought to know it's not sooner than later, but I could be fine with just warning in the log file for 1.2 and 2.0, and only rejecting in 2.1 if someone thinks it's safer.</description>
      <version>1.2.16,2.0.6,2.1beta1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.ModificationStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6657" opendate="2014-2-5 00:00:00" fixdate="2014-2-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Log the newsize value alongside the heap size at startup</summary>
      <description>It would be nice to have the newsize value logged alongside the heap size at startup to more easily track down problems.</description>
      <version>2.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.CassandraDaemon.java</file>
    </fixedFiles>
  </bug>
  <bug id="6658" opendate="2014-2-5 00:00:00" fixdate="2014-2-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Nodes flap once at startup</summary>
      <description>Upon initially seeing each other, a node will mark another UP, then DOWN, then UP again.</description>
      <version>2.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.gms.FailureDetector.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6666" opendate="2014-2-6 00:00:00" fixdate="2014-9-6 01:00:00" resolution="Duplicate">
    <buginformation>
      <summary>Avoid accumulating tombstones after partial hint replay</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.HintedHandOffManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6667" opendate="2014-2-6 00:00:00" fixdate="2014-2-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Mean cells per sstable is calculated incorrectly</summary>
      <description>We currently take the average of the mean for each partition, rather than correctly weighting by cell count. This affects hint paging as well as index selectivity calculation.</description>
      <version>1.2.16,2.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.metrics.ColumnFamilyMetrics.java</file>
      <file type="M">src.java.org.apache.cassandra.db.DataTracker.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStoreMBean.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6678" opendate="2014-2-7 00:00:00" fixdate="2014-2-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unwanted schema pull while upgrading nodes from 1.2 to 2.0</summary>
      <description>While upgrading from 1.2 to 2.0, the 1.2 nodes are not supposed to pull schemas from upgraded 2.0 nodes to avoid conflicts.This relies on network version checks between the two nodes, but there's a bit of a race between the Gossiper, which is activated first, and the MessagingService, which is activated after the Gossiper and handles network version exchange: if a 1.2 node Gossiper gets a gossip message from a newly 2.0 node before opening connections from the MessagingService, the version will still be 1.2, and the schema will be pulled from the new node.A possible solution may be to have the Gossiper update the network version upon receiving the first gossip message of an upgraded node: thoughts?</description>
      <version>1.2.16,2.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.MigrationManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="6687" opendate="2014-2-10 00:00:00" fixdate="2014-2-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CQL: "drop table if exists" throws exception when table does not exist</summary>
      <description>MacBook-Bro-6:~ brenthaines$ cqlshConnected to Test Cluster at localhost:9160.[cqlsh 4.1.1 | Cassandra 2.0.5 | CQL spec 3.1.1 | Thrift protocol 19.39.0]Use HELP for help.cqlsh&gt; use apps;cqlsh:apps&gt; describe table brands;Column family 'brands' not foundcqlsh:apps&gt; drop table if exists brands;Bad Request: unconfigured columnfamily brandscqlsh:apps&gt;</description>
      <version>2.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.DropTableStatement.java</file>
    </fixedFiles>
  </bug>
  <bug id="6688" opendate="2014-2-11 00:00:00" fixdate="2014-2-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Avoid possible sstable overlaps with leveled compaction</summary>
      <description>Two cases where we can end up with overlapping sstables in the leveled manifest;FIrst one is when we skip levels during compaction. Here we need to make sure we are not compacting in newLevel - 1 since if, for example, we are doing a L1 -&gt; L2 compaction and then start a new L0 compaction where we decide to skip L1, we could have overlapping sstables in L2 when the compactions are done. This case is new in 2.0 since we check if we skip levels before the compaction starts.Second case is where we try to include as many overlapping L0 sstables as possible, here we could add sstables that are not compacting, but overlap sstables that are.</description>
      <version>2.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.LeveledManifest.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6695" opendate="2014-2-12 00:00:00" fixdate="2014-2-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Don&amp;#39;t exchange schema between nodes with different versions (no pull, no push)</summary>
      <description>Subject. Don't push schema to unknown-, or differently major-versioned nodes, and don't pull schema from them, either.Since we don't support schema altering during upgrade, and adding nodes during cluster upgrades is also a non-recommended thing, this is what we are going to do.Until CASSANDRA-6038, that is.</description>
      <version>1.2.16,2.0.6,2.1beta1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.MigrationManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6701" opendate="2014-2-13 00:00:00" fixdate="2014-2-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>IN on the last clustering columns + ORDER BY DESC yield no results</summary>
      <description>That's not a very common mix but well, the following return no results which is obviously bogus:CREATE TABLE test (k int, c1 int, c2 int, PRIMARY KEY (k, c1, c2));INSERT INTO test(k, c1, c2) VALUES (0, 0, 0);INSERT INTO test(k, c1, c2) VALUES (0, 0, 1);INSERT INTO test(k, c1, c2) VALUES (0, 0, 2);SELECT * FROM test WHERE k=0 AND c1 = 0 AND c2 IN (2, 0) ORDER BY c1 DESCNote: it's pretty useless to order on a column which has an equal restriction, and that's probably why nobody ran into this yet, but that's really just due to a minor typo so there is no reason not to fix.</description>
      <version>1.2.16,2.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6703" opendate="2014-2-14 00:00:00" fixdate="2014-3-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cqlsh support for "static" CQL3 columns</summary>
      <description>Show "static" columns in DESCRIBE CREATE/ALTER TABLE autocompletions</description>
      <version>2.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">examples.hadoop.cql3.word.count.src.WordCountSetup.java</file>
      <file type="M">examples.hadoop.cql3.word.count.src.WordCountCounters.java</file>
      <file type="M">examples.hadoop.cql3.word.count.src.WordCount.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">pylib.cqlshlib.cql3handling.py</file>
      <file type="M">bin.cqlsh</file>
    </fixedFiles>
  </bug>
  <bug id="6707" opendate="2014-2-14 00:00:00" fixdate="2014-2-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>AIOOBE when doing select count(*) from on a mixed cluster.</summary>
      <description>After upgrading one node from 1.2 to 2.0, the following query fails with timeout:Connected to test at localhost:9160.[cqlsh 4.1.0 | Cassandra 2.0.5.1-SNAPSHOT | CQL spec 3.1.1 | Thrift protocol 19.39.0]Use HELP for help.cqlsh&gt; select count(*) from cfs.sblocks;Request did not complete within rpc_timeout.Table definition:cqlsh&gt; describe columnfamily cfs.sblocks;CREATE TABLE sblocks ( key blob, column1 blob, value blob, PRIMARY KEY (key, column1)) WITH COMPACT STORAGE AND bloom_filter_fp_chance=0.000068 AND caching='KEYS_ONLY' AND comment='Stores blocks of information associated with a inode' AND dclocal_read_repair_chance=0.000000 AND gc_grace_seconds=864000 AND index_interval=128 AND read_repair_chance=0.100000 AND replicate_on_write='true' AND populate_io_cache_on_flush='true' AND default_time_to_live=0 AND speculative_retry='99.0PERCENTILE' AND memtable_flush_period_in_ms=0 AND compaction={'class': 'com.datastax.bdp.hadoop.cfs.compaction.CFSCompactionStrategy'} AND compression={};The 1.2 node reports the following error:ERROR 08:38:02,006 Exception in thread Thread[Thread-32,5,main]java.lang.ArrayIndexOutOfBoundsException: 36 at org.apache.cassandra.net.MessageIn.read(MessageIn.java:59) at org.apache.cassandra.net.IncomingTcpConnection.receiveMessage(IncomingTcpConnection.java:208) at org.apache.cassandra.net.IncomingTcpConnection.handleModernVersion(IncomingTcpConnection.java:140) at org.apache.cassandra.net.IncomingTcpConnection.run(IncomingTcpConnection.java:83)There were no errors during the upgrade.</description>
      <version>2.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.net.MessagingService.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6713" opendate="2014-2-14 00:00:00" fixdate="2014-2-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Snapshot based repair does not send snapshot command to itself</summary>
      <description>Due to this, the Merkle tree created will differ a lot causing lot of streaming to happen.</description>
      <version>1.2.16,2.0.6,2.1beta1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.AntiEntropyService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6714" opendate="2014-2-17 00:00:00" fixdate="2014-2-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix replaying old (1.2) commitlog in Cassandra 2.0</summary>
      <description>Our docs, and code, both explicitly say that you should drain a node before upgrading to a new major release.If you don't do what the docs explicitly tell you to do, however, Cassandra won't scream at you. Also, we do currently have logic to replay 1.2 commitlog in 2.0, but it seems to be slightly broken, unfortunately.</description>
      <version>2.0.6,2.1beta1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLogReplayer.java</file>
      <file type="M">src.java.org.apache.cassandra.db.commitlog.CommitLogDescriptor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6722" opendate="2014-2-18 00:00:00" fixdate="2014-2-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cross-partition ordering should have warning or be disallowed when paging</summary>
      <description>consider this schema/data/query:CREATE TABLE paging_test ( id int, value text, PRIMARY KEY (id, value)) WITH CLUSTERING ORDER BY (value ASC) |id|value| |1 |a | |2 |b | |1 |c | |2 |d | |1 |e | |2 |f | |1 |g | |2 |h | |1 |i | |2 |j |select * from paging_test where id in (1,2) order by value asc;When paging the above query I get the sorted results from id=1 first, then the sorted results from id=2 after that. I was testing this because I was curious if the paging system could somehow globally sort the results but it makes sense that we can't do that, since that would require all results to be collated up front.</description>
      <version>2.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6734" opendate="2014-2-19 00:00:00" fixdate="2014-2-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use correct partitioner in AbstractViewSSTableFinder</summary>
      <description>I don't think this breaks anything yet since we don't do range queries against index tables, but fixing it is a prereq for doing so (CASSANDRA-4476).</description>
      <version>2.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.DataTracker.java</file>
      <file type="M">src.java.org.apache.cassandra.db.ColumnFamilyStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="6735" opendate="2014-2-19 00:00:00" fixdate="2014-2-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Exceptions during memtable flushes on shutdown hook prevent process shutdown</summary>
      <description>If an exception occurs while flushing memtables during the shutdown hook, the process is left hanging due to non-daemon threads still running.</description>
      <version>1.2.16,2.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.service.StorageService.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6748" opendate="2014-2-21 00:00:00" fixdate="2014-2-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>If null is explicitly set to a column, paging_state will not work</summary>
      <description>If null is explicitly set to a column, paging_state will not work. My test procedure is as follows:------Create a table and insert 10 records using cqlsh. The query is as follows:CREATE TABLE mytable (id int, range int, value text, PRIMARY KEY (id, range));INSERT INTO mytable (id, range) VALUES (0, 0);INSERT INTO mytable (id, range) VALUES (0, 1);INSERT INTO mytable (id, range) VALUES (0, 2);INSERT INTO mytable (id, range) VALUES (0, 3);INSERT INTO mytable (id, range) VALUES (0, 4);INSERT INTO mytable (id, range, value) VALUES (0, 5, null);INSERT INTO mytable (id, range, value) VALUES (0, 6, null);INSERT INTO mytable (id, range, value) VALUES (0, 7, null);INSERT INTO mytable (id, range, value) VALUES (0, 8, null);INSERT INTO mytable (id, range, value) VALUES (0, 9, null);Select 10 records using datastax driver. The pseudocode is as follows:Statement statement = QueryBuilder.select().from("mytable").setFetchSize(1);ResultSet rs = session.execute(statement);for(Row row : rs){ System.out.println(String.format("id=%d, range=%d, value=%s", row.getInt("id"), row.getInt("range"), row.getString("value")));}The result is as follows:id=0, range=0, value=nullid=0, range=1, value=nullid=0, range=2, value=nullid=0, range=3, value=nullid=0, range=4, value=nullid=0, range=5, value=nullid=0, range=7, value=nullid=0, range=9, value=null------Result is 8 records although 10 records were expected. I originally raised this issue in the mailing lists: http://www.mail-archive.com/user@cassandra.apache.org/msg34752.html</description>
      <version>2.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test.unit.org.apache.cassandra.service.QueryPagerTest.java</file>
      <file type="M">test.unit.org.apache.cassandra.SchemaLoader.java</file>
      <file type="M">src.java.org.apache.cassandra.service.pager.SliceQueryPager.java</file>
      <file type="M">src.java.org.apache.cassandra.service.pager.RangeSliceQueryPager.java</file>
      <file type="M">src.java.org.apache.cassandra.service.pager.AbstractQueryPager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6769" opendate="2014-2-25 00:00:00" fixdate="2014-2-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Static columns break IN clauses</summary>
      <description>If you use static columns, as implemented in CASSANDRA-6561, then very simple SELECT...WHERE...IN queries fail with an internal NPE.create table foo (x text, y text, s text static, primary key (x,y));insert into foo (x,y,s) values ('a','b','c');select * from foo where x='a' and y in ('b','c');Request did not complete within rpc_timeout.ERROR &amp;#91;ReadStage:190&amp;#93; 2014-02-25 14:19:16,400 CassandraDaemon.java (line 196) Exception in thread Thread&amp;#91;ReadStage:190,5,main&amp;#93;java.lang.RuntimeException: java.lang.NullPointerException at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:1900) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:722)Caused by: java.lang.NullPointerException at org.apache.cassandra.db.filter.ColumnSlice$NavigableMapIterator.computeNext(ColumnSlice.java:141) at org.apache.cassandra.db.filter.ColumnSlice$NavigableMapIterator.computeNext(ColumnSlice.java:162) at org.apache.cassandra.db.filter.ColumnSlice$NavigableMapIterator.computeNext(ColumnSlice.java:162) at org.apache.cassandra.db.filter.ColumnSlice$NavigableMapIterator.computeNext(ColumnSlice.java:117) at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143) at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138) at org.apache.cassandra.db.filter.SliceQueryFilter$1.hasNext(SliceQueryFilter.java:148) at org.apache.cassandra.db.filter.QueryFilter$2.getNext(QueryFilter.java:157) at org.apache.cassandra.db.filter.QueryFilter$2.hasNext(QueryFilter.java:140) at org.apache.cassandra.utils.MergeIterator$OneToOne.computeNext(MergeIterator.java:200) at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143) at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138) at org.apache.cassandra.db.filter.SliceQueryFilter.collectReducedColumns(SliceQueryFilter.java:185) at org.apache.cassandra.db.filter.QueryFilter.collateColumns(QueryFilter.java:122) at org.apache.cassandra.db.filter.QueryFilter.collateOnDiskAtom(QueryFilter.java:80) at org.apache.cassandra.db.filter.QueryFilter.collateOnDiskAtom(QueryFilter.java:72) at org.apache.cassandra.db.CollationController.collectAllData(CollationController.java:297) at org.apache.cassandra.db.CollationController.getTopLevelColumns(CollationController.java:53) at org.apache.cassandra.db.ColumnFamilyStore.getTopLevelColumns(ColumnFamilyStore.java:1550) at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:1379) at org.apache.cassandra.db.Keyspace.getRow(Keyspace.java:327) at org.apache.cassandra.db.SliceFromReadCommand.getRow(SliceFromReadCommand.java:65) at org.apache.cassandra.service.StorageProxy$LocalReadRunnable.runMayThrow(StorageProxy.java:1341) at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:1896)</description>
      <version>2.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.SelectStatement.java</file>
    </fixedFiles>
  </bug>
  <bug id="6782" opendate="2014-2-27 00:00:00" fixdate="2014-3-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>setting TTL on some columns seems to expire whole row</summary>
      <description>I create a table with 4 columns, set a ttl on 2 of the columns and when the TTL is up, the entire row disappears.cqlsh:myks&gt; CREATE TABLE paging_test ( ... id int, ... mytext text, ... anothervalue text, ... somevalue text, ... PRIMARY KEY (id, mytext) ... );cqlsh:myks&gt; insert into paging_test (id, mytext, anothervalue, somevalue) values (1, 'foo', 'some', 'another');cqlsh:myks&gt; select * from paging_test; id | mytext | anothervalue | somevalue----+--------+--------------+----------- 1 | foo | some | another(1 rows)cqlsh:myks&gt; update paging_test using ttl 10 ... set somevalue='one', anothervalue='two' ... where id = 1 and mytext = 'foo';cqlsh:myks&gt; select * from paging_test; id | mytext | anothervalue | somevalue----+--------+--------------+----------- 1 | foo | two | one(1 rows)cqlsh:myks&gt; -- wait for it....cqlsh:myks&gt; select * from paging_test;(0 rows)</description>
      <version>2.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.UpdateStatement.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6784" opendate="2014-2-28 00:00:00" fixdate="2014-2-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compaction timestamp captured incorrectly in Compaction History table</summary>
      <description>Compaction finish time is incorrectly captured using System.nanoTime() before the compaction is triggered. The finish time should be captured using System.currentTimeMillis() as per #4432. The suggested patch captures using FBUtilities.timestampMicros() after the compaction completes.This however doesn't fix the formatting of timestamp values by cqlsh which throws decoding errors as below: Failed to format value NNN.. as timestamp: timestamp out of range for platform time_tReference : https://issues.apache.org/jira/browse/CASSANDRA-4432</description>
      <version>2.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.db.compaction.CompactionTask.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6813" opendate="2014-3-6 00:00:00" fixdate="2014-3-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>server side ClassCastException using compact storage</summary>
      <description>The following snippet fails on the current 2.0 branch and succeeds on the 2.1 branch.create KEYSPACE test WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1};USE test ;CREATE TABLE lock ( partition text, key text, owner text, PRIMARY KEY ((partition), key)) WITH COMPACT STORAGE;INSERT INTO lock(partition,key,owner) VALUES ('a','b',null) ;UPDATE lock SET owner='z' WHERE partition='a' AND key='b' IF owner=null;On the 2.0 branch a ClassCastException is logged in the server log file.ERROR [ReadStage:244] 2014-03-07 09:38:47,227 CassandraDaemon.java (line 196) Exception in thread Thread[ReadStage:244,5,main]java.lang.RuntimeException: java.lang.ClassCastException: org.apache.cassandra.db.marshal.BytesType cannot be cast to org.apache.cassandra.db.marshal.CompositeType at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:1900) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:744)Caused by: java.lang.ClassCastException: org.apache.cassandra.db.marshal.BytesType cannot be cast to org.apache.cassandra.db.marshal.CompositeType at org.apache.cassandra.db.filter.SliceQueryFilter.columnCounter(SliceQueryFilter.java:231)</description>
      <version>2.0.6</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.cassandra.cql3.statements.CQL3CasConditions.java</file>
      <file type="M">src.java.org.apache.cassandra.cql3.ColumnCondition.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>
