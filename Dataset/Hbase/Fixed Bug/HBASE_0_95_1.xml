<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="7712" opendate="2013-1-29 00:00:00" fixdate="2013-1-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Pass ScanType into preCompact()</summary>
      <description>See related discussion:http://search-hadoop.com/m/a7BYc2RITZ22/Getting+the+scan+type+at+preCompact&amp;subj=Re+Getting+the+scan+type+at+preCompact</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorInterface.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.SimpleRegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Compactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.java</file>
    </fixedFiles>
  </bug>
  <bug id="8327" opendate="2013-4-11 00:00:00" fixdate="2013-4-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Consolidate class loaders</summary>
      <description>HBASE-1936 introduced a class loader to load filter classes dynamically. We have a coprocessor class loader. These two usecases are a little different. However, some logic is similar, especially in the test code. We should do some refactory and reuse some code.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.94.8,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestClassLoading.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorClassLoader.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestDynamicClassLoader.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.DynamicClassLoader.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestGet.java</file>
    </fixedFiles>
  </bug>
  <bug id="8386" opendate="2013-4-19 00:00:00" fixdate="2013-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>deprecate TableMapReduce.addDependencyJars(Configuration, class&lt;?&gt; ...)</summary>
      <description>We expose two public static methods names addDependencyJars. One of them, void addDependencyJars(Job, is very helpful &amp;#8211; goes out of its way to detect job dependencies as well as shipping all the necessary HBase dependencies. The other is shfty and nefarious, void addDependencyJars(Configuration, Class&lt;?&gt;...) &amp;#8211; it only adds exactly what the user requests, forcing them to resolve dependencies themselves and giving a false sense of security. We should deprecate the latter throw a big giant warning when people use that one. The handy functionality of providing help when our heuristics fail can be added via a new method signature, something like void addDependencyJars(Job, Class&lt;?&gt; .... This method would do everything void addDependencyJars(Job does, plus let the user specify arbitrary additional classes. That way HBase still can help the user, but also gives them super-powers to compensate for when our heuristics fail.For reference, this appears to be the reason why HBase + Pig doesn't really work out of the box. See HBaseStorage.java</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.mapreduce.adoc</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapred.TestTableSnapshotInputFormat.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableSnapshotInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableMapReduceUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.WALPlayer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.ImportTsv.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.Import.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestWithCellVisibilityLoadAndVerify.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestLoadAndVerify.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
    </fixedFiles>
  </bug>
  <bug id="8407" opendate="2013-4-23 00:00:00" fixdate="2013-4-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove Async HBase from 0.95 and trunk.</summary>
      <description>Async HBase won't work on a protobuf'd server for quite a while. We should remove that code from perf evaluation until it async hbase is working again.</description>
      <version>0.98.0,0.95.1</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
      <file type="M">hbase-server.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8408" opendate="2013-4-23 00:00:00" fixdate="2013-8-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement namespace</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestLoadAndVerify.java</file>
      <file type="M">hbase-server.src.test.ruby.shell.shell.test.rb</file>
      <file type="M">hbase-server.src.test.ruby.hbase.table.test.rb</file>
      <file type="M">hbase-server.src.test.ruby.hbase.hbase.test.rb</file>
      <file type="M">hbase-server.src.test.ruby.hbase.admin.test.rb</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestMiniClusterLoadSequential.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestMergeTool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestMergeTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHFileArchiveUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsckComparator.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestFSTableDescriptors.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestCoprocessorScanPolicy.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.RestartMetaTest.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.ProcessBasedLocalHBaseCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MultiThreadedWriter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MultiThreadedReader.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MultiThreadedAction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MockRegionServerServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.LoadTestTool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.HFileArchiveTestingUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildOverlap.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildHole.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.OfflineMetaRebuildTestCore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.HbckTestingUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.thrift.TestThriftServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.thrift2.TestThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestZooKeeper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestSerialization.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestRegionRebalancing.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestMultiVersions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestIOFencing.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestInfoServers.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestHTableDescriptor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestFSTableDescriptorForceCreation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestDrainingServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestCompare.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestSnapshotTask.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestSnapshotLogSplitter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestRestoreSnapshotHelper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestRestoreFlushSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestReferenceRegionHFilesTask.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestFlushSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestExportSnapshot.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.SnapshotTestingUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.token.TestTokenAuthentication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestZKPermissionsWatcher.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestTablePermissions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessControlFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestTableResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestStatusResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestScannersWithFilters.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestScannerResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestRowResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestMultiRowResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestGzipFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.PerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestTableRegionModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestStorageClusterStatusModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.client.TestRemoteTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationSource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestMultiSlaveReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestMasterReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationHLogReaderManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALActionsListener.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRollingNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRolling.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRollAbort.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLogSplit.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLogMethods.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLogFiltering.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLog.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestDurability.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.HLogPerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestWideScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSeekOptimizations.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRSStatusServlet.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestResettingCounters.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerNoMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionMergeTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionMergeTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionFavoredNodes.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestParallelPut.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMemStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestJoinedScanners.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionServerBulkLoad.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionInfo.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionFileSystem.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestGetClosestAtOrBefore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestFSErrorsExposed.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestEndToEndSplitTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDefaultCompactSelection.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompactionState.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestColumnSeeking.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCacheOnWriteInSchema.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestBlocksScanned.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestBlocksRead.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestAtomicOperation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.HFileReadWriteTest.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.handler.TestOpenRegionHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.handler.TestCloseRegionHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MiniHBaseCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestZKBasedOpenCloseRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestTableLockManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRollingRestart.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRestartCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRegionPlacement.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestOpenedRegionHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterTransitions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterStatusServlet.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterRestartAfterDisablingTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterMetrics.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.snapshot.TestSnapshotManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.snapshot.TestSnapshotHFileCleaner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.handler.TestTableDescriptorModification.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.handler.TestTableDeleteFamilyHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.handler.TestCreateTableHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.cleaner.TestSnapshotFromMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.cleaner.TestHFileLinkCleaner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestFavoredNodeAssignmentHelper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.BalancerTestBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestWALPlayer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTimeRangeMapRed.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableSplit.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFilesSplitRecovery.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestImportExport.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestHLogRecordReader.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestScannerSelectionUsingTTL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestScannerSelectionUsingKeyRange.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestLoadAndSwitchEncodeOnDisk.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestChangingEncoding.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HTestConst.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestCase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestMultipleColumnPrefixFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestFilterWrapper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestFilterWithScanLimits.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestDependentColumnFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestColumnPrefixFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestWALObserver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithRemove.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithAbort.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverStacking.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverScannerOpenHook.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestOpenTableInCoprocessor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestMasterObserver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestMasterCoprocessorExceptionWithRemove.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestMasterCoprocessorExceptionWithAbort.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorInterface.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorEndpoint.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestClassLoading.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestBigDecimalColumnInterpreter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestAggregateProtocol.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.SimpleRegionObserver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.SampleRegionWALObserver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.constraint.TestConstraints.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.constraint.TestConstraint.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotMetadata.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotCloneIndependence.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestRestoreSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMultipleTimestamps.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMetaScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestIntraRowPagination.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHTablePool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHTableMultiplexer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHBaseAdminNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide3.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestCloneSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestClientScannerRPCTimeout.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.HConnectionTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.catalog.TestMetaReaderEditorNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.catalog.TestMetaReaderEditor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.catalog.TestMetaMigrationConvertingToPB.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.catalog.TestCatalogTracker.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestHFileArchiving.java</file>
      <file type="M">hbase-server.src.main.ruby.shell.commands.rb</file>
      <file type="M">hbase-server.src.main.ruby.shell.rb</file>
      <file type="M">hbase-server.src.main.ruby.hbase.table.rb</file>
      <file type="M">hbase-server.src.main.ruby.hbase.admin.rb</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.tablesDetailed.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.snapshot.jsp</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ModifyRegionUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.Merge.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HMerge.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HFileArchiveUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsckRepair.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSTableDescriptors.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSTableDescriptorMigrationToSubdir.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.Canary.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.TableDescriptors.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.TableInfoCopyTask.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotLogSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.ExportSnapshot.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.TokenUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.ZKPermissionWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.TableAuthManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AuthResult.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlLists.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.SchemaResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RootResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RegionsResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.TableSchemaModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.TableRegionModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteAdmin.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALEditsReplaySink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogKey.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.snapshot.RegionServerSnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionMergeTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionMergeRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.OnlineRegions.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.KeyPrefixRegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DelimitedKeyPrefixRegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactionTool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.ReplicationProtbufUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableLockManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.RestoreSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.MasterSnapshotVerifier.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.DisabledTableSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.CloneSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableModifyFamilyHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableEventHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableDeleteFamilyHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableAddFamilyHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.OpenedRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ModifyTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.EnableTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DisableTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DeleteTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.CreateTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ClosedRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.RegionLocationFinder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.FavoredNodeAssignmentHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableSplit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableInputFormatBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.WALPlayer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableSplit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.MultiTableInputFormatBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.ImportTsv.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.LocalHBaseCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.HFileLink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.package-info.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.constraint.ConstraintProcessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.HFileArchiver.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">hbase-protocol.src.main.protobuf.ZooKeeper.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.WAL.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.SecureBulkLoad.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.MasterMonitor.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.MasterAdmin.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.hbase.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.AccessControl.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.SecureBulkLoadProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MasterMonitorProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MasterAdminProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.catalog.MetaReader.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.AggregationClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.SecureBulkLoadClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnectionWrapper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTableInterface.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTableMultiplexer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTablePool.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MetaScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MultiServerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionServerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Registry.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.UnmodifyableHTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ZooKeeperRegistry.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.CoprocessorEnvironment.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RegionCoprocessorRpcChannel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.TablePermission.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.UserPermission.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.ClientSnapshotDescriptionUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.TablePartiallyOpenException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableExistsException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableNotDisabledException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableNotEnabledException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableNotFoundException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKTableReadOnly.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestAsyncProcess.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestClientNoCluster.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotFromAdmin.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Bytes.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestKeyValue.java</file>
      <file type="M">hbase-examples.src.test.java.org.apache.hadoop.hbase.coprocessor.example.TestBulkDeleteProtocol.java</file>
      <file type="M">hbase-examples.src.test.java.org.apache.hadoop.hbase.coprocessor.example.TestZooKeeperScanPolicyObserver.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestLazyCfLoading.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestManyRegions.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.mttr.IntegrationTestMTTR.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
    </fixedFiles>
  </bug>
  <bug id="8431" opendate="2013-4-25 00:00:00" fixdate="2013-4-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix missing headers</summary>
      <description>Now that rat is testing more files there are some missing.</description>
      <version>0.98.0,0.95.1</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestIPv6NIOServerSocketChannel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationSmallTests.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.NoOpScanPolicyObserver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestImportTsvParser.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapperStub.java</file>
      <file type="M">hbase-hadoop1-compat.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestMetricsWALSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestMetricsHLogSource.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestShowProperties.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.ipc.TestPayloadCarryingRpcController.java</file>
      <file type="M">bin.test.process.based.cluster.sh</file>
    </fixedFiles>
  </bug>
  <bug id="8444" opendate="2013-4-26 00:00:00" fixdate="2013-4-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Acknowledge that 0.95+ requires 1.0.3 hadoop at least.</summary>
      <description>As per this mail thread, http://search-hadoop.com/m/stbKO1YNWZe/Compile+does+not+work+against+Hadoop-1.0.0+-+1.0.2&amp;subj=Re+Compile+does+not+work+against+Hadoop+1+0+0+1+0+2... 0.95.x requires hadoop 1.0.3 at least. Note it in the refguide hadoop section.</description>
      <version>None</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.configuration.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8477" opendate="2013-5-2 00:00:00" fixdate="2013-5-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hadoop2] TestTableInputFormatScan* fails intermittently with PrivilegedActionException</summary>
      <description>In the test we see the following log messages which indicate an authentication problem and then some sort of recovery problem.2013-04-16 23:27:04,469 ERROR [IPC Server handler 0 on 45600] security.UserGroupInformation(1370): PriviledgedActionException as:ec2-user.hfs.2 (auth:SIMPLE) cause:org.apache.hadoop.security.AccessControlException: Can't continue with getBlockLocalPathInfo() authorization. The user ec2-user.hfs.2 is not allowed to call getBlockLocalPathInfo2013-04-16 23:27:04,501 WARN [PRI IPC Server handler 4 on 33892] hdfs.DFSInputStream(489): Failed to connect to /127.0.0.1:55547 for block, add to deadNodes and continue. org.apache.hadoop.security.AccessControlException: Can't continue with getBlockLocalPathInfo() authorization. The user ec2-user.hfs.2 is not allowed to call getBlockLocalPathInfo at org.apache.hadoop.hdfs.server.datanode.DataNode.checkBlockLocalPathAccess(DataNode.java:1016) at org.apache.hadoop.hdfs.server.datanode.DataNode.getBlockLocalPathInfo(DataNode.java:1026) at org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolServerSideTranslatorPB.getBlockLocalPathInfo(ClientDatanodeProtocolServerSideTranslatorPB.java:112) at org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(ClientDatanodeProtocolProtos.java:5104) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:454) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:910) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1694) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1690) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:396) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1367) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1688)org.apache.hadoop.security.AccessControlException: Can't continue with getBlockLocalPathInfo() authorization. The user ec2-user.hfs.2 is not allowed to call getBlockLocalPathInfo at org.apache.hadoop.hdfs.server.datanode.DataNode.checkBlockLocalPathAccess(DataNode.java:1016) at org.apache.hadoop.hdfs.server.datanode.DataNode.getBlockLocalPathInfo(DataNode.java:1026) at org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolServerSideTranslatorPB.getBlockLocalPathInfo(ClientDatanodeProtocolServerSideTranslatorPB.java:112) at org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(ClientDatanodeProtocolProtos.java:5104) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:454) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:910) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1694) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1690) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:396) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1367) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1688) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27) at java.lang.reflect.Constructor.newInstance(Constructor.java:513) at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:90) at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57) at org.apache.hadoop.hdfs.DFSClient.getLocalBlockReader(DFSClient.java:790) at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:888) at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:455) at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:645) at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:689) at java.io.DataInputStream.readFully(DataInputStream.java:178) at java.io.DataInputStream.readFully(DataInputStream.java:152) at org.apache.hadoop.hbase.util.FSTableDescriptors.getTableDescriptorModtime(FSTableDescriptors.java:429) at org.apache.hadoop.hbase.util.FSTableDescriptors.getTableDescriptorModtime(FSTableDescriptors.java:414) at org.apache.hadoop.hbase.util.FSTableDescriptors.get(FSTableDescriptors.java:169) at org.apache.hadoop.hbase.util.FSTableDescriptors.get(FSTableDescriptors.java:132) at org.apache.hadoop.hbase.regionserver.HRegionServer.openRegion(HRegionServer.java:3350) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.apache.hadoop.hbase.ipc.ProtobufRpcServerEngine$Server.call(ProtobufRpcServerEngine.java:174) at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1871)Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Can't continue with getBlockLocalPathInfo() authorization. The user ec2-user.hfs.2 is not allowed to call getBlockLocalPathInfo at org.apache.hadoop.hdfs.server.datanode.DataNode.checkBlockLocalPathAccess(DataNode.java:1016) at org.apache.hadoop.hdfs.server.datanode.DataNode.getBlockLocalPathInfo(DataNode.java:1026) at org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolServerSideTranslatorPB.getBlockLocalPathInfo(ClientDatanodeProtocolServerSideTranslatorPB.java:112) at org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(ClientDatanodeProtocolProtos.java:5104) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:454) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:910) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1694) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1690) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:396) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1367) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1688) at org.apache.hadoop.ipc.Client.call(Client.java:1164) at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:202) at com.sun.proxy.$Proxy20.getBlockLocalPathInfo(Unknown Source) at org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolTranslatorPB.getBlockLocalPathInfo(ClientDatanodeProtocolTranslatorPB.java:199) at org.apache.hadoop.hdfs.BlockReaderLocal.getBlockPathInfo(BlockReaderLocal.java:254) at org.apache.hadoop.hdfs.BlockReaderLocal.newBlockReader(BlockReaderLocal.java:167) at org.apache.hadoop.hdfs.DFSClient.getLocalBlockReader(DFSClient.java:786) ... 17 moreThis seems similar to the other short-circuit-read hadoop2 related failures</description>
      <version>0.98.0,0.95.1</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScanBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="8498" opendate="2013-5-6 00:00:00" fixdate="2013-5-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>PB WAL reading is broken due to some partial reads</summary>
      <description>From dev list, there's IOException during log splitting on hadoop-2.0.3. We need to understand whether this is caused by EOF, and ignore it if it is.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.BaseDecoder.java</file>
    </fixedFiles>
  </bug>
  <bug id="8510" opendate="2013-5-8 00:00:00" fixdate="2013-5-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBASE-8469 added a hdfs-site.xml file for tests but it gets included in the test jar</summary>
      <description>aleksshulman found in his tests that HBase recently started ignoring hdfs-site.xml when it's on the classpath. I found that HBASE-8469 added an hdfs-site.xml for the unit tests but it's not excluded when building the jar.</description>
      <version>0.98.0,0.95.1</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8535" opendate="2013-5-13 00:00:00" fixdate="2013-5-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Test for zk leak does not account for unsynchronized access to zk watcher</summary>
      <description>Test can detect a live zk connection in a closed hconnection because it does not accesses the zk watcher in a synchronized manner.</description>
      <version>0.98.0,0.95.1</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
    </fixedFiles>
  </bug>
  <bug id="8569" opendate="2013-5-17 00:00:00" fixdate="2013-11-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve coverage in package org.apache.hadoop.hbase.security</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.TestUser.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.HBaseSaslRpcClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.TestSecureRPC.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestDelayedRpc.java</file>
    </fixedFiles>
  </bug>
  <bug id="8586" opendate="2013-5-21 00:00:00" fixdate="2013-6-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Revisit of hbase-8483, "HConnectionManager can leak ZooKeeper connections when using deleteStaleConnection"</summary>
      <description>hbase-8483 did not fix testDeleteForZKConnLeak definitively. Here is a follow on issue.Eric Yu has suggested something to try. Will attach the patch.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
    </fixedFiles>
  </bug>
  <bug id="8588" opendate="2013-5-21 00:00:00" fixdate="2013-5-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[Documentation]: Add information about adding REST and Thrift API kerberos principals to HBase ACL table</summary>
      <description>When users set up secure REST and Thrift API gateways, those principals will need entries in the HBase ACL table in order to interact with HBase.We should add that to the documentation so that they can have success with it right away.</description>
      <version>0.94.8,0.95.1</version>
      <fixedVersion>0.94.8,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.security.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8617" opendate="2013-5-25 00:00:00" fixdate="2013-6-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Introducing a new config to disable writes during recovering</summary>
      <description>In distributedLogReplay(hbase-7006), we allow writes even when a region is in recovering. It may cause undesired behavior when applications(or deployments) already are near its write capacity because distributedLogReplay generates more write traffic to remaining region servers.The new config "hbase.regionserver.disallow.writes.when.recovering" tries to address the above situation so that recovering won't be affected by application normal write traffic.The default value of this config is false(meaning allow writes in recovery)</description>
      <version>0.98.0,0.95.1</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="8618" opendate="2013-5-25 00:00:00" fixdate="2013-5-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Master is providing dead RegionServer ServerName&amp;#39;s to the balancer</summary>
      <description>The balancer should not be passed any ServerName's for RS's that are dead.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
    </fixedFiles>
  </bug>
  <bug id="8622" opendate="2013-5-25 00:00:00" fixdate="2013-5-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove &amp;#39; You are currently running the HMaster without HDFS append support enabled. This may result in data loss. Please see the HBase wiki for details. &amp;#39; from UI</summary>
      <description>We show ' You are currently running the HMaster without HDFS append support enabled. This may result in data loss. Please see the HBase wiki for details. ' if append not enabled. But we don't turn it on since hadoop1 because default is that it is on. Remove this confusing warning from UI.</description>
      <version>0.95.1</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterStatusServlet.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="8642" opendate="2013-5-29 00:00:00" fixdate="2013-7-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[Snapshot] List and delete snapshot by table</summary>
      <description>Support list and delete snapshots by table names.User scenario:A user wants to delete all the snapshots which were taken in January month for a table 't' where snapshot names starts with 'Jan'.</description>
      <version>0.98.0,0.95.0,0.95.1,0.95.2</version>
      <fixedVersion>0.98.14,1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.shell.rb</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotFromClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
    </fixedFiles>
  </bug>
  <bug id="8643" opendate="2013-5-29 00:00:00" fixdate="2013-5-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Do not log full classnames in logs, just the last two levels</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.log4j.properties</file>
    </fixedFiles>
  </bug>
  <bug id="8665" opendate="2013-5-30 00:00:00" fixdate="2013-6-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>bad compaction priority behavior in queue can cause store to be blocked</summary>
      <description>Note that this can be solved by bumping up the number of compaction threads but still it seems like this priority "inversion" should be dealt with.There's a store with 1 big file and 3 flushes (1 2 3 4) sitting around and minding its own business when it decides to compact. Compaction (2 3 4) is created and put in queue, it's low priority, so it doesn't get out of the queue for some time - other stores are compacting. Meanwhile more files are flushed and at (1 2 3 4 5 6 7) it decides to compact (5 6 7). This compaction now has higher priority than the first one. After that if the load is high it enters vicious cycle of compacting and compacting files as they arrive, with store being blocked on and off, with the (2 3 4) compaction staying in queue for up to ~20 minutes (that I've seen).I wonder why we do thing thing where we queue compaction and compact separately. Perhaps we should take snapshot of all store priorities, then do select in order and execute the first compaction we find. This will need starvation safeguard too but should probably be better.Btw, exploring compaction policy may be more prone to this, as it can select files from the middle, not just beginning, which, given the treatment of already selected files that was not changed from the old ratio-based one (all files with lower seqNums than the ones selected are also ineligible for further selection), will make more files ineligible (e.g. imagine with 10 blocking files, with 8 present (1-8), (6 7 8) being selected and getting stuck). Today I see the case that would also apply to old policy, but yesterday I saw file distribution something like this: 4,5g, 2,1g, 295,9m, 113,3m, 68,0m, 67,8m, 1,1g, 295,1m, 100,4m, unfortunately w/o enough logs to figure out how it resulted.</description>
      <version>0.95.1</version>
      <fixedVersion>0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
    </fixedFiles>
  </bug>
  <bug id="8666" opendate="2013-5-31 00:00:00" fixdate="2013-6-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>META region isn&amp;#39;t fully recovered during master initialization when META region recovery had chained failures</summary>
      <description>In distributedLogReplay mode when Meta recovery had experienced chained failures(recovery failed multiple times in a row), META region can't be fully recovered during master starts up.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="8669" opendate="2013-5-31 00:00:00" fixdate="2013-6-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>change exploring compaction policy to prefer smaller compactions on blocked stores</summary>
      <description>Side-note from HBASE-8665 discussion. When we compact a blocked store, we might want to use a different heuristic to choose between the options.</description>
      <version>None</version>
      <fixedVersion>0.95.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDefaultCompactSelection.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy.java</file>
    </fixedFiles>
  </bug>
  <bug id="867" opendate="2008-9-4 00:00:00" fixdate="2008-6-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>If millions of columns in a column family, hbase scanner won&amp;#39;t come up</summary>
      <description>Our Daniel has uploaded a table that has a column family with millions of columns in it. He can get items from the table promptly specifying row and column. Scanning is another matter. Thread dumping I see we're stuck in the scanner constructor nexting through cells.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="8672" opendate="2013-5-31 00:00:00" fixdate="2013-6-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create an Integration test for Bulk Loads</summary>
      <description>Bulk loads and MR are not well tested using our IT tests. We should add a test that bulk loads hfiles and then scans over the resulting table to make sure that all the data is there.</description>
      <version>0.98.0,0.95.1</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HFileOutputFormat.java</file>
    </fixedFiles>
  </bug>
  <bug id="8693" opendate="2013-6-5 00:00:00" fixdate="2013-8-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>DataType: provide extensible type API</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.types.TestStruct.java</file>
    </fixedFiles>
  </bug>
  <bug id="8705" opendate="2013-6-7 00:00:00" fixdate="2013-6-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RS holding META when restarted in a single node setup may hang infinitely without META assignment</summary>
      <description>This bug may be minor as it likely to happen in a single node setup.I restarted the RS holding META. The master tried assigning META using MetaSSH. But tried this before the new RS came up.So as not region plan is found if (plan == null) { LOG.warn("Unable to determine a plan to assign " + region); if (tomActivated){ this.timeoutMonitor.setAllRegionServersOffline(true); } else { regionStates.updateRegionState(region, RegionState.State.FAILED_OPEN); } return; }we just return without assigment. And this being the META the small cluster just hangs.</description>
      <version>0.95.1</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="8710" opendate="2013-6-7 00:00:00" fixdate="2013-10-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The balancer shouldn&amp;#39;t try balancing one node</summary>
      <description>In my logs, testing 0.95.1 RC1, I see:2013-06-07 17:31:47,377 DEBUG [ip-10-20-46-44.novalocal,48569,1370640098134-BalancerChore] balancer.StochasticLoadBalancer: Could not find a better load balance plan. Tried 3200 different configurations in 27ms, and did not find anything with a computed cost less than 25.0Ideally we'd not even try one configuration, let alone 3.2k.</description>
      <version>0.95.1</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
    </fixedFiles>
  </bug>
  <bug id="8711" opendate="2013-6-7 00:00:00" fixdate="2013-9-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Requests count is completely off</summary>
      <description>I tried 0.95.1 RC1 in standalone, and the requests count in both the master and RS web UIs are wrong. I haven't dug too much in but it seems too low when I'm sending load, and it takes &gt;10 seconds to clear up when the cluster becomes completely idle.</description>
      <version>0.95.1</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="8726" opendate="2013-6-11 00:00:00" fixdate="2013-8-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create an Integration Test for online schema change</summary>
      <description>With table locks in place it should be time to start really testing online table schema changes.</description>
      <version>0.98.0,0.95.1</version>
      <fixedVersion>0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.util.ChaosMonkey.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedListWithChaosMonkey.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestDataIngestWithChaosMonkey.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestDataIngestSlowDeterministic.java</file>
    </fixedFiles>
  </bug>
  <bug id="8732" opendate="2013-6-11 00:00:00" fixdate="2013-7-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HFileBlockDefaultEncodingContext isn&amp;#39;t thread-safe but is used by all readers, breaks column encoding</summary>
      <description>Getting an error when opening a scanner on a file that has no encoding.</description>
      <version>0.98.0,0.95.1</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationSmallTests.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationQueueFailoverCompressed.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationQueueFailover.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoderImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="8733" opendate="2013-6-12 00:00:00" fixdate="2013-6-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update our hadoop2 in trunk and 0.95 to 2.0.5-alpha (We are currently 2.0.2)</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8737" opendate="2013-6-12 00:00:00" fixdate="2013-7-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[replication] Change replication RPC to use cell blocks</summary>
      <description>Currently, the replication rpc that ships edits simply dumps the byte value of WAL edit key/value pairs into a protobuf message.Modify the replication rpc mechanism to use cell blocks so it can leverage encoding and compression.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationSmallTests.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.Replication.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ReplicationSourceService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ReplicationSinkService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.ReplicationProtbufUtil.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Admin.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.AdminProtos.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.HeapSize.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.ipc.TestIPCUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.IPCUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Put.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Delete.java</file>
    </fixedFiles>
  </bug>
  <bug id="8738" opendate="2013-6-12 00:00:00" fixdate="2013-6-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[refGuide] Overhauled HBase metrics section</summary>
      <description>Overhauled HBase metrics section in Ops chapter. Broke out flat list of metrics into 2 sub-sections: most important, and "other". Added many metrics, and improved descriptions of all metrics. Added warning to Ganglia users about default metric emission.Thanks to Elliot Clark, Greg Waffen, James McDermott, Charles Douthart.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8739" opendate="2013-6-12 00:00:00" fixdate="2013-6-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[refGuide] corrected map-task "spitting"</summary>
      <description>Nit fix in the MapReduce chapter.Corrected section heading "Map-Task Spitting" to "Map-Task Splitting".</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="874" opendate="2008-9-5 00:00:00" fixdate="2008-9-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>deleting a table kills client rpc; no subsequent communication if shell or thrift server, etc.</summary>
      <description>In shell, create a table, drop it, then try recreate. Will get:NativeException: java.io.IOException: The client is stopped</description>
      <version>None</version>
      <fixedVersion>0.18.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.util.TestMigrate.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.util.DisabledTestMetaUtils.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.HBaseClusterTestCase.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HMerge.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="8741" opendate="2013-6-13 00:00:00" fixdate="2013-11-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scope sequenceid to the region rather than regionserver (WAS: Mutations on Regions in recovery mode might have same sequenceIDs)</summary>
      <description>Currently, when opening a region, we find the maximum sequence ID from all its HFiles and then set the LogSequenceId of the log (in case the later is at a small value). This works good in recovered.edits case as we are not writing to the region until we have replayed all of its previous edits. With distributed log replay, if we want to enable writes while a region is under recovery, we need to make sure that the logSequenceId &gt; maximum logSequenceId of the old regionserver. Otherwise, we might have a situation where new edits have same (or smaller) sequenceIds. We can store region level information in the WALTrailer, than this scenario could be avoided by:a) reading the trailer of the "last completed" file, i.e., last wal file which has a trailer and,b) completely reading the last wal file (this file would not have the trailer, so it needs to be read completely).In future, if we switch to multi wal file, we could read the trailer for all completed WAL files, and reading the remaining incomplete files.</description>
      <version>0.95.1</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationHLogReaderManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALActionsListener.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRollingNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLogSplit.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLog.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.HLogPerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestHLogRecordReader.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestWALObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="8760" opendate="2013-6-18 00:00:00" fixdate="2013-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>possible loss of data in snapshot taken after region split</summary>
      <description>Right after a region split but before the daughter regions are compacted, we have two daughter regions containing Reference files to the parent hfiles.If we take snapshot right at the moment, the snapshot will succeed, but it will only contain the daughter Reference files. Since there is no hold on the parent hfiles, they will be deleted by the HFile Cleaner after they are no longer needed by the daughter regions soon after.A minimum we need to do is the keep these parent hfiles from being deleted.</description>
      <version>0.94.8,0.95.1</version>
      <fixedVersion>0.98.0,0.94.12,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.ExportSnapshot.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.RestoreSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.MasterSnapshotVerifier.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.EnabledTableSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.DisabledTableSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.CloneSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.CreateTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.HFileLink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.catalog.MetaEditor.java</file>
    </fixedFiles>
  </bug>
  <bug id="8763" opendate="2013-6-18 00:00:00" fixdate="2013-6-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Combine MVCC and SeqId</summary>
      <description>HBASE-8701 and a lot of recent issues include good discussions about mvcc + seqId semantics. It seems that having mvcc and the seqId complicates the comparator semantics a lot in regards to flush + WAL replay + compactions + delete markers and out of order puts. Thinking more about it I don't think we need a MVCC write number which is different than the seqId. We can keep the MVCC semantics, read point and smallest read points intact, but combine mvcc write number and seqId. This will allow cleaner semantics + implementation + smaller data files. We can do some brainstorming for 0.98. We still have to verify that this would be semantically correct, it should be so by my current understanding.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMultiVersionConsistencyControl.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDefaultMemStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMultiParallel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALEdit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogKey.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSWALEntry.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MultiVersionConsistencyControl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultMemStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="8768" opendate="2013-6-19 00:00:00" fixdate="2013-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve bulk load performance by moving key value construction from map phase to reduce phase.</summary>
      <description>ImportTSV bulkloading approach uses MapReduce framework. Existing mapper and reducer classes used by ImportTSV are TsvImporterMapper.java and PutSortReducer.java. ImportTSV tool parses the tab(by default) seperated values from the input files and Mapper class generates the PUT objects for each row using the Key value pairs created from the parsed text. PutSortReducer then uses the partions based on the regions and sorts the Put objects for each region. Overheads we can see in the above approach:==========================================1) keyvalue construction for each parsed value in the line adding extra data like rowkey,columnfamily,qualifier which will increase around 5x extra data to be shuffled in reduce phase.We can calculate data size to shuffled as below Data to be shuffled = nl*nt*(rl+cfl+cql+vall+tsl+30)If we move keyvalue construction to reduce phase we datasize to be shuffle will be which is very less compared to above. Data to be shuffled = nl*nt*vallnl - Number of lines in the raw filent - Number of tabs or columns including row key.rl - row length which will be different for each line.cfl - column family length which will be different for each familycql - qualifier lengthtsl - timestamp length.vall- each parsed value length.30 bytes for kv size,number of families etc.2) In mapper side we are creating put objects by adding all keyvalues constructed for each line and in reducer we will again collect keyvalues from put and sort them.Instead we can directly create and sort keyvalues in reducer.Solution:========We can improve bulk load performance by moving the key value construction from mapper to reducer so that Mapper just sends the raw text for each row to the Reducer. Reducer then parses the records for rows and create and sort the key value pairs before writing to HFiles. Conclusion:===========The above suggestions will improve map phase performance by avoiding keyvalue construction and reduce phase performance by avoiding excess data to be shuffled.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestImportTsvParser.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestImportTsv.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.ImportTsv.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HFileOutputFormat.java</file>
    </fixedFiles>
  </bug>
  <bug id="8774" opendate="2013-6-20 00:00:00" fixdate="2013-7-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add BatchSize and Filter to Thrift2</summary>
      <description>Attached Patch will add BatchSize and Filter support to Thrift2</description>
      <version>0.95.1</version>
      <fixedVersion>0.98.0,0.95.2,0.94.10</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.thrift2.TestThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.thrift2.hbase.thrift</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftUtilities.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TScan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TGet.java</file>
    </fixedFiles>
  </bug>
  <bug id="8786" opendate="2013-6-21 00:00:00" fixdate="2013-6-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Creating a table with a Bloom filter on the shell is broken.</summary>
      <description>create 'tsdb', {NAME =&gt; 't', VERSIONS =&gt; 1, BLOOMFILTER =&gt; 'row'}results in:ERROR: uninitialized constant Java::OrgApacheHadoopHbaseRegionserver::StoreFile::BloomType</description>
      <version>0.95.1</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug id="8789" opendate="2013-6-22 00:00:00" fixdate="2013-7-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add max RPC version to meta-region-server zk node.</summary>
      <description>For clients to boot strap themselves they need to know the max rpc version that the meta server will accept. We should add that to the zookeeper node.</description>
      <version>0.98.0,0.95.1</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-protocol.src.main.protobuf.ZooKeeper.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.MetaRegionTracker.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.MasterAddressTracker.java</file>
    </fixedFiles>
  </bug>
  <bug id="8791" opendate="2013-6-23 00:00:00" fixdate="2013-6-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Precommit hadoopqa is broke since -r1491656</summary>
      <description>Fails like this:[INFO] ------------------------------------------------------------------------[INFO] BUILD FAILURE[INFO] ------------------------------------------------------------------------[INFO] Total time: 42.547s[INFO] Finished at: Fri Jun 21 02:43:29 UTC 2013[INFO] Final Memory: 48M/569M[INFO] ------------------------------------------------------------------------[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.5.1:testCompile (default-testCompile) on project hbase-it: Compilation failure[ERROR] /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/trunk/hbase-it/src/test/java/org/apache/hadoop/hbase/mapreduce/IntegrationTestBulkLoad.java:[589,36] cannot access org.apache.hadoop.mapred.MiniMRCluster[ERROR] class file for org.apache.hadoop.mapred.MiniMRCluster not found[ERROR] util.startMiniMapReduceCluster();[ERROR] -&gt; [Help 1]org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.5.1:testCompile (default-testCompile) on project hbase-it: Compilation failure/home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/trunk/hbase-it/src/test/java/org/apache/hadoop/hbase/mapreduce/IntegrationTestBulkLoad.java:[589,36] cannot access org.apache.hadoop.mapred.MiniMRClusterclass file for org.apache.hadoop.mapred.MiniMRCluster not found util.startMiniMapReduceCluster(); at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:213) at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153) at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145) at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:84) at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:59) at org.apache.maven.lifecycle.internal.LifecycleStarter.singleThreadedBuild(LifecycleStarter.java:183) at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:161) at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:319) at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:156) at org.apache.maven.cli.MavenCli.execute(MavenCli.java:537) at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:196) at org.apache.maven.cli.MavenCli.main(MavenCli.java:141) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:290) at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:230) at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:409) at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:352)Caused by: org.apache.maven.plugin.CompilationFailureException: Compilation failure/home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/trunk/hbase-it/src/test/java/org/apache/hadoop/hbase/mapreduce/IntegrationTestBulkLoad.java:[589,36] cannot access org.apache.hadoop.mapred.MiniMRClusterclass file for org.apache.hadoop.mapred.MiniMRCluster not found util.startMiniMapReduceCluster(); at org.apache.maven.plugin.AbstractCompilerMojo.execute(AbstractCompilerMojo.java:729) at org.apache.maven.plugin.TestCompilerMojo.execute(TestCompilerMojo.java:161) at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:101) at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:209) ... 19 more</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8813" opendate="2013-6-27 00:00:00" fixdate="2013-6-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix time b/w recoverLease invocations from HBASE 8449</summary>
      <description>The time b/w recover lease attempts is conservative but is still not correct. It does not factor in Datanode heartbeat time intervals.</description>
      <version>0.98.0,0.95.1</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8853" opendate="2013-7-2 00:00:00" fixdate="2013-7-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The client connection is not cut when receiving the failure notification</summary>
      <description>It seems we broke something when we changed the client code (likely nio stuff). Here is a fix and a unit test.</description>
      <version>0.95.1</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClusterStatusListener.java</file>
    </fixedFiles>
  </bug>
  <bug id="8855" opendate="2013-7-2 00:00:00" fixdate="2013-7-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestTableInputFormatScan1/2 fail semi-silently with the hadoop 2 profile</summary>
      <description>It looks like TestTableInputFormatScan1 and TestTableInputFormatScan2 never complete and surefire doesn't complain about it. Sure, you may see this:Tests run: 6, Failures: 5, Errors: 1, Skipped: 0, Time elapsed: 269.036 sec &lt;&lt;&lt; FAILURE!org.apache.maven.surefire.util.SurefireReflectionException: ...org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:74)Caused by: java.lang.OutOfMemoryError: PermGen spaceorg.apache.maven.surefire.booter.SurefireBooterForkException: Error occurred in starting fork, check output in log... testScanEmptyToBBA(org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan1) testScanEmptyToBBB(org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan1) testScanEmptyToOPP(org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan1) testScanEmptyToEmpty(org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan1)But then:[INFO] HBase - Server .................................... SUCCESS [10:59.929s]This is on my machine. On our local jenkins it's leaking and the processes never die. And this is only with Hadoop 2. It also looks like other tests are failing with PermGen space.</description>
      <version>0.94.8,0.95.1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="886" opendate="2008-9-16 00:00:00" fixdate="2008-9-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Sort the tables in the web UI</summary>
      <description>From the list:hi all,I just thought that it would be great if you could addArrays.sort(tables);in master.jsp somwhere near"&lt;% HTableDescriptor[] tables = new HBaseAdmin(conf).listTables(); if(tables != null &amp;&amp; tables.length &gt; 0) { %&gt;"it is really annoying if one have to find a table in an unsorted list krzysiek</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="8868" opendate="2013-7-4 00:00:00" fixdate="2013-3-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>add metric to report client shortcircuit reads</summary>
      <description>With the availability of shortcircuit reads, when the feature is enabled there is no metric which exposes how many times the regionserver was able to shortcircuit the read and not make a IPC to the datanode.It will be great to add the metric and expose it via Ganglia.</description>
      <version>0.94.8,0.95.1</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,1.7.0,2.2.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.schema.design.adoc</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerMetrics.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperStub.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.FSDataInputStreamWrapper.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="887" opendate="2008-9-17 00:00:00" fixdate="2008-9-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix a hotspot in scanners</summary>
      <description>When scanning, we do a lot of RPCs and this has a huge performance hit. I propose that we add a way to fetch more rows during next() and put them in cache. This should be configurable.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HRegionInterface.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.transactional.TransactionalTable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.MetaScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="8870" opendate="2013-7-4 00:00:00" fixdate="2013-9-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Store.needsCompaction() should include minFilesToCompact</summary>
      <description>read here: public boolean needsCompaction() { return (storefiles.size() - filesCompacting.size()) &gt; minFilesToCompact; }imho, it should be public boolean needsCompaction() { return (storefiles.size() - filesCompacting.size()) &gt;= minFilesToCompact; }</description>
      <version>0.95.1</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.cleaner.TestSnapshotFromMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverScannerOpenHook.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.RatioBasedCompactionPolicy.java</file>
    </fixedFiles>
  </bug>
  <bug id="8875" opendate="2013-7-5 00:00:00" fixdate="2013-7-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>incorrect javadoc for EXCLUDE_FROM_MINOR_COMPACTION</summary>
      <description>/** Major compaction flag in FileInfo */+ /** Minor compaction flag in FileInfo */ public static final byte[] EXCLUDE_FROM_MINOR_COMPACTION_KEY = Bytes.toBytes("EXCLUDE_FROM_MINOR_COMPACTION");</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
    </fixedFiles>
  </bug>
  <bug id="8876" opendate="2013-7-5 00:00:00" fixdate="2013-7-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Addendum to HBASE-8774 Add BatchSize and Filter to Thrift2 - Add BatchSize Test</summary>
      <description>HBASE-8774 adds support for batching through large rows. A unit test was missing though, which is added here. Further cleanup as well, to test scan, scan with filter, and scan with batch size separately.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2,0.94.10</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TScan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TGet.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.thrift2.TestThriftHBaseServiceHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="8880" opendate="2013-7-5 00:00:00" fixdate="2013-7-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Integration Tests shouldn&amp;#39;t set the number or reties.</summary>
      <description>Setting the number of client reties should be a function of the environment, not of the test.</description>
      <version>0.98.0,0.95.1</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestDataIngestWithChaosMonkey.java</file>
    </fixedFiles>
  </bug>
  <bug id="8924" opendate="2013-7-10 00:00:00" fixdate="2013-7-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Master Can fail to come up after chaos monkey if the sleep time is too short.</summary>
      <description>On a real cluster the master won't come up if the sleep time between killing and starting is too short.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.util.ChaosMonkey.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.mttr.IntegrationTestMTTR.java</file>
    </fixedFiles>
  </bug>
  <bug id="8983" opendate="2013-7-18 00:00:00" fixdate="2013-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBaseConnection#deleteAllConnections does not always delete</summary>
      <description>Cf; mailing list http://search-hadoop.com/m/wurpu1s8Fhs/liochon&amp;subj=Re+Connection+reference+counting</description>
      <version>0.95.1</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationDisableInactivePeer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MiniHBaseCluster.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="8984" opendate="2013-7-18 00:00:00" fixdate="2013-7-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Test online snapshots with online merge</summary>
      <description>Add unit tests to verify that after an online merge: taking a snapshot still works snapshots and cloned tables are still in a good state.Also on the same line, fix the unit test to have more than one region, and test multi RS/multi regions online snapshot.</description>
      <version>0.95.1</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestFlushSnapshotFromClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="8986" opendate="2013-7-18 00:00:00" fixdate="2013-7-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace hardcoded special file/dir names with the relative HConstant</summary>
      <description>There're some hardcoded names in the tests (like .archive, .logs &amp; co)replace them with the relative HConstants.*</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestWALReferenceTask.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestFlushSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestExportSnapshot.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLogSplit.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLog.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.snapshot.TestSnapshotLogCleaner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotCloneIndependence.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestHFileArchiving.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="9006" opendate="2013-7-20 00:00:00" fixdate="2013-7-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RPC code requires cellBlockCodecClass even though one is defined by default</summary>
      <description>The protobuf definition provides a default value:// This is sent on connection setup after the connection preamble is sent.message ConnectionHeader { [...] optional string cellBlockCodecClass = 3 [default = "org.apache.hadoop.hbase.codec.KeyValueCodec"]; // Compressor we will use if cell block is compressed. Server will throw exception if not supported. // Class must implement hadoop's CompressionCodec Interface [...]}Yet if one doesn't explicitly set a value, the code was rejecting the connection.</description>
      <version>0.95.1</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="9052" opendate="2013-7-26 00:00:00" fixdate="2013-7-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Prevent split/merged region from assigning again</summary>
      <description>If a region is split/merged, before it's removed from meta, you can still assign it from the HBase shell. It's better to prevent this from happening.</description>
      <version>0.95.1</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionMergeTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DisableTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DeleteTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.master.RegionState.java</file>
    </fixedFiles>
  </bug>
  <bug id="9055" opendate="2013-7-27 00:00:00" fixdate="2013-8-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBaseAdmin#isTableEnabled() should return false for non-existent table</summary>
      <description>Currently HBaseAdmin#isTableEnabled() returns true for a table which doesn't exist.We should check table existence.</description>
      <version>0.95.1</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKTableReadOnly.java</file>
    </fixedFiles>
  </bug>
  <bug id="906" opendate="2008-9-27 00:00:00" fixdate="2008-9-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[shell] Truncates output</summary>
      <description>This is bad because it gives odd impression that an upload was not complete. One line fix in the formatter.</description>
      <version>None</version>
      <fixedVersion>0.18.1,0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.Formatter.rb</file>
    </fixedFiles>
  </bug>
  <bug id="9062" opendate="2013-7-27 00:00:00" fixdate="2013-7-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove TestReplicationKillRs* tests temporarily</summary>
      <description>Removing this suite of tests for now. jdcryans is working on fixing these over in HBASE-8615 but currently he is off in "exotic location". Removing meantime to get in some clean builds. Will put back in HBASE-9061 which is critical for 0.95.2</description>
      <version>None</version>
      <fixedVersion>0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationKillSlaveRS.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationKillRS.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationKillMasterRSCompressed.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationKillMasterRS.java</file>
    </fixedFiles>
  </bug>
  <bug id="9077" opendate="2013-7-29 00:00:00" fixdate="2013-8-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make Web ui Fluid width</summary>
      <description>Region names and other unusually long strings really make the ui look weird. We should go with a fluid ui width the minimize the breakage.</description>
      <version>0.98.0,0.95.1</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.thrift.thrift.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.zk.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.tablesDetailed.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="9078" opendate="2013-7-29 00:00:00" fixdate="2013-8-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Downstream build including hbase-client fails because can&amp;#39;t find com.sun.jdmk:jmxtools</summary>
      <description>I've hacked up a downstream maven project. If I include hbase-client, my build fails with this:[INFO] ------------------------------------------------------------------------[INFO] BUILD FAILURE[INFO] ------------------------------------------------------------------------[INFO] Total time: 0.821s[INFO] Finished at: Mon Jul 29 15:58:39 PDT 2013[INFO] Final Memory: 4M/81M[INFO] ------------------------------------------------------------------------[ERROR] Failed to execute goal on project client: Could not resolve dependencies for project org.hbase.downstream:client:jar:1.0-SNAPSHOT: The following artifacts could not be resolved: com.sun.jdmk:jmxtools:jar:1.2.1, com.sun.jmx:jmxri:jar:1.2.1: Failure to find com.sun.jdmk:jmxtools:jar:1.2.1 in http://repo.maven.apache.org/maven2 was cached in the local repository, resolution will not be reattempted until the update interval of central has elapsed or updates are forced -&gt; [Help 1]org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal on project client: Could not resolve dependencies for project org.hbase.downstream:client:jar:1.0-SNAPSHOT: The following artifacts could not be resolved: com.sun.jdmk:jmxtools:jar:1.2.1, com.sun.jmx:jmxri:jar:1.2.1: Failure to find com.sun.jdmk:jmxtools:jar:1.2.1 in http://repo.maven.apache.org/maven2 was cached in the local repository, resolution will not be reattempted until the update interval of central has elapsed or updates are forced at org.apache.maven.lifecycle.internal.LifecycleDependencyResolver.getDependencies(LifecycleDependencyResolver.java:210) at org.apache.maven.lifecycle.internal.LifecycleDependencyResolver.resolveProjectDependencies(LifecycleDependencyResolver.java:117) at org.apache.maven.lifecycle.internal.MojoExecutor.ensureDependenciesAreResolved(MojoExecutor.java:258) at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:201) at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153) at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145) at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:84) at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:59) at org.apache.maven.lifecycle.internal.LifecycleStarter.singleThreadedBuild(LifecycleStarter.java:183) at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:161)Digging, the 1.2.15 log4j pulled in by our transitive zk include has "bad metadata" &amp;#8211; see http://stackoverflow.com/questions/9047949/missing-artifact-com-sun-jdmkjmxtoolsjar1-2-1</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9087" opendate="2013-7-30 00:00:00" fixdate="2013-8-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Handlers being blocked during reads</summary>
      <description>I'm having a lot of handlers (90 - 300 aprox) being blocked when reading rows. They are blocked during changedReaderObserver registration.Lars Hofhansl suggests to change the implementation of changedReaderObserver from CopyOnWriteList to ConcurrentHashMap.Here is a stack trace: "IPC Server handler 99 on 60020" daemon prio=10 tid=0x0000000041c84000 nid=0x2244 waiting on condition &amp;#91;0x00007ff51fefd000&amp;#93; java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) parking to wait for &lt;0x00000000c5c13ae8&gt; (a java.util.concurrent.locks.ReentrantLock$NonfairSync) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:156) at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:811) at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:842) at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1178) at java.util.concurrent.locks.ReentrantLock$NonfairSync.lock(ReentrantLock.java:186) at java.util.concurrent.locks.ReentrantLock.lock(ReentrantLock.java:262) at java.util.concurrent.CopyOnWriteArrayList.addIfAbsent(CopyOnWriteArrayList.java:553) at java.util.concurrent.CopyOnWriteArraySet.add(CopyOnWriteArraySet.java:221) at org.apache.hadoop.hbase.regionserver.Store.addChangedReaderObserver(Store.java:1085) at org.apache.hadoop.hbase.regionserver.StoreScanner.&lt;init&gt;(StoreScanner.java:138) at org.apache.hadoop.hbase.regionserver.Store.getScanner(Store.java:2077) at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.&lt;init&gt;(HRegion.java:3755) at org.apache.hadoop.hbase.regionserver.HRegion.instantiateRegionScanner(HRegion.java:1804) at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1796) at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1771) at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:4776) at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:4750) at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:2152) at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3700) at sun.reflect.GeneratedMethodAccessor26.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.apache.hadoop.hbase.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:320) at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1426)</description>
      <version>0.94.7,0.95.1</version>
      <fixedVersion>0.98.0,0.95.2,0.94.11</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="9121" opendate="2013-8-2 00:00:00" fixdate="2013-8-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update HTrace to 2.00 and add new example usage.</summary>
      <description>Update HTrace to 2.00. This adds maven modularization so the client doesn't need all of HTraces dependencies.Also while changing to the new api I added some new very small ammounts of tracing around ZK and HFileReaderv2.</description>
      <version>0.95.1</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.trace.HBaseLocalFileSpanReceiver.java</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.trace.TestHTraceHooks.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.trace.SpanReceiverHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.EnableTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DisableTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RequestContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderV2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.executor.EventHandler.java</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.mttr.IntegrationTestMTTR.java</file>
      <file type="M">hbase-it.pom.xml</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
      <file type="M">hbase-client.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9123" opendate="2013-8-2 00:00:00" fixdate="2013-8-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Filter protobuf generated code from long line warning</summary>
      <description>For big patch, such as the one for namespace, there would be many changes in the protobuf generated code.See example here: https://builds.apache.org/job/PreCommit-HBASE-Build/6569/consoleWe should filter protobuf generated code from long line warning</description>
      <version>None</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  <bug id="9128" opendate="2013-8-5 00:00:00" fixdate="2013-8-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Drop the &amp;#39;.&amp;#39; prefix from names under hbase.rootdir after namespaces goes in</summary>
      <description>Change it so instead of hbase.rootdir looking like this:drwxr-xr-x 5 stack staff 170 Aug 5 14:43 .data-rw-r--r-- 1 stack staff 12 Aug 5 14:43 .hbase.id.crc-rw-r--r-- 1 stack staff 12 Aug 5 14:43 .hbase.version.crcdrwxr-xr-x 3 stack staff 102 Aug 5 14:43 .logsdrwxr-xr-x 2 stack staff 68 Aug 5 14:43 .oldlogsdrwxr-xr-x 3 stack staff 102 Aug 5 14:43 .tmp-rwxrwxrwx 1 stack staff 42 Aug 5 14:43 hbase.id-rwxrwxrwx 1 stack staff 7 Aug 5 14:43 hbase.versionIt looks like this:drwxr-xr-x 5 stack staff 170 Aug 5 14:43 data-rw-r--r-- 1 stack staff 12 Aug 5 14:43 .hbase.id.crc-rw-r--r-- 1 stack staff 12 Aug 5 14:43 .hbase.version.crcdrwxr-xr-x 3 stack staff 102 Aug 5 14:43 logsdrwxr-xr-x 2 stack staff 68 Aug 5 14:43 oldlogsdrwxr-xr-x 3 stack staff 102 Aug 5 14:43 tmp-rwxrwxrwx 1 stack staff 42 Aug 5 14:43 hbase.id-rwxrwxrwx 1 stack staff 7 Aug 5 14:43 hbase.versionAlso removes any ROOT dir if it is present.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestNamespace.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLog.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.migration.TestNamespaceUpgrade.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.migration.NamespaceUpgrade.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="9135" opendate="2013-8-6 00:00:00" fixdate="2013-8-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade hadoop 1 version to 1.2.1 which is stable</summary>
      <description>Here is related discussion:http://search-hadoop.com/m/nA71y1kKHDm1/Hadoop+version+1.2.1+%2528stable%2529+released&amp;subj=Re+ANNOUNCE+Hadoop+version+1+2+1+stable+releasedOlder hadoop 1 artifacts would be phased out.</description>
      <version>None</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9163" opendate="2013-8-8 00:00:00" fixdate="2013-8-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add timeouts to HBaseAdmin because hanging/zombying</summary>
      <description>Let me add timeouts. HBaseAdmin is acting up since namespaces went in. Add timeouts so hopefully fails faster.</description>
      <version>None</version>
      <fixedVersion>0.95.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="9164" opendate="2013-8-8 00:00:00" fixdate="2013-8-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Convert List&lt;? extends Cell&gt; anti pattern to List&lt;Cell&gt; pattern.</summary>
      <description>As described in HBASE-9142, using List&lt;? extends Cell&gt; is an anti pattern that adds unnecessary typing and casting clutter to the code base. It would be best to remove this before we release 0.95.2 or 0.96.</description>
      <version>0.95.1</version>
      <fixedVersion>0.95.2,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.HLogPerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.protobuf.TestReplicationProtobuf.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestWALObserver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverBypass.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.SimpleRegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftUtilities.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MultiRowMutationProcessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.ReplicationProtbufUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.PutSortReducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.PutCombiner.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Put.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Mutation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Increment.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Delete.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Append.java</file>
    </fixedFiles>
  </bug>
  <bug id="9191" opendate="2013-8-12 00:00:00" fixdate="2013-8-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update Loadbalancer method to throw HBaseIOException</summary>
      <description>Some load balancers need a way to communicate failure scenarios so the AM has the opportunity to better handle them.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRegionPlacement.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.LoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BalancerChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="9205" opendate="2013-8-13 00:00:00" fixdate="2013-8-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>fix javadoc warning violation introduced by HBASE-9142</summary>
      <description>I missed a javadoc @link in HBASE-9142.</description>
      <version>0.95.1</version>
      <fixedVersion>0.95.2,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.AggregateImplementation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Increment.java</file>
    </fixedFiles>
  </bug>
  <bug id="9234" opendate="2013-8-15 00:00:00" fixdate="2013-8-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Rebuilding user regions should ignore system tables</summary>
      <description>System tables are already assigned when rebuilding user regions. So we don't need to consider system table regions in rebuilding user regions.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.TableName.java</file>
    </fixedFiles>
  </bug>
</bugrepository>
