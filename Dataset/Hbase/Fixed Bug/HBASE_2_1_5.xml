<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="21462" opendate="2018-11-9 00:00:00" fixdate="2018-7-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add note for CopyTable section explained it does not perform a diff, but a full write from source to target</summary>
      <description>Performance is a common issue with CopyTable is when the key/time range for the data to be copied is large because it basically scans all rows on the specified range, in the source and perform related puts on the source. We should add extra note explaining that on the reference guide, to help users/admins understand when to choose between the different tools/approaches for syncing clusters.</description>
      <version>3.0.0-alpha-1,2.1.5</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="21463" opendate="2018-11-9 00:00:00" fixdate="2018-11-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The checkOnlineRegionsReport can accidentally complete a TRSP</summary>
      <description>On our testing cluster, we observe a race condition:1. A regionServerReport request is built2. A TRSP is scheduled to reopen the region3. The region is closed at RS side4. The OpenRegionProcedure is created5. The regionServerReport generated at step 1 is executed, and we find that the region is opened on the RS, so we update the region state to OPEN.6. The OpenRegionProcedure notices that the region has already been in the OPEN state so gives up and finishes.7. The TRSP finishes.8. The region is recorded as OPEN on the RS but actually not, and can not recover unless we use HBCK2.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMasterFailoverWithProcedures.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestEnableTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.assignment.MockMasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.EnableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.AssignmentManager.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.MasterProcedure.proto</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureExecutor.java</file>
    </fixedFiles>
  </bug>
  <bug id="22249" opendate="2019-4-16 00:00:00" fixdate="2019-4-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Rest Server throws NoClassDefFoundError with Java 11 (run-time)</summary>
      <description>While starting the rest server multiple instances of the followingÂ error can be seen:java.lang.NoClassDefFoundError: javax/activation/DataSourceAfter start-up of the server, while serving requests, following errors can be seen:Caused by: A MultiException has 3 exceptions. They are:1. java.lang.NoClassDefFoundError: Could not initialize class com.sun.xml.bind.v2.model.impl.RuntimeBuiltinLeafInfoImpl2. java.lang.IllegalStateException: Unable to perform operation: create on org.apache.hadoop.hbase.rest.provider.JAXBContextResolver3. java.lang.IllegalStateException: Unable to perform operation: create on org.glassfish.jersey.internal.ContextResolverFactoryAnd the requests failed like this:&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html;charset=ISO-8859-1"/&gt;&lt;title&gt;Error 500 &lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h2&gt;HTTP ERROR: 500&lt;/h2&gt;&lt;p&gt;Problem accessing /. Reason:&lt;pre&gt; Request failed.&lt;/pre&gt;&lt;/p&gt;&lt;hr /&gt;&lt;/body&gt;&lt;/html&gt;</description>
      <version>2.1.5</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.5</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-rest.pom.xml</file>
      <file type="M">hbase-resource-bundle.src.main.resources.META-INF.LICENSE.vm</file>
    </fixedFiles>
  </bug>
  <bug id="22379" opendate="2019-5-8 00:00:00" fixdate="2019-5-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix Markdown for "Voting on Release Candidates" in book</summary>
      <description>The Markdown in the section "Voting on Release Candidates" of the HBase book seems to be broken. It looks like that there should be a quote, which isn't displayed correctly. Same is true for the formatting of the Maven RAT command.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,1.4.10,2.3.0,2.0.6,2.1.5,1.3.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="22380" opendate="2019-5-8 00:00:00" fixdate="2019-10-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>break circle replication when doing bulkload</summary>
      <description>when enabled master-master bulkload replication, HFiles will be replicated circularly between two clusters</description>
      <version>3.0.0-alpha-1,1.5.0,2.2.0,1.4.10,2.0.5,2.3.0,2.1.5,1.3.5</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.1.7,2.2.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.BulkLoadHFilesTool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.HFileReplicator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SecureBulkLoadManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.AsyncClusterConnectionImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.AsyncClusterConnection.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.WAL.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.Client.proto</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.tool.TestBulkLoadHFilesSplitRecovery.java</file>
    </fixedFiles>
  </bug>
  <bug id="22384" opendate="2019-5-8 00:00:00" fixdate="2019-5-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Formatting issues in administration section of book</summary>
      <description>The administration section in the book (64.3.2. Administration) has some formatting issues. Due to that issues the list count is not accurate, as well as the indentation of some code snippets.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,1.4.10,2.3.0,2.0.6,2.1.5,1.3.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.security.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="2242" opendate="2010-2-19 00:00:00" fixdate="2010-2-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[EC2] Downgrade JDK to 6u17 and rebuild AMIs</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.4,0.90.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.contrib.ec2.bin.hbase-ec2-env.sh</file>
    </fixedFiles>
  </bug>
  <bug id="22471" opendate="2019-5-26 00:00:00" fixdate="2019-5-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Our nightly jobs for master and branch-2 are still using hadoop-2.7.1 in integration test</summary>
      <description>We use ls to get the hadoop 2 jars, so maybe the problem is that the 2.7.1 jars are already there for a long time. We need to clean the workspace.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  <bug id="22472" opendate="2019-5-26 00:00:00" fixdate="2019-5-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The newly split TestReplicationStatus* tests are flaky</summary>
      <description>They are introduced by HBASE-22455, from the original TestReplicationStatus tests. Need to dig more.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationStatusSourceStartedTargetStoppedWithRecovery.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationStatusSourceStartedTargetStoppedNoOps.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationStatusSourceStartedTargetStoppedNewOp.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationStatusBothNormalAndRecoveryLagging.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationStatusAfterLagging.java</file>
    </fixedFiles>
  </bug>
  <bug id="22474" opendate="2019-5-26 00:00:00" fixdate="2019-5-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add --mvn-custom-repo parameter to yetus calls</summary>
      <description>PreCommit validation from yetus uses a shared .m2 repository. By addingÂ --mvn-custom-repo and --jenkins paramters yetus will use a custom .m2 directory for executions for PR validations.https://yetus.apache.org/documentation/0.9.0/precommit-buildtools/</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,1.4.10,2.0.6,2.1.5,1.3.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile.GitHub</file>
    </fixedFiles>
  </bug>
  <bug id="22539" opendate="2019-6-4 00:00:00" fixdate="2019-8-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>WAL corruption due to early DBBs re-use when Durability.ASYNC_WAL is used</summary>
      <description>SummaryWe had been chasing a WAL corruption issue reported on one of our customers deployments running release 2.1.1 (CDH 6.1.0). After providing a custom modified jar with the extra sanity checks implemented byÂ HBASE-21401 applied on some code points, plus additional debugging messages, we believe it is related to DirectByteBuffer usage, and Unsafe copy from offheap memory to on-heap array triggered here, such as when writing into a non ByteBufferWriter type, as done here.More details on the following comment.Â </description>
      <version>2.2.0,2.0.5,2.1.5</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.0.6,2.2.1,2.1.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestFSHLog.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestAsyncFSWAL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.AbstractTestWALReplay.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSWALEntry.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.ServerCall.java</file>
    </fixedFiles>
  </bug>
  <bug id="22547" opendate="2019-6-6 00:00:00" fixdate="2019-6-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Align the config keys and add document for offheap read in HBase Book.</summary>
      <description>We found many useful tips about offheap reading when developing &amp; testing HBASE-21879, will prepare a doc for this.Some of them are in google doc now : https://docs.google.com/document/d/1xSy9axGxafoH-Qc17zbD2Bd--rWjjI00xTWQZ8ZwI_E/edit?usp=sharing</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
      <file type="M">src.main.asciidoc.book.adoc</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mob.TestMobWithByteBuffAllocator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.io.TestByteBuffAllocator.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.ByteBuffAllocator.java</file>
    </fixedFiles>
  </bug>
  <bug id="22549" opendate="2019-6-6 00:00:00" fixdate="2019-6-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document how to re-run github PR checks</summary>
      <description>Our psomogyi has a trick for re-running github PR checks that is not force-push of original patch. Lets get it into the refguide.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="2255" opendate="2010-2-23 00:00:00" fixdate="2010-3-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>take trunk back to hadoop 0.20</summary>
      <description>revert the dependency on hadoop 0.21, back to hadoop 0.20 (we hardly knew ye)</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLog.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreReconstruction.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.RowCounter.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.Import.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.Export.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.CopyTable.java</file>
      <file type="M">core.pom.xml</file>
      <file type="M">contrib.transactional.pom.xml</file>
      <file type="M">contrib.stargate.pom.xml</file>
      <file type="M">contrib.mdc.replication.pom.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="22554" opendate="2019-6-9 00:00:00" fixdate="2019-6-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade to surefire 2.22.2</summary>
      <description>Surefire 2.22.2Â has a fix for corrupted output:Â SUREFIRE-1614Â </description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.2.0,2.3.0,2.0.6,2.1.6,1.3.6,1.4.11</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="22559" opendate="2019-6-10 00:00:00" fixdate="2019-6-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[RPC] set guard against CALL_QUEUE_HANDLER_FACTOR_CONF_KEY</summary>
      <description>CALL_QUEUE_HANDLER_FACTOR_CONF_KEY is hbase.ipc.server.callqueue.handler.factor, a float number, which is supposed between &amp;#91;0.0, 1.0&amp;#93;. If it is greater than 1, for example, 2.0, the call queues and handlers will be expanded twice:float callQueuesHandlersFactor = this.conf.getFloat(CALL_QUEUE_HANDLER_FACTOR_CONF_KEY, 0);this.numCallQueues = computeNumCallQueues(handlerCount, callQueuesHandlersFactor);this.handlerCount = Math.max(handlerCount, this.numCallQueues);protected int computeNumCallQueues(final int handlerCount, final float callQueuesHandlersFactor) { return Math.max(1, (int) Math.round(handlerCount * callQueuesHandlersFactor));}We already have hbase.regionserver.handler.count set, what mentioned above looks tricky.The purpose of this conf is to control how many handlers can share one call queue, expanding the number of handlers (a kind of side-effects) is not included, from my understanding.</description>
      <version>None</version>
      <fixedVersion>1.5.0,2.3.0,2.2.1,1.4.11</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcExecutor.java</file>
    </fixedFiles>
  </bug>
  <bug id="22563" opendate="2019-6-10 00:00:00" fixdate="2019-6-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reduce retained jobs for Jenkins pipelines</summary>
      <description>Our jobs are taking up lots of space. Try to help out infra quickly by reducing the number of old builds we keep.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.2.0,2.3.0,2.0.6,2.1.6,1.3.6,1.4.11</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile.GitHub</file>
      <file type="M">dev-support.Jenkinsfile</file>
      <file type="M">dev-support.flaky-tests.run-flaky-tests.Jenkinsfile</file>
      <file type="M">dev-support.flaky-tests.flaky-reporting.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  <bug id="22612" opendate="2019-6-20 00:00:00" fixdate="2019-6-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Address the final overview reviewing comments of HBASE-21879</summary>
      <description>I've created a big PR(https://github.com/apache/hbase/pull/320) for HBASE-21879, and Apache9 left some minor issues. Will address those comment here.If others have some comment about that PR, will also address in this PR.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.nio.RefCnt.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.ByteBufferListOutputStream.java</file>
    </fixedFiles>
  </bug>
  <bug id="22617" opendate="2019-6-22 00:00:00" fixdate="2019-6-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Recovered WAL directories not getting cleaned up</summary>
      <description>WhileÂ colocating the recovered edits directory with hbase.wal.dir, BASE_NAMESPACE_DIR got missed. This results in recovered edits being put in a separate directory rather than the default region directory even if the hbase.wal.dir is not overridden. Eg. if data is stored in /hbase/data/namespace/table1, recovered edits are put inÂ  /hbase/namespace/table1. This also messes up the regular cleaner chores which never operate on this new directory and these directories will never be deleted, even for split parents or dropped tables. We should change the default back to have the base namespace directory in path.</description>
      <version>1.3.3,2.2.0,1.4.8,2.1.1,1.4.9,2.1.2,1.4.10,2.1.3,1.3.4,2.1.4,2.1.5,1.3.5</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.0.6,2.2.1,2.1.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRecoveredEdits.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestTruncateTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestCreateTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestHFileArchiving.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALSplitUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DisableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.SplitTableRegionProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.RegionStateStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.MergeTableRegionsProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.GCRegionProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.HFileArchiver.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.CommonFSUtils.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.util.BackupUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="2265" opendate="2010-2-25 00:00:00" fixdate="2010-7-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HFile and Memstore should maintain minimum and maximum timestamps</summary>
      <description>In order to fix HBASE-1485 and HBASE-29, it would be very helpful to have HFile and Memstore track their maximum and minimum timestamps. This has the following nice properties: for a straight Get, if an entry has been already been found with timestamp X, and X &gt;= HFile.maxTimestamp, the HFile doesn't need to be checked. Thus, the current fast behavior of get can be maintained for those who use strictly increasing timestamps, but "correct" behavior for those who sometimes write out-of-order. for a scan, the "latest timestamp" of the storage can be used to decide which cell wins, even if the timestamp of the cells is equal. In essence, rather than comparing timestamps, instead you are able to compare tuples of (row timestamp, storage.max_timestamp) in general, min_timestamp(storage A) &gt;= max_timestamp(storage B) if storage A was flushed after storage B.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreFile.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestStore.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestMemStore.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.MemStore.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.KeyValueHeap.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="22656" opendate="2019-7-4 00:00:00" fixdate="2019-7-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[Metrics] Tabe metrics &amp;#39;BatchPut&amp;#39; and &amp;#39;BatchDelete&amp;#39; are never updated</summary>
      <description>public void updatePutBatch(TableName tn, long t) { if (tableMetrics != null &amp;&amp; tn != null) { tableMetrics.updatePut(tn, t); // Here should use updatePutBatch } ... } public void updateDeleteBatch(TableName tn, long t) { if (tableMetrics != null &amp;&amp; tn != null) { tableMetrics.updateDelete(tn, t); // Here should use updateDeleteBatch } ... }</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,2.2.1,2.1.6,1.4.11</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="22714" opendate="2019-7-19 00:00:00" fixdate="2019-7-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>BuffferedMutatorParams opertationTimeOut() is misspelt</summary>
      <description>The method `opertationTimeOut()` in `BuffferedMutatorParams` is misspelt.Â </description>
      <version>2.1.5</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.BufferedMutatorParams.java</file>
    </fixedFiles>
  </bug>
  <bug id="22842" opendate="2019-8-13 00:00:00" fixdate="2019-8-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Tmp directory should not be deleted when master restart used for user scan snapshot feature</summary>
      <description>When create table,Â table directories are firstly created in tmp directory and then move to data directory. So HDFS ACLs are set at the following tmp directories used for ACLs inherited:{hbase-rootdir}/.tmp/data{hbase-rootdir}/.tmp/data/{namespace}{hbase-rootdir}/.tmp/data/{namespace}/{table}When master restart, it will delete tmp directory and this will break this feature.Â </description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestSnapshotScannerHDFSAclController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
    </fixedFiles>
  </bug>
  <bug id="22911" opendate="2019-8-24 00:00:00" fixdate="2019-8-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>fewer concurrent github PR builds</summary>
      <description>we've been regularly getting 4-5 concurrent builds of PRs.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,2.2.1,2.1.6,1.3.6,1.4.11,2.0.7</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile.GitHub</file>
    </fixedFiles>
  </bug>
  <bug id="22913" opendate="2019-8-24 00:00:00" fixdate="2019-8-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use Hadoop label for nightly builds</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,2.2.1,2.1.6,1.3.6,1.4.11</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  <bug id="23055" opendate="2019-9-19 00:00:00" fixdate="2019-6-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Alter hbase:meta</summary>
      <description>hbase:meta is currently hardcoded. Its schema cannot be change.This issue is about allowing edits to hbase:meta schema. It will allow our being able to set encodings such as the block-with-indexes which will help quell CPU usage on host carrying hbase:meta. A dynamic hbase:meta is first step on road to being able to split meta.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestFSTableDescriptorForceCreation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.assignment.MockMasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.RestoreSnapshotProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure.java</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.describe.rb</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestZKAsyncRegistry.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ZKDataMigrator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotManifest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MirroringTableStateManager.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.CommonFSUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRegistry.java</file>
      <file type="M">hbase-zookeeper.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">hbase-zookeeper.src.main.java.org.apache.hadoop.hbase.zookeeper.MetaTableLocator.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestFSTableDescriptors.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestHBaseMetaEdit.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRollingNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestGetClosestAtOrBefore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestClusterId.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMetaWithReplicas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTableAdminApi3.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTableAdminApi2.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncAccessControlAdminApi.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSTableDescriptors.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.TableDescriptors.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.RejectReplicationRequestStateChecker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.zksyncer.MetaLocationSyncer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.ModifyPeerProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.AbstractPeerProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.EnableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DisableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.RegionStateStore.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZNodePaths.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MetaTableAccessor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ZKAsyncRegistry.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.AsyncMetaTableAccessor.java</file>
    </fixedFiles>
  </bug>
  <bug id="23172" opendate="2019-10-14 00:00:00" fixdate="2019-10-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase Canary region success count metrics reflect column family successes, not region successes</summary>
      <description>HBase Canary reads once per column family per region. The current "region success count" should actually be "column family success count," which means we need another metric that actually reflects region success count. Additionally, the region read and write latencies only store the latencies of the last column family of the region read. Instead of a map of regions to a single latency value and success value, we should map each region to a list of such values.</description>
      <version>3.0.0-alpha-1,1.3.0,1.4.0,1.5.0,2.0.0,2.1.5,2.2.1</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,1.6.0,2.1.8,2.2.3</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.tool.TestCanaryTool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.CanaryTool.java</file>
    </fixedFiles>
  </bug>
  <bug id="23664" opendate="2020-1-8 00:00:00" fixdate="2020-1-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade JUnit to 4.13</summary>
      <description>New JUnit released a week ago. Let's give it a spin.https://github.com/junit-team/junit4/blob/master/doc/ReleaseNotes4.13.md</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="2367" opendate="2010-3-23 00:00:00" fixdate="2010-4-23 01:00:00" resolution="Won&amp;#39;t Fix">
    <buginformation>
      <summary>[PE] add an option to toggle writeToWAL false on puts</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
    </fixedFiles>
  </bug>
</bugrepository>
