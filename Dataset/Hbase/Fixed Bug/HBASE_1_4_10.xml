<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="21688" opendate="2019-1-8 00:00:00" fixdate="2019-4-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Address WAL filesystem issues</summary>
      <description>Scan and fix code base to use new way of instantiating WAL File System. https://issues.apache.org/jira/browse/HBASE-21457?focusedCommentId=16734688&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16734688</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.0.6,2.1.5</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestWALEntryStream.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.AbstractTestDLS.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.fs.TestBlockReorderMultiBlocks.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.WALEntryStream.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.WALLink.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestLoadAndVerify.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
      <file type="M">hbase-backup.src.test.java.org.apache.hadoop.hbase.backup.master.TestBackupLogCleaner.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.impl.IncrementalBackupManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.AbstractFSWALProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterWalManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="21884" opendate="2019-2-13 00:00:00" fixdate="2019-2-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix box/unbox findbugs warning in secure bulk load</summary>
      <description>Reason TestsFindBugs module:hbase-serverBoxed value is unboxed and then immediately reboxed in org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint.incrementUgiReference(UserGroupInformation) At SecureBulkLoadEndpoint.java:then immediately reboxed in org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint.incrementUgiReference(UserGroupInformation) At SecureBulkLoadEndpoint.java:[line 268]Looking at branch-2 and master I suspect we're doing the same wasteful operation but findbugs can't see it through the lambda definition.</description>
      <version>3.0.0-alpha-1,1.5.0,2.2.0,2.1.1,2.0.3,2.1.2,2.0.4,1.4.10,1.3.4,1.2.11,2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,1.4.10,2.0.5,1.3.4,1.2.11,2.3.0,2.1.4</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SecureBulkLoadManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="21889" opendate="2019-2-13 00:00:00" fixdate="2019-2-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use thrift 0.12.0 when build thrift by compile-thrift profile</summary>
      <description>Build command.mvn compile -Pcompile-thrift</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.0.5,2.3.0,2.1.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="22380" opendate="2019-5-8 00:00:00" fixdate="2019-10-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>break circle replication when doing bulkload</summary>
      <description>when enabled master-master bulkload replication, HFiles will be replicated circularly between two clusters</description>
      <version>3.0.0-alpha-1,1.5.0,2.2.0,1.4.10,2.0.5,2.3.0,2.1.5,1.3.5</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.1.7,2.2.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.BulkLoadHFilesTool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.HFileReplicator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SecureBulkLoadManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.AsyncClusterConnectionImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.AsyncClusterConnection.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.WAL.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.Client.proto</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.tool.TestBulkLoadHFilesSplitRecovery.java</file>
    </fixedFiles>
  </bug>
  <bug id="22384" opendate="2019-5-8 00:00:00" fixdate="2019-5-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Formatting issues in administration section of book</summary>
      <description>The administration section in the book (64.3.2. Administration) has some formatting issues. Due to that issues the list count is not accurate, as well as the indentation of some code snippets.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,1.4.10,2.3.0,2.0.6,2.1.5,1.3.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.security.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="22399" opendate="2019-5-12 00:00:00" fixdate="2019-5-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change default hadoop-two.version to 2.8.x and remove the 2.7.x hadoop checks</summary>
      <description>Our nightly is failing so let's do this first, and for the ref guide changes can be done in another sub task.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestReversedScannerCallable.java</file>
      <file type="M">dev-support.Jenkinsfile</file>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  <bug id="22400" opendate="2019-5-12 00:00:00" fixdate="2019-5-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove the adapter code in async fs implementation for hadoop-2.7.x</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputSaslHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputHelper.java</file>
    </fixedFiles>
  </bug>
  <bug id="22518" opendate="2019-6-1 00:00:00" fixdate="2019-6-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>yetus personality is treating branch-1.4 like earlier branches for hadoopcheck</summary>
      <description>seen on HBASE-22509</description>
      <version>1.4.10</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,1.4.10,2.3.0,2.0.6,1.3.5,2.1.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  <bug id="22585" opendate="2019-6-14 00:00:00" fixdate="2019-6-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Ensure javax.annotation doesn&amp;#39;t get include in shaded artifacts when built with Java 11</summary>
      <description>Master &amp; branch-2 build fails on Java 11. Complaints about the hbase-shaded-check-invariants. Will paste the stacktrace if needed in the comments. </description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shaded.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-client.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="22617" opendate="2019-6-22 00:00:00" fixdate="2019-6-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Recovered WAL directories not getting cleaned up</summary>
      <description>While colocating the recovered edits directory with hbase.wal.dir, BASE_NAMESPACE_DIR got missed. This results in recovered edits being put in a separate directory rather than the default region directory even if the hbase.wal.dir is not overridden. Eg. if data is stored in /hbase/data/namespace/table1, recovered edits are put in  /hbase/namespace/table1. This also messes up the regular cleaner chores which never operate on this new directory and these directories will never be deleted, even for split parents or dropped tables. We should change the default back to have the base namespace directory in path.</description>
      <version>1.3.3,2.2.0,1.4.8,2.1.1,1.4.9,2.1.2,1.4.10,2.1.3,1.3.4,2.1.4,2.1.5,1.3.5</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.0.6,2.2.1,2.1.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRecoveredEdits.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestTruncateTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestCreateTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestHFileArchiving.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALSplitUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DisableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.SplitTableRegionProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.RegionStateStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.MergeTableRegionsProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.GCRegionProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.HFileArchiver.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.CommonFSUtils.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.util.BackupUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="22628" opendate="2019-6-25 00:00:00" fixdate="2019-7-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document the custom WAL directory (hbase.wal.dir) usage</summary>
      <description>Custom WAL directory usage must be documented, otherwise it may lead to inconsistent data during migrating to new WAL dir path. You can consider below scenario while migrating to custom WAL directory. Setup HBase cluster with the default setting (all WAL files are under the root directory ie. /hbase/WALs). Create table 't1' and insert few records Flush meta table (so that table region entries persist in FS) Forcibly kill HBase processes (HM &amp; RS). Configure the hbase.wal.dir to outside the root dir (say /hbaseWAL) Start the HBase servers Scan 't1'Ideally HMaster should submit split task of old RS(s) WAL files (created under /hbase/WALs) and old data should be replayed. But currently, during HM startup we populate the previous dead servers from the current WAL dir ( hbase.wal.dir -&gt; /hbaseWAL). Since WAL dir path is new, so you need to copy RegionServer WAL directories manualy from old WAL dir to new path. </description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="2266" opendate="2010-2-25 00:00:00" fixdate="2010-2-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[stargate] missing MiniDFSCluster dependency</summary>
      <description>This is the problem: java.lang.NoClassDefFoundError: org/apache/hadoop/net/StaticMapping at org.apache.hadoop.hdfs.MiniDFSCluster.&lt;init&gt;(MiniDFSCluster.java:287)Some dependency is missing from the sub project.% mvn -DskipTests clean install...&amp;#91;INFO&amp;#93; BUILD SUCCESSFUL% mvn -Dtest=Test00MiniCluster test...Tests run: 4, Failures: 0, Errors: 4, Skipped: 0From the test log file:testDFSMiniCluster(org.apache.hadoop.hbase.stargate.Test00MiniCluster) Time elapsed: 1.263 sec &lt;&lt;&lt; ERROR!java.lang.NoClassDefFoundError: org/apache/hadoop/net/StaticMapping at org.apache.hadoop.hdfs.MiniDFSCluster.&lt;init&gt;(MiniDFSCluster.java:287) at org.apache.hadoop.hbase.stargate.MiniClusterTestCase.startDFS(MiniClusterTestCase.java:81) at org.apache.hadoop.hbase.stargate.MiniClusterTestCase.startMiniCluster(MiniClusterTestCase.java:187) at org.apache.hadoop.hbase.stargate.MiniClusterTestCase.setUp(MiniClusterTestCase.java:225) at junit.framework.TestCase.runBare(TestCase.java:132)</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">contrib.stargate.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="22664" opendate="2019-7-8 00:00:00" fixdate="2019-7-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move protobuf stuff in hbase-rsgroup to hbase-protocol-shaded</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-rsgroup.src.main.protobuf.RSGroupAdmin.proto</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupProtobufUtil.java</file>
      <file type="M">hbase-rsgroup.src.test.java.org.apache.hadoop.hbase.rsgroup.VerifyingRSGroupAdminClient.java</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupInfoManagerImpl.java</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupAdminEndpoint.java</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupAdminClient.java</file>
      <file type="M">hbase-rsgroup.pom.xml</file>
      <file type="M">hbase-protocol.src.main.protobuf.RSGroupAdmin.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.RSGroupAdmin.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.RSGroup.proto</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="2273" opendate="2010-2-27 00:00:00" fixdate="2010-2-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[stargate] export metrics via Hadoop metrics, JMX, and ZooKeeper</summary>
      <description>Export metrics via Hadoop metrics, JMX, and ZooKeeper.At the moment, just "requests": requests per second. Put up ephemeral znodes in Zookeeper which include requests metric to facilitate monitoring and load balancing.</description>
      <version>None</version>
      <fixedVersion>0.20.4,0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">contrib.stargate.src.test.java.org.apache.hadoop.hbase.stargate.auth.TestZooKeeperAuthenticator.java</file>
      <file type="M">contrib.stargate.src.main.java.org.apache.hadoop.hbase.stargate.VersionResource.java</file>
      <file type="M">contrib.stargate.src.main.java.org.apache.hadoop.hbase.stargate.TableResource.java</file>
      <file type="M">contrib.stargate.src.main.java.org.apache.hadoop.hbase.stargate.StorageClusterVersionResource.java</file>
      <file type="M">contrib.stargate.src.main.java.org.apache.hadoop.hbase.stargate.StorageClusterStatusResource.java</file>
      <file type="M">contrib.stargate.src.main.java.org.apache.hadoop.hbase.stargate.SchemaResource.java</file>
      <file type="M">contrib.stargate.src.main.java.org.apache.hadoop.hbase.stargate.ScannerResource.java</file>
      <file type="M">contrib.stargate.src.main.java.org.apache.hadoop.hbase.stargate.ScannerInstanceResource.java</file>
      <file type="M">contrib.stargate.src.main.java.org.apache.hadoop.hbase.stargate.RowResource.java</file>
      <file type="M">contrib.stargate.src.main.java.org.apache.hadoop.hbase.stargate.RootResource.java</file>
      <file type="M">contrib.stargate.src.main.java.org.apache.hadoop.hbase.stargate.RESTServlet.java</file>
      <file type="M">contrib.stargate.src.main.java.org.apache.hadoop.hbase.stargate.RegionsResource.java</file>
      <file type="M">contrib.stargate.src.main.java.org.apache.hadoop.hbase.stargate.Main.java</file>
      <file type="M">contrib.stargate.src.main.java.org.apache.hadoop.hbase.stargate.Constants.java</file>
      <file type="M">contrib.stargate.src.main.java.org.apache.hadoop.hbase.stargate.auth.ZooKeeperAuthenticator.java</file>
      <file type="M">contrib.stargate.src.main.java.org.apache.hadoop.hbase.stargate.auth.JDBCAuthenticator.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="22785" opendate="2019-8-3 00:00:00" fixdate="2019-8-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reduce number of Checkstyle issues in client exceptions</summary>
      <description>The exceptions in the client module have some Checkstyle issues. Also, the Javadocs should be extended and enhanced.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,2.0.6,2.2.1,2.1.6,1.3.6,1.4.11</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ZooKeeperConnectionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.YouAreDeadException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.UnknownScannerException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.UnknownRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableNotFoundException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableNotEnabledException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableNotDisabledException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableInfoMissingException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableExistsException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.NotServingRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.DroppedSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.DoNotRetryIOException.java</file>
    </fixedFiles>
  </bug>
  <bug id="22786" opendate="2019-8-3 00:00:00" fixdate="2019-8-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix Checkstyle issues in tests of hbase-client</summary>
      <description>The hbase-client module has some Checkstyle issues in its tests, which should get fixed.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,2.0.6,2.2.1,2.1.6,1.3.6,1.4.11</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.util.BuilderStyleTest.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.TestHTableDescriptor.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.TestHColumnDescriptor.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.shaded.protobuf.TestProtobufUtil.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.quotas.TestQuotaSettingsFactory.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.quotas.TestQuotaFilter.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.ipc.TestHBaseRpcControllerImpl.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.ipc.TestCellBlockBuilder.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.filter.TestLongComparator.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.exceptions.TestClientExceptionsUtil.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestTableDescriptorBuilder.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestScan.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestOperation.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestMetricsConnection.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestGet.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestColumnFamilyDescriptorBuilder.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestClientExponentialBackoff.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestAttributes.java</file>
    </fixedFiles>
  </bug>
  <bug id="22787" opendate="2019-8-3 00:00:00" fixdate="2019-8-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up of tests in hbase-zookeeper</summary>
      <description>The tests in the hbase-zookeeper module can be cleaned up in several ways, starting with simplifying some of the assertions and reduce the visibility of some fields, methods and helper classes.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.0.6,2.2.1,2.1.6</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-zookeeper.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKUtilNoServer.java</file>
      <file type="M">hbase-zookeeper.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKUtil.java</file>
      <file type="M">hbase-zookeeper.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKNodeTracker.java</file>
      <file type="M">hbase-zookeeper.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKMulti.java</file>
      <file type="M">hbase-zookeeper.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKMainServer.java</file>
      <file type="M">hbase-zookeeper.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKLeaderManager.java</file>
      <file type="M">hbase-zookeeper.src.test.java.org.apache.hadoop.hbase.zookeeper.TestRecoverableZooKeeper.java</file>
      <file type="M">hbase-zookeeper.src.test.java.org.apache.hadoop.hbase.zookeeper.TestReadOnlyZKClient.java</file>
      <file type="M">hbase-zookeeper.src.test.java.org.apache.hadoop.hbase.zookeeper.TestHQuorumPeer.java</file>
      <file type="M">hbase-zookeeper.src.test.java.org.apache.hadoop.hbase.HBaseZKTestingUtility.java</file>
    </fixedFiles>
  </bug>
  <bug id="22837" opendate="2019-8-12 00:00:00" fixdate="2019-8-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move "Custom WAL Directory" section from "Bulk Loading" to "Write Ahead Log (WAL)" chapter</summary>
      <description>Currently, explanation about Custom WAL Directory configuration is a sub-topic of Bulk Loading, chapter, yet this subject has not much relation with bulk loading at all. It should rather be moved to a sub-section of the Write Ahead Log (WAL) chapter.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="22872" opendate="2019-8-17 00:00:00" fixdate="2019-8-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Don&amp;#39;t create normalization plan unnecesarily when split and merge both are disabled</summary>
      <description>We should not proceed futher in normalization plan creation if split and merge both are disabled on a table.</description>
      <version>1.4.10</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.2.1,1.3.6,1.4.11,2.1.7</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.normalizer.SimpleRegionNormalizer.java</file>
    </fixedFiles>
  </bug>
  <bug id="22873" opendate="2019-8-17 00:00:00" fixdate="2019-8-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Typo in block caching docs</summary>
      <description>To turn off block cache for a scan, setCacheBlocks should be used, but the hbase book says "setCaching", which is not relevant.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="22875" opendate="2019-8-18 00:00:00" fixdate="2019-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestShell and TestAdminShell2 are broken</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.list.table.snapshots.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.list.snapshots.rb</file>
    </fixedFiles>
  </bug>
  <bug id="22881" opendate="2019-8-19 00:00:00" fixdate="2019-10-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix non-daemon threads in hbase server implementation</summary>
      <description>"pool-8-thread-3" #7252 prio=5 os_prio=0 tid=0x00007f91040044c0 nid=0xd71e waiting on condition &amp;#91;0x00007f8f4d209000&amp;#93; java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) parking to wait for &lt;0x00000005c0e49ed0&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Locked ownable synchronizers: None"pool-8-thread-2" #7251 prio=5 os_prio=0 tid=0x00007f910c010be0 nid=0xd71d waiting on condition &amp;#91;0x00007f8f4daab000&amp;#93; java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) parking to wait for &lt;0x00000005c0e49ed0&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Locked ownable synchronizers: None"pool-8-thread-1" #7250 prio=5 os_prio=0 tid=0x00007f91000019d0 nid=0xd71c waiting on condition &amp;#91;0x00007f8f4da6a000&amp;#93; java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) parking to wait for &lt;0x00000005c0e49ed0&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Locked ownable synchronizers: None"pool-5-thread-3" #7248 prio=5 os_prio=0 tid=0x00007f9238005ad0 nid=0xd71a waiting on condition &amp;#91;0x00007f8f4cb65000&amp;#93; java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) parking to wait for &lt;0x00000005c0ec51e0&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.1,2.1.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.IncrementCoalescer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.procedure.SimpleRSProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ModifyRegionUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.HFileContentValidator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.BulkLoadHFilesTool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotManifest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.HFileReplicator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.snapshot.RegionServerSnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.flush.RegionServerFlushTableProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterMobCompactionThread.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.SplitTableRegionProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.HFileArchiver.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Threads.java</file>
    </fixedFiles>
  </bug>
  <bug id="22891" opendate="2019-8-22 00:00:00" fixdate="2019-8-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use HBaseQA in HBase-PreCommit-GitHub-PR job</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,2.2.1,2.1.6,1.3.6,1.4.11,2.0.7</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile.GitHub</file>
    </fixedFiles>
  </bug>
  <bug id="22911" opendate="2019-8-24 00:00:00" fixdate="2019-8-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>fewer concurrent github PR builds</summary>
      <description>we've been regularly getting 4-5 concurrent builds of PRs.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,2.2.1,2.1.6,1.3.6,1.4.11,2.0.7</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile.GitHub</file>
    </fixedFiles>
  </bug>
  <bug id="22913" opendate="2019-8-24 00:00:00" fixdate="2019-8-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use Hadoop label for nightly builds</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,2.2.1,2.1.6,1.3.6,1.4.11</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  <bug id="22975" opendate="2019-9-5 00:00:00" fixdate="2019-9-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add read and write QPS metrics at server level and table level</summary>
      <description>Use HBase‘s existing class DropwizardMeter to collect read and write QPS. The collected location is the same as metrics readRequestsCount and writeRequestsCount.</description>
      <version>2.2.0,1.4.10</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,1.4.11,2.1.7,2.2.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerTableMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsTableLatenciesImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="23066" opendate="2019-9-24 00:00:00" fixdate="2019-12-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create a config that forces to cache blocks on compaction</summary>
      <description>In cases where users care a lot about read performance for tables that are small enough to fit into a cache (or the cache is large enough), prefetchOnOpen can be enabled to make the entire table available in cache after the initial region opening is completed. Any new data can also be guaranteed to be in cache with the cacheBlocksOnWrite setting.However, the missing piece is when all blocks are evicted after a compaction. We found very poor performance after compactions for tables under heavy read load and a slower backing filesystem (S3). After a compaction the prefetching threads need to compete with threads servicing read requests and get constantly blocked as a result. This is a proposal to introduce a new cache configuration option that would cache blocks on write during compaction for any column family that has prefetch enabled. This would virtually guarantee all blocks are kept in cache after the initial prefetch on open is completed allowing for guaranteed steady read performance despite a slow backing file system.</description>
      <version>1.4.10</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestCacheOnWrite.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
    </fixedFiles>
  </bug>
  <bug id="23069" opendate="2019-9-24 00:00:00" fixdate="2019-1-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>periodic dependency bump for Sep 2019</summary>
      <description>we should do a pass to see if there are any dependencies we can bump. (also follow-on we should automate this check)</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="2307" opendate="2010-3-10 00:00:00" fixdate="2010-3-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase-2295 changed hregion size, testheapsize broke... fix it.</summary>
      <description>Both trunk and branch are broke at mo.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="23207" opendate="2019-10-23 00:00:00" fixdate="2019-10-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Log a region open journal</summary>
      <description>Like HBASE-22828, but for region opening.Also, tweak the calls to enableStatusJournal to pass through 'true' as parameter to include the current status in the journal, for slightly more context.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,1.6.0,1.4.12,1.3.7,2.1.8,2.2.3</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="2327" opendate="2010-3-15 00:00:00" fixdate="2010-3-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[EC2] Allocate elastic IP addresses for ZK and master nodes</summary>
      <description>Amazon EC2 supports Elastic IP Addresses to implement the effect of having a static IP address for public servers running on EC2. Up on hbase-users@ there was some recent discussion, confirmed, that when an EC2 instance queries the external DNS name of an elastic IP address, EC2 DNS returns the internal IP address of the instance to which the elastic IP address is bound, so it is safe to use elastic IPs for the ZK and master nodes. We gain the ability to do transparent replacement of one instance, e.g. failed, with another without incurring any additional cost. Update launch-hbase-zookeeper and launch-hbase-master to allocate elastic IPs: $ ec2-allocate-address ADDRESS 1.1.1.1and then assign the elastic IP address to the appropriate instance(s):$ ec2-associate-address -i i-11111111 1.1.1.1ADDRESS 1.1.1.1 i-11111111and then get the external DNS name to use when performing substitutions on master and slave configs:$ ec2-describe-instances i-11111111 | egrep ^INSTANCE | cut -f4ec2-1-1-1-1.compute-1.amazonaws.comWhen shutting down the cluster, just release the elastic IPs after terminating the instances:ec2-release-address 1.1.1.1...NOTE: AWS accounts default to a limit of 5 Elastic IP addresses but most will run with 1 master and 3 or 1 ZK instances. And, the ZK ensemble can be shared. A follow up issue can address making scripts to launch replacements for failed instances transparently.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">contrib.ec2.bin.terminate-hbase-cluster</file>
      <file type="M">contrib.ec2.bin.launch-hbase-zookeeper</file>
      <file type="M">contrib.ec2.bin.launch-hbase-slaves</file>
      <file type="M">contrib.ec2.bin.launch-hbase-master</file>
      <file type="M">contrib.ec2.bin.image.create-hbase-image-remote</file>
      <file type="M">contrib.ec2.bin.hbase-ec2-env.sh</file>
      <file type="M">contrib.ec2.bin.create-hbase-image</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="23829" opendate="2020-2-11 00:00:00" fixdate="2020-4-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Get `-PrunSmallTests` passing on JDK11</summary>
      <description>Start with the small tests, shaking out issues identified by the harness. So far it seems like -Dhadoop.profile=3.0 and -Dhadoop-three.version=3.3.0-SNAPSHOT maybe be required.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-with-hadoop-check-invariants.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-check-invariants.pom.xml</file>
      <file type="M">hbase-http.src.test.java.org.apache.hadoop.hbase.http.log.TestLogLevel.java</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestFutureUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="24455" opendate="2020-5-28 00:00:00" fixdate="2020-6-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Correct the doc of "On the number of column families"</summary>
      <description>Currently all the compaction is store basis yet, so correct the content.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,1.7.0,2.2.6</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.schema.design.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="24456" opendate="2020-5-28 00:00:00" fixdate="2020-6-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Immutable Scan as unmodifiable subclass or wrapper of Scan</summary>
      <description>We should provide an ImmutableScan as subclass or wrapper of Scan which can be used specifically by Coprocessors as read only Scan. This suggestion came up while reviewing HBASE-24321 by multiple reviewers: https://github.com/apache/hbase/pull/1655</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CustomizedScanInfoBuilder.java</file>
    </fixedFiles>
  </bug>
  <bug id="24458" opendate="2020-5-28 00:00:00" fixdate="2020-6-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>release scripts using docker should specify needed disk consistency</summary>
      <description>reading through existing docs and write ups for Docker Desktop (the dominant docker option for running on OS X machines), it looks like the host-to-container mapping get significant perf gains if we can relax from strict container-host consistency on the filesystem.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.create-release.do-release-docker.sh</file>
    </fixedFiles>
  </bug>
</bugrepository>
