<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="10098" opendate="2013-12-6 00:00:00" fixdate="2013-12-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[WINDOWS] pass in native library directory from hadoop for unit tests</summary>
      <description>On windows, Hadoop depends on native libraries for doing it's job. The bin scripts already handle finding hadoop's native libs and adding them to java.library.path, but for running HBase's unit tests, we need to pass them in.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.2,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="10141" opendate="2013-12-12 00:00:00" fixdate="2013-4-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>instead of putting expired store files thru compaction, just archive them</summary>
      <description>From HBASE-9648</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StripeStoreFileManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultStoreFileManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.RatioBasedCompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration.java</file>
    </fixedFiles>
  </bug>
  <bug id="10146" opendate="2013-12-12 00:00:00" fixdate="2013-12-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bump HTrace version to 2.04</summary>
      <description>2.04 has been released with a bug fix for what happens when htrace fails.</description>
      <version>0.98.0,0.96.1,0.99.0</version>
      <fixedVersion>0.98.0,0.96.2,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="10151" opendate="2013-12-13 00:00:00" fixdate="2013-12-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>No-op HeapMemoryTuner</summary>
      <description>Provide a no-op HeapMemoryTuner that does not change any memory settings, just enforces the old style fixed proportions.</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultHeapMemoryTuner.java</file>
    </fixedFiles>
  </bug>
  <bug id="10169" opendate="2013-12-16 00:00:00" fixdate="2013-3-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Batch coprocessor</summary>
      <description>This is designed to improve the coprocessor invocation in the client side. Currently the coprocessor invocation is to send a call to each region. If thereâ€™s one region server, and 100 regions are located in this server, each coprocessor invocation will send 100 calls, each call uses a single thread in the client side. The threads will run out soon when the coprocessor invocations are heavy. In this design, all the calls to the same region server will be grouped into one in a single coprocessor invocation. This call will be spread into each region in the server side.</description>
      <version>0.99.0</version>
      <fixedVersion>0.98.1,0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.ColumnAggregationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HTableWrapper.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Client.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ClientProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ResponseConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTablePool.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTableInterface.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="10175" opendate="2013-12-16 00:00:00" fixdate="2013-12-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>2-thread ChaosMonkey steps on its own toes</summary>
      <description>ChaosMonkey with one destructive and one volatility (flush-compact-split-etc.) threads steps on its own toes and logs a lot of exceptions.A simple solution would be to catch most (or all), like NotServingRegionException, and log less (not a full callstack for example, it's not very useful anyway).A more complicated/complementary one would be to keep track which regions the destructive thread affects and use other regions for volatile one.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.SplitRandomRegionOfTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.MoveRegionsOfTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.MergeRandomAdjacentRegionsOfTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.FlushTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.FlushRandomRegionOfTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.CompactTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.CompactRandomRegionOfTableAction.java</file>
    </fixedFiles>
  </bug>
  <bug id="1018" opendate="2008-11-22 00:00:00" fixdate="2008-11-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Regionservers should report detailed health to master; master should flag troubled regionservers in UI</summary>
      <description>Regionservers should report detailed health to master. The master should flag troubled regionservers in the UI.The concern at the moment is primarily heap. Regionservers should report used, committed, and max heap metrics in the periodic report. The master should flag in the regionserver list on /master.jsp those regionservers where available heap is below a configurable threshold.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.TestToString.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HBaseRPCProtocolVersion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HServerLoad.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10184" opendate="2013-12-17 00:00:00" fixdate="2013-6-17 01:00:00" resolution="Incomplete">
    <buginformation>
      <summary>[Online Schema Change]: Add additional tests for online schema change</summary>
      <description>There are some gaps in testing for Online Schema Change:Examples of some tests that should be added:1. Splits with online schema change2. Merge during online schema change3. MR over HBase during online schema change4. Bulk Load during online schema change5. Online change table owner6. Online Replication scope change7. Online Bloom Filter change8. Snapshots during online schema change (HBASE-10136)</description>
      <version>0.96.1,0.99.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionServerBulkLoad.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestEndToEndSplitTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestRowCounter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="1020" opendate="2008-11-22 00:00:00" fixdate="2008-11-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Regionserver OOME handler should dump vital stats</summary>
      <description>On OOME the regionserver should dump into the log some vital stats: Number of regions Number of store files Estimated item count and size of memcache(s) Estimated item count and size of store file indexesAssumes the reserve can be released upon OOME to allow the additional actions.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10202" opendate="2013-12-18 00:00:00" fixdate="2013-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Documentation is lacking information about rolling-restart.sh script.</summary>
      <description>Current documentation is talking about graceful_stop.sh and how to do a rolling restart but is not talking about the rolling-restart.sh script. We need to document that.</description>
      <version>0.98.0,0.94.14,0.99.0,0.96.1.1</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  <bug id="10206" opendate="2013-12-19 00:00:00" fixdate="2013-12-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Explain tags in the hbase book</summary>
      <description></description>
      <version>0.98.0,0.99.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.security.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1022" opendate="2008-11-23 00:00:00" fixdate="2008-11-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add storefile index size to hbase metrics</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.metrics.RegionServerMetrics.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStoreFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10226" opendate="2013-12-23 00:00:00" fixdate="2013-12-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[AccessController] Namespace grants not always checked</summary>
      <description>Namespace grants for a user are supposed to supercede table level permissions, a middle tier between table grants and global grants. We are not always checking.</description>
      <version>0.98.0,0.96.2,0.99.0</version>
      <fixedVersion>0.98.0,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestZKPermissionsWatcher.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.TableAuthManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="10232" opendate="2013-12-23 00:00:00" fixdate="2013-12-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove native profile from hbase-shell</summary>
      <description>HBase shell module has no native source it shouldn't have a native profile. I think I copied that over by mistake.</description>
      <version>0.98.0,0.99.0,0.96.1.1</version>
      <fixedVersion>0.98.0,0.96.2,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="10234" opendate="2013-12-23 00:00:00" fixdate="2013-12-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Correct "column-oriented" descriptor on home page</summary>
      <description>Per the conversation on dev list, update the high-level project description to not describe HBase as "column-oriented".</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.site.xdoc.index.xml</file>
    </fixedFiles>
  </bug>
  <bug id="10240" opendate="2013-12-26 00:00:00" fixdate="2013-9-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove 0.94-&gt;0.96 migration code</summary>
      <description>Remove the objects and code only needed for supporting migration to 0.96 from 0.94.</description>
      <version>None</version>
      <fixedVersion>2.0.0-alpha-3,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestTablePermissions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.HbaseObjectWritableFor96Migration.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.TestReference.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="10252" opendate="2013-12-29 00:00:00" fixdate="2013-12-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Don&amp;#39;t write back to WAL/memstore when Increment amount is zero (mostly for query rather than update intention)</summary>
      <description>When user calls Increment by providing amount=0, we don't write the original value to WAL or memstore : adding 0 yields a 'new' value just with the same value as the original one.1. user provides 0 amount for query rather than for update, this fix is ok; this intention is the most possible case;2. user provides 0 amount for an update, this fix is also ok : no need to touch back-end value if that value isn't changed;3. either case we both return correct value, and keep subsequent query results correct : if the 0 amount Increment is the first update, the query is the same for retrieving a 0 value or retrieving nothing;</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestDurability.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="10265" opendate="2014-1-2 00:00:00" fixdate="2014-1-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade to commons-logging 1.1.3</summary>
      <description>Per HADOOP-10147 and HDFS-5678, through we didn't observe any deadlock due to common-logging in HBase, to me, it's still worth to bump the version.</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1027" opendate="2008-11-24 00:00:00" fixdate="2008-12-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make global flusher check work with percentages rather than hard code memory sizes.</summary>
      <description>Currently defaults are 512M for upperbound and 256 for the lowerbound. Comes of HBASE-1023.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.TestGlobalMemcacheLimit.java</file>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.MemcacheFlusher.java</file>
    </fixedFiles>
  </bug>
  <bug id="10302" opendate="2014-1-9 00:00:00" fixdate="2014-1-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix rat check issues in hbase-native-client.</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-native-client.src.rpc.CMakeLists.txt</file>
      <file type="M">hbase-native-client.cmake.modules.FindLibEv.cmake</file>
      <file type="M">hbase-native-client.cmake.modules.FindGTest.cmake</file>
    </fixedFiles>
  </bug>
  <bug id="1031" opendate="2008-11-27 00:00:00" fixdate="2008-1-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add the Zookeeper jar</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10314" opendate="2014-1-10 00:00:00" fixdate="2014-9-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add Chaos Monkey that doesn&amp;#39;t touch the master</summary>
      <description></description>
      <version>0.98.0,0.99.0,0.96.1.1</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.factories.MonkeyFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="10335" opendate="2014-1-14 00:00:00" fixdate="2014-1-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>AuthFailedException in zookeeper may block replication forever</summary>
      <description>ReplicationSource will rechoose sinks when encounted exceptions during skipping edits to the current sink. But if the zookeeper client for peer cluster go to AUTH_FAILED state, the ReplicationSource will always get AuthFailedException. The ReplicationSource does not reconnect the peer, because reconnectPeer only handle ConnectionLossException and SessionExpiredException. As a result, the replication will print log: 2014-01-14,12:07:06,892 INFO org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: Getting 0 rs from peer cluster # 202014-01-14,12:07:06,892 INFO org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: Slave cluster looks down: 20 has 0 region serversand be blocked forever.I think other places may have same problems for not handling AuthFailedException in zookeeper. eg: HBASE-8675.apurtell</description>
      <version>0.94.15,0.99.0</version>
      <fixedVersion>0.98.0,0.96.2,0.99.0,0.94.17</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeersZKImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="10336" opendate="2014-1-14 00:00:00" fixdate="2014-6-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove deprecated usage of Hadoop HttpServer in InfoServer</summary>
      <description>Recent changes in Hadoop HttpServer give NPE when running on hadoop 3.0.0-SNAPSHOT. This way we use HttpServer is deprecated and will probably be not fixed (see HDFS-5760). We'd better move to the new proposed builder pattern, which means we can no more use inheritance to build our nice InfoServer.</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RESTServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="10337" opendate="2014-1-14 00:00:00" fixdate="2014-2-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HTable.get() uninteruptible</summary>
      <description>I've got a stuck thread on HTable.get() that can't be interrupted, looks like its designed to be interruptible but can't be in interrupted in practice due to while loop.The offending code is in org.apache.hadoop.hbase.ipc.HBaseClient.call() line 981, it catches InterruptedException then goes right back to waiting due to the while loop.It looks like future versions of the client (.95+) are significantly different and might not have this problem... Not sure about release schedules etc. or if this version is still getting patched.</description>
      <version>0.98.0,0.94.9,0.99.0,0.96.1.1</version>
      <fixedVersion>0.98.0,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestClientOperationInterrupt.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ExceptionUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="10351" opendate="2014-1-15 00:00:00" fixdate="2014-2-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LoadBalancer changes for supporting region replicas</summary>
      <description>LoadBalancer has to be aware of and enforce placement of region replicas so that the replicas are not co-hosted in the same server, host or rack. This will ensure that the region is highly available during process / host / rack failover.</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.0,hbase-10070</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionReplicas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterOperationsForRegionReplicas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestStochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestBaseLoadBalancer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.BalancerTestBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RackManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.RegionLocationFinder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.FavoredNodeLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="10352" opendate="2014-1-15 00:00:00" fixdate="2014-2-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Region and RegionServer changes for opening region replicas, and refreshing store files</summary>
      <description>Region replicas should be opened in read-only mode, and the "replica" mode so that they serve queries from the primary regions' files. This jira will also capture periodic refreshing of the store files from the secondary regions so that they can get flushed and compacted files according to the "region snapshots" section in the design doc for the parent jira.</description>
      <version>None</version>
      <fixedVersion>0.99.0,hbase-10070</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerNoMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MultiVersionConsistencyControl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ModifyTableHandler.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="10355" opendate="2014-1-16 00:00:00" fixdate="2014-3-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Failover RPC&amp;#39;s from client using region replicas</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.99.0,hbase-10070</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerNoMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StorefileRefresherChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.CoprocessorHConnection.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestAsyncProcess.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionAdapter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClusterConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
    </fixedFiles>
  </bug>
  <bug id="10356" opendate="2014-1-16 00:00:00" fixdate="2014-2-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Failover RPC&amp;#39;s for multi-get</summary>
      <description>This is extension of HBASE-10355 to add failover support for multi-gets.</description>
      <version>None</version>
      <fixedVersion>0.99.0,hbase-10070</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.HConnectionTestingUtility.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.CoprocessorHConnection.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestAsyncProcess.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionLocations.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionReplicaUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MultiServerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MultiAction.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionAdapter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClusterConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Action.java</file>
    </fixedFiles>
  </bug>
  <bug id="10357" opendate="2014-1-16 00:00:00" fixdate="2014-5-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Failover RPC&amp;#39;s for scans</summary>
      <description>This is extension of HBASE-10355 to add failover support for scans.</description>
      <version>None</version>
      <fixedVersion>0.99.0,hbase-10070</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestMultiVersions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabels.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestRestoreSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestReplicasClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.HConnectionTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.catalog.TestMetaReaderEditorNoCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Client.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ClientProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ResponseConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MultiServerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClusterConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallReversedScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="10358" opendate="2014-1-16 00:00:00" fixdate="2014-5-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Shell changes for setting consistency per request</summary>
      <description>We can add shell support to set consistency per request.</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.shell.formatter.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.scan.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.get.rb</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.table.rb</file>
    </fixedFiles>
  </bug>
  <bug id="10359" opendate="2014-1-16 00:00:00" fixdate="2014-2-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Master/RS WebUI changes for region replicas</summary>
      <description>Some UI changes to make region replicas more visible.</description>
      <version>None</version>
      <fixedVersion>0.99.0,hbase-10070</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="10361" opendate="2014-1-16 00:00:00" fixdate="2014-2-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable/AlterTable support for region replicas</summary>
      <description>Add support for region replicas in master operations enable table and modify table.</description>
      <version>None</version>
      <fixedVersion>0.99.0,hbase-10070</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.alter.rb</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterOperationsForRegionReplicas.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ModifyTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.EnableTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.catalog.MetaEditor.java</file>
    </fixedFiles>
  </bug>
  <bug id="10362" opendate="2014-1-16 00:00:00" fixdate="2014-2-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBCK changes for supporting region replicas</summary>
      <description>We should support region replicas in HBCK. The changes are probably not that intrusive.</description>
      <version>None</version>
      <fixedVersion>0.99.0,hbase-10070</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="10370" opendate="2014-1-17 00:00:00" fixdate="2014-1-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compaction in out-of-date Store causes region split failure</summary>
      <description>In out product cluster, we encounter a problem that two daughter regions can not been opened for FileNotFoundException.2014-01-14,20:12:46,927 INFO org.apache.hadoop.hbase.regionserver.SplitRequest: Running rollback/cleanup of failed split of user_profile,xxxxxxxxx,1389671863815.99e016485b0bc142d67ae07a884f6966.; Failed lg-hadoop-st34.bj,21600,1389060755669-daughterOpener=ec8bbda0f132c481b451fa40e7152b98java.io.IOException: Failed lg-hadoop-st34.bj,21600,1389060755669-daughterOpener=ec8bbda0f132c481b451fa40e7152b98 at org.apache.hadoop.hbase.regionserver.SplitTransaction.openDaughters(SplitTransaction.java:375) at org.apache.hadoop.hbase.regionserver.SplitTransaction.execute(SplitTransaction.java:467) at org.apache.hadoop.hbase.regionserver.SplitRequest.run(SplitRequest.java:69) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:662)Caused by: java.io.IOException: java.io.IOException: java.io.FileNotFoundException: File does not exist: /hbase/lgprc-xiaomi/user_profile/99e016485b0bc142d67ae07a884f6966/A/5e05d706e4a84f34acc2cf00f089a4cf....The reason is that a compaction in an out-of-date Store deletes the hfiles, which are referenced by the daughter regions after split. This will cause the daughter regions can not be opened forever. The timeline is that Assumption: there are two hfiles: a, b in Store A in Region Rt0: A compaction request of Store A(a+b) in Region R is sent.t1: First Split for Region R. But this split is timeout and rollbacked. In the rollback, region reinitializes all store objects , see SplitTransaction #824. Now the store is Region R is A'(a+b).t2: Run the compaction sent in t0 . (hfile: a + b -&gt; c): A(a+b) -&gt; A(c). Hfile a and b are archived.t3: Another Split for Region R. R splits into two region R.0, R.1, which create hfile references for hfile a, b from Store A'(a + b)t4: For hfile a, b have been deleted, the opening for region R.0 and R.1 will failed for FileNotFoundException.I have add a test to identity this problem.After search the jira, maybe HBASE-8502 is the same problem. goldin</description>
      <version>0.94.3,0.98.0,0.99.0</version>
      <fixedVersion>0.98.0,0.96.2,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="10371" opendate="2014-1-17 00:00:00" fixdate="2014-1-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compaction creates empty hfile, then selects this file for compaction and creates empty hfile and over again</summary>
      <description>(1) Select HFile for compaction2014-01-16 01:01:25,111 INFO org.apache.hadoop.hbase.regionserver.compactions.CompactSelection: Deleting the expired store file by compaction: hdfs://dump002002.cm6:9000/hbase-0.90/storagetable/7d8941661904fb99a41f79a1fce47767/a/f3e38d10d579420494079e17a2557f0b whose maxTimeStamp is -1 while the max expired timestamp is 1389632485111(2) Compact2014-01-16 01:01:26,042 DEBUG org.apache.hadoop.hbase.regionserver.Compactor: Compacting hdfs://dump002002.cm6:9000/hbase-0.90/storagetable/7d8941661904fb99a41f79a1fce47767/a/f3e38d10d579420494079e17a2557f0b, keycount=0, bloomtype=NONE, size=534, encoding=NONE2014-01-16 01:01:26,045 DEBUG org.apache.hadoop.hbase.util.FSUtils: Creating file=hdfs://dump002002.cm6:9000/hbase-0.90/storagetable/7d8941661904fb99a41f79a1fce47767/.tmp/40de5d79f80e4fb197e409fb99ab0fd8 with permission=rwxrwxrwx2014-01-16 01:01:26,076 INFO org.apache.hadoop.hbase.regionserver.Store: Renaming compacted file at hdfs://dump002002.cm6:9000/hbase-0.90/storagetable/7d8941661904fb99a41f79a1fce47767/.tmp/40de5d79f80e4fb197e409fb99ab0fd8 to hdfs://dump002002.cm6:9000/hbase-0.90/storagetable/7d8941661904fb99a41f79a1fce47767/a/40de5d79f80e4fb197e409fb99ab0fd82014-01-16 01:01:26,142 INFO org.apache.hadoop.hbase.regionserver.Store: Completed compaction of 1 file(s) in a of storagetable,01:,1369377609136.7d8941661904fb99a41f79a1fce47767. into 40de5d79f80e4fb197e409fb99ab0fd8, size=534; total size for store is 399.0 M2014-01-16 01:01:26,142 INFO org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest: completed compaction: regionName=storagetable,01:,1369377609136.7d8941661904fb99a41f79a1fce47767., storeName=a, fileCount=1, fileSize=534, priority=16, time=18280340606333745; duration=0sec(3) Select HFile for compaction2014-01-16 03:48:05,120 INFO org.apache.hadoop.hbase.regionserver.compactions.CompactSelection: Deleting the expired store file by compaction: hdfs://dump002002.cm6:9000/hbase-0.90/storagetable/7d8941661904fb99a41f79a1fce47767/a/40de5d79f80e4fb197e409fb99ab0fd8 whose maxTimeStamp is -1 while the max expired timestamp is 1389642485120(4) Compact2014-01-16 03:50:17,731 DEBUG org.apache.hadoop.hbase.regionserver.Compactor: Compacting hdfs://dump002002.cm6:9000/hbase-0.90/storagetable/7d8941661904fb99a41f79a1fce47767/a/40de5d79f80e4fb197e409fb99ab0fd8, keycount=0, bloomtype=NONE, size=534, encoding=NONE2014-01-16 03:50:17,732 DEBUG org.apache.hadoop.hbase.util.FSUtils: Creating file=hdfs://dump002002.cm6:9000/hbase-0.90... this loop for ever.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.2,0.99.0,0.94.17</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDefaultCompactSelection.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.MockStoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.RatioBasedCompactionPolicy.java</file>
    </fixedFiles>
  </bug>
  <bug id="10373" opendate="2014-1-17 00:00:00" fixdate="2014-1-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add more details info for ACL group in HBase book</summary>
      <description>Current ACL section '8.3. Access Control' in HBase book, not instructs user to grant ACL for group. I think this is good to make it clear for users due to I think that this is great and important feature for users to manage their ACL more easily.mailing listhttp://mail-archives.apache.org/mod_mbox/hbase-user/201401.mbox/%3CCA+RK=_B+UMFZWiAeud9FsQJk8RS8L-VUo6aRVos8k5SUtOGFjA@mail.gmail.com%3E</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.security.xml</file>
    </fixedFiles>
  </bug>
  <bug id="10384" opendate="2014-1-20 00:00:00" fixdate="2014-1-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Failed to increment serveral columns in one Increment</summary>
      <description>We have some problem to increment several columns of a row in one increment request.This one works, we can get all columns incremented as expected: Increment inc1 = new Increment(row); inc1.addColumn(cf, Bytes.toBytes("counter_A"), 1L); inc1.addColumn(cf, Bytes.toBytes("counter_B"), 1L); inc1.addColumn(cf, Bytes.toBytes("counter_C"), 1L); inc1.addColumn(cf, Bytes.toBytes("counter_D"), 1L); testTable.increment(inc1);However, this one just increments counter_A, other columns are reset to 1 instead of incremented: Increment inc1 = new Increment(row); inc1.addColumn(cf, Bytes.toBytes("counter_B"), 1L); inc1.addColumn(cf, Bytes.toBytes("counter_C"), 1L); inc1.addColumn(cf, Bytes.toBytes("counter_A"), 1L); inc1.addColumn(cf, Bytes.toBytes("counter_D"), 1L); testTable.increment(inc1);</description>
      <version>0.98.0,0.99.0,0.96.1.1</version>
      <fixedVersion>0.98.0,0.96.2,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="10401" opendate="2014-1-22 00:00:00" fixdate="2014-1-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbck] perform overlap group merges in parallel</summary>
      <description>In a recent support case, we encountered a corrupt hbase that had thousands of "overlap groups" (regions that had overlapping key ranges). The current implementation repairs these by serially taking a group, perorming a merge and then moving on to the next group. Because assignments and hdfs nn operations are involved each merge could take on the order of seconds. With thousands of overlap groups, this could take hours to complete.This patch makes it so that these independent merge groups are merged in parallel. It uses the same thread pool for other fs info-gathering operations.</description>
      <version>0.92.2,0.98.0,0.94.16,0.99.0,0.96.1.1</version>
      <fixedVersion>0.98.0,0.96.2,0.99.0,0.94.17</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="10402" opendate="2014-1-22 00:00:00" fixdate="2014-1-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[docs] Add docs on how to create and tag a point release.</summary>
      <description>I've added a few steps to the "How to release" section of the ref guide based on what I learned about doing a quickie release.This is what I think I should have done &amp;#8211; if you disagree please suggest how it should be done.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.developer.xml</file>
    </fixedFiles>
  </bug>
  <bug id="10436" opendate="2014-1-28 00:00:00" fixdate="2014-2-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>restore regionserver lists removed from hbase 0.96+ jmx</summary>
      <description>HBase 0.96's refactored jmx beans do not contain the master's list of dead region servers and live regionservers with load info. HBase 0.94 did (though in a single monolithic blob). This JMX interface should be considered as much of an API as the the normal wire or java api. Dropping values from this was done without deprecation and the removal of this information is a functional regression.We should provide the information in the 0.96+ JMX. HBase 0.94 had a monolithic JMX blob ("hadoop:service=Master,name=Master") that contained a lot of information, including the regionserver list and the cached regionserver load for each region found on the master webpage. 0.96+ refactored jmx this into several jmx beans which could be selectively retrieved. These include: hadoop:service=HBase,name=Master,sub=AssignmentManager hadoop:service=HBase,name=Master,sub=Balancer hadoop:service=HBase,name=Master,sub=Server hadoop:service=HBase,name=Master,sub=FileSystemSpecifically the (Hadoop:service=HBase,name=Master,sub=Server) listing that used to contain regionservers and deadregionservers in jmx were replaced in with numRegionServers and numDeadRegionservers which only contain counts. I propose just adding another mbean called "RegionServers" under the bean: "hadoop:service=HBase,name=Master,sub=RegionServers"</description>
      <version>0.98.0,0.96.0,0.99.0</version>
      <fixedVersion>0.96.2,0.98.1,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterMetricsWrapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterWrapperImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterSourceImpl.java</file>
      <file type="M">hbase-hadoop1-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="10440" opendate="2014-1-29 00:00:00" fixdate="2014-1-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>integration tests fail due to nonce collisions</summary>
      <description>Before HBASE-9899 is implemented, and after HBASE-3787, HBase throws OperationConflictException when client retries an already-successful non-idempotent request because the response didn't reach the client.Integration tests run into this when CM kills servers hard during relatively-recently-added appends and increments. They need to handle this, read verification would make sure the results are still correct</description>
      <version>0.98.0,0.99.0</version>
      <fixedVersion>0.98.0,0.99.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MultiThreadedUpdater.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.LoadTestTool.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestIngest.java</file>
    </fixedFiles>
  </bug>
  <bug id="10455" opendate="2014-2-3 00:00:00" fixdate="2014-2-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cleanup InterruptedException management</summary>
      <description>4 changes in this code:1) When caught and rethrowed as a IOException we always rethrow InterruptedIOException2) When we were both throwing an exception AND resetting the interrupt status we only throw an exception now.3) When we were trying to reset the status by Thread.interrupted() (which does not do that), we now do it for real with a Thread.currentThread.interrupt().4) Sometimes, we were rethrowing something else then InterruptedIOException, while the contract would have allowed it. I've changed this as well.This patch does not make means that we're fine when we're interrupted, but we're globally cleaner at least. I will then create other patches specific to some parts.</description>
      <version>0.98.0,0.99.0</version>
      <fixedVersion>0.98.0,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableNamespaceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableLockManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.MetaServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableMapReduceUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.BlockingRpcCallback.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTableUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.catalog.MetaReader.java</file>
    </fixedFiles>
  </bug>
  <bug id="10456" opendate="2014-2-3 00:00:00" fixdate="2014-2-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Balancer should not run if it&amp;#39;s just turned off.</summary>
      <description>TestHBaseFsck failed recently because the balancer ran one more time even after it's turned off. Balancer should double-check if it is on before each run.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="10473" opendate="2014-2-5 00:00:00" fixdate="2014-2-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add utility for adorning http Context</summary>
      <description>Add a utillity class that is used where ever we put up a webserver so we adorn http Context the same in all cases.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.2,0.99.0,0.94.17</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.HBaseRESTTestingUtility.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.InfoServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RESTServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="10477" opendate="2014-2-6 00:00:00" fixdate="2014-2-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Regression from HBASE-10337</summary>
      <description>a piece of code that should not have make it...ping andrew.purtell@gmail.com</description>
      <version>0.98.0,0.99.0</version>
      <fixedVersion>0.98.0,0.99.0,hbase-10070</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="10481" opendate="2014-2-7 00:00:00" fixdate="2014-2-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>API Compatibility JDiff script does not properly handle arguments in reverse order</summary>
      <description>jmhsieh found an issue when doing a diff between a pre-0.96 branch and a post-0.96 branch.Typically, if the pre-0.96 branch is specified first, and the post-0.96 branch second, the exisitng logic handles it.When it is in the reverse order, that logic is not handled properly.The fix should address this.</description>
      <version>0.98.0,0.94.16,0.99.0,0.96.1.1</version>
      <fixedVersion>0.98.1,0.99.0,0.96.1.1,0.94.17</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.jdiffHBasePublicAPI.sh</file>
    </fixedFiles>
  </bug>
  <bug id="10516" opendate="2014-2-13 00:00:00" fixdate="2014-2-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Refactor code where Threads.sleep is called within a while/for loop</summary>
      <description>Threads.sleep implementation: public static void sleep(long millis) { try { Thread.sleep(millis); } catch (InterruptedException e) { e.printStackTrace(); Thread.currentThread().interrupt(); } }From above implementation, the current thread's interrupt status is restored/reset when InterruptedException is caught and handled. If this method is called within a while/for loop, if a first InterruptedException is thrown during sleep, it will make the Threads.sleep in next loop immediately throw InterruptedException without expected sleep. This behavior breaks the intention for independent sleep in each loopI mentioned above in HBASE-10497 and this jira is created to handle it separately per nkeywal's suggestion</description>
      <version>0.98.0,0.99.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DeleteTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
    </fixedFiles>
  </bug>
  <bug id="10519" opendate="2014-2-13 00:00:00" fixdate="2014-2-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add handling for swallowed InterruptedException thrown by Thread.sleep in rest related files</summary>
      <description>A sub-task of HBASE-10497</description>
      <version>0.98.0,0.99.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="10522" opendate="2014-2-13 00:00:00" fixdate="2014-2-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Correct wrong handling and add proper handling for swallowed InterruptedException thrown by Thread.sleep in client</summary>
      <description>A sub-task of HBASE-10497 rethrow rather than ignore InterruptedException thrown in deleteTable, this behavior is to align with other similar methods such as createTable/enableTable/disableTable correct some wrong handling of InterruptedException where Thread.currentThread.interrupt() is called within while loops</description>
      <version>0.98.0,0.99.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTableMultiplexer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="10523" opendate="2014-2-13 00:00:00" fixdate="2014-2-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Correct wrong handling and add proper handling for swallowed InterruptedException thrown by Thread.sleep in util</summary>
      <description>A sub-task of HBASE-10497 correct wrong handling of InterruptedException where Thread.currentThread.interrupt() is called within while loops add proper handling for swallowed InterruptedException</description>
      <version>0.98.0,0.99.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.JVMClusterUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="10524" opendate="2014-2-13 00:00:00" fixdate="2014-2-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Correct wrong handling and add proper handling for swallowed InterruptedException thrown by Thread.sleep in regionserver</summary>
      <description>A sub-task of HBASE-10497 correct wrong handling of InterruptedException where Thread.currentThread.interrupt() is called within while loops add proper handling for swallowed InterruptedException</description>
      <version>0.98.0,0.99.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitLogWorker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="10525" opendate="2014-2-13 00:00:00" fixdate="2014-2-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow the client to use a different thread for writing to ease interrupt</summary>
      <description>This is an issue in the HBASE-10070 context, but as well more generally if you want to interrupt an operation with a limited cost. I will attach a doc with a more detailed explanation.This adds a thread per region server; so it's otional. The first patch activates it by default to see how it behaves on a full hadoop-qa run. The target is to be unset by default.</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.0,hbase-10070</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionManager.java</file>
      <file type="M">dev-support.findbugs-exclude.xml</file>
    </fixedFiles>
  </bug>
  <bug id="10566" opendate="2014-2-19 00:00:00" fixdate="2014-2-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cleanup rpcTimeout in the client</summary>
      <description>There are two issues:1) A confusion between the socket timeout and the call timeoutSocket timeouts should be minimal: a default like 20 seconds, that could be lowered to single digits timeouts for some apps: if we can not write to the socket in 10 second, we have an issue. This is different from the total duration (send query + do query + receive query), that can be longer, as it can include remotes calls on the server and so on. Today, we have a single value, it does not allow us to have low socket read timeouts.2) The timeout can be different between the calls. Typically, if the total time, retries included is 60 seconds but failed after 2 seconds, then the remaining is 58s. HBase does this today, but by hacking with a thread local storage variable. It's a hack (it should have been a parameter of the methods, the TLS allowed to bypass all the layers. May be protobuf makes this complicated, to be confirmed), but as well it does not really work, because we can have multithreading issues (we use the updated rpc timeout of someone else, or we create a new BlockingRpcChannelImplementation with a random default timeout).Ideally, we could send the call timeout to the server as well: it will be able to dismiss alone the calls that it received but git stick in the request queue or in the internal retries (on hdfs for example).This will make the system more reactive to failure.I think we can solve this now, especially after 10525. The main issue is to something that fits well with protobuf...Then it should be easy to have a pool of thread for writers and readers, w/o a single thread per region server as today.</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionServerBulkLoad.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestEndToEndSplitTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALEditsReplaySink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitLogWorker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.ReplicationProtbufUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RegionCoprocessorRpcChannel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.PayloadCarryingRpcController.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RetryingCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionServerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Put.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MultiServerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.DelegatingRetryingCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="10573" opendate="2014-2-20 00:00:00" fixdate="2014-5-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use Netty 4</summary>
      <description>Pull in Netty 4 and sort out the consequences.</description>
      <version>0.99.0,hbase-10191</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestFuzzyRowAndColumnRangeFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ClusterStatusPublisher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-prefix-tree.pom.xml</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Addressing.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClusterStatusListener.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientIdGenerator.java</file>
      <file type="M">hbase-client.pom.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
    </fixedFiles>
  </bug>
  <bug id="10599" opendate="2014-2-24 00:00:00" fixdate="2014-3-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace System.currentMillis() with EnvironmentEdge.currentTimeMillis in memstore flusher and related places</summary>
      <description>Memstoreflusher still uses System.currentMillis. Better to replace it with EnvironmentEdge.currentMillis(),</description>
      <version>0.98.0,0.99.0,0.96.1.1</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
    </fixedFiles>
  </bug>
  <bug id="10607" opendate="2014-2-25 00:00:00" fixdate="2014-5-25 01:00:00" resolution="Invalid">
    <buginformation>
      <summary>[JDK8] NoSuchMethodError involving ConcurrentHashMap.keySet if running on JRE 7</summary>
      <description>If you try running HBase built with Java 8 on a Java 7 JRE, then processes will fail early with:java.lang.NoSuchMethodError: java.util.concurrent.ConcurrentHashMap.keySet()Ljava/util/concurrent/ConcurrentHashMap$KeySetView;I came across this incidentally. I suppose we should consider documenting this in the manual in the Troubleshooting section.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.troubleshooting.xml</file>
    </fixedFiles>
  </bug>
  <bug id="10637" opendate="2014-2-28 00:00:00" fixdate="2014-3-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>rpcClient: Setup the iostreams when writing</summary>
      <description>Since HBASE-10525, we can write in a different thread than the client. This allows the client thread to be interrupted w/o any impact on the shared tcp connection. We should setup the iostream on the second thread as well, i.e. when we do the write, and not when we do the getConnection.</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.0,hbase-10070</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ExceptionUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="10662" opendate="2014-3-4 00:00:00" fixdate="2014-3-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RegionScanner is never closed if the region has been moved-out or re-opened when performing scan request</summary>
      <description>During regionserver processes scan request from client, it fails the request by throwing a wrapped NotServingRegionException to client if it finds the region related to the passed-in scanner-id has been re-opened, and it also removes the RegionScannerHolder from the scanners. In fact under this case, the old and invalid RegionScanner related to the passed-in scanner-id should be closed and the related lease should be cancelled at the mean time as well.Currently region's related scanners aren't closed when closing the region, a region scanner is closed only when requested explicitly by client, or by expiration of the related lease, in this sense the close of region scanners is quite passive and lag.When regionserver processes scan request from client and can't find online region corresponding to the passed-in scanner-id (due to being moved out) or find the region has been re-opened, it throws NotServingRegionException and removes the corresponding RegionScannerHolder from scanners without closing the related region scanner (nor cancelling the related lease), but when the lease expires, the related region scanner still doesn't be closed since it doesn't present in scanners now.</description>
      <version>None</version>
      <fixedVersion>0.98.1,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="10678" opendate="2014-3-5 00:00:00" fixdate="2014-3-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make verifyrep tool implement toolrunner</summary>
      <description>Currently verifyrep tool doesn't take -D args since it doesn't implement the toolrunner interface. So we need to make changes to config files on the client everytime we need run it with custom arguments.</description>
      <version>0.99.0</version>
      <fixedVersion>0.96.2,0.98.1,0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication.java</file>
    </fixedFiles>
  </bug>
  <bug id="10679" opendate="2014-3-5 00:00:00" fixdate="2014-3-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Both clients get wrong scan results if the first scanner expires and the second scanner is created with the same scannerId on the same region</summary>
      <description>The scenario is as below (both Client A and Client B scan against Region R) A opens a scanner SA on R, the scannerId is N, it successfully get its first row "a" SA's lease expires and it's removed from scanners B opens a scanner SB on R, the scannerId is N too. it successfully get its first row "m" A issues its second scan request with scannerId N, regionserver finds N is valid scannerId and the region matches too. (since the region is always online on this regionserver and both two scanners are against it), so it executes scan request on SB, returns "n" to A &amp;#8211; wrong! (get data from other scanner, A expects row something like "b" that follows "a") B issues its second scan request with scannerId N, regionserver also thinks it's valid, and executes scan on SB, return "o" to B &amp;#8211; wrong! (should return "n" but "n" has been scanned out by A just now)The consequence is both clients get wrong scan results: A gets data from scanner created by other client, its own scanner has expired and removed B misses data which should be gotten but has been wrongly scanned out by AThe root cause is scannerId generated by regionserver can't be guaranteed unique within regionserver's whole lifecycle, there is only guarantee that scannerIds of scanners that are currently still valid (not expired) are unique, so a same scannerId can present in scanners again after a former scanner with this scannerId expires and has been removed from scanners. And if the second scanner is against the same region, the bug arises.Theoretically, the possibility of above scenario should be very rare(two consecutive scans on a same region from two different clients get a same scannerId, and the first expires before the second is created), but it does can happen, and once it happens, the consequence is severe(all clients involved get wrong data), and should be extremely hard to diagnose/debug</description>
      <version>None</version>
      <fixedVersion>0.96.2,0.98.1,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="1072" opendate="2008-12-20 00:00:00" fixdate="2008-12-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change Thread.join on exit to a timed Thread.join</summary>
      <description>Here is a hungup regionserver stuck on the running of the dfs shutdown thread:"Thread-11" prio=10 tid=0x00007fcd00a9b400 nid=0x751d waiting on condition [0x0000000042458000..0x0000000042458d00] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at org.apache.hadoop.ipc.Client.stop(Client.java:667) at org.apache.hadoop.ipc.RPC$ClientCache.stopClient(RPC.java:189) at org.apache.hadoop.ipc.RPC$ClientCache.access$400(RPC.java:138) at org.apache.hadoop.ipc.RPC$Invoker.close(RPC.java:229) - locked &lt;0x00007fcd06c6b470&gt; (a org.apache.hadoop.ipc.RPC$Invoker) at org.apache.hadoop.ipc.RPC$Invoker.access$500(RPC.java:196) at org.apache.hadoop.ipc.RPC.stopProxy(RPC.java:353) at org.apache.hadoop.hdfs.DFSClient.close(DFSClient.java:213) - locked &lt;0x00007fcd06c6b3a0&gt; (a org.apache.hadoop.hdfs.DFSClient) at org.apache.hadoop.hdfs.DistributedFileSystem.close(DistributedFileSystem.java:243) at org.apache.hadoop.fs.FileSystem$Cache.closeAll(FileSystem.java:1413) - locked &lt;0x00007fcd06ab9b68&gt; (a org.apache.hadoop.fs.FileSystem$Cache) at org.apache.hadoop.fs.FileSystem.closeAll(FileSystem.java:236) at org.apache.hadoop.fs.FileSystem$ClientFinalizer.run(FileSystem.java:221) - locked &lt;0x00007fcd06aaeee0&gt; (a org.apache.hadoop.fs.FileSystem$ClientFinalizer)Above is just doing this: // wait until all connections are closed while (!connections.isEmpty()) { try { Thread.sleep(100); } catch (InterruptedException e) { } }Might never go down or wont' go down promptly.Should interrupt threads if join timesout and just continue with exit.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.util.Threads.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10720" opendate="2014-3-11 00:00:00" fixdate="2014-3-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>rpcClient: Wrong log level when closing the connection</summary>
      <description>LOG.warn(getName() + ": marking at should close, reason =" + e.getMessage()); if (LOG.isDebugEnabled()) { LOG.debug(getName() + ": marking at should close, reason =" + e.getMessage()); &lt;== Once is enough }</description>
      <version>0.99.0,hbase-10070</version>
      <fixedVersion>0.99.0,hbase-10070</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="10729" opendate="2014-3-12 00:00:00" fixdate="2014-3-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable table doesn&amp;#39;t balance out replicas evenly if the replicas were unassigned earlier</summary>
      <description>Enable table doesn't assign out replicas keeping availability in mind, if the replicas were unassigned before the table was disabled. For example, when a snapshot is restored and then the table is enabled, the replicas are unevenly assigned. The reason for this is that the the enable table invokes randomAssign that assigns one region at a time. Since the master doesn't have any information about the unassigned replicas, the calls to randomAssign can't do any availability checks.</description>
      <version>None</version>
      <fixedVersion>0.99.0,hbase-10070</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.EnableTableHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="10731" opendate="2014-3-12 00:00:00" fixdate="2014-3-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix environment variables typos in scripts</summary>
      <description>I noticed in the top of many of the scripts in bin/ that the old environment variables are documented, such asHADOOP_SSH_OPTS Options passed to ssh when running remote commands.However, in the script code, HBASE_SSH_OPTS is clearly used.I've attached a trivial script to fix this in many locations.</description>
      <version>0.99.0</version>
      <fixedVersion>0.96.2,0.98.1,0.99.0,0.94.18</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.rolling-restart.sh</file>
      <file type="M">bin.regionservers.sh</file>
      <file type="M">bin.master-backup.sh</file>
      <file type="M">bin.hbase-cleanup.sh</file>
    </fixedFiles>
  </bug>
  <bug id="10744" opendate="2014-3-13 00:00:00" fixdate="2014-3-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>AM#CloseRegion no need to retry on FailedServerException</summary>
      <description>When a regionserver restarts, AM#CloseRegion could get FailedServerException, or ServerNotRunningYetException. The call should not be retried since we know the original regionserver should be down.</description>
      <version>None</version>
      <fixedVersion>0.96.2,0.98.1,0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="10788" opendate="2014-3-19 00:00:00" fixdate="2014-3-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add 99th percentile of latency in PE</summary>
      <description>In production env, 99th percentile of latency is more important than the avg. The 99th percentile is helpful to measure the influence of GC, slow read/write of HDFS.</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
    </fixedFiles>
  </bug>
  <bug id="10815" opendate="2014-3-24 00:00:00" fixdate="2014-3-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Master regionserver should be rolling-upgradable</summary>
      <description>In HBASE-10569, two things could affect the rolling-upgrade from a 0.96+ release: Master doesn't have its own info server anymore. It shares the same info server with the regionserver. We can have a setting so that we can start two info servers, one for the master on the original port, and one for the regionserver. Backup master is a regionserver now. So it could hold regions. This could affect some deployment. We can have a setting so that we can prevent backup master from serving any region.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestBaseLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMasterCommandLine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.SimpleLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ActiveMasterManager.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="10881" opendate="2014-4-1 00:00:00" fixdate="2014-4-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support reverse scan in thrift2</summary>
      <description>Support reverse scan in thrift2.</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift.TestThriftServer.java</file>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift2.TestThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-thrift.src.main.resources.org.apache.hadoop.hbase.thrift.Hbase.thrift</file>
      <file type="M">hbase-thrift.src.main.resources.org.apache.hadoop.hbase.thrift2.hbase.thrift</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TScan.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftUtilities.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TScan.java</file>
    </fixedFiles>
  </bug>
  <bug id="10888" opendate="2014-4-1 00:00:00" fixdate="2014-4-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable distributed log replay as default</summary>
      <description>Enable 'distributed log replay' by default. Depends on hfilev3 being enabled.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.LogReplayHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.CreateTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.DeadServer.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.java</file>
    </fixedFiles>
  </bug>
  <bug id="10903" opendate="2014-4-3 00:00:00" fixdate="2014-4-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBASE-10740 regression; cannot pass commands for zk to run</summary>
      <description>We can't do this:./bin/hbase zkcli deleteall /hbase/rs/c2022.halxg.cloudera.com,16020,1396502726715after upgrade to 3.4.6 zookeeper. Works if I put back 3.4.5.See below where only difference is the zk jar:[stack@c2022 hbase-0.99.0-SNAPSHOT]$ ~/bin/java/bin/java -cp ~/hbase-0.96.1.1-hadoop2/lib/zookeeper-3.4.5.jar:lib/slf4j-log4j12-1.6.4.jar:lib/slf4j-api-1.6.4.jar:lib/log4j-1.2.17.jar org.apache.zookeeper.ZooKeeperMain -server c2020:2181 ls "/hbase/rs"Connecting to c2020:2181log4j:WARN No appenders could be found for logger (org.apache.zookeeper.ZooKeeper).log4j:WARN Please initialize the log4j system properly.log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.WATCHER::WatchedEvent state:SyncConnected type:None path:null[c2020.halxg.cloudera.com,16020,1396482186194, c2021.halxg.cloudera.com,16020,1396499398203, c2023.halxg.cloudera.com,16020,1396498834473, c2025.halxg.cloudera.com,16020,1396482188110, c2022.halxg.cloudera.com,16020,1396502726715, c2024.halxg.cloudera.com,16020,1396482188280][stack@c2022 hbase-0.99.0-SNAPSHOT]$ ~/bin/java/bin/java -cp lib/zookeeper-3.4.6.jar:lib/slf4j-log4j12-1.6.4.jar:lib/slf4j-api-1.6.4.jar:lib/log4j-1.2.17.jar org.apache.zookeeper.ZooKeeperMain -server c2020:2181 ls "/hbase/rs"Connecting to c2020:2181log4j:WARN No appenders could be found for logger (org.apache.zookeeper.ZooKeeper).log4j:WARN Please initialize the log4j system properly.log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.</description>
      <version>0.98.1,0.99.0</version>
      <fixedVersion>0.99.0,0.98.2,0.96.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZooKeeperMainServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperMainServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="10917" opendate="2014-4-6 00:00:00" fixdate="2014-4-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix hbase book "Tests" page</summary>
      <description>The command specified to run all tests under the package using a wild card mvn test -Dtest=org.apache.hadoop.hbase.client.* doesnt work. Instead it should be mvn test '-Dtest=org.apache.hadoop.hbase.client.*' .</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.developer.xml</file>
    </fixedFiles>
  </bug>
  <bug id="10918" opendate="2014-4-6 00:00:00" fixdate="2014-4-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[VisibilityController] System table backed ScanLabelGenerator</summary>
      <description>A ScanLabelGenerator that retrieves a static set of authorizations for a user or group from a new HBase system table, and insures these auths are part of the effective set.Useful for forcing a baseline set of auths for a user.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.DefaultScanLabelGenerator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.Authorizations.java</file>
    </fixedFiles>
  </bug>
  <bug id="10925" opendate="2014-4-7 00:00:00" fixdate="2014-4-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Do not OOME, throw RowTooBigException instead</summary>
      <description>If 10M columns in a row, throw a RowTooBigException rather than OOME when Get'ing or Scanning w/o in-row scan flag set.</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="10931" opendate="2014-4-8 00:00:00" fixdate="2014-4-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enhance logs</summary>
      <description>We've got some logs that are expecting toString that are not there.</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionFileSystem.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperNodeTracker.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.catalog.CatalogTracker.java</file>
    </fixedFiles>
  </bug>
  <bug id="10951" opendate="2014-4-10 00:00:00" fixdate="2014-4-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use PBKDF2 to generate test encryption keys in the shell</summary>
      <description>We provide some support in the shell for setting the column family data encryption key, which enables some simple testing when kicking the tires. (CF data key management should be done using the Java API.) Despite the very modest goal there might be an objection to using a hash instead of a key derivation function, so just go ahead and do that.</description>
      <version>0.98.1,0.99.0</version>
      <fixedVersion>0.99.0,0.98.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.Encryption.java</file>
    </fixedFiles>
  </bug>
  <bug id="10952" opendate="2014-4-10 00:00:00" fixdate="2014-4-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[REST] Let the user turn off block caching if desired</summary>
      <description>After HBASE-10884 the REST gateway will use scanner defaults with respect to block caching. Add support for a query parameter for hinting blocks for the query should not be cached. Enable block caching by default.</description>
      <version>0.98.1,0.99.0</version>
      <fixedVersion>0.99.0,0.98.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestScannerModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestModelBase.java</file>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.rest.XMLSchema.xsd</file>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.ScannerMessage.proto</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerResultGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RowResultGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RowResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ResultGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.ScannerMessage.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.MultiRowResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.ScannerModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.Constants.java</file>
    </fixedFiles>
  </bug>
  <bug id="10955" opendate="2014-4-10 00:00:00" fixdate="2014-4-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBCK leaves the region in masters in-memory RegionStates if region hdfs dir is lost</summary>
      <description>One of our tests removes the hdfs directory for the region, and invokes HBCK to fix the issue. This test fails flakily because the region is removed from meta and unassigned, but the region is not offlined from the masters in-memory. This affects further LB runs and disable table, etc. In case of inMeta &amp;&amp; !inHdfs &amp;&amp; isDeployed, we should not just close the region from RS, but call master.unassign().</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsckRepair.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="10956" opendate="2014-4-10 00:00:00" fixdate="2014-4-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade hadoop-2 dependency to 2.4.0</summary>
      <description>Hadoop 2.4.0 has been released:http://search-hadoop.com/m/LgpTk2YKhUfThis JIRA is to upgrade hadoop-2 dependency to 2.4.0</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1097" opendate="2008-12-29 00:00:00" fixdate="2008-12-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>SequenceFile.Reader keeps around buffer whose size is that of largest item read -&gt; results in lots of dead heap</summary>
      <description>Andrew is OOMEing again. Looking at some of his heaps, I can count Reader with DataOutputBuffers of ~600MB in a 2G heap. Testing I see that the DataOutputBuffer allocated at head of Mapfile.Reader is reused when we call next, a reset is called. If I trace, the DataOutputBuffer has in it an internal Buffer class which is based on ByteArrayOutputStream. Reset of the DOB eventually goes through to the BAOS reset. This just sets the position. It keeps the buffer sized to whatever it grew to last time this BAOS was used (Figuring this was a little complicated by the fact that DOB does some fancy footwork in a reset override to avoid copies).</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestHStoreFile.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.MapFilePerformanceEvaluation.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStoreScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStoreFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.HBaseMapFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.BloomFilterMapFile.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11" opendate="2008-1-30 00:00:00" fixdate="2008-4-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbase] Unexpected exits corrupt DFS</summary>
      <description>When a RegionServer exits unexpectedly, it often leaves its DFS files open. In the case of the redo log, this can result in a zero-length file, which a newly started RegionServer will be unable to read, causing it to exit again. It also causes DFS corruption, requiring the admin to run a dfs fsck -delete before HBase can be restarted.</description>
      <version>None</version>
      <fixedVersion>0.1.2,0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HLog.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1100" opendate="2008-12-30 00:00:00" fixdate="2008-12-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBASE-1062 broke TestForceSplit</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.hbase-site.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11009" opendate="2014-4-17 00:00:00" fixdate="2014-4-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>We sync every hbase:meta table write twice</summary>
      <description>Found by @nkeywal and devaraj and noted on the tail of HBASE-10156.</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
    </fixedFiles>
  </bug>
  <bug id="11028" opendate="2014-4-18 00:00:00" fixdate="2014-4-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>FSLog: Avoid an extra sync if the current transaction is already sync&amp;#39;d</summary>
      <description>See HBASE-10156.</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
    </fixedFiles>
  </bug>
  <bug id="11038" opendate="2014-4-19 00:00:00" fixdate="2014-4-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Filtered scans can bypass metrics collection</summary>
      <description>In RegionScannerImpl#nextRaw, after a batch of results are retrieved, delegates to the filter regarding continuation of the scan. If filterAllRemaining returns true, the method exits immediately, without calling MetricsRegion#updateNextScan.</description>
      <version>0.96.2,0.98.1,0.99.0</version>
      <fixedVersion>0.99.0,0.98.2,0.96.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="11048" opendate="2014-4-21 00:00:00" fixdate="2014-5-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support setting custom priority per client RPC</summary>
      <description>Servers have the ability to handle custom rpc priority levels, but currently we are only using it to differentiate META/ROOT updates from replication and other 'priority' updates (as specified by annotation tags per RS method). However, some clients need the ability to create custom handlers (e.g. PHOENIX-938) which can really only be cleanly tied together to requests by the request priority. The disconnect is in that there is no way for the client to overwrite the priority per table - the PayloadCarryingRpcController will always just set priority per ROOT/META and otherwise just use the generic priority.</description>
      <version>0.99.0,0.98.2</version>
      <fixedVersion>0.99.0,0.98.3</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.HConnectionTestingUtility.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALEditsReplaySink.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestAsyncProcess.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MultiServerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallReversedScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
    </fixedFiles>
  </bug>
  <bug id="11055" opendate="2014-4-23 00:00:00" fixdate="2014-4-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Extends the sampling size</summary>
      <description>The latency is measured with a 1K buffer.It's not very comfortable when you're looking at 99.999% latency on multiple millions of operation.Unfortunately, the constructor is protected, so we need to hack a little...</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
    </fixedFiles>
  </bug>
  <bug id="11059" opendate="2014-4-23 00:00:00" fixdate="2014-6-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ZK-less region assignment</summary>
      <description>It seems that most people don't like region assignment with ZK (HBASE-5487), which causes many uncertainties. This jira is to support ZK-less region assignment. We need to make sure this patch doesn't break backward compatibility/rolling upgrade.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.6</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.zookeeper.TestRecoverableZooKeeper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestDrainingServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerNoMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionMergeTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestEndToEndSplitTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.handler.TestOpenRegionHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.handler.TestCloseRegionHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MockRegionServerServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestZKBasedOpenCloseRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRestartCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestOpenedRegionHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannersFromClientSide.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionMergeTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignCallable.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.RegionServerStatus.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionLoad.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.master.RegionState.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.catalog.MetaReader.java</file>
    </fixedFiles>
  </bug>
  <bug id="11062" opendate="2014-4-23 00:00:00" fixdate="2014-9-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbtop</summary>
      <description>A top-like monitor could be useful for testing, debugging, operations of clusters of moderate size, and possibly for diagnosing issues in large clusters.Consider a curses interface like the one presented by atop (http://www.atoptool.nl/images/screenshots/genericw.png) - with aggregate metrics collected over a monitoring interval in the upper portion of the pane, and a listing of discrete measurements sorted and filtered by various criteria in the bottom part of the pane. One might imagine a cluster overview with cluster aggregate metrics above and a list of regionservers sorted by utilization below; and a regionserver view with process metrics above and a list of metrics by operation type below, or a list of client connections, or a list of threads, sorted by utilization, throughput, or latency. Generically 'htop' is taken but would be distinctive in the HBase context, a utility org.apache.hadoop.hbase.HTopNo need necessarily for a curses interface. Could be an external monitor with a web front end as has been discussed before. I do like the idea of a process that runs in a terminal because I interact with dev and test HBase clusters exclusively by SSH. UPDATE:The tool name is changed from htop to hbtop.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.1.7,2.2.2</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-assembly.pom.xml</file>
      <file type="M">bin.hbase</file>
      <file type="M">hbase-hbtop.src.main.java.org.apache.hadoop.hbase.hbtop.terminal.impl.KeyPressGenerator.java</file>
      <file type="M">hbase-hbtop.src.main.java.org.apache.hadoop.hbase.hbtop.screen.top.TopScreenView.java</file>
      <file type="M">hbase-hbtop.src.main.java.org.apache.hadoop.hbase.hbtop.screen.top.FilterDisplayModeScreenView.java</file>
      <file type="M">hbase-hbtop.src.main.java.org.apache.hadoop.hbase.hbtop.screen.mode.ModeScreenView.java</file>
      <file type="M">hbase-hbtop.src.main.java.org.apache.hadoop.hbase.hbtop.screen.field.FieldScreenView.java</file>
      <file type="M">hbase-hbtop.src.main.java.org.apache.hadoop.hbase.hbtop.mode.TableModeStrategy.java</file>
      <file type="M">hbase-hbtop.src.main.java.org.apache.hadoop.hbase.hbtop.mode.RegionServerModeStrategy.java</file>
      <file type="M">hbase-hbtop.src.main.java.org.apache.hadoop.hbase.hbtop.HBTop.java</file>
    </fixedFiles>
  </bug>
  <bug id="11068" opendate="2014-4-24 00:00:00" fixdate="2014-8-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update code to use Admin factory method instead of constructor</summary>
      <description>Where feasible, the code should be updated to use the HConnection factory method for the admin interface. For instance, the following: HBaseAdmin admin = new HBaseAdmin(conf);would be changed to: Admin admin = HConnectionManager.createConnection(conf).getAdmin();This would also require updates to admin calls that refer to a tablename as byte[] or String. admin.enableTable("mytable");would change to: admin.enableTable(TableName.valueOf("mytable"));</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRowProcessorEndpoint.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.OfflineMetaRebuildTestCore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestNamespace.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestMetaTableAccessor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestHColumnDescriptorDefaultVersions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestRestoreFlushSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestFlushSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestExportSnapshot.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.SnapshotTestingUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithDeletes.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabels.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestTablePermissions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestScanEarlyTermination.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestCellACLWithMultipleVersions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestCellACLs.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestTableScan.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestTableResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestSchemaResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestScannersWithLabels.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestScannersWithFilters.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestScannerResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestMultiRowResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestGzipFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.RowResourceBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.client.TestRemoteTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRolling.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRollAbort.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestTags.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSCVFWithMiniCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionMergeTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestEndToEndSplitTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestEncryptionKeyRotation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.procedure.TestProcedureManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.migration.TestNamespaceUpgrade.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestTableLockManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRollingRestart.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterRestartAfterDisablingTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentListener.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.handler.TestTableDescriptorModification.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.handler.TestTableDeleteFamilyHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.handler.TestCreateTableHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.cleaner.TestSnapshotFromMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatTestBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.Action.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.AddColumnAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.ChangeBloomFilterAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.ChangeCompressionAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.ChangeEncodingAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.ChangeVersionsAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.CompactRandomRegionOfTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.CompactTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.FlushRandomRegionOfTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.FlushTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.MergeRandomAdjacentRegionsOfTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.MoveRandomRegionOfTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.MoveRegionsOfTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.RemoveColumnAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.SnapshotTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.SplitRandomRegionOfTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.TruncateTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestIngest.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestIngestWithEncryption.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestManyRegions.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestRegionReplicaPerf.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.mapreduce.IntegrationTestBulkLoad.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.mapreduce.IntegrationTestImportTsv.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.StripeCompactionsPerformanceEvaluation.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestLoadAndVerify.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestTimeBoundedRequestsWithRegionReplicas.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.trace.IntegrationTestSendTraceRequests.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.Canary.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsckRepair.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestHFileArchiving.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestClientOperationInterrupt.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestCloneSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide3.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestRestoreSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotCloneIndependence.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotMetadata.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestTableSnapshotScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.constraint.TestConstraint.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestClassLoading.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorEndpoint.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestMasterCoprocessorExceptionWithAbort.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestMasterCoprocessorExceptionWithRemove.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestMasterObserver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestOpenTableInCoprocessor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverBypass.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverScannerOpenHook.java</file>
    </fixedFiles>
  </bug>
  <bug id="11069" opendate="2014-4-24 00:00:00" fixdate="2014-6-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Decouple region merging from ZooKeeper</summary>
      <description>Region Merge should be decoupled from ZK.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionMergeTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.BaseCoordinatedStateManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="11076" opendate="2014-4-25 00:00:00" fixdate="2014-5-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update refguide on getting 0.94.x to run on hadoop 2.2.0+</summary>
      <description>http://hbase.apache.org/book.html#d248e643 contains steps for rebuilding 0.94 code base to run on hadoop 2.2.0+However, the files under src/main/java/org/apache/hadoop/hbase/protobuf/generated were produced by protoc 2.4.0These files need to be regenerated.See http://search-hadoop.com/m/DHED4j7Um02/HBase+0.94+on+hadoop+2.2.0&amp;subj=Re+HBase+0+94+on+hadoop+2+2+0+2+4+0+This issue is to update refguide with this regeneration step.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.configuration.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11086" opendate="2014-4-28 00:00:00" fixdate="2014-4-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add htrace support for PerfEval</summary>
      <description>Per the title.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
    </fixedFiles>
  </bug>
  <bug id="11088" opendate="2014-4-28 00:00:00" fixdate="2014-7-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support Visibility Expression Deletes in Shell</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.4</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.put.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.deleteall.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.delete.rb</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.table.rb</file>
    </fixedFiles>
  </bug>
  <bug id="11094" opendate="2014-4-29 00:00:00" fixdate="2014-6-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Distributed log replay is incompatible for rolling restarts</summary>
      <description>0.99.0 comes with dist log replay by default (HBASE-10888). However, reading the code and discussing this with Jeffrey, we realized that the dist log replay code is not compatible with rolling upgrades from 0.98.0 and 1.0.0.The issue is that, the region server looks at it own configuration to decide whether the region should be opened in replay mode or not. The open region RPC does not contain that info. So if dist log replay is enabled on master, the master will assign the region and schedule replay tasks. If the region is opened in a RS that does not have this conf enabled, then it will happily open the region in normal mode (not replay mode) causing possible (transient) data loss.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.4</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestSerialization.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLogSplit.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLogMethods.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitLogWorker.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerNoMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestSplitLogManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterFileSystem.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMultiParallel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.SplitLogTask.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitLogWorker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.HLogSplitterHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.MetaServerShutdownHandler.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.ZooKeeper.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Admin.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.AdminProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="11133" opendate="2014-5-7 00:00:00" fixdate="2014-5-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add an option to skip snapshot verification after Export</summary>
      <description>Add a "-skip-dst-verify" option to skip snapshot verification after Export</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.0,0.96.3,0.98.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.ExportSnapshot.java</file>
    </fixedFiles>
  </bug>
  <bug id="11135" opendate="2014-5-7 00:00:00" fixdate="2014-6-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change region sequenceid generation so happens earlier in the append cycle rather than just before added to file</summary>
      <description>Currently we assign the region edit/sequence id just before we put it in the WAL. We do it in the single thread that feeds from the ring buffer. Doing it at this point, we can ensure order, that the edits will be in the file in accordance w/ the ordering of the region sequence id.But the point at which region sequence id is assigned an edit is deep down in the WAL system and there is a lag between our putting an edit into the WAL system and the edit actually getting its edit/sequence id.This lag &amp;#8211; "late-binding" &amp;#8211; complicates the unification of mvcc and region sequence id, especially around async WAL writes (and, related, for no-WAL writes) &amp;#8211; the parent for this issue (For async, how you get the edit id in our system when the threads have all gone home &amp;#8211; unless you make them wait?)Chatting w/ Jeffrey Zhong yesterday, we came up with a crazypants means of getting the region sequence id near-immediately. We'll run two ringbuffers. The first will mesh all handler threads and the consumer will generate ids (we will have order on other side of this first ring buffer), and then if async or no sync, we will just let the threads return ... updating mvcc just before we let them go. All other calls will go up on to the second ring buffer to be serviced as now (batching, distribution out among the sync'ing threads). The first rb will have no friction and should turn at fast rates compared to the second. There should not be noticeable slowdown nor do I foresee this refactor intefering w/ our multi-WAL plans.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRolling.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLog.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALEdit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALActionsListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SyncFuture.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.RingBufferTruck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogKey.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSWALEntry.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.Encryption.java</file>
    </fixedFiles>
  </bug>
  <bug id="11143" opendate="2014-5-9 00:00:00" fixdate="2014-5-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve replication metrics</summary>
      <description>We are trying to report on replication lag and find that there is no good single metric to do that.ageOfLastShippedOp is close, but unfortunately it is increased even when there is nothing to ship on a particular RegionServer.I would like discuss a few options here:Add a new metric: replicationQueueTime (or something) with the above meaning. I.e. if we have something to ship we set the age of that last shipped edit, if we fail we increment that last time (just like we do now). But if there is nothing to replicate we set it to current time (and hence that metric is reported to close to 0).Alternatively we could change the meaning of ageOfLastShippedOp to mean to do that. That might lead to surprises, but the current behavior is clearly weird when there is nothing to replicate.Comments? jdcryans, stack.If approach sounds good, I'll make a patch for all branches.Edit: Also adds a new shippedKBs metric to track the amount of data that is shipped via replication.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.94.20,0.98.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.MetricsSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="11149" opendate="2014-5-9 00:00:00" fixdate="2014-5-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Wire encryption is broken</summary>
      <description>Upon some testing with the QOP configuration (hbase.rpc.protection), discovered that RPC doesn't work with "integrity" and "privacy" values for the configuration key. I was using 0.98.x for testing but I believe the issue is there in trunk as well (haven't checked 0.96 and 0.94).</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.96.3,0.98.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.TestHBaseSaslRpcClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.HBaseSaslRpcServer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.SaslUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.HBaseSaslRpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="11161" opendate="2014-5-13 00:00:00" fixdate="2014-5-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Provide example of POJO encoding with protobuf</summary>
      <description>It would be nice to see how to use the DataType API with some out-of-the-box data serialization tools. This ticket is to provide such an example using Protobuf, since we already ship that dependency.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.3</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11203" opendate="2014-5-19 00:00:00" fixdate="2014-5-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up javadoc and findbugs warnings in trunk</summary>
      <description>Fix outstanding WARNINGS (some of which I am responsible for recently). Fix some findbugs while at it. Remove references to mortbay log.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.AbstractHFileReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ClientSideRegionScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.NullComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FilterList.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.AggregationClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="11209" opendate="2014-5-20 00:00:00" fixdate="2014-5-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Increase the default value for hbase.hregion.memstore.block.multipler from 2 to 4</summary>
      <description>On a YCSB test, I saw a 33% performance increase, both on the max latency and on the throughput. I'm convinced enough that this value is better that I think it makes sense to change it on 0.98 as well.More fundamentally, but outside of the scope of this patch, I think this parameter should be changed to something at the region server level: today, we have: global memstore check: if we're other 40%, we flush the biggest memstore local: no more than 2 (proposed: 4) memstore size per region.But if we have enough memory and a spike on a region, there is no reason for not taking the write.</description>
      <version>0.99.0,0.98.2</version>
      <fixedVersion>0.99.0,0.98.3</fixedVersion>
      <type>Brainstorming</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11214" opendate="2014-5-20 00:00:00" fixdate="2014-5-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fixes for scans on a replicated table</summary>
      <description>During testing with the IT in HBASE-10818, found an issue to do with how "close" of scanners was handled.</description>
      <version>None</version>
      <fixedVersion>0.99.0,hbase-10070</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestReplicasClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MetaScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallReversedScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="11226" opendate="2014-5-21 00:00:00" fixdate="2014-5-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document and increase the default value for hbase.hstore.flusher.count</summary>
      <description>HBASE-6466 add the possibility to have multiple threads for the flusher.The default value is 1, but this should be incremented to 2 reasons: I've observed that the flush of a region can be delayed because another is in progress. During a write load, this leads to an increased latency because the memstore size increases and then block the client if, by accident, a flusher hits a slow or bad datanode, all the flush will have to wait until the timeouts expires. With 2 or more flushers and some luck the other regions will be flushed by the second thread.Lastly this setting is important enough to be documented in the standard hbase site imho.I think it's important enough to go in the .98 branch as wellThere will be an impact: as the flush won't be queued (or less queued) we may have more compactions...</description>
      <version>0.99.0,0.98.2</version>
      <fixedVersion>0.99.0,0.98.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11261" opendate="2014-5-28 00:00:00" fixdate="2014-7-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Handle splitting/merging of regions that have region_replication greater than one</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionMergeTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestReplicasClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ServerRegionReplicaUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ClosedRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="11266" opendate="2014-5-28 00:00:00" fixdate="2014-9-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove shaded references to logger</summary>
      <description>shouldn't reference com.sun.org.* instead we should reference org.*</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRowProcessorEndpoint.java</file>
    </fixedFiles>
  </bug>
  <bug id="11268" opendate="2014-5-28 00:00:00" fixdate="2014-5-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HTablePool is now a deprecated class, should update docs to reflect this</summary>
      <description>jdcryans said in HBASE-11196: HTablePool, it's now a deprecated class, so we should eventually update that too (but let's stick to this jira's scope).</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11273" opendate="2014-5-30 00:00:00" fixdate="2014-6-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix jersey and slf4j deps</summary>
      <description>Hadoop 2.4 wants newer version than us, it's always dangerous to downgrade 3rd parties versions...</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11276" opendate="2014-5-30 00:00:00" fixdate="2014-7-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add back support for running ChaosMonkey as standalone tool</summary>
      <description>According to the ref guide, it was once possible to run ChaosMonkey as a standalone tool against a deployed cluster. After 0.94, this is no longer possible.</description>
      <version>0.98.0,0.96.0,0.99.0</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.2,1.3.0,2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestingUtility.java</file>
    </fixedFiles>
  </bug>
  <bug id="11297" opendate="2014-6-4 00:00:00" fixdate="2014-8-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove some synchros in the rpcServer responder</summary>
      <description>This is on top of another patch that I'm going to put into another jira.</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestDelayedRpc.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.CallRunner.java</file>
    </fixedFiles>
  </bug>
  <bug id="1130" opendate="2009-1-17 00:00:00" fixdate="2009-1-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>PrefixRowFilter</summary>
      <description>I quickly implemented a prefix row filter and an accompanying test case. This is important in terms of HBase emulating big table's capabilities. The Regex Filter is going to be too slow I think. This just does a straight byte comparison so should be very fast.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11311" opendate="2014-6-9 00:00:00" fixdate="2014-6-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Secure Bulk Load does not execute chmod 777 on the files</summary>
      <description>With HBASE-10902 we lost the setPermission() on the hfiles that we are moving, resulting in a Permission denied when we try to remove the filePermission denied: user=hbase, access=WRITE, inode="/hbase/.../3de9fdb2a99e4ef9937b4622317d10e0_SeqId_2_":testuser:hadoop:-rwxr-xr-x for(Pair&lt;byte[], String&gt; el: familyPaths) {- Path p = new Path(el.getSecond());- LOG.trace("Setting permission for: " + p);- fs.setPermission(p, PERM_ALL_ACCESS);</description>
      <version>0.99.0,0.98.2</version>
      <fixedVersion>0.99.0,0.98.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint.java</file>
    </fixedFiles>
  </bug>
  <bug id="11315" opendate="2014-6-10 00:00:00" fixdate="2014-7-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Keeping MVCC for configurable longer time</summary>
      <description>After hbase-8763, we need keep mvcc number longer in hfile so that it can be used to order changes during writes. For example, the known put,delete,put,... scenario, cross region server scan, out of order puts(in recovery case).Current thinking is that we make the retention period configurable(below we're using 1 day to explain). During major compaction, we check hfile's creation time if a hfile creation time is older than 1 day then all mvcc of KVs in that hfile will be removed. If a hfile is created within 1 day, then all mvccs of KVs in that hfile will be kept. In case there are time clock skew, we can firstly sort hfiles based on its seqId in ascending order and find the first hfile's creation time stamp less than 1 day. Then mvcc of all hfiles before the found file will be removed during compaction.</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSeekOptimizations.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestReversibleScanners.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDefaultMemStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileBlock.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogKey.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSWALEntry.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MultiVersionConsistencyControl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultMemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.StripeCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.Compactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.ReplicationProtbufUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderV2.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.WAL.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.WALProtos.java</file>
      <file type="M">hbase-prefix-tree.src.test.java.org.apache.hadoop.hbase.codec.prefixtree.row.data.TestRowDataDifferentTimestamps.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeCell.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestByteRangeWithKVSerialization.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.codec.TestCellCodec.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValueUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.EncodedDataBlock.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.Cell.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.ipc.TestPayloadCarryingRpcController.java</file>
    </fixedFiles>
  </bug>
  <bug id="11316" opendate="2014-6-10 00:00:00" fixdate="2014-7-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expand info about compactions beyond HBASE-11120</summary>
      <description>Round 2 - expand info about the algorithms, talk about stripe compaction, and talk more about configuration. Hopefully find some rules of thumb.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.book.xml</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDefaultCompactSelection.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.compactions.TestStripeCompactionPolicy.java</file>
    </fixedFiles>
  </bug>
  <bug id="11317" opendate="2014-6-10 00:00:00" fixdate="2014-7-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expand unit testing to cover Mockito and MRUnit and give more examples</summary>
      <description>The section at http://hbase.apache.org/book.html#mockito only has a TODO where examples should go.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.developer.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11319" opendate="2014-6-10 00:00:00" fixdate="2014-6-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>No need to use favored node mapping initialization to find all regions</summary>
      <description>During a clean re/start, favored node mapping initialization scans meta for an assignment snapshot. We can avoid this scan since such info is already loaded into region states. For small cluster, this is not a big deal. However, if there are lots of regions, the scan is better not to do.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRSKilledWhenInitializing.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRestartCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterShutdown.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="11320" opendate="2014-6-10 00:00:00" fixdate="2014-6-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reenable bucket cache logging</summary>
      <description>Our bucket caches run threads in the background to log stats on a period only since we moved the log level to default INFO, these DEBUG level logs no longer show up. Make the loggings INFO level (and do some fixup to make bucket cache and lru loggings look same).</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MultiVersionConsistencyControl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.BlockCacheUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="11341" opendate="2014-6-13 00:00:00" fixdate="2014-6-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ZKProcedureCoordinatorRpcs should respond only to members</summary>
      <description>ZKProcedureCoordinatorRpcs nodeCreated() responds to events of every znode under the procedure and not only members.INFO: Received created event: /hbase/&lt;proc&gt;/reached/&lt;instance&gt;INFO: Received created event: /hbase/&lt;proc&gt;/reached/&lt;instance&gt;/&lt;member&gt;the result is a warning (no other side effects)WARN [main-EventThread] procedure.ProcedureCoordinator: Member '&lt;instance&gt;' is trying to release an unknown procedure 'reachedapurtell posted in HBASE-10926 the steps to reproduce it:$ cd ./src/hbase$ git checkout master$ mvn -DskipTests clean installIn one console:$ ./bin/hbase master startIn another console:$ ./bin/hbase org.apache.hadoop.hbase.util.LoadTestTool -num_keys 100000 \ -read 10:100 -write 1:100:10In a third console:$ ./bin/hbase shellhbase&gt; while true do ; flush 'cluster_test' ; sleep 10 ; end</description>
      <version>0.99.0,0.94.20,0.98.3</version>
      <fixedVersion>0.99.0,0.94.21,0.98.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="11347" opendate="2014-6-13 00:00:00" fixdate="2014-6-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>For some errors, the client can retry infinitely</summary>
      <description>As the title says...</description>
      <version>0.99.0,0.98.3</version>
      <fixedVersion>0.99.0,0.98.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestAsyncProcess.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
    </fixedFiles>
  </bug>
  <bug id="11353" opendate="2014-6-14 00:00:00" fixdate="2014-6-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Wrong Write Request Count</summary>
      <description>See title...</description>
      <version>0.99.0,0.98.3</version>
      <fixedVersion>0.99.0,0.98.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="11355" opendate="2014-6-16 00:00:00" fixdate="2014-7-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>a couple of callQueue related improvements</summary>
      <description>In one of my in-memory read only testing(100% get requests), one of the top scalibility bottleneck came from the single callQueue. A tentative sharing this callQueue according to the rpc handler number showed a big throughput improvement(the original get() qps is around 60k, after this one and other hotspot tunning, i got 220k get() qps in the same single region server) in a YCSB read only scenario.Another stuff we can do is seperating the queue into read call queue and write call queue, we had done it in our internal branch, it would helpful in some outages, to avoid all read or all write requests ran out of all handler threads.One more stuff is changing the current blocking behevior once the callQueue is full, considering the full callQueue almost means the backend processing is slow somehow, so a fail-fast here should be more reasonable if we using HBase as a low latency processing system. see "callQueue.put(call)"</description>
      <version>0.99.0,0.94.20</version>
      <fixedVersion>0.99.0,0.98.4</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ReflectionUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="11387" opendate="2014-6-20 00:00:00" fixdate="2014-6-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>metrics: wrong totalRequestCount</summary>
      <description>We have an unit test here, but it tests for greater than instead of equals. So we didn't see that the number was the double of the actual value.As well we were not testing the multi case.</description>
      <version>0.99.0,0.98.3</version>
      <fixedVersion>0.99.0,0.98.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="11391" opendate="2014-6-20 00:00:00" fixdate="2014-6-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thrift table creation will fail with default TTL with sanity checks</summary>
      <description>Creating a table from thrift without explicitly supplying TTL fails because of the new checks introduced in HBASE-10591.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.resources.org.apache.hadoop.hbase.thrift.Hbase.thrift</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftUtilities.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.ColumnDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="11394" opendate="2014-6-20 00:00:00" fixdate="2014-10-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replication can have data loss if peer id contains hyphen "-"</summary>
      <description>This is an extension to HBASE-8207. It seems that there is no check for the peer id string (which is the short name for the replication peer) format. So in case a peer id containing "-", it will cause data loss silently on server failure. I did not verify the claim via testing though, this is just purely from reading the code.</description>
      <version>None</version>
      <fixedVersion>0.98.8,0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationTrackerZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeersZKImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="11395" opendate="2014-6-21 00:00:00" fixdate="2014-6-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add logging for HBase table operations</summary>
      <description>Currently table creation and disable handlers don't log name of table when operation is complete.Table name should be included in the log.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.4</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DisableTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.CreateTableHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="11403" opendate="2014-6-23 00:00:00" fixdate="2014-6-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix race conditions around Object#notify</summary>
      <description>We do have some race conditions there. We don't see them fail in the unit tests, because our #wait are bounded. But from a performance point of view, they do occur. I've reviewed them and fix all the issue I found excepted in the AM (haven't reviewed this one, may be it's fine).On a perf test, this seems to improve the max latency.</description>
      <version>0.99.0,0.98.3</version>
      <fixedVersion>0.99.0,0.98.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.LogRoller.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
    </fixedFiles>
  </bug>
  <bug id="11405" opendate="2014-6-24 00:00:00" fixdate="2014-9-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Multiple invocations of hbck in parallel disables balancer permanently</summary>
      <description>This is because of the following piece of code in hbck boolean oldBalancer = admin.setBalancerRunning(false, true); try { onlineConsistencyRepair(); } finally { admin.setBalancerRunning(oldBalancer, false); }Newer invocations set oldBalancer to false as it was disabled by previous invocations and this disables balancer permanently unless its manually turned on by the user. Easy to reproduce, just run hbck 100 times in a loop in 2 different sessions and you can see that balancer is set to false in the HMaster logs.</description>
      <version>0.99.0</version>
      <fixedVersion>0.98.7,0.94.24,0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="11487" opendate="2014-7-9 00:00:00" fixdate="2014-7-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ScanResponse carries non-zero cellblock for CloseScanRequest (ScanRequest with close_scanner = true)</summary>
      <description>After upgrading hbase from 0.94 to 0.96, we've found that our asynchbase client keep throwing errors during normal scan. It turns out these errors are due to Scanner.close call in asynchbase. Since asynchbase assumes the ScanResponse of CloseScannerRequest should never carry any cellblocks, it will throw an exception if there is a violation.In the asynchbase client (1.5.0), it constructs a CloseScannerRequest in the following way, ScanRequest.newBuilder() .setScannerId(scanner_id) .setCloseScanner(true) .build();Note, it does not set numOfRows, which kind of make sense. Why a close scanner request cares about number of rows to scan ?However, after narrowing down the CloseScannerRequest code path, it seems the issue is on regionserver side. In RsRpcServices.scan, we always init numOfRows to scan to 1 and we do this even for ScanRequest with close_scanner = true. This causes response for CloseScannerRequest will carry a cellBlock (if scan stops before the end row and this could happen in many normal scenarios)There are two fixes, either we always set numOfRows in asynchbase client side when constructing a CloseScannerRequest or we fix the default value in the server side.From a hbase client side point of view, it seems make less sense that server will send you a cellBlock for your close scanner request, unless the request explicitly asks for. We've made the change in our server code and the asynchbase client errors goes away. In addition to this issue, I want to know if we have any specifications for our hbase rpc. Like if close_scanner = true in ScanRequest and numOfRows is not set, ScanResponse guarantees that there is no cellBlock in the response. Since we moved to protobuf and many fields are optional for compatibility consideration, it might be helpful to have such specification which helps people to develop code that depends on hbase rpc.</description>
      <version>0.96.2,0.99.0,2.0.0</version>
      <fixedVersion>0.99.0,0.98.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="11489" opendate="2014-7-10 00:00:00" fixdate="2014-7-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ClassNotFoundException while running IT tests in trunk using &amp;#39;mvn verify&amp;#39;</summary>
      <description>Trying to run mvn verify -Dit.test=IntegrationTestBigLinkedList -Dtest.output.tofile=falsecauses this ClassNotFoundException issuetestContinuousIngest(org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList): org/jboss/netty/channel/ChannelFactory</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11491" opendate="2014-7-10 00:00:00" fixdate="2014-7-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add an option to sleep randomly during the tests with the PE tool</summary>
      <description>This allows to find some interesting bugs....</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
    </fixedFiles>
  </bug>
  <bug id="11497" opendate="2014-7-10 00:00:00" fixdate="2014-7-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expose RpcScheduling implementations as LimitedPrivate interfaces</summary>
      <description>In PHOENIX-938 we are attempting to resolve cross-RS deadlocks in indexing by adding custom RPC handlers (so regular puts/reads don't interfere with index updates). However, we've run into a couple of snags where the interfaces change, making it a bit more difficult to support interoperability between minor versions as the underlying RPC handling changed (for the better, but still different .This would just mark those interfaces Public, Evolving, so we still have some flexibility, but don't break existing usage.Note, this kind of thing will come up for any client who is doing custom RPC handling - beyond the recently added flexibility - but wants to stay in line with the current HBase implementation (rather than building their own RPC handling mechanisms).</description>
      <version>0.99.0,0.98.4</version>
      <fixedVersion>0.99.0,0.98.4</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcSchedulerContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.FifoRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SimpleRpcSchedulerFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SingleQueueRpcExecutor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServerInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.MultipleQueueRpcExecutor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HBaseInterfaceAudience.java</file>
    </fixedFiles>
  </bug>
  <bug id="11508" opendate="2014-7-14 00:00:00" fixdate="2014-8-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document changes to IPC config parameters from HBASE-11492</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.troubleshooting.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11509" opendate="2014-7-14 00:00:00" fixdate="2014-7-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Forward port HBASE-11039 to trunk and branch-1 after HBASE-11489</summary>
      <description>The visibility related IT test case that verifies delete behaviour has to be ported to branch-1 and master after HBASE-11489 is fixed.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.Import.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.CellVisibility.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="11513" opendate="2014-7-14 00:00:00" fixdate="2014-7-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Combine SingleMultiple Queue RpcExecutor into a single class</summary>
      <description>Its a little odd that we use multiple classes, leading to mutliple if-else conditions for rpc execution when we could just combine them into one. Makes the logic and also puts the code into one place</description>
      <version>0.99.0,0.98.4,2.0.0</version>
      <fixedVersion>0.99.0,0.98.4</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SingleQueueRpcExecutor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.MultipleQueueRpcExecutor.java</file>
    </fixedFiles>
  </bug>
  <bug id="11520" opendate="2014-7-15 00:00:00" fixdate="2014-7-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Simplify offheap cache config by removing the confusing "hbase.bucketcache.percentage.in.combinedcache"</summary>
      <description>Remove "hbase.bucketcache.percentage.in.combinedcache". It is unnecessary complication of block cache config. Let L1 config setup be as it is whether a L2 present or not, just set hfile.block.cache.size (not hbase.bucketcache.size * (1.0 - hbase.bucketcache.percentage.in.combinedcache)). For L2, let hbase.bucketcache.size be the actual size of the bucket cache, not hbase.bucketcache.size * hbase.bucketcache.percentage.in.combinedcache.Attached patch removes the config. and updates docs. Adds tests to confirm configs are as expected whether a CombinedBlockCache deploy or a strict L1+L2 deploy.</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.upgrading.xml</file>
      <file type="M">src.main.docbkx.book.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestCacheConfig.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.package-info.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
    </fixedFiles>
  </bug>
  <bug id="11531" opendate="2014-7-16 00:00:00" fixdate="2014-7-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RegionStates for regions under region-in-transition znode are not updated on startup</summary>
      <description>While testing HBASE-11059, saw that if there are regions under region-in-transition znode their states are not updated in META and master memory on startup.</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.0,0.98.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="11555" opendate="2014-7-21 00:00:00" fixdate="2014-7-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TableSnapshotRegionSplit should be public</summary>
      <description>This class extends Writable and so should be public so it can be used outside of the existing code line we ship. This will be consistent with TableSplit, which is also public.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.5</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat.java</file>
    </fixedFiles>
  </bug>
  <bug id="11571" opendate="2014-7-22 00:00:00" fixdate="2014-3-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bulk load handling from secondary region replicas</summary>
      <description>We should be replaying the bulk load events from the primary region replica in the secondary region replica so that the bulk loaded files will be made visible in the secondaries. This will depend on HBASE-11567 and HBASE-11568</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionReplayEvents.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestBulkLoad.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="11573" opendate="2014-7-22 00:00:00" fixdate="2014-7-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Report age on eviction</summary>
      <description>From the parent issue, Todd reminds us of the old Jim Gray '5 minute rule' on whether to cache.In master, we were reporting age only it was the inactionable inverse of 'how long blocks are staying in the cache'.Let me add to our cache stats a histogram of age on eviction and change the UI reporting so it is age at eviction (plus stddev). The JSON version has percentiles (and if wanted, the old age report of age of items in cache).</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHeapMemoryManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestLruBlockCache.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestBlockCacheReporting.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheStats.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketCacheStats.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.BlockCacheUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.DataInputInputStream.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="11575" opendate="2014-7-23 00:00:00" fixdate="2014-7-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Pseudo distributed mode does not work as documented</summary>
      <description>After master-RS colocation, now the pseudo dist-mode does not work as documented since you cannot start a region server in the same port 16020. I think we can either select a random port (and info port) for the master's region server, or document how to do a pseudo-distributed setup in the book. jxiang wdyt?</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.getting.started.xml</file>
      <file type="M">conf.regionservers</file>
      <file type="M">bin.local-regionservers.sh</file>
      <file type="M">bin.local-master-backup.sh</file>
      <file type="M">bin.hbase-config.sh</file>
    </fixedFiles>
  </bug>
  <bug id="11591" opendate="2014-7-25 00:00:00" fixdate="2014-8-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scanner fails to retrieve KV from bulk loaded file with highest sequence id than the cell&amp;#39;s mvcc in a non-bulk loaded file</summary>
      <description>See discussion in HBASE-11339.When we have a case where there are same KVs in two files one produced by flush/compaction and the other thro the bulk load.Both the files have some same kvs which matches even in timestamp.Steps:Add some rows with a specific timestamp and flush the same. Bulk load a file with the same data.. Enusre that "assign seqnum" property is set.The bulk load should use HFileOutputFormat2 (or ensure that we write the bulk_time_output key).This would ensure that the bulk loaded file has the highest seq num.Assume the cell in the flushed/compacted store file is row1,cf,cq,ts1, value1 and the cell in the bulk loaded file isrow1,cf,cq,ts1,value2 (There are no parallel scans).Issue a scan on the table in 0.96. The retrieved value is row1,cf1,cq,ts1,value2But the same in 0.98 will retrieve row1,cf1,cq,ts2,value1. This is a behaviour change. This is because of this code public int compare(KeyValueScanner left, KeyValueScanner right) { int comparison = compare(left.peek(), right.peek()); if (comparison != 0) { return comparison; } else { // Since both the keys are exactly the same, we break the tie in favor // of the key which came latest. long leftSequenceID = left.getSequenceID(); long rightSequenceID = right.getSequenceID(); if (leftSequenceID &gt; rightSequenceID) { return -1; } else if (leftSequenceID &lt; rightSequenceID) { return 1; } else { return 0; } } }Here in 0.96 case the mvcc of the cell in both the files will have 0 and so the comparison will happen from the else condition . Where the seq id of the bulk loaded file is greater and would sort out first ensuring that the scan happens from that bulk loaded file.In case of 0.98+ as we are retaining the mvcc+seqid we are not making the mvcc as 0 (remains a non zero positive value). Hence the compare() sorts out the cell in the flushed/compacted file. Which means though we know the lateset file is the bulk loaded file we don't scan the data.Seems to be a behaviour change. Will check on other corner cases also but we are trying to know the behaviour of bulk load because we are evaluating if it can be used for MOB design.</description>
      <version>0.99.0,2.0.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestScanWithBloomError.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="11631" opendate="2014-7-31 00:00:00" fixdate="2014-8-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Wait a little till server is online in assigning meta</summary>
      <description>In assigning the meta to a regionserver not the master, the regionserver could have not processed the reportForDuty response yet. This happens a lot in unit tests. It's better to wait a little bit.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="1167" opendate="2009-1-31 00:00:00" fixdate="2009-1-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>JSP doesn&amp;#39;t work in a git checkout</summary>
      <description>Running from a git checkout, the JSP pages are not getting compiled right. HBase is up and running fine, but I get 404s on any requests to the info server.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11681" opendate="2014-8-6 00:00:00" fixdate="2014-8-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update and move doc about disabling the WAL</summary>
      <description>Move the docs about disabling the WAL from the Performance section to the WAL section, point to the new location, and add info about getDurability and setDurability methods. Leave the big fat warnings about data loss in both the Performance and WAL sections.</description>
      <version>0.99.0,2.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.performance.xml</file>
      <file type="M">src.main.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11682" opendate="2014-8-6 00:00:00" fixdate="2014-8-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Explain hotspotting</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.schema.design.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11703" opendate="2014-8-7 00:00:00" fixdate="2014-8-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Meta region state could be corrupted</summary>
      <description>Internal meta region state could be corrupted if the meta is not on master:1. the meta region server (not master) shuts down,2. meta SSH offlines it without updating the dead server's region list,3. meta is transitioned to pending_open and the previous server (the dead server) of meta is lost,4. meta is assigned somewhere else without updating its previous server,5. normal SSH processes the dead server and offlines all of it's dead regions including the meta, so the meta internal state is corrupted</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="11705" opendate="2014-8-8 00:00:00" fixdate="2014-8-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>callQueueSize should be decremented in a fail-fast scenario</summary>
      <description>Discussed on the user@hbase mailing list (http://markmail.org/thread/w3cqjxwo2smkn2jw). If a client disconnects the call queue size is not decremented causing new calls to get rejected with a CallQueueTooBigException.</description>
      <version>0.98.0,0.99.0,2.0.0</version>
      <fixedVersion>0.99.0,0.98.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.CallRunner.java</file>
    </fixedFiles>
  </bug>
  <bug id="11709" opendate="2014-8-8 00:00:00" fixdate="2014-8-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestMasterShutdown can fail sometime</summary>
      <description>This applies to 1.0 and master, not previous versions.</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="11726" opendate="2014-8-12 00:00:00" fixdate="2014-8-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Master should fail-safe if starting with a pre 0.96 layout</summary>
      <description>We recently saw this: If user inadvertently starts the HBase Master after deploying new HBase binaries (any version that supports namespaces), the HMaster will start the migration to PBs the the hbase.version file per HBASE-5453 and that will write a new version file PB-serialized but with the old version number. Further restarts of the master will fail because the hbase version file has been migrated to PBs and there will be version mismatch. The right approach should be to fail safe the master if we find an old hbase.version file in order to force user to run upgrade tool.</description>
      <version>0.96.2,0.99.0,0.98.5,2.0.0</version>
      <fixedVersion>0.99.0,0.98.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="11727" opendate="2014-8-12 00:00:00" fixdate="2014-8-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Assignment wait time error in case of ServerNotRunningYetException</summary>
      <description>maxWaitTime = this.server.getConfiguration(). getLong("hbase.regionserver.rpc.startup.waittime", 60000);It should add the current time.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="11735" opendate="2014-8-14 00:00:00" fixdate="2014-8-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document Configurable Bucket Sizes in bucketCache</summary>
      <description></description>
      <version>0.99.0,0.98.4,0.98.5</version>
      <fixedVersion>0.99.0,0.98.6</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.book.xml</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11736" opendate="2014-8-14 00:00:00" fixdate="2014-8-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document SKIP_FLUSH snapshot option</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11737" opendate="2014-8-14 00:00:00" fixdate="2014-8-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document callQueue improvements from HBASE-11355 and HBASE-11724</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.performance.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11738" opendate="2014-8-14 00:00:00" fixdate="2014-9-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document improvements to LoadTestTool and PerformanceEvaluation</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11739" opendate="2014-8-14 00:00:00" fixdate="2014-8-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document blockCache contents report in the UI</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11779" opendate="2014-8-19 00:00:00" fixdate="2014-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document the new requirement to set JAVA_HOME before starting HBase</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.getting.started.xml</file>
      <file type="M">src.main.docbkx.configuration.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1178" opendate="2009-2-3 00:00:00" fixdate="2009-2-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add shutdown command to shell</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.19.1,0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.hirb.rb</file>
      <file type="M">bin.HBase.rb</file>
    </fixedFiles>
  </bug>
  <bug id="11781" opendate="2014-8-20 00:00:00" fixdate="2014-9-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document new TableMapReduceUtil scanning options</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11782" opendate="2014-8-20 00:00:00" fixdate="2014-8-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document that hbase.MetaMigrationConvertingToPB needs to be set to true for migrations pre 0.96</summary>
      <description>See HBASE-11651</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.upgrading.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11788" opendate="2014-8-20 00:00:00" fixdate="2014-11-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase is not deleting the cell when a Put with a KeyValue, KeyValue.Type.Delete is submitted</summary>
      <description>Code executed: @Test public void testHbasePutDeleteCell() throws Exception { TableName tableName = TableName.valueOf("my_test"); Configuration configuration = HBaseConfiguration.create(); HTableInterface table = new HTable(configuration, tableName); final String rowKey = "12345"; final byte[] familly = Bytes.toBytes("default"); // put one row Put put = new Put(Bytes.toBytes(rowKey)); put.add(familly, Bytes.toBytes("A"), Bytes.toBytes("a")); put.add(familly, Bytes.toBytes("B"), Bytes.toBytes("b")); put.add(familly, Bytes.toBytes("C"), Bytes.toBytes("c")); table.put(put); // get row back and assert the values Get get = new Get(Bytes.toBytes(rowKey)); Result result = table.get(get); Assert.isTrue(Bytes.toString(result.getValue(familly, Bytes.toBytes("A"))).equals("a"), "Column A value should be a"); Assert.isTrue(Bytes.toString(result.getValue(familly, Bytes.toBytes("B"))).equals("b"), "Column B value should be b"); Assert.isTrue(Bytes.toString(result.getValue(familly, Bytes.toBytes("C"))).equals("c"), "Column C value should be c"); // put the same row again with C column deleted put = new Put(Bytes.toBytes(rowKey)); put.add(familly, Bytes.toBytes("A"), Bytes.toBytes("a")); put.add(familly, Bytes.toBytes("B"), Bytes.toBytes("b")); put.add(new KeyValue(Bytes.toBytes(rowKey), familly, Bytes.toBytes("C"), HConstants.LATEST_TIMESTAMP, KeyValue.Type.DeleteColumn)); table.put(put); // get row back and assert the values get = new Get(Bytes.toBytes(rowKey)); result = table.get(get); Assert.isTrue(Bytes.toString(result.getValue(familly, Bytes.toBytes("A"))).equals("a"), "Column A value should be a"); Assert.isTrue(Bytes.toString(result.getValue(familly, Bytes.toBytes("B"))).equals("b"), "Column A value should be b"); Assert.isTrue(result.getValue(familly, Bytes.toBytes("C")) == null, "Column C should not exists"); }This assertion fails, the cell is not deleted but rather the value is empty:hbase(main):029:0&gt; scan 'my_test'ROW COLUMN+CELL 12345 column=default:A, timestamp=1408473082290, value=a 12345 column=default:B, timestamp=1408473082290, value=b 12345 column=default:C, timestamp=1408473082290, value= This behavior is different than previous 4.8.x Cloudera version and is currently corrupting all hive queries involving is null or is not null operators on the columns mapped to hbase</description>
      <version>0.99.0,0.96.1.1,0.98.5,2.0.0</version>
      <fixedVersion>0.99.0,0.98.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="11847" opendate="2014-8-28 00:00:00" fixdate="2014-9-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HFile tool should be able to print block headers</summary>
      <description>Printing the block index is helpful, but sometimes you want to see more info about the blocks themselves.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.7</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter.java</file>
    </fixedFiles>
  </bug>
  <bug id="11849" opendate="2014-8-28 00:00:00" fixdate="2014-8-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up orphaned private audience classes</summary>
      <description>We have some classes in master that are private audience and no longer used internally. We should remove them.I'll build a list for server-side modules along with when they got orphaned so we can decide on removal from older branches.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.OrphanHLogAfterSplitException.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.ThreadLocalEncoderPool.java</file>
    </fixedFiles>
  </bug>
  <bug id="11859" opendate="2014-8-28 00:00:00" fixdate="2014-8-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>&amp;#39;hadoop jar&amp;#39; references in documentation should mention hbase-server.jar, not hbase.jar</summary>
      <description>There are various org.apache.hadoop.util.Tool implementations mentioned in the documentation as being run with "hadoop jar hbase-VERSION.jar &lt;toolname&gt;". These classes now live in in the hbase-server module, so that jar name should be hbase-server-VERSION.jar.The same applies to the documentation on running MapReduce jobs against HBase.</description>
      <version>0.99.0,0.98.6,2.0.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.troubleshooting.xml</file>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
      <file type="M">src.main.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1186" opendate="2009-2-5 00:00:00" fixdate="2009-3-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Memory-aware Maps with LRU eviction for Cell Cache</summary>
      <description>Caching is key for 0.20. We need a set of memory-aware data structures to manage our caches.I propose two initial classes: LruHashMap and LruBlockMapLruHashMap is currently being used over in HBASE-80 for the Cell cache. Erik Holstad has done extensive testing and benchmarking and will post results over in this issue. Memory-aware Fixed size LRU evictionLruBlockMap can be used for the block caching of the new file format in HBASE-61. It should try to use all available memory, but must contend with Memcaches so is resizable to deal with heap pressure. Adding high priority blocks (evicted last) gives us in-memory functionality as described in bigtable paper. Memory-aware Fully resizable LRU eviction (with some additions) High priority blocks Optional: Scan resistant algorithmPart of this issue is also solving how we will determine the size of cached objects.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.io.HeapSize.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11887" opendate="2014-9-3 00:00:00" fixdate="2014-9-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Memory retention in branch-1; millions of instances of LiteralByteString for column qualifier and value</summary>
      <description>Trying to test branch-1, I run out of mem pretty fast. Looking at dumps, I see too many instances of LiteralByteString. Seem to be 'qualifiers' and 'values' out of pb QualifierValue... and on up to the multi call into the server. Am having trouble finding how the retention is being done... Filing issue in meantime while work on it.</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.0,0.98.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.CallRunner.java</file>
    </fixedFiles>
  </bug>
  <bug id="11906" opendate="2014-9-6 00:00:00" fixdate="2014-9-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Meta data loss with distributed log replay</summary>
      <description>In the attached log, you can see, before log replaying, the region is open on e1205:A3. 2014-09-05 16:38:46,705 INFO [B.defaultRpcServer.handler=5,queue=2,port=20020] master.RegionStateStore: Updating row IntegrationTestBigLinkedList,\x90Jy\x04\xA7\x90Jp,1409959495482.cbb0d736ebfabcf4a07e5a7b395fcdf7. with state=OPEN&amp;openSeqNum=40118237&amp;server=e1205.halxg.cloudera.com,20020,1409960280431After the log replay, we got from meta the region is open on e1209A4. 2014-09-05 16:41:12,257 INFO [ActiveMasterManager] master.AssignmentManager: Loading from meta: {cbb0d736ebfabcf4a07e5a7b395fcdf7 state=OPEN, ts=1409960472257, server=e1209.halxg.cloudera.com,20020,1409959391651}The replayed edits show the log does have the edit expected:2014-09-05 16:41:11,862 INFO [B.defaultRpcServer.handler=18,queue=0,port=20020] regionserver.RSRpcServices: Meta replay edit type=PUT,mutation={"totalColumns":4,"families":{"info":[{"timestamp":1409960326705,"tag":["3:\\x00\\x00\\x00\\x00\\x02bad"],"value":"e1205.halxg.cloudera.com:20020","qualifier":"server","vlen":30},{"timestamp":1409960326705,"tag":["3:\\x00\\x00\\x00\\x00\\x02bad"],"value":"\\x00\\x00\\x01HH.\\x81o","qualifier":"serverstartcode","vlen":8},{"timestamp":1409960326705,"tag":["3:\\x00\\x00\\x00\\x00\\x02bad"],"value":"\\x00\\x00\\x00\\x00\\x02d'\\xDD","qualifier":"seqnumDuringOpen","vlen":8},{"timestamp":1409960326706,"tag":["3:\\x00\\x00\\x00\\x00\\x02bad"],"value":"OPEN","qualifier":"state","vlen":4}]},"row":"IntegrationTestBigLinkedList,\\x90Jy\\x04\\xA7\\x90Jp,1409959495482.cbb0d736ebfabcf4a07e5a7b395fcdf7."}Why we picked up a wrong value with an older time stamp?2014-09-05 16:41:11,063 INFO [B.defaultRpcServer.handler=9,queue=0,port=20020] regionserver.RSRpcServices: Meta replay edit type=PUT,mutation={"totalColumns":4,"families":{"info":[{"timestamp":1409959994634,"tag":["3:\\x00\\x00\\x00\\x00\\x00\\x00\\x09\\x99"],"value":"e1209.halxg.cloudera.com:20020","qualifier":"server","vlen":30},{"timestamp":1409959994634,"tag":["3:\\x00\\x00\\x00\\x00\\x00\\x00\\x09\\x99"],"value":"\\x00\\x00\\x01HH \\xF1\\xA3","qualifier":"serverstartcode","vlen":8},{"timestamp":1409959994634,"tag":["3:\\x00\\x00\\x00\\x00\\x00\\x00\\x09\\x99"],"value":"\\x00\\x00\\x00\\x00\\x00\\x01\\xB7\\xAB","qualifier":"seqnumDuringOpen","vlen":8},{"timestamp":1409959994634,"tag":["3:\\x00\\x00\\x00\\x00\\x00\\x00\\x09\\x99"],"value":"OPEN","qualifier":"state","vlen":4}]},"row":"IntegrationTestBigLinkedList,\\x90Jy\\x04\\xA7\\x90Jp,1409959495482.cbb0d736ebfabcf4a07e5a7b395fcdf7."}</description>
      <version>0.99.0,2.0.0</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="11908" opendate="2014-9-7 00:00:00" fixdate="2014-1-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Region replicas should be added to the meta table at the time of table creation</summary>
      <description>While testing async replication handling and failover handling for region replicas, we've found that sometimes the secondary region replicas do not open and update meta quickly enough, and hence meta would not contain any information about the region replica id. If a reader caches the meta row before all region replicas are open the first time (such as the async wal replication endpoint), then it may miss the region replica and won't know about it until it refreshes it's cache again. Instead, we should add entries to the meta for all of the region replicas at the time of create table (just like primary regions).</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestMetaTableAccessor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMetaScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.RestoreSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.CloneSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStateStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TruncateTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.CreateTableHandler.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MetaTableAccessor.java</file>
    </fixedFiles>
  </bug>
  <bug id="11909" opendate="2014-9-8 00:00:00" fixdate="2014-9-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Region count listed by HMaster UI and hbck are different</summary>
      <description>The count displayed in the HMaster UI can be lower than the count of regions as done by hbck or by counting subdirectories of /hbase/&lt;table&gt;. This is explained in the comments &amp;#91;1&amp;#93; but I think it should be documented as well&amp;#91;1&amp;#93; https://git-wip-us.apache.org/repos/asf?p=hbase.git;a=blob;f=hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java#l578</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11949" opendate="2014-9-11 00:00:00" fixdate="2014-9-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Setting hfile.block.cache.size=0 doesn&amp;#39;t actually disable blockcache</summary>
      <description>stack noticed this one over on HBASE-11845. The provided patched worked as intended on 0.98, but not on branch-1 or master.Marking as minor because we highly encourage users not to do this anyway (it's just a convenience for tools).</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
    </fixedFiles>
  </bug>
  <bug id="1195" opendate="2009-2-11 00:00:00" fixdate="2009-4-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>If HBase directory exists but version file is inexistent, still proceed with bootstrapping</summary>
      <description>On the dev list I suggested we change the way we manage the empty HBase directory case. Stack answered:Yes. In fact, its probably safe-to-do now we've left far behind thepre-history versions of hbase where there was no hbase.version file in thehbase.rootdir. If absent, lets proceed and just write it rather than treatit as a non-migrated instance</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11951" opendate="2014-9-12 00:00:00" fixdate="2014-9-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create script to update and publish the website, update docs accordingly</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.developer.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11960" opendate="2014-9-12 00:00:00" fixdate="2014-9-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Provide a sample to show how to use Thrift client authentication</summary>
      <description>Now Thrift server can authenticate clients. However, many people asked how to use it. Although we have some info in the refguide, it doesn't mention how to change the client to turn it on. A sample should help.</description>
      <version>None</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.thrift.DemoClient.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.thrift2.DemoClient.java</file>
      <file type="M">hbase-examples.README.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11961" opendate="2014-9-12 00:00:00" fixdate="2014-9-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document region state transitions</summary>
      <description>Document the region state transitions in the refguide.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11963" opendate="2014-9-12 00:00:00" fixdate="2014-9-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Synchronize peer cluster replication connection attempts</summary>
      <description>Synchronize peer cluster connection attempts to avoid races and rate limit connections when multiple replication sources try to connect to the peer cluster. If the peer cluster is down we can get out of control over time.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.7,0.94.24,0.98.6.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.HBaseReplicationEndpoint.java</file>
    </fixedFiles>
  </bug>
  <bug id="11964" opendate="2014-9-12 00:00:00" fixdate="2014-10-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve spreading replication load from failed regionservers</summary>
      <description>Improve replication source thread handling. Improve fanout when transferring queues. Ensure replication sources terminate properly.</description>
      <version>None</version>
      <fixedVersion>0.99.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="12007" opendate="2014-9-17 00:00:00" fixdate="2014-9-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>StochasticBalancer should avoid putting user regions on master</summary>
      <description>We should enhance how StochasticBalancer picks up a random server so that it can avoid putting user regions on master, because regions on master are handled differently in a separate method.</description>
      <version>None</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestRegionRebalancing.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestStochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
    </fixedFiles>
  </bug>
  <bug id="12052" opendate="2014-9-22 00:00:00" fixdate="2014-9-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>BulkLoad Failed due to no write permission on input files</summary>
      <description>The issue is that HBase bulkload is done by Region Server which normally runs under hbase user while the input hfile folder &amp; the user starts the bulkload could be any user.Below is the error message when user "hrt_qa" bulkload files which "hrt_qa" has the write permission while the bulkload operation still fail with "Permission denied" error.We had similar handling for this issue in secure env so the proposed fix is to reuse SecureBulkLoadEndPoint in un-secure env as well. In the future, we can rename the class to BulkLoadEndPoint.java.io.IOException: Exception in rename at org.apache.hadoop.hbase.regionserver.HRegionFileSystem.rename(HRegionFileSystem.java:947) at org.apache.hadoop.hbase.regionserver.HRegionFileSystem.commitStoreFile(HRegionFileSystem.java:347) at org.apache.hadoop.hbase.regionserver.HRegionFileSystem.bulkLoadStoreFile(HRegionFileSystem.java:421) at org.apache.hadoop.hbase.regionserver.HStore.bulkLoadHFile(HStore.java:723) at org.apache.hadoop.hbase.regionserver.HRegion.bulkLoadHFiles(HRegion.java:3603) at org.apache.hadoop.hbase.regionserver.HRegion.bulkLoadHFiles(HRegion.java:3525) at org.apache.hadoop.hbase.regionserver.HRegionServer.bulkLoadHFile(HRegionServer.java:3276) at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:28863) at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2008) at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:92) at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.consumerLoop(SimpleRpcScheduler.java:160) at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.access$000(SimpleRpcScheduler.java:38) at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler$1.run(SimpleRpcScheduler.java:110) at java.lang.Thread.run(Thread.java:662)Caused by: org.apache.hadoop.security.AccessControlException: Permission denied: user=hbase, access=WRITE, inode="/tmp/a0f3ee35-4c8f-4077-93d0-94d8e5bae914/0":hrt_qa:hdfs:drwxr-xr-x at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:265) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:251) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:232) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5515)</description>
      <version>0.99.0,0.98.6</version>
      <fixedVersion>0.98.7,0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.FsDelegationToken.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFilesSplitRecovery.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles.java</file>
    </fixedFiles>
  </bug>
  <bug id="12059" opendate="2014-9-23 00:00:00" fixdate="2014-9-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create hbase-annotations module</summary>
      <description>Different versions of hadoop have different annotations. We can smooth this out by providing our own.</description>
      <version>0.99.0,0.98.6.1</version>
      <fixedVersion>0.98.7,0.99.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.TableState.java</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-thrift.pom.xml</file>
      <file type="M">hbase-testing-util.pom.xml</file>
      <file type="M">hbase-shell.pom.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperMainServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKServerTool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.SortedCopyOnWriteSet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionSizeCalculator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.Merge.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ManualEnvironmentEdge.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.JvmVersion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.JvmPauseMonitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HttpServerUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.hbck.OfflineMetaRepair.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HashedBytes.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSHDFSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.DirectMemoryUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.CompressionTest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.CompoundBloomFilterWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotManifestV1.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.ExportSnapshot.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityLabelService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityLabelFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityExpEvaluator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.ScanLabelGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.ExpressionExpander.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.FsDelegationToken.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.SecurityUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.HbaseObjectWritableFor96Migration.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AuthResult.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.Constants.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.Response.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteAdmin.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.Cluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.Client.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALActionsListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SyncFuture.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.RingBufferTruck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogPrettyPrinter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSWALEntry.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreConfigInformation.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.snapshot.RegionServerSnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.snapshot.FlushSnapshotSubprocedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SimpleRpcSchedulerFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RpcSchedulerFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RowProcessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ReversedRegionScannerImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetaLogRoller.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreChunkPool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HeapMemoryTuner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.BaseRowProcessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.UserQuotaState.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.TimeBasedLimiter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.RegionServerQuotaManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.RateLimiter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaState.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaLimiterFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaLimiter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.OperationQuota.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.NoopQuotaLimiter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.NoopOperationQuota.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.MasterQuotaManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.DefaultOperationQuota.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureCoordinatorRpcs.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.RegionServerProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ProcedureMemberRpcs.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ProcedureManagerHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.MasterProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.flush.FlushTableSubprocedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.StateDumpServlet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotLogCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.MasterSnapshotVerifier.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.EnabledTableSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.DisabledTableSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SnapshotSentinel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionPlan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MetricsMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.MetaServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DispatchMergingRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableSplit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableReduce.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableRecordReaderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableRecordReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableOutputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableMapReduceUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableMap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableInputFormatBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.RowCounter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.IdentityTableReduce.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.IdentityTableMap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.HRegionPartitioner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.GroupingTableMap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.Driver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.WALPlayer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.VisibilityExpressionResolver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TsvImporterTextMapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TsvImporterMapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TextSortReducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableSplit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableReducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableRecordReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableOutputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableOutputCommitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.SimpleTotalOrderPartitioner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.RowCounter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.ResultSerialization.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.PutSortReducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.PutCombiner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.MultiTableOutputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.MultiTableInputFormatBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.MultiTableInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.KeyValueSortReducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.KeyValueSerialization.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.ImportTsv.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.Import.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.IdentityTableReducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.IdentityTableMapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HRegionPartitioner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HFileOutputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.GroupingTableMapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.Export.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.Driver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.DefaultVisibilityExpressionResolver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.CopyTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.CellCreator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.CellCounter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.LocalHBaseCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.UnknownServiceException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServerInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcSchedulerContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcExecutor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcCallContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RequestContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.PriorityFunction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.EmptyServiceNameException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.BufferChain.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.BalancedQueueRpcExecutor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheStats.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CachedBlock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.Cacheable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.package-info.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.IOEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.ByteBufferIOEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocatorException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.BlockPriority.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.BlockCachesIterator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.BlockCacheKey.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.FSDataInputStreamWrapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.ServerConfigurationKeys.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.package-info.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.log.LogLevel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.lib.package-info.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.jmx.package-info.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.HttpServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.HttpConfig.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.FilterInitializer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.conf.ConfServlet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.AdminAuthorizedServlet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HealthReport.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.errorhandling.TimeoutExceptionInjector.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.errorhandling.TimeoutException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.errorhandling.ForeignExceptionSnare.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.errorhandling.ForeignExceptionListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.errorhandling.ForeignException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.WALObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.WALCoprocessorEnvironment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.ObserverContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.EndpointObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseWALObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseRowProcessorEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseRegionServerObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.TableSnapshotScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HTableWrapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.coprocessor.RowProcessorClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.CoprocessorHConnection.java</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-protocol.src.main.java.com.google.protobuf.HBaseZeroCopyByteString.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.util.byterange.impl.ByteRangeTreeSet.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.util.byterange.impl.ByteRangeHashSet.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.scanner.ReversibleCellScanner.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.EncoderPool.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.ArraySearcherPool.java</file>
      <file type="M">hbase-prefix-tree.pom.xml</file>
      <file type="M">hbase-it.pom.xml</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.util.MetricQuantile.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.mapreduce.JobUtil.java</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.testclassification.VerySlowRegionServerTests.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.testclassification.VerySlowMapReduceTests.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.testclassification.SmallTests.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.testclassification.SecurityTests.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.testclassification.RPCTests.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.testclassification.RestTests.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.testclassification.ReplicationTests.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.testclassification.RegionServerTests.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.testclassification.MiscTests.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.testclassification.MediumTests.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.testclassification.MasterTests.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.testclassification.MapReduceTests.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.testclassification.LargeTests.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.testclassification.IOTests.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.testclassification.IntegrationTests.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.testclassification.FlakeyTests.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.testclassification.FilterTests.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.testclassification.CoprocessorTests.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.testclassification.ClientTests.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.VersionInfo.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.SimplePositionedMutableByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.SimplePositionedByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.SimpleMutableByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.PrettyPrinter.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.PositionedByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.PairOfSameType.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Pair.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.OrderedBytes.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Order.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.MurmurHash.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.MD5Hash.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.JenkinsHash.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Hash.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.EnvironmentEdge.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.DefaultEnvironmentEdge.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Counter.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ConcurrentIndex.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Bytes.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteRangeUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteBufferUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Base64.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.Union4.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.Union3.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.Union2.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.TerminatedWrapper.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.StructIterator.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.StructBuilder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.Struct.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawStringTerminated.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawStringFixedLength.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawString.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawShort.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawLong.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawInteger.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawFloat.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawDouble.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawBytesTerminated.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawBytesFixedLength.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawBytes.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawByte.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedString.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedNumeric.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedInt8.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedInt64.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedInt32.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedInt16.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedFloat64.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedFloat32.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedBytesBase.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedBlobVar.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedBlob.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.FixedLengthWrapper.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.DataType.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.TagType.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.Tag.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.TableName.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.security.UserProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.NamespaceDescriptor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.util.StreamUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.TimeRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.TagCompressionContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.SizedCellScanner.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.ImmutableBytesWritable.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.DataBlockEncoding.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.KeyStoreKeyProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.KeyProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.Encryptor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.Encryption.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.DefaultCipherProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.Decryptor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.Context.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.CipherProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.Cipher.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.aes.AESEncryptor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.aes.AESDecryptor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.aes.AES.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.compress.Compression.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.CellOutputStream.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.ByteBufferOutputStream.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HBaseIOException.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HBaseInterfaceAudience.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HBaseConfiguration.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.CodecException.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.BaseEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellScanner.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellScannable.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellComparator.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.Cell.java</file>
      <file type="M">hbase-common.pom.xml</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.HQuorumPeer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ZooKeeperConnectionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.YouAreDeadException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.util.JsonMapper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.util.FileSystemVersionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.UnknownScannerException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.UnknownRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableNotFoundException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableNotEnabledException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableNotDisabledException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableInfoMissingException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableExistsException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.UnknownSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.TablePartiallyOpenException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotExistsException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotDoesNotExistException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotCreationException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.RestoreSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.HBaseSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.CorruptedSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ServerName.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ServerLoad.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.LabelAlreadyExistsException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.InvalidLabelException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.CellVisibility.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.Authorizations.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.EncryptionUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.Permission.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.AccessDeniedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationTrackerZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationStateZKBase.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueuesZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueuesClientZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeerConfig.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationListener.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionTooBusyException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.WrongRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FailedSyncBeforeLogCloseException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FailedLogCloseException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerStoppedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerRunningException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.LeaseException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.BloomType.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionLoad.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.ThrottleType.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.ThrottleSettings.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaType.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaTableUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaSettingsFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaSettings.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaScope.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaRetriever.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.PleaseHoldException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.NotServingRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.NotAllMetaRegionsOnlineException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.NamespaceNotFoundException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.NamespaceExistException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.master.RegionState.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MasterNotRunningException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.WrongVersionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.UnsupportedCompressionCodecException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.UnsupportedCellCodecException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.StoppedRpcClientException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.ServerNotRunningYetException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcControllerFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.PayloadCarryingRpcController.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.IPCUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.FatalConnectionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.DelegatingPayloadCarryingRpcController.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.CoprocessorRpcChannel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.CallerDisconnectedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.BlockingRpcCallback.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.BadAuthException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.InvalidFamilyOperationException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HRegionLocation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.WhileMatchFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ValueFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.TimestampsFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.SubstringComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.SkipFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.SingleColumnValueFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.SingleColumnValueExcludeFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.RowFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.RegexStringComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.RandomRowFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.QualifierFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.PrefixFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ParseFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ParseConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.PageFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.NullComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.MultipleColumnPrefixFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.KeyOnlyFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.InvalidRowFilterException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.IncompatibleFilterException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.InclusiveStopFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FuzzyRowFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FirstKeyValueMatchingQualifiersFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FirstKeyOnlyFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FilterList.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.Filter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FamilyFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.DependentColumnFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.CompareFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ColumnRangeFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ColumnPrefixFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ColumnPaginationFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ColumnCountGetFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ByteArrayComparable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.BitComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.BinaryPrefixComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.BinaryComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.executor.ExecutorType.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.UnknownProtocolException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.RegionOpeningException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.RegionMovedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.RegionInRecoveryException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.OperationConflictException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.MergeRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.LockTimeoutException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.DroppedSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.DoNotRetryIOException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ClusterStatus.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ClockOutOfSyncException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.WrongRowIOException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.UnmodifyableHTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.UnmodifyableHRegionInfo.java</file>
      <file type="M">dev-support.publish.hbase.website.sh</file>
      <file type="M">hbase-client.pom.xml</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Action.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Append.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Attributes.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallReversedScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClusterConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Connection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Consistency.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.Batch.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.DoubleColumnInterpreter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.DelegatingRetryingCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Delete.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Durability.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Get.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnectable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnectionKey.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTableFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTableInterfaceFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTableMultiplexer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Increment.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.IsolationLevel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MasterKeepAliveConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MultiAction.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MultiResponse.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Mutation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.NoServerForRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Operation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.OperationWithAttributes.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Put.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Query.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionOfflineException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.replication.ReplicationAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Result.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ResultScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RetriesExhaustedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RetryingCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Row.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RowMutations.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerTimeoutException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Table.java</file>
    </fixedFiles>
  </bug>
  <bug id="12068" opendate="2014-9-23 00:00:00" fixdate="2014-9-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[Branch-1] Avoid need to always do KeyValueUtil#ensureKeyValue for Filter transformCell</summary>
      <description>During read with Filters added to Scan/Get, the core code calls transformCell(Cell) on the Filter. Most of the filters do not implement transform API so the method from FilterBase will get executed @Override public Cell transformCell(Cell v) throws IOException { // Old filters based off of this class will override KeyValue transform(KeyValue). // Thus to maintain compatibility we need to call the old version. return transform(KeyValueUtil.ensureKeyValue(v)); }Here always it do KeyValueUtil.ensureKeyValue. When a non KV cell comes in, we need recreate KV and do deep copy of key and value!We have to stick with this model in branch-1 for BC.So as a workaround to avoid possible KV convert, we can implement transformCell(Cell) method in all of our individual Filter classes which just return the incoming cell (So that method from FilterBase wont get executed)</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.upgrading.xml</file>
    </fixedFiles>
  </bug>
  <bug id="12082" opendate="2014-9-24 00:00:00" fixdate="2014-9-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Find a way to set timestamp on Cells on the server</summary>
      <description>On write path, we have to replace the ts on cells when the coming in ts is HConstants.LATEST_TIMESTAMP. Also on delete version cells we have to adjust the ts. All these places, now we do Cell to KV convert.We can provide a similar way as we have given for setting seqId</description>
      <version>0.99.0</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MultiRowMutationProcessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="12145" opendate="2014-10-1 00:00:00" fixdate="2014-10-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix javadoc and findbugs so new folks aren&amp;#39;t freaked when they see them</summary>
      <description>Misc set of fixes to get these attributes green again.</description>
      <version>None</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.SchemaResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RowTooBigException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.RatioBasedCompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableRecordReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.PrettyPrinter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeersZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionAdminServiceCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="12279" opendate="2014-10-16 00:00:00" fixdate="2014-11-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Generated thrift files were generated with the wrong parameters</summary>
      <description>It turns out that the java code generated from the thrift files have been generated with the wrong settings.Instead of the documented (thrift, thrift2) thrift -strict --gen java:hashcode the current files seem to be generated instead withthrift -strict --gen java</description>
      <version>0.94.0,0.98.0,0.99.0</version>
      <fixedVersion>0.98.8,0.94.26,0.99.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TScan.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TRowResult.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TRegionInfo.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TIncrement.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TColumn.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TCell.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TAppend.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.Mutation.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.IOError.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.IllegalArgument.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.Hbase.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.ColumnDescriptor.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.BatchMutation.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.AlreadyExists.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TTimeRange.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TScan.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TRowMutations.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TResult.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TPut.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TMutation.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIOError.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIncrement.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIllegalArgument.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.THBaseService.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TGet.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TDelete.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumnValue.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumnIncrement.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumn.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TCellVisibility.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TAuthorization.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TAppend.java</file>
    </fixedFiles>
  </bug>
  <bug id="12343" opendate="2014-10-24 00:00:00" fixdate="2014-11-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document recommended configuration for 0.98 from HBASE-11964</summary>
      <description>We're not committing the configuration changes from HBASE-11964 to 0.98 but they should be the recommend configuration for replication. Add a paragraph to the replication section of the manual on this.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  <bug id="12345" opendate="2014-10-25 00:00:00" fixdate="2014-6-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unsafe based ByteBuffer Comparator</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.UnsafeAccess.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteBufferUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="12444" opendate="2014-11-7 00:00:00" fixdate="2014-12-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Total number of requests overflow because it&amp;#39;s int</summary>
      <description>When running hbck, I noticed "Number of requests" was wrong:Average load: 466.41237113402065Number of requests: -1835941345Number of regions: 45242Number of regions in transition: 0The root cause is it use int, and clearly it overflowed.I'll update a patch later.</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.StorageClusterStatusResource.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.StorageClusterStatusModel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ClusterStatus.java</file>
    </fixedFiles>
  </bug>
  <bug id="12445" opendate="2014-11-7 00:00:00" fixdate="2014-11-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase is removing all remaining cells immediately after the cell marked with marker = KeyValue.Type.DeleteColumn via PUT</summary>
      <description>Code executed: @Test public void testHbasePutDeleteCell() throws Exception { TableName tableName = TableName.valueOf("my_test"); Configuration configuration = HBaseConfiguration.create(); HTableInterface table = new HTable(configuration, tableName); final String rowKey = "12345"; final byte[] familly = Bytes.toBytes("default"); // put one row Put put = new Put(rowKey); put.add(family, Bytes.toBytes("A"), Bytes.toBytes("a")); put.add(family, Bytes.toBytes("B"), Bytes.toBytes("b")); put.add(family, Bytes.toBytes("C"), Bytes.toBytes("c")); put.add(family, Bytes.toBytes("D"), Bytes.toBytes("d")); table.put(put); // get row back and assert the values Get get = new Get(rowKey); Result result = table.get(get); assertTrue("Column A value should be a", Bytes.toString(result.getValue(family, Bytes.toBytes("A"))).equals("a")); assertTrue("Column B value should be b", Bytes.toString(result.getValue(family, Bytes.toBytes("B"))).equals("b")); assertTrue("Column C value should be c", Bytes.toString(result.getValue(family, Bytes.toBytes("C"))).equals("c")); assertTrue("Column D value should be d", Bytes.toString(result.getValue(family, Bytes.toBytes("D"))).equals("d")); // put the same row again with C column deleted put = new Put(rowKey); put.add(family, Bytes.toBytes("A"), Bytes.toBytes("a1")); put.add(family, Bytes.toBytes("B"), Bytes.toBytes("b1")); KeyValue marker = new KeyValue(rowKey, family, Bytes.toBytes("C"), HConstants.LATEST_TIMESTAMP, KeyValue.Type.DeleteColumn); put.add(marker); put.add(family, Bytes.toBytes("D"), Bytes.toBytes("d1")); table.put(put); // get row back and assert the values get = new Get(rowKey); result = table.get(get); assertTrue("Column A value should be a1", Bytes.toString(result.getValue(family, Bytes.toBytes("A"))).equals("a1")); assertTrue("Column B value should be b1", Bytes.toString(result.getValue(family, Bytes.toBytes("B"))).equals("b1")); assertTrue("Column C should not exist", result.getValue(family, Bytes.toBytes("C")) == null); assertTrue("Column D value should be d1", Bytes.toString(result.getValue(family, Bytes.toBytes("D"))).equals("d1")); }This assertion fails, the cell D is also deleted</description>
      <version>None</version>
      <fixedVersion>0.98.8,0.99.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestPutWithDelete.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="15672" opendate="2016-4-18 00:00:00" fixdate="2016-4-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hadoop.hbase.security.visibility.TestVisibilityLabelsWithDeletes fails</summary>
      <description>016-04-18 15:02:50,632 WARN &amp;#91;member: &amp;#39;10.22.11.177,55156,1461016964801&amp;#39; subprocedure-pool5-thread-1&amp;#93; flush.RegionServerFlushTableProcedureManager$FlushTableSubprocedurePool(275): Got Exception in FlushSubprocedurePooljava.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: Timestamp cannot be negative. minStamp:-9223372036854775808, maxStamp:128 at java.util.concurrent.FutureTask.report(FutureTask.java:122) at java.util.concurrent.FutureTask.get(FutureTask.java:188) at org.apache.hadoop.hbase.procedure.flush.RegionServerFlushTableProcedureManager$FlushTableSubprocedurePool.waitForOutstandingTasks(RegionServerFlushTableProcedureManager.java:251) at org.apache.hadoop.hbase.procedure.flush.FlushTableSubprocedure.flushRegions(FlushTableSubprocedure.java:102) at org.apache.hadoop.hbase.procedure.flush.FlushTableSubprocedure.acquireBarrier(FlushTableSubprocedure.java:113) at org.apache.hadoop.hbase.procedure.Subprocedure.call(Subprocedure.java:166) at org.apache.hadoop.hbase.procedure.Subprocedure.call(Subprocedure.java:1) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.IllegalArgumentException: Timestamp cannot be negative. minStamp:-9223372036854775808, maxStamp:128 at org.apache.hadoop.hbase.io.TimeRange.&lt;init&gt;(TimeRange.java:81) at org.apache.hadoop.hbase.regionserver.TimeRangeTracker.toTimeRange(TimeRangeTracker.java:204) at org.apache.hadoop.hbase.regionserver.ImmutableSegment.&lt;init&gt;(ImmutableSegment.java:44) at org.apache.hadoop.hbase.regionserver.SegmentFactory.createImmutableSegment(SegmentFactory.java:57) at org.apache.hadoop.hbase.regionserver.DefaultMemStore.snapshot(DefaultMemStore.java:93) at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.prepare(HStore.java:2151) at org.apache.hadoop.hbase.regionserver.HRegion.internalPrepareFlushCache(HRegion.java:2324) at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2192) at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2163) at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:2054) at org.apache.hadoop.hbase.regionserver.HRegion.flush(HRegion.java:1980) at org.apache.hadoop.hbase.procedure.flush.FlushTableSubprocedure$RegionFlushTask.call(FlushTableSubprocedure.java:68) at org.apache.hadoop.hbase.procedure.flush.FlushTableSubprocedure$RegionFlushTask.call(FlushTableSubprocedure.java:1) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)</description>
      <version>0.99.0,0.98.4</version>
      <fixedVersion>1.3.0,0.98.19,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityController.java</file>
    </fixedFiles>
  </bug>
  <bug id="15673" opendate="2016-4-18 00:00:00" fixdate="2016-4-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[PE tool] Fix latency metrics for multiGet</summary>
      <description>we write out latency value after each row is processes by testRow() function. But if multiget is enabled, say set to 10, testRow() returns immediately for 9 rows and sends out request in the 10th iteration. This screws up latency metrics (50th, 75th, 90th percentiles are all 0).</description>
      <version>None</version>
      <fixedVersion>1.3.0,0.98.19,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
    </fixedFiles>
  </bug>
  <bug id="4625" opendate="2011-10-19 00:00:00" fixdate="2011-11-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Convert @deprecated HBaseTestCase tests JUnit4 style tests</summary>
      <description>This will class has 47 references so separating out into a separate subtask.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestMergeTool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestWideScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreFileInfo.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestScanWildcardColumnTracker.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestScanDeleteTracker.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestQueryMatcher.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestKeyValueHeap.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestGetClosestAtOrBefore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestBlocksScanned.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestBlocksRead.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestSeekTo.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFile.java</file>
    </fixedFiles>
  </bug>
  <bug id="4626" opendate="2011-10-19 00:00:00" fixdate="2011-10-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Filters unnecessarily copy byte arrays...</summary>
      <description>Just looked at SingleCol and ValueFilter... And on every column compared they create a copy of the column and/or value portion of the KV.</description>
      <version>None</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.WritableByteArrayComparable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.SubstringComparator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.SingleColumnValueFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.RegexStringComparator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.NullComparator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.CompareFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.BitComparator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.BinaryPrefixComparator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.BinaryComparator.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4955" opendate="2011-12-5 00:00:00" fixdate="2011-8-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use the official versions of surefire &amp; junit</summary>
      <description>We currently use private versions for Surefire &amp; JUnit since HBASE-4763.This JIRA traks what we need to move to official versions.Surefire 2.11 is just out, but, after some tests, it does not contain all what we need.JUnit. Could be for JUnit 4.11. Issue to monitor:https://github.com/KentBeck/junit/issues/359: fixed in our version, no feedback for an integration on trunkSurefire: Could be for Surefire 2.12. Issues to monitor are:329 (category support): fixed, we use the official implementation from the trunk786 (@Category with forkMode=always): fixed, we use the official implementation from the trunk791 (incorrect elapsed time on test failure): fixed, we use the official implementation from the trunk793 (incorrect time in the XML report): Not fixed (reopen) on trunk, fixed on our version.760 (does not take into account the test method): fixed in trunk, not fixed in our version798 (print immediately the test class name): not fixed in trunk, not fixed in our version799 (Allow test parallelization when forkMode=always): not fixed in trunk, not fixed in our version800 (redirectTestOutputToFile not taken into account): not yet fix on trunk, fixed on our version800 &amp; 793 are the more important to monitor, it's the only ones that are fixed in our version but not on trunk.</description>
      <version>0.94.0,0.98.0,0.96.0,0.99.0</version>
      <fixedVersion>0.99.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.http.TestServletFilter.java</file>
    </fixedFiles>
  </bug>
  <bug id="4956" opendate="2011-12-5 00:00:00" fixdate="2011-7-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Control direct memory buffer consumption by HBaseClient</summary>
      <description>As Jonathan explained here https://groups.google.com/group/asynchbase/browse_thread/thread/c45bc7ba788b2357?pli=1 , standard hbase client inadvertently consumes large amount of direct memory.We should consider using netty for NIO-related tasks.</description>
      <version>None</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Result.java</file>
    </fixedFiles>
  </bug>
  <bug id="886" opendate="2008-9-16 00:00:00" fixdate="2008-9-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Sort the tables in the web UI</summary>
      <description>From the list:hi all,I just thought that it would be great if you could addArrays.sort(tables);in master.jsp somwhere near"&lt;% HTableDescriptor[] tables = new HBaseAdmin(conf).listTables(); if(tables != null &amp;&amp; tables.length &gt; 0) { %&gt;"it is really annoying if one have to find a table in an unsorted list krzysiek</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9020" opendate="2013-7-22 00:00:00" fixdate="2013-7-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make hbase-it HBASE_HOME configurable</summary>
      <description>For hbase-it test, it assumes the test runs on a box with HBASE_HOME the same as that on the cluster. However, I generally run the client/driver on my dev box which has different HBASE_HOME as that on my cluster. It will be helpful if I can specify the remote hbase home via some configuration.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.HBaseClusterManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="9346" opendate="2013-8-26 00:00:00" fixdate="2013-12-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBCK should provide an option to check if regions boundaries are the same in META and in stores.</summary>
      <description>If META don't have the same region boundaries as the stores files, writes and read might go to the wrong place. We need to provide a way to check that withing HBCK.</description>
      <version>0.94.14,0.98.1,0.99.0,0.96.1.1</version>
      <fixedVersion>0.98.0,0.94.16,0.96.2,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="9406" opendate="2013-8-31 00:00:00" fixdate="2013-8-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document 0.96 migration</summary>
      <description>himanshu@cloudera.com posted doc on the parent issue. This is about integrating it into the refguide.</description>
      <version>None</version>
      <fixedVersion>0.96.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.upgrading.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9473" opendate="2013-9-9 00:00:00" fixdate="2013-9-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change UI to list &amp;#39;system tables&amp;#39; rather than &amp;#39;catalog tables&amp;#39;.</summary>
      <description>Minor, one-line, bit of polishing.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="9476" opendate="2013-9-9 00:00:00" fixdate="2013-9-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Yet more master log cleanup</summary>
      <description>Even more cleanup, tightening, of log output (was staring at some over the last day..)</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.OpenedRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKAssign.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
    </fixedFiles>
  </bug>
</bugrepository>
