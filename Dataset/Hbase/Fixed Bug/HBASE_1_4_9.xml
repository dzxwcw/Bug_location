<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="21547" opendate="2018-12-4 00:00:00" fixdate="2018-1-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Precommit uses master flaky list for other branches</summary>
      <description>Precommit job downloads the flaky exclude list for master branch when the uploaded patch file is made for different branches.As an example check https://builds.apache.org/job/PreCommit-HBASE-Build/15192 which was against branch-1 but the unit test downloaded master's flaky list.15:26:05 [Tue Dec 4 14:26:04 UTC 2018 INFO]: Personality: patch unit15:26:05 [Tue Dec 4 14:26:04 UTC 2018 INFO]: EXCLUDE_TESTS_URL=https://builds.apache.org/job/HBase-Find-Flaky-Tests/job/master/lastSuccessfulBuild/artifact/excludes/15:26:05 [Tue Dec 4 14:26:04 UTC 2018 INFO]: INCLUDE_TESTS_URL=15:26:05 --2018-12-04 14:26:04-- https://builds.apache.org/job/HBase-Find-Flaky-Tests/job/master/lastSuccessfulBuild/artifact/excludes/15:26:05 Resolving builds.apache.org (builds.apache.org)... 195.201.213.130, 2a01:4f8:c0:2cc9::215:26:05 Connecting to builds.apache.org (builds.apache.org)|195.201.213.130|:443... connected.15:26:06 HTTP request sent, awaiting response... 200 15:26:06 Length: 866 [application/octet-stream]15:26:06 Saving to: 'excludes'15:26:06 15:26:06 0K 100% 43.0M=0s15:26:06 15:26:06 2018-12-04 14:26:06 (43.0 MB/s) - 'excludes' saved [866/866]15:26:06 15:26:09 cd /testptch/hbase/hbase-thrift15:26:09 mvn --batch-mode -Dmaven.repo.local=/home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/yetus-m2/hbase-branch-1-patch-1 -DHBasePatchProcess -Dhttps.protocols=TLSv1.2 -PrunAllTests -Dtest.exclude.pattern=**/master.cleaner.TestSnapshotFromMaster.java,**/client.TestRestoreSnapshotFromClientAfterSplittingRegions.java,**/regionserver.TestRegionMergeTransactionOnCluster.java,**/client.TestCloneSnapshotFromClientAfterSplittingRegion.java,**/master.assignment.TestAssignmentManager.java,**/master.assignment.TestAMAssignWithRandExec.java,**/client.TestMobCloneSnapshotFromClientAfterSplittingRegion.java,**/regionserver.TestCompactingToCellFlatMapMemStore.java,**/replication.TestReplicationSmallTestsSync.java,**/TestMultiVersions.java,**/client.TestMobRestoreSnapshotFromClientAfterSplittingRegions.java,**/client.TestRestoreSnapshotFromClientWithRegionReplicas.java,**/regionserver.TestRegionServerAbortTimeout.java,**/replication.TestMasterReplication.java,**/backup.TestIncrementalBackupWithBulkLoad.java,**/master.replication.TestRegisterPeerWorkerWhenRestarting.java clean test -fae &gt; /testptch/patchprocess/patch-unit-hbase-thrift.txt 2&gt;&amp;1</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,1.2.10,1.4.10,2.1.3,2.0.5,1.3.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  <bug id="2155" opendate="2010-1-22 00:00:00" fixdate="2010-8-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add the option to bind to a specific IP address to the Nonblocking Thrift servers</summary>
      <description>This is not possible in Thrift 0.2.0 so we'll have to wait until the next version is released (which includes THRIFT-684). After that is released this is an easy and quick fix. For a few more details see HBASE-1373 and HBASE-65.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="21791" opendate="2019-1-27 00:00:00" fixdate="2019-1-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade thrift dependency to 0.12.0</summary>
      <description>As somebody have already known, that there is a CVE for thrift from 0.5.0 to 0.11.0.https://nvd.nist.gov/vuln/detail/CVE-2018-1320As the CVE is already public, let's upgrade our thrift dependency and release new versions ASAP.</description>
      <version>3.0.0-alpha-1,1.5.0,1.3.3,2.2.0,1.4.9,2.1.2,1.2.10,2.0.4</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.2.0,2.1.3,2.0.5,2.3.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TScan.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TRowResult.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TRegionInfo.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TIncrement.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TColumn.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TCell.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TAppend.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.Mutation.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.IOError.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.IllegalArgument.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.Hbase.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.ColumnDescriptor.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.BatchMutation.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.AlreadyExists.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TTimeRange.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TTableName.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TTableDescriptor.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TServerName.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TScan.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TRowMutations.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TResult.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TReadType.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TPut.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TNamespaceDescriptor.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TMutation.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TKeepDeletedCells.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIOError.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIncrement.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIllegalArgument.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.THRegionLocation.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.THRegionInfo.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.THBaseService.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TGet.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TDurability.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TDeleteType.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TDelete.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TDataBlockEncoding.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TConsistency.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TCompressionAlgorithm.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TCompareOp.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumnValue.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumnIncrement.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumnFamilyDescriptor.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumn.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TCellVisibility.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TBloomFilterType.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TAuthorization.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TAppend.java</file>
    </fixedFiles>
  </bug>
  <bug id="21794" opendate="2019-1-27 00:00:00" fixdate="2019-2-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update the Coprocessor observer example given in section 111.1 of the ref guide.</summary>
      <description>The given example should be changed after the CP changes (HBASE-17732)</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.cp.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="21795" opendate="2019-1-28 00:00:00" fixdate="2019-2-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Client application may get stuck (time bound) if a table modify op is called immediately after split op</summary>
      <description>Steps: Create a table Split the table Modify the table immediately after splittingExpected: The modify table procedure completes and control returns back to clientActual: The modify table procedure completes and control does not return back to client, until catalog janitor runs and deletes parent or future timeout occurs</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.3,2.0.5,2.3.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="21806" opendate="2019-1-29 00:00:00" fixdate="2019-1-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>add an option to roll WAL on very slow syncs</summary>
      <description>In large heterogeneous clusters sometimes a slow datanode can cause WAL syncs to be very slow. In this case, before the bad datanode recovers, or is discovered and repaired, it would be helpful to roll WAL on a very slow sync to get a new pipeline.Otherwise the slow WAL will impact write latency for a long time (slow writes result in less writes result in the WAL not being rolled for longer)</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutput.java</file>
    </fixedFiles>
  </bug>
  <bug id="2222" opendate="2010-2-12 00:00:00" fixdate="2010-2-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve log "Trying to contact region server Some server for region , row &amp;#39;ip_info_100,,1263329969690&amp;#39;, but failed after 11 attempts."</summary>
      <description>Get the table we're trying to do lookup on in there at least and tell it like it is, that nothing was found for and the asked-for lookup.</description>
      <version>None</version>
      <fixedVersion>0.20.4,0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="22272" opendate="2019-4-19 00:00:00" fixdate="2019-4-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix Checkstyle errors in hbase-backup</summary>
      <description>There are a few Checkstyle errors in hbase-backup, which should be fixed.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-backup.src.test.java.org.apache.hadoop.hbase.backup.TestBackupMerge.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupSystemTable.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupCommands.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.BackupDriver.java</file>
    </fixedFiles>
  </bug>
  <bug id="22285" opendate="2019-4-22 00:00:00" fixdate="2019-3-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>A normalizer which merges very small size regions with adjacent regions.(MergeToNormalize)</summary>
      <description>There are scenarios where we have seen around 5% of total regions with a size of 0 bytes and another 5-6 % regions with size in a few bytes. These kinds of regions increase with time considering we have TTL over the rows. After exploring the option of RegionNormalizer and doing some quick runs we found that that is not suitable considering it also splits the regions and merges to normalize. What we really want is to split as per Split policy and merge very small regions with adjacent regions to make sure we reduce 0-byte regions.We can plugin this normalizer using the property "hbase.master.normalizer.class"</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.normalizer.SimpleRegionNormalizer.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="22291" opendate="2019-4-22 00:00:00" fixdate="2019-4-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix recovery of recovered.edits files under root dir</summary>
      <description>It looks like a few places are using incorrect FS instances in the replayRecoveredEditsForPath method that was introduced in HBASE-20734.</description>
      <version>1.4.9</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,1.4.10,2.3.0,2.1.5,1.3.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="22311" opendate="2019-4-25 00:00:00" fixdate="2019-5-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update community docs to recommend use of "Co-authored-by" in git commits</summary>
      <description>discussion on [DISCUSS] switch from "Ammending-Author" to "Co-authored-by" in commit messages seems to have out in favor. Updated section should include a brief explanation (that includes "multiple authors" expressly instead of just the "fixed up this thing" that's there for Amending-Author). It should also have pointers to the github feature explanation. So long as those docs exist they're pretty good.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="2244" opendate="2010-2-20 00:00:00" fixdate="2010-3-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>META gets inconsistent in a number of crash scenarios</summary>
      <description>(Forking this issue off from HBASE-2235).During load testing, in a number of failure scenarios (unexpected region server deaths) etc., we notice that META can get inconsistent. This primarily happens for regions which are in the process of being split. Manually running add_table.rb seems to fix the tables meta data just fine. But it would be good to do automatic cleansing (as part of META scanners work) and/or avoid these inconsistent states altogether.For example, for a particular startkey, I see all these entries:test1,1204765,1266569946560 column=info:regioninfo, timestamp=1266581302018, value=REGION =&gt; {NAME =&gt; 'test1, 1204765,1266569946560', STARTKEY =&gt; '1204765', ENDKEY =&gt; '1441091', ENCODED =&gt; 18 19368969, OFFLINE =&gt; true, SPLIT =&gt; true, TABLE =&gt; {{NAME =&gt; 'test1', FAMILIES =&gt; [{NAME =&gt; 'actions', VERSIONS =&gt; '3', COMPRESSION =&gt; 'NONE', TTL =&gt; '2147483647' , BLOCKSIZE =&gt; '65536', IN_MEMORY =&gt; 'false', BLOCKCACHE =&gt; 'true'}]}} test1,1204765,1266569946560 column=info:server, timestamp=1266570029133, value=10.129.68.212:60020 test1,1204765,1266569946560 column=info:serverstartcode, timestamp=1266570029133, value=1266562597546 test1,1204765,1266569946560 column=info:splitB, timestamp=1266581302018, value=\x00\x071441091\x00\x00\x00\x0 1\x26\xE6\x1F\xDF\x27\x1Btest1,1290703,1266581233447\x00\x071290703\x00\x00\x00\x 05\x05test1\x00\x00\x00\x00\x00\x02\x00\x00\x00\x07IS_ROOT\x00\x00\x00\x05false\x 00\x00\x00\x07IS_META\x00\x00\x00\x05false\x00\x00\x00\x01\x07\x07actions\x00\x00 \x00\x07\x00\x00\x00\x0BBLOOMFILTER\x00\x00\x00\x05false\x00\x00\x00\x0BCOMPRESSI ON\x00\x00\x00\x04NONE\x00\x00\x00\x08VERSIONS\x00\x00\x00\x013\x00\x00\x00\x03TT L\x00\x00\x00\x0A2147483647\x00\x00\x00\x09BLOCKSIZE\x00\x00\x00\x0565536\x00\x00 \x00\x09IN_MEMORY\x00\x00\x00\x05false\x00\x00\x00\x0ABLOCKCACHE\x00\x00\x00\x04t rueh\x0FQ\xCF test1,1204765,1266581233447 column=info:regioninfo, timestamp=1266609172177, value=REGION =&gt; {NAME =&gt; 'test1, 1204765,1266581233447', STARTKEY =&gt; '1204765', ENDKEY =&gt; '1290703', ENCODED =&gt; 13 73493090, OFFLINE =&gt; true, SPLIT =&gt; true, TABLE =&gt; {{NAME =&gt; 'test1', FAMILIES =&gt; [{NAME =&gt; 'actions', VERSIONS =&gt; '3', COMPRESSION =&gt; 'NONE', TTL =&gt; '2147483647' , BLOCKSIZE =&gt; '65536', IN_MEMORY =&gt; 'false', BLOCKCACHE =&gt; 'true'}]}} test1,1204765,1266581233447 column=info:server, timestamp=1266604768670, value=10.129.68.213:60020 test1,1204765,1266581233447 column=info:serverstartcode, timestamp=1266604768670, value=1266562597511 test1,1204765,1266581233447 column=info:splitA, timestamp=1266609172177, value=\x00\x071226169\x00\x00\x00\x0 1\x26\xE7\xCA,\x7D\x1Btest1,1204765,1266609171581\x00\x071204765\x00\x00\x00\x05\ x05test1\x00\x00\x00\x00\x00\x02\x00\x00\x00\x07IS_ROOT\x00\x00\x00\x05false\x00\ x00\x00\x07IS_META\x00\x00\x00\x05false\x00\x00\x00\x01\x07\x07actions\x00\x00\x0 0\x07\x00\x00\x00\x0BBLOOMFILTER\x00\x00\x00\x05false\x00\x00\x00\x0BCOMPRESSION\ x00\x00\x00\x04NONE\x00\x00\x00\x08VERSIONS\x00\x00\x00\x013\x00\x00\x00\x03TTL\x 00\x00\x00\x0A2147483647\x00\x00\x00\x09BLOCKSIZE\x00\x00\x00\x0565536\x00\x00\x0 0\x09IN_MEMORY\x00\x00\x00\x05false\x00\x00\x00\x0ABLOCKCACHE\x00\x00\x00\x04true \xB9\xBD\xFEO test1,1204765,1266581233447 column=info:splitB, timestamp=1266609172177, value=\x00\x071290703\x00\x00\x00\x0 1\x26\xE7\xCA,\x7D\x1Btest1,1226169,1266609171581\x00\x071226169\x00\x00\x00\x05\ x05test1\x00\x00\x00\x00\x00\x02\x00\x00\x00\x07IS_ROOT\x00\x00\x00\x05false\x00\ x00\x00\x07IS_META\x00\x00\x00\x05false\x00\x00\x00\x01\x07\x07actions\x00\x00\x0 0\x07\x00\x00\x00\x0BBLOOMFILTER\x00\x00\x00\x05false\x00\x00\x00\x0BCOMPRESSION\ x00\x00\x00\x04NONE\x00\x00\x00\x08VERSIONS\x00\x00\x00\x013\x00\x00\x00\x03TTL\x 00\x00\x00\x0A2147483647\x00\x00\x00\x09BLOCKSIZE\x00\x00\x00\x0565536\x00\x00\x0 0\x09IN_MEMORY\x00\x00\x00\x05false\x00\x00\x00\x0ABLOCKCACHE\x00\x00\x00\x04true \xE1\xDF\xF8p test1,1204765,1266609171581 column=info:regioninfo, timestamp=1266609172212, value=REGION =&gt; {NAME =&gt; 'test1, 1204765,1266609171581', STARTKEY =&gt; '1204765', ENDKEY =&gt; '1226169', ENCODED =&gt; 21 34878372, TABLE =&gt; {{NAME =&gt; 'test1', FAMILIES =&gt; [{NAME =&gt; 'actions', VERSIONS = &gt; '3', COMPRESSION =&gt; 'NONE', TTL =&gt; '2147483647', BLOCKSIZE =&gt; '65536', IN_MEMOR Y =&gt; 'false', BLOCKCACHE =&gt; 'true'}]}}</description>
      <version>None</version>
      <fixedVersion>0.20.4,0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.BaseScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="22449" opendate="2019-5-21 00:00:00" fixdate="2019-5-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>https everywhere in Maven metadata</summary>
      <description>There will be some attention paid to insecure URLs used for retrieval of build dependencies. While our build does not have direct exposure to this we do have some insecure URLs pointing to secondary resources like JIRA, mailing list archives, hbase.apache.org, and the online book. Make these https too. I left the license header text alone, although there is a URL to the ASL 2 license embedded there. If we are going to update that, let's do that as a separate task because just about every file is going to be touched.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,1.4.10,2.3.0,2.1.5,1.3.5</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-zookeeper.pom.xml</file>
      <file type="M">hbase-thrift.pom.xml</file>
      <file type="M">hbase-testing-util.pom.xml</file>
      <file type="M">hbase-shell.pom.xml</file>
      <file type="M">hbase-shaded.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-with-hadoop-check-invariants.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-mapreduce.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-client.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-client-byo-hadoop.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-check-invariants.pom.xml</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-rsgroup.pom.xml</file>
      <file type="M">hbase-rest.pom.xml</file>
      <file type="M">hbase-resource-bundle.pom.xml</file>
      <file type="M">hbase-replication.pom.xml</file>
      <file type="M">hbase-protocol.pom.xml</file>
      <file type="M">hbase-protocol-shaded.pom.xml</file>
      <file type="M">hbase-procedure.pom.xml</file>
      <file type="M">hbase-metrics.pom.xml</file>
      <file type="M">hbase-metrics-api.pom.xml</file>
      <file type="M">hbase-mapreduce.pom.xml</file>
      <file type="M">hbase-it.pom.xml</file>
      <file type="M">hbase-http.pom.xml</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-hadoop-compat.pom.xml</file>
      <file type="M">hbase-external-blockcache.pom.xml</file>
      <file type="M">hbase-examples.pom.xml</file>
      <file type="M">hbase-endpoint.pom.xml</file>
      <file type="M">hbase-common.pom.xml</file>
      <file type="M">hbase-client.pom.xml</file>
      <file type="M">hbase-checkstyle.pom.xml</file>
      <file type="M">hbase-build-configuration.pom.xml</file>
      <file type="M">hbase-backup.pom.xml</file>
      <file type="M">hbase-assembly.pom.xml</file>
      <file type="M">hbase-archetypes.pom.xml</file>
      <file type="M">hbase-archetypes.hbase-shaded-client-project.pom.xml</file>
      <file type="M">hbase-archetypes.hbase-client-project.pom.xml</file>
      <file type="M">hbase-archetypes.hbase-archetype-builder.pom.xml</file>
      <file type="M">hbase-annotations.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="22617" opendate="2019-6-22 00:00:00" fixdate="2019-6-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Recovered WAL directories not getting cleaned up</summary>
      <description>While colocating the recovered edits directory with hbase.wal.dir, BASE_NAMESPACE_DIR got missed. This results in recovered edits being put in a separate directory rather than the default region directory even if the hbase.wal.dir is not overridden. Eg. if data is stored in /hbase/data/namespace/table1, recovered edits are put in  /hbase/namespace/table1. This also messes up the regular cleaner chores which never operate on this new directory and these directories will never be deleted, even for split parents or dropped tables. We should change the default back to have the base namespace directory in path.</description>
      <version>1.3.3,2.2.0,1.4.8,2.1.1,1.4.9,2.1.2,1.4.10,2.1.3,1.3.4,2.1.4,2.1.5,1.3.5</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.0.6,2.2.1,2.1.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRecoveredEdits.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestTruncateTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestCreateTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestHFileArchiving.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALSplitUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DisableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.SplitTableRegionProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.RegionStateStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.MergeTableRegionsProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.GCRegionProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.HFileArchiver.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.CommonFSUtils.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.util.BackupUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="22624" opendate="2019-6-25 00:00:00" fixdate="2019-7-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Should sanity check table configuration when clone snapshot to a new table</summary>
      <description>HBASE-12570 imporved table configuration sanity checking. But it only worked for create table or alter table. Should check table configuration too when clone snapshot to a new table.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift.TestThriftSpnegoHttpServer.java</file>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift.TestThriftServerCmdLine.java</file>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift.TestThriftServer.java</file>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift.TestThriftHttpServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerMetrics.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestModifyTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestCreateTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSizeFailures.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestIncrementsFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestIncrementFromClientSideWithCoprocessor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestIllegalTableDescriptor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestBlockEvictionFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAvoidCellReferencesIntoShippedBlocks.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestRegionReplicaReplication.java</file>
    </fixedFiles>
  </bug>
  <bug id="22625" opendate="2019-6-25 00:00:00" fixdate="2019-8-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>documet use scan snapshot feature</summary>
      <description>Add the design doc in dev-support/design-docs{{ and describe }}the feature in the reference guide.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc.book.adoc</file>
      <file type="M">src.main.asciidoc..chapters.snapshot.scanner.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="22785" opendate="2019-8-3 00:00:00" fixdate="2019-8-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reduce number of Checkstyle issues in client exceptions</summary>
      <description>The exceptions in the client module have some Checkstyle issues. Also, the Javadocs should be extended and enhanced.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,2.0.6,2.2.1,2.1.6,1.3.6,1.4.11</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ZooKeeperConnectionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.YouAreDeadException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.UnknownScannerException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.UnknownRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableNotFoundException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableNotEnabledException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableNotDisabledException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableInfoMissingException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableExistsException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.NotServingRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.DroppedSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.DoNotRetryIOException.java</file>
    </fixedFiles>
  </bug>
  <bug id="22786" opendate="2019-8-3 00:00:00" fixdate="2019-8-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix Checkstyle issues in tests of hbase-client</summary>
      <description>The hbase-client module has some Checkstyle issues in its tests, which should get fixed.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,2.0.6,2.2.1,2.1.6,1.3.6,1.4.11</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.util.BuilderStyleTest.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.TestHTableDescriptor.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.TestHColumnDescriptor.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.shaded.protobuf.TestProtobufUtil.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.quotas.TestQuotaSettingsFactory.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.quotas.TestQuotaFilter.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.ipc.TestHBaseRpcControllerImpl.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.ipc.TestCellBlockBuilder.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.filter.TestLongComparator.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.exceptions.TestClientExceptionsUtil.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestTableDescriptorBuilder.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestScan.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestOperation.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestMetricsConnection.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestGet.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestColumnFamilyDescriptorBuilder.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestClientExponentialBackoff.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestAttributes.java</file>
    </fixedFiles>
  </bug>
  <bug id="22787" opendate="2019-8-3 00:00:00" fixdate="2019-8-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up of tests in hbase-zookeeper</summary>
      <description>The tests in the hbase-zookeeper module can be cleaned up in several ways, starting with simplifying some of the assertions and reduce the visibility of some fields, methods and helper classes.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.0.6,2.2.1,2.1.6</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-zookeeper.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKUtilNoServer.java</file>
      <file type="M">hbase-zookeeper.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKUtil.java</file>
      <file type="M">hbase-zookeeper.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKNodeTracker.java</file>
      <file type="M">hbase-zookeeper.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKMulti.java</file>
      <file type="M">hbase-zookeeper.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKMainServer.java</file>
      <file type="M">hbase-zookeeper.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKLeaderManager.java</file>
      <file type="M">hbase-zookeeper.src.test.java.org.apache.hadoop.hbase.zookeeper.TestRecoverableZooKeeper.java</file>
      <file type="M">hbase-zookeeper.src.test.java.org.apache.hadoop.hbase.zookeeper.TestReadOnlyZKClient.java</file>
      <file type="M">hbase-zookeeper.src.test.java.org.apache.hadoop.hbase.zookeeper.TestHQuorumPeer.java</file>
      <file type="M">hbase-zookeeper.src.test.java.org.apache.hadoop.hbase.HBaseZKTestingUtility.java</file>
    </fixedFiles>
  </bug>
  <bug id="22837" opendate="2019-8-12 00:00:00" fixdate="2019-8-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move "Custom WAL Directory" section from "Bulk Loading" to "Write Ahead Log (WAL)" chapter</summary>
      <description>Currently, explanation about Custom WAL Directory configuration is a sub-topic of Bulk Loading, chapter, yet this subject has not much relation with bulk loading at all. It should rather be moved to a sub-section of the Write Ahead Log (WAL) chapter.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="2327" opendate="2010-3-15 00:00:00" fixdate="2010-3-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[EC2] Allocate elastic IP addresses for ZK and master nodes</summary>
      <description>Amazon EC2 supports Elastic IP Addresses to implement the effect of having a static IP address for public servers running on EC2. Up on hbase-users@ there was some recent discussion, confirmed, that when an EC2 instance queries the external DNS name of an elastic IP address, EC2 DNS returns the internal IP address of the instance to which the elastic IP address is bound, so it is safe to use elastic IPs for the ZK and master nodes. We gain the ability to do transparent replacement of one instance, e.g. failed, with another without incurring any additional cost. Update launch-hbase-zookeeper and launch-hbase-master to allocate elastic IPs: $ ec2-allocate-address ADDRESS 1.1.1.1and then assign the elastic IP address to the appropriate instance(s):$ ec2-associate-address -i i-11111111 1.1.1.1ADDRESS 1.1.1.1 i-11111111and then get the external DNS name to use when performing substitutions on master and slave configs:$ ec2-describe-instances i-11111111 | egrep ^INSTANCE | cut -f4ec2-1-1-1-1.compute-1.amazonaws.comWhen shutting down the cluster, just release the elastic IPs after terminating the instances:ec2-release-address 1.1.1.1...NOTE: AWS accounts default to a limit of 5 Elastic IP addresses but most will run with 1 master and 3 or 1 ZK instances. And, the ZK ensemble can be shared. A follow up issue can address making scripts to launch replacements for failed instances transparently.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">contrib.ec2.bin.terminate-hbase-cluster</file>
      <file type="M">contrib.ec2.bin.launch-hbase-zookeeper</file>
      <file type="M">contrib.ec2.bin.launch-hbase-slaves</file>
      <file type="M">contrib.ec2.bin.launch-hbase-master</file>
      <file type="M">contrib.ec2.bin.image.create-hbase-image-remote</file>
      <file type="M">contrib.ec2.bin.hbase-ec2-env.sh</file>
      <file type="M">contrib.ec2.bin.create-hbase-image</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="23829" opendate="2020-2-11 00:00:00" fixdate="2020-4-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Get `-PrunSmallTests` passing on JDK11</summary>
      <description>Start with the small tests, shaking out issues identified by the harness. So far it seems like -Dhadoop.profile=3.0 and -Dhadoop-three.version=3.3.0-SNAPSHOT maybe be required.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-with-hadoop-check-invariants.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-check-invariants.pom.xml</file>
      <file type="M">hbase-http.src.test.java.org.apache.hadoop.hbase.http.log.TestLogLevel.java</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestFutureUtils.java</file>
    </fixedFiles>
  </bug>
</bugrepository>
