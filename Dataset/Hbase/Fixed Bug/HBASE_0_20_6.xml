<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="2907" opendate="2010-8-11 00:00:00" fixdate="2010-10-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[rest/stargate] Improve error response when trying to create a scanner on a nonexistant table</summary>
      <description>Since 0.20.4, an attempt to create a scanner for a nonexistant table receives a "400 Bad Request" response with no furthur information. Prior to 0.20.4 it would receive a "500 org.apache.hadoop.hbase.TableNotFoundException: &lt;table&gt;" response with a stack trace in the body.Neither of these is ideal - the 400 fails to identify what aspect of the request was bad, and the 500 incorrectly suggests that the error was internal. Ideally the error should be a 400 error with information in the body identifying the nature of the problem.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.rest.TestScannerResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.ScannerResource.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2917" opendate="2010-8-13 00:00:00" fixdate="2010-10-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reseek directly to next row</summary>
      <description>When done with the current row, reseek directly to the next row rather than spending time reading more keys of current row which are not required.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2941" opendate="2010-8-30 00:00:00" fixdate="2010-9-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>port HADOOP-6713 - threading scalability for RPC reads - to HBase</summary>
      <description>HADOOP-6713 has patch to fix the read scalability of hadoop rpc. Right now a single thread accepts() then receives the RPC payload for every single RPC in hbase. Including object creation, writable deserialization, etc.Apply the patch from that issue to our own forked HBaseRPC code.</description>
      <version>0.20.6,0.89.20100621</version>
      <fixedVersion>0.89.20100924,0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HBaseServer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2943" opendate="2010-8-31 00:00:00" fixdate="2010-9-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>major_compact (and other admin commands) broken for .META.</summary>
      <description>Table admin commands seem to be broken against META. Implementation is new in master rewrite branch so should wait until that goes in to see if this bug still exists.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnection.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.catalog.CatalogTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.avro.AvroServer.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.catalog.MetaReader.java</file>
    </fixedFiles>
  </bug>
  <bug id="2944" opendate="2010-9-1 00:00:00" fixdate="2010-9-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cannot alter bloomfilter setting for a column family from hbase shell</summary>
      <description>hbase(main):002:0&gt; create 't1', 'cf'create 't1', 'cf'0 row(s) in 1.1320 secondshbase(main):003:0&gt; disable 't1'disable 't1'0 row(s) in 1.0810 secondshbase(main):004:0&gt; alter 't1', {NAME =&gt; 'cf', BLOOMFILTER =&gt; 'ROW'}alter 't1', {NAME =&gt; 'cf', BLOOMFILTER =&gt; 'ROW'}ERROR: no constructor with arguments matching [class org.jruby.java.proxies.ArrayJavaProxy, class org.jruby.RubyFixnum, class org.jruby.RubyString, class org.jruby.RubyBoolean, class org.jruby.RubyBoolean, class org.jruby.RubyFixnum, class org.jruby.RubyFixnum, class org.jruby.RubyBoolean, class org.jruby.RubyFixnum] on object #&lt;Java::OrgApacheHadoopHbase::HColumnDescriptor:0x1e4218cb&gt;</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.ruby.hbase.admin.rb</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2968" opendate="2010-9-8 00:00:00" fixdate="2010-10-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>No standard family filter provided</summary>
      <description>We have various filters, like QualifierFilter or ValueFilter, but no FamilyFilter.But if we want to use FilterList, we must have such filter to construct equationslike (family == 'myfamily' &amp;&amp; qualifer == 'aaa') || (family == 'otherfamily' &amp;&amp; qualifier == 'bbb').</description>
      <version>0.20.6</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.filter.TestFilter.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3017" opendate="2010-9-20 00:00:00" fixdate="2010-9-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>More log pruning</summary>
      <description>This issue covers some tightening up of log messages; as is all of the zk noise tends to overwhelm.For example, zkwatcher logs a generic "This event happened in zk with path X and event type Y" but just after, there will be a log from the handler of this zk event with this subsequent log more descriptive. This change would make zkwatcher log at INFO by default rather than DEBUG cutting down on logging content (re-enabling DEBUG is easy to do if needed).</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKAssign.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">conf.log4j.properties</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.main.resources.hbase-webapps.master.master.jsp</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="3018" opendate="2010-9-20 00:00:00" fixdate="2010-9-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bulk assignment on startup runs serially through the cluster servers assigning in bulk to one at a time</summary>
      <description>Multi-thread the bulk startup assignment of regions.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3019" opendate="2010-9-21 00:00:00" fixdate="2010-9-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make bulk assignment on cluster startup run faster</summary>
      <description>Currently, as of HBASE-3018, we come up with a bulk assignment plan that is sorted by server. We then spawn a thread to assign out the regions per server so we are assigning in parallel. This works but is still slow enough (It looks to be slower than the old assignment where we'd do lumps of N regions at a time). We should be able to pass a regionserver all the regions to open in one RPC. We need to figure how to keep up zk state while regionserver is processing a big lot of regions. This looks a little awkward to do since currently open handler just opens region &amp;#8211; there is no notion of doing a ping while waiting to run.Being able to start the cluster fast is important for those times we take it down to do major upgrade; the longer it takes to spin up, the longer our 'downtime'.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestLogsCleaner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.OpenedRegionHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HRegionInterface.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3022" opendate="2010-9-21 00:00:00" fixdate="2010-9-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change format of enum messages in o.a.h.h.executor package</summary>
      <description>Change RS2ZK_REGION_CLOSING to RS_ZK_REGION_CLOSING format. Ryan and J-D prefer the latter (It was Ryan's idea).</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLogSplit.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestZKBasedOpenCloseRegion.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestRestartCluster.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestMaster.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKAssign.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenRootHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenMetaHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseRootHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseMetaHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.TableModifyFamilyHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.TableDeleteFamilyHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.TableAddFamilyHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.OpenedRegionHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.ModifyTableHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.EnableTableHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.DisableTableHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.DeleteTableHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.ClosedRegionHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.executor.ExecutorService.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.executor.EventHandler.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3026" opendate="2010-9-22 00:00:00" fixdate="2010-9-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fixup of "missing" daughters on split is too aggressive</summary>
      <description>There is a bug in how we check for whether the daughters mentioned in parent region are present in .META. The check is done when we are processing a server shutdown. We're making the mistake of checking for presence of the daughter in the list of regions that used to live on the crashed server BUT fact of the matter is is that the daughter could just as well be rebalanced to another server.The upshot is that we are inserting into .META. and trying to assign regions that are already assigned.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3040" opendate="2010-9-26 00:00:00" fixdate="2010-9-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>BlockIndex readIndex too slowly in heavy write scenario</summary>
      <description>region size is configured with 128M, block size is 64K, the table has 5 column familiesat the beginning, when region split, master assigns daughters to new region servers, new region server open region, readIndex of this region's storefile(about 1000 blocks) spent 30~50ms, with the data import region server spent more and more time (sometimes up to several seconds) to load 1000 block indicesat right now, we resolve this issue by getting all indices of one hfile within one DFS read instead of 1000 reads.is there any other better resolution?</description>
      <version>0.20.6</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFile.java</file>
    </fixedFiles>
  </bug>
  <bug id="3111" opendate="2010-10-14 00:00:00" fixdate="2010-10-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestTableMapReduce broken up on hudson</summary>
      <description>So, test has failed for various reasons since fixed over last week or so. It is currently failing when the reducer starts up. Its failing because its not picking up the zk servers location; its using stale config.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.TableOutputFormat.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormat.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.IdentityTableReducer.java</file>
    </fixedFiles>
  </bug>
  <bug id="3113" opendate="2010-10-14 00:00:00" fixdate="2010-10-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Don&amp;#39;t reassign regions if cluster is being shutdown</summary>
      <description>On stop of a cluster, handling a close message, we'll go ahead and reassign regions as per normal though the cluster up flag is false. This is what cause the TestRegionRebalancing test to fail up on hudson just now, #1546.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerClosedException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HRegionInterface.java</file>
    </fixedFiles>
  </bug>
  <bug id="3117" opendate="2010-10-16 00:00:00" fixdate="2010-5-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update Thrift to 0.5 version</summary>
      <description>Thrift 0.5 has been released already and we want to upgrade to at least 0.3 but 0.5 has a lot of improvements so that would be the best.Unfortunately the Java lib has changed so that we'll have to regenerate the current Thrift interface and fix the implementation (byte[] -&gt; ByteBuffer).They also have problems getting Thrift into a Maven repository so we'll need to do our current workaround again unfortunately and upload it to a repository. That would be Ryan's I think?I'll upload an updated thrift jar and a patch for the old Thrift code.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3120" opendate="2010-10-18 00:00:00" fixdate="2010-11-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[rest] content transcoding</summary>
      <description>We have a reasonable user request for support for decoding of base64 encoded values into raw/binary when servicing GET requests with an Accept header of application/octet-stream. We can introduce a table schema attribute for column families that instructs the REST gateway to perform input and/or output transcoding, with base64-&gt;binary (for GET) and vice versa (for PUT or POST) as the first supported option.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.TableResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.SchemaResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.ScannerResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.RowResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.RegionsResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.ExistsResource.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3121" opendate="2010-10-18 00:00:00" fixdate="2010-10-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[rest] Do not perform cache control when returning results</summary>
      <description>The REST interface currently provides MaxAge hints to HTTP cache servers when returning results, but does not do so in a way that makes much sense. For some other responses such as scanner results or schema, the REST interface provides a NoCache hint. That seems appropriate. Otherwise, especially given the rich configuration languages of caching servers such as Varnish, it is probably not appropriate to manage cache policy in the REST interface.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.SchemaResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.RowResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.RESTServlet.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3161" opendate="2010-10-27 00:00:00" fixdate="2010-11-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Provide option for Stargate to only serve GET requests</summary>
      <description>Provide option for Stargate to only serve GET requests. Hbase health check can utilize this option.</description>
      <version>0.20.6</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.rest.TestSchemaResource.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.rest.TestScannerResource.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.rest.TestRowResource.java</file>
      <file type="M">src.main.resources.hbase-default.xml</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.SchemaResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.ScannerResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.ScannerInstanceResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.RowResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.RESTServlet.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.Main.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.Constants.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3200" opendate="2010-11-5 00:00:00" fixdate="2010-11-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make is so can disable DEBUG logging on HConnectionImplemenation without losing important messages</summary>
      <description>Default logging in HBase is DEBUG. DEBUG of HConnectionImplementation will output all interactions with region cache. This can be lots of debug if client is heavily-used. Make it so can turn it off but not lose important stuff like connect and disconnect from zk.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.MetaScanner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">conf.log4j.properties</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3201" opendate="2010-11-5 00:00:00" fixdate="2010-11-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add accounting of empty regioninfo_qualifier rows in meta to hbasefsck.</summary>
      <description>Make an accounting of empty HREGION_QUALIFIER rows in .META. Emit count and details in hbase fsck too.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HBaseFsck.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.catalog.MetaReader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3203" opendate="2010-11-5 00:00:00" fixdate="2010-11-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>We can get an order to open a region while shutting down and it&amp;#39;ll hold up regionserver shutdown</summary>
      <description>Starting and stopping clusters I see that an open directive can come in while we are shutting down all the user space regions on a particular regionserver. Regionservers will only shut themselves down after all user space regions have closed. We queue up all the closes at a particular time. If an open comes in while we are in the closing condition, then the regionserver won't go down. The region open needs to be blocked.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerServices.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3204" opendate="2010-11-5 00:00:00" fixdate="2010-11-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reenable deferred log flush</summary>
      <description>Deferred log flush was disabled a few months ago, reenable it and make it false by default.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3273" opendate="2010-11-23 00:00:00" fixdate="2010-11-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Set the ZK default timeout to 3 minutes</summary>
      <description>Following HBASE-3272, Stack suggested that we up the ZK timeout and proposed that we set it to 3 minutes (he said that last part in person). This should cover most of the big GC pauses out there.</description>
      <version>None</version>
      <fixedVersion>0.90.0,0.92.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.resources.hbase-default.xml</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.HQuorumPeer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMasterCommandLine.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.docbkx.book.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3275" opendate="2010-11-24 00:00:00" fixdate="2010-3-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[rest] No gzip/deflate content encoding support</summary>
      <description>The REST gateway does not support gzip or deflate content encoding. This is a bug because it is a very common performance optimization and Jetty trivially supports it.</description>
      <version>None</version>
      <fixedVersion>0.90.0,0.92.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.rest.TestGzipFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.filter.GzipFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.Main.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3305" opendate="2010-12-3 00:00:00" fixdate="2010-1-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow round-robin distribution for table created with multiple regions</summary>
      <description>We can distribute the initial regions created for a new table in round-robin fashion.</description>
      <version>0.20.6</version>
      <fixedVersion>0.90.1,0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.LoadBalancer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3373" opendate="2010-12-18 00:00:00" fixdate="2010-1-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow regions to be load-balanced by table</summary>
      <description>From our experience, cluster can be well balanced and yet, one table's regions may be badly concentrated on few region servers.For example, one table has 839 regions (380 regions at time of table creation) out of which 202 are on one server.It would be desirable for load balancer to distribute regions for specified tables evenly across the cluster. Each of such tables has number of regions many times the cluster size.</description>
      <version>0.20.6</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.TestRegionRebalancing.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="3374" opendate="2010-12-19 00:00:00" fixdate="2010-3-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Our jruby jar has *GPL jars in it; fix</summary>
      <description>The latest JRuby's complete jar bundles *GPL jars (JNA and JFFI among others). It looks like the functionality we depend on &amp;#8211; the shell in particular &amp;#8211; makes use of these dirty jars so they are hard to strip. They came in because we (I!) just updated our JRuby w/o checking in on what updates contained. JRuby has been doing this for a while now (1.1.x added the first LGPL). You have to go all the ways back to the original HBase checkin, HBASE-487, of JRuby &amp;#8211; 1.0.3 &amp;#8211; to get a JRuby w/o *GPL jars.Plan is to try and revert our JRuby all the ways down to 1.0.3 before shipping 0.90.0. Thats what this issue is about.We should also look into moving off JRuby in the medium to long-term. Its kinda awkward sticking on an old version that is no longer supported. I'll open an issue for that.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestShell.java</file>
      <file type="M">src.main.ruby.shell.commands.list.rb</file>
      <file type="M">src.main.ruby.shell.commands.balance.switch.rb</file>
      <file type="M">src.main.ruby.hbase.table.rb</file>
      <file type="M">src.main.ruby.hbase.replication.admin.rb</file>
      <file type="M">src.main.ruby.hbase.hbase.rb</file>
      <file type="M">src.main.ruby.hbase.admin.rb</file>
      <file type="M">src.main.ruby.hbase.rb</file>
      <file type="M">pom.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>
