<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="21077" opendate="2018-8-20 00:00:00" fixdate="2018-8-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>MR job launched by hbase incremental backup command failed with FileNotFoundException</summary>
      <description>Discovered during internal testing by Romil Choksi.MR job launched by hbase incremental backup command failed with FileNotFoundExceptionfrom test console log2018-06-12 04:27:31,160|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|2018-06-12 04:27:31,160 INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_1528766389356_00442018-06-12 04:27:31,186|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|2018-06-12 04:27:31,184 INFO [main] mapreduce.JobSubmitter: Executing with tokens: [Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:ns1, Ident: (token for hbase: HDFS_DELEGATION_TOKEN owner=hbase@EXAMPLE.COM, renewer=yarn, realUser=, issueDate=1528777648605, maxDate=1529382448605, sequenceNumber=175, masterKeyId=2), Kind: kms-dt, Service: 172.27.68.203:9393, Ident: (kms-dt owner=hbase, renewer=yarn, realUser=, issueDate=1528777649149, maxDate=1529382449149, sequenceNumber=49, masterKeyId=2), Kind: HBASE_AUTH_TOKEN, Service: bc71e347-78ff-4f95-af44-006f9b549a84, Ident: (org.apache.hadoop.hbase.security.token.AuthenticationTokenIdentifier@5), Kind: kms-dt, Service: 172.27.52.14:9393, Ident: (kms-dt owner=hbase, renewer=yarn, realUser=, issueDate=1528777648918, maxDate=1529382448918, sequenceNumber=50, masterKeyId=2)]2018-06-12 04:27:31,477|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|2018-06-12 04:27:31,477 INFO [main] conf.Configuration: found resource resource-types.xml at file:/etc/hadoop/3.0.0.0-1476/0/resource-types.xml2018-06-12 04:27:31,527|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|2018-06-12 04:27:31,527 INFO [main] impl.TimelineClientImpl: Timeline service address: ctr-e138-1518143905142-359429-01-000004.hwx.site:81902018-06-12 04:27:32,563|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|2018-06-12 04:27:32,562 INFO [main] impl.YarnClientImpl: Submitted application application_1528766389356_00442018-06-12 04:27:32,634|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|2018-06-12 04:27:32,634 INFO [main] mapreduce.Job: The url to track the job: https://ctr-e138-1518143905142-359429-01-000003.hwx.site:8090/proxy/application_1528766389356_0044/2018-06-12 04:27:32,635|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|2018-06-12 04:27:32,635 INFO [main] mapreduce.Job: Running job: job_1528766389356_00442018-06-12 04:27:44,807|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|2018-06-12 04:27:44,806 INFO [main] mapreduce.Job: Job job_1528766389356_0044 running in uber mode : false2018-06-12 04:27:44,809|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|2018-06-12 04:27:44,809 INFO [main] mapreduce.Job: map 0% reduce 0%2018-06-12 04:27:54,926|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|2018-06-12 04:27:54,925 INFO [main] mapreduce.Job: map 5% reduce 0%2018-06-12 04:27:56,950|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|2018-06-12 04:27:56,950 INFO [main] mapreduce.Job: Task Id : attempt_1528766389356_0044_m_000002_0, Status : FAILED2018-06-12 04:27:56,979|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|Error: java.io.FileNotFoundException: File does not exist: hdfs://ns1/apps/hbase/data/oldWALs/ctr-e138-1518143905142-359429-01-000004.hwx.site%2C16020%2C1528776085205.15287761609152018-06-12 04:27:56,979|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1583)2018-06-12 04:27:56,980|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1576)2018-06-12 04:27:56,980|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)2018-06-12 04:27:56,980|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1591)2018-06-12 04:27:56,980|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.hbase.regionserver.wal.ReaderBase.init(ReaderBase.java:64)2018-06-12 04:27:56,981|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader.init(ProtobufLogReader.java:165)2018-06-12 04:27:56,981|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.hbase.wal.WALFactory.createReader(WALFactory.java:289)2018-06-12 04:27:56,981|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.hbase.wal.WALFactory.createReader(WALFactory.java:271)2018-06-12 04:27:56,981|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.hbase.wal.WALFactory.createReader(WALFactory.java:259)2018-06-12 04:27:56,981|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.hbase.wal.WALFactory.createReader(WALFactory.java:395)2018-06-12 04:27:56,982|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.hbase.wal.AbstractFSWALProvider.openReader(AbstractFSWALProvider.java:449)2018-06-12 04:27:56,982|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.hbase.mapreduce.WALInputFormat$WALRecordReader.openReader(WALInputFormat.java:166)2018-06-12 04:27:56,982|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.hbase.mapreduce.WALInputFormat$WALRecordReader.initialize(WALInputFormat.java:158)2018-06-12 04:27:56,983|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:560)2018-06-12 04:27:56,983|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:798)2018-06-12 04:27:56,983|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)2018-06-12 04:27:56,983|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)2018-06-12 04:27:56,983|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at java.security.AccessController.doPrivileged(Native Method)2018-06-12 04:27:56,984|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at javax.security.auth.Subject.doAs(Subject.java:422)2018-06-12 04:27:56,984|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1686)2018-06-12 04:27:56,984|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)2018-06-12 04:27:56,984|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|But looks like it did find the file on hdfs, test script runs incremental backup command as HBase user.2018-06-12 04:27:30,756|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|2018-06-12 04:27:30,755 DEBUG [main] mapreduce.WALInputFormat: Scanning hdfs://ns1/apps/hbase/data/oldWALs/ctr-e138-1518143905142-359429-01-000004.hwx.site%2C16020%2C1528776085205.1528776160915 for WAL files2018-06-12 04:27:30,758|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|2018-06-12 04:27:30,758 INFO [main] mapreduce.WALInputFormat: Found: HdfsLocatedFileStatus{path=hdfs://ns1/apps/hbase/data/oldWALs/ctr-e138-1518143905142-359429-01-000004.hwx.site%2C16020%2C1528776085205.1528776160915; isDirectory=false; length=18031; replication=3; blocksize=268435456; modification_time=1528776689363; access_time=1528776160921; owner=hbase; group=hdfs; permission=rwx--x--x; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false}</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-backup.src.test.java.org.apache.hadoop.hbase.backup.TestIncrementalBackup.java</file>
      <file type="M">hbase-backup.src.test.java.org.apache.hadoop.hbase.backup.TestBackupBase.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.impl.IncrementalBackupManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="21179" opendate="2018-9-10 00:00:00" fixdate="2018-9-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix the number of actions in responseTooSlow log</summary>
      <description>responseTooSlow2018-09-10 16:13:53,022 WARN &amp;#91;B.DefaultRpcServer.handler=209,queue=29,port=60020&amp;#93; ipc.RpcServer: (responseTooSlow): {"processingtimems":321262,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"127.0.0.1:56149","param":"region= tsdb,\\x00\\x00.[\\x89\\x1F\\xB0\\x00\\x00\\x01\\x00\\x01Y\\x00\\x00\\x02\\x00\\x00x04,1536133210446.7c752de470bd5558a001117b123a5db5., for 1 actions and 1st row key=\\x00\\x00.[\\x96x16p","starttimems":1536566911759,"queuetimems":0,"class":"HRegionServer","responsesize":2,"method":"Multi"}The responseTooSlow log is printed when the processing time of a request exceeds the specified threshold. The number of actions and the contents of the first rowkey in the request will be included in the log.However, the number of actions is inaccurate, and it is actually the number of regions that the request needs to visit.Just like the logs above, users may be mistaken for using 321262ms to process an action, which is incredible, so we need to fix it.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.3.3,1.2.8,2.2.0,1.4.8,2.1.1,2.0.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="21188" opendate="2018-9-12 00:00:00" fixdate="2018-9-12 01:00:00" resolution="Later">
    <buginformation>
      <summary>Print heap and gc informations in our junit ResourceChecker</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.ResourceCheckerJUnitListener.java</file>
    </fixedFiles>
  </bug>
  <bug id="21189" opendate="2018-9-12 00:00:00" fixdate="2018-9-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>flaky job should gather machine stats</summary>
      <description>flaky test should gather all the same environment information as our normal nightly tests.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.3.3,1.2.8,2.2.0,1.4.8,2.1.1,2.0.3</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.flaky-tests.run-flaky-tests.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  <bug id="21190" opendate="2018-9-12 00:00:00" fixdate="2018-9-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Log files and count of entries in each as we load from the MasterProcWAL store</summary>
      <description>Sometimes this can take a while especially if loads of files. Emit counts of entries so operator gets sense of scale of procedures being processed.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.3.3,2.2.0,1.4.8,2.1.1,2.0.3</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALFormatReader.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALFormat.java</file>
    </fixedFiles>
  </bug>
  <bug id="21191" opendate="2018-9-12 00:00:00" fixdate="2018-10-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a holding-pattern if no assign for meta or namespace (Can happen if masterprocwals have been cleared).</summary>
      <description>If the masterprocwals have been removed &amp;#8211; operator error, hdfs dataloss, or because we have gotten ourselves into a pathological state where we have hundreds of masterprocwals too process and it is taking too long so we just want to startover &amp;#8211; then master startup will have a dilemma. Master startup needs hbase:meta to be online. If the masterprocwals have been removed, there may be no outstanding assign or a servercrashprocedure with coverage for hbase:meta (I ran into this issue repeatedly in internal testing purging masterprocwals on a large test cluster). Worse, when master startup cannot find an online hbase:meta, it exits after exhausting the RPC retries.So, we need a holding-pattern for master startup if hbase:meta is not online if only so an operator can schedule an assign for meta or so they can assign fixup procedures (HBASE-21035 has discussion on why we cannot just auto-schedule an assign of meta).</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1,2.0.3</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestMetaTableAccessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableNamespaceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionServerTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.EnableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DisableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterWalManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.AssignmentManager.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.RetryCounterFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="21212" opendate="2018-9-20 00:00:00" fixdate="2018-9-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Wrong flush time when update flush metric</summary>
      <description></description>
      <version>3.0.0-alpha-1,2.1.0,2.0.2</version>
      <fixedVersion>3.0.0-alpha-1,1.3.3,2.2.0,1.4.8,2.1.1,2.0.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="21214" opendate="2018-9-20 00:00:00" fixdate="2018-9-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbck2] setTableState just sets hbase:meta state, not in-memory state</summary>
      <description>Means that we have to go get another Master to see the table state change because in-memory state is still pegged at the old value.TODO: Check the is_enabled/is_disabled shell commands to make sure they are reading from the right place.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="21215" opendate="2018-9-20 00:00:00" fixdate="2018-10-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Figure how to invoke hbck2; make it easy to find</summary>
      <description>In https://docs.google.com/document/d/1Oun4G3M5fyrM0OxXcCKYF8td0KD7gJQjnU9Ad-2t-uk/edit#, the doc on hbck2 'form', one item to figure is how to invoke hbck2. Related, how to make it easy to find? busbey has some ideas (posted in doc). This issue is for implementation.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1,2.0.3</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug id="21217" opendate="2018-9-21 00:00:00" fixdate="2018-9-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Revisit the executeProcedure method for open/close region</summary>
      <description>Currently we just call openRegion and closeRegion directly, which is a bit buggy. For example, in order to not fail all the open region requests while there is only one failure, we will catch the exception and set a flag in the return value. But for executeProcedures call, the return value will be ignored, and we expect the openRegion method will always call reportRegionStateTransition to report the failure but in fact it does not...And after HBASE-20881, we can confirm that the race could happen, where we send a close request to a region which is opening(HBASE-21199), and vice visa. So I think here we need to revisit the implementation of executeProcedures to make it more stable.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MockRegionServerServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.executor.ExecutorService.java</file>
    </fixedFiles>
  </bug>
  <bug id="21254" opendate="2018-9-29 00:00:00" fixdate="2018-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Need to find a way to limit the number of proc wal files</summary>
      <description>For regionserver, we have a max wal file limitation, if we reach the limitation, we will trigger a flush on specific regions so that we can delete old wal files. But for proc wals, we do not have this mechanism, and it will be worse after HBASE-21233, as if there is an old procedure which can not make progress and do not persist its state, we need to keep the old proc wal file for ever...</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1,2.0.3</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.assignment.MockMasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.TestProcedureStoreTracker.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.ProcedureStoreTracker.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.ProcedureStoreBase.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.ProcedureStore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.BitSetNode.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureExecutor.java</file>
    </fixedFiles>
  </bug>
  <bug id="21269" opendate="2018-10-4 00:00:00" fixdate="2018-10-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Forward-port to branch-2 " HBASE-21213 [hbck2] bypass leaves behind state in RegionStates when assign/unassign"</summary>
      <description>A bunch of this patch does not apply to branch-2 and master now we don't have AP or UP anymore. Need to figure if we need override in branch-2 and master. Let me upload the forward-port done so far. Can finish this when move to branch-2.2 exercise. FYI Apache9</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.test.ruby.shell.shell.test.rb</file>
      <file type="M">hbase-shell.src.test.java.org.apache.hadoop.hbase.client.TestShell.java</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.list.procedures.rb</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestMetaTableAccessor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHbck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ProcedureSyncWait.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ProcedurePrepareLatch.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ProcedureDescriber.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.TransitRegionStateProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.AssignmentManager.java</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupInfoManagerImpl.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.MasterProcedure.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.Master.proto</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.TestProcedureBypass.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.RemoteProcedureException.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureUtil.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureExecutor.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.Procedure.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Hbck.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseHbck.java</file>
    </fixedFiles>
  </bug>
  <bug id="21290" opendate="2018-10-11 00:00:00" fixdate="2018-10-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>No need to instantiate BlockCache for master which not carry table</summary>
      <description>In our production clusters, we use different jvm config for master/regionserver but use same hbase-site.xml for master/regionserver. And master has a small heap/offheap config. So the regionserver's hbase.bucketcache.size is not suitable for master. I thought we don't need to instantiate BlockCache for master which not carry table.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1,2.0.3</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.MobCacheConfig.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
    </fixedFiles>
  </bug>
  <bug id="21325" opendate="2018-10-17 00:00:00" fixdate="2018-10-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Force to terminate regionserver when abort hang in somewhere</summary>
      <description>When testing sync replication, I found that, if I transit the remote cluster to DA, while the local cluster is still in A, the region server will hang when shutdown. As the fsOk flag only test the local cluster(which is reasonable), we will enter the waitOnAllRegionsToClose, and since the WAL is broken(the remote wal directory is gone) so we will never succeed. And this lead to an infinite wait inside waitOnAllRegionsToClose.So I think here we should have an upper bound for the wait time in waitOnAllRegionsToClose method.</description>
      <version>3.0.0-alpha-1,2.2.0,2.1.1,2.0.2</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="21354" opendate="2018-10-21 00:00:00" fixdate="2018-10-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure may be deleted improperly during master restarts resulting in &amp;#39;Corrupt&amp;#39;</summary>
      <description>Good news! stack, Apache9, I may find the root cause of mysterious ‘Corrupted procedure’ or some procedures disappeared after master restarts(happens during ITBLL).This is because during master restarts, we load procedures from the log, and builds the 'holdingCleanupTracker' according each log's tracker. We may mark a procedure in the oldest log as deleted if one log doesn't contain the procedure. This is Inappropriate since one log will not contain info of the log if this procedure was not updated during the time. We can only delete the procedure only if it is not in the global tracker, which have the whole picture.trackerNode = tracker.lookupClosestNode(trackerNode, procId); if (trackerNode == null || !trackerNode.contains(procId) || trackerNode.isModified(procId)) { // the procedure was removed or modified node.delete(procId); }A test case(testProcedureShouldNotCleanOnLoad) shows cleanly how the corruption happened in the patch.</description>
      <version>2.1.0,2.0.2</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1,2.0.3</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.ProcedureStoreTracker.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.ProcedureTestingUtility.java</file>
    </fixedFiles>
  </bug>
  <bug id="21356" opendate="2018-10-21 00:00:00" fixdate="2018-10-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>bulkLoadHFile API should ensure that rs has the source hfile&amp;#39;s write permission</summary>
      <description>If the rs bulk load a HFile but has no write permission of it, we can read &amp; compact the hfile, but after the compaction finished, the HFile willl be moved to archive directory, the HFileCleaner won't has permission to delete, then the HFile will always be keep in HDFS. Need check the file's write permission when run bulkLoadHFile at server side, if no write permission, then reject.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.0.3,2.1.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="21389" opendate="2018-10-26 00:00:00" fixdate="2018-10-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Revisit the procedure lock for sync replication</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.SyncReplicationReplayWALProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.RecoverStandbyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.AbstractPeerProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.PeerQueue.java</file>
    </fixedFiles>
  </bug>
  <bug id="21396" opendate="2018-10-26 00:00:00" fixdate="2018-11-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create 2.1.1 release</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.1.1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.downloads.xml</file>
    </fixedFiles>
  </bug>
  <bug id="2140" opendate="2010-1-17 00:00:00" fixdate="2010-1-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>findbugs issues - 2 performance warnings as suggested by findbugs</summary>
      <description>Integer.valueOf favored instead of new Integer() map.entrySet() favored instead of map.keySet()</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="21400" opendate="2018-10-27 00:00:00" fixdate="2018-8-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>correct spelling error of &amp;#39;initilize&amp;#39; in comment</summary>
      <description>When I learned the code of HBase-RPC,I found a spelling error in the comment.Is the word "initilize" should be "initialize"?</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.1,2.1.6</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.BlockingRpcConnection.java</file>
    </fixedFiles>
  </bug>
  <bug id="21413" opendate="2018-10-31 00:00:00" fixdate="2018-12-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Empty meta log doesn&amp;#39;t get split when restart whole cluster</summary>
      <description>After I restart whole cluster, there is a splitting directory still exists on hdfs. Then I found there is only an empty meta wal file in it. I'll dig into this later.</description>
      <version>2.1.1,2.0.2</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.2,2.0.4</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterWalManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="21414" opendate="2018-10-31 00:00:00" fixdate="2018-12-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>StoreFileSize growth rate metric</summary>
      <description>A metric on the growth rate of storefile sizes would be nice to have as a way of monitoring traffic patterns. I know you can get the same insight from graphing the delta on the storeFileSize metric, but not all metrics visualization tools support that</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsRegionServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperStub.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="21417" opendate="2018-11-1 00:00:00" fixdate="2018-11-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Pre commit build is broken due to surefire plugin crashes</summary>
      <description>The recent builds are all failed with[ERROR] ExecutionException The forked VM terminated without properly saying goodbye. VM crash or System.exit called?[ERROR] Command was /bin/sh -c cd /testptch/hbase/hbase-rsgroup &amp;&amp; /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java -enableassertions -Dhbase.build.id=2018-10-31T11:09:36Z -Xmx2800m -Djava.security.egd=file:/dev/./urandom -Djava.net.preferIPv4Stack=true -Djava.awt.headless=true -jar /testptch/hbase/hbase-rsgroup/target/surefire/surefirebooter3799876849632796400.jar /testptch/hbase/hbase-rsgroup/target/surefire 2018-10-31T11-09-52_393-jvmRun1 surefire4495583426680149115tmp surefire_05657090267882138674tmp[ERROR] Error occurred in starting fork, check output in log[ERROR] Process Exit Code: 1risdenk provided some useful reference:https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=911925https://github.com/carlossg/docker-maven/issues/90https://github.com/carlossg/docker-maven/issues/92It seems to be an OpenJDK issue.Let's see if there are any workarounds.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.3.3,2.2.0,2.0.3,1.4.9,2.1.2,1.2.9</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="21424" opendate="2018-11-1 00:00:00" fixdate="2018-11-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change flakies and nightlies so scheduled less often</summary>
      <description>Infra wrote us:Chris Thistlethwaite &lt;christ@apache.org&gt;9:09 AM (25 minutes ago) to dev, teamGreetings!During the Jenkins outage yesterday I noticed a ton of builds fromHBase-Flaky-Tests https://builds.apache.org/view/H-L/view/HBase/job/HBase-Flaky-Tests/ inthe queue. Turns out this runs a bunch of pipeline builds every hourwhich clogs up Jenkins, both for you and other projects. For example,branch-2.0 is currently queuing 3 builds, waiting on the 4th to finish,and it's also behind the HBase Nightly.That brings me to HBase Nightly https://builds.apache.org/view/H-L/view/HBase/job/HBase%20Nightly/ itruns every 6 hours, which is a bit excessive for a nightly build whichby definition should be once a day. Especially as it gets dangerouslyclose to running into itself as builds currently around 4-5 hours ofbuild time.I suggest something more like Flaky-Tests every 6 hours and the Nightlyonce a day. If you agree to these changes, feel free to update Jenkins.Otherwise, I'll update the jobs in the next few days if there is noresponse.Please add team@infra.apache.org and/or my address to any replies aswe're not subbed to your dev list.Thank you,Chris T.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.0.3,1.4.9,2.1.2,1.2.9</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.flaky-tests.run-flaky-tests.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  <bug id="2147" opendate="2010-1-19 00:00:00" fixdate="2010-3-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>run zookeeper in the same jvm as master during non-distributed mode</summary>
      <description>this will avoid needing to 'ssh localhost' to start hbase on a stand-alone non-distributed machine. We should run ZK in the same JVM and also change the scripts too.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.MiniZooKeeperCluster.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.start-hbase.sh</file>
    </fixedFiles>
  </bug>
  <bug id="21606" opendate="2018-12-14 00:00:00" fixdate="2018-7-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document use of the meta table load metrics added in HBASE-19722</summary>
      <description>HBASE-19722 added a great new tool for figuring out where cluster load is coming from. Needs a section in the ref guide When should I use this? Why shouldn't I use it all the time? What does using it look like? How do I use it?I think all the needed info for making something to answer these questions is in the discussion on HBASE-19722</description>
      <version>3.0.0-alpha-1,1.5.0,1.4.6,2.2.0,2.0.2,2.1.3</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,2.0.6,2.2.1,2.1.6,1.4.11</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="21618" opendate="2018-12-19 00:00:00" fixdate="2018-1-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scan with the same startRow(inclusive=true) and stopRow(inclusive=false) returns one result</summary>
      <description>I expect the following code to return none result, but still return a row:byte[] rowkey = "some key existed";Scan scan = new Scan();scan.withStartRow(rowkey, true);scan.withStopRow(rowkey, false);htable.getScanner(scan);</description>
      <version>2.0.2</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.2,2.0.4,1.4.10</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.protobuf.TestProtobufUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannersFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide3.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.shaded.protobuf.TestProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="21705" opendate="2019-1-11 00:00:00" fixdate="2019-1-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Should treat meta table specially for some methods in AsyncAdmin</summary>
      <description>For example, tableExists, isTableEnabled, isTableDisabled...For now, we will go to the meta table directly but obviously, meta table does not contain the record for itself...</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.3,2.0.5</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTableAdminApi3.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.AsyncMetaTableAccessor.java</file>
    </fixedFiles>
  </bug>
  <bug id="21976" opendate="2019-3-1 00:00:00" fixdate="2019-3-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Deal with RetryImmediatelyException for batching request</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.4</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncBatchRpcRetryingCaller.java</file>
    </fixedFiles>
  </bug>
  <bug id="21977" opendate="2019-3-1 00:00:00" fixdate="2019-3-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Skip replay WAL and update seqid when open regions restored from snapshot</summary>
      <description>TableSnapshotScanner restore a snapshot and then open the restored regions. When open these regions, we can skip replay WAL and update seqid.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestRestoreSnapshotHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ClientSideRegionScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="21978" opendate="2019-3-2 00:00:00" fixdate="2019-3-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Should close AsyncRegistry if we fail to get cluster id when creating AsyncConnection</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.4</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="22077" opendate="2019-3-21 00:00:00" fixdate="2019-3-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expose sleep time as a command line argument of IntergationTestBackupRestore</summary>
      <description>Extend command line arguments of IntergationTestBackupRestore with a sleep time of chaos monkey options to be able to setup policy of region server restarts more granularly.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestBackupRestore.java</file>
    </fixedFiles>
  </bug>
  <bug id="2208" opendate="2010-2-10 00:00:00" fixdate="2010-6-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TableServers # processBatchOfRows - converts from List to [ ] - Expensive copy</summary>
      <description>With autoFlush to false and a large write buffer on HTable, when we write bulk puts - TableServer # processBatchOfRows , convert the input (List) to an [ ] , before sending down the wire. With a write buffer as large as 20 MB , that becomes an expensive copy when we do - list.toArray(new T[ ] ). May be - should we change the wire protocol to support List as well , and then revisit this to prevent the bulk copy ?Batch b = new Batch(this) { @Override int doCall(final List&lt;Row&gt; currentList, final byte [] row, final byte [] tableName) throws IOException, RuntimeException { *final Put [] puts = currentList.toArray(PUT_ARRAY_TYPE);* return getRegionServerWithRetries(new ServerCallable&lt;Integer&gt;(this.c, tableName, row) { public Integer call() throws IOException { return server.put(location.getRegionInfo().getRegionName(), puts); } }); }</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HRegionInterface.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="22135" opendate="2019-3-30 00:00:00" fixdate="2019-4-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>AsyncAdmin will not refresh master address</summary>
      <description>This is a big problem... If we stop the active master and promote the backup master, all methods in AsyncAdmin, which need to connect the master will fail as they try to connect to the old active master forever...</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.5</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncMetaRegionLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncMasterRequestRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncConnectionImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="23118" opendate="2019-10-4 00:00:00" fixdate="2019-10-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[RELEASE SCRIPTS] Allow creating a RC from an existing tag</summary>
      <description>Generating the CHANGES.md requires some manual works such as checking whether the things in git are the same with on jira, so I'd like to do this manually and also make the tag manually.So I think the release scripts should have the ability to start making a release from an existing tag, instead of always start from the very beginning where we will generate and commit CHANGES.md.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.create-release.release-util.sh</file>
      <file type="M">dev-support.create-release.do-release.sh</file>
    </fixedFiles>
  </bug>
</bugrepository>
