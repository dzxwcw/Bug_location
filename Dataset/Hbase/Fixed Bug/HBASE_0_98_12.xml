<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="12916" opendate="2015-1-26 00:00:00" fixdate="2015-1-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>No access control for replicating WAL entries</summary>
      <description>Currently, there is no access control for replicating WAL entries in secure HBase cluster. Any authenticated user can write any data they want to any table of a secure cluster by using the replication api.Simple solution is to add permission check before replicating WAL entries. And only user with global write permission can replicate WAL entries to this cluster.Another option is adding "Replication" action in hbase and only user with "Replication" permission can replicate WAL entries to this cluster?apurtell What's your suggestion? Thanks</description>
      <version>0.94.26,0.98.12,2.0.0</version>
      <fixedVersion>1.0.0,0.98.10,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionServerObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseRegionServerObserver.java</file>
    </fixedFiles>
  </bug>
  <bug id="13218" opendate="2015-3-12 00:00:00" fixdate="2015-3-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Correct the syntax shown for using ExportSnapshot tool in the book</summary>
      <description>It is $ bin/hbase class org.apache.hadoop.hbase.snapshot.ExportSnapshot -snapshot MySnapshot -copy-to hdfs://srv2:8082/hbase -mappers 16It should be$ bin/hbase org.apache.hadoop.hbase.snapshot.ExportSnapshot -snapshot MySnapshot -copy-to hdfs://srv2:8082/hbase -mappers 16</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="13286" opendate="2015-3-19 00:00:00" fixdate="2015-3-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Minimum timeout for a rpc call could be 1 ms instead of 2 seconds</summary>
      <description>There is a check in the client to be sure that we don't use a timeout of zero (i.e. infinite). This includes setting the minimal time out for a rpc timeout to 2 seconds. However, it makes sense for some calls (typically gets going to the cache) to have much lower timeouts. So it's better to do the check vs. zero but with a minimal timeout of 1. I fixed a typo &amp; a wrong comment in this patch as well. I don't understand this code: // t could be a RemoteException so go around again. translateException(t); // We don't use the result?but may be it's good.</description>
      <version>1.0.0,0.98.12</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="13289" opendate="2015-3-19 00:00:00" fixdate="2015-4-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>typo in splitSuccessCount metric</summary>
      <description>Our split metrics have a misspelled Count and it shows up in our jmx metrics "splitSuccessCounnt" : 0,</description>
      <version>1.0.0,0.98.10,1.1.0,0.98.11,0.98.12,0.98.10.1,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="13326" opendate="2015-3-24 00:00:00" fixdate="2015-3-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Disabled table can&amp;#39;t be enabled after HBase is restarted</summary>
      <description>The folks at Intel discovered a pretty nasty bug in 1.0 and 1.1 (but not master). Steps to reproduce:1. Create a table, any table.2. Disable the table.3. Restart HBase.4. Try enabling the table.The table won't become enabled and the master web UI will indicate a never-ending region in transition. Also worth noting is that mbertozzi dug in and noted that this isn't happening in the master branch.</description>
      <version>1.0.0,1.1.0,0.98.12</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  <bug id="13332" opendate="2015-3-24 00:00:00" fixdate="2015-3-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix the usage of doAs/runAs in Visibility Controller tests.</summary>
      <description>The "doAs" bug is also affecting VC related tests too.</description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityWithCheckAuths.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLablesWithGroups.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithSLGStack.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithDeletes.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithDefaultVisLabelService.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithACL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabels.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelReplicationWithExpAsString.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestEnforcingScanLabelGenerator.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestDefaultScanLabelGeneratorStack.java</file>
    </fixedFiles>
  </bug>
  <bug id="13334" opendate="2015-3-25 00:00:00" fixdate="2015-4-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>FindBugs should create precise report for new bugs introduced</summary>
      <description>Currently findbugs build process reports only number of bugs introduced. And there is no report on what acutally was introduced.Lets improve that: we can use computeBugHistory to generate precise report on new bugs (and optionally missed bugs).Report should be available in html format.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.properties</file>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  <bug id="13376" opendate="2015-4-1 00:00:00" fixdate="2015-2-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improvements to Stochastic load balancer</summary>
      <description>There are two things this jira tries to address:1. The locality picker in the stochastic balancer does not pick regions with least locality as candidates for swap/move. So when any user configures locality cost in the configs, the balancer does not always seems to move regions with bad locality. 2. When a cluster has equal number of loaded regions, it always picks the first one. It should pick a random region on one of the equally loaded servers. This improves a chance of finding a good candidate, when load picker is invoked several times.</description>
      <version>1.0.0,0.98.12</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestStochasticLoadBalancer2.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestStochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.BalancerTestBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.RegionLocationFinder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
    </fixedFiles>
  </bug>
  <bug id="1338" opendate="2009-4-22 00:00:00" fixdate="2009-4-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBASE-1234 lost use of compaction.dir; we were compacting into live store subdirectory</summary>
      <description>Found up on Ryan's cluster.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.BaseScanner.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13473" opendate="2015-4-15 00:00:00" fixdate="2015-4-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>deleted cells come back alive after the stripe compaction</summary>
      <description>during the STRIPE compaction,deletes(tombstones) are being dropped in 2 cases.1. Compaction including L0 (includeL0 == true)2. L0 has no files (canDropDeletesWithoutL0 == true)To drop delete marker and keep the consistency during compaction, All of HFiles in the stripe has to be selected, just like major compaction.otherwise, after the compaction only delete markers would be gone, and deleted cells (which is in the not-selected HFiles) are going to be alive again.In my cluster, there was no file on L0(canDropDeletesWithoutL0==true) and not all files are selected for compaction, so some of deleted rows have come back alive and appears when i get or scan after compactions.I made a patch about it.it checks if all files are selected before we set the majorRange of compaction request .</description>
      <version>1.0.1,1.1.0,0.98.12,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.13,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.compactions.TestStripeCompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy.java</file>
    </fixedFiles>
  </bug>
  <bug id="13527" opendate="2015-4-22 00:00:00" fixdate="2015-4-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The default value for hbase.client.scanner.max.result.size is never actually set on Scans</summary>
      <description>Now that max result size is driven from the client side like caching (HBASE-13362), we also need to set Scan.maxResultSize to the default value of hbase.client.scanner.max.result.size which is never performed. I think this has gone unnoticed because the server used to read the configuration hbase.client.scanner.max.result.size for itself, but now we expect the serialized Scan sent from the client side to contain this information. Realistically this should have been set on the Scans even before HBASE-13362, it's surprising that it's not as the scanner code seems to indicate otherwise.Ultimately, the end result is that, by default, scan RPC's are limited by hbase.server.scanner.max.result.size (note this is the new server side config not the client side config) which has a default value of 100 MB. The scan RPC's should instead be limited by hbase.client.scanner.max.result.size which has a default value of 2 MB.The reason why this issue occurs is because, by default, a new Scan() initializes Scan.maxResultSize to -1. This initial value of -1 will never be changed unless Scan#setMaxResultSize() is called. In the event that this value is not changed, the Scan that is serialized and sent to the server will also have Scan.maxResultSize = -1. Then, when the server is deciding what size limit should be enforced, it sees that Scan.maxResultSize = -1 so it uses the most relaxed size restriction possible, which is hbase.server.scanner.max.result.size (default value 100 MB).</description>
      <version>1.0.0,1.1.0,0.98.12,1.2.0,2.0.0</version>
      <fixedVersion>1.1.0,0.98.12,1.0.2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannersFromClientSide.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.TableConfiguration.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="13528" opendate="2015-4-22 00:00:00" fixdate="2015-4-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>A bug on selecting compaction pool</summary>
      <description>When the selectNow == true, in requestCompactionInternal, the compaction pool section is incorrect.as discussed in:http://mail-archives.apache.org/mod_mbox/hbase-dev/201504.mbox/%3CCAAAYAnNC06E-pUG_Fhu9-7x5z--tm_apnFqpuqfn%3DLdNESE3mA%40mail.gmail.com%3E</description>
      <version>0.98.12</version>
      <fixedVersion>1.1.0,0.98.13,1.0.2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
    </fixedFiles>
  </bug>
  <bug id="13561" opendate="2015-4-25 00:00:00" fixdate="2015-7-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ITBLL.Verify doesn&amp;#39;t actually evaluate counters after job completes</summary>
      <description>Was digging through ITBLL and noticed this oddity:The Verify Tool doesn't actually call Verify#verify(long) like the Loop Tool does. Granted, it doesn't know the total number of KVs that were written given the current arguments, it's not even checking to see if there things like UNDEFINED records found.It seems to me that Verify should really be doing some checking on the counters like Loop does and not just leaving it up to the visual inspection of whomever launched the task.Am I missing something?</description>
      <version>1.0.0,1.1.0,0.98.12,2.0.0</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
    </fixedFiles>
  </bug>
  <bug id="13563" opendate="2015-4-25 00:00:00" fixdate="2015-4-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add missing table owner to AC tests.</summary>
      <description>As per the description.</description>
      <version>None</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
    </fixedFiles>
  </bug>
  <bug id="13608" opendate="2015-5-1 00:00:00" fixdate="2015-5-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>413 Error with Stargate through Knox, using AD, SPNEGO, and Pre-Auth</summary>
      <description>Jody Steadman reported that attempts to access Stargate via Apache Knox using curl ends with 413 error when the following conditions are met:AD is being used directly for KerberosThe knox principal is configured to require Kerberos pre-authStargate is using SPNEGOPre-auth errors exist in Kerberos debug log outputsumit.gupta found that the gateway logs in the environment provided by Jody Steadman has the following error:2015-04-20 14:24:21,660 DEBUG http.headers (DefaultClientConnection.java:sendRequestHeader(273)) - &gt;&gt; GET /version?doAs=jsteadman HTTP/1.12015-04-20 14:24:21,661 DEBUG http.headers (DefaultClientConnection.java:sendRequestHeader(276)) - &gt;&gt; Host: node1.jodylaptop.net:600802015-04-20 14:24:21,661 DEBUG http.headers (DefaultClientConnection.java:sendRequestHeader(276)) - &gt;&gt; Connection: Keep-Alive2015-04-20 14:24:21,661 DEBUG http.headers (DefaultClientConnection.java:sendRequestHeader(276)) - &gt;&gt; User-Agent: Apache-HttpClient/4.2.5 (java 1.5)2015-04-20 14:24:21,661 DEBUG http.headers (DefaultClientConnection.java:sendRequestHeader(276)) - &gt;&gt; Authorization: Negotiate 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-04-20 14:24:21,664 DEBUG http.wire (Wire.java:wire(63)) - &lt;&lt; "HTTP/1.1 413 FULL head[\r][\n]"2015-04-20 14:24:21,665 DEBUG http.wire (Wire.java:wire(63)) - &lt;&lt; "Connection: close[\r][\n]"2015-04-20 14:24:21,666 DEBUG http.wire (Wire.java:wire(63)) - &lt;&lt; "[\r][\n]"Sumit suggested using large buffer size in hbase REST Server to get rid of the "FULL Head" error</description>
      <version>0.98.12</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.RESTServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="13694" opendate="2015-5-15 00:00:00" fixdate="2015-5-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CallQueueSize is incorrectly decremented until the response is sent</summary>
      <description>We should decrement the CallQueueSize as soon as we no longer need the call around, e.g. after RpcServer.CurCall.set(null) otherwise we will be only pushing back other client requests while we send the response back to the client that originated the call.</description>
      <version>1.1.0,0.98.12,1.0.2,1.2.0,2.0.0</version>
      <fixedVersion>1.2.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.CallRunner.java</file>
    </fixedFiles>
  </bug>
  <bug id="13885" opendate="2015-6-10 00:00:00" fixdate="2015-6-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ZK watches leaks during snapshots</summary>
      <description>When taking snapshot of a table a watcher over /hbase/online-snapshot/abort/snapshot-name is created which is never cleared when the snapshot is successful. If we use snapshots to take backups daily we accumulate a lot of watches.Steps to reproduce -1) Take snapshot of a table - snapshot 'table_1', 'abc'2) Run the following on zk node or alternatively observe zk watches metric echo "wchc" | nc localhost 2181/hbase/online-snapshot/abort/abc can be found.</description>
      <version>0.98.12</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.1,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureMemberRpcs.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureCoordinatorRpcs.java</file>
    </fixedFiles>
  </bug>
  <bug id="13959" opendate="2015-6-24 00:00:00" fixdate="2015-6-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Region splitting uses a single thread in most common cases</summary>
      <description>When storefiles need to be split as part of a region split, the current logic uses a threadpool with the size set to the size of the number of stores. Since most common table setup involves only a single column family, this translates to having a single store and so the threadpool is run with a single thread. However, in a write heavy workload, there could be several tens of storefiles in a store at the time of splitting, and with a threadpool size of one, these files end up getting split sequentially.With a bit of tracing, I noticed that it takes on an average of 350ms to create a single reference file, and splitting each storefile involves creating two of these, so with a storefile count of 20, it takes about 14s just to get through this phase alone (2 reference files for each storefile), pushing the total time the region is offline to 18s or more. For environments that are setup to fail fast, this makes the client exhaust all retries and fail with NotServingRegionException.The fix should increase the concurrency of this operation.</description>
      <version>0.98.12</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.2,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransactionImpl.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="1396" opendate="2009-5-9 00:00:00" fixdate="2009-5-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove unused sequencefile and mapfile config. from hbase-default.xml</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="14000" opendate="2015-6-30 00:00:00" fixdate="2015-7-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Region server failed to report to Master and was stuck in reportForDuty retry loop</summary>
      <description>In a HA cluster, region server got stuck in reportForDuty retry loop if the active master is restarting and later on master switch happens before it reports successfully.Root cause is same as HBASE-13317, but the region server tried to connect master when it was starting, so rssStub reset didnt happen as if (ioe instanceof ServerNotRunningYetException) { LOG.debug("Master is not running yet"); }When master starts, master switch happened. So RS always tried to connect to standby master.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.1.2,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="14063" opendate="2015-7-13 00:00:00" fixdate="2015-7-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use BufferBackedCell in read path after HBASE-12213 and HBASE-12295</summary>
      <description>Subtask to ensure that the BytebufferBackedCell gets used in the read path after HBASE-12213 and HBASE-12295 goes in. This would help to clearly change the required places and makes the review easier.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.bucket.TestByteBufferIOEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.BloomFilterUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.SizeCachedNoTagsKeyValue.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.ByteBufferIOEngine.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteBufferUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.OffheapKeyOnlyKeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.NoTagsKeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValueUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
    </fixedFiles>
  </bug>
  <bug id="1460" opendate="2009-5-31 00:00:00" fixdate="2009-6-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Concurrent LRU Block Cache</summary>
      <description>The LRU-based block cache that will be committed in HBASE-1192 is thread-safe but contains a big lock on the hash map. Under high load, the block cache will be hit very heavily from a number of threads, so it needs to be built to handle massive concurrency.This issue aims to implement a new block cache with LRU eviction, but backed by a ConcurrentHashMap and a separate eviction thread. Influence will be drawn from Solr's ConcurrentLRUCache, however there are major differences because solr treats all cached elements as equal size whereas we are dependent on our HeapSize interface with realistic (though approximate) heap usage.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.transactional.CleanOldTransactionsChore.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.transactional.TransactionManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HLog.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.io.TestHeapSize.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.hfile.SimpleBlockCache.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.hfile.BlockCache.java</file>
      <file type="M">conf.hbase-site.xml</file>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
    </fixedFiles>
  </bug>
  <bug id="14600" opendate="2015-10-13 00:00:00" fixdate="2015-10-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make #testWalRollOnLowReplication looser still</summary>
      <description>The parent upped timeouts on testWalRollOnLowReplication. It still fails on occasion. Chatting w/ mbertozzi, he suggested that if we've make progress in the test, return the test as compeleted successfully if we get a RuntimeException out of the sync call....(because DN is slow to recover).</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestWALProcedureStoreOnHDFS.java</file>
    </fixedFiles>
  </bug>
  <bug id="15087" opendate="2016-1-9 00:00:00" fixdate="2016-1-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix hbase-common findbugs complaints</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestByteBufferUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.UnsafeAccess.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.DynamicClassLoader.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.DNS.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteBufferUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.CopyOnWriteArrayMap.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ProcedureInfo.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.OffheapKeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.JitterScheduledThreadPoolExecutorImpl.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellComparator.java</file>
    </fixedFiles>
  </bug>
</bugrepository>
