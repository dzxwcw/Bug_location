<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="18269" opendate="2017-6-26 00:00:00" fixdate="2017-6-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Jython docs out of date</summary>
      <description>The documentation describing how to launch Jython + HBase is out of date. - https://hbase.apache.org/book.html#jythonFirst, we would set the classpath differently:HBASE_CLASSPATH=/home/hbase/jython.jar bin/hbase org.python.util.jythonThen, the actual code example is out of date too:&gt;&gt;&gt; desc = HTableDescriptor(tablename)&gt;&gt;&gt; desc.addFamily(HColumnDescriptor("content:"))Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; at org.apache.hadoop.hbase.HColumnDescriptor.isLegalFamilyName(HColumnDescriptor.java:566) at org.apache.hadoop.hbase.HColumnDescriptor.&lt;init&gt;(HColumnDescriptor.java:470) at org.apache.hadoop.hbase.HColumnDescriptor.&lt;init&gt;(HColumnDescriptor.java:425) at org.apache.hadoop.hbase.HColumnDescriptor.&lt;init&gt;(HColumnDescriptor.java:390) at org.apache.hadoop.hbase.HColumnDescriptor.&lt;init&gt;(HColumnDescriptor.java:338) at org.apache.hadoop.hbase.HColumnDescriptor.&lt;init&gt;(HColumnDescriptor.java:327) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:526) at org.python.core.PyReflectedConstructor.constructProxy(PyReflectedConstructor.java:211)We should make sure that the examples we claim are runnable actually are.</description>
      <version>1.3.1,1.2.6,1.5.0,1.4.2,2.0.0</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.external.apis.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="19391" opendate="2017-11-30 00:00:00" fixdate="2017-2-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Calling HRegion#initializeRegionInternals from a region replica can still re-create a region directory</summary>
      <description>This is a follow up from HBASE-18024. There stills a chance that attempting to open a region that is not the default region replica can still create a GC'd region directory by the CatalogJanitor causing inconsistencies with hbck.</description>
      <version>2.0.0-alpha-4,1.4.2</version>
      <fixedVersion>2.0.0-beta-2,1.3.3,1.4.3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionFileSystem.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionOpen.java</file>
    </fixedFiles>
  </bug>
  <bug id="20019" opendate="2018-2-19 00:00:00" fixdate="2018-2-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document the ColumnValueFilter</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="2002" opendate="2009-11-21 00:00:00" fixdate="2009-11-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Coprocessors: Client side support</summary>
      <description>"High-level call interface for clients. Unlike RPC, calls addressed to rows or ranges of rows. Coprocessor client library resolves to actual locations. Calls across multiple rows automatically split into multiple parallelized RPCs"Generic multicall RPC facility which incorporates this and multiget/multiput/multidelete and parallel scanners.Group and batch RPCs by region server. Track and retry outstanding RPCs. Ride over region relocations. Support addressing by explicit region identifier or by row key or row key range. Include a facility for merging results client side.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.resources.hbase-default.xml</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HRegionInterface.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HBaseServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HBaseRPCProtocolVersion.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HBaseRPC.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HBaseClient.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.HbaseObjectWritable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.MultiResponse.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.MultiAction.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HTableInterface.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnection.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.Action.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2009" opendate="2009-11-24 00:00:00" fixdate="2009-11-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[EC2] support mapreduce subsystem</summary>
      <description>Feedback up on hbase-user@ from Naresh Rapolu: Your scripts are working fine. We restarted everything and tested, and they are working fine. A few issues though : While starting, launch-hbase-cluster gives the following error. error: "fs.epoll.max_user_instance" is an unknown key. It occurs during starting zookeeper instances. We needed MapReduce along with HBase. The note on the JIRA page that you only need to add only two lines in hbase-ec2-env.sh is insufficient. The following changes need to be made. 1. hbase-ec2-env.sh should write mapred.job.tracker property into hadoop-site.xml ( Also shouldnt you be having core-site.xml and hdfs-site.xml as it is hadoop-0.20.1 ??? Infact because of this , there are warning messages all over the place when you are using hdfs through command line ). 2. HADOOP_CLASSPATH in hadoop/conf/hadoop-env.sh needs to be changed in the underlying AMI, to include hbase, zookeeper jars and conf directory. Probably you can modify the public AMI, and recreate the bundle as the paths to these are known apriori. 3. For other users, the following three lines should be added in hbase-ec2-env.sh For master: "$HADOOP_HOME"/bin/hadoop-daemon.sh start jobtracker "$HADOOP_HOME"/bin/hadoop-daemon.sh start tasktracker For slave: "$HADOOP_HOME"/bin/hadoop-daemon.sh start tasktracker.</description>
      <version>None</version>
      <fixedVersion>0.95.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.contrib.ec2.bin.hbase-ec2-init-zookeeper-remote.sh</file>
      <file type="M">src.contrib.ec2.bin.hbase-ec2-init-remote.sh</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2011" opendate="2009-11-25 00:00:00" fixdate="2009-11-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add zktop like output to HBase&amp;#39;s master UI (zk.jsp)</summary>
      <description>It would be nice to add a zktop (http://github.com/phunt/zktop#readme) like output to the master's zk.jsp. That way one could quickly gather important insights on the ZK status.</description>
      <version>None</version>
      <fixedVersion>0.20.3,0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="20110" opendate="2018-3-1 00:00:00" fixdate="2018-3-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Findbugs in zk and mr caused nightly #409 branch-2 to fail</summary>
      <description>Build nightly #409 on branch-2 passed all unit tests on hadoop2 and hadoop3 and then failed because of extant findbugs issues in zk and mr.Here was report from the nightly:01:24:40 | Vote | Subsystem | Runtime | Comment01:24:40 ============================================================================01:24:40 | 0 | reexec | 0m 17s | Docker mode activated. 01:24:40 | | | | Prechecks 01:24:40 | | | | Compile Tests 01:24:40 | 0 | mvndep | 0m 10s | Maven dependency ordering 01:24:40 | +1 | mvninstall | 3m 23s | the source passed 01:24:40 | +1 | compile | 3m 17s | the source passed 01:24:40 | -0 | javac | 3m 17s | root has 32 issues. 01:24:40 | 0 | findbugs | 0m 1s | Skipped 15 modules in the source tree 01:24:40 | | | | with no Java source.01:24:40 | -1 | findbugs | 0m 22s | hbase-zookeeper in branch-2 has 3 extant 01:24:40 | | | | Findbugs warnings.01:24:40 | -1 | findbugs | 0m 32s | hbase-mapreduce in branch-2 has 1 extant 01:24:40 | | | | Findbugs warnings.01:24:40 | | | | Other Tests 01:24:40 | +1 | unit | 158m 41s | root in the source passed. 01:24:40 | | | 180m 39s | A couple of dead assigns and a compareTo w/o an equals ignored in original class but copy-paste was missing the findbugs exemption.</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-zookeeper.src.main.java.org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.Import.java</file>
    </fixedFiles>
  </bug>
  <bug id="20111" opendate="2018-3-1 00:00:00" fixdate="2018-3-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Able to split region explicitly even on shouldSplit return false from split policy</summary>
      <description>Currently able to split the region explicitly even when the split policy returns from shouldSplit.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin1.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.SplitTableRegionProcedure.java</file>
    </fixedFiles>
  </bug>
  <bug id="20112" opendate="2018-3-1 00:00:00" fixdate="2018-4-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Include test results from nightly hadoop3 tests in jenkins test results</summary>
      <description>right now our nightly tests that run atop hadoop 3 are reported on pass/fail but aren't recorded via the jenkins reporting mechanism.we should add them.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0,1.3.3,1.4.4,2.0.1,1.2.7</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  <bug id="2327" opendate="2010-3-15 00:00:00" fixdate="2010-3-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[EC2] Allocate elastic IP addresses for ZK and master nodes</summary>
      <description>Amazon EC2 supports Elastic IP Addresses to implement the effect of having a static IP address for public servers running on EC2. Up on hbase-users@ there was some recent discussion, confirmed, that when an EC2 instance queries the external DNS name of an elastic IP address, EC2 DNS returns the internal IP address of the instance to which the elastic IP address is bound, so it is safe to use elastic IPs for the ZK and master nodes. We gain the ability to do transparent replacement of one instance, e.g. failed, with another without incurring any additional cost. Update launch-hbase-zookeeper and launch-hbase-master to allocate elastic IPs: $ ec2-allocate-address ADDRESS 1.1.1.1and then assign the elastic IP address to the appropriate instance(s):$ ec2-associate-address -i i-11111111 1.1.1.1ADDRESS 1.1.1.1 i-11111111and then get the external DNS name to use when performing substitutions on master and slave configs:$ ec2-describe-instances i-11111111 | egrep ^INSTANCE | cut -f4ec2-1-1-1-1.compute-1.amazonaws.comWhen shutting down the cluster, just release the elastic IPs after terminating the instances:ec2-release-address 1.1.1.1...NOTE: AWS accounts default to a limit of 5 Elastic IP addresses but most will run with 1 master and 3 or 1 ZK instances. And, the ZK ensemble can be shared. A follow up issue can address making scripts to launch replacements for failed instances transparently.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">contrib.ec2.bin.terminate-hbase-cluster</file>
      <file type="M">contrib.ec2.bin.launch-hbase-zookeeper</file>
      <file type="M">contrib.ec2.bin.launch-hbase-slaves</file>
      <file type="M">contrib.ec2.bin.launch-hbase-master</file>
      <file type="M">contrib.ec2.bin.image.create-hbase-image-remote</file>
      <file type="M">contrib.ec2.bin.hbase-ec2-env.sh</file>
      <file type="M">contrib.ec2.bin.create-hbase-image</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="23829" opendate="2020-2-11 00:00:00" fixdate="2020-4-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Get `-PrunSmallTests` passing on JDK11</summary>
      <description>Start with the small tests, shaking out issues identified by the harness. So far it seems like -Dhadoop.profile=3.0 and -Dhadoop-three.version=3.3.0-SNAPSHOT maybe be required.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-with-hadoop-check-invariants.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-check-invariants.pom.xml</file>
      <file type="M">hbase-http.src.test.java.org.apache.hadoop.hbase.http.log.TestLogLevel.java</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestFutureUtils.java</file>
    </fixedFiles>
  </bug>
</bugrepository>
