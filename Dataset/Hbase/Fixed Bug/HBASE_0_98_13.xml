<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="13374" opendate="2015-4-1 00:00:00" fixdate="2015-4-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Small scanners (with particular configurations) do not return all rows</summary>
      <description>I recently ran into a couple data loss issues with small scans. Similar to HBASE-13262, these issues only appear when scans are configured in such a way that the max result size limit is reached before the caching limit is reached. As far as I can tell, this issue affects branches 0.98+I should note that after investigation it looks like the root cause of these issues is not the same as HBASE-13262. Rather, these issue are caused by errors in the small scanner logic (I will explain in more depth below). Furthermore, I do know that the solution from HBASE-13262 has not made its way into small scanners (it is being addressed in HBASE-13335). As a result I made sure to test these issues with the patch from HBASE-13335 applied and I saw that they were still present.The following two issues have been observed (both lead to data loss):1. When a small scan is configured with a caching value of Integer.MAX_VALUE, and a maxResultSize limit that is reached before the region is exhausted, integer overflow will occur. This eventually leads to a preemptive skip of the regions.2. When a small scan is configured with a maxResultSize that is smaller than the size of a single row, the small scanner will jump between regions preemptively. This issue seems to be because small scanners assume that, unless a region is exhausted, at least 2 rows will be returned from the server. This assumption isn't clearly state in the small scanners but is implied through the use of skipRowOfFirstResult.Again, I would like to stress that the root cause of these issues is NOT related to the cause of HBASE-13262. These issues occur because of inappropriate assumption made in the small scanner logic. The inappropriate assumptions are:1. Integer overflow will not occur when incrementing caching2. At least 2 rows will be returned from the server unless the region has been exhaustedI am attaching a patch that contains tests to display these issues. If these issues should be split into separate JIRAs please let me know.</description>
      <version>1.0.0,1.1.0,0.98.13,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannersFromClientSide.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallReversedScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="13375" opendate="2015-4-1 00:00:00" fixdate="2015-5-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Provide HBase superuser higher priority over other users in the RPC handling</summary>
      <description>HBASE-13351 annotates Master RPCs so that RegionServer RPCs are treated with a higher priority compared to user RPCs (and they are handled by a separate set of handlers, etc.). It may be good to stretch this to users too - hbase superuser (configured via hbase.superuser) gets higher priority over other users in the RPC handling. That way the superuser can always perform administrative operations on the cluster even if all the normal priority handlers are occupied (for example, we had a situation where all the master's handlers were tied up with many simultaneous createTable RPC calls from multiple users and the master wasn't able to perform any operations initiated by the admin). (Discussed this some with enis and elserj).Does this make sense to others?</description>
      <version>None</version>
      <fixedVersion>1.2.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestQosFunction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestPriorityRpc.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterPriorityRpc.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.AnnotationReadingPriorityFunction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.PriorityFunction.java</file>
    </fixedFiles>
  </bug>
  <bug id="1359" opendate="2009-4-30 00:00:00" fixdate="2009-7-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>After a large truncating table HBase becomes unresponsive</summary>
      <description>If you see **** I removed and ip or something for security reasonsOnce I truncate the table, hbase freaks out for about 10 seconds and all the thrift servers die.Thrift server log:2009-04-02 12:09:08,971 INFO org.apache.hadoop.ipc.HBaseClass: Retrying connect to server: /*****:60020. Already tried 0 time(s).You see this a bunch of times and then it times outThe hbase shellnhbase(main):001:0&gt; truncate 't2'09/04/30 13:01:08 INFO zookeeper.ZooKeeperWrapper: Quorum servers: ****Truncating t2; it may take a whileDisabling table...09/04/30 13:01:19 INFO client.HBaseAdmin: Disabled t20 row(s) in 10.3417 secondsDropping table...09/04/30 13:01:19 INFO client.HBaseAdmin: Deleted t20 row(s) in 0.1592 secondsCreating table...0 row(s) in 14.7567 secondshbase(main):002:0&gt; lsitNameError: undefined local variable or method `lsit' for #&lt;Object:0x3bbe9a50&gt; from (hbase):3hbase(main):003:0&gt; lsitNameError: undefined local variable or method `lsit' for #&lt;Object:0x3bbe9a50&gt; from (hbase):4hbase(main):004:0&gt; listNativeException: java.lang.NullPointerException: null from org/apache/hadoop/hbase/client/HConnectionManager.java:344:in `processRow' from org/apache/hadoop/hbase/client/MetaScanner.java:64:in `metaScan' from org/apache/hadoop/hbase/client/MetaScanner.java:29:in `metaScan' from org/apache/hadoop/hbase/client/HConnectionManager.java:351:in `listTables' from org/apache/hadoop/hbase/client/HBaseAdmin.java:121:in `listTables' from sun/reflect/NativeMethodAccessorImpl.java:-2:in `invoke0' from sun/reflect/NativeMethodAccessorImpl.java:39:in `invoke' from sun/reflect/DelegatingMethodAccessorImpl.java:25:in `invoke' from java/lang/reflect/Method.java:597:in `invoke' from org/jruby/javasupport/JavaMethod.java:298:in `invokeWithExceptionHandling' from org/jruby/javasupport/JavaMethod.java:259:in `invoke' from org/jruby/java/invokers/InstanceMethodInvoker.java:36:in `call' from org/jruby/runtime/callsite/CachingCallSite.java:260:in `cacheAndCall' from org/jruby/runtime/callsite/CachingCallSite.java:75:in `call' from org/jruby/ast/CallNoArgNode.java:61:in `interpret' from org/jruby/ast/ForNode.java:101:in `interpret'... 113 levels... from org/jruby/internal/runtime/methods/DynamicMethod.java:226:in `call' from org/jruby/internal/runtime/methods/CompiledMethod.java:216:in `call' from org/jruby/internal/runtime/methods/CompiledMethod.java:71:in `call' from org/jruby/runtime/callsite/CachingCallSite.java:260:in `cacheAndCall' from org/jruby/runtime/callsite/CachingCallSite.java:75:in `call' from home/fds/ts/hadoop/hbase/bin/$dot_dot/bin/hirb.rb:441:in `_file_' from home/fds/ts/hadoop/hbase/bin/$dot_dot/bin/hirb.rb:-1:in `_file_' from home/fds/ts/hadoop/hbase/bin/$dot_dot/bin/hirb.rb:-1:in `load' from org/jruby/Ruby.java:564:in `runScript' from org/jruby/Ruby.java:467:in `runNormally' from org/jruby/Ruby.java:340:in `runFromMain' from org/jruby/Main.java:214:in `run' from org/jruby/Main.java:100:in `run' from org/jruby/Main.java:84:in `main' from /home/fds/ts/hadoop/hbase/bin/../bin/hirb.rb:300:in `list' from (hbase):5hbase(main):005:0&gt;hbase(main):006:0*</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13647" opendate="2015-5-8 00:00:00" fixdate="2015-6-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Default value for hbase.client.operation.timeout is too high</summary>
      <description>Default value for hbase.client.operation.timeout is too high, it is LONG.Max.That value will block any service calls to coprocessor endpoints indefinitely.Should we introduce better default value for that?</description>
      <version>1.0.1,0.98.13,1.2.0,1.1.1,2.0.0</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="13746" opendate="2015-5-22 00:00:00" fixdate="2015-5-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>list_replicated_tables command is not listing table in hbase shell.</summary>
      <description>IN HBase shell prompt execute the following commandlist_replicated_tableshbase(main):014:0&gt; list_replicated_tablesTABLE:COLUMNFAMILY ReplicationTypeERROR: undefined method `TNAME' for Java::OrgApacheHadoopHbaseClientReplication::ReplicationAdmin:ClassHere is some help for this command:List all the tables and column families replicated from this cluster hbase&gt; list_replicated_tables hbase&gt; list_replicated_tables 'abc.*' list.select {|s| pattern.match(s.get(ReplicationAdmin.TNAME))}</description>
      <version>1.1.0,0.98.13,1.0.2,2.0.0</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.replication.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug id="13770" opendate="2015-5-25 00:00:00" fixdate="2015-10-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Programmatic JAAS configuration option for secure zookeeper may be broken</summary>
      <description>While verifying the patch fix for HBASE-13768 we were unable to successfully test the programmatic JAAS configuration option for secure ZooKeeper integration. Unclear if that was due to a bug or incorrect test configuration.Update the security section of the online book with clear instructions for setting up the programmatic JAAS configuration option for secure ZooKeeper integration.Verify it works.Fix as necessary.</description>
      <version>1.0.1,1.1.0,0.98.13,1.2.0,2.0.0</version>
      <fixedVersion>1.2.0,1.3.0,0.98.15,1.0.3,1.1.3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZooKeeperACL.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMasterCommandLine.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.HQuorumPeer.java</file>
    </fixedFiles>
  </bug>
  <bug id="13789" opendate="2015-5-28 00:00:00" fixdate="2015-6-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ForeignException should not be sent to the client</summary>
      <description>ForeignException is in hbase-server so the client will not be able to deserialize it, and also it will hide the DoNotRetryException of the cause.I haven't found an easy way to test it, aside manually looking at the logs. and this stuff will go away with proc-v2. so for now the easy workaround is catch the ForeignException in the master which are just the few places related to proc-v1 and throw the cause to the client</description>
      <version>0.98.13,1.0.1.1,1.1.0.1,2.0.0</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="13826" opendate="2015-6-2 00:00:00" fixdate="2015-6-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unable to create table when group acls are appropriately set.</summary>
      <description>Steps for reproducing the issue. Create user 'test' and group 'hbase-admin'. Grant global create permissions to 'hbase-admin'. Add user 'test' to 'hbase-admin' group. Create table operation for 'test' user will throw ADE.</description>
      <version>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.TableAuthManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="13926" opendate="2015-6-17 00:00:00" fixdate="2015-6-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Close the scanner only after Call#setResponse</summary>
      <description>This is for HBASE-12295. We will be delivering cells directly from shared cache memory. HBASE-12295 adds a ref count based prevention mechanism to avoid block eviction, when that memory area in use by scanners. We will decrement ref count at scanner close. The memory area will be in use till a cellblock is created or PB scan reply message is built. So we can delay the close of the scanner until the response is set for the scanner Call. This is done via a RpcCallback way. The callback is set on Call at scan time. Once the setResponse is done, the Call will execute the RpcCallback.This jira also adds a facility to do some cleanup/close during the course of scan. Scan from client makes many RPCs fetching N rows each time. Only at the end the scanner close will happen. We will add a new batchClose() facility with which we can do any cleanup after every rpc call is executed and rows fetched for return.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.NonLazyKeyValueScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Leases.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.KeyValueScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.KeyValueHeap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcCallContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.HalfStoreFileReader.java</file>
    </fixedFiles>
  </bug>
  <bug id="13933" opendate="2015-6-18 00:00:00" fixdate="2015-6-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>DBE&amp;#39;s seekBefore with tags corrupts the tag&amp;#39;s offset information thus leading to incorrect results</summary>
      <description>The problem occurs with moveToPrevious() case and incase of tags we copy the previous pointer's tag info to the current because already decoded the tags.Will check once again before I post other details. I have a test case to reproduce the problem. Found this while working with MultibyteBuffers and verified if this is present in trunk - it is in all branches where we have tags compression (I suppose) will verify</description>
      <version>1.0.0,1.0.1,1.1.0,0.98.13,1.0.1.1,1.1.0.1,2.0.0</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.1,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestSeekTo.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
    </fixedFiles>
  </bug>
  <bug id="13938" opendate="2015-6-19 00:00:00" fixdate="2015-6-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Deletes done during the region merge transaction may get eclipsed</summary>
      <description>Was looking at an issue from our internal testing. It seems the Deletes of the region rows from the meta done during the merge transaction could be eclipsed by the Put of a region row that might have happened moments before.The master logs this for the merge:2015-06-18 13:13:46,018 INFO [AM.ZK.Worker-pool2-t12] master.AssignmentManager: Handled MERGED event; merged=IntegrationTestIngest,a666665c,1434633226681.0927319db6bf5e128e3bec2a420819aa., region_a=IntegrationTestIngest,a666665c,1434631353820.8b911862d7705ac808b8d132d0154c16., region_b=IntegrationTestIngest,acccccc2,1434631353820.1bdaf759862f45d133ef77fdbda21aec., on ddas-2-5.openstacklocal,16020,1434632778438One of the regions that got merged got Opened a few seconds back:2015-06-18 13:13:46,591 INFO [RS_OPEN_REGION-ddas-2-5:16020-1] regionserver.HRegion: Onlined 1bdaf759862f45d133ef77fdbda21aec; next sequenceid=182988The above would have done a Put in the meta.Looking at the raw scan of the meta, for the new merged region, the creation timestamp is 1434633226101: IntegrationTestIngest,a666665c,1434633226681.0927319db6bf5e128e3bec2a420819aa. column=info:regioninfo, timestamp=1434633226101, value={ENCODED =&gt; 0927319db6bf5e128e3bec2a420819aa, NAME =&gt; 'IntegrationTestIngest,a666665c,1434633226681.0927319db6bf5e128e3bec2a420819aa.', STARTKEY =&gt; 'a666665c', ENDKEY =&gt; 'b3333328'}Looking at the raw scan of the meta, the timestamp for the region open of the already merged region is 1434633226600. This is a little after the merge transaction's timestamp.IntegrationTestIngest,acccccc2,1434631353820.1bdaf759862f45d133ef77fdbda21aec. column=info:seqnumDuringOpen, timestamp=1434633226600, value=\x00\x00\x00\x00\x00\x02\xCA\xCC IntegrationTestIngest,acccccc2,1434631353820.1bdaf759862f45d133ef77fdbda21aec. column=info:server, timestamp=1434633226600, value=ddas-2-5.openstacklocal:16020 IntegrationTestIngest,acccccc2,1434631353820.1bdaf759862f45d133ef77fdbda21aec. column=info:serverstartcode, timestamp=1434633226600, value=1434632778438We need to fix it so that the merge region transaction also takes the master's timestamp. Similar to HBASE-13875.When this happens, clients start to see a row in the meta with an empty HRegionInfo (this is because the Put done during the region open only updates the location information but not the HRI, and the HRI deleted during the merge transaction "remains deleted").</description>
      <version>None</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.1,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestMetaTableAccessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionMergeRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStateStore.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Admin.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.AdminProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MetaTableAccessor.java</file>
    </fixedFiles>
  </bug>
  <bug id="13969" opendate="2015-6-25 00:00:00" fixdate="2015-6-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>AuthenticationTokenSecretManager is never stopped in RPCServer</summary>
      <description>AuthenticationTokenSecretManager is never stopped in RPCServer. AuthenticationTokenSecretManager mgr = createSecretManager(); if (mgr != null) { setSecretManager(mgr); mgr.start(); }It should be stopped during exit.</description>
      <version>0.98.13</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.2,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="13985" opendate="2015-6-29 00:00:00" fixdate="2015-8-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add configuration to skip validating HFile format when bulk loading</summary>
      <description>When bulk loading millions of HFile into one HTable, checking HFile format is the most time-consuming phase. Maybe we could use a parallel mechanism to increase the speed, but when it comes to millions of HFiles, it may still cost dozens of minutes. So I think it's necessary to add an option for advanced user to bulkload without checking HFile format at all. Of course, the default value of this option should be true.</description>
      <version>0.98.13</version>
      <fixedVersion>0.98.14,1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
    </fixedFiles>
  </bug>
  <bug id="13996" opendate="2015-6-30 00:00:00" fixdate="2015-8-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add write sniffing in canary</summary>
      <description>Currently the canary tool only sniff the read operations, it's hard to finding the problem in write path. To support the write sniffing, we create a system table named 'canary' in the canary tool. And the tool will make sure that the region number is large than the number of the regionserver and the regions will be distributed onto all regionservers.Periodically, the tool will put data to these regions to calculate the write availability of HBase and send alerts if needed.</description>
      <version>0.98.13,1.1.0.1</version>
      <fixedVersion>0.98.14,1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.Canary.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="14045" opendate="2015-7-9 00:00:00" fixdate="2015-7-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bumping thrift version to 0.9.2.</summary>
      <description>From mailing list conversation:Currently, HBase is using Thrift 0.9.0 version, with the latest version being 0.9.2. Currently, the HBase Thrift gateway is vulnerable to crashes due to THRIFT-2660 when used with default transport and the workaround for this problem is switching to framed transport. Unfortunately, the recently added impersonation support [1] doesn't work with framed transport leaving thrift gateway using this feature susceptible to crashes. Updating thrift version to 0.9.2 will help us in mitigating this problem. Given that security is one of key requirements for the production clusters, it would be good to ensure our users that security features in thrift gateway can be used without any major concerns. Aside this, there are also some nice fixes pertaining to leaky resources in 0.9.2 like [2] and [3].As far compatibility guarantees are concerned, thrift assures 100% wire compatibility. However, it is my understanding that there were some minor additions (new API) in 0.9.2 [4] which won't work in 0.9.0, but that won't affect us since we are not using those features. And I tried running test suite and did manual testing with thrift version set to 0.9.2 and things are running smoothly. If there are no objections to this change, I would be more than happy to file a jira and follow this up.[1] https://issues.apache.org/jira/browse/HBASE-11349[2] https://issues.apache.org/jira/browse/THRIFT-2274[3] https://issues.apache.org/jira/browse/THRIFT-2359[4] https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12310800&amp;version=12324954</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="14193" opendate="2015-8-7 00:00:00" fixdate="2015-9-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove support for direct upgrade from pre-0.96 versions</summary>
      <description>As discussed on the mailing list this will remove all support for upgrades from pre-0.96 versions.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSTableDescriptorMigrationToSubdir.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">bin.hbase.cmd</file>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug id="14196" opendate="2015-8-7 00:00:00" fixdate="2015-8-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thrift server idle connection timeout issue</summary>
      <description>When idle connection get cleaned from Thrift server, underlying table instances are still cached in a thread local cache.This is the antipattern. Table objects are lightweight and should not be cached, besides this, underlying connections can be closed by periodic connection cleaner chore (ConnectionCache) and cached table instances may become invalid. This is Thrift1 specific issue. Thrift2 is OK.</description>
      <version>0.98.13,1.1.1,1.0.1.1,1.1.0.1</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.2,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.IncrementCoalescer.java</file>
    </fixedFiles>
  </bug>
  <bug id="14198" opendate="2015-8-7 00:00:00" fixdate="2015-10-7 01:00:00" resolution="Invalid">
    <buginformation>
      <summary>Eclipse project generation is broken in master</summary>
      <description>After running mvn eclipse:eclipse I tried to import projects into Eclipse (Luna) and got multiple build errors, similar to:Cannot nest output folder 'hbase-thrift/target/test-classes/META-INF' inside output folder 'hbase-thrift/target/test-classes' hbase-thrift</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="14230" opendate="2015-8-17 00:00:00" fixdate="2015-9-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>replace reflection in FSHlog with HdfsDataOutputStream#getCurrentBlockReplication()</summary>
      <description>As comment TODO said, we use HdfsDataOutputStream#getCurrentBlockReplication and DFSOutputStream.getPipeLine to replace reflection in FSHlog</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
    </fixedFiles>
  </bug>
</bugrepository>
