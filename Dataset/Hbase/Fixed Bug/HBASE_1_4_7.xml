<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="20890" opendate="2018-7-15 00:00:00" fixdate="2018-8-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>PE filterScan seems to be stuck forever</summary>
      <description>Command Used~/current/bigdata-hbase/hbase/hbase/bin/hbase pe --nomapred randomWrite 1 &gt; write 2&gt;&amp;1~/current/bigdata-hbase/hbase/hbase/bin/hbase pe --nomapred filterScan 1 &gt; filterScan 2&gt;&amp;1 OutputThis kept running for several hours just printing the below messages in logs -bash-4.1$ grep "Advancing internal scanner to startKey" filterScan.1 | head2018-07-13 10:44:45,188 DEBUG [TestClient-0] client.ClientScanner - Advancing internal scanner to startKey at '0000000000000000000052359'2018-07-13 10:44:45,976 DEBUG [TestClient-0] client.ClientScanner - Advancing internal scanner to startKey at '0000000000000000000052359'2018-07-13 10:44:46,695 DEBUG [TestClient-0] client.ClientScanner - Advancing internal scanner to startKey at '0000000000000000000052359'.....-bash-4.1$ grep "Advancing internal scanner to startKey" filterScan.1 | tail2018-07-15 06:20:22,353 DEBUG [TestClient-0] client.ClientScanner - Advancing internal scanner to startKey at '0000000000000000000052359'2018-07-15 06:20:23,044 DEBUG [TestClient-0] client.ClientScanner - Advancing internal scanner to startKey at '0000000000000000000052359'2018-07-15 06:20:23,768 DEBUG [TestClient-0] client.ClientScanner - Advancing internal scanner to startKey at '0000000000000000000052359' </description>
      <version>3.0.0-alpha-1,1.5.0,1.3.3,2.2.0,1.4.7</version>
      <fixedVersion>3.0.0-alpha-1,1.3.3,2.2.0,1.4.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
    </fixedFiles>
  </bug>
  <bug id="21058" opendate="2018-8-15 00:00:00" fixdate="2018-8-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Nightly tests for branches 1 fail to build ref guide</summary>
      <description>Nightly on all branches 1 reports failure to get a PDF version of the ref guide-1 refguide 2m 14s patch failed to produce the pdf version of the reference guide.Actual build log looks clean[INFO] --- asciidoctor-maven-plugin:1.5.2.1:process-asciidoc (output-pdf) @ hbase ---asciidoctor: WARNING: conversion missing in backend pdf for inline_indextermasciidoctor: WARNING: conversion missing in backend pdf for inline_indextermasciidoctor: WARNING: conversion missing in backend pdf for inline_indextermasciidoctor: WARNING: conversion missing in backend pdf for inline_indextermasciidoctor: WARNING: conversion missing in backend pdf for inline_indextermasciidoctor: WARNING: conversion missing in backend pdf for passasciidoctor: WARNING: conversion missing in backend pdf for inline_indextermasciidoctor: WARNING: conversion missing in backend pdf for inline_indextermasciidoctor: WARNING: conversion missing in backend pdf for inline_indextermasciidoctor: WARNING: conversion missing in backend pdf for inline_indextermasciidoctor: WARNING: conversion missing in backend pdf for inline_imageasciidoctor: WARNING: conversion missing in backend pdf for inline_image[INFO] Rendered /testptch/hbase/src/main/asciidoc/book.adoc</description>
      <version>1.5.0,1.3.3,1.2.7,1.4.7</version>
      <fixedVersion>3.0.0-alpha-1,1.3.3,2.2.0,1.2.7,2.1.1,2.0.2,1.4.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  <bug id="21070" opendate="2018-8-17 00:00:00" fixdate="2018-5-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>SnapshotFileCache won&amp;#39;t update for snapshots stored in S3</summary>
      <description>The SnapshotFileCache depends on last modified time to determine whether to update the Snapshot HFile cache. However, in S3, real 'folders' don't exist. S3 filesystems create a dummy file in place of a folder, but the dummy file last modified time is not updated when files are changed 'under' it. This means that the SnapshotFileCache doesn't pick up new snapshot HFiles and these files aren't removed from the HFileCleaner and can be eligible for deletion. My patch removes the lastmodified assumption.</description>
      <version>3.0.0-alpha-1,2.1.1,1.4.7</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.snapshot.TestSnapshotFileCache.java</file>
    </fixedFiles>
  </bug>
  <bug id="21074" opendate="2018-8-20 00:00:00" fixdate="2018-8-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>JDK7 branches need to pass "-Dhttps.protocols=TLSv1.2" to maven when building</summary>
      <description>Maven central now requires TLSv1.2 and by default JDK7 doesn't use it. So anyone building from a clean repo will fail like our nightly check of building the convenience binary from the source tarball e.g. 1.4[INFO] Scanning for projects...[INFO] Downloading from apache release: https://repository.apache.org/content/repositories/releases/org/apache/apache/18/apache-18.pom[INFO] Downloaded from apache release: https://repository.apache.org/content/repositories/releases/org/apache/apache/18/apache-18.pom (16 kB at 14 kB/s)[INFO] Downloading from Nexus: http://repository.apache.org/snapshots/org/apache/felix/maven-bundle-plugin/2.5.3/maven-bundle-plugin-2.5.3.pom[INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/apache/felix/maven-bundle-plugin/2.5.3/maven-bundle-plugin-2.5.3.pom[ERROR] [ERROR] Some problems were encountered while processing the POMs:[ERROR] Unresolveable build extension: Plugin org.apache.felix:maven-bundle-plugin:2.5.3 or one of its dependencies could not be resolved: Failed to read artifact descriptor for org.apache.felix:maven-bundle-plugin:jar:2.5.3 @ @ [ERROR] The build could not read 1 project -&gt; [Help 1][ERROR] [ERROR] The project org.apache.hbase:hbase:1.4.7-SNAPSHOT (/home/jenkins/jenkins-slave/workspace/HBase_Nightly_branch-1.4-EDDBHIHAYHZVAGB2FQL37O5LZNSEJJEXGP55DEGOA4FQKBLNWBAQ/unpacked_src_tarball/pom.xml) has 1 error[ERROR] Unresolveable build extension: Plugin org.apache.felix:maven-bundle-plugin:2.5.3 or one of its dependencies could not be resolved: Failed to read artifact descriptor for org.apache.felix:maven-bundle-plugin:jar:2.5.3: Could not transfer artifact org.apache.felix:maven-bundle-plugin:pom:2.5.3 from/to central (https://repo.maven.apache.org/maven2): Received fatal alert: protocol_version -&gt; [Help 2][ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.[ERROR] Re-run Maven using the -X switch to enable full debug logging.[ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles:[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException[ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/PluginManagerExceptionif we pass "-Dhttps.protocols=TLSv1.2" to maven then it should work for any JDK7 version.</description>
      <version>1.5.0,1.3.3,1.2.7,1.4.7</version>
      <fixedVersion>3.0.0-alpha-1,1.3.3,2.2.0,1.2.7,2.1.1,2.0.2,1.4.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  <bug id="21077" opendate="2018-8-20 00:00:00" fixdate="2018-8-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>MR job launched by hbase incremental backup command failed with FileNotFoundException</summary>
      <description>Discovered during internal testing by Romil Choksi.MR job launched by hbase incremental backup command failed with FileNotFoundExceptionfrom test console log2018-06-12 04:27:31,160|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|2018-06-12 04:27:31,160 INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_1528766389356_00442018-06-12 04:27:31,186|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|2018-06-12 04:27:31,184 INFO [main] mapreduce.JobSubmitter: Executing with tokens: [Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:ns1, Ident: (token for hbase: HDFS_DELEGATION_TOKEN owner=hbase@EXAMPLE.COM, renewer=yarn, realUser=, issueDate=1528777648605, maxDate=1529382448605, sequenceNumber=175, masterKeyId=2), Kind: kms-dt, Service: 172.27.68.203:9393, Ident: (kms-dt owner=hbase, renewer=yarn, realUser=, issueDate=1528777649149, maxDate=1529382449149, sequenceNumber=49, masterKeyId=2), Kind: HBASE_AUTH_TOKEN, Service: bc71e347-78ff-4f95-af44-006f9b549a84, Ident: (org.apache.hadoop.hbase.security.token.AuthenticationTokenIdentifier@5), Kind: kms-dt, Service: 172.27.52.14:9393, Ident: (kms-dt owner=hbase, renewer=yarn, realUser=, issueDate=1528777648918, maxDate=1529382448918, sequenceNumber=50, masterKeyId=2)]2018-06-12 04:27:31,477|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|2018-06-12 04:27:31,477 INFO [main] conf.Configuration: found resource resource-types.xml at file:/etc/hadoop/3.0.0.0-1476/0/resource-types.xml2018-06-12 04:27:31,527|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|2018-06-12 04:27:31,527 INFO [main] impl.TimelineClientImpl: Timeline service address: ctr-e138-1518143905142-359429-01-000004.hwx.site:81902018-06-12 04:27:32,563|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|2018-06-12 04:27:32,562 INFO [main] impl.YarnClientImpl: Submitted application application_1528766389356_00442018-06-12 04:27:32,634|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|2018-06-12 04:27:32,634 INFO [main] mapreduce.Job: The url to track the job: https://ctr-e138-1518143905142-359429-01-000003.hwx.site:8090/proxy/application_1528766389356_0044/2018-06-12 04:27:32,635|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|2018-06-12 04:27:32,635 INFO [main] mapreduce.Job: Running job: job_1528766389356_00442018-06-12 04:27:44,807|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|2018-06-12 04:27:44,806 INFO [main] mapreduce.Job: Job job_1528766389356_0044 running in uber mode : false2018-06-12 04:27:44,809|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|2018-06-12 04:27:44,809 INFO [main] mapreduce.Job: map 0% reduce 0%2018-06-12 04:27:54,926|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|2018-06-12 04:27:54,925 INFO [main] mapreduce.Job: map 5% reduce 0%2018-06-12 04:27:56,950|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|2018-06-12 04:27:56,950 INFO [main] mapreduce.Job: Task Id : attempt_1528766389356_0044_m_000002_0, Status : FAILED2018-06-12 04:27:56,979|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|Error: java.io.FileNotFoundException: File does not exist: hdfs://ns1/apps/hbase/data/oldWALs/ctr-e138-1518143905142-359429-01-000004.hwx.site%2C16020%2C1528776085205.15287761609152018-06-12 04:27:56,979|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1583)2018-06-12 04:27:56,980|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1576)2018-06-12 04:27:56,980|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)2018-06-12 04:27:56,980|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1591)2018-06-12 04:27:56,980|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.hbase.regionserver.wal.ReaderBase.init(ReaderBase.java:64)2018-06-12 04:27:56,981|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader.init(ProtobufLogReader.java:165)2018-06-12 04:27:56,981|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.hbase.wal.WALFactory.createReader(WALFactory.java:289)2018-06-12 04:27:56,981|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.hbase.wal.WALFactory.createReader(WALFactory.java:271)2018-06-12 04:27:56,981|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.hbase.wal.WALFactory.createReader(WALFactory.java:259)2018-06-12 04:27:56,981|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.hbase.wal.WALFactory.createReader(WALFactory.java:395)2018-06-12 04:27:56,982|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.hbase.wal.AbstractFSWALProvider.openReader(AbstractFSWALProvider.java:449)2018-06-12 04:27:56,982|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.hbase.mapreduce.WALInputFormat$WALRecordReader.openReader(WALInputFormat.java:166)2018-06-12 04:27:56,982|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.hbase.mapreduce.WALInputFormat$WALRecordReader.initialize(WALInputFormat.java:158)2018-06-12 04:27:56,983|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:560)2018-06-12 04:27:56,983|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:798)2018-06-12 04:27:56,983|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)2018-06-12 04:27:56,983|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)2018-06-12 04:27:56,983|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at java.security.AccessController.doPrivileged(Native Method)2018-06-12 04:27:56,984|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at javax.security.auth.Subject.doAs(Subject.java:422)2018-06-12 04:27:56,984|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1686)2018-06-12 04:27:56,984|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)2018-06-12 04:27:56,984|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|But looks like it did find the file on hdfs, test script runs incremental backup command as HBase user.2018-06-12 04:27:30,756|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|2018-06-12 04:27:30,755 DEBUG [main] mapreduce.WALInputFormat: Scanning hdfs://ns1/apps/hbase/data/oldWALs/ctr-e138-1518143905142-359429-01-000004.hwx.site%2C16020%2C1528776085205.1528776160915 for WAL files2018-06-12 04:27:30,758|INFO|MainThread|machine.py:167 - run()||GUID=cb1d85c9-023c-4bc5-bf87-9c231c917eab|2018-06-12 04:27:30,758 INFO [main] mapreduce.WALInputFormat: Found: HdfsLocatedFileStatus{path=hdfs://ns1/apps/hbase/data/oldWALs/ctr-e138-1518143905142-359429-01-000004.hwx.site%2C16020%2C1528776085205.1528776160915; isDirectory=false; length=18031; replication=3; blocksize=268435456; modification_time=1528776689363; access_time=1528776160921; owner=hbase; group=hdfs; permission=rwx--x--x; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false}</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-backup.src.test.java.org.apache.hadoop.hbase.backup.TestIncrementalBackup.java</file>
      <file type="M">hbase-backup.src.test.java.org.apache.hadoop.hbase.backup.TestBackupBase.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.impl.IncrementalBackupManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="21465" opendate="2018-11-11 00:00:00" fixdate="2018-11-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Retry on reportRegionStateTransition can lead to unexpected errors</summary>
      <description>It is possible that the reportRegionStateTransition method is succeeded at master side, but before returning the the region server, the rpc connection is broken, or the master restarts. So next when the region server try again,we will find that the state for the region and the TRSP is not correct, and can lead to a RS abort or something even worse.We should be able to determine whether a reportRegionStateTransition call is just a retry and has already been succeeded, and just ignore it.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.assignment.TestAssignmentManagerBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.TransitRegionStateProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.assignment.TestReportRegionStateTransitionRetry.java</file>
    </fixedFiles>
  </bug>
  <bug id="2222" opendate="2010-2-12 00:00:00" fixdate="2010-2-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve log "Trying to contact region server Some server for region , row &amp;#39;ip_info_100,,1263329969690&amp;#39;, but failed after 11 attempts."</summary>
      <description>Get the table we're trying to do lookup on in there at least and tell it like it is, that nothing was found for and the asked-for lookup.</description>
      <version>None</version>
      <fixedVersion>0.20.4,0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="23829" opendate="2020-2-11 00:00:00" fixdate="2020-4-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Get `-PrunSmallTests` passing on JDK11</summary>
      <description>Start with the small tests, shaking out issues identified by the harness. So far it seems like -Dhadoop.profile=3.0 and -Dhadoop-three.version=3.3.0-SNAPSHOT maybe be required.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-with-hadoop-check-invariants.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-check-invariants.pom.xml</file>
      <file type="M">hbase-http.src.test.java.org.apache.hadoop.hbase.http.log.TestLogLevel.java</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestFutureUtils.java</file>
    </fixedFiles>
  </bug>
</bugrepository>
