<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="1587" opendate="2009-6-26 00:00:00" fixdate="2009-6-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update ganglia config and doc to account for ganglia 3.1 and hadoop-4675</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.hadoop-metrics.properties</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="15870" opendate="2016-5-20 00:00:00" fixdate="2016-6-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Specify columns in REST multi gets</summary>
      <description>The REST multi-gets feature currently does not allow specifying only certain columns or column families. Adding support for these should be quite simple and improve the usability of the multi-gets feature.</description>
      <version>None</version>
      <fixedVersion>1.3.0,0.98.21,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.TestMultiRowResource.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.TableResource.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.MultiRowResource.java</file>
    </fixedFiles>
  </bug>
  <bug id="20153" opendate="2018-3-8 00:00:00" fixdate="2018-3-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>enable error-prone analysis in precommit</summary>
      <description>We've done a lot of work to get rid of the error-prone errors, we should make sure they stay out. Let's enable errorProne profile and analysis in precommit.busbey - I tried figuring out how to pass flags (-PerrorProne to the mvn compile precommit check but was unable to unravel that thread. Any help is appreciated.</description>
      <version>None</version>
      <fixedVersion>1.4.3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  <bug id="20163" opendate="2018-3-9 00:00:00" fixdate="2018-4-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Forbid major compaction when standby cluster replay the remote wals</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MockRegionServerServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="20164" opendate="2018-3-9 00:00:00" fixdate="2018-3-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>failed hadoopcheck should add footer link</summary>
      <description>thought for sure this already had an issue, busbey, but I can't find it.</description>
      <version>None</version>
      <fixedVersion>1.3.2,1.4.3,2.0.0,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  <bug id="20165" opendate="2018-3-9 00:00:00" fixdate="2018-3-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Shell command to make a normal peer to be a serial replication peer</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.test.ruby.hbase.replication.admin.test.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.list.peers.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.rb</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.replication.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug id="2017" opendate="2009-11-30 00:00:00" fixdate="2009-11-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Set configurable max value size check to 10MB</summary>
      <description>Make the user think about whether storing larger values than 10MB is a good idea.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="20189" opendate="2018-3-13 00:00:00" fixdate="2018-3-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Typo in Required Java Version error message while building HBase.</summary>
      <description>Change 'requirs' to 'requires'. See below:$ mvn clean install -DskipTests...[WARNING] Rule 2: org.apache.maven.plugins.enforcer.RequireJavaVersion failed with message:Java is out of date.  HBase requirs at least version 1.8 of the JDK to properly build from source.  You appear to be using an older version. You can use either "mvn -version" or  "mvn enforcer:display-info" to verify what version is active.  See the reference guide on building for more information: http://hbase.apache.org/book.html#build</description>
      <version>None</version>
      <fixedVersion>1.3.2,1.4.3,2.0.0,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="2019" opendate="2009-12-1 00:00:00" fixdate="2009-12-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[EC2] Prompt for and remember credentials if not configured</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.contrib.ec2.bin.image.create-hbase-image-remote</file>
      <file type="M">src.contrib.ec2.bin.hbase-ec2-env.sh</file>
      <file type="M">src.contrib.ec2.bin.create-hbase-image</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="20190" opendate="2018-3-14 00:00:00" fixdate="2018-3-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix default for MIGRATE_TABLE_STATE_FROM_ZK_KEY</summary>
      <description>All works but the flag name will confuse: name is MIGRATE_TABLE_STATE_FROM_ZK_KEY but you'd set it to true to NOT migrate from zk. Found by tedyu in the parent issue.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableStateManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="2041" opendate="2009-12-12 00:00:00" fixdate="2009-2-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change WAL default configuration values</summary>
      <description>My last email on the thread "Should we change the default value of hbase.regionserver.flushlogentries for 0.21?"Ok to make sure I get this right: we enable deferred log flush by default we set flushlogentries=1Also since 10 seconds is kind of a huge window I propose that: we set optionalLogFlush=1000which is the MySQL default. We also have to update the wiki (there'salready an entry on deferred log flush) by adding the configuration offlushlogentries.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
    </fixedFiles>
  </bug>
  <bug id="20410" opendate="2018-4-13 00:00:00" fixdate="2018-4-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>upgrade protoc compiler to 3.5.1-1</summary>
      <description>See HBASE-20356After doing the cleanup there, I was informed that there's a 3.5.1-1 version of the compiler binaries that work on rhel6, so let's just go to that. Wish I knew about it beforehand.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
      <file type="M">hbase-protocol-shaded.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="20438" opendate="2018-4-17 00:00:00" fixdate="2018-4-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add an HBase antipattern check for reintroducing commons-logging</summary>
      <description>We moved to slf4j in HBASE-10092, but looking at our source tree we've had some regression back to commons-logging:$ git grep -E "org.apache.commons.logging.Log(Factory|;)"hbase-server/src/main/java/org/apache/hadoop/hbase/master/zksyncer/ClientZKSyncer.java:import org.apache.commons.logging.Log;hbase-server/src/main/java/org/apache/hadoop/hbase/master/zksyncer/ClientZKSyncer.java:import org.apache.commons.logging.LogFactory;hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/FileArchiverNotifierImpl.java:import org.apache.commons.logging.Log;hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/FileArchiverNotifierImpl.java:import org.apache.commons.logging.LogFactory;hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/RegionSizeReportingChore.java:import org.apache.commons.logging.Log;hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/RegionSizeReportingChore.java:import org.apache.commons.logging.LogFactory;hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/RegionSizeStoreImpl.java:import org.apache.commons.logging.Log;hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/RegionSizeStoreImpl.java:import org.apache.commons.logging.LogFactory;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/throttle/StoreHotnessProtector.java:import org.apache.commons.logging.Log;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/throttle/StoreHotnessProtector.java:import org.apache.commons.logging.LogFactory;hbase-server/src/test/java/org/apache/hadoop/hbase/TestClusterPortAssignment.java:import org.apache.commons.logging.Log;hbase-server/src/test/java/org/apache/hadoop/hbase/TestClusterPortAssignment.java:import org.apache.commons.logging.LogFactory;hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFlushFromClient.java:import org.apache.commons.logging.Log;hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFlushFromClient.java:import org.apache.commons.logging.LogFactory;hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSeparateClientZKCluster.java:import org.apache.commons.logging.Log;hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSeparateClientZKCluster.java:import org.apache.commons.logging.LogFactory;hbase-server/src/test/java/org/apache/hadoop/hbase/procedure/TestFailedProcCleanup.java:import org.apache.commons.logging.Log;hbase-server/src/test/java/org/apache/hadoop/hbase/procedure/TestFailedProcCleanup.java:import org.apache.commons.logging.LogFactory;hbase-server/src/test/java/org/apache/hadoop/hbase/wal/TestDisabledWAL.java:import org.apache.commons.logging.Log;hbase-server/src/test/java/org/apache/hadoop/hbase/wal/TestDisabledWAL.java:import org.apache.commons.logging.LogFactory;We should do the same kind of check that we do to avoid e.g. the Hadoop annotations</description>
      <version>3.0.0-alpha-1,2.1.0,2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  <bug id="20566" opendate="2018-5-10 00:00:00" fixdate="2018-5-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Creating a system table after enabling rsgroup feature puts region into RIT</summary>
      <description>Steps to reproduce Enable rsgroup feature Enable quota feature which created hbase::quota table quota table region will be marked as RIT since the rsgroup for the table is not known2018-05-10 14:33:32,392 INFO [ProcedureExecutorThread-0] zookeeper.ZKTableStateManager: Moving table hbase:quota state from null to ENABLING2018-05-10 14:33:32,397 WARN [ProcedureExecutorThread-0] rsgroup.RSGroupBasedLoadBalancer: Group for table hbase:quota is null2018-05-10 14:33:32,398 WARN [ProcedureExecutorThread-0] master.RegionStates: Failed to open/close 89490cd5e00ea8948af413a1df65091a on null, set to FAILED_OPEN2018-05-10 14:33:32,398 INFO [ProcedureExecutorThread-0] master.RegionStates: Transition {89490cd5e00ea8948af413a1df65091a state=OFFLINE, ts=1525977212397, server=null} to {89490cd5e00ea8948af413a1df65091a state=FAILED_OPEN, ts=1525977212398, server=null}2018-05-10 14:33:32,398 INFO [ProcedureExecutorThread-0] zookeeper.ZKTableStateManager: Moving table hbase:quota state from ENABLING to ENABLED Reason for this issue:  system table creation doesn't move the table to the appropriate rs group to which system namespace is assigned to. Need to execute logic similar to what is done in the RSGroupAdminEndpoint for post table creation for user table creation.Work Around Assigning the system table to default rsgroup (or to the rsgroup to which the system namespace has been assigned). Manually assigning the region in RIT from the system table  </description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-rsgroup.src.test.java.org.apache.hadoop.hbase.rsgroup.TestRSGroups.java</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupInfoManagerImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="20567" opendate="2018-5-11 00:00:00" fixdate="2018-5-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Pass both old and new descriptors to pre/post hooks of modify operations for table and namespace</summary>
      <description>In postModify* hooks like postModifyX(..., Descriptor newDesc), there's no way of getting the old descriptor which was there before modification happened.Having both old and new descriptors will make the hooks more useful.We felt the need when we wanted to audit certain events but there was no way of deducing them by just seeing 'after-state' of modification.To keep the method signatures consistent, i have modified both pre and post hooks with new arguments which are well named and commented.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0,2.0.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MasterObserver.java</file>
    </fixedFiles>
  </bug>
  <bug id="20720" opendate="2018-6-12 00:00:00" fixdate="2018-6-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make 2.0.1 release</summary>
      <description>Let me push out a release off branch-2.0, a 2.0.1. It has a bunch of fixes and some perf improvements. A nightly run just passed clean: https://builds.apache.org/view/H-L/view/HBase/job/HBase%20Nightly/job/branch-2.0/421/</description>
      <version>None</version>
      <fixedVersion>2.0.1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.downloads.xml</file>
    </fixedFiles>
  </bug>
  <bug id="20847" opendate="2018-7-5 00:00:00" fixdate="2018-7-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The parent procedure of RegionTransitionProcedure may not have the table lock</summary>
      <description>For example, SCP can also schedule AssignProcedure and obviously it will not hold the table lock.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1,2.0.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.SchemaLocking.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.LockStatus.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.LockAndQueue.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMasterProcedureScheduler.java</file>
    </fixedFiles>
  </bug>
  <bug id="2085" opendate="2009-12-31 00:00:00" fixdate="2009-12-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>StringBuffer -&gt; StringBuilder - conversion of references as necessary</summary>
      <description>Some references in toString() converted from StringBuffer to StringBuilder as concurrency is probably not needed in those contexts as the references do not get out of scope.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.mapreduce.DisabledBecauseVariableSubstTooLargeExceptionTestTableIndex.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapreduce.BuildTableIndex.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.TimeRange.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.ImmutableBytesWritable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.Result.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.Put.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.Get.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.Delete.java</file>
      <file type="M">src.contrib.stargate.src.java.org.apache.hadoop.hbase.stargate.model.TableRegionModel.java</file>
      <file type="M">src.contrib.stargate.src.java.org.apache.hadoop.hbase.stargate.client.Client.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="20860" opendate="2018-7-9 00:00:00" fixdate="2018-7-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Merged region&amp;#39;s RIT state may not be cleaned after master restart</summary>
      <description>In MergeTableRegionsProcedure, we issue UnassignProcedures to offline regions to merge. But if we restart master just after MergeTableRegionsProcedure finished these two UnassignProcedure and before it can delete their meta entries. The new master will found these two region is CLOSED but no procedures are attached to them. They will be regard as RIT regions and nobody will clean the RIT state for them later.A quick way to resolve this stuck situation in the production env is restarting master again, since the meta entries are deleted in MergeTableRegionsProcedure. Here, I offer a fix for this problem.</description>
      <version>3.0.0-alpha-1,2.1.0,2.0.1</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1,2.0.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.RegionStates.java</file>
    </fixedFiles>
  </bug>
  <bug id="20893" opendate="2018-7-16 00:00:00" fixdate="2018-8-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Data loss if splitting region while ServerCrashProcedure executing</summary>
      <description>Similar case as HBASE-20878.</description>
      <version>3.0.0-alpha-1,2.1.0,2.0.1</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1,2.0.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALSplitter.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.MasterProcedure.proto</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMergeTableRegionsWhileRSCrash.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.SplitTableRegionProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.MergeTableRegionsProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.AssignProcedure.java</file>
    </fixedFiles>
  </bug>
  <bug id="20928" opendate="2018-7-24 00:00:00" fixdate="2018-7-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Rewrite calculation of midpoint in binarySearch functions to prevent overflow</summary>
      <description>There are couple of issues in the function: &gt;&gt;&gt; operator would mess the values if low + high end up being negative. This shouldn't happen but I don't see anything to prevent this from happening. The code fails around boundary values of low and high. This is a well known binary search catch. https://ai.googleblog.com/2006/06/extra-extra-read-all-about-it-nearly.html Most of the code should already be covered by tests. I would have liked to add a test that actually fails without the fix but given these are private methods I am not sure on the best place to add the test. Suggestions?</description>
      <version>None</version>
      <fixedVersion>1.5.0,2.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CellFlatMap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.nio.ByteBuff.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.RowIndexSeekerV1.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Bytes.java</file>
    </fixedFiles>
  </bug>
  <bug id="20977" opendate="2018-7-30 00:00:00" fixdate="2018-7-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Don&amp;#39;t use the word "Snapshot" when defining "HBase Snapshots"</summary>
      <description>From http://hbase.apache.org/book.html#ops.snapshotsHBase Snapshots allow you to take a snapshot of a table without too much impact on Region ServersWe should change this to not use the word "snapshot" when defining what HBase Snapshots are. It's confusing enough to English-as-a-first-language individuals; I imagine it's even more cyclical to ESL individuals.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="20985" opendate="2018-7-31 00:00:00" fixdate="2018-8-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>add two attributes when we do normalization</summary>
      <description>Currently when we turn on normalization switch, it will help balance the whole table based on total region size / total region count. I add two attributes so that we can set total region count or average region size we want to achieve when normalization done.</description>
      <version>2.1.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.test.ruby.hbase.admin.test.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.alter.rb</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.normalizer.TestSimpleRegionNormalizer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.normalizer.SimpleRegionNormalizer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.TableDescriptorBuilder.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.TableDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="20986" opendate="2018-7-31 00:00:00" fixdate="2018-8-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Separate the config of block size when we do log splitting and write Hlog</summary>
      <description>Since the block size of recovered edits and hlog are the same right now, if we set a large value to block size, name node may not able to assign enough space when we do log splitting. But set a large value to hlog block size can help reduce the number of region server asking for a new block. Thus I think separate the config of block size is necessary.</description>
      <version>3.0.0-alpha-1,2.1.0,2.0.1,2.2.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.FSHLogProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="2100" opendate="2010-1-9 00:00:00" fixdate="2010-1-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[EC2] Adjust fs.file-max</summary>
      <description>From Robert Gibbon up on hbase-user@:Maybe you are running Red Hat? Just changing limits.conf I think won'twork because RH has a maximum total open files across the whole system,which is 4096 by default, unless you do something like this tooecho "32768" &gt; /proc/sys/fs/file-maxservice network restartTo make it permanent edit /etc/sysctl.conf to include the line: fs.file-max = 32768Update the remote init script appropriately.</description>
      <version>None</version>
      <fixedVersion>0.20.3,0.90.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.contrib.ec2.bin.hbase-ec2-init-remote.sh</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2103" opendate="2010-1-9 00:00:00" fixdate="2010-1-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[EC2] pull version from build</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.3,0.90.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.contrib.ec2.bin.image.create-hbase-image-remote</file>
      <file type="M">src.contrib.ec2.bin.hbase-ec2-env.sh</file>
      <file type="M">src.contrib.build-contrib.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="21032" opendate="2018-8-9 00:00:00" fixdate="2018-8-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ScanResponses contain only one cell each</summary>
      <description>I have a long row with a bunch of columns that I'm scanning with setAllowPartialResults(true). In the response I'm getting the first partial ScanResponse being around 2MB with multiple cells while all of the consequent ones being 1 cell per ScanResponse. After digging more, I found that each of those single cell ScanResponse partials are preceded by a heartbeat (zero cells). This results in two requests per cell to a regionserver.I've attached code to reproduce it on hbase version 2.1.0 (it works as expected on 2.0.0 and 2.0.1).App.javaI'm fairly certain it's a serverside issue as gohbase client is having the same issue. I have not tried to reproduce this with multi-row scan.</description>
      <version>2.1.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="21084" opendate="2018-8-21 00:00:00" fixdate="2018-8-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>When cloning a snapshot including a split parent region, the split parent region of the cloned table will be online</summary>
      <description>Investigating HBASE-21015, I found another issue. It seems like after HBASE-20881, the split parent region of the cloned table will be online when cloning a snapshot including a split parent region.Steps to reproduce are as follows, which is the same as the steps in HBASE-21015:1. Create a tablecreate "test", "cf"2. Put some data into the table(0...2000).each{|i| put "test", "row#{i}", "cf:col", "val"}3. Split the tablesplit "test"4. Take a snapshot of the table before CatalogJanitor cleans up the split parent regionsnapshot "test", "snap"5. Clone the snapshotclone_snapshot "snap", "cloned_table"After following the above steps, the split parent region of the cloned table will be online.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestCloneSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CloneSnapshotProcedure.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionReplicaUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="21153" opendate="2018-9-5 00:00:00" fixdate="2018-9-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Shaded client jars should always build in relevant phase to avoid confusion</summary>
      <description>edit:Now that our assembly directly relies on the shaded clients, failing to build the actual client jars (e.g. because -P release is required to fill in their contents) causes confusing errors for downstream folks about classes not being found when they run simple commands like hbase version.We should always fill in the shaded artifacts to make our build easier to understand.original report:: When I run the hbase version command it comes back with:$ ./bin/hbase versionError: Could not find or load main class org.apache.hadoop.hbase.util.GetJavaPropertyError: Could not find or load main class org.apache.hadoop.hbase.util.VersionInfoThe two classes are in hbase-commons.The nice shaded refactoring of our bin/hbase &amp;#8211; i.e. using shaded jars wherever possible &amp;#8211; may have overstretched expecting version to work with shaded client (busbey ?). If so, fix is &lt; one-liner.</description>
      <version>3.0.0-alpha-1,2.1.0,2.2.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shaded.hbase-shaded-mapreduce.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-client.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-client-byo-hadoop.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="21154" opendate="2018-9-5 00:00:00" fixdate="2018-11-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove hbase:namespace table; fold it into hbase:meta</summary>
      <description>Namespace table is a small system table. Usually it has two rows. It must be assigned before user tables but after hbase:meta goes out. Its presence complicates our startup and is a constant source of grief when for whatever reason, it is not up and available. In fact, master startup is predicated on hbase:namespace being assigned and will not make progress unless it is up.Lets just add a new 'ns' column family to hbase:meta for namespace.Here is a default ns table content:hbase(main):023:0* scan 'hbase:namespace'ROW COLUMN+CELL default column=info:d, timestamp=1526694059106, value=\x0A\x07default hbase column=info:d, timestamp=1526694059461, value=\x0A\x05hbase</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsckMOB.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestNamespace.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestGlobalMemStoreSize.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationWALEntryFilters.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.AbstractTestLogRolling.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerMetrics.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionReplicasWithRestartScenarios.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestPerColumnFamilyFlush.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestLogRoller.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRollingRestart.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRestartCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterRestartAfterDisablingTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterOperationsForRegionReplicas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterMetrics.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestProcedurePriority.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestModifyNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMasterProcedureScheduler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestFavoredStochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.assignment.TestRegionMoveAndAbandon.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.AbstractTestDLS.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncNamespaceAdminApi.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ZKNamespaceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSTableDescriptors.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableNamespaceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.TableQueue.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.TableProcedureInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.InitMetaProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CreateNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.AbstractStateMachineNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.locking.LockProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ClusterSchemaServiceImpl.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">hbase-rsgroup.src.test.java.org.apache.hadoop.hbase.rsgroup.TestRSGroupsBasics.java</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupInfoManagerImpl.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.MasterProcedure.proto</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.TableName.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.NamespaceDescriptor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.TableDescriptorBuilder.java</file>
    </fixedFiles>
  </bug>
  <bug id="21155" opendate="2018-9-5 00:00:00" fixdate="2018-9-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Save on a few log strings and some churn in wal splitter by skipping out early if no logs in dir</summary>
      <description>Trivial change to splitlogmanager that saves us a log line at least per WAL dir when it goes to split. Also saves some not-needed churn in SLM.</description>
      <version>2.1.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionServerTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterWalManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALFormat.java</file>
    </fixedFiles>
  </bug>
  <bug id="21157" opendate="2018-9-6 00:00:00" fixdate="2018-9-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Split TableInputFormatScan to individual tests</summary>
      <description>We have done a split in HBASE-8326, which split the test to two parts. But it is still a bit slow, split it into several tests can increase the parallelism and make the 'mvn test' run faster.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1,2.0.3</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScanBase.java</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan2.java</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan1.java</file>
    </fixedFiles>
  </bug>
  <bug id="21179" opendate="2018-9-10 00:00:00" fixdate="2018-9-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix the number of actions in responseTooSlow log</summary>
      <description>responseTooSlow2018-09-10 16:13:53,022 WARN &amp;#91;B.DefaultRpcServer.handler=209,queue=29,port=60020&amp;#93; ipc.RpcServer: (responseTooSlow): {"processingtimems":321262,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"127.0.0.1:56149","param":"region= tsdb,\\x00\\x00.[\\x89\\x1F\\xB0\\x00\\x00\\x01\\x00\\x01Y\\x00\\x00\\x02\\x00\\x00x04,1536133210446.7c752de470bd5558a001117b123a5db5., for 1 actions and 1st row key=\\x00\\x00.[\\x96x16p","starttimems":1536566911759,"queuetimems":0,"class":"HRegionServer","responsesize":2,"method":"Multi"}The responseTooSlow log is printed when the processing time of a request exceeds the specified threshold. The number of actions and the contents of the first rowkey in the request will be included in the log.However, the number of actions is inaccurate, and it is actually the number of regions that the request needs to visit.Just like the logs above, users may be mistaken for using 321262ms to process an action, which is incredible, so we need to fix it.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.3.3,1.2.8,2.2.0,1.4.8,2.1.1,2.0.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="21206" opendate="2018-9-18 00:00:00" fixdate="2018-9-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scan with batch size may return incomplete cells</summary>
      <description>See the attached UT. the table has 5 columns and each column has at least one cell in it, but when we scan the table with batchSize=3, we only got 3 cells returned , the other 2 cells got lost ...It's a critial bug and should be fixed..</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,1.4.8,2.1.1,2.0.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide3.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="21212" opendate="2018-9-20 00:00:00" fixdate="2018-9-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Wrong flush time when update flush metric</summary>
      <description></description>
      <version>3.0.0-alpha-1,2.1.0,2.0.2</version>
      <fixedVersion>3.0.0-alpha-1,1.3.3,2.2.0,1.4.8,2.1.1,2.0.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="21214" opendate="2018-9-20 00:00:00" fixdate="2018-9-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbck2] setTableState just sets hbase:meta state, not in-memory state</summary>
      <description>Means that we have to go get another Master to see the table state change because in-memory state is still pegged at the old value.TODO: Check the is_enabled/is_disabled shell commands to make sure they are reading from the right place.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="21215" opendate="2018-9-20 00:00:00" fixdate="2018-10-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Figure how to invoke hbck2; make it easy to find</summary>
      <description>In https://docs.google.com/document/d/1Oun4G3M5fyrM0OxXcCKYF8td0KD7gJQjnU9Ad-2t-uk/edit#, the doc on hbck2 'form', one item to figure is how to invoke hbck2. Related, how to make it easy to find? busbey has some ideas (posted in doc). This issue is for implementation.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1,2.0.3</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug id="21217" opendate="2018-9-21 00:00:00" fixdate="2018-9-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Revisit the executeProcedure method for open/close region</summary>
      <description>Currently we just call openRegion and closeRegion directly, which is a bit buggy. For example, in order to not fail all the open region requests while there is only one failure, we will catch the exception and set a flag in the return value. But for executeProcedures call, the return value will be ignored, and we expect the openRegion method will always call reportRegionStateTransition to report the failure but in fact it does not...And after HBASE-20881, we can confirm that the race could happen, where we send a close request to a region which is opening(HBASE-21199), and vice visa. So I think here we need to revisit the implementation of executeProcedures to make it more stable.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MockRegionServerServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.executor.ExecutorService.java</file>
    </fixedFiles>
  </bug>
  <bug id="21232" opendate="2018-9-26 00:00:00" fixdate="2018-9-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Show table state in Tables view on Master home page</summary>
      <description>Add a column to the Tables panel on the Master home page. Useful when trying to figure if table is enabled/disable/disabling/enabling...</description>
      <version>2.1.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="21233" opendate="2018-9-26 00:00:00" fixdate="2018-9-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow the procedure implementation to skip persistence of the state after a execution</summary>
      <description>Discussed with stack and allan163 on HBASE-21035, that when retrying we do not need to persist the procedure state every time, as the retry timeout is not a critical stuff. It is OK that we loss this information and start from 0 when after restarting.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1,2.0.3</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureExecutor.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.Procedure.java</file>
    </fixedFiles>
  </bug>
  <bug id="21254" opendate="2018-9-29 00:00:00" fixdate="2018-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Need to find a way to limit the number of proc wal files</summary>
      <description>For regionserver, we have a max wal file limitation, if we reach the limitation, we will trigger a flush on specific regions so that we can delete old wal files. But for proc wals, we do not have this mechanism, and it will be worse after HBASE-21233, as if there is an old procedure which can not make progress and do not persist its state, we need to keep the old proc wal file for ever...</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1,2.0.3</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.assignment.MockMasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.TestProcedureStoreTracker.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.ProcedureStoreTracker.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.ProcedureStoreBase.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.ProcedureStore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.BitSetNode.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureExecutor.java</file>
    </fixedFiles>
  </bug>
  <bug id="2126" opendate="2010-1-14 00:00:00" fixdate="2010-1-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix build break - ec2</summary>
      <description>Because all contrib/** reuses build-contrib.xml -, internally they reuse ivy-retrieve.xml and hence need the presence of an ivy.xml in ec2 directory to succeed. Temporary patch with no dependencies in . Ideal patch should be to refactor build&amp;#42;.xml as appropriate.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="21290" opendate="2018-10-11 00:00:00" fixdate="2018-10-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>No need to instantiate BlockCache for master which not carry table</summary>
      <description>In our production clusters, we use different jvm config for master/regionserver but use same hbase-site.xml for master/regionserver. And master has a small heap/offheap config. So the regionserver's hbase.bucketcache.size is not suitable for master. I thought we don't need to instantiate BlockCache for master which not carry table.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1,2.0.3</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.MobCacheConfig.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
    </fixedFiles>
  </bug>
  <bug id="21334" opendate="2018-10-18 00:00:00" fixdate="2018-10-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestMergeTableRegionsProcedure is flakey</summary>
      <description>Error Messagefound 5 corrupted procedure(s) on replayStacktracejava.io.IOException: found 5 corrupted procedure(s) on replay at org.apache.hadoop.hbase.master.assignment.TestMergeTableRegionsProcedure.testMergeWithoutPONR(TestMergeTableRegionsProcedure.java:295)</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1,2.0.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureTestingUtility.java</file>
    </fixedFiles>
  </bug>
  <bug id="21351" opendate="2018-10-20 00:00:00" fixdate="2018-11-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The force update thread may have race with PE worker when the procedure is rolling back</summary>
      <description>We will acquire the procExecutionLock for a procedure when force updating its state to prevent race with PE worker, but this does not work then the procedure is rolling back.If a procedure is failed, we will mark the root procedure stack as FAILED, and then start to rollback the whole procedure stack. We will pop every procedure in the stack and try to rollback them. So we may change the state of a procedure without holding its procExecutionLock when rolling back.This means we may persist an intermediate state of a procedure and cause corruption when loading procedures.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.0.3,2.1.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.wal.TestForceUpdateProcedure.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureExecutor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.IdLock.java</file>
    </fixedFiles>
  </bug>
  <bug id="21354" opendate="2018-10-21 00:00:00" fixdate="2018-10-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure may be deleted improperly during master restarts resulting in &amp;#39;Corrupt&amp;#39;</summary>
      <description>Good news! stack, Apache9, I may find the root cause of mysterious ‘Corrupted procedure’ or some procedures disappeared after master restarts(happens during ITBLL).This is because during master restarts, we load procedures from the log, and builds the 'holdingCleanupTracker' according each log's tracker. We may mark a procedure in the oldest log as deleted if one log doesn't contain the procedure. This is Inappropriate since one log will not contain info of the log if this procedure was not updated during the time. We can only delete the procedure only if it is not in the global tracker, which have the whole picture.trackerNode = tracker.lookupClosestNode(trackerNode, procId); if (trackerNode == null || !trackerNode.contains(procId) || trackerNode.isModified(procId)) { // the procedure was removed or modified node.delete(procId); }A test case(testProcedureShouldNotCleanOnLoad) shows cleanly how the corruption happened in the patch.</description>
      <version>2.1.0,2.0.2</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1,2.0.3</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.ProcedureStoreTracker.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.ProcedureTestingUtility.java</file>
    </fixedFiles>
  </bug>
  <bug id="21356" opendate="2018-10-21 00:00:00" fixdate="2018-10-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>bulkLoadHFile API should ensure that rs has the source hfile&amp;#39;s write permission</summary>
      <description>If the rs bulk load a HFile but has no write permission of it, we can read &amp; compact the hfile, but after the compaction finished, the HFile willl be moved to archive directory, the HFileCleaner won't has permission to delete, then the HFile will always be keep in HDFS. Need check the file's write permission when run bulkLoadHFile at server side, if no write permission, then reject.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.0.3,2.1.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="21396" opendate="2018-10-26 00:00:00" fixdate="2018-11-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create 2.1.1 release</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.1.1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.downloads.xml</file>
    </fixedFiles>
  </bug>
  <bug id="2140" opendate="2010-1-17 00:00:00" fixdate="2010-1-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>findbugs issues - 2 performance warnings as suggested by findbugs</summary>
      <description>Integer.valueOf favored instead of new Integer() map.entrySet() favored instead of map.keySet()</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="21400" opendate="2018-10-27 00:00:00" fixdate="2018-8-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>correct spelling error of &amp;#39;initilize&amp;#39; in comment</summary>
      <description>When I learned the code of HBase-RPC,I found a spelling error in the comment.Is the word "initilize" should be "initialize"?</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.1,2.1.6</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.BlockingRpcConnection.java</file>
    </fixedFiles>
  </bug>
  <bug id="21502" opendate="2018-11-20 00:00:00" fixdate="2018-4-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update SyncTable section on RefGuide once HBASE-20586 is committed</summary>
      <description>SyncTable refguide section currently mentions limitation to run it on different kerberos realm. HBASE-20586 is ongoing to resolve this problem. This jira is to make sure RefGuide is updated accordingly once HBASE-20586 is resolved.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="2164" opendate="2010-1-23 00:00:00" fixdate="2010-1-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Ivy nit - clean up configs</summary>
      <description>Ivy nits Hadoop core - renamed to Hadoop HBase as appropriate. irrelevant configurations - s3-server/ s3-client / jetty removed.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ivy.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="21640" opendate="2018-12-25 00:00:00" fixdate="2018-12-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove the TODO when increment zero</summary>
      <description> // If delta amount to apply is 0, don't write WAL or MemStore.long deltaAmount = getLongValue(delta);// TODO: Does zero value mean reset Cell? For example, the ttl.apply = deltaAmount != 0;This is an optimization when increment 0. But it introduced some new problems.1.As the TODO said, Does zero value mean reset ttl?2.HBASE-17318 have to introduce a new variable "firstWrite" because it don't apply 0.3. There is a coprocessor method postMutationBeforeWAL to return a new cell. But it may be not applied. // Give coprocessors a chance to update the new cellif (coprocessorHost != null) { newCell = coprocessorHost.postMutationBeforeWAL(mutationType, mutation, currentValue, newCell);}// If apply, we need to update memstore/WAL with new value; add it toApply.if (apply || firstWrite) { toApply.add(newCell);} So my proposal is remove this optimization. Any suggestions are welcomed.     </description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.2,2.0.4</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestDurability.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="21643" opendate="2018-12-26 00:00:00" fixdate="2018-12-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Introduce two new region coprocessor method and deprecated postMutationBeforeWAL</summary>
      <description>The old method postMutationBeforeWAL is not accurate about what it do. It is only called during increment and append. But the name is "Mutation"... And the javadoc only said it will be called by increment...* Called after a new cell has been created during an increment operation, but before* it is committed to the WAL or memstore. We use this coprocessor in our use case. And need add some cells to apply to WAL. So I introduced two new method postIncrementBeforeWAL and postAppendBeforeWAL to instead of this.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionObserver.java</file>
    </fixedFiles>
  </bug>
  <bug id="21976" opendate="2019-3-1 00:00:00" fixdate="2019-3-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Deal with RetryImmediatelyException for batching request</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.4</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncBatchRpcRetryingCaller.java</file>
    </fixedFiles>
  </bug>
  <bug id="21977" opendate="2019-3-1 00:00:00" fixdate="2019-3-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Skip replay WAL and update seqid when open regions restored from snapshot</summary>
      <description>TableSnapshotScanner restore a snapshot and then open the restored regions. When open these regions, we can skip replay WAL and update seqid.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestRestoreSnapshotHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ClientSideRegionScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="21978" opendate="2019-3-2 00:00:00" fixdate="2019-3-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Should close AsyncRegistry if we fail to get cluster id when creating AsyncConnection</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.4</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="22074" opendate="2019-3-20 00:00:00" fixdate="2019-3-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Should use procedure store to persist the state in reportRegionStateTransition</summary>
      <description>For now we will update the meta region directly. This may cause lots of problems and after a bunch of fixes, we still can not solve the problem in HBASE-22060.So maybe the approach itself is not a good choice, let's try another way to see if it could work better.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestServerRemoteProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.assignment.TestCloseRegionWhileRSCrash.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.assignment.TestAssignmentManagerBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.UnassignRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.AssignRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.RSProcedureDispatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.UnassignProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.TransitRegionStateProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.RegionRemoteProcedureBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.OpenRegionProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.CloseRegionProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.AssignProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.AssignmentManager.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.RegionServerStatus.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.MasterProcedure.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.Admin.proto</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="22077" opendate="2019-3-21 00:00:00" fixdate="2019-3-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expose sleep time as a command line argument of IntergationTestBackupRestore</summary>
      <description>Extend command line arguments of IntergationTestBackupRestore with a sleep time of chaos monkey options to be able to setup policy of region server restarts more granularly.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestBackupRestore.java</file>
    </fixedFiles>
  </bug>
  <bug id="2208" opendate="2010-2-10 00:00:00" fixdate="2010-6-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TableServers # processBatchOfRows - converts from List to [ ] - Expensive copy</summary>
      <description>With autoFlush to false and a large write buffer on HTable, when we write bulk puts - TableServer # processBatchOfRows , convert the input (List) to an [ ] , before sending down the wire. With a write buffer as large as 20 MB , that becomes an expensive copy when we do - list.toArray(new T[ ] ). May be - should we change the wire protocol to support List as well , and then revisit this to prevent the bulk copy ?Batch b = new Batch(this) { @Override int doCall(final List&lt;Row&gt; currentList, final byte [] row, final byte [] tableName) throws IOException, RuntimeException { *final Put [] puts = currentList.toArray(PUT_ARRAY_TYPE);* return getRegionServerWithRetries(new ServerCallable&lt;Integer&gt;(this.c, tableName, row) { public Integer call() throws IOException { return server.put(location.getRegionInfo().getRegionName(), puts); } }); }</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HRegionInterface.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="22312" opendate="2019-4-25 00:00:00" fixdate="2019-5-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hadoop 3 profile for hbase-shaded-mapreduce should like mapreduce as a provided dependency</summary>
      <description>the hadoop 3 profile currently misses declaring a provided dependency on the core mapreduce client module. that means we pick it up as a compile dependency from the hbase-mapreduce module, which means we include things in the shaded jar that we don't need to. (and expressly aren't supposed to include because they're supposed to come from Hadoop at runtime).</description>
      <version>2.1.0,2.2.0,2.1.1,2.1.2,2.1.3,2.1.4</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.5</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shaded.hbase-shaded-mapreduce.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="22314" opendate="2019-4-25 00:00:00" fixdate="2019-5-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>shaded byo-hadoop client should list needed hadoop modules as provided scope to avoid inclusion of unnecessary transitive depednencies</summary>
      <description>attempting to build against current hadoop trunk for HBASE-22087 shows that hte byo-hadoop client is trying to package transitive dependencies from the hadoop dependencies that we expressly say we don't need to bring with us.it's because we don't list those modules as provided, so all of their transitives are also in compile scope. The shading module does simple filtering when excluding things in a given scope, it doesn't e.g. make sure to also exclude the transitive dependencies of things it keeps out.since we don't want to list all the transitive dependencies of hadoop in our shading exclusion, we should list the needed hadoop modules as provided.</description>
      <version>2.1.0,2.2.0,2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.5</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shaded.hbase-shaded-client-byo-hadoop.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="22326" opendate="2019-4-29 00:00:00" fixdate="2019-5-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix Checkstyle errors in hbase-examples</summary>
      <description>Fix the remaining Checkstyle errors in the hbase-examples module and enable Checkstyle to fail on violations.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-examples.src.test.java.org.apache.hadoop.hbase.mapreduce.TestMapReduceExamples.java</file>
      <file type="M">hbase-examples.src.test.java.org.apache.hadoop.hbase.coprocessor.example.TestRefreshHFilesEndpoint.java</file>
      <file type="M">hbase-examples.src.test.java.org.apache.hadoop.hbase.coprocessor.example.TestRefreshHFilesBase.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.thrift.HttpDoAsClient.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.thrift.DemoClient.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.thrift2.DemoClient.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.mapreduce.SampleUploader.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.mapreduce.IndexBuilder.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.coprocessor.example.RefreshHFilesEndpoint.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.coprocessor.example.ExampleMasterObserverWithMetrics.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.coprocessor.example.BulkDeleteEndpoint.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.client.example.RefreshHFilesClient.java</file>
      <file type="M">hbase-examples.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="22327" opendate="2019-4-29 00:00:00" fixdate="2019-5-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix remaining Checkstyle issues in hbase-hadoop-compat</summary>
      <description>There is a single Checkstyle error left in the hbase-hadoop-compat module, which should be fixed.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsTableSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="22478" opendate="2019-5-27 00:00:00" fixdate="2019-5-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add jackson dependency for hbase-http module</summary>
      <description>We use Configuration.dumpConfiguration method in ConfServlet, which will reference jackson.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-http.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="22616" opendate="2019-6-21 00:00:00" fixdate="2019-6-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>responseTooXXX logging for Multi should characterize the component ops</summary>
      <description>Multi RPC can be a mix of gets and mutations. The responseTooXXX logging for Multi ops should characterize the operations within the request so we have some clue about whether read or write dispatch was involved.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,2.2.1,2.1.6,1.3.6,1.4.11</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="22624" opendate="2019-6-25 00:00:00" fixdate="2019-7-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Should sanity check table configuration when clone snapshot to a new table</summary>
      <description>HBASE-12570 imporved table configuration sanity checking. But it only worked for create table or alter table. Should check table configuration too when clone snapshot to a new table.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift.TestThriftSpnegoHttpServer.java</file>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift.TestThriftServerCmdLine.java</file>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift.TestThriftServer.java</file>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift.TestThriftHttpServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerMetrics.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestModifyTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestCreateTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSizeFailures.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestIncrementsFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestIncrementFromClientSideWithCoprocessor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestIllegalTableDescriptor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestBlockEvictionFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAvoidCellReferencesIntoShippedBlocks.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestRegionReplicaReplication.java</file>
    </fixedFiles>
  </bug>
  <bug id="22625" opendate="2019-6-25 00:00:00" fixdate="2019-8-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>documet use scan snapshot feature</summary>
      <description>Add the design doc in dev-support/design-docs{{ and describe }}the feature in the reference guide.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc.book.adoc</file>
      <file type="M">src.main.asciidoc..chapters.snapshot.scanner.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="22773" opendate="2019-7-31 00:00:00" fixdate="2019-8-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>when set blockSize option in Performance Evaluation tool, error occurs:ERROR: Unrecognized option/command: --blockSize=131072</summary>
      <description>I believe "blockSize" is an new options for PE in HBase2.0, when i try to set the blockSize, error occurs:ERROR: Unrecognized option/command: --blockSize=131072.The error occurs because of missing a "continue;" when we match the option "blockSize". If there isn't a "continue" the program will execute the last "printUsageAndExit branch".</description>
      <version>2.1.0,2.2.0,2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,2.0.6,2.2.1,2.1.6,1.4.11</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
    </fixedFiles>
  </bug>
  <bug id="22796" opendate="2019-8-6 00:00:00" fixdate="2019-9-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[HBCK2] Add fix of overlaps to fixMeta hbck Service</summary>
      <description>fixMeta currently does holes in meta only courtesy of HBASE-22771 which added fixMeta to hbck Service; missing was fix of overlaps too. This JIRA is about adding fix of overlaps to general fixMeta call.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.1.7,2.2.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMetaFixer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MetaFixer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.RegionStateNode.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
    </fixedFiles>
  </bug>
  <bug id="22927" opendate="2019-8-26 00:00:00" fixdate="2019-9-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade mockito version for Java 11 compatibility</summary>
      <description>Pasting the discussion from HBASE-22534 here:"Currently mockito-core version is at 2.1.0. According to https://github.com/mockito/mockito/blob/release/2.x/doc/release-notes/official.md, looks like Java 11 compatibility was introduced in 2.19+. And 2.23.2 claims to have full java 11 support after byte-buddy fix etc."</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.1.7,2.2.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shaded.hbase-shaded-with-hadoop-check-invariants.pom.xml</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-check-invariants.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="22943" opendate="2019-8-28 00:00:00" fixdate="2019-9-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Various procedures should not cache log trace level</summary>
      <description>several of the procedures have an idiom where they keep a member variable for if the log is at trace level or not, wrapped in a function so that it can be lazily looked up. This gives us an overhead per call of autoboxing and a function call, instead of just the function call from asking the logging system directly.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.1,2.1.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.RestoreSnapshotProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.EnableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CloneSnapshotProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.SplitTableRegionProcedure.java</file>
    </fixedFiles>
  </bug>
  <bug id="22945" opendate="2019-8-29 00:00:00" fixdate="2019-9-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Show quota infos in master UI</summary>
      <description>Add a page in master UI to show the following quota infos:if rpc throttle is enabled;if exceed throttle quota is enabled;namespace throtlles;user throttles.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.header.jsp</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.MasterQuotaManager.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.ThrottleSettings.java</file>
    </fixedFiles>
  </bug>
  <bug id="22946" opendate="2019-8-29 00:00:00" fixdate="2019-9-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix TableNotFound when grant/revoke if AccessController is not loaded</summary>
      <description>When doing grant, revoke..., a TableNotFoundException will occur if AccessController if is not configured.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="22959" opendate="2019-8-31 00:00:00" fixdate="2019-8-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add 2.1.6 to download page</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.downloads.xml</file>
    </fixedFiles>
  </bug>
  <bug id="22962" opendate="2019-9-1 00:00:00" fixdate="2019-9-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix typo in javadoc description</summary>
      <description>for example :'a HTTP' change into 'an http''an unique' change into 'a unique''an URL' change into 'a URL'</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.1,2.1.7</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift2.TestThriftConnection.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.GenericTestUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSyncUp.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheableDeserializerIdManager.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.client.Response.java</file>
      <file type="M">hbase-http.src.test.java.org.apache.hadoop.hbase.http.TestServletFilter.java</file>
      <file type="M">hbase-http.src.test.java.org.apache.hadoop.hbase.http.TestPathFilter.java</file>
      <file type="M">hbase-http.src.test.java.org.apache.hadoop.hbase.http.TestGlobalFilter.java</file>
      <file type="M">hbase-http.src.test.java.org.apache.hadoop.hbase.http.log.TestLogLevel.java</file>
      <file type="M">hbase-http.src.main.java.org.apache.hadoop.hbase.http.jmx.JMXJsonServlet.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.CommonFSUtils.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.util.BackupUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="22970" opendate="2019-9-3 00:00:00" fixdate="2019-9-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>split parents show as overlaps in the HBCK Report</summary>
      <description>Split parents show in the overlap list and continue to do so until cleared up by CatalogJanitor.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.1,2.1.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionInfo.java</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.hbck.jsp</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionInfo.java</file>
    </fixedFiles>
  </bug>
  <bug id="23041" opendate="2019-9-18 00:00:00" fixdate="2019-9-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Should not show split parent regions in HBCK report&amp;#39;s unknown server part</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.1.7,2.2.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HbckChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
    </fixedFiles>
  </bug>
  <bug id="23222" opendate="2019-10-28 00:00:00" fixdate="2019-10-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Better logging and mitigation for MOB compaction failures</summary>
      <description>Some logging and mitigation options for MOB dataloss issues described in HBASE-22075.</description>
      <version>2.1.0,2.0.0,2.2.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.1.8,2.2.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.resources.log4j.properties</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.cleaner.TestHFileCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.MobUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.compactions.PartitionedMobCompactor.java</file>
    </fixedFiles>
  </bug>
  <bug id="2324" opendate="2010-3-14 00:00:00" fixdate="2010-3-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Refactoring of TableRecordReader (mapred / mapreduce) for reuse outside the scope of InputSplit / RecordReader</summary>
      <description>For the storing of tf-idf in hbase ( lucene-hbase project) we need to scan the keys across the table and retrieve columnar values. Quite an amount of logic can be reused from TableRecordReader for the purpose. Refactored TableRecordReader ( from being a protected inner class to a public class outside ) Created an impl class , that does the actual work, without the dependency on hadop.mapreduce.* packages ( RecordReader) while retaining the implementation that can be reused across libraries.Do the same thing for .mapred. and .mapreduce. packages. Let me know the thoughts on the same.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapred.TableInputFormatBase.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>
