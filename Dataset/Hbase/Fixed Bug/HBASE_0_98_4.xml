<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="11438" opendate="2014-6-30 00:00:00" fixdate="2014-8-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[Visibility Controller] Support UTF8 character as Visibility Labels</summary>
      <description>This would be an action item that we would be addressing so that the visibility labels could have UTF8 characters in them. Also allow the user to use a client supplied API that allows to specify the visibility labels inside double quotes such that UTF8 characters and cases like &amp;, |, ! and double quotes itself could be specified with proper escape sequence. Accumulo too provides one such API in the client side.</description>
      <version>0.98.4</version>
      <fixedVersion>0.99.0,0.98.6</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabels.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestExpressionParser.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.ScannerModel.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestScan.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityLabelsValidator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.CellVisibility.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.Authorizations.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.ExpressionParser.java</file>
    </fixedFiles>
  </bug>
  <bug id="11497" opendate="2014-7-10 00:00:00" fixdate="2014-7-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expose RpcScheduling implementations as LimitedPrivate interfaces</summary>
      <description>In PHOENIX-938 we are attempting to resolve cross-RS deadlocks in indexing by adding custom RPC handlers (so regular puts/reads don't interfere with index updates). However, we've run into a couple of snags where the interfaces change, making it a bit more difficult to support interoperability between minor versions as the underlying RPC handling changed (for the better, but still different .This would just mark those interfaces Public, Evolving, so we still have some flexibility, but don't break existing usage.Note, this kind of thing will come up for any client who is doing custom RPC handling - beyond the recently added flexibility - but wants to stay in line with the current HBase implementation (rather than building their own RPC handling mechanisms).</description>
      <version>0.99.0,0.98.4</version>
      <fixedVersion>0.99.0,0.98.4</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcSchedulerContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.FifoRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SimpleRpcSchedulerFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SingleQueueRpcExecutor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServerInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.MultipleQueueRpcExecutor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HBaseInterfaceAudience.java</file>
    </fixedFiles>
  </bug>
  <bug id="11510" opendate="2014-7-14 00:00:00" fixdate="2014-7-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Visibility serialization format tag gets duplicated in Append/Increment&amp;#39;ed cells</summary>
      <description>When the Append/Increment contains a CellVisibility, we will rewrite this new tags in to the new Cell. There while copying the non vis tags, we exclude TagType.VISIBILITY_TAG_TYPE only. So the old cell can contain TagType VISIBILITY_EXP_SERIALIZATION_TAG_TYPE and we will copy that one, and next while creating Tags for the new CellVisibility we will add this tag again. So a cell after 100 Increments will contain 100 tags of type VISIBILITY_EXP_SERIALIZATION_TAG_TYPE!</description>
      <version>0.98.4</version>
      <fixedVersion>0.99.0,0.98.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityController.java</file>
    </fixedFiles>
  </bug>
  <bug id="11513" opendate="2014-7-14 00:00:00" fixdate="2014-7-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Combine SingleMultiple Queue RpcExecutor into a single class</summary>
      <description>Its a little odd that we use multiple classes, leading to mutliple if-else conditions for rpc execution when we could just combine them into one. Makes the logic and also puts the code into one place</description>
      <version>0.99.0,0.98.4,2.0.0</version>
      <fixedVersion>0.99.0,0.98.4</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SingleQueueRpcExecutor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.MultipleQueueRpcExecutor.java</file>
    </fixedFiles>
  </bug>
  <bug id="11516" opendate="2014-7-15 00:00:00" fixdate="2014-8-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Track time spent in executing coprocessors in each region.</summary>
      <description>Currently, the time spent in executing coprocessors is not yet being tracked. This feature can be handy for debugging coprocessors in case of any trouble.</description>
      <version>0.98.4</version>
      <fixedVersion>0.99.0,0.98.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperStub.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmpl.jamon</file>
      <file type="M">hbase-hadoop2-compat.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSource.java</file>
      <file type="M">hbase-hadoop-compat.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11536" opendate="2014-7-17 00:00:00" fixdate="2014-8-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Puts of region location to Meta may be out of order which causes inconsistent of region location</summary>
      <description>In product hbase cluster, we found inconsistency of region location in the meta table. Region cdfa2ed711bbdf054d9733a92fd43eb5 is onlined in regionserver 10.237.12.13:11600 but the region location in Meta table is 10.237.12.15:11600.This is because of the out-of-order puts for meta table. HMaster try to assign the region to 10.237.12.15:11600. RegionServer: 10.237.12.15:11600. During the opening the region, the put of region location(10.237.12.15:11600) to meta table is timeout(60s) and the htable retry for second time. (regionserver serving meta has got the request of the put. The timeout is beause ther is a bad disk in this regionserver and sync of hlog is very slow.)During the retry in htable, the OpenRegionHandler is timeout(100s) and the PostOpenDeployTasksThread is interrupted. Through the htable is closed in the MetaEditor finally, the share connection the htable used is not closed and the call of put for meta table is on-flying in the connection. Assumed that this on-flying call of put to meta is named call A. RegionServer: 10.237.12.15:11600. For the timeout of OpenRegionHandler, the OpenRegionHandler marks the assign state of this region to FAILED_OPEN. HMaster watchs this event of FAILED_OPEN and assigns the region to another regionserver: 10.237.12.13:11600 RegionServer: 10.237.12.13:11600. This regionserver opens the region successfully . Assumed that the put of region location(10.237.12.13:11600) to meta table in this regionserver is named B.There is no order guarantee for call A and B. If call A is processed after call B in regionserver serving meta region, the region location in meta table will be wrong.From the raw scan of meta table we found:scan '.META.', {RAW =&gt; true, LIMIT =&gt; 1, VERSIONS =&gt; 10, STARTROW =&gt; 'xxx.adfa2ed711bbdf054d9733a92fd43eb5.'} xxx.adfa2ed711bbdf054d9733a92fd43eb5. column=info:server, timestamp=1404885460553(=&gt; Wed Jul 09 13:57:40 +0800 2014), value=10.237.12.15:11600 --&gt; Retry put from 10.237.12.15xxx.adfa2ed711bbdf054d9733a92fd43eb5. column=info:server, timestamp=1404885456731(=&gt; Wed Jul 09 13:57:36 +0800 2014), value=10.237.12.13:11600 --&gt; put from 10.237.12.13xxx.adfa2ed711bbdf054d9733a92fd43eb5. column=info:server, timestamp=1404885353122( Wed Jul 09 13:55:53 +0800 2014), value=10.237.12.15:11600 --&gt; First put from 10.237.12.15Related hbase log is attached in this issue and disscusions are welcomed.For there is no order guarantee for puts from different htables, one solution for this issue is to give an increased id for each assignment of a region and use this id as the timestamp of put of region location to meta table. The region location with large assign id will be got by hbase clients.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.94.23,0.98.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MetaTableAccessor.java</file>
    </fixedFiles>
  </bug>
  <bug id="11568" opendate="2014-7-22 00:00:00" fixdate="2014-2-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Async WAL replication for region replicas</summary>
      <description>As mentioned in parent issue, and design docs for phase-1 (HBASE-10070) and Phase-2 (HBASE-11183), implement asynchronous WAL replication from the WAL files of the primary region to the secondary region replicas. The WAL replication will build upon the pluggable replication framework introduced in HBASE-11367, and the distributed WAL replay. Upon having some experience with the patch, we changed the design so that there is only one replication queue for doing the async wal replication to secondary replicas rather than having a queue per region replica. This is due to the fact that, we do not want to tail the logs of every region server for a single region replica. Handling of flushes/compactions and memstore accounting will be handled in other subtasks.</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLogMethods.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerNoMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionReplicas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ServerRegionReplicaUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.ReplicationProtbufUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.CreateTableHandler.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCaller.java</file>
    </fixedFiles>
  </bug>
  <bug id="11569" opendate="2014-7-22 00:00:00" fixdate="2014-2-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Flush / Compaction handling from secondary region replicas</summary>
      <description>We should be handling flushes and compactions from the primary region replica being replayed to the secondary region replica via HBASE-11568. Some initial thoughts for how can this be done is discussed in HBASE-11183. More details will come together with the patch.</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestPerColumnFamilyFlush.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ServerRegionReplicaUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFlushContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultMemStore.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.WAL.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.WALProtos.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="11571" opendate="2014-7-22 00:00:00" fixdate="2014-3-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bulk load handling from secondary region replicas</summary>
      <description>We should be replaying the bulk load events from the primary region replica in the secondary region replica so that the bulk loaded files will be made visible in the secondaries. This will depend on HBASE-11567 and HBASE-11568</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionReplayEvents.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestBulkLoad.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="11573" opendate="2014-7-22 00:00:00" fixdate="2014-7-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Report age on eviction</summary>
      <description>From the parent issue, Todd reminds us of the old Jim Gray '5 minute rule' on whether to cache.In master, we were reporting age only it was the inactionable inverse of 'how long blocks are staying in the cache'.Let me add to our cache stats a histogram of age on eviction and change the UI reporting so it is age at eviction (plus stddev). The JSON version has percentiles (and if wanted, the old age report of age of items in cache).</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHeapMemoryManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestLruBlockCache.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestBlockCacheReporting.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheStats.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketCacheStats.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.BlockCacheUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.DataInputInputStream.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="11575" opendate="2014-7-23 00:00:00" fixdate="2014-7-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Pseudo distributed mode does not work as documented</summary>
      <description>After master-RS colocation, now the pseudo dist-mode does not work as documented since you cannot start a region server in the same port 16020. I think we can either select a random port (and info port) for the master's region server, or document how to do a pseudo-distributed setup in the book. jxiang wdyt?</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.getting.started.xml</file>
      <file type="M">conf.regionservers</file>
      <file type="M">bin.local-regionservers.sh</file>
      <file type="M">bin.local-master-backup.sh</file>
      <file type="M">bin.hbase-config.sh</file>
    </fixedFiles>
  </bug>
  <bug id="11583" opendate="2014-7-24 00:00:00" fixdate="2014-8-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Refactoring out the configuration changes for enabling VisibilityLabels in the unit tests.</summary>
      <description>All the unit tests contain the code for enabling the visibility changes. Incorporating future configuration changes for Visibility Labels configuration can be made easier by refactoring them out to a single place.</description>
      <version>0.98.4</version>
      <fixedVersion>0.99.0,0.98.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithSLGStack.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithDistributedLogReplay.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithDeletes.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsOpWithDifferentUsersNoACL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabels.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestEnforcingScanLabelGenerator.java</file>
    </fixedFiles>
  </bug>
  <bug id="11588" opendate="2014-7-25 00:00:00" fixdate="2014-7-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RegionServerMetricsWrapperRunnable misused the &amp;#39;period&amp;#39; parameter</summary>
      <description>The 'period' parameter in RegionServerMetricsWrapperRunnable is in MILLISECOND. When initializing the 'lastRan' parameter, the original code misused the 'period' as in SECOND.</description>
      <version>0.98.4</version>
      <fixedVersion>0.99.0,0.98.5</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="11606" opendate="2014-7-28 00:00:00" fixdate="2014-7-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable ZK-less region assignment by default</summary>
      <description>Let's enable ZK-less region assignment by default in the master branch.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ConfigUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
    </fixedFiles>
  </bug>
  <bug id="11607" opendate="2014-7-29 00:00:00" fixdate="2014-8-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document HBase metrics</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11610" opendate="2014-7-29 00:00:00" fixdate="2014-8-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enhance remote meta updates</summary>
      <description>Currently, if the meta region is on a regionserver instead of the master, meta update is synchronized on one HTable instance. We should be able to do better.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.6</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStateStore.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCallerFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="11611" opendate="2014-7-29 00:00:00" fixdate="2014-8-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up ZK-based region assignment</summary>
      <description>We can clean up the ZK-based region assignment code and use the ZK-less one in the master branch, to make the code easier to understand and maintain.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildOverlap.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildHole.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestZooKeeper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestMetaTableAccessor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestIOFencing.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestDrainingServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestZKLessSplitOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestZKLessMergeOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerNoMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionReplicas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionMergeTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestEndToEndSplitTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.handler.TestOpenRegionHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.handler.TestCloseRegionHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.migration.TestUpgradeTo96.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.migration.TestNamespaceUpgrade.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestZKLessAMOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestZKBasedOpenCloseRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRollingRestart.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRestartCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestOpenedRegionHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterRestartAfterDisablingTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.master.RegionState.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionTransition.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKAssign.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.ZooKeeper.proto</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.BaseCoordinatedStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.CloseRegionCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.OpenRegionCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.RegionMergeCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.SplitTransactionCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZkCloseRegionCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZkOpenRegionCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZkRegionMergeCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZKSplitTransactionCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignCallable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ClosedRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.OpenedRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.OfflineCallback.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStateStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.migration.UpgradeTo96.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseMetaHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenMetaHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionMergeTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ConfigUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsckRepair.java</file>
      <file type="M">hbase-server.src.test.data.TestNamespaceUpgrade.tgz</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestReplicasClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannersFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestChangingEncoding.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.Mocking.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
    </fixedFiles>
  </bug>
  <bug id="11639" opendate="2014-8-1 00:00:00" fixdate="2014-12-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[Visibility controller] Replicate the visibility of Cells as strings</summary>
      <description>This issue is aimed at persisting the visibility labels as strings in the WAL rather than Label ordinals. This would help in replicating the label ordinals to the replication cluster as strings directly and also that after HBASE-11553 would help because the replication cluster could have an implementation as string based visibility labels.</description>
      <version>0.98.4</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.ExpAsStringVisibilityLabelServiceImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityLabelService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityLabelsCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityLabelOrdinalProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.DefaultVisibilityLabelServiceImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.DefaultVisibilityExpressionResolver.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.TagType.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.Tag.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityConstants.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityController.java</file>
    </fixedFiles>
  </bug>
  <bug id="11655" opendate="2014-8-4 00:00:00" fixdate="2014-8-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document how to use Bash with HBase Shell</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.shell.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11723" opendate="2014-8-12 00:00:00" fixdate="2014-8-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document all options of bin/hbase command</summary>
      <description>The bin/hbase command is not documented fully in the Ref Guide: http://hbase.apache.org/book.html#toolsSpecifically a few new options were added in HBASE-11649 and need to be documented. Also the generic usage instructions need to be there.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11728" opendate="2014-8-13 00:00:00" fixdate="2014-8-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Data loss while scanning using PREFIX_TREE DATA-BLOCK-ENCODING</summary>
      <description>In Scan case, i prepare some data as beflow:Table Desc (Using the prefix-tree encoding) :'prefix_tree_test', {NAME =&gt; 'cf_1', DATA_BLOCK_ENCODING =&gt; 'PREFIX_TREE', TTL =&gt; '15552000'}and i put 5 rows as:(RowKey , Qualifier, Value)'a-b-0-0', 'qf_1', 'c1-value''a-b-A-1', 'qf_1', 'c1-value''a-b-A-1-1402329600-1402396277', 'qf_2', 'c2-value''a-b-A-1-1402397227-1402415999', 'qf_2', 'c2-value-2''a-b-B-2-1402397300-1402416535', 'qf_2', 'c2-value-3'so i try to scan the rowKey between 'a-b-A-1' and 'a-b-A-1:' , i and got the corret result:Test 1: Scan scan = new Scan();scan.setStartRow("a-b-A-1".getBytes());scan.setStopRow("a-b-A-1:".getBytes());------------------------------------------------------'a-b-A-1', 'qf_1', 'c1-value''a-b-A-1-1402329600-1402396277', 'qf_2', 'c2-value''a-b-A-1-1402397227-1402415999', 'qf_2', 'c2-value-2'and then i try next , scan to addColumnTest2:Scan scan = new Scan();scan.addColumn(Bytes.toBytes("cf_1") , Bytes.toBytes("qf_2"));scan.setStartRow("a-b-A-1".getBytes());scan.setStopRow("a-b-A-1:".getBytes());----------------------------------------------except:'a-b-A-1-1402329600-1402396277', 'qf_2', 'c2-value''a-b-A-1-1402397227-1402415999', 'qf_2', 'c2-value-2'but actually i got nonthing. Then i update the addColumn for scan.addColumn(Bytes.toBytes("cf_1") , Bytes.toBytes("qf_1")); and i got the expected result 'a-b-A-1', 'qf_1', 'c1-value' as well.then i do more testing... i update the case to modify the startRow greater than the 'a-b-A-1' Test3:Scan scan = new Scan();scan.setStartRow("a-b-A-1-".getBytes());scan.setStopRow("a-b-A-1:".getBytes());------------------------------------------------------except:'a-b-A-1-1402329600-1402396277', 'qf_2', 'c2-value''a-b-A-1-1402397227-1402415999', 'qf_2', 'c2-value-2'but actually i got nothing again. i modify the start row greater than 'a-b-A-1-1402329600-1402396277'Scan scan = new Scan();scan.setStartRow("a-b-A-1-140239".getBytes());scan.setStopRow("a-b-A-1:".getBytes());and i got the expect row as well:'a-b-A-1-1402397227-1402415999', 'qf_2', 'c2-value-2'So, i think it may be a bug in the prefix-tree encoding.It happens after the data flush to the storefile, and it's ok when the data in mem-store.</description>
      <version>0.96.1.1,0.98.4</version>
      <fixedVersion>0.99.0,0.98.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="11735" opendate="2014-8-14 00:00:00" fixdate="2014-8-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document Configurable Bucket Sizes in bucketCache</summary>
      <description></description>
      <version>0.99.0,0.98.4,0.98.5</version>
      <fixedVersion>0.99.0,0.98.6</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.book.xml</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11736" opendate="2014-8-14 00:00:00" fixdate="2014-8-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document SKIP_FLUSH snapshot option</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11737" opendate="2014-8-14 00:00:00" fixdate="2014-8-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document callQueue improvements from HBASE-11355 and HBASE-11724</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.performance.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11738" opendate="2014-8-14 00:00:00" fixdate="2014-9-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document improvements to LoadTestTool and PerformanceEvaluation</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11739" opendate="2014-8-14 00:00:00" fixdate="2014-8-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document blockCache contents report in the UI</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11796" opendate="2014-8-21 00:00:00" fixdate="2014-9-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add client support for atomic checkAndMutate</summary>
      <description>Currently HBase has support for atomic checkAndPut as well as checkAndDelete operations on individual rows. HBase also supports the atomic submission of multiple operations through mutateRow. It would be nice to support atomic checkAndMutate(RowMutations) as well.</description>
      <version>None</version>
      <fixedVersion>0.98.7,0.99.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.HTablePool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HTableWrapper.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Client.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ClientProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Table.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="11838" opendate="2014-8-27 00:00:00" fixdate="2014-10-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable PREFIX_TREE in integration tests</summary>
      <description>HBASE-11728 fixed a PREFIX_TREE encoding bug. Let's try to enable the encoding in integration tests.</description>
      <version>None</version>
      <fixedVersion>0.98.7,0.99.1</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.ChangeEncodingAction.java</file>
    </fixedFiles>
  </bug>
  <bug id="11839" opendate="2014-8-27 00:00:00" fixdate="2014-9-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestRegionRebalance is flakey</summary>
      <description>Besides failing many times on the prebuild TestRegionRebalance fails on my local machine eventually simply withexport RUNNIN=true; mvn clean install -DskipTests ; while ($RUNNIN) ; do mvn test -Dtest=TestRegionRebalancing || RUNNIN=false;done</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
    </fixedFiles>
  </bug>
  <bug id="11903" opendate="2014-9-5 00:00:00" fixdate="2014-12-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Directly invoking split &amp; merge of replica regions should be disallowed</summary>
      <description>When the primary is split/merged the secondaries follow suit. We should disallow calling split/merge on the secondaries directly.</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHBaseAdminNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin1.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="1198" opendate="2009-2-11 00:00:00" fixdate="2009-2-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>OOME in IPC server does not trigger abort behavior</summary>
      <description>OOME in IPC server does not trigger abort behavior. Fix.</description>
      <version>None</version>
      <fixedVersion>0.19.1,0.20.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HBaseServer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11981" opendate="2014-9-16 00:00:00" fixdate="2014-10-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document how to find the units of measure for a given HBase metric</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11982" opendate="2014-9-16 00:00:00" fixdate="2014-9-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bootstraping hbase:meta table creates a WAL file in region dir</summary>
      <description>We are using an HRegion.createRegion() method in MFS.bootstrap() which is for unit tests: 2014-09-15 18:20:47,755 INFO [M:0;localhost:53201] wal.FSHLog: New WAL /var/folders/h5/bbxg50c12r5bhsd9hf1n9hlr0000gp/T/hbase-enis/hbase/data/hbase/meta/1588230740/WALs/hlog.1410830447741..2014-09-15 18:20:47,825 DEBUG [M:0;localhost:53201] wal.FSHLog: Closing WAL writer in file:/var/folders/h5/bbxg50c12r5bhsd9hf1n9hlr0000gp/T/hbase-enis/hbase/data/hbase/meta/1588230740/WALs..2014-09-15 18:20:47,826 DEBUG [M:0;localhost:53201] wal.FSHLog: Moved 1 WAL file(s) to /var/folders/h5/bbxg50c12r5bhsd9hf1n9hlr0000gp/T/hbase-enis/hbase/data/hbase/meta/1588230740/oldWALs</description>
      <version>None</version>
      <fixedVersion>0.98.7,0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
    </fixedFiles>
  </bug>
  <bug id="12438" opendate="2014-11-6 00:00:00" fixdate="2014-11-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add -Dsurefire.rerunFailingTestsCount=2 to patch build runs so flakies get rerun</summary>
      <description>Tripped over this config today: -Dsurefire.rerunFailingTestsCount=I made a test fail, then pass, and I got this output: Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Flakes: 1Notice the 'Flakes' addition on the far-right.Let me enable this on hadoopqa builds. Hopefully will help make it so new contribs are not frightened off by flakies thinking their patch the cause.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  <bug id="12954" opendate="2015-2-2 00:00:00" fixdate="2015-4-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Ability impaired using HBase on multihomed hosts</summary>
      <description>For HBase clusters running on unusual networks (such as NAT'd cloud environments or physical machines with multiple IP's per network interface) it would be ideal to have a way to both specify: which IP interface to which HBase master or region-server will bind what hostname HBase will advertise in Zookeeper both for a master or region-server processWhile efforts such as HBASE-8640 go a long way to normalize these two sources of information, it is not possible in the current design of the properties available to an administrator for these to be unambiguously specified.One has been able to request hbase.master.ipc.address or hbase.regionserver.ipc.address but one can not specify the desired HBase hbase.master.hostname. (It was removed in HBASE-1357, further I am unaware of a region-server equivalent.)I use a configuration management system to generate all of my configuration files on a per-machine basis. As such, an option to generate a file specifying exactly which hostname to use would be helpful.Today, specifying the bind address for HBase works and one can use an HBase-only DNS for faking what to put in Zookeeper but this is far from ideal. Network interfaces have no intrinsic IP address, nor hostname. Specifing a DNS server is awkward as the DNS server may differ from the system's resolver and is a single IP address. Similarly, on hosts which use a transient VIP (e.g. through keepalived) for other services, it means there's a seemingly non-deterministic hostname choice made by HBase depending on the state of the VIP at daemon start-up time.I will attach two networking examples I use which become very difficult to manage under the current properties.</description>
      <version>0.98.4</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestClockSkewDetection.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.RegionServerStatus.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerHostname.java</file>
    </fixedFiles>
  </bug>
  <bug id="13239" opendate="2015-3-13 00:00:00" fixdate="2015-3-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase grant at specific column level does not work for Groups</summary>
      <description>While performing Grant command to a specific column in a table - to a specific group does not produce needed results. However, when specific user is mentioned (instead of group name) in grant command, it becomes effectiveSteps to Reproduce : 1) using super-user, Grant a table/column family/column level grant to a group2) login using a user ( part of the above group) and scan the table. It does not return any results3) using super-user, Grant a table/column family/column level grant to a specific user ( instead of group) 4) login using that specific user and scan the table. It produces correct results, i.e. provides only the column where user has select privileges</description>
      <version>0.98.4</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.TableAuthManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="1324" opendate="2009-4-13 00:00:00" fixdate="2009-4-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase-1234 broke testget2 unit test (and broke the build)</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestGet2.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13241" opendate="2015-3-14 00:00:00" fixdate="2015-3-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add tests for group level grants</summary>
      <description>We need to have tests for group-level grants for various scopes. ref: HBASE-13239</description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController2.java</file>
    </fixedFiles>
  </bug>
  <bug id="14280" opendate="2015-8-21 00:00:00" fixdate="2015-9-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bulk Upload from HA cluster to remote HA hbase cluster fails</summary>
      <description>Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(java.io.IOException): java.io.IOException: Wrong FS: hdfs://ha-aggregation-nameservice1/hbase_upload/82c89692-6e78-46ef-bbea-c9e825318bfe/A/1aaaa31358d641c69d6c34b803c187b0, expected: hdfs://ha-hbase-nameservice1 at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2113) at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:108) at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:114) at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:94) at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.IllegalArgumentException: Wrong FS: hdfs://ha-aggregation-nameservice1/hbase_upload/82c89692-6e78-46ef-bbea-c9e825318bfe/A/1aaaa31358d641c69d6c34b803c187b0, expected: hdfs://ha-hbase-nameservice1 at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:645) at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:193) at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:105) at org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:1136) at org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:1132) at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81) at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1132) at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:414) at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1423) at org.apache.hadoop.hbase.regionserver.HRegionFileSystem.commitStoreFile(HRegionFileSystem.java:372) at org.apache.hadoop.hbase.regionserver.HRegionFileSystem.bulkLoadStoreFile(HRegionFileSystem.java:451) at org.apache.hadoop.hbase.regionserver.HStore.bulkLoadHFile(HStore.java:750) at org.apache.hadoop.hbase.regionserver.HRegion.bulkLoadHFiles(HRegion.java:4894) at org.apache.hadoop.hbase.regionserver.HRegion.bulkLoadHFiles(HRegion.java:4799) at org.apache.hadoop.hbase.regionserver.HRegionServer.bulkLoadHFile(HRegionServer.java:3377) at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:29996) at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2078) ... 4 more at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1498) at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1684) at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1737) at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.bulkLoadHFile(ClientProtos.java:29276) at org.apache.hadoop.hbase.protobuf.ProtobufUtil.bulkLoadHFile(ProtobufUtil.java:1548) ... 11 more</description>
      <version>0.98.4</version>
      <fixedVersion>1.2.0,1.3.0,1.1.3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSHDFSUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="14449" opendate="2015-9-18 00:00:00" fixdate="2015-9-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Rewrite deadlock prevention for concurrent connection close</summary>
      <description>The deadlock prevention approach used in HBASE-14241 introduces unnecessary logic which is not intuitive.Depending on the value for config hbase.ipc.client.specificThreadForWriting , there may or may not be CallSender threads running.The attached patch simplifies deadlock prevention by using a Set which represents the Connections to be closed. Outside the synchronized (connections) block, this Set is iterated where the Connections are closed.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,1.0.3,1.1.3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClientImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="15672" opendate="2016-4-18 00:00:00" fixdate="2016-4-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hadoop.hbase.security.visibility.TestVisibilityLabelsWithDeletes fails</summary>
      <description>016-04-18 15:02:50,632 WARN &amp;#91;member: &amp;#39;10.22.11.177,55156,1461016964801&amp;#39; subprocedure-pool5-thread-1&amp;#93; flush.RegionServerFlushTableProcedureManager$FlushTableSubprocedurePool(275): Got Exception in FlushSubprocedurePooljava.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: Timestamp cannot be negative. minStamp:-9223372036854775808, maxStamp:128 at java.util.concurrent.FutureTask.report(FutureTask.java:122) at java.util.concurrent.FutureTask.get(FutureTask.java:188) at org.apache.hadoop.hbase.procedure.flush.RegionServerFlushTableProcedureManager$FlushTableSubprocedurePool.waitForOutstandingTasks(RegionServerFlushTableProcedureManager.java:251) at org.apache.hadoop.hbase.procedure.flush.FlushTableSubprocedure.flushRegions(FlushTableSubprocedure.java:102) at org.apache.hadoop.hbase.procedure.flush.FlushTableSubprocedure.acquireBarrier(FlushTableSubprocedure.java:113) at org.apache.hadoop.hbase.procedure.Subprocedure.call(Subprocedure.java:166) at org.apache.hadoop.hbase.procedure.Subprocedure.call(Subprocedure.java:1) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.IllegalArgumentException: Timestamp cannot be negative. minStamp:-9223372036854775808, maxStamp:128 at org.apache.hadoop.hbase.io.TimeRange.&lt;init&gt;(TimeRange.java:81) at org.apache.hadoop.hbase.regionserver.TimeRangeTracker.toTimeRange(TimeRangeTracker.java:204) at org.apache.hadoop.hbase.regionserver.ImmutableSegment.&lt;init&gt;(ImmutableSegment.java:44) at org.apache.hadoop.hbase.regionserver.SegmentFactory.createImmutableSegment(SegmentFactory.java:57) at org.apache.hadoop.hbase.regionserver.DefaultMemStore.snapshot(DefaultMemStore.java:93) at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.prepare(HStore.java:2151) at org.apache.hadoop.hbase.regionserver.HRegion.internalPrepareFlushCache(HRegion.java:2324) at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2192) at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2163) at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:2054) at org.apache.hadoop.hbase.regionserver.HRegion.flush(HRegion.java:1980) at org.apache.hadoop.hbase.procedure.flush.FlushTableSubprocedure$RegionFlushTask.call(FlushTableSubprocedure.java:68) at org.apache.hadoop.hbase.procedure.flush.FlushTableSubprocedure$RegionFlushTask.call(FlushTableSubprocedure.java:1) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)</description>
      <version>0.99.0,0.98.4</version>
      <fixedVersion>1.3.0,0.98.19,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityController.java</file>
    </fixedFiles>
  </bug>
  <bug id="15673" opendate="2016-4-18 00:00:00" fixdate="2016-4-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[PE tool] Fix latency metrics for multiGet</summary>
      <description>we write out latency value after each row is processes by testRow() function. But if multiget is enabled, say set to 10, testRow() returns immediately for 9 rows and sends out request in the 10th iteration. This screws up latency metrics (50th, 75th, 90th percentiles are all 0).</description>
      <version>None</version>
      <fixedVersion>1.3.0,0.98.19,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
    </fixedFiles>
  </bug>
  <bug id="15967" opendate="2016-6-5 00:00:00" fixdate="2016-6-5 01:00:00" resolution="Abandoned">
    <buginformation>
      <summary>Metric for active ipc Readers and make default fraction of cpu count</summary>
      <description>Our ipc Readers are hard coded at 10 regardless since . Running w/ less Readers, we go faster..(e.g. 12 Readers has us doing 135k with workloadc and 6 readers has us doing 145k).. .but hard to tell what count of Readers are needed since no metric.This issue changes Readers to be 1/4 the installed CPUs or 8, whichever is the minimum, and then adds a new hbase.regionserver.ipc.runningReaders metric so you have a chance seeing whats needed.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="15968" opendate="2016-6-6 00:00:00" fixdate="2016-7-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>New behavior of versions considering mvcc and ts rather than ts only</summary>
      <description>In HBase book, we have a section in Versions called "Current Limitations" see http://hbase.apache.org/book.html#_current_limitations28.3. Current Limitations28.3.1. Deletes mask PutsDeletes mask puts, even puts that happened after the delete was entered. See HBASE-2256. Remember that a delete writes a tombstone, which only disappears after then next major compaction has run. Suppose you do a delete of everything ⇐ T. After this you do a new put with a timestamp ⇐ T. This put, even if it happened after the delete, will be masked by the delete tombstone. Performing the put will not fail, but when you do a get you will notice the put did have no effect. It will start working again after the major compaction has run. These issues should not be a problem if you use always-increasing versions for new puts to a row. But they can occur even if you do not care about time: just do delete and put immediately after each other, and there is some chance they happen within the same millisecond.28.3.2. Major compactions change query results…​create three cell versions at t1, t2 and t3, with a maximum-versions setting of 2. So when getting all versions, only the values at t2 and t3 will be returned. But if you delete the version at t2 or t3, the one at t1 will appear again. Obviously, once a major compaction has run, such behavior will not be the case anymore…​ (See Garbage Collection in Bending time in HBase.)These limitations result from the current implementation on multi-versions: we only consider timestamp, no matter when it comes; we will not remove old version immediately if there are enough number of new versions. So we can get a stronger semantics of versions by two guarantees:1, Delete will not mask Put that comes after it.2, If a version is masked by enough number of higher versions (VERSIONS in cf's conf), it will never be seen any more.Some examples for understanding:(delete t&lt;=3 means use Delete.addColumns to delete all versions whose ts is not greater than 3, and delete t3 means use Delete.addColumn to delete the version whose ts=3)case 1: put t2 -&gt; put t3 -&gt; delete t&lt;=3 -&gt; put t1, and we will get t1 because the put is after delete.case 2: maxversion=2, put t1 -&gt; put t2 -&gt; put t3 -&gt; delete t3, and we will always get t2 no matter if there is a major compaction, because t1 is masked when we put t3 so t1 will never be seen.case 3: maxversion=2, put t1 -&gt; put t2 -&gt; put t3 -&gt; delete t2 -&gt; delete t3, and we will get nothing.case 4: maxversion=3, put t1 -&gt; put t2 -&gt; put t3 -&gt; delete t2 -&gt; delete t3, and we will get t1 because it is not masked.case 5: maxversion=2, put t1 -&gt; put t2 -&gt; put t3 -&gt; delete t3 -&gt; put t1, and we can get t3+t1 because when we put t1 at second time it is the 2nd latest version and it can be read.case 6:maxversion=2, put t3-&gt;put t2-&gt;put t1, and we will get t3+t2 just like what we can get now, ts is still the key of versions.Different VERSIONS may result in different results even the size of result is smaller than VERSIONS(see case 3 and 4). So Get/Scan.setMaxVersions will be handled at end after we read correct data according to CF's VERSIONS setting.The semantics is different from the current HBase, and we may need more logic to support the new semantic, so it is configurable and default is disabled.</description>
      <version>None</version>
      <fixedVersion>2.0.0-alpha-2,2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestCoprocessorScanPolicy.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithDeletes.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestReversibleScanners.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMajorCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDefaultMemStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDefaultCompactSelection.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompactingMemStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.querymatcher.TestUserScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.querymatcher.TestCompactionScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ScanInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.UserScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.StripeCompactionScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.NormalUserScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.MinorCompactionScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.MajorCompactionScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.LegacyScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.DropDeletesCompactionScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.DeleteTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.CompactionScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.ColumnTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.Compactor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ColumnFamilyDescriptorBuilder.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ColumnFamilyDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="4625" opendate="2011-10-19 00:00:00" fixdate="2011-11-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Convert @deprecated HBaseTestCase tests JUnit4 style tests</summary>
      <description>This will class has 47 references so separating out into a separate subtask.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestMergeTool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestWideScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreFileInfo.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestScanWildcardColumnTracker.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestScanDeleteTracker.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestQueryMatcher.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestKeyValueHeap.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestGetClosestAtOrBefore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestBlocksScanned.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestBlocksRead.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestSeekTo.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFile.java</file>
    </fixedFiles>
  </bug>
  <bug id="4626" opendate="2011-10-19 00:00:00" fixdate="2011-10-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Filters unnecessarily copy byte arrays...</summary>
      <description>Just looked at SingleCol and ValueFilter... And on every column compared they create a copy of the column and/or value portion of the KV.</description>
      <version>None</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.WritableByteArrayComparable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.SubstringComparator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.SingleColumnValueFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.RegexStringComparator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.NullComparator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.CompareFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.BitComparator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.BinaryPrefixComparator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.BinaryComparator.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>
