<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="21739" opendate="2019-1-18 00:00:00" fixdate="2019-1-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move grant/revoke from regionserver to master</summary>
      <description>Create a sub-task to move grant/revoke from regionserver to master. Other access control operations(getUserPermissions/ checkPermissions/ hasPermission) will be moved in another sub-task.</description>
      <version>3.0.0-alpha-1,2.2.0,2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.client.ThriftAdmin.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestNamespaceCommands.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.SecureTestUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlLists.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MasterObserver.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.Master.proto</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.ShadedAccessControlUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ShortCircuitMasterConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
    </fixedFiles>
  </bug>
  <bug id="2174" opendate="2010-1-29 00:00:00" fixdate="2010-3-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Stop from resolving HRegionServer addresses to names using DNS on every heartbeat</summary>
      <description>Over the time many parts of the code have evolved in different ways and one issue is that addresses are handled differently in different parts of the code. We need to set a standard and correct any inconsistencies.</description>
      <version>None</version>
      <fixedVersion>0.20.4,0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.ProcessServerShutdown.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.ProcessRegionOpen.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.HServerInfo.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="21741" opendate="2019-1-18 00:00:00" fixdate="2019-1-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a note in "HFile Tool" section regarding &amp;#39;seqid=0&amp;#39;</summary>
      <description>In few parts of the HFile, where the seqid is irrelevant such as: firstKey=Optional&amp;#91;row0/cf:column/1547846312435/Put/seqid=0&amp;#93; lastKey=Optional&amp;#91;row9/cf:column/1547846312490/Put/seqid=0&amp;#93;Let's make a note on the doc in the 'HFile Tool' section, that seqid=0 in such cases means seqid is irrelevant here because it's a 'KeyOnlyKeyValue'.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="21884" opendate="2019-2-13 00:00:00" fixdate="2019-2-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix box/unbox findbugs warning in secure bulk load</summary>
      <description>Reason TestsFindBugs module:hbase-serverBoxed value is unboxed and then immediately reboxed in org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint.incrementUgiReference(UserGroupInformation) At SecureBulkLoadEndpoint.java:then immediately reboxed in org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint.incrementUgiReference(UserGroupInformation) At SecureBulkLoadEndpoint.java:[line 268]Looking at branch-2 and master I suspect we're doing the same wasteful operation but findbugs can't see it through the lambda definition.</description>
      <version>3.0.0-alpha-1,1.5.0,2.2.0,2.1.1,2.0.3,2.1.2,2.0.4,1.4.10,1.3.4,1.2.11,2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,1.4.10,2.0.5,1.3.4,1.2.11,2.3.0,2.1.4</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SecureBulkLoadManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="21889" opendate="2019-2-13 00:00:00" fixdate="2019-2-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use thrift 0.12.0 when build thrift by compile-thrift profile</summary>
      <description>Build command.mvn compile -Pcompile-thrift</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.0.5,2.3.0,2.1.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="21907" opendate="2019-2-15 00:00:00" fixdate="2019-2-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Should set priority for rpc request</summary>
      <description>Now in async client we just ignored the priority for RpcController.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncTableImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Put.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncSingleRequestRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncServerRequestRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncScanSingleRegionRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRpcRetryingCallerFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncMasterRequestRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncBatchRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdminRequestRetryingCaller.java</file>
    </fixedFiles>
  </bug>
  <bug id="21909" opendate="2019-2-15 00:00:00" fixdate="2019-2-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Validate the put instance before executing in AsyncTable.put method</summary>
      <description>Align with the sync client implementation.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncBufferMutator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncTableImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.BufferedMutatorImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncConnectionConfiguration.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncBufferedMutatorImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncBufferedMutatorBuilderImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncBufferedMutatorBuilder.java</file>
    </fixedFiles>
  </bug>
  <bug id="22314" opendate="2019-4-25 00:00:00" fixdate="2019-5-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>shaded byo-hadoop client should list needed hadoop modules as provided scope to avoid inclusion of unnecessary transitive depednencies</summary>
      <description>attempting to build against current hadoop trunk for HBASE-22087 shows that hte byo-hadoop client is trying to package transitive dependencies from the hadoop dependencies that we expressly say we don't need to bring with us.it's because we don't list those modules as provided, so all of their transitives are also in compile scope. The shading module does simple filtering when excluding things in a given scope, it doesn't e.g. make sure to also exclude the transitive dependencies of things it keeps out.since we don't want to list all the transitive dependencies of hadoop in our shading exclusion, we should list the needed hadoop modules as provided.</description>
      <version>2.1.0,2.2.0,2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.5</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shaded.hbase-shaded-client-byo-hadoop.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="22345" opendate="2019-4-30 00:00:00" fixdate="2019-5-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>REST Server must have specific version of javax.annotations available at runtime</summary>
      <description>When compiled and run with JDK8, Rest server throws NoClassDefFoundError: javax/annotation/Priority Need to add in the correct dependency version or upgrade the appropriate rest component.</description>
      <version>3.0.0-alpha-1,2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-shaded.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-client.pom.xml</file>
      <file type="M">hbase-protocol-shaded.pom.xml</file>
      <file type="M">hbase-assembly.src.main.assembly.hadoop-two-compat.xml</file>
      <file type="M">hbase-assembly.src.main.assembly.client.xml</file>
    </fixedFiles>
  </bug>
  <bug id="22365" opendate="2019-5-5 00:00:00" fixdate="2019-5-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Region may be opened on two RegionServers</summary>
      <description>Found this problem when run ITBLL with our internal branch which is based on branch-2.2. So mark this as a blocker for 2.2.0. A region 7ebdca9cd09e26074749b546586e2156 is moved from RS-st99 to RS-st98 and the TRSP succeed. Meanwhile, RS-st99 crashed and schedule a new SCP for RS-st99. So SCP initialized subprocedures for 7ebdca9cd09e26074749b546586e2156, too. Then the 7ebdca9cd09e26074749b546586e2156 was assigned to two RegionServers.</description>
      <version>3.0.0-alpha-1,2.2.0,2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.TransitRegionStateProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.RegionRemoteProcedureBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.OpenRegionProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.CloseRegionProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="22380" opendate="2019-5-8 00:00:00" fixdate="2019-10-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>break circle replication when doing bulkload</summary>
      <description>when enabled master-master bulkload replication, HFiles will be replicated circularly between two clusters</description>
      <version>3.0.0-alpha-1,1.5.0,2.2.0,1.4.10,2.0.5,2.3.0,2.1.5,1.3.5</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.1.7,2.2.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.BulkLoadHFilesTool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.HFileReplicator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SecureBulkLoadManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.AsyncClusterConnectionImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.AsyncClusterConnection.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.WAL.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.Client.proto</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.tool.TestBulkLoadHFilesSplitRecovery.java</file>
    </fixedFiles>
  </bug>
  <bug id="22384" opendate="2019-5-8 00:00:00" fixdate="2019-5-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Formatting issues in administration section of book</summary>
      <description>The administration section in the book (64.3.2. Administration) has some formatting issues. Due to that issues the list count is not accurate, as well as the indentation of some code snippets.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,1.4.10,2.3.0,2.0.6,2.1.5,1.3.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.security.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="22460" opendate="2019-5-22 00:00:00" fixdate="2019-10-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reopen a region if store reader references may have leaked</summary>
      <description>We can leak store reader references if a coprocessor or core function somehow opens a scanner, or wraps one, and then does not take care to call close on the scanner or the wrapped instance. A reasonable mitigation for a reader reference leak would be a fast reopen of the region on the same server (initiated by the RS) This will release all resources, like the refcount, leases, etc. The clients should gracefully ride over this like any other region transition. This reopen would be like what is done during schema change application and ideally would reuse the relevant code. If the refcount is over some ridiculous threshold this mitigation could be triggered along with a fat WARN in the logs.</description>
      <version>3.0.0-alpha-1,1.5.0,2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
      <file type="M">src.main.asciidoc..chapters.hbase-default.adoc</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperStub.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ReopenTableRegionsProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.ClusterStatus.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.ClusterStatus.proto</file>
      <file type="M">hbase-hadoop2-compat.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ServerMetricsBuilder.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionMetricsBuilder.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionMetrics.java</file>
    </fixedFiles>
  </bug>
  <bug id="22563" opendate="2019-6-10 00:00:00" fixdate="2019-6-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reduce retained jobs for Jenkins pipelines</summary>
      <description>Our jobs are taking up lots of space. Try to help out infra quickly by reducing the number of old builds we keep.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.2.0,2.3.0,2.0.6,2.1.6,1.3.6,1.4.11</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile.GitHub</file>
      <file type="M">dev-support.Jenkinsfile</file>
      <file type="M">dev-support.flaky-tests.run-flaky-tests.Jenkinsfile</file>
      <file type="M">dev-support.flaky-tests.flaky-reporting.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  <bug id="22689" opendate="2019-7-13 00:00:00" fixdate="2019-7-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Line break for fix version in documentation</summary>
      <description>The section describing the policy for the fix version in JIRA is missing line breaks.</description>
      <version>3.0.0-alpha-1,1.5.0,2.3.0,2.0.6,2.2.1,2.1.6,1.3.6,1.4.11</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,2.0.6,2.2.1,2.1.6,1.3.6,1.4.11</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="22773" opendate="2019-7-31 00:00:00" fixdate="2019-8-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>when set blockSize option in Performance Evaluation tool, error occurs:ERROR: Unrecognized option/command: --blockSize=131072</summary>
      <description>I believe "blockSize" is an new options for PE in HBase2.0, when i try to set the blockSize, error occurs:ERROR: Unrecognized option/command: --blockSize=131072.The error occurs because of missing a "continue;" when we match the option "blockSize". If there isn't a "continue" the program will execute the last "printUsageAndExit branch".</description>
      <version>2.1.0,2.2.0,2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,2.0.6,2.2.1,2.1.6,1.4.11</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
    </fixedFiles>
  </bug>
  <bug id="22790" opendate="2019-8-4 00:00:00" fixdate="2019-8-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add deprecation version for hbase.ipc.server.reservoir.initial.buffer.size &amp; hbase.ipc.server.reservoir.initial.max</summary>
      <description>During the deprecation in HBASE-22598 the deprecation version was not added in the documentation. It should be added as a reminder in what version it can be removed.</description>
      <version>3.0.0-alpha-1,2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.ByteBuffAllocator.java</file>
    </fixedFiles>
  </bug>
  <bug id="22838" opendate="2019-8-12 00:00:00" fixdate="2019-8-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>assembly:single failure: user id or group id &amp;#39;xxxxx&amp;#39; is too big</summary>
      <description> tarball build with assembly:single command fails with user id(mac) or group id(ubuntu) too big error:$ mvn clean install package assembly:single -DskipTests............[ERROR] Failed to execute goal org.apache.maven.plugins:maven-assembly-plugin:3.0.0:single (default-cli) on project hbase-assembly: Execution default-cli of goal org.apache.maven.plugins:maven-assembly-plugin:3.0.0:single failed: user id 'xxxxxxxx' is too big ( &gt; 2097151 ). -&gt; [Help 1][ERROR][ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.[ERROR] Re-run Maven using the -X switch to enable full debug logging.[ERROR][ERROR] For more information about the errors and possible solutions, please read the following articles:[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/PluginExecutionException[ERROR][ERROR] After correcting the problems, you can resume the build with the command[ERROR]   mvn &lt;goals&gt; -rf :hbase-assemblyTo avoid this error and to get better features for tarball build, we should upgrade tarLongFileMode from gnu to posix: MPOM-132This works for assembly plugin &gt;= 2.5.0: MASSEMBLY-728 </description>
      <version>3.0.0-alpha-1,1.5.0,2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,2.0.6,2.2.1,2.1.6,1.3.6,1.4.11</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-assembly.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="22863" opendate="2019-8-15 00:00:00" fixdate="2019-8-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Avoid Jackson versions and dependencies with known CVEs</summary>
      <description>Partly forwardport from branch-1 Jira: HBASE-22728Even though master and branch-2 have moved away from Jackson1 some time back, HBase is still pulling in some vulnerable jackson dependencies (e.g. jackson-mapper-asl:1.9.13) from Hadoop: [INFO] --- maven-dependency-plugin:3.1.1:tree (default-cli) @ hbase-mapreduce ---[INFO] org.apache.hbase:hbase-mapreduce:jar:3.0.0-SNAPSHOT[INFO] +- org.apache.hbase:hbase-server:jar:3.0.0-SNAPSHOT:compile[INFO] | \- org.apache.hbase:hbase-http:jar:3.0.0-SNAPSHOT:compile[INFO] | \- org.codehaus.jackson:jackson-core-asl:jar:1.9.13:compile[INFO] +- org.apache.hadoop:hadoop-mapreduce-client-jobclient:test-jar:tests:2.8.5:test[INFO] | \- org.apache.avro:avro:jar:1.7.7:compile[INFO] | \- org.codehaus.jackson:jackson-mapper-asl:jar:1.9.13:compile[INFO] \- org.apache.hadoop:hadoop-mapreduce-client-core:jar:2.8.5:compile[INFO] \- org.apache.hadoop:hadoop-yarn-common:jar:2.8.5:compile[INFO] +- org.codehaus.jackson:jackson-jaxrs:jar:1.9.13:compile[INFO] \- org.codehaus.jackson:jackson-xc:jar:1.9.13:compile[INFO] --- maven-dependency-plugin:3.1.1:tree (default-cli) @ hbase-shaded-testing-util ---[INFO] org.apache.hbase:hbase-shaded-testing-util:jar:3.0.0-SNAPSHOT[INFO] \- org.apache.hadoop:hadoop-common:test-jar:tests:2.8.5:compile[INFO] +- com.sun.jersey:jersey-json:jar:1.9:compile[INFO] | +- org.codehaus.jackson:jackson-jaxrs:jar:1.8.3:compile[INFO] | \- org.codehaus.jackson:jackson-xc:jar:1.8.3:compile[INFO] +- org.codehaus.jackson:jackson-core-asl:jar:1.9.13:compile[INFO] \- org.codehaus.jackson:jackson-mapper-asl:jar:1.9.13:compile[INFO] org.apache.hbase:hbase-shaded-testing-util-tester:jar:3.0.0-SNAPSHOT[INFO] \- org.apache.hbase:hbase-shaded-testing-util:jar:3.0.0-SNAPSHOT:test[INFO] \- org.apache.hadoop:hadoop-common:test-jar:tests:2.8.5:test[INFO] +- com.sun.jersey:jersey-json:jar:1.9:test[INFO] | +- org.codehaus.jackson:jackson-jaxrs:jar:1.8.3:test[INFO] | \- org.codehaus.jackson:jackson-xc:jar:1.8.3:test[INFO] +- org.codehaus.jackson:jackson-core-asl:jar:1.9.13:compile[INFO] \- org.codehaus.jackson:jackson-mapper-asl:jar:1.9.13:compileJackson1 is not being used in HBase code anymore and hence, we should include it only at test scope if required by Hadoop but definitely exclude it from corresponding Hadoop dependencies. </description>
      <version>3.0.0-alpha-1,2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.1,2.1.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-testing-util.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-testing-util-tester.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-mapreduce.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-client-byo-hadoop.pom.xml</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-mapreduce.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="22911" opendate="2019-8-24 00:00:00" fixdate="2019-8-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>fewer concurrent github PR builds</summary>
      <description>we've been regularly getting 4-5 concurrent builds of PRs.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,2.2.1,2.1.6,1.3.6,1.4.11,2.0.7</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile.GitHub</file>
    </fixedFiles>
  </bug>
  <bug id="22913" opendate="2019-8-24 00:00:00" fixdate="2019-8-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use Hadoop label for nightly builds</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,2.2.1,2.1.6,1.3.6,1.4.11</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  <bug id="22954" opendate="2019-8-30 00:00:00" fixdate="2019-9-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Whitelist net.java.dev.jna which got pulled in through Hadoop 3.3.0</summary>
      <description>YARN-9477 added a new dependency net.java.dev.jna, which resulted in license check failure in HBase because the checker thinks it's LGPL 2.1 licensed. But in fact, it is dual licensed. &lt;name&gt;Java Native Access&lt;/name&gt; &lt;description&gt;Java Native Access&lt;/description&gt; &lt;url&gt;https://github.com/java-native-access/jna&lt;/url&gt; &lt;licenses&gt; &lt;license&gt; &lt;name&gt;LGPL, version 2.1&lt;/name&gt; &lt;url&gt;http://www.gnu.org/licenses/licenses.html&lt;/url&gt; &lt;distribution&gt;repo&lt;/distribution&gt; &lt;/license&gt; &lt;license&gt; &lt;name&gt;Apache License v2.0&lt;/name&gt; &lt;url&gt;http://www.apache.org/licenses/LICENSE-2.0.txt&lt;/url&gt; &lt;distribution&gt;repo&lt;/distribution&gt; &lt;/license&gt; &lt;/licenses&gt;We can(1) white list this dependency(2) or update the license checker to search for if any of the licenses is permitted</description>
      <version>3.0.0-alpha-1,2.3.0,2.1.7,2.2.2</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.1,2.1.7</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-resource-bundle.src.main.resources.supplemental-models.xml</file>
    </fixedFiles>
  </bug>
  <bug id="23035" opendate="2019-9-17 00:00:00" fixdate="2019-9-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Retain region to the last RegionServer make the failover slower</summary>
      <description>Now if one RS crashed, the regions will try to use the old location for the region deploy. But one RS only have 3 threads to open region by default. If a RS have hundreds of regions, the failover is very slower. Assign to same RS may have good locality if the Datanode is deploied on same host. But slower failover make the availability worse. And the locality is not big deal when deploy HBase on cloud.This was introduced by HBASE-18946.</description>
      <version>3.0.0-alpha-1,2.3.0,2.2.1,2.1.6</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.1.7,2.2.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionReplicasWithRestartScenarios.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRetainAssignmentOnRestartSplitWithoutZk.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRetainAssignmentOnRestart.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterOperationsForRegionReplicas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestSCPBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.TransitRegionStateProcedure.java</file>
    </fixedFiles>
  </bug>
  <bug id="23041" opendate="2019-9-18 00:00:00" fixdate="2019-9-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Should not show split parent regions in HBCK report&amp;#39;s unknown server part</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.1.7,2.2.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HbckChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
    </fixedFiles>
  </bug>
  <bug id="23043" opendate="2019-9-18 00:00:00" fixdate="2019-9-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestWALEntryStream times out</summary>
      <description>TestWALEntryStream#testDifferentCounts times out almost every time (90%+).On my machine the test runs in 9,5 minutes but on ASF infra it reaches the 720s timeout.</description>
      <version>3.0.0-alpha-1,2.3.0,2.1.7,2.2.2</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.1.7,2.2.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="23093" opendate="2019-9-29 00:00:00" fixdate="2019-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Avoid Optional Anti-Pattern where possible</summary>
      <description>Optional should be used as a return type only. It's a neat solution for handling data that might  not be present. We should avoid using Optional Anti-Patterns i.e. using it as a field or parameter type due to these reasons:1. Using Optional parameters causing conditional logic inside the methods is not productive.2. Packing an argument in an Optional is suboptimal for the compiler and does an unnecessary wrapping.3. Optional field is not serializable.</description>
      <version>3.0.0-alpha-1,2.3.0,1.6.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.2,2.1.8</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTableAdminApi3.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTableAdminApi.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncRegionAdminApi2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSWALEntry.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.client.example.HttpProxyExample.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableRegionLocatorImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRegionLocatorHelper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncNonMetaRegionLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncMetaRegionLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.AsyncMetaTableAccessor.java</file>
    </fixedFiles>
  </bug>
  <bug id="23094" opendate="2019-9-29 00:00:00" fixdate="2019-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Wrong log message in simpleRegionNormaliser while checking if merge is enabled.</summary>
      <description>In the following log message :LOG.debug("Unable to determine whether split is enabled", e);it should be "Unable to determine whether merge is enabled" while checking if merge is enabled. It can lead to confusion while debugging through logs.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,1.3.6,1.4.11,2.2.2,2.1.8</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.normalizer.SimpleRegionNormalizer.java</file>
    </fixedFiles>
  </bug>
  <bug id="23106" opendate="2019-10-1 00:00:00" fixdate="2019-10-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>WAL tools doc cleanup; talk of WAL Reader/Verifier; link WALPlayer</summary>
      <description>We had a WALPlayer that loads edits up into hbase cluster but what I wanted yesterday was a WAL verifier so I could find the bad WAL messing me up.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="23156" opendate="2019-10-12 00:00:00" fixdate="2019-1-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>start-hbase.sh failed with ClassNotFoundException when build with hadoop3</summary>
      <description>Exception in thread "main" java.lang.NoClassDefFoundError: com/ctc/wstx/io/InputBootstrapperException in thread "main" java.lang.NoClassDefFoundError: com/ctc/wstx/io/InputBootstrapper at org.apache.hadoop.hbase.util.HBaseConfTool.main(HBaseConfTool.java:39)Caused by: java.lang.ClassNotFoundException: com.ctc.wstx.io.InputBootstrapper at java.net.URLClassLoader.findClass(URLClassLoader.java:382) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ... 1 moreException in thread "main" java.lang.NoClassDefFoundError: com/ctc/wstx/io/InputBootstrapper at org.apache.hadoop.hbase.zookeeper.ZKServerTool.main(ZKServerTool.java:63)Caused by: java.lang.ClassNotFoundException: com.ctc.wstx.io.InputBootstrapper at java.net.URLClassLoader.findClass(URLClassLoader.java:382) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ... 1 more</description>
      <version>3.0.0-alpha-1,2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="2328" opendate="2010-3-15 00:00:00" fixdate="2010-7-15 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Make important configurations more obvious to new users</summary>
      <description>Over the last 2 weeks, I encountered many situations where people didn't set file descriptors and xcievers higher and that was causing a ton of problems that are hard to debug if you're not used to them. To improve that we should: Refuse to start HBase if ulimit -n returns some small number smaller than 2048, or at least print out in big red blinking letters that the current configuration is bad and then link to a simple troubleshooting entry on the wiki. Write a clearer Getting Started document where we don't give as much explanations but add more stuff like "this is what your hbase-site.xml/hdfs-site/xml should look like now" and give a complete file example. At this point we don't even give a number for xcievers and we expect new users to come up with one.Any other low hanging fruit others can think of?</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.javadoc.overview.html</file>
      <file type="M">src.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="23283" opendate="2019-11-13 00:00:00" fixdate="2019-11-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Provide clear and consistent logging about the period of enabled chores</summary>
      <description>Similar to HBASE-23038, we should always log info about our enabled chores. Right now wether or not we get some information is up to particular Chore constructors and by and large we don't get any log messages when things can get started, even if the period is something impossibly long (e.g. 3000 days).When we go to schedule the chore here: if (chore.getPeriod() &lt;= 0) { LOG.info("The period is {} seconds, {} is disabled", chore.getPeriod(), chore.getName()); return false; }we should add an else clause that says it's enabled. It looks like we could then just call chore.toString to get the proper details about the chore and its period.</description>
      <version>3.0.0-alpha-1,2.3.0,1.7.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,1.6.0,2.1.8,2.2.3</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ChoreService.java</file>
    </fixedFiles>
  </bug>
  <bug id="23286" opendate="2019-11-13 00:00:00" fixdate="2019-1-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve MTTR: Split WAL to HFile</summary>
      <description>After HBASE-20724, the compaction event marker is not used anymore when failover. So our new proposal is split WAL to HFile to imporve MTTR. It has 3 steps: Read WAL and write HFile to region’s column family’s recovered.hfiles directory. Open region. Bulkload the recovered.hfiles for every column family.The design doc was attathed by a google doc. Any suggestions are welcomed.</description>
      <version>3.0.0-alpha-1,2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestWALSplit.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.AbstractTestWALReplay.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALSplitUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.RecoveredEditsOutputSink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.OutputSink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.BoundedRecoveredEditsOutputSink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CellSet.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="23334" opendate="2019-11-23 00:00:00" fixdate="2019-11-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The table-lock node of zk is not needed since HBASE-16786</summary>
      <description>The table-lock znode still be created when init,and it may cause confusion.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.3</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-zookeeper.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKWatcher.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZNodePaths.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZNodePaths.java</file>
    </fixedFiles>
  </bug>
  <bug id="23364" opendate="2019-11-20 00:00:00" fixdate="2019-12-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HRegionServer sometimes does not shut down.</summary>
      <description>Note that I initially assumed this to be a Phoenix bug. But I tracked it down to HBase.I noticed that recently only. Latest build from HBase's branch-1 and latest build from Phoenix' 4.x-HBase-1.5. I don't know, yet, whether it's a Phoenix or an HBase issues.Just filing it here for later reference.jstack show this thread as the only non-daemon thread:"pool-11-thread-1" #470 prio=5 os_prio=0 tid=0x0000558a709a4800 nid=0x238e waiting on condition [0x00007f213ad68000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x000000058eafece8&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)No other information. Somebody created a thread pool somewhere and forgot to set the threads to daemon or is not shutting down the pool properly.Edit: I looked for other reference of the locked objects in the stack dump, but didn't find any.  </description>
      <version>3.0.0-alpha-1,2.3.0,1.6.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,1.6.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.LossyCounting.java</file>
    </fixedFiles>
  </bug>
  <bug id="23633" opendate="2020-1-3 00:00:00" fixdate="2020-3-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Find a way to handle the corrupt recovered hfiles</summary>
      <description>Copy the comment from PR review. If the file is a corrupt HFile, an exception will be thrown here, which will cause the region to fail to open.Maybe we can add a new parameter to control whether to skip the exception, similar to recover edits which has a parameter "hbase.hregion.edits.replay.skip.errors"; Regions that can't be opened because of detached References or corrupt hfiles are a fact-of-life. We need work on this issue. This will be a new variant on the problem &amp;#8211; i.e. bad recovered hfiles.On adding a config to ignore bad files and just open, thats a bit dangerous as per @infraio .... as it could mean silent data loss.</description>
      <version>3.0.0-alpha-1,2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="23635" opendate="2020-1-3 00:00:00" fixdate="2020-1-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reduce number of Checkstyle violations in hbase-mapreduce</summary>
      <description>In hbase-mapreduce Checkstyle reports a lot of violations. The number of violations should be reduced.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.3,2.1.9</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-mapreduce.src.test.resources.org.apache.hadoop.hbase.PerformanceEvaluation.Counter.properties</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.TestPerformanceEvaluation.java</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.mapreduce.TsvImporterCustomTestMapper.java</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableSplit.java</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.mapreduce.TestSyncTable.java</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.mapreduce.TestImportTsvParser.java</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.mapreduce.TestHashTable.java</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.mapreduce.TestCellCounter.java</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatTestBase.java</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.mapreduce.NMapInputFormat.java</file>
    </fixedFiles>
  </bug>
  <bug id="23664" opendate="2020-1-8 00:00:00" fixdate="2020-1-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade JUnit to 4.13</summary>
      <description>New JUnit released a week ago. Let's give it a spin.https://github.com/junit-team/junit4/blob/master/doc/ReleaseNotes4.13.md</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="23675" opendate="2020-1-10 00:00:00" fixdate="2020-1-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move to Apache parent POM version 22</summary>
      <description>Apache parent POM version 22 was released on 2020/01/09.</description>
      <version>3.0.0-alpha-1,2.3.0,1.6.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,1.6.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-build-configuration.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="23688" opendate="2020-1-14 00:00:00" fixdate="2020-1-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update docs for setting up IntelliJ as a development environment</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="23689" opendate="2020-1-15 00:00:00" fixdate="2020-1-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bookmark for github PR to jira redirection</summary>
      <description>Following is a simple js snippet that redirects from any HBase PR to its corresponding jira. Without this, one has to copy the jira ID from the PR, construct a jira URL manually and paste it in the browser URL bar. Saves a bunch of clicks.javascript:location.href='https://issues.apache.org/jira/browse/'document.getElementsByClassName("js-issue-title")[0].innerHTML.match(/HBASE-\d/)[0];Particularly helpful for reviewers who'd like to read the jira contents often when reviewing a PR.For chrome: Right Click on the bookmarks bar Click on Add page. Fill in the following details: Name: HBase jira redirect (or any other that you prefer) URL: – snippet from above-- Click SaveNow you should see "HBase jira redirect" (or any other name you gave) bookmark on the bar. Go to any Github PR, click on this button and it redirects to the corresponding jira.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="23690" opendate="2020-1-15 00:00:00" fixdate="2020-1-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Checkstyle plugin complains about our checkstyle.xml format; doc how to resolve mismatched version</summary>
      <description>Trying to add the checkstyle.xml to the intellij checkstyle plugin after reading HBASE-23688, it complains with the following when it reads in the config file:com.puppycrawl.tools.checkstyle.api.CheckstyleException: cannot initialize module TreeWalker - TreeWalker is not allowed as a parent of LineLength Please review 'Parent Module' section for this Check in web documentation if Check is standard. at com.puppycrawl.tools.checkstyle.Checker.setupChild(Checker.java:473) at com.puppycrawl.tools.checkstyle.api.AutomaticBean.configure(AutomaticBean.java:198) at org.infernus.idea.checkstyle.service.cmd.OpCreateChecker.execute(OpCreateChecker.java:61) at org.infernus.idea.checkstyle.service.cmd.OpCreateChecker.execute(OpCreateChecker.java:26) at org.infernus.idea.checkstyle.service.CheckstyleActionsImpl.executeCommand(CheckstyleActionsImpl.java:130) at org.infernus.idea.checkstyle.service.CheckstyleActionsImpl.createChecker(CheckstyleActionsImpl.java:60) at org.infernus.idea.checkstyle.service.CheckstyleActionsImpl.createChecker(CheckstyleActionsImpl.java:51) at org.infernus.idea.checkstyle.checker.CheckerFactoryWorker.run(CheckerFactoryWorker.java:46)Caused by: com.puppycrawl.tools.checkstyle.api.CheckstyleException: TreeWalker is not allowed as a parent of LineLength Please review 'Parent Module' section for this Check in web documentation if Check is standard. at com.puppycrawl.tools.checkstyle.TreeWalker.setupChild(TreeWalker.java:147) at com.puppycrawl.tools.checkstyle.api.AutomaticBean.configure(AutomaticBean.java:198) at com.puppycrawl.tools.checkstyle.Checker.setupChild(Checker.java:468) ... 7 more</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="23691" opendate="2020-1-15 00:00:00" fixdate="2020-1-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add 2.2.3 to download page</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.downloads.xml</file>
    </fixedFiles>
  </bug>
  <bug id="23697" opendate="2020-1-15 00:00:00" fixdate="2020-4-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document new RegionProcedureStore operation and migration</summary>
      <description>Add a few notes to the refguide on the new RegionProcedureStore, how it works (A 'Region' but buried in the Master with dedicated flushing/compacting threads and archivers for WAL and hfile), how it differs from WALPS, and note it auto-migrates and there should be new issue moving on to the new store.Mention the configuration. Mention it is on WALFS even though it is a 'Region', etc.</description>
      <version>2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="23709" opendate="2020-1-19 00:00:00" fixdate="2020-1-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unwrap the real user to properly dispatch proxy-user auth&amp;#39;n</summary>
      <description>Currently TestSecureRESTServer fails consistently on branch-2 and should be fixed.</description>
      <version>3.0.0-alpha-1,2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.provider.BuiltInProviderSelector.java</file>
    </fixedFiles>
  </bug>
  <bug id="23710" opendate="2020-1-20 00:00:00" fixdate="2020-1-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Priority configuration for system coprocessors</summary>
      <description>Currenty HBase allows operators to set system region coprocessors via hbase-site.xml to be loaded on each table in a cluster (or alternately, all tables but system tables). HBase assumes that the first loaded system coprocessor gets the first, or SYSTEM priority, with each subsequent system coproc getting incremented by 1. As a reminder, in HBase lower priorities go first. It can be useful for an operator to be able to define a coprocessor on each table that needs a different priority. For example, an operator might want a coproc to load on each table last, so that it can enforce some system invariant and know that no other coproc will interfere with it. I propose adding optional priority config to the hbase-site.xml configuration, separated from each coproc class in the comma-separated list by a special character (perhaps a pipe, such as table coprocs use) that's not used in class names. The region coprocessor host will parse the priority if present and use it when instantiating the coproc.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,1.6.0,2.1.9,2.2.4</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.cp.adoc</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorHost.java</file>
    </fixedFiles>
  </bug>
  <bug id="23741" opendate="2020-1-27 00:00:00" fixdate="2020-3-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Data loss when WAL split to HFile enabled</summary>
      <description>Very simple steps as below,1. Create table with 1 region2. Insert 1 record 3. Flush the table 4. Scan table and observe timestamp of the inserted row5. Insert same row key with same timestamp as previously inserted but with different value6. Kill -9 RS where table region is online7. Start RSScan the table and check the result, latest cell must be returned.Thanks sreenivasulureddy for finding this issue.</description>
      <version>3.0.0-alpha-1,2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestWALSplitToHFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALSplitUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.BoundedRecoveredHFilesOutputSink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="23753" opendate="2020-1-28 00:00:00" fixdate="2020-1-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update of errorprone generated failures</summary>
      <description>Parent issue updated hbase-thirdparty which updated errorprone. The nightly compile started failing with 'compile'/errorprone complaints. All look good. Let me fix.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestSnapshotScannerHDFSAclController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSinkManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionReplicasWithRestartScenarios.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.executor.EventHandler.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionInfoBuilder.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionInfo.java</file>
    </fixedFiles>
  </bug>
  <bug id="23755" opendate="2020-1-28 00:00:00" fixdate="2020-2-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[OpenTracing] Declare HTrace is unusable in the user doc</summary>
      <description>The trace doesn't work at all in HBase 2.0 and above after HBASE-18601 (the trace doesn't get picked up at the server side). We should make a note in the user doc stating it is unusable deprecated in HBase 2.x because HTrace is in Attic. removed from HBase 3.0 and above.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
      <file type="M">src.main.asciidoc..chapters.tracing.adoc</file>
      <file type="M">src.main.asciidoc.book.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="23793" opendate="2020-2-4 00:00:00" fixdate="2020-2-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Increase maven heap allocation to 4G in Yetus personality</summary>
      <description>I saw this over on https://builds.apache.org/view/H-L/view/HBase/job/HBase%20Nightly/job/branch-2/2447/console. Looks like we need to bump the memory allocation for maven. I wonder if this is the underlying cause of HBASE-22470. 6:38:47 ============================================================================16:38:47 ============================================================================16:38:47 Finished build.16:38:47 ============================================================================16:38:47 ============================================================================16:38:47 16:38:47 Post stage[Pipeline] stash16:38:48 Warning: overwriting stash 'hadoop2-result'16:38:48 Stashed 1 file(s)[Pipeline] junit16:38:48 Recording test results16:38:54 Remote call on H2 failedError when executing always post condition:java.io.IOException: Remote call on H2 failed at hudson.remoting.Channel.call(Channel.java:963) at hudson.FilePath.act(FilePath.java:1072) at hudson.FilePath.act(FilePath.java:1061) at hudson.tasks.junit.JUnitParser.parseResult(JUnitParser.java:114) at hudson.tasks.junit.JUnitResultArchiver.parse(JUnitResultArchiver.java:137) at hudson.tasks.junit.JUnitResultArchiver.parseAndAttach(JUnitResultArchiver.java:167) at hudson.tasks.junit.pipeline.JUnitResultsStepExecution.run(JUnitResultsStepExecution.java:52) at hudson.tasks.junit.pipeline.JUnitResultsStepExecution.run(JUnitResultsStepExecution.java:25) at org.jenkinsci.plugins.workflow.steps.SynchronousNonBlockingStepExecution.lambda$start$0(SynchronousNonBlockingStepExecution.java:47) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)Caused by: java.lang.OutOfMemoryError: Java heap space at com.sun.org.apache.xerces.internal.util.XMLStringBuffer.append(XMLStringBuffer.java:208) at com.sun.org.apache.xerces.internal.impl.XMLEntityScanner.scanData(XMLEntityScanner.java:1515) at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanCDATASection(XMLDocumentFragmentScannerImpl.java:1654) at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:3014) at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:602) at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:112) at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:505) at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:842) at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:771) at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141) at com.sun.org.apache.xerces.internal.parsers.AbstractSAXParser.parse(AbstractSAXParser.java:1213) at com.sun.org.apache.xerces.internal.jaxp.SAXParserImpl$JAXPSAXParser.parse(SAXParserImpl.java:643) at org.dom4j.io.SAXReader.read(SAXReader.java:465) at org.dom4j.io.SAXReader.read(SAXReader.java:343) at hudson.tasks.junit.SuiteResult.parse(SuiteResult.java:178) at hudson.tasks.junit.TestResult.parse(TestResult.java:348) at hudson.tasks.junit.TestResult.parsePossiblyEmpty(TestResult.java:281) at hudson.tasks.junit.TestResult.parse(TestResult.java:206) at hudson.tasks.junit.TestResult.parse(TestResult.java:178) at hudson.tasks.junit.TestResult.&lt;init&gt;(TestResult.java:143) at hudson.tasks.junit.JUnitParser$ParseResultCallable.invoke(JUnitParser.java:146) at hudson.tasks.junit.JUnitParser$ParseResultCallable.invoke(JUnitParser.java:118) at hudson.FilePath$FileCallableWrapper.call(FilePath.java:3052) at hudson.remoting.UserRequest.perform(UserRequest.java:212) at hudson.remoting.UserRequest.perform(UserRequest.java:54) at hudson.remoting.Request$2.run(Request.java:369) at hudson.remoting.InterceptingExecutorService$1.call(InterceptingExecutorService.java:72) ... 4 more[Pipeline] }[Pipeline] // withEnv[Pipeline] }[Pipeline] // node[Pipeline] }[Pipeline] // stage[Pipeline] }16:38:54 Failed in branch yetus jdk8 hadoop2 checks</description>
      <version>2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,1.6.0,1.3.7,2.1.9,1.4.13,2.2.4</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  <bug id="23798" opendate="2020-2-5 00:00:00" fixdate="2020-3-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove hbase-prototcol module</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-protocol.src.main.protobuf.test.rpc.service.proto</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift2.TestThriftHBaseServiceHandlerWithLabels.java</file>
      <file type="M">hbase-thrift.pom.xml</file>
      <file type="M">hbase-testing-util.pom.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithSLGStack.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.protobuf.TestReplicationProtobuf.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.protobuf.TestProtobufUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.CellModel.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.ZooKeeper.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.WAL.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.VisibilityLabels.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Tracing.proto</file>
      <file type="M">hbase-assembly.pom.xml</file>
      <file type="M">hbase-client.pom.xml</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.Batch.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Table.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.CoprocessorRpcChannel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.ServerRpcController.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.ClientSnapshotDescriptionUtils.java</file>
      <file type="M">hbase-endpoint.pom.xml</file>
      <file type="M">hbase-endpoint.src.test.java.org.apache.hadoop.hbase.coprocessor.TestSecureExport.java</file>
      <file type="M">hbase-examples.pom.xml</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.types.PBCell.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.types.PBType.java</file>
      <file type="M">hbase-examples.src.test.java.org.apache.hadoop.hbase.types.TestPBCell.java</file>
      <file type="M">hbase-it.pom.xml</file>
      <file type="M">hbase-mapreduce.pom.xml</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.mapreduce.TestImportTSVWithVisibilityLabels.java</file>
      <file type="M">hbase-protocol.pom.xml</file>
      <file type="M">hbase-protocol.README.txt</file>
      <file type="M">hbase-protocol.src.main.java.com.google.protobuf.HBaseZeroCopyByteString.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.util.ByteStringer.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.AccessControl.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Admin.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Authentication.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Cell.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Client.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.ClusterId.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.ClusterStatus.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Comparator.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Encryption.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.ErrorHandling.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Filter.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.FS.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.HBase.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.HFile.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.LoadBalancer.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.MapReduce.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.MultiRowMutation.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.PingProtocol.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Quota.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.RowProcessor.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.RPC.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.RSGroup.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.RSGroupAdmin.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Snapshot.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.test.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.TestProcedure.proto</file>
    </fixedFiles>
  </bug>
  <bug id="23799" opendate="2020-2-5 00:00:00" fixdate="2020-3-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make our core coprocessors use shaded protobuf</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-endpoint.src.main.protobuf.Export.proto</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestWALFiltering.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.VisibilityLabelsWithDeletesTestBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestWithDisabledAuthorization.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityWithCheckAuths.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLablesWithGroups.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithDeletes.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithDefaultVisLabelService.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithACL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsOpWithDifferentUsersNoACL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabels.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.token.TestTokenAuthentication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.token.TestGenerateDelegationToken.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestRpcAccessChecks.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestNamespaceCommands.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.SecureTestUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rsgroup.VerifyingRSGroupAdmin.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rsgroup.TestMigrateRSGroupInfo.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.RegionAsTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MockRegionServerServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterCoprocessorServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockNoopMasterServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorMetrics.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMetaWithReplicas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide5.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide3.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestConnection.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.DummyAsyncTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityLabelsCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.TokenUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.TokenProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.PermissionStorage.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupInfoManagerImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupAdminServiceImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupAdminEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupAdminClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RowProcessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.BaseRowProcessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MirroringTableStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.SingletonCoprocessorService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.EndpointObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorServiceBackwardCompatiblity.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseRowProcessorEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.coprocessor.RowProcessorClient.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.AccessControl.proto</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestMetaReplicas.java</file>
      <file type="M">hbase-examples.src.main.protobuf.RefreshHFiles.proto</file>
      <file type="M">hbase-examples.src.main.protobuf.Examples.proto</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.coprocessor.example.RowCountEndpoint.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.coprocessor.example.RefreshHFilesEndpoint.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.coprocessor.example.BulkDeleteEndpoint.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.client.example.RefreshHFilesClient.java</file>
      <file type="M">hbase-endpoint.src.test.java.org.apache.hadoop.hbase.regionserver.TestServerCustomProtocol.java</file>
      <file type="M">hbase-endpoint.src.test.java.org.apache.hadoop.hbase.ipc.TestCoprocessorRpcUtils.java</file>
      <file type="M">hbase-endpoint.src.test.java.org.apache.hadoop.hbase.coprocessor.TestSecureExport.java</file>
      <file type="M">hbase-endpoint.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRowProcessorEndpoint.java</file>
      <file type="M">hbase-endpoint.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorEndpoint.java</file>
      <file type="M">hbase-endpoint.src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorTableEndpoint.java</file>
      <file type="M">hbase-endpoint.src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorServiceBackwardCompatibility.java</file>
      <file type="M">hbase-endpoint.src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorEndpoint.java</file>
      <file type="M">hbase-endpoint.src.test.java.org.apache.hadoop.hbase.coprocessor.TestBatchCoprocessorEndpoint.java</file>
      <file type="M">hbase-endpoint.src.test.java.org.apache.hadoop.hbase.coprocessor.TestAsyncCoprocessorEndpoint.java</file>
      <file type="M">hbase-endpoint.src.test.java.org.apache.hadoop.hbase.coprocessor.ProtobufCoprocessorService.java</file>
      <file type="M">hbase-endpoint.src.test.java.org.apache.hadoop.hbase.coprocessor.ColumnAggregationEndpointWithErrors.java</file>
      <file type="M">hbase-endpoint.src.test.java.org.apache.hadoop.hbase.coprocessor.ColumnAggregationEndpointNullResponse.java</file>
      <file type="M">hbase-endpoint.src.test.java.org.apache.hadoop.hbase.coprocessor.ColumnAggregationEndpoint.java</file>
      <file type="M">hbase-endpoint.src.main.protobuf.IncrementCounterProcessor.proto</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AdminOverAsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientCoprocessorRpcController.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.CoprocessorBlockingRpcCallback.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.BigDecimalColumnInterpreter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.DoubleColumnInterpreter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.LongColumnInterpreter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MasterCoprocessorRpcChannelImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Mutation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncTableImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionCoprocessorRpcChannelImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionCoprocessorServiceExec.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionServerCoprocessorRpcChannelImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ServiceCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.SyncCoprocessorRpcChannel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Table.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.TableOverAsyncTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.Coprocessor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.coprocessor.ColumnInterpreter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.BinaryComponentComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.CoprocessorRpcChannel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.CoprocessorRpcUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.ServerRpcController.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MetaTableAccessor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.SecurityInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.token.AuthenticationTokenIdentifier.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.token.ClientTokenUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ResponseConverter.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.security.token.TestClientTokenUtil.java</file>
      <file type="M">hbase-endpoint.pom.xml</file>
      <file type="M">hbase-endpoint.src.main.java.org.apache.hadoop.hbase.client.coprocessor.AggregationClient.java</file>
      <file type="M">hbase-endpoint.src.main.java.org.apache.hadoop.hbase.client.coprocessor.AggregationHelper.java</file>
      <file type="M">hbase-endpoint.src.main.java.org.apache.hadoop.hbase.client.coprocessor.AsyncAggregationClient.java</file>
      <file type="M">hbase-endpoint.src.main.java.org.apache.hadoop.hbase.coprocessor.AggregateImplementation.java</file>
      <file type="M">hbase-endpoint.src.main.java.org.apache.hadoop.hbase.coprocessor.Export.java</file>
      <file type="M">hbase-endpoint.src.main.protobuf.Aggregate.proto</file>
      <file type="M">hbase-endpoint.src.main.protobuf.BulkDelete.proto</file>
      <file type="M">hbase-endpoint.src.main.protobuf.ColumnAggregationNullResponseProtocol.proto</file>
      <file type="M">hbase-endpoint.src.main.protobuf.ColumnAggregationProtocol.proto</file>
      <file type="M">hbase-endpoint.src.main.protobuf.ColumnAggregationWithErrorsProtocol.proto</file>
      <file type="M">hbase-endpoint.src.main.protobuf.DummyRegionServerEndpoint.proto</file>
    </fixedFiles>
  </bug>
  <bug id="23800" opendate="2020-2-5 00:00:00" fixdate="2020-4-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add documentation about the CECPs changes</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.protobuf.adoc</file>
      <file type="M">src.main.asciidoc..chapters.cp.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="23803" opendate="2020-2-5 00:00:00" fixdate="2020-2-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[DOC] Fix the maths on the section explaining call queue tuning options</summary>
      <description>Section "121.11. Tuning callQueue Options" from the RefGuide has some mismatches when explaining the percentages applied by different values set to hbase.ipc.server.callqueue.read.ratio and hbase.ipc.server.callqueue.scan.ratio, respectively, such as:A value of .3 uses 30% of the queues for reading and 60% for writing. Given a value of 10 for hbase.ipc.server.num.callqueue, 3 queues would be used for reads and 7 for writes.Should be:A value of .3 uses 30% of the queues for reading and 70% for writing. Given a value of 10 for hbase.ipc.server.num.callqueue, 3 queues would be used for reads and 7 for writes.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.performance.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="23804" opendate="2020-2-6 00:00:00" fixdate="2020-2-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix default master addr hostname in master registry</summary>
      <description>Currently, master RPC server (not info server) always binds to the address endpoint to which the default hostname of the server resolves to. However, master registry picks the default end point to connect to as "localhost:16000" when "hbase.masters" are not configured. This is leading to a mismatch because the server may not be listening on the loopback address. This is a problem only in the scripts (single proc/pseudo distributed modes) because these are the cases in which "hbase.masters" is not populated by default.The fix is to pick the service endpoint the same way the RPC server does it.</description>
      <version>3.0.0-alpha-1,2.3.0,1.6.0,HBASE-18095</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,HBASE-18095</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerHostname.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.MockHStoreFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMasterRegistry.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.RatioBasedCompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.DateTieredCompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.DNS.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MasterRegistry.java</file>
    </fixedFiles>
  </bug>
  <bug id="23809" opendate="2020-2-7 00:00:00" fixdate="2020-2-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The RSGroup shell test is missing</summary>
      <description>We exclude the rsgroup_shell_test.rb in TestShell, but never introduce a TestRSGroupShell to include it...</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.1.9,2.2.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupAdminServer.java</file>
      <file type="M">hbase-shell.src.test.java.org.apache.hadoop.hbase.client.AbstractTestShell.java</file>
    </fixedFiles>
  </bug>
  <bug id="23855" opendate="2020-2-16 00:00:00" fixdate="2020-2-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change bytes size to human readable size for Server Metrics of RegionServer Web UI</summary>
      <description>I found that the “BytesBufferAllocator Status” in RegionServer Web UI still using "Bytes" as a fixture unit. I think we should use "MB" or "GB" when the size is too large  The Web UI after improvement:</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="23857" opendate="2020-2-17 00:00:00" fixdate="2020-2-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add 2.1.9 to download page</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.downloads.xml</file>
    </fixedFiles>
  </bug>
  <bug id="23859" opendate="2020-2-17 00:00:00" fixdate="2020-2-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Modify "Block locality" of RegionServer Web UI to human readable percentage</summary>
      <description>The unit of "Block locality" in Web UI just like picture 1I think we should change it to percentage unit like picture 2 </description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.4,2.1.10</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="23932" opendate="2020-3-5 00:00:00" fixdate="2020-3-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Minor improvements to Region Normalizer</summary>
      <description>While hbck2 runs through fixes to meta, the Normalizer kicks in to "help". Mostly this is fine, however, things get confused when fixMeta is action on a region and then the normalizer decides to do something as well. Could be we advise operators disable normalizer while running hbck2, but would be better if the normalizer was less aggressive, so that there's fewer flags to fiddle.</description>
      <version>2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.normalizer.TestSimpleRegionNormalizer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.normalizer.TestMergeNormalizer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.normalizer.AbstractRegionNormalizer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="23933" opendate="2020-3-5 00:00:00" fixdate="2020-4-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Separate a hbase-balancer or hbase-assignment module</summary>
      <description>Open an issue here. After we merge hbase-rsgroup back to hbase-server, the hbase-server even makes findbugs OOM...So I think we should try to move out classes to make the module smaller...</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRegionPlan.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestServerAndLoad.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SnapshotOfRegionAssignmentFromMeta.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionPlan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RackManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.ServerAndLoad.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.RegionInfoComparator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.MetricsStochasticBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.MetricsBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.ClusterLoadState.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BalancerRegionLoad.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.ServerState.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentVerificationReport.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.favored.StartcodeAgnosticServerName.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.favored.FavoredNodesPromoter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.favored.FavoredNodesPlan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.favored.FavoredNodeAssignmentHelper.java</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-assembly.src.main.assembly.hadoop-two-compat.xml</file>
      <file type="M">hbase-assembly.src.main.assembly.hadoop-three-compat.xml</file>
      <file type="M">hbase-assembly.pom.xml</file>
      <file type="M">hbase-balancer.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="23936" opendate="2020-3-5 00:00:00" fixdate="2020-3-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thrift support for get and clear slow_log APIs</summary>
      <description>Provide thrift support for get_slowlog_responses() and clear_slowlog_responses() Admin APIs.</description>
      <version>3.0.0-alpha-1,2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift2.TestThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-thrift.src.main.resources.org.apache.hadoop.hbase.thrift2.hbase.thrift</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftUtilities.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TTimeRange.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TThriftServerType.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TTableName.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TTableDescriptor.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TServerName.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TScan.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TRowMutations.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TResult.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TReadType.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TPut.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TNamespaceDescriptor.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TMutation.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TKeepDeletedCells.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIOError.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIncrement.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIllegalArgument.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.THRegionLocation.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.THRegionInfo.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.THBaseService.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TGet.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TDurability.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TDeleteType.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TDelete.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TDataBlockEncoding.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TConsistency.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TCompressionAlgorithm.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TCompareOperator.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumnValue.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumnIncrement.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumnFamilyDescriptor.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumn.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TCellVisibility.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TBloomFilterType.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TAuthorization.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TAppend.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.client.ThriftAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="23937" opendate="2020-3-5 00:00:00" fixdate="2020-4-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Retrieve online large RPC logs</summary>
      <description>Similar to online slow RPC response logs, we should also provide get and clear of large RPC logs which should be stored in the online RingBuffer. Many of slow response logs would also turn out to be large response logs for RegionServers.</description>
      <version>3.0.0-alpha-1,2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TResult.java</file>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift2.TestThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-thrift.src.main.resources.org.apache.hadoop.hbase.thrift2.hbase.thrift</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftUtilities.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TTimeRange.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TThriftServerType.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TTableName.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TTableDescriptor.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TSlowLogRecord.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TSlowLogQueryFilter.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TServerName.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TScan.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TRowMutations.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AdminOverAsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.SlowLogQueryFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.SlowLogRecord.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.RequestConverter.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.Admin.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.TooSlowLog.proto</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.slowlog.RpcLogDetails.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.slowlog.SlowLogEventHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.slowlog.SlowLogRecorder.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin2.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.slowlog.TestSlowLogRecorder.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rsgroup.VerifyingRSGroupAdmin.java</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.rb</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.client.ThriftAdmin.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TAppend.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TAuthorization.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TBloomFilterType.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TCellVisibility.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumn.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumnFamilyDescriptor.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumnIncrement.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumnValue.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TCompareOperator.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TCompressionAlgorithm.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TConsistency.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TDataBlockEncoding.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TDelete.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TDeleteType.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TDurability.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TGet.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.THBaseService.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.THRegionInfo.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.THRegionLocation.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIllegalArgument.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIncrement.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIOError.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TKeepDeletedCells.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TMutation.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TNamespaceDescriptor.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TPut.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TReadType.java</file>
    </fixedFiles>
  </bug>
  <bug id="23938" opendate="2020-3-5 00:00:00" fixdate="2020-5-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replicate slow/large RPC calls to HDFS</summary>
      <description>We should provide capability to replicate complete slow and large RPC logs to HDFS or create new system table in addition to Ring Buffer. This way we don't lose any of slow logs and operator can retrieve all the slow/large logs. Replicating logs to HDFS / creating new system table should be configurable.</description>
      <version>3.0.0-alpha-1,2.3.0,1.7.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.slowlog.TestSlowLogRecorder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.slowlog.SlowLogRecorder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.slowlog.RpcLogDetails.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.slowlog.LogEventHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="23957" opendate="2020-3-10 00:00:00" fixdate="2020-5-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[flakey test] client.TestMultiParallel fails to read hbase-site.xml</summary>
      <description>Saw this on a PreCommit run.Log file says2020-03-09 22:48:26,295 FATAL [Time-limited test] conf.Configuration(2853): error parsing conf hbase-site.xmljava.io.FileNotFoundException: /home/jenkins/jenkins-slave/workspace/Base-PreCommit-GitHub-PR_PR-1258@2/yetus-jdk8-hadoop2-check/src/hbase-server/target/test-classes/hbase-site.xml (No such file or directory) at java.io.FileInputStream.open0(Native Method) at java.io.FileInputStream.open(FileInputStream.java:195) at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:138) at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:93) at sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:90) at sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:188) at org.apache.hadoop.conf.Configuration.parse(Configuration.java:2672) at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:2746) at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:2706) at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2579) at org.apache.hadoop.conf.Configuration.get(Configuration.java:1091) at org.apache.hadoop.conf.Configuration.getTrimmed(Configuration.java:1145) at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2363) at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2793) at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2810) at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:100) at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2849) at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2831) at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:389) at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:181) at org.apache.hadoop.hbase.fs.HFileSystem.&lt;init&gt;(HFileSystem.java:85) at org.apache.hadoop.hbase.fs.HFileSystem.get(HFileSystem.java:465) at org.apache.hadoop.hbase.HBaseTestingUtility.getTestFileSystem(HBaseTestingUtility.java:3180) at org.apache.hadoop.hbase.HBaseTestingUtility.getNewDataTestDirOnTestFS(HBaseTestingUtility.java:507) at org.apache.hadoop.hbase.HBaseTestingUtility.setupDataTestDirOnTestFS(HBaseTestingUtility.java:496) at org.apache.hadoop.hbase.HBaseTestingUtility.getDataTestDirOnTestFS(HBaseTestingUtility.java:469) at org.apache.hadoop.hbase.HBaseTestingUtility.getDataTestDirOnTestFS(HBaseTestingUtility.java:483) at org.apache.hadoop.hbase.HBaseTestingUtility.createDirsAndSetProperties(HBaseTestingUtility.java:651) at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:603) at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:586) at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:1039) at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:1004) at org.apache.hadoop.hbase.client.TestMultiParallel.beforeClass(TestMultiParallel.java:96)This stage ran on H9.</description>
      <version>2.3.0,1.4.13,2.2.4</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,1.7.0,2.2.5</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.resources.hbase-site2.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestUpdateConfiguration.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncClusterAdminApi.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncAdminBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="23975" opendate="2020-3-12 00:00:00" fixdate="2020-3-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make hbase-rest use our shaded protobuf</summary>
      <description>This is a strange one, we also use protobuf in hbase-rest and it is a non shaded version...</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.TestScannersWithLabels.java</file>
      <file type="M">hbase-rest.src.main.protobuf.VersionMessage.proto</file>
      <file type="M">hbase-rest.src.main.protobuf.TableSchemaMessage.proto</file>
      <file type="M">hbase-rest.src.main.protobuf.TableListMessage.proto</file>
      <file type="M">hbase-rest.src.main.protobuf.TableInfoMessage.proto</file>
      <file type="M">hbase-rest.src.main.protobuf.StorageClusterStatusMessage.proto</file>
      <file type="M">hbase-rest.src.main.protobuf.ScannerMessage.proto</file>
      <file type="M">hbase-rest.src.main.protobuf.NamespacesMessage.proto</file>
      <file type="M">hbase-rest.src.main.protobuf.NamespacePropertiesMessage.proto</file>
      <file type="M">hbase-rest.src.main.protobuf.ColumnSchemaMessage.proto</file>
      <file type="M">hbase-rest.src.main.protobuf.CellSetMessage.proto</file>
      <file type="M">hbase-rest.src.main.protobuf.CellMessage.proto</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.VersionModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.TableSchemaModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.TableListModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.TableInfoModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.StorageClusterStatusModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.ScannerModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.NamespacesModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.NamespacesInstanceModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.CellSetModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.CellModel.java</file>
      <file type="M">hbase-rest.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="23999" opendate="2020-3-17 00:00:00" fixdate="2020-3-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[flakey test] TestTableOutputFormatConnectionExhaust</summary>
      <description>Hit this during master startup sequence in the test.2020-03-16 23:40:37,298 ERROR [StoreOpener-1588230740-1] conf.Configuration(2980): error parsing conf hbase-site.xmlcom.ctc.wstx.exc.WstxEOFException: Unexpected EOF in prolog at [row,col,system-id]: [1,0,"file:/home/vagrant/repos/hbase/hbase-mapreduce/target/test-classes/hbase-site.xml"] at com.ctc.wstx.sr.StreamScanner.throwUnexpectedEOF(StreamScanner.java:687) at com.ctc.wstx.sr.BasicStreamReader.handleEOF(BasicStreamReader.java:2220) at com.ctc.wstx.sr.BasicStreamReader.nextFromProlog(BasicStreamReader.java:2126) at com.ctc.wstx.sr.BasicStreamReader.next(BasicStreamReader.java:1181) at org.apache.hadoop.conf.Configuration$Parser.parseNext(Configuration.java:3277) at org.apache.hadoop.conf.Configuration$Parser.parse(Configuration.java:3071) at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:2964) at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:2930) at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2805) at org.apache.hadoop.conf.Configuration.get(Configuration.java:1199) at org.apache.hadoop.conf.Configuration.getTrimmed(Configuration.java:1253) at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1659) at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:70) at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:84) at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:98) at org.apache.hadoop.hbase.io.crypto.Context.&lt;init&gt;(Context.java:44) at org.apache.hadoop.hbase.io.crypto.Encryption$Context.&lt;init&gt;(Encryption.java:64) at org.apache.hadoop.hbase.io.crypto.Encryption$Context.&lt;clinit&gt;(Encryption.java:61) at org.apache.hadoop.hbase.regionserver.HStore.&lt;init&gt;(HStore.java:228) at org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:5890) at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1096) at org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1093) at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) at java.base/java.lang.Thread.run(Thread.java:834)2020-03-16 23:40:37,301 ERROR [master/bionic:0:becomeActiveMaster] regionserver.HRegion(1137): Could not initialize all stores for the region=hbase:meta,,1.1588230740Looking at the file under target/test-classes, it looks like this is a file written by YARN.&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;&lt;configuration&gt;&lt;property&gt;&lt;name&gt;yarn.log-aggregation.file-formats&lt;/name&gt;&lt;value&gt;TFile&lt;/value&gt;&lt;final&gt;false&lt;/final&gt;&lt;source&gt;yarn-default.xml&lt;/source&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;hbase.master.mob.ttl.cleaner.period&lt;/name&gt;&lt;value&gt;86400&lt;/value&gt;&lt;final&gt;false&lt;/final&gt;&lt;source&gt;hbase-default.xml&lt;/source&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;dfs.namenode.resource.check.interval&lt;/name&gt;&lt;value&gt;5000&lt;/value&gt;&lt;final&gt;false&lt;/final&gt;&lt;source&gt;hdfs-default.xml&lt;/source&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;mapreduce.jobhistory.client.thread-count&lt;/name&gt;&lt;value&gt;10&lt;/value&gt;&lt;final&gt;false&lt;/final&gt;&lt;source&gt;mapred-default.xml&lt;/source&gt;&lt;/property&gt;...My guess is that we have something in the MR framework unconfigured, it's writing these temporary job files to some default (like the first class path location or something??) and parallel test runs are stomping on each other.</description>
      <version>2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.5</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompactionTool.java</file>
    </fixedFiles>
  </bug>
  <bug id="2400" opendate="2010-4-1 00:00:00" fixdate="2010-6-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>new connector for Avro RPC access to HBase cluster</summary>
      <description>Build a new connector contrib architecturally equivalent to the Thrift connector, but using Avro serialization and associated transport and RPC server work. Support AAA (audit, authentication, authorization).</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug id="24002" opendate="2020-3-17 00:00:00" fixdate="2020-3-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>shadedjars check does not propagate --hadoop-profile</summary>
      <description>After HBASE-23829, we see the shadedjars check fail on JDK11 stages. From the logTue Mar 17 00:14:24 UTC 2020cd /home/jenkins/jenkins-slave/workspace/Base-PreCommit-GitHub-PR_PR-1296/yetus-jdk11-hadoop3-check/src/opt/maven/bin/mvn --batch-mode -Dmaven.repo.local=/home/jenkins/jenkins-slave/workspace/Base-PreCommit-GitHub-PR_PR-1296/yetus-m2/hbase-branch-2-patch-1 clean verify -fae --batch-mode -pl hbase-shaded/hbase-shaded-check-invariants -am -Dtest=NoUnitTests -DHBasePatchProcess -Prelease -Dmaven.javadoc.skip=true -Dcheckstyle.skip=true -Dspotbugs.skip=true...[INFO] --- maven-enforcer-plugin:3.0.0-M2:enforce (hadoop3-profile-required) @ hbase ---[INFO] Adding ignore: module-info[WARNING] Rule 0: org.apache.maven.plugins.enforcer.RequireProperty failed with message:HBase with JDK11 requires Hadoop3. Activate the profile with `-Dhadoop.profile=3.0`.</description>
      <version>3.0.0-alpha-1,2.3.0,2.4.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  <bug id="24004" opendate="2020-3-17 00:00:00" fixdate="2020-3-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Include hadoop version in Nightly report name</summary>
      <description>A minor thing I missed in HBASE-23876. Have this report name match the other "JDKX, HadoopY" report names.</description>
      <version>3.0.0-alpha-1,2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  <bug id="24007" opendate="2020-3-17 00:00:00" fixdate="2020-3-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Get `-PrunLargeTests` passing on JDK11</summary>
      <description>Build on HBASE-23829 and HBASE-24006, now looking at large tests.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="24016" opendate="2020-3-18 00:00:00" fixdate="2020-3-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change nightly poll from cron @daily to pollSCM @daily; i.e. run nightly if a change ONLY</summary>
      <description>Change build on branch-1.3, 1.4, 2.1, and feature branches HBASE-23162-branch-1 and HBASE-22114-branch-1 to be pollSCM @daily &amp;#8211; i.e. poll once a day and if change run nightly &amp;#8211; rather than build every night regardless.See https://lists.apache.org/thread.html/r5dca2cacc123f2e5719c622add6853ac62b56b2a77885fe0b2eb53c3%40%3Cdev.hbase.apache.org%3E for dev list discussion on downing our nightly load.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,1.3.7,1.7.0,2.1.10,1.4.14,2.2.5</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  <bug id="24057" opendate="2020-3-26 00:00:00" fixdate="2020-3-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add modules to mapreduce job classpaths</summary>
      <description>Modularization of hbase-server introduced new top-level modules that are missing from MapReduce jobs' classpath.CompactionTool job in MapReduce mode required ReplicationUtils class which is moved to the hbase-replication module.</description>
      <version>3.0.0-alpha-1,2.3.0,2.4.0,2.1.10,2.2.5</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.1.10,2.2.5</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="2406" opendate="2010-4-3 00:00:00" fixdate="2010-10-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Define semantics of cell timestamps/versions</summary>
      <description>There is a lot of general confusion over the semantics of the cell timestamp. In particular, a couple questions that often come up: If multiple writes to a cell have the same timestamp, are all versions maintained or just the last? Is it OK to write cells in a non-increasing timestamp order?Let's discuss, figure out what semantics make sense, and then move towards (a) documentation, (b) unit tests that prove we have those semantics.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.site.xml</file>
      <file type="M">src.docbkx.sample.article.xml</file>
      <file type="M">pom.xml</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="24062" opendate="2020-3-26 00:00:00" fixdate="2020-4-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add 2.1.10 to download page</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.downloads.xml</file>
    </fixedFiles>
  </bug>
  <bug id="24071" opendate="2020-3-27 00:00:00" fixdate="2020-4-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[JDK11] Remove `unit` filter from nightly and precommit jobs</summary>
      <description>Added in HBASE-23946, we can remove this filter once HBASE-24007 lands.</description>
      <version>3.0.0-alpha-1,2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile.GitHub</file>
      <file type="M">dev-support.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  <bug id="24092" opendate="2020-3-31 00:00:00" fixdate="2020-4-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix links to build reports generated by nightly job</summary>
      <description>Links going back to JIRA look likeFor more information [see jdk8 (hadoop2) report|https://builds.apache.org/job/HBase%20Nightly/job/branch-2/2574//JDK8_Nightly_Build_Report_(Hadoop2)/]But the actual URL to this report is https://builds.apache.org/job/HBase%20Nightly/job/branch-2/2574/JDK8_20Nightly_20Build_20Report_20_28Hadoop2_29/</description>
      <version>3.0.0-alpha-1,2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  <bug id="24105" opendate="2020-4-2 00:00:00" fixdate="2020-4-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[Flakey Test] regionserver.TestRegionReplicas</summary>
      <description>There are 3 failed runs from flakey test board.org.apache.hadoop.hbase.regionserver.TestRegionReplicas.testFlushAndCompactionsInPrimaryFailing for the past 1 build (Since #5954 )Took 45 sec.Error Messageexpected null, but was:&lt;org.apache.hadoop.hbase.NotServingRegionException: TestRegionReplicas,,1585782621571_0001.0896d89824217690d8a4b391bb139962. is not online on asf905.gq1.ygridcore.net,37761,1585782616299&gt;Stacktracejava.lang.AssertionError: expected null, but was:&lt;org.apache.hadoop.hbase.NotServingRegionException: TestRegionReplicas,,1585782621571_0001.0896d89824217690d8a4b391bb139962. is not online on asf905.gq1.ygridcore.net,37761,1585782616299&gt; at org.apache.hadoop.hbase.regionserver.TestRegionReplicas.testFlushAndCompactionsInPrimary(TestRegionReplicas.java:432)Standard OutputFormatting using clusterid: testClusterIDjava.lang.ThreadGroup[name=PEWorkerGroup,maxpri=10] Thread[HFileArchiver-3,5,PEWorkerGroup] Thread[HFileArchiver-4,5,PEWorkerGroup]Standard Error</description>
      <version>2.3.0,2.4.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="24112" opendate="2020-4-3 00:00:00" fixdate="2020-4-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[RSGroup] Support renaming rsgroup</summary>
      <description>Rsgroup name once is decided at the beginning, it is difficult to rename it.Current approach is removing all tables and servers back to default rsgroup, then delete it and add a rsgroup with the new name, after that moving regions and servers back. Or without moving back, if machine resources is ample. Anyway, it is an expensive operation: moving regions, breaking region's locality.And given that rsgroup is one kind of managements in cluster, and management sometimes changes, renaming is necessary.It is simple in implementation. I'm working on it.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,1.7.0,2.2.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.client.ThriftAdmin.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rsgroup.VerifyingRSGroupAdmin.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rsgroup.TestRSGroupsAdmin1.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupInfoManagerImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupInfoManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupAdminServiceImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rsgroup.DisabledRSGroupInfoManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MasterObserver.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.server.rsgroup.RSGroupAdmin.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.server.master.Master.proto</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AdminOverAsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
    </fixedFiles>
  </bug>
  <bug id="24113" opendate="2020-4-3 00:00:00" fixdate="2020-4-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade the maven we use from 3.5.4 to 3.6.3 in nightlies</summary>
      <description>I want to up parallelism of nightlies and hopefully improve stability. Lets use latest maven, go from 3.5.4 to 3.6.3.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">dev-support.hbase.docker.Dockerfile</file>
      <file type="M">dev-support.docker.Dockerfile</file>
    </fixedFiles>
  </bug>
  <bug id="24115" opendate="2020-4-4 00:00:00" fixdate="2020-5-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Relocate test-only REST "client" from src/ to test/ and mark Private</summary>
      <description>Relocate test-only REST "client" from src/ to test/ and annotate as Private. The classes o.a.h.h.rest.Remote* were developed to facilitate REST unit tests and incorrectly committed to src/ . Although this "breaks" compatibility by moving public classes to test jar and marking them private, no attention has been paid to these classes with respect to performance, convenience, or security. Consensus from various discussions over the years is to move them to test/ as was intent of the original committer, but misplaced by the same individual.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,1.3.7,1.7.0,2.1.10,1.4.14,2.2.5</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteAdmin.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.rest.RESTDemoClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="24119" opendate="2020-4-6 00:00:00" fixdate="2020-4-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Polish the protobuf usage in hbase-examples</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.server.coprocessor.examples.RowCount.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.server.coprocessor.examples.RefreshHFiles.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.server.coprocessor.examples.BulkDelete.proto</file>
      <file type="M">hbase-protocol-shaded.pom.xml</file>
      <file type="M">hbase-examples.src.test.java.org.apache.hadoop.hbase.types.TestPBCell.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.types.PBType.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.types.PBCell.java</file>
      <file type="M">hbase-examples.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="2412" opendate="2010-4-6 00:00:00" fixdate="2010-4-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[stargate] PerformanceEvaluation</summary>
      <description>A version of PE that works with Stargate. Patch includes a number of fixes for multiuser mode and the client library also.</description>
      <version>None</version>
      <fixedVersion>0.20.4,0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">contrib.stargate.core.src.main.java.org.apache.hadoop.hbase.stargate.util.UserData.java</file>
      <file type="M">contrib.stargate.core.src.main.java.org.apache.hadoop.hbase.stargate.util.HTableTokenBucket.java</file>
      <file type="M">contrib.stargate.core.src.main.java.org.apache.hadoop.hbase.stargate.User.java</file>
      <file type="M">contrib.stargate.core.src.main.java.org.apache.hadoop.hbase.stargate.TableResource.java</file>
      <file type="M">contrib.stargate.core.src.main.java.org.apache.hadoop.hbase.stargate.StorageClusterStatusResource.java</file>
      <file type="M">contrib.stargate.core.src.main.java.org.apache.hadoop.hbase.stargate.SchemaResource.java</file>
      <file type="M">contrib.stargate.core.src.main.java.org.apache.hadoop.hbase.stargate.ScannerResource.java</file>
      <file type="M">contrib.stargate.core.src.main.java.org.apache.hadoop.hbase.stargate.RowResource.java</file>
      <file type="M">contrib.stargate.core.src.main.java.org.apache.hadoop.hbase.stargate.RootResource.java</file>
      <file type="M">contrib.stargate.core.src.main.java.org.apache.hadoop.hbase.stargate.RESTServlet.java</file>
      <file type="M">contrib.stargate.core.src.main.java.org.apache.hadoop.hbase.stargate.RegionsResource.java</file>
      <file type="M">contrib.stargate.core.src.main.java.org.apache.hadoop.hbase.stargate.model.TableSchemaModel.java</file>
      <file type="M">contrib.stargate.core.src.main.java.org.apache.hadoop.hbase.stargate.model.TableRegionModel.java</file>
      <file type="M">contrib.stargate.core.src.main.java.org.apache.hadoop.hbase.stargate.Main.java</file>
      <file type="M">contrib.stargate.core.src.main.java.org.apache.hadoop.hbase.stargate.client.RemoteHTable.java</file>
      <file type="M">contrib.stargate.core.src.main.java.org.apache.hadoop.hbase.stargate.client.Cluster.java</file>
      <file type="M">contrib.stargate.core.src.main.java.org.apache.hadoop.hbase.stargate.client.Client.java</file>
      <file type="M">contrib.stargate.core.pom.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="24121" opendate="2020-4-6 00:00:00" fixdate="2020-4-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[Authorization] ServiceAuthorizationManager isn&amp;#39;t dynamically updatable. And it should be.</summary>
      <description>Some more background information.ServiceAuthorizationManager is responsible for the Services access rights defined in hbase-policy.xml which locates under $hbase_home/conf directory.Currently, since it doesn't support update dynamically, we need to restart master/regionservers to make configurations take effect. It is an expensive and low efficient admin operation.HDFS has the refreshPolicy to do that, HBase also has update_config command, we can make use of that.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,1.7.0,1.4.14,2.2.5</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="24122" opendate="2020-4-6 00:00:00" fixdate="2020-4-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change machine ulimit-l to ulimit-a so dumps full ulimit rather than just &amp;#39;max locked memory&amp;#39;</summary>
      <description>Dump out full ulimit list under the machine dir job output rather than one-liner. More utility.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.5</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.gather.machine.environment.sh</file>
    </fixedFiles>
  </bug>
  <bug id="24143" opendate="2020-4-8 00:00:00" fixdate="2020-4-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[JDK11] Switch default garbage collector from CMS</summary>
      <description>When running HBase tools on the cli, one of the warnings generated isOpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.Java9+ use G1GC as the default collector. Maybe we simply omit GC configurations and use the default settings? Or someone has some suggested settings we can ship out of the box?</description>
      <version>3.0.0-alpha-1,2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.hbase-env.sh</file>
      <file type="M">bin.hbase-config.sh</file>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug id="24185" opendate="2020-4-14 00:00:00" fixdate="2020-4-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Junit tests do not behave well with System.exit or Runtime.halt or JVM exits in general.</summary>
      <description>This ends up exiting the JVM and confusing / erroring out the test runner that manages that JVM as well as cutting off test output files.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.HBaseClassTestRule.java</file>
    </fixedFiles>
  </bug>
  <bug id="24221" opendate="2020-4-21 00:00:00" fixdate="2020-6-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support bulkLoadHFile by family</summary>
      <description>Support bulkLoadHFile by family to avoid long time waiting of bulkLoadHFile because of compacting at server side</description>
      <version>3.0.0-alpha-1,2.3.0,2.2.4</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.tool.TestBulkLoadHFilesByFamily.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.tool.TestBulkLoadHFiles.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.BulkLoadHFilesTool.java</file>
    </fixedFiles>
  </bug>
  <bug id="24226" opendate="2020-4-21 00:00:00" fixdate="2020-1-21 01:00:00" resolution="Unresolved">
    <buginformation>
      <summary>Address other hard references to &amp;#39;/tmp&amp;#39; found in Configuration</summary>
      <description>HBASE-24175 started up cleaning hard /tmp references out of Configuration when tests run. I got most of them but then if its hadoop2 or hadoop3 or jenkins or local, the list seems to change. Here are more...</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.snapshot.TestExportSnapshotAdjunct.java</file>
    </fixedFiles>
  </bug>
  <bug id="24256" opendate="2020-4-24 00:00:00" fixdate="2020-5-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>When fixOverlap hits the max region limit, it is possible to include the same region in multiple merge request</summary>
      <description>If the same region is included in multiple merge requests, the first merge cleans up the region state, the second merge request will fail with error msg "No state for region ****". The algo needs to be improved to make sure the same region is not included in multi merge requests.</description>
      <version>3.0.0-alpha-1,2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMetaFixer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MetaFixer.java</file>
    </fixedFiles>
  </bug>
  <bug id="24258" opendate="2020-4-24 00:00:00" fixdate="2020-5-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[Hadoop3.3] Update license for org.ow2.asm:*</summary>
      <description>Hadoop 3.3 brings a few Jetty dependencies which transitively brings in org.ow2.asm:asm-analysis, org.ow2.asm:asm-commons, org.ow2.asm:asm-tree.When testing with the latest Jetty (9.4.26.v20200117) I found its org.ow2.asm:* updated from 7.1 to 7.2, which changed the declared license from "BSD" to "BSD-3-Clause License" (The actual license text did not change). The HBase's license checker doesn't accept it.File the jira to update it to "BSD 3-Clause License" so that HBase can build.[INFO] | | | +- org.eclipse.jetty.websocket:javax-websocket-server-impl:jar:9.4.26.v20200117:test[INFO] | | | | +- org.eclipse.jetty:jetty-annotations:jar:9.4.26.v20200117:test[INFO] | | | | | +- org.eclipse.jetty:jetty-plus:jar:9.4.26.v20200117:test[INFO] | | | | | | \- org.eclipse.jetty:jetty-jndi:jar:9.4.26.v20200117:test[INFO] | | | | | \- org.ow2.asm:asm-commons:jar:7.2:test[INFO] | | | | | +- org.ow2.asm:asm-tree:jar:7.2:test[INFO] | | | | | \- org.ow2.asm:asm-analysis:jar:7.2:testThis product includes asm-analysis licensed under the BSD-3-Clause.ERROR: Please check ^^^^^^^^^^^^ this License for acceptability here:https://www.apache.org/legal/resolvedIf it is okay, then update the list named 'non_aggregate_fine' in the LICENSE.vm file.If it isn't okay, then revert the change that added the dependency.More info on the dependency:&lt;groupId&gt;org.ow2.asm&lt;/groupId&gt;&lt;artifactId&gt;asm-analysis&lt;/artifactId&gt;&lt;version&gt;7.2&lt;/version&gt;</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.5</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-resource-bundle.src.main.resources.supplemental-models.xml</file>
    </fixedFiles>
  </bug>
  <bug id="24261" opendate="2020-4-24 00:00:00" fixdate="2020-5-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Redo all of our github notification integrations on new ASF infra feature</summary>
      <description>The new ASF Infra feature for customizing how project gets notifications from github appears to have silently thrown away all the integration we already had set up.I don't know that full set of things we need. We presumably need to do this for all of our repos. make sure all notifications on PRs is going to issues@ make sure we get links on JIRA for related PRs make sure we do not get updates on JIRA for every PR comment</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">.asf.yaml</file>
    </fixedFiles>
  </bug>
  <bug id="24263" opendate="2020-4-26 00:00:00" fixdate="2020-4-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestDelegationToken is broken</summary>
      <description>After reverting HBASE-23881, it is fine.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.NettyHBaseSaslRpcClientHandler.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.AbstractHBaseSaslRpcClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="24264" opendate="2020-4-26 00:00:00" fixdate="2020-4-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Disable TestNettyIPC.testHedgedAsyncEcho</summary>
      <description>It is flaky and cause the flaky job time out.Disable it for now, and re-enable it in the sub task.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.AbstractTestIPC.java</file>
    </fixedFiles>
  </bug>
  <bug id="24265" opendate="2020-4-26 00:00:00" fixdate="2020-5-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove hedged rpc call support, implement the logic in MaterRegistry directly</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestRpcClientLeaks.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestProtobufRpcServiceImpl.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.AbstractTestIPC.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannersFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMasterRegistry.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestClientTimeouts.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.FromClientSideBase.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.NettyRpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.HedgedRpcChannel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.AbstractRpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.MasterRegistryFetchException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MasterRegistry.java</file>
    </fixedFiles>
  </bug>
  <bug id="24266" opendate="2020-4-27 00:00:00" fixdate="2020-5-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document of Hbase on Aarch64</summary>
      <description>Provide documentation on how to run hbase on aarch64 architecture.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="24296" opendate="2020-5-1 00:00:00" fixdate="2020-5-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>install yetus as a part of building the rm docker image.</summary>
      <description>right now we have to download yetus on each release run. we should be able to point at a local install instead.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.create-release.release-util.sh</file>
      <file type="M">dev-support.create-release.release-build.sh</file>
      <file type="M">dev-support.create-release.hbase-rm.Dockerfile</file>
      <file type="M">dev-support.create-release.do-release.sh</file>
      <file type="M">dev-support.create-release.do-release-docker.sh</file>
    </fixedFiles>
  </bug>
  <bug id="24297" opendate="2020-5-1 00:00:00" fixdate="2020-5-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>release scripts should be able to use a custom git repo</summary>
      <description>doing a full new clone is expensive, especially for the main repo. we should be able to optionally point at an existing clone.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.create-release.release-util.sh</file>
      <file type="M">dev-support.create-release.release-build.sh</file>
      <file type="M">dev-support.create-release.do-release-docker.sh</file>
    </fixedFiles>
  </bug>
  <bug id="24303" opendate="2020-5-1 00:00:00" fixdate="2020-5-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Undo core of parent TestSecureRESTServer change; use fix over in HBASE-24280 instead</summary>
      <description>Parent issue puts in a place that makes TestSecureRESTServer pass up on jenkins by shoving into the dependency list the jersey1 ServletContainer. Root issue was change in how we specified profiles in nightlies; both hadoop3 and hadoop2 were mistakenly active (HBASE-24280). This issue is about undoing the dependency insertion after fix for HBASE-24280 goes in.Don't want to revert the parent. It has cleanups that should stay.</description>
      <version>3.0.0-alpha-1,2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-rest.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="24304" opendate="2020-5-2 00:00:00" fixdate="2020-5-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Separate a hbase-asyncfs module</summary>
      <description>To hold the async fs related class for WAL implementation as the hbase-server module is too big.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-thrift.pom.xml</file>
      <file type="M">hbase-testing-util.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-testing-util.pom.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestWALFactory.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestFSUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestFSHDFSUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.HBaseKerberosUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRolling.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.asyncfs.TestSendBufSizePredictor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.asyncfs.TestSaslFanOutOneBlockAsyncDFSOutput.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.asyncfs.TestOverwriteFileUnderConstruction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.asyncfs.TestLocalAsyncOutput.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.asyncfs.TestFanOutOneBlockAsyncDFSOutput.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.AbstractFSWALProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.CancelableProgressable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.WALEntryStream.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplaySyncReplicationWALCallable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.asyncfs.WrapperAsyncFSOutput.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.asyncfs.SendBufSizePredictor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.asyncfs.ProtobufDecoder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputSaslHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutput.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.asyncfs.AsyncFSOutputHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.asyncfs.AsyncFSOutput.java</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-rest.pom.xml</file>
      <file type="M">hbase-mapreduce.pom.xml</file>
      <file type="M">hbase-examples.pom.xml</file>
      <file type="M">hbase-endpoint.pom.xml</file>
      <file type="M">hbase-assembly.src.main.assembly.hadoop-three-compat.xml</file>
      <file type="M">hbase-assembly.src.main.assembly.components.xml</file>
      <file type="M">hbase-assembly.src.main.assembly.client-components.xml</file>
    </fixedFiles>
  </bug>
  <bug id="24343" opendate="2020-5-8 00:00:00" fixdate="2020-5-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document how to configure the http request log</summary>
      <description></description>
      <version>2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.log4j.properties</file>
    </fixedFiles>
  </bug>
  <bug id="24345" opendate="2020-5-8 00:00:00" fixdate="2020-5-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[ACL] renameRSGroup should require Admin level permission</summary>
      <description>Currently renameRSgroup can be called by anyone without permission</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,1.7.0,2.2.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rsgroup.TestRSGroupsWithACL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rsgroup.TestRSGroupsBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug id="24428" opendate="2020-5-25 00:00:00" fixdate="2020-5-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Priority compaction for recently split daughter regions</summary>
      <description>We observe that under hotspotting conditions that splitting will proceed very slowly and the "Cannot split region due to reference files being there" log line will be logged excessively. (branch-1 based production.) This is because after a region is split it must be compacted before it can be split again. Reference files must be replaced by real HFiles, normal housekeeping performed during compaction. However if the regionserver is under excessive load, its compaction queues may become deep. The daughters of a recently split hotspotting region may themselves continue to hotspot and will rapidly need to split again. If the scheduled compaction work to remove/replace reference files is queued hundreds or thousands of compaction queue elements behind current, the recently split daughter regions will not be able to split again for a long time and may grow very large, producing additional complications (very large regions, very deep replication queues).To help avoid this condition we should prioritize the compaction of recently split daughter regions. Compaction requests include a priority field and CompactionRequest implements a comparator that sorts by this field. We already detect when a compaction request involves a region that has reference files, to ensure that it gets selected to be eligible for compaction, but we do not seem to prioritize the requests for post-split housekeeping. Split work should be placed at the top of the queue. Ensure that this is happening.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,1.7.0,2.2.6</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.SortedCompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionRequestImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="2448" opendate="2010-4-14 00:00:00" fixdate="2010-4-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scanner threads are interrupted without acquiring lock properly</summary>
      <description>There are a few places where scanner threads are interrupted with .interrupt() instead of .interruptIfAlive(). This means that if they're in the midst of the checkFileSystem operation, it'll end up catching the interruption there, determine that the filesystem is down, and shut down the whole server. Other nasties can also result.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.Sleeper.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.RegionManager.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.ProcessRegionOpen.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.ModifyTableMeta.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.BaseScanner.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.Chore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="24506" opendate="2020-6-5 00:00:00" fixdate="2020-6-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>async client deadlock</summary>
      <description>I ran into an issue where one instance in a cluster of application servers backed by HBase stopped processing requests. Looking at a thread dump, it seems HBase client threads are deadlocked:https://pastebin.com/raw/B3FJL1AgThe deadlock seemed to happen at the same time that a region server was abruptly stopped (the physical server was restarted unexpectedly).I'm using the hbase async API. The hbase client version is 2.2.4. The server is running 2.2.4 as well.</description>
      <version>3.0.0-alpha-1,2.3.0,2.2.4,2.4.0,2.2.5</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.ipc.TestNettyRpcConnection.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTableGetMultiThreaded.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.ipc.TestIPCUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.NettyRpcConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.IPCUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="2453" opendate="2010-4-15 00:00:00" fixdate="2010-4-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Revisit compaction policies after HBASE-2248 commit</summary>
      <description>HBASE-2248 turned Gets into Scans server-side. It also removed the invariant that deletes in a file only apply to other files and not itself (no longer processes MemStore deletes when the delete happens). This has implications for our minor compaction policy.We are currently processing deletes during minor compactions in a way that makes it so we do the actual deleting as we compact, but we retain the delete records themselves. This makes it so we retain the invariant of deletes only applying to other files.Since this is now gone post HBASE-2248, we should revisit our compaction policies.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.TestMinorCompactingStoreScanner.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.MinorCompactingStoreScanner.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="24535" opendate="2020-6-10 00:00:00" fixdate="2020-6-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Tweak the master registry docs for branch-2</summary>
      <description>As Nick pointed out in https://github.com/apache/hbase/pull/1880, we need to re-word the content a bit so that it makes sense to branch-2 users. Specifically the following What version has the feature shipped A slight modification to the config keys after hedging moved from rpc layer to the registry code (HBASE-24265)The latter applies to the master branch too.</description>
      <version>2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="24547" opendate="2020-6-12 00:00:00" fixdate="2020-6-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thrift support for HBASE-23941</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift2.TestThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-thrift.src.main.resources.org.apache.hadoop.hbase.thrift2.hbase.thrift</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftUtilities.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TTimeRange.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TThriftServerType.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TTableName.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TTableDescriptor.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TServerName.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TScan.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TRowMutations.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TResult.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TReadType.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TPut.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TOnlineLogRecord.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TNamespaceDescriptor.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TMutation.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TLogType.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TLogQueryFilter.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TKeepDeletedCells.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIOError.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIncrement.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIllegalArgument.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.THRegionLocation.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.THRegionInfo.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.THBaseService.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TGet.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TDurability.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TDeleteType.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TDelete.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TDataBlockEncoding.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TConsistency.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TCompressionAlgorithm.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TCompareOperator.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumnValue.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumnIncrement.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumnFamilyDescriptor.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumn.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TCellVisibility.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TBloomFilterType.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TAuthorization.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TAppend.java</file>
    </fixedFiles>
  </bug>
  <bug id="24562" opendate="2020-6-15 00:00:00" fixdate="2020-7-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Stabilize master startup with meta replicas enabled</summary>
      <description>This is related to HBASE-21624 . I created a separate ticket because in the original one a "complete solution for meta replicas" was requested and this is not one. I'm just trying to make master startup more stable by making assigning meta replicas asynchronous and preventing a potential assignment failure from crashing master.The idea is that starting master with less or even no meta replicas assigned is preferable to not having a running master.</description>
      <version>3.0.0-alpha-1,2.3.0,2.4.0,2.2.5</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.6</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMetaWithReplicas.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterMetaBootstrap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="24567" opendate="2020-6-15 00:00:00" fixdate="2020-6-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create release should url-encode all characters when building git uri</summary>
      <description>The release tool doesn't url encode all characters provided for ASF_USERNAME, ASF_PASSWORD.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.create-release.release-util.sh</file>
    </fixedFiles>
  </bug>
  <bug id="24603" opendate="2020-6-21 00:00:00" fixdate="2020-6-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Zookeeper sync() call is async</summary>
      <description>Here is the method that does a sync() of lagging followers with leader in the quorum. We rely on this to see a consistent snapshot of ZK data from multiple clients. However the problem is that the underlying sync() call is actually asynchronous since we are passing a 'null' call back. See the ZK API doc for details. The end-result is that sync() doesn't guarantee that it has happened by the time it returns. /** * Forces a synchronization of this ZooKeeper client connection. * &lt;p&gt; * Executing this method before running other methods will ensure that the * subsequent operations are up-to-date and consistent as of the time that * the sync is complete. * &lt;p&gt; * This is used for compareAndSwap type operations where we need to read the * data of an existing node and delete or transition that node, utilizing the * previously read version and data. We want to ensure that the version read * is up-to-date from when we begin the operation. */ public void sync(String path) throws KeeperException { this.recoverableZooKeeper.sync(path, null, null); }We rely on this heavily (at least in the older branches that do ZK based region assignment). In branch-1 we saw weird "BadVersionException" exceptions in RITs because of the inconsistent view of the ZK snapshot. It could manifest differently in other branches. Either way, this is something we need to fix.</description>
      <version>3.0.0-alpha-1,2.3.0,1.7.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,1.7.0,2.1.10,2.2.6</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-zookeeper.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKWatcher.java</file>
      <file type="M">hbase-zookeeper.src.main.java.org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.ZKVisibilityLabelWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.example.HFileArchiveManager.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Threads.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="24604" opendate="2020-6-21 00:00:00" fixdate="2020-6-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove the stable-1 notice on our download page</summary>
      <description>We have already removed it from our dist release directory.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.downloads.xml</file>
    </fixedFiles>
  </bug>
  <bug id="24630" opendate="2020-6-24 00:00:00" fixdate="2020-6-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Purge dev javadoc from client bin tarball</summary>
      <description>For 2.0, the decision was made to exclude the bulky "developer" api docs from the binary artifacts, via HBASE-20149. This change needs applied to the client tarball as well.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.1.10,2.2.6</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-assembly.src.main.assembly.client-components.xml</file>
    </fixedFiles>
  </bug>
  <bug id="2468" opendate="2010-4-19 00:00:00" fixdate="2010-6-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improvements to prewarm META cache on clients</summary>
      <description>A couple different use cases cause storms of reads to META during startup. For example, a large MR job will cause each map task to hit meta since it starts with an empty cache.A couple possible improvements have been proposed: MR jobs could ship a copy of META for the table in the DistributedCache Clients could prewarm cache by doing a large scan of all the meta for the table instead of random reads for each miss Each miss could fetch ahead some number of rows in META</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.MetaScanner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnection.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2471" opendate="2010-4-20 00:00:00" fixdate="2010-11-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Splitting logs, we&amp;#39;ll make an output file though the region no longer exists</summary>
      <description>The "human unit tester" (Kannan) last night wondered what happens splitting logs and we come across an edit whose region has since been removed. Taking a look, it looks like we'll create the output file and write the edits for the no-longer-extant region anyways. This will leave litter in the filesystem &amp;#8211; region split files that will never be used nor removed. This issue is about verifying that indeed this is whats happening (We do SequenceFile.createWriter with the overwrite flag set to true which tracing seems to mean create all intermediary directories &amp;#8211; to be verified) and if it indeed is happening, fixing split so unless the region dir exists, don't write out edits.. just drop them.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLogSplit.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLog.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2473" opendate="2010-4-20 00:00:00" fixdate="2010-5-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add to admin create table start and end key params and desired number of regions</summary>
      <description>This would be an adornment on create table that pre-creates N regions in the new table. It came up yesterday at the hbase hackathon3.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.util.TestBytes.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.Bytes.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.ipc.HMasterInterface.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.ipc.HBaseRPCProtocolVersion.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>
