<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="11544" opendate="2014-7-18 00:00:00" fixdate="2014-4-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[Ergonomics] hbase.client.scanner.caching is dogged and will try to return batch even if it means OOME</summary>
      <description>Running some tests, I set hbase.client.scanner.caching=1000. Dataset has large cells. I kept OOME'ing.Serverside, we should measure how much we've accumulated and return to the client whatever we've gathered once we pass out a certain size threshold rather than keep accumulating till we OOME.</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestAcidGuarantees.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.TableSnapshotScanner.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Client.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ClientProtos.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ResponseConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Result.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ScannerContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.NoLimitScannerContext.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestMergeTool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestPartialResultsFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestWideScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStripeCompactor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.coprocessor.example.BulkDeleteEndpoint.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.coprocessor.example.RowCountEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ClientSideRegionScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.AggregateImplementation.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.Compactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.InternalScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.KeyValueHeap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlLists.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestIntraRowPagination.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestReplicasClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.ColumnAggregationEndpoint.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.ColumnAggregationEndpointNullResponse.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.ColumnAggregationEndpointWithErrors.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorInterface.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestColumnPrefixFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestDependentColumnFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestInvocationRecordFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestMultipleColumnPrefixFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestCase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestPrefixTree.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestScannerSelectionUsingKeyRange.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestScannerSelectionUsingTTL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.compactions.TestStripeCompactionPolicy.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestAtomicOperation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestBlocksScanned.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestColumnSeeking.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDefaultMemStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestGetClosestAtOrBefore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestKeepDeletes.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMajorCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMultiColumnScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionMergeTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestReversibleScanners.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestScanWithBloomError.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSeekOptimizations.java</file>
    </fixedFiles>
  </bug>
  <bug id="3925" opendate="2011-5-26 00:00:00" fixdate="2011-10-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make Shell&amp;#39;s -d and debug cmd behave the same</summary>
      <description>The -d option switches log4j to DEBUG and leaves the backtrace level at the default. When using the supplied debug command we only switch the backtrace, but I would think this also should set the log4j levels:# Debugging methoddef debug if @shell.debug @shell.debug = false conf.back_trace_limit = 0 else @shell.debug = true conf.back_trace_limit = 100 end debug?endcould be something like # Debugging methoddef debug if @shell.debug @shell.debug = false conf.back_trace_limit = 0 log_level = org.apache.log4j.Level::ERROR else @shell.debug = true conf.back_trace_limit = 100 log_level = org.apache.log4j.Level::DEBUG end org.apache.log4j.Logger.getLogger("org.apache.zookeeper").setLevel(log_level) org.apache.log4j.Logger.getLogger("org.apache.hadoop.hbase").setLevel(log_level) debug?end</description>
      <version>0.90.3,0.90.7,0.92.2,0.94.3,0.98.0,0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hirb.rb</file>
    </fixedFiles>
  </bug>
  <bug id="4379" opendate="2011-9-13 00:00:00" fixdate="2011-7-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbck] Does not complain about tables with no end region [Z,]</summary>
      <description>hbck does not detect or have an error condition when the last region of a table is missing (end key != '').</description>
      <version>0.90.5,0.92.0,0.94.0,0.95.2</version>
      <fixedVersion>0.92.2,0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.hbck.TableIntegrityErrorHandlerImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.hbck.TableIntegrityErrorHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="4676" opendate="2011-10-25 00:00:00" fixdate="2011-2-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Prefix Compression - Trie data block encoding</summary>
      <description>The HBase data block format has room for 2 significant improvements for applications that have high block cache hit ratios. First, there is no prefix compression, and the current KeyValue format is somewhat metadata heavy, so there can be tremendous memory bloat for many common data layouts, specifically those with long keys and short values.Second, there is no random access to KeyValues inside data blocks. This means that every time you double the datablock size, average seek time (or average cpu consumption) goes up by a factor of 2. The standard 64KB block size is ~10x slower for random seeks than a 4KB block size, but block sizes as small as 4KB cause problems elsewhere. Using block sizes of 256KB or 1MB or more may be more efficient from a disk access and block-cache perspective in many big-data applications, but doing so is infeasible from a random seek perspective.The PrefixTrie block encoding format attempts to solve both of these problems. Some features: trie format for row key encoding completely eliminates duplicate row keys and encodes similar row keys into a standard trie structure which also saves a lot of space the column family is currently stored once at the beginning of each block. this could easily be modified to allow multiple family names per block all qualifiers in the block are stored in their own trie format which caters nicely to wide rows. duplicate qualifers between rows are eliminated. the size of this trie determines the width of the block's qualifier fixed-width-int the minimum timestamp is stored at the beginning of the block, and deltas are calculated from that. the maximum delta determines the width of the block's timestamp fixed-width-intThe block is structured with metadata at the beginning, then a section for the row trie, then the column trie, then the timestamp deltas, and then then all the values. Most work is done in the row trie, where every leaf node (corresponding to a row) contains a list of offsets/references corresponding to the cells in that row. Each cell is fixed-width to enable binary searching and is represented by &amp;#91;1 byte operationType, X bytes qualifier offset, X bytes timestamp delta offset&amp;#93;.If all operation types are the same for a block, there will be zero per-cell overhead. Same for timestamps. Same for qualifiers when i get a chance. So, the compression aspect is very strong, but makes a few small sacrifices on VarInt size to enable faster binary searches in trie fan-out nodes.A more compressed but slower version might build on this by also applying further (suffix, etc) compression on the trie nodes at the cost of slower write speed. Even further compression could be obtained by using all VInts instead of FInts with a sacrifice on random seek speed (though not huge).One current drawback is the current write speed. While programmed with good constructs like TreeMaps, ByteBuffers, binary searches, etc, it's not programmed with the same level of optimization as the read path. Work will need to be done to optimize the data structures used for encoding and could probably show a 10x increase. It will still be slower than delta encoding, but with a much higher decode speed. I have not yet created a thorough benchmark for write speed nor sequential read speed.Though the trie is reaching a point where it is internally very efficient (probably within half or a quarter of its max read speed) the way that hbase currently uses it is far from optimal. The KeyValueScanner and related classes that iterate through the trie will eventually need to be smarter and have methods to do things like skipping to the next row of results without scanning every cell in between. When that is accomplished it will also allow much faster compactions because the full row key will not have to be compared as often as it is now.Current code is on github. The trie code is in a separate project than the slightly modified hbase. There is an hbase project there as well with the DeltaEncoding patch applied, and it builds on top of that.https://github.com/hotpads/hbase/tree/prefix-trie-1https://github.com/hotpads/hbase-prefix-trie/tree/hcell-scannersI'll follow up later with more implementation ideas.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestEncodedSeekers.java</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-common.src.main.java.org.apache.hbase.cell.CellOutputStream.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hbase.cell.CellComparator.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.test.RedundantKVGenerator.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Bytes.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteRangeTool.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.DataBlockEncoding.java</file>
    </fixedFiles>
  </bug>
  <bug id="4922" opendate="2011-12-1 00:00:00" fixdate="2011-12-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[packaging] Assembly tars up hbase in a subdir; i.e. after untar hbase-0.92.0 has a subdir named 0.92.0</summary>
      <description>Reported by Roman.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="4923" opendate="2011-12-1 00:00:00" fixdate="2011-8-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[packaging] Assembly should make only executables executable (docs should not be executable!)</summary>
      <description>Reported by Roman.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.assembly.all.xml</file>
    </fixedFiles>
  </bug>
  <bug id="5076" opendate="2011-12-20 00:00:00" fixdate="2011-8-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase shell hangs when creating some &amp;#39;illegal&amp;#39; tables.</summary>
      <description>In hbase shell. These commands hang:create 'hbase.version','foo'create 'splitlog','foo'Interestinglycreate 'hbase.id','foo'create existingtablename, 'foo'create '.META.','foo'create '-ROOT-','foo'are properly rejected.We should probably either rename to make the files illegal table names (hbase.version to .hbase.version and splitlog to .splitlog) or we could add more special cases.</description>
      <version>0.92.0,0.94.1,0.94.2,0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="5206" opendate="2012-1-16 00:00:00" fixdate="2012-3-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Port HBASE-5155 to 0.92, 0.94, and TRUNK</summary>
      <description>This JIRA ports HBASE-5155 (ServerShutDownHandler And Disable/Delete should not happen parallely leading to recreation of regions that were deleted) to 0.92 and TRUNK</description>
      <version>0.92.2,0.94.0,0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.TestDrainingServer.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKTable.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestMasterRestartAfterDisablingTable.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestMaster.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKTable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.DeleteTableHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="5213" opendate="2012-1-17 00:00:00" fixdate="2012-4-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>"hbase master stop" does not bring down backup masters</summary>
      <description>Typing "hbase master stop" produces the following message:"stop Start cluster shutdown; Master signals RegionServer shutdown"It seems like backup masters should be considered part of the cluster, but they are not brought down by "hbase master stop"."stop-hbase.sh" does correctly bring down the backup masters.The same behavior is observed when a client app makes use of the client API HBaseAdmin.shutdown() http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HBaseAdmin.html#shutdown() &amp;#8211; this isn't too surprising since I think "hbase master stop" just calls this API.It seems like HBASE-1448 address this; perhaps there was a regression?</description>
      <version>0.90.5,0.92.0,0.94.0,0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestActiveMasterManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.ActiveMasterManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="5372" opendate="2012-2-9 00:00:00" fixdate="2012-6-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Table mutation operations should check table level rights, not global rights</summary>
      <description>drop/modify/disable/enable etc table operations should not check for global CREATE/ADMIN rights, but table CREATE/ADMIN rights. Since we check for global permissions first for table permissions, configuring table access using global permissions will continue to work.</description>
      <version>0.94.0,0.94.1,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug id="5525" opendate="2012-3-6 00:00:00" fixdate="2012-4-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Truncate and preserve region boundaries option</summary>
      <description>A tool that would be useful for testing (and maybe in prod too) would be a truncate option to keep the current region boundaries. Right now what you have to do is completely kill the table and recreate it with the correct regions.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.1</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.ruby.shell.rb</file>
      <file type="M">hbase-server.src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug id="5526" opendate="2012-3-6 00:00:00" fixdate="2012-3-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Configurable file and directory based umask</summary>
      <description>Currently many all the files created by the HBase user are just written using the default file permissions granted by hdfs. However, to ensure only the correct user/group views the files and directories, we need to be able to apply a configurable umask to either directories or files. This ticket covers setting permissions for files written to dfs, as opposed to things like pid and log files.The impetus for this was to allow the web-user to view the directory structure of hbase, but not to actually see any of the actual data hbase is storing.</description>
      <version>None</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.util.TestFSUtils.java</file>
      <file type="M">src.main.resources.hbase-default.xml</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.AbstractHFileWriter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="5564" opendate="2012-3-12 00:00:00" fixdate="2012-6-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bulkload is discarding duplicate records</summary>
      <description>Duplicate records are getting discarded when duplicate records exists in same input file and more specifically if they exists in same split.Duplicate records are considered if the records are from diffrent different splits.Version under test: HBase 0.92</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.mapreduce.TestImportTsv.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.TsvImporterMapper.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.ImportTsv.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestImportTsv.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TsvImporterMapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.ImportTsv.java</file>
    </fixedFiles>
  </bug>
  <bug id="5573" opendate="2012-3-13 00:00:00" fixdate="2012-5-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace client ZooKeeper watchers by simple ZooKeeper reads</summary>
      <description>Some code in the package needs to read data in ZK. This could be done by a simple read, but is actually implemented with a watcher. This holds ZK resources.Fixing this could also be an opportunity to remove the need for the client to provide the master address and port.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.TestZooKeeper.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.replication.ReplicationAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="5589" opendate="2012-3-15 00:00:00" fixdate="2012-3-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add of the offline call to the Master Interface</summary>
      <description>Hbck from HBASE-5128 requires an offline method on the master to properly cleanup state during certain assignment repair operations. This will this method will be added to recent and older versions of HBase.</description>
      <version>0.90.6,0.92.0,0.94.0,0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HMasterInterface.java</file>
    </fixedFiles>
  </bug>
  <bug id="559" opendate="2008-4-3 00:00:00" fixdate="2008-4-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>MR example job to count table rows</summary>
      <description>The Lars' import is a little messy; he's not sure how many records were imported. Running a select takes a couple of hours. He happens to have an idle MR cluster standing by. An example MR job that just did a count of records would be generally useful. Could even output row keys so you'd have a list of what made it in. Later, if this tool becomes popular with derivatives and similiars, we can bundle a jar of MR jobs to run against your tables that can answer common queries and that are amenable to subclassing/modification.</description>
      <version>None</version>
      <fixedVersion>0.1.2,0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.package-info.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="5591" opendate="2012-3-16 00:00:00" fixdate="2012-10-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ThiftServerRunner.HBaseHandler.toBytes() is identical to Bytes.getBytes()</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionThriftServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="5604" opendate="2012-3-20 00:00:00" fixdate="2012-4-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>M/R tool to replay WAL files</summary>
      <description>Just an idea I had. Might be useful for restore of a backup using the HLogs.This could an M/R (with a mapper per HLog file).The tool would get a timerange and a (set of) table(s). We'd pick the right HLogs based on time before the M/R job is started and then have a mapper per HLog file.The mapper would then go through the HLog, filter all WALEdits that didn't fit into the time range or are not any of the tables and then uses HFileOutputFormat to generate HFiles.Would need to indicate the splits we want, probably from a live table.</description>
      <version>None</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.mapreduce.TestWALPlayer.java</file>
      <file type="M">src.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  <bug id="5631" opendate="2012-3-24 00:00:00" fixdate="2012-9-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbck should handle case where .tableinfo file is missing.</summary>
      <description>0.92+ branches have a .tableinfo file which could be missing from hdfs. hbck should be able to detect and repair this properly.</description>
      <version>0.92.2,0.94.0,0.95.2</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.HbckTestingUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="5633" opendate="2012-3-24 00:00:00" fixdate="2012-3-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>NPE reading ZK config in HBase</summary>
      <description>If zoo.cfg contains server.* ("server.0=server0:2888:3888\n") and cluster.distributed property (in hbase-site.xml) is empty we get an NPE in parseZooCfg().The easy way to reproduce the bug is running org.apache.hbase.zookeeper.TestHQuorumPeer with hbase-site.xml containing:&lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;&lt;/value&gt;&lt;/property&gt;</description>
      <version>None</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKConfig.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="5642" opendate="2012-3-27 00:00:00" fixdate="2012-3-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[findbugs] Exclude Thrift and Protobuf warnings</summary>
      <description>Exclude thrift and protobuf warnings since these are machine generated.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">dev-support.test-patch.properties</file>
    </fixedFiles>
  </bug>
  <bug id="5644" opendate="2012-3-27 00:00:00" fixdate="2012-4-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[findbugs] Fix null pointer warnings.</summary>
      <description>See https://builds.apache.org/job/PreCommit-HBASE-Build/1313//artifact/trunk/patchprocess/newPatchFindbugsWarnings.htmlFix the NP category</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.Merge.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.ShutdownHook.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.metrics.SchemaConfigured.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.CellCounter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">dev-support.test-patch.properties</file>
      <file type="M">dev-support.findbugs-exclude.xml</file>
    </fixedFiles>
  </bug>
  <bug id="5645" opendate="2012-3-27 00:00:00" fixdate="2012-4-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[findbugs] Fix correctness warnings</summary>
      <description>See https://builds.apache.org/job/PreCommit-HBASE-Build/1313//artifact/trunk/patchprocess/newPatchFindbugsWarnings.htmlFix the warnings in the correctness section.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.PoolMap.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.JVMClusterUtil.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.FSTableDescriptors.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreLAB.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.DefaultLoadBalancer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.CellCounter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFile.java</file>
      <file type="M">dev-support.test-patch.properties</file>
      <file type="M">dev-support.findHangingTest.sh</file>
    </fixedFiles>
  </bug>
  <bug id="5652" opendate="2012-3-27 00:00:00" fixdate="2012-4-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[findbugs] Fix lock release on all paths</summary>
      <description>See https://builds.apache.org/job/PreCommit-HBASE-Build/1313//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html#Warnings_MT_CORRECTNESSCategory UL</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.LogRoller.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">dev-support.test-patch.properties</file>
      <file type="M">dev-support.findbugs-exclude.xml</file>
    </fixedFiles>
  </bug>
  <bug id="5653" opendate="2012-3-27 00:00:00" fixdate="2012-4-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[findbugs] fix perf warnings</summary>
      <description>See https://builds.apache.org/job/PreCommit-HBASE-Build/1313//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html#Warnings_PERFORMANCE</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.executor.TestExecutorService.java</file>
      <file type="M">src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSinkMetrics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSink.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.metrics.HBaseInfo.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.DefaultLoadBalancer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.MultithreadedTableMapper.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.WritableRpcEngine.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.slab.SlabCache.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.slab.SingleSizeCache.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.executor.ExecutorService.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException.java</file>
      <file type="M">dev-support.test-patch.properties</file>
    </fixedFiles>
  </bug>
  <bug id="5654" opendate="2012-3-27 00:00:00" fixdate="2012-4-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[findbugs] Address dodgy bugs</summary>
      <description>See https://builds.apache.org/job/PreCommit-HBASE-Build/1313//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html#Warnings_STYLEThis may be broken down further.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.RegionSplitter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.PoolMap.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.FSHDFSUtils.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.CompressionTest.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.CompoundBloomFilterWriter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.ByteBloomFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreLAB.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionProgress.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.WritableRpcEngine.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.AbstractHFileWriter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HServerLoad.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.FilterList.java</file>
      <file type="M">src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">dev-support.test-patch.properties</file>
      <file type="M">dev-support.findbugs-exclude.xml</file>
    </fixedFiles>
  </bug>
  <bug id="5688" opendate="2012-3-30 00:00:00" fixdate="2012-4-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Convert zk root-region-server znode content to pb</summary>
      <description>Move the root-region-server znode content from the versioned bytes that ServerName.getVersionedBytes outputs to instead be pb.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestMasterNoCluster.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.catalog.TestCatalogTrackerOnCluster.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.catalog.TestCatalogTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.RootRegionTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.catalog.RootLocationEditor.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos.java</file>
    </fixedFiles>
  </bug>
  <bug id="5693" opendate="2012-4-1 00:00:00" fixdate="2012-4-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>When creating a region, the master initializes it and creates a memstore within the master server</summary>
      <description>I didn't do a complete analysis, but the attached patch saves more than 0.25s for each region creation and locally all the unit tests work.</description>
      <version>0.95.2</version>
      <fixedVersion>0.94.4,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.CreateTableHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="5699" opendate="2012-4-2 00:00:00" fixdate="2012-12-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Run with &gt; 1 WAL in HRegionServer</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.0.0,1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="5712" opendate="2012-4-4 00:00:00" fixdate="2012-4-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Parallelize load of .regioninfo files in diagnostic/repair portion of hbck.</summary>
      <description>On heavily loaded hdfs's some dfs nodes may not respond quickly and backs off for 60s before attempting to read data from another datanode. Portions of the information gathered from hdfs (.regioninfo files) are loaded serially. With HBase with clusters with 100's, or 1000's, or 10000's regions encountering these 60s delay blocks progress and can be very painful. There is already some parallelization of portions of the hdfs information load operations and the goal here is move the reading of .regioninfos into the parallelized sections..</description>
      <version>0.90.7,0.92.2,0.94.0,0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="5714" opendate="2012-4-4 00:00:00" fixdate="2012-8-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add write permissions check before any hbck run that modifies hdfs.</summary>
      <description>We encoutered a situation where hbck was run by an under-privileged user that was unable to write/modify/merge regions due to hdfs perms. Unfortunately, this user was alerted of this after several minutes of read-only operations. hbck should fail early by having a write perm check and providing actionable advice to the hbase admin.Maybe something like: "Current user yy does not have write perms to &lt;hbase home&gt;. Please run hbck as hdfs user xxx"</description>
      <version>0.90.6,0.92.2,0.94.0,0.95.2</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="5715" opendate="2012-4-4 00:00:00" fixdate="2012-4-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Revert &amp;#39;Instant schema alter&amp;#39; for now, HBASE-4213</summary>
      <description>See this discussion: http://search-hadoop.com/m/NxCQh1KlSxR1/Pull+instant+schema+updating+out%253F&amp;subj=Pull+instant+schema+updating+out+Pull out hbase-4213 for now. Can add it back later.</description>
      <version>None</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.util.MockRegionServerServices.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestInstantSchemaChangeSplit.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestInstantSchemaChangeFailover.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestInstantSchemaChange.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.InstantSchemaChangeTestBase.java</file>
      <file type="M">src.main.resources.hbase-default.xml</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.SchemaChangeTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.MasterSchemaChangeTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.OnlineRegions.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.TableModifyFamilyHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.TableEventHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.TableDeleteFamilyHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.TableAddFamilyHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.ModifyTableHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.DeleteTableHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.LocalHBaseCluster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HMasterInterface.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.executor.EventHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="5717" opendate="2012-4-4 00:00:00" fixdate="2012-4-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scanner metrics are only reported if you get to the end of a scanner</summary>
      <description>When you turn on Scanner Metrics, the metrics are currently only made available if you run over all records available in the scanner. If you stop iterating before the end, the values are never flushed into the metrics object (in the Scan attribute).Will supply a patch with fix and test.</description>
      <version>None</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="5719" opendate="2012-4-4 00:00:00" fixdate="2012-4-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enhance hbck to sideline overlapped mega regions</summary>
      <description>If there are too many regions in one overlapped group (by default, more than 10), hbck currently doesn't merge them since it takes time.In this case, we can sideline some regions in the group and break the overlapping to fix the inconsistency. Later on, sidelined regions can be bulk loaded manually.</description>
      <version>0.94.0,0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.util.TestRegionSplitCalculator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.RegionSplitCalculator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="5734" opendate="2012-4-5 00:00:00" fixdate="2012-4-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change hbck sideline root</summary>
      <description>Currently hbck sideline root is the root which can run into permission issue. We can change it to /hbck</description>
      <version>0.94.0,0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="5739" opendate="2012-4-6 00:00:00" fixdate="2012-4-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade guava to 11.0.2</summary>
      <description>Hadoop has upgraded to this new version of Guava. We should, too, so we don't have compatibility issues running on Hadoop 2.0+</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.slab.SingleSizeCache.java</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="5740" opendate="2012-4-6 00:00:00" fixdate="2012-4-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compaction interruption may be due to balacing</summary>
      <description>Currently, the log shows Aborting compaction of store LOG in region .... because user requested stop.But it is actually because of balancing.Currently, there is no way to figure out who closed the region. So it is better to change the message to say it is because of user, or balancing.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.Compactor.java</file>
    </fixedFiles>
  </bug>
  <bug id="5747" opendate="2012-4-7 00:00:00" fixdate="2012-4-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Forward port "hbase-5708 [89-fb] Make MiniMapRedCluster directory a subdirectory of target/test"</summary>
      <description>Forward port as much as we can of Mikhail's hard-won test cleanups over on 0.89 branch Will improve our being able to run unit tests in //. He also found a few bugs.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.resources.hbase-site.xml</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKLeaderManager.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.util.TestMiniClusterLoadSequential.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.TestZooKeeper.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.TestHBaseTestingUtility.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.TestFullLogReconstruction.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLog.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreFile.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestSplitLogManager.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.mapreduce.TestTimeRangeMapRed.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.hfile.TestScannerSelectionUsingTTL.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileSeek.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileDataBlockEncoder.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFile.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.hfile.TestFixedFileTrailer.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.HBaseTestCase.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorEndpoint.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.coprocessor.TestClassLoading.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="5755" opendate="2012-4-9 00:00:00" fixdate="2012-4-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Region sever looking for master forever with cached stale data.</summary>
      <description>When the master address tracker doesn't have the master address ZK data, or the cached data is wrong, region server should not use the cached data.It should pull the data from ZK directly again.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.MasterAddressTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="5760" opendate="2012-4-10 00:00:00" fixdate="2012-4-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unit tests should write only under /target</summary>
      <description>Some of the unit test runs result in files under $hbase_home/test, $hbase_home/build, or $hbase_home/. We should ensure that all tests use target as their data location.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverStacking.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorInterface.java</file>
    </fixedFiles>
  </bug>
  <bug id="5785" opendate="2012-4-13 00:00:00" fixdate="2012-5-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Adding unit tests for protbuf utils introduced for HRegionInterface pb conversion</summary>
      <description>We need to add some unit tests for the probuf utilities to catch issues earlier.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="5787" opendate="2012-4-13 00:00:00" fixdate="2012-4-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Table owner can&amp;#39;t disable/delete his/her own table</summary>
      <description>An user with CREATE privileges can create a table, but can not disable it, because disable operation require ADMIN privileges. Also if a table is already disabled, anyone can remove it.public void preDeleteTable(ObserverContext&lt;MasterCoprocessorEnvironment&gt; c, byte[] tableName) throws IOException { requirePermission(Permission.Action.CREATE);}public void preDisableTable(ObserverContext&lt;MasterCoprocessorEnvironment&gt; c, byte[] tableName) throws IOException { /* TODO: Allow for users with global CREATE permission and the table owner */ requirePermission(Permission.Action.ADMIN);}</description>
      <version>0.92.1,0.94.0,0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">security.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">security.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug id="5794" opendate="2012-4-14 00:00:00" fixdate="2012-4-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Jenkins builds timing out; undo setting hbase.client.retries.number to 100</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.resources.hbase-site.xml</file>
    </fixedFiles>
  </bug>
  <bug id="5800" opendate="2012-4-16 00:00:00" fixdate="2012-4-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Birds of a feather link on web page doesn&amp;#39;t work.</summary>
      <description>just missing the http://</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.index.xml</file>
    </fixedFiles>
  </bug>
  <bug id="5805" opendate="2012-4-17 00:00:00" fixdate="2012-4-17 01:00:00" resolution="Cannot Reproduce">
    <buginformation>
      <summary>TestServerCustomProtocol failing intermittently.</summary>
      <description>Trace:java.lang.AssertionError: Results should contain region test,ccc,1334638013935.b9d77206f6eb226928b898e66fd1d508. for row 'ccc' at org.junit.Assert.fail(Assert.java:93) at org.junit.Assert.assertTrue(Assert.java:43) at org.apache.hadoop.hbase.regionserver.TestServerCustomProtocol.verifyRegionResults(TestServerCustomProtocol.java:363) at org.apache.hadoop.hbase.regionserver.TestServerCustomProtocol.testNullReturn(TestServerCustomProtocol.java:330) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)</description>
      <version>0.95.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  <bug id="5819" opendate="2012-4-18 00:00:00" fixdate="2012-4-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>SplitLogs function could leak resources</summary>
      <description>You would need to be unlucky and with a system in a bad shape but we have no reason to keep this in production code.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
    </fixedFiles>
  </bug>
  <bug id="582" opendate="2008-4-16 00:00:00" fixdate="2008-4-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase 554 forgot to clear results on each iteration caused by a filter</summary>
      <description>I noticed this while working on new filters. Not sure if it will trip up any existing filters, but it is surely a bug.Patch to follow</description>
      <version>None</version>
      <fixedVersion>0.1.2,0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5823" opendate="2012-4-18 00:00:00" fixdate="2012-4-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hbck should be able to print help</summary>
      <description>bin/hbase hbck -h and -help should print the help message. It used to print help when unrecognized options are passed. We can backport this to 0.92/0.94 branches as well.</description>
      <version>0.92.1,0.94.1,0.95.2</version>
      <fixedVersion>0.92.2,0.94.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="5844" opendate="2012-4-20 00:00:00" fixdate="2012-5-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Delete the region servers znode after a regions server crash</summary>
      <description>today, if the regions server crashes, its znode is not deleted in ZooKeeper. So the recovery process will stop only after a timeout, usually 30s.By deleting the znode in start script, we remove this delay and the recovery starts immediately.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">bin.hbase-daemon.sh</file>
    </fixedFiles>
  </bug>
  <bug id="5849" opendate="2012-4-21 00:00:00" fixdate="2012-4-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>On first cluster startup, RS aborts if root znode is not available</summary>
      <description>When launching a fresh new cluster, the master has to be started first, which might create race conditions for starting master and rs at the same time. Master startup code is smt like this: establish zk connection create root znodes in zk (/hbase) create ephemeral node for master /hbase/master, Region server start up code is smt like this: establish zk connection check whether the root znode (/hbase) is there. If not, shutdown. wait for the master to create znodes /hbase/masterSo, the problem is on the very first launch of the cluster, RS aborts to start since /hbase znode might not have been created yet (only the master creates it if needed). Since /hbase/ is not deleted on cluster shutdown, on subsequent cluster starts, it does not matter which order the servers are started. So this affects only first launchs.</description>
      <version>0.92.2,0.94.1,0.95.2</version>
      <fixedVersion>0.92.2,0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.TestClusterBootOrder.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="5862" opendate="2012-4-23 00:00:00" fixdate="2012-4-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>After Region Close remove the Operation Metrics.</summary>
      <description>If a region is closed then Hadoop metrics shouldn't still be reporting about that region.</description>
      <version>None</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerMetrics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.metrics.RegionServerDynamicMetrics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.metrics.RegionMetricsStorage.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.metrics.OperationMetrics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="5867" opendate="2012-4-24 00:00:00" fixdate="2012-5-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve Compaction Throttle Default</summary>
      <description>We recently had a production issue where our compactions fell behind because our compaction throttle was improperly tuned and accidentally upgraded all compactions to the large pool. The default from HBASE-3877 makes 1 bad assumption: the default number of flushed files in a compaction. Currently the algorithm is:throttleSize ~= flushSize * 2This assumes that the basic compaction utilizes 3 files and that all 3 files are compressed. In this case, "hbase.hstore.compaction.min" == 6 &amp;&amp; the values were not very compressible. Both conditions should be taken into consideration. As a default, it is less damaging for the large thread to be slightly higher than it needs to be versus having everything accidentally promoted.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
    </fixedFiles>
  </bug>
  <bug id="5872" opendate="2012-4-25 00:00:00" fixdate="2012-4-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve hadoopqa script to include checks for hadoop 0.23 build</summary>
      <description>There have been a few patches that have made it into hbase trunk that have broken the compile of hbase against hadoop 0.23.x, without being known for a few days.We could have the bot do a few things:1) verify that patch compiles against hadoop 232) verify that unit tests pass against hadoop 23</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  <bug id="5877" opendate="2012-4-25 00:00:00" fixdate="2012-5-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>When a query fails because the region has moved, let the regionserver return the new address to the client</summary>
      <description>This is mainly useful when we do a rolling restart. This will decrease the load on the master and the network load.Note that a region is not immediately opened after a close. So: it seems preferable to wait before retrying on the other server. An optimisation would be to have an heuristic depending on when the region was closed. during a rolling restart, the server moves the regions then stops. So we may have failures when the server is stopped, and this patch won't help.The implementation in the first patch does: on the region move, there is an added parameter on the regionserver#close to say where we are sending the region the regionserver keeps a list of what was moved. Each entry is kept 100 seconds. the regionserver sends a specific exception when it receives a query on a moved region. This exception contains the new address. the client analyses the exeptions and update its cache accordingly...</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.util.MockRegionServerServices.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
      <file type="M">src.main.protobuf.Admin.proto</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.OnlineRegions.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.protobuf.generated.AdminProtos.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="5879" opendate="2012-4-25 00:00:00" fixdate="2012-5-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable JMX metrics collection for the Thrift proxy</summary>
      <description>We need to enable JMX on the Thrift proxy on a separate port different from the JMX port used by regionserver. This is necessary for metrics collection.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase-config.sh</file>
    </fixedFiles>
  </bug>
  <bug id="588" opendate="2008-4-17 00:00:00" fixdate="2008-4-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Still a &amp;#39;hole&amp;#39; in scanners, even after HBASE-532</summary>
      <description>Before HBASE-532, as soon as a flush started, we called snapshot. Snapshot used to copy current live memcache into a 'snapshot' TreeMap inside in Memcache. This snapshot TreeMap was an accumulation of all snapshots since last flush. Whenever we took out a scanner, we'd do a copy of this snapshot into a new backing map carried by the scanner (Every outstanding Scanner had complete copy). Memcache snapshots were cleared when a flush started. Flushing could take near no time to up to tens of seconds during which an scanners taken out meantime would not see the edits in the snapshot currently being flushed and gets or getFull would also return incorrect answers because the content of the snapshot was not available to them.HBASE-532 made it so the snapshot was available until flush was done &amp;#8211; until a file had made it out to disk. This fixed gets and getFull and any scanners taken out during flushing. But there is still a hole. Any outstanding scanners will be going against the state of Store Readers at time scanner was opened; they will not see the new flush file.Chatting about this on IRC, Jim suggests that we pass either memcache or current snapshot to each Scanner (Pass the snapshot if not empty). The notion is that the Scanner would hold on to the Scanner reference should it be cleared by flushing. Upside is that scanner wouldn't have to be concerned with the new flush that has been put out to disk. Downsides are that Scanner data could be way stale if for instance the memcache was near to flushing but we hadn't done it yet. And we wouldn't be clearing the snapshot promptly so would be some memory pressure.Another suggestion is that flushing send an event. Listeners such as outstanding scanners would notice event and open the new Reader. Would have to skip forward in the new Reader to catch up with the current set but shouldn't be bad. Same mechanism could be used to let compactions be moved into place while scanners were outstanding closing down all existing readers skipping to the current 'next' location in the new compacted store file.</description>
      <version>None</version>
      <fixedVersion>0.1.2,0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.test.org.apache.hadoop.hbase.MultiRegionTable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStoreScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HAbstractScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Flusher.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.CacheFlushListener.java</file>
    </fixedFiles>
  </bug>
  <bug id="5884" opendate="2012-4-26 00:00:00" fixdate="2012-4-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>MapReduce package info has broken link to bulk-loads</summary>
      <description>Bulk Loads link goes to an old link, which we have dropped recently.</description>
      <version>0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.package-info.java</file>
    </fixedFiles>
  </bug>
  <bug id="5885" opendate="2012-4-26 00:00:00" fixdate="2012-4-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Invalid HFile block magic on Local file System</summary>
      <description>ERROR: java.lang.RuntimeException: org.apache.hadoop.hbase.client.RetriesExhaustedException: Failed after attempts=7, exceptions:Thu Apr 26 11:19:18 PDT 2012, org.apache.hadoop.hbase.client.ScannerCallable@190a621a, java.io.IOException: java.io.IOException: Could not iterate StoreFileScanner[HFileScanner for reader reader=file:/tmp/hbase-eclark/hbase/TestTable/e2d1c846363c75262cbfd85ea278b342/info/bae2681d63734066957b58fe791a0268, compression=none, cacheConf=CacheConfig:enabled &amp;#91;cacheDataOnRead=true&amp;#93; &amp;#91;cacheDataOnWrite=false&amp;#93; &amp;#91;cacheIndexesOnWrite=false&amp;#93; &amp;#91;cacheBloomsOnWrite=false&amp;#93; &amp;#91;cacheEvictOnClose=false&amp;#93; &amp;#91;cacheCompressed=false&amp;#93;, firstKey=0000000001/info:data/1335463981520/Put, lastKey=0002588100/info:data/1335463902296/Put, avgKeyLen=30, avgValueLen=1000, entries=1215085, length=1264354417, cur=0000000248/info:data/1335463994457/Put/vlen=1000/ts=0] at org.apache.hadoop.hbase.regionserver.StoreFileScanner.next(StoreFileScanner.java:135) at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:95) at org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:368) at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:127) at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.nextInternal(HRegion.java:3323) at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.next(HRegion.java:3279) at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.next(HRegion.java:3296) at org.apache.hadoop.hbase.regionserver.HRegionServer.next(HRegionServer.java:2393) at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.apache.hadoop.hbase.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:364) at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1376)Caused by: java.io.IOException: Invalid HFile block magic: \xEC\xD5\x9D\xB4\xC2bfo at org.apache.hadoop.hbase.io.hfile.BlockType.parse(BlockType.java:153) at org.apache.hadoop.hbase.io.hfile.BlockType.read(BlockType.java:164) at org.apache.hadoop.hbase.io.hfile.HFileBlock.&lt;init&gt;(HFileBlock.java:254) at org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderV2.readBlockDataInternal(HFileBlock.java:1779) at org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderV2.readBlockData(HFileBlock.java:1637) at org.apache.hadoop.hbase.io.hfile.HFileReaderV2.readBlock(HFileReaderV2.java:327) at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.readNextDataBlock(HFileReaderV2.java:555) at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.next(HFileReaderV2.java:651) at org.apache.hadoop.hbase.regionserver.StoreFileScanner.next(StoreFileScanner.java:130) ... 12 moreThu Apr 26 11:19:19 PDT 2012, org.apache.hadoop.hbase.client.ScannerCallable@190a621a, java.io.IOException: java.io.IOException: java.lang.IllegalArgumentException at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:1132) at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:1121) at org.apache.hadoop.hbase.regionserver.HRegionServer.next(HRegionServer.java:2420) at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.apache.hadoop.hbase.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:364) at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1376)Caused by: java.lang.IllegalArgumentException at java.nio.Buffer.position(Buffer.java:216) at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.next(HFileReaderV2.java:630) at org.apache.hadoop.hbase.regionserver.StoreFileScanner.next(StoreFileScanner.java:130) at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:95) at org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:406) at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:127) at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.nextInternal(HRegion.java:3323) at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.next(HRegion.java:3279) at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.next(HRegion.java:3296) at org.apache.hadoop.hbase.regionserver.HRegionServer.next(HRegionServer.java:2393) ... 5 moreOn latest 0.94 branch I spun up a new standalone hbase. Then I started a performance evaluation run hbase/bin/hbase org.apache.hadoop.hbase.PerformanceEvaluation --nomapred randomWrite 10after that completed I tried a scan of TestTable. The scan got the above error.</description>
      <version>0.94.0,0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.hfile.TestChecksum.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.fs.HFileSystem.java</file>
    </fixedFiles>
  </bug>
  <bug id="5886" opendate="2012-4-26 00:00:00" fixdate="2012-5-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add new metric for possible data loss due to puts without WAL</summary>
      <description>Add a metrics to keep track of puts without WAL and possible data loss size.</description>
      <version>None</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.metrics.RegionServerMetrics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="5888" opendate="2012-4-27 00:00:00" fixdate="2012-5-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clover profile in build</summary>
      <description>Clover is disabled right now. I would like to add a profile that enables clover reports. We can also backport this to 0.92, and 0.94, since we are also interested in test coverage for those branches.</description>
      <version>0.92.2,0.94.1,0.95.2</version>
      <fixedVersion>0.94.4,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="5893" opendate="2012-4-27 00:00:00" fixdate="2012-4-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow spaces in coprocessor conf (aka trim() className)</summary>
      <description>This is annoying especially for coprocessors where you've long class name.but maybe is a bug of Configuration.getStrings() that doesn't trim each string.When you've comma separated values like in the coprocessors case, you've to pack together your values without spaces ("v1,v2,v3,...") otherwise the coprocessor is not loaded because the class name with spaces is not found.&lt;property&gt; &lt;name&gt;hbase.coprocessor.master.classes&lt;/name&gt; &lt;value&gt; org.apache.hadoop.hbase.security.token.TokenProvider, org.apache.hadoop.hbase.security.access.AccessController &lt;/value&gt;&lt;/property&gt;</description>
      <version>0.92.1,0.94.0,0.95.2</version>
      <fixedVersion>0.92.2,0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorHost.java</file>
    </fixedFiles>
  </bug>
  <bug id="5901" opendate="2012-4-30 00:00:00" fixdate="2012-5-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use union type protobufs instead of class/byte pairs for multi requests</summary>
      <description>The current implementation of multi actions uses repeated "NameBytesPair"s for the contents of multi actions. Instead, we should introduce a union type protobuf for the valid actions. This makes the RPCs smaller since they don't need to carry class names, and makes deserialization faster since it can avoid some copying and reflection.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.protobuf.Client.proto</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.RegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.protobuf.generated.ClientProtos.java</file>
    </fixedFiles>
  </bug>
  <bug id="5903" opendate="2012-4-30 00:00:00" fixdate="2012-5-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Detect the test classes without categories</summary>
      <description>The tests are executed by category. When a test does not have a category, it's not run on prebuild nor central build.This new test checks the test classess and list the ones without category. It fails if it finds one. As it's a small test it will be executed on the developper machine and will fail immediately on the central builds.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.TestHColumnDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="5926" opendate="2012-5-3 00:00:00" fixdate="2012-5-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Delete the master znode after a master crash</summary>
      <description>This is the continuation of the work done in HBASE-5844.But we can't apply exactly the same strategy: for the region server, there is a znode per region server, while for the master &amp; backup master there is a single znode for both.So if we apply the same strategy as for a regionserver, we may have this scenario:1) Master starts2) Backup master starts3) Master dies4) ZK detects it5) Backup master receives the update from ZK6) Backup master creates the new master node and become the main master7) Previous master script continues8) Previous master script deletes the master node in ZK9) =&gt; issue: we deleted the node just created by the new masterThis should not happen often (usually the znode will be deleted soon enough), but it can happen.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.zookeeper.TestZooKeeperNodeTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.MasterAddressTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMasterCommandLine.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.ActiveMasterManager.java</file>
      <file type="M">bin.hbase-daemon.sh</file>
    </fixedFiles>
  </bug>
  <bug id="5934" opendate="2012-5-4 00:00:00" fixdate="2012-8-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add the ability for Performance Evaluation to set the table compression</summary>
      <description>When testing it's nice to get a more realistic set of numbers. As such allowing the tool to create pre-split regions was needed. Compression should be the same.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
    </fixedFiles>
  </bug>
  <bug id="5939" opendate="2012-5-4 00:00:00" fixdate="2012-5-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add an autorestart option in the start scripts</summary>
      <description>When a binary dies on a server, we don't try to restart it while it would be possible in most cases.We can have something as:loop start wait if cleanStop then exit if already stopped less than 5 minutes ago sleep 5 minuteendloopThis is simple for master &amp; backup master, a little bit more complex for the region server as it can be stopped by a script or by the shutdown procedure.On a long long term it could allow a restart with exactly the same assignments.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.start-hbase.sh</file>
      <file type="M">bin.hbase-daemon.sh</file>
    </fixedFiles>
  </bug>
  <bug id="5945" opendate="2012-5-5 00:00:00" fixdate="2012-11-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reduce buffer copies in IPC server response path</summary>
      <description>The new PB code is sloppy with buffers and makes several needless copies. This increases GC time a lot. A few simple changes can cut this back down.</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.96.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestIPC.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide3.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServer.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceImpl.java</file>
      <file type="M">hbase-hadoop1-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSource.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.IPCUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="5948" opendate="2012-5-6 00:00:00" fixdate="2012-5-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Deprecate and remove the Avro gateway</summary>
      <description>Deprecate the Avro gateway in 0.94. Remove in 0.96. Made a blocker against that release.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.avro.package.html</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.avro.AvroUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.avro.AvroServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="5953" opendate="2012-5-7 00:00:00" fixdate="2012-6-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expose the current state of the balancerSwitch</summary>
      <description>The balancerSwitch as in both 0.90 and 0.92.1 is implemented in such a way that it is impossible to retrieve its value without changing it:/**Turn the load balancer on or off.@param b If true, enable balancer. If false, disable balancer.@return Previous balancer value*/public boolean balanceSwitch(final boolean b);It would be nice to have a way to just get the current state.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.protobuf.ClusterStatus.proto</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ClusterStatus.java</file>
    </fixedFiles>
  </bug>
  <bug id="5959" opendate="2012-5-8 00:00:00" fixdate="2012-5-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add other load balancers</summary>
      <description>Now that balancers are pluggable we should give some options.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.2</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestRegionRebalancing.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestDefaultLoadBalancer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerAndLoad.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionPlan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.LoadBalancerFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.LoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.DefaultLoadBalancer.java</file>
      <file type="M">hbase-server.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="5965" opendate="2012-5-8 00:00:00" fixdate="2012-8-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move replication znodes to pb</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.main.protobuf.ZooKeeper.proto</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.ReplicationZookeeper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.Replication.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.replication.ReplicationAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="5966" opendate="2012-5-9 00:00:00" fixdate="2012-7-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>MapReduce based tests broken on Hadoop 2.0.0-alpha</summary>
      <description>Some fairly recent change in Hadoop 2.0.0-alpha has broken our MapReduce test rigging. Below is a representative error, can be easily reproduced with:mvn -PlocalTests -Psecurity \ -Dhadoop.profile=23 -Dhadoop.version=2.0.0-SNAPSHOT \ clean test \ -Dtest=org.apache.hadoop.hbase.mapreduce.TestTableMapReduceAnd the result:------------------------------------------------------- T E S T S-------------------------------------------------------Running org.apache.hadoop.hbase.mapreduce.TestTableMapReduceTests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 54.292 sec &lt;&lt;&lt; FAILURE!-------------------------------------------------------------------------------Test set: org.apache.hadoop.hbase.mapreduce.TestTableMapReduce-------------------------------------------------------------------------------Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 54.292 sec &lt;&lt;&lt; FAILURE!testMultiRegionTable(org.apache.hadoop.hbase.mapreduce.TestTableMapReduce) Time elapsed: 21.935 sec &lt;&lt;&lt; ERROR!java.lang.reflect.UndeclaredThrowableException at org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl.unwrapAndThrowException(YarnRemoteExceptionPBImpl.java:135) at org.apache.hadoop.yarn.api.impl.pb.client.ClientRMProtocolPBClientImpl.getNewApplication(ClientRMProtocolPBClientImpl.java:134) at org.apache.hadoop.mapred.ResourceMgrDelegate.getNewJobID(ResourceMgrDelegate.java:183) at org.apache.hadoop.mapred.YARNRunner.getNewJobID(YARNRunner.java:216) at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:339) at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1226) at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1223) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:416) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1232) at org.apache.hadoop.mapreduce.Job.submit(Job.java:1223) at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1244) at org.apache.hadoop.hbase.mapreduce.TestTableMapReduce.runTestOnTable(TestTableMapReduce.java:151) at org.apache.hadoop.hbase.mapreduce.TestTableMapReduce.testMultiRegionTable(TestTableMapReduce.java:129) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:616) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20) at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:47) at org.junit.rules.RunRules.evaluate(RunRules.java:18) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222) at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28) at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30) at org.junit.runners.ParentRunner.run(ParentRunner.java:300) at org.apache.maven.surefire.junit4.JUnit4TestSet.execute(JUnit4TestSet.java:53) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:123) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:104) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:616) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:164) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:110) at org.apache.maven.surefire.booter.SurefireStarter.invokeProvider(SurefireStarter.java:175) at org.apache.maven.surefire.booter.SurefireStarter.runSuitesInProcessWhenForked(SurefireStarter.java:81) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:68)Caused by: com.google.protobuf.ServiceException: java.net.ConnectException: Call From acer.localdomain/192.168.122.1 to 0.0.0.0:8032 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:188) at $Proxy89.getNewApplication(Unknown Source) at org.apache.hadoop.yarn.api.impl.pb.client.ClientRMProtocolPBClientImpl.getNewApplication(ClientRMProtocolPBClientImpl.java:132) ... 45 moreCaused by: java.net.ConnectException: Call From acer.localdomain/192.168.122.1 to 0.0.0.0:8032 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:725) at org.apache.hadoop.ipc.Client.call(Client.java:1160) at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:185) ... 47 moreCaused by: java.net.ConnectException: Connection refused at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:592) at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206) at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:522) at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:487) at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:469) at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:563) at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:212) at org.apache.hadoop.ipc.Client.getConnection(Client.java:1266) at org.apache.hadoop.ipc.Client.call(Client.java:1136) ... 48 more</description>
      <version>0.94.0,0.95.2</version>
      <fixedVersion>0.94.1,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
    </fixedFiles>
  </bug>
  <bug id="5974" opendate="2012-5-9 00:00:00" fixdate="2012-10-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scanner retry behavior with RPC timeout on next() seems incorrect</summary>
      <description>I'm seeing the following behavior: set RPC timeout to a short value call next() for some batch of rows, big enough so the client times out before the result is returned the HConnectionManager stuff will retry the next() call to the same server. At this point, one of two things can happen: 1) the previous next() call will still be processing, in which case you get a LeaseException, because it was removed from the map during the processing, or 2) the next() call will succeed but skip the prior batch of rows.</description>
      <version>0.90.7,0.92.1,0.94.0,0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.protobuf.Client.proto</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.JVMClusterUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ClientProtos.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="5990" opendate="2012-5-11 00:00:00" fixdate="2012-5-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestHCM failed with Hadoop 2.0.0</summary>
      <description>Running org.apache.hadoop.hbase.client.TestHCMTests run: 7, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 11.742 sec &lt;&lt;&lt; FAILURE!Failed tests: testRegionCaching(org.apache.hadoop.hbase.client.TestHCM)</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.RegionMovedException.java</file>
    </fixedFiles>
  </bug>
  <bug id="5992" opendate="2012-5-11 00:00:00" fixdate="2012-5-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Generalization of region move implementation + manage draining servers in bulk assign</summary>
      <description>The region move implementation now has now a similar behavior whatever the destination server is specified or not. This allows: to benefit from the improvement in HBASE-5877 as a side effect to have the coprocessors calls when the destination server is not specifiedThis includes various fixes around draining servers. Draining servers were not excluded during a bulk assign. This is now fixed.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.TestDrainingServer.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.CreateTableHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="5998" opendate="2012-5-14 00:00:00" fixdate="2012-5-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bulk assignment: regionserver optimization by using a temporary cache for table descriptors when receveing an open regions request</summary>
      <description>During the assignment, on the regionserver, before creating the handlers we load the table description. Even if there is a cache, we check the timestamps for each region, while it's not necessary. The test below is just with one node, with more nodes the benefit will improve. By limiting the time spent in HRegion#openRegion we increase the parallelization during cluster startup, as the master is using a pool of threads to call the RS.&amp;#8211; Without the fix2012-05-14 11:40:52,501 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Bulk assigning 1193 region(s) to localhost,11003,13369884440432012-05-14 11:41:09,947 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Bulk assigning done for localhost,11003,1336988444043&amp;#8211; With the fix2012-05-14 11:34:40,444 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Bulk assigning 1193 region(s) to localhost,11003,13369884440432012-05-14 11:34:40,929 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Bulk assigning done for localhost,11003,1336988065948</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="6001" opendate="2012-5-15 00:00:00" fixdate="2012-5-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade slf4j to 1.6.1</summary>
      <description>We need to upgrade slf4j to 1.6.1 since other hadoop components use 1.6.1 now.</description>
      <version>None</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6004" opendate="2012-5-15 00:00:00" fixdate="2012-5-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Adding more logging to help debugging MR job</summary>
      <description>MR job sometime fails because scanner expired. In this case, it will be helpful to know the last successful row, the ip of the region sever, and so on.</description>
      <version>0.94.0,0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapred.TableRecordReaderImpl.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
    </fixedFiles>
  </bug>
  <bug id="6005" opendate="2012-5-15 00:00:00" fixdate="2012-5-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Broken Links on Homepages</summary>
      <description>I ran w3c's link checker on the homepage and there a few broken links.I'll start getting a patch to fix the links that were broken.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.old.news.xml</file>
      <file type="M">src.site.xdoc.cygwin.xml</file>
      <file type="M">src.main.javadoc.overview.html</file>
      <file type="M">src.docbkx.preface.xml</file>
      <file type="M">src.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6007" opendate="2012-5-15 00:00:00" fixdate="2012-5-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make getTableRegions return an empty list if the table does not exist</summary>
      <description>Making the getTableRegions Thrift API method handle TableNotFoundException and return an empty list in that case. Without this the behavior is dependent on whether an HTable object is present in the thread-local cache in case a table was deleted.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
    </fixedFiles>
  </bug>
  <bug id="6011" opendate="2012-5-16 00:00:00" fixdate="2012-5-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unable to start master in local mode</summary>
      <description>Got this trying to launch head of 0.94 branch in local mode from the build tree but it happens with trunk and 0.92 too:12/05/15 19:35:45 ERROR master.HMasterCommandLine: Failed to start masterjava.lang.ClassCastException: org.apache.hadoop.hbase.master.HMaster cannot be cast to org.apache.hadoop.hbase.master.HMasterCommandLine$LocalHMaster at org.apache.hadoop.hbase.master.HMasterCommandLine.startMaster(HMasterCommandLine.java:142) at org.apache.hadoop.hbase.master.HMasterCommandLine.run(HMasterCommandLine.java:103) at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65) at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:76) at org.apache.hadoop.hbase.master.HMaster.main(HMaster.java:1761)</description>
      <version>0.92.2,0.94.1,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.LocalHBaseCluster.java</file>
    </fixedFiles>
  </bug>
  <bug id="6012" opendate="2012-5-16 00:00:00" fixdate="2012-6-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Handling RegionOpeningState for bulk assign</summary>
      <description>Since HBASE-5914, we using bulk assign for SSHBut in the bulk assign case if we get an ALREADY_OPENED case there is no one to clear the znode created by bulk assign. Another thing, when RS opening a list of regions, if one region is already in transition, it will throw RegionAlreadyInTransitionException and stop opening other regions.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.ResponseConverter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="6022" opendate="2012-5-16 00:00:00" fixdate="2012-5-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Include Junit in the libs when packaging so that TestAcidGaurntee can run</summary>
      <description>If JUnit is not in the libs folder running the test acid command fails.</description>
      <version>None</version>
      <fixedVersion>0.94.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6023" opendate="2012-5-16 00:00:00" fixdate="2012-5-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Normalize security audit logging level with Hadoop</summary>
      <description>A pretty trivial change, we log failed authentication attempts at WARN level, as does Hadoop, but log successful authentication at TRACE level, where Hadoop instead logs it at INFO level.</description>
      <version>0.92.2,0.94.1,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HBaseServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="6025" opendate="2012-5-16 00:00:00" fixdate="2012-9-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expose Hadoop Dynamic Metrics through JSON Rest interface</summary>
      <description></description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.ruby.shell.formatter.rb</file>
      <file type="M">hbase-server.src.main.ruby.shell.commands.rb</file>
      <file type="M">hbase-server.src.main.ruby.shell.rb</file>
      <file type="M">hbase-server.src.main.ruby.hbase.table.rb</file>
      <file type="M">hbase-server.src.main.ruby.hbase.hbase.rb</file>
      <file type="M">hbase-server.src.main.ruby.hbase.admin.rb</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.zk.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.tablesDetailed.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="6057" opendate="2012-5-19 00:00:00" fixdate="2012-5-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change some tests categories to optimize build time</summary>
      <description>Some tests categorized as small takes more than 15s: it's better if they are executed in // with the medium tests.Some medium tests last less than 2s: it's better to have then executed with the small tests: we save a fork.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.zookeeper.TestHQuorumPeer.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.util.TestPoolMap.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRollingNoCluster.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestMemStore.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestGetClosestAtOrBefore.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestCompoundBloomFilter.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.monitoring.TestTaskMonitor.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.monitoring.TestMemoryBoundedLogMessageBuffer.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.metrics.TestMetricsMBeanBase.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestDefaultLoadBalancer.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestClockSkewDetection.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.ipc.TestPBOnWritableRpc.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.hfile.TestLruBlockCache.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileBlockCompatibility.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.hfile.TestFixedFileTrailer.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.hfile.TestChecksum.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.encoding.TestEncodedSeekers.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.encoding.TestBufferedDataBlockEncoder.java</file>
    </fixedFiles>
  </bug>
  <bug id="6061" opendate="2012-5-21 00:00:00" fixdate="2012-5-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix ACL "Admin" Table inconsistent permission check</summary>
      <description>the requirePermission() check for "admin" operation on a table is currently inconsistent.Table Owner with CREATE rights (that means, the owner has created that table) can enable/disable and delete the table but needs ADMIN rights to add/remove/modify a column.</description>
      <version>0.92.1,0.94.0,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug id="6062" opendate="2012-5-21 00:00:00" fixdate="2012-5-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>preCheckAndPut/Delete() checks for READ when also a WRITE is performed</summary>
      <description>preCheckAndPut() and preCheckAndDelete() checks for READ when they also want to WRITE... for me checking for WRITE permission is the right thing... what do you say about that? keep READ, replace with WRITE?</description>
      <version>0.92.1,0.94.0,0.95.2</version>
      <fixedVersion>0.92.2,0.94.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug id="6065" opendate="2012-5-22 00:00:00" fixdate="2012-5-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Log for flush would append a non-sequential edit in the hlog, leading to possible data loss</summary>
      <description>After completing flush region, we will append a log edit in the hlog file through HLog#completeCacheFlush.public void completeCacheFlush(final byte [] encodedRegionName, final byte [] tableName, final long logSeqId, final boolean isMetaRegion){...HLogKey key = makeKey(encodedRegionName, tableName, logSeqId, System.currentTimeMillis(), HConstants.DEFAULT_CLUSTER_ID);...}when we make the hlog key, we use the seqId from the parameter, and it is generated by HLog#startCacheFlush,Here, we may append a lower seq id edit than the last edit in the hlog file.If it is the last edit log in the file, it may cause data loss.because HRegion#replayRecoveredEditsIfAny{...maxSeqId = Math.abs(Long.parseLong(fileName)); if (maxSeqId &lt;= minSeqId) { String msg = "Maximum sequenceid for this log is " + maxSeqId + " and minimum sequenceid for the region is " + minSeqId + ", skipped the whole file, path=" + edits; LOG.debug(msg); continue; }...}We may skip the splitted log file, because we use the lase edit's seq id as its file name, and consider this seqId as the max seq id in this log file.</description>
      <version>None</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
    </fixedFiles>
  </bug>
  <bug id="6087" opendate="2012-5-24 00:00:00" fixdate="2012-5-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add hbase-common module</summary>
      <description>Add an hbase-common module so common/utility classes can be pulled up out of hbase-server. This is not the moving of classes, just the general project setup.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.HBaseHomePath.java</file>
      <file type="M">hbase-common.pom.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestBytes.java</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-site.src.docbkx.developer.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.VersionAnnotation.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.VersionInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.Bytes.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.ImmutableBytesWritable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HBaseConfiguration.java</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-assembly.src.assembly.all.xml</file>
      <file type="M">hbase-assembly.pom.xml</file>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug id="6107" opendate="2012-5-25 00:00:00" fixdate="2012-5-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Distributed log splitting hangs even there is no task under /hbase/splitlog</summary>
      <description>Sometimes, master web UI shows the distributed log splitting is going on, waiting for one last task to be done. However, in ZK, there is no task under /hbase/splitlog at all.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="6109" opendate="2012-5-25 00:00:00" fixdate="2012-6-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve RIT performances during assignment on large clusters</summary>
      <description>The main points in this patch are: lowering the number of copy of the RIT list lowering the number of synchronization synchronizing on a region rather than on everythingIt also contains: some fixes around the RIT notification: the list was sometimes modified without a corresponding 'notify'. some tests flakiness correction, actually unrelated to this patch.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestDrainingServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterStatusServlet.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.Mocking.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestMasterObserver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MXBeanImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterDumpServlet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="6110" opendate="2012-5-27 00:00:00" fixdate="2012-6-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix TestInfoServers</summary>
      <description>With the recent port to modules, we broke a couple of tests, including this one. The fix needs to ensure that the webapp still works from the in-situ and packaged running of HBase.</description>
      <version>0.95.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-site.pom.xml</file>
      <file type="M">hbase-server.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-assembly.pom.xml</file>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug id="6117" opendate="2012-5-28 00:00:00" fixdate="2012-7-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Revisit default condition added to Switch cases in Trunk</summary>
      <description>We found that in some cases the default case in switch block was just throwing illegalArg Exception. There are cases where we may get some other state for which we should not throw IllegalArgException.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="6118" opendate="2012-5-28 00:00:00" fixdate="2012-5-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a testcase for HBASE-6065</summary>
      <description>It would be nice to have a testcase for HBASE-6065. Internally we have written a test case to simulate the problem. Thought that it would be better to contribute the same.</description>
      <version>None</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
    </fixedFiles>
  </bug>
  <bug id="6131" opendate="2012-5-29 00:00:00" fixdate="2012-5-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add attribution for code added by HBASE-5533 metrics</summary>
      <description>See the comment over in https://issues.apache.org/jira/browse/HBASE-5533?focusedCommentId=13283920&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13283920The metrics histogram code was copied w/o attribution. Fix.</description>
      <version>None</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.metrics.TestMetricsHistogram.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.metrics.TestExponentiallyDecayingSample.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.metrics.RegionServerMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.metrics.histogram.UniformSample.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.metrics.histogram.Snapshot.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.metrics.histogram.Sample.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.metrics.histogram.MetricsHistogram.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.metrics.histogram.ExponentiallyDecayingSample.java</file>
      <file type="M">hbase-server.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6138" opendate="2012-5-31 00:00:00" fixdate="2012-6-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HadoopQA not running findbugs [Trunk]</summary>
      <description>HadoopQA shows like -1 findbugs. The patch appears to cause Findbugs (version 1.3.9) to fail.But not able to see any reports linkWhen I checked the console output for the build I can see[INFO] --- findbugs-maven-plugin:2.4.0:findbugs (default-cli) @ hbase-common ---[INFO] Fork Value is true[INFO] ------------------------------------------------------------------------[INFO] Reactor Summary:[INFO] [INFO] HBase ............................................. SUCCESS [1.890s][INFO] HBase - Common .................................... FAILURE [2.238s][INFO] HBase - Server .................................... SKIPPED[INFO] HBase - Assembly .................................. SKIPPED[INFO] HBase - Site ...................................... SKIPPED[INFO] ------------------------------------------------------------------------[INFO] BUILD FAILURE[INFO] ------------------------------------------------------------------------[INFO] Total time: 4.856s[INFO] Finished at: Thu May 31 03:35:35 UTC 2012[INFO] Final Memory: 23M/154M[INFO] ------------------------------------------------------------------------[ERROR] Could not find resource '${parent.basedir}/dev-support/findbugs-exclude.xml'. -&gt; [Help 1][ERROR] Because of this error Findbugs is getting run!</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6160" opendate="2012-6-4 00:00:00" fixdate="2012-6-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>META entries from daughters can be deleted before parent entries</summary>
      <description>HBASE-5986 fixed and issue, where the client sees the META entry for the parent, but not the children. However, after the fix, we have seen the following issue in tests: Region A is split to -&gt; B, CRegion B is split to -&gt; D, EAfter some time, META entry for B is deleted since it is not needed anymore, but META entry for Region A stays in META (C still refers it). In this case, the client throws RegionOfflineException for B.</description>
      <version>0.92.2,0.94.0,0.95.2</version>
      <fixedVersion>0.92.2,0.94.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
    </fixedFiles>
  </bug>
  <bug id="6165" opendate="2012-6-5 00:00:00" fixdate="2012-8-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replication can overrun .META. scans on cluster re-start</summary>
      <description>When restarting a large set of regions on a reasonably small cluster the replication from another cluster tied up every xceiver meaning nothing could be onlined.</description>
      <version>None</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestPriorityRpc.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseRpcMetrics.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="6167" opendate="2012-6-5 00:00:00" fixdate="2012-6-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix xinclude for docs broke when we multi-moduled</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6177" opendate="2012-6-6 00:00:00" fixdate="2012-6-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add .idea to RAT excludes</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6178" opendate="2012-6-6 00:00:00" fixdate="2012-9-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LoadTest tool no longer packaged after the modularization</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.assembly.hadoop-two-compat.xml</file>
      <file type="M">src.assembly.hadoop-one-compat.xml</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6179" opendate="2012-6-6 00:00:00" fixdate="2012-6-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix stylesheet broke since multimodule and address feedback gotten in new comment system</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.ops.mgt.xml</file>
      <file type="M">src.docbkx.configuration.xml</file>
      <file type="M">src.docbkx.book.xml</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6182" opendate="2012-6-7 00:00:00" fixdate="2012-11-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make HBase works with jdk1.7</summary>
      <description>jdk1.7 is out for a while. HBase should support it.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestGetClosestAtOrBefore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.GetClosestRowBeforeTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.catalog.MetaReader.java</file>
    </fixedFiles>
  </bug>
  <bug id="6188" opendate="2012-6-7 00:00:00" fixdate="2012-6-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove the concept of table owner</summary>
      <description>The table owner concept was a design simplification in the initial drop.First, the design changes under review means only a user with GLOBAL CREATE permission can create a table, which will probably be an administrator.Then, granting implicit permissions may lead to oversights and it adds unnecessary conditionals to our code. So instead the administrator with GLOBAL CREATE permission should make the appropriate grants at table create time.</description>
      <version>0.94.0,0.94.1,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlLists.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="6192" opendate="2012-6-8 00:00:00" fixdate="2012-6-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document ACL matrix in the book</summary>
      <description>We have an excellent matrix at https://issues.apache.org/jira/secure/attachment/12531252/Security-ACL%20Matrix.pdf for ACL. Once the changes are done, we can adapt that and put it in the book, also add some more documentation about the new authorization features.</description>
      <version>0.94.1,0.95.2</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.security.xml</file>
    </fixedFiles>
  </bug>
  <bug id="62" opendate="2007-11-13 00:00:00" fixdate="2007-7-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbase] Allow user add arbitrary key/value pairs to table and column descriptors</summary>
      <description>Folks have asked if they can tag columns and tables with markings of their own designation. Examples include 'type' and 'descriptiion'.</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.util.TestMetaUtils.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.util.TestMigrate.java</file>
      <file type="M">src.testdata.HADOOP-2478-testdata.zip</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestTable.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.client.TestHTable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.Migrate.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.ThriftUtilities.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.TableHandler.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HAbstractScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HMasterInterface.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.UnmodifyableHTableDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.MetaScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.BloomFilterDescriptor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6201" opendate="2012-6-12 00:00:00" fixdate="2012-9-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase integration/system tests</summary>
      <description>Integration and general system tests have been discussed previously, and the conclusion is that we need to unify how we do "release candidate" testing (HBASE-6091).In this issue, I would like to discuss and agree on a general plan, and open subtickets for execution so that we can carry out most of the tests in HBASE-6091 automatically. Initially, here is what I have in mind: 1. Create hbase-it (or hbase-tests) containing forward port of HBASE-4454 (without any tests). This will allow integration test to be run with mvn verify 2. Add ability to run all integration/system tests on a given cluster. Smt like: mvn verify -Dconf=/etc/hbase/conf/ should run the test suite on the given cluster. (Right now we can launch some of the tests (TestAcidGuarantees) from command line). Most of the system tests will be client side, and interface with the cluster through public APIs. We need a tool on top of MiniHBaseCluster or improve HBaseTestingUtility, so that tests can interface with the mini cluster or the actual cluster uniformly.3. Port candidate unit tests to the integration tests module. Some of the candidates are: TestAcidGuarantees / TestAtomicOperation TestRegionBalancing (HBASE-6053) TestFullLogReconstruction TestMasterFailover TestImportExport TestMultiVersions / TestKeepDeletes TestFromClientSide TestShell and src/test/ruby TestRollingRestart Test**OnCluster Balancer testsThese tests should continue to be run as unit tests w/o any change in semantics. However, given an actual cluster, they should use that, instead of spinning a mini cluster. 4. Add more tests, especially, long running ingestion tests (goraci, BigTop's TestLoadAndVerify, LoadTestTool), and chaos monkey style fault tests. All suggestions welcome.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.developer.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6203" opendate="2012-6-12 00:00:00" fixdate="2012-7-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create hbase-it module</summary>
      <description>Create hbase-it, as per parent issue, and re-introduce HBASE-4454</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="621" opendate="2008-5-9 00:00:00" fixdate="2008-5-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make MAX_VERSIONS work like TTL: In scans and gets, check MAX_VERSIONs setting and return that many only rather than wait on compaction</summary>
      <description>HBASE-47 added specification of TTL on cells. The implementation checks cell timestamp against configured TTL before returning results scanning or getting. You can also set the maximum versions of a cell to keep. The maximum versions is not checked scanning or getting, only when we compact (We'll drop cells that are beyond the maximum version at compaction time). This issue is about adding check for maximum versions to gets and scans so that if you ask for all versions but have configured the store to only keep 3 versions, though 4 may have been inserted, you'll currently get 4 returned (if compactions have not had a chance to run).</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Memcache.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6211" opendate="2012-6-14 00:00:00" fixdate="2012-6-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Put latencies in jmx</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.metrics.TestMetricsMBeanBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.metrics.MetricsMBeanBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.metrics.histogram.MetricsHistogram.java</file>
    </fixedFiles>
  </bug>
  <bug id="6220" opendate="2012-6-15 00:00:00" fixdate="2012-7-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>PersistentMetricsTimeVaryingRate gets used for non-time-based metrics</summary>
      <description>PersistentMetricsTimeVaryingRate gets used for metrics that are not time-based, leading to confusing names such as "avg_time" for compaction size, etc. You hav to read the code in order to understand that this is actually referring to bytes, not seconds.</description>
      <version>0.95.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.metrics.RegionServerMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.metrics.MasterMetrics.java</file>
    </fixedFiles>
  </bug>
  <bug id="6223" opendate="2012-6-17 00:00:00" fixdate="2012-10-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document hbck improvements: HBASE-6173, HBASE-5360</summary>
      <description>We had a couple hbck improvements recently: HBASE-6173 and HBASE-5360.We should document them. Especially, for HBASE-5360, it's somethingone normally doesn't do.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6224" opendate="2012-6-18 00:00:00" fixdate="2012-6-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>add Pre and Post coprocessor hooks for BulkLoad</summary>
      <description></description>
      <version>0.94.1,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.SimpleRegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.java</file>
    </fixedFiles>
  </bug>
  <bug id="6236" opendate="2012-6-19 00:00:00" fixdate="2012-6-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Offline meta repair fails if the HBase base mount point is on a different cluster/volume than its parent in a ViewFS or similar FS</summary>
      <description>While building the .META. and &amp;#45;ROOT&amp;#45; from FS data alone (HBASE-4377), hbck tries to move the existing .META. and &amp;#45;ROOT&amp;#45; directories to a backup folder.This backup folder is created at the same level as the base HBase folder (e.g. /hbase-xxxxxx if the base HBase folder is '/hbase').In a federated HDFS like ViewFS and other similar FS implementations, it is not possible to rename files/directories across namespace volumes (ViewFS guide section 3.5) and as a result hbck crashes.A solution to this problem is to create the backup directory under the folder where HBase base folder has been mounted. This ensures that source and destination of rename operation are on the same namespace volume.Patch for 0.94 and trunk is attached for review. The patch modifies the location of the backup directory from '/hbase-xxxxxxx' to '/hbase/.hbcktmp-xxxxxxx'</description>
      <version>None</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.hbck.OfflineMetaRepair.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="6238" opendate="2012-6-19 00:00:00" fixdate="2012-6-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Grant on META not taking effect</summary>
      <description>User is not able to perform authorized operations on Meta.</description>
      <version>0.94.0,0.94.1,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlLists.java</file>
    </fixedFiles>
  </bug>
  <bug id="6242" opendate="2012-6-20 00:00:00" fixdate="2012-6-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>New UI should color task list entries</summary>
      <description>The old UI changed the background color of tasklist entries according to their final status: green if successful, yellow if aborted, red if failed. Bring this back in the new UI.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="6243" opendate="2012-6-20 00:00:00" fixdate="2012-6-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>New UI should space detailed latency columns equally</summary>
      <description>Spacing between the columns of the detailed latencies tab should be roughly equal. Round latencies to two digits right of decimal point.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="6245" opendate="2012-6-20 00:00:00" fixdate="2012-8-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upon page refresh new UI should return to the previously selected tab</summary>
      <description></description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="6247" opendate="2012-6-20 00:00:00" fixdate="2012-6-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[REST] HTablePool.putTable is deprecated</summary>
      <description>HTablePool.putTable is deprecated, use returnTable instead.</description>
      <version>0.92.2,0.94.1,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.SchemaResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerResultGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RowResultGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RowResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RegionsResource.java</file>
    </fixedFiles>
  </bug>
  <bug id="6252" opendate="2012-6-21 00:00:00" fixdate="2012-6-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TABLE ADMIN should be allowed to relocate regions</summary>
      <description></description>
      <version>0.94.0,0.94.1,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug id="6253" opendate="2012-6-21 00:00:00" fixdate="2012-7-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Do not allow user to disable or drop ACL table</summary>
      <description>Currently HTableDescriptor.isLegalTableName API doesn't check for the acl table name, due to this user can able to disable/enable/drop/create the acl table.</description>
      <version>0.94.1,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug id="6256" opendate="2012-6-21 00:00:00" fixdate="2012-6-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Zk Dump was missed in the move to new UI</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.css.hbase.css</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.zk.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.tablesDetailed.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="6260" opendate="2012-6-22 00:00:00" fixdate="2012-9-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>balancer state should be stored in ZK</summary>
      <description>See: https://issues.apache.org/jira/browse/HBASE-5953?focusedCommentId=13270200&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13270200And: https://issues.apache.org/jira/browse/HBASE-5630?focusedCommentId=13399225&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13399225In short, we need to move the balancer state to ZK so that it won't have to be restarted if the master dies.</description>
      <version>0.95.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.LoadBalancerTracker.java</file>
    </fixedFiles>
  </bug>
  <bug id="6265" opendate="2012-6-25 00:00:00" fixdate="2012-7-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Calling getTimestamp() on a KV in cp.prePut() causes KV not to be flushed</summary>
      <description>There is an issue when you call getTimestamp() on any KV handed into a Coprocessor's prePut(). It initializes the internal "timestampCache" variable. When you then pass it to the normal processing, the region server sets the time to the server time in case you have left it unset from the client side (updateLatestStamp() call). The TimeRangeTracker then calls getTimestamp() later on to see if it has to include the KV, but instead of getting the proper time it sees the cached timestamp from the prePut() call.</description>
      <version>0.92.0,0.94.0,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestKeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
    </fixedFiles>
  </bug>
  <bug id="6274" opendate="2012-6-26 00:00:00" fixdate="2012-6-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Proto files should be in the same palce</summary>
      <description>Currently, proto files are under hbase-server/src/main/protobuf and hbase-server/src/protobuf. It's better to put them together.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.protobuf.RegionServerStatus.proto</file>
      <file type="M">hbase-server.src.protobuf.Client.proto</file>
      <file type="M">hbase-server.src.protobuf.Admin.proto</file>
    </fixedFiles>
  </bug>
  <bug id="6292" opendate="2012-6-29 00:00:00" fixdate="2012-6-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compact can skip the security access control</summary>
      <description>When client sends compact command to rs, the rs just create a CompactionRequest, and then put it into the thread pool to process the CompactionRequest. And when the region do the compact, it uses the rs's ugi to process the compact, so the compact can successfully done.Example:user "mapred" do not have permission "Admin",hbase(main):001:0&gt; user_permission 'Security'User Table,Family,Qualifier:Permission mapred Security,f1,c1: [Permission: actions=READ,WRITE] hbase(main):004:0&gt; put 'Security', 'r6', 'f1:c1', 'v9'0 row(s) in 0.0590 secondshbase(main):005:0&gt; put 'Security', 'r6', 'f1:c1', 'v10'0 row(s) in 0.0040 secondshbase(main):006:0&gt; compact 'Security'0 row(s) in 0.0260 secondsMaybe we can add permission check in the preCompactSelection() ?</description>
      <version>0.94.0,0.94.1,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactionRequestor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.java</file>
    </fixedFiles>
  </bug>
  <bug id="6295" opendate="2012-6-30 00:00:00" fixdate="2012-6-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Possible performance improvement in client batch operations: presplit and send in background</summary>
      <description>today batch algo is:for Operation o: List&lt;Op&gt;{ add o to todolist if todolist &gt; maxsize or o last in list split todolist per location send split lists to region servers clear todolist wait}We could: create immediately the final object instead of an intermediate array split per location immediately instead of sending when the list as a whole is full, send it when there is enough data for a single locationIt would be:for Operation o: List&lt;Op&gt;{ get location add o to todo location.todolist if (location.todolist &gt; maxLocationSize) send location.todolist to region server clear location.todolist // don't wait, continue the loop}send remainingwaitIt's not trivial to write if you add error management: retried list must be shared with the operations added in the todolist. But it's doable.It's interesting mainly for 'big' writes</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ServerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Action.java</file>
      <file type="M">hbase-server.src.test.resources.hbase-site.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTableMultiplexer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
    </fixedFiles>
  </bug>
  <bug id="6303" opendate="2012-7-2 00:00:00" fixdate="2012-7-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HCD.setCompressionType should use Enum support for storing compression types as strings</summary>
      <description>Let's not require an update to HCD every time the HFile compression enum is changed.</description>
      <version>0.94.0,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="6314" opendate="2012-7-3 00:00:00" fixdate="2012-7-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fast fail behavior for unauthenticated user</summary>
      <description>In case of unauthenticated users in secure hbase, hbase shell does a connection retry at two levels:a) HConnection: It retries hbase.client.retries.number times in the getMaster()b) HBaseAdmin: it again retries hbase.client.retries.number times in its ctrSo, hbase shell retries square number of times of the configured setting. We can make it failfast (no retries) in case the user is not authenticated (no valid kerberos credentials).</description>
      <version>0.92.0,0.94.0,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="6316" opendate="2012-7-3 00:00:00" fixdate="2012-10-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Confirm can upgrade to 0.96 from 0.94 by just stopping and restarting</summary>
      <description>Over in HBASE-6294, LarsH says you have to currently clear zk to get a 0.96 to start over data written by a 0.94. Need to fix it so don't have to do this &amp;#8211; that zk state left over gets auto-migrated.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.Reference.java</file>
    </fixedFiles>
  </bug>
  <bug id="6317" opendate="2012-7-3 00:00:00" fixdate="2012-12-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Master clean start up and Partially enabled tables make region assignment inconsistent.</summary>
      <description>If we have a table in partially enabled state (ENABLING) then on HMaster restart we treat it as a clean cluster start up and do a bulk assign. Currently in 0.94 bulk assign will not handle ALREADY_OPENED scenarios and it leads to region assignment problems. Analysing more on this we found that we have better way to handle these scenarios.if (false == checkIfRegionBelongsToDisabled(regionInfo) &amp;&amp; false == checkIfRegionsBelongsToEnabling(regionInfo)) { synchronized (this.regions) { regions.put(regionInfo, regionLocation); addToServers(regionLocation, regionInfo); }We dont add to regions map so that enable table handler can handle it. But as nothing is added to regions map we think it as a clean cluster start up.Will come up with a patch tomorrow.</description>
      <version>None</version>
      <fixedVersion>0.94.4,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.EnableTableHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="6332" opendate="2012-7-5 00:00:00" fixdate="2012-7-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve POM for better integration with downstream ivy projects</summary>
      <description>Currently there are 2 issues affecting the downstream ivy projects: no default value for slf4j.version dependency on a non-standard junit artifactI suggest we correct both of these in order to ensure the smooth upgrade path for things like Sqoop.</description>
      <version>0.94.1,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6355" opendate="2012-7-8 00:00:00" fixdate="2012-7-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow HBase to compile against JDK7</summary>
      <description></description>
      <version>0.94.1,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6357" opendate="2012-7-9 00:00:00" fixdate="2012-7-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Failed distributed log splitting stuck on master web UI</summary>
      <description>Failed distributed log splitting MonitoredTask is stuck on the master web UI since it is not aborted.</description>
      <version>None</version>
      <fixedVersion>0.92.2,0.94.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="6368" opendate="2012-7-10 00:00:00" fixdate="2012-5-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade Guava for critical performance bug fix</summary>
      <description>The bug is http://code.google.com/p/guava-libraries/issues/detail?id=1055See discussion under 'Upgrade to Guava 12.0.1: Performance bug in CacheBuilder/LoadingCache fixed!'</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6373" opendate="2012-7-11 00:00:00" fixdate="2012-7-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add more context information to audit log messages</summary>
      <description>The attached patch adds more information to the audit log messages; namely, it includes the IP address where the request originated, if it's available.The patch is against trunk, but I've tested it against the 0.92 branch. I didn't find any unit test for this code, please let me know if I missed something.</description>
      <version>0.94.2,0.95.2</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug id="6377" opendate="2012-7-12 00:00:00" fixdate="2012-7-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBASE-5533 metrics miss all operations submitted via MultiAction</summary>
      <description>A client application (LoadTestTool) calls put() on HTables. Internally to the HBase client those puts are batched into MultiActions. The total number of put operations shown in the RegionServer's put metrics histogram never increases from 0 even though millions of such operations are made. Needless to say the latency for those operations are not measured either. The value of HBASE-5533 metrics are suspect given the client will batch put and delete ops like this.I had a fix in progress but HBASE-6284 messed it up. Before, MultiAction processing in HRegionServer would distingush between puts and deletes and dispatch them separately. It was easy to account for the time for them. Now both puts and deletes are submitted in batch together as mutations.</description>
      <version>0.94.1,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.metrics.RegionServerMetrics.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="6380" opendate="2012-7-12 00:00:00" fixdate="2012-7-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>bulkload should update the store.storeSize</summary>
      <description>After bulkloading some HFiles into the Table, we found the force-split didn't work because of the MidKey == NULL. Only if we re-booted the HBase service, the force-split can work normally.</description>
      <version>0.94.0,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
    </fixedFiles>
  </bug>
  <bug id="6382" opendate="2012-7-12 00:00:00" fixdate="2012-7-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade Jersey to 1.8 to match Hadoop 1 and 2</summary>
      <description>Upgrade Jersey dependency from 1.4 to 1.8 to match Hadoop dependencies.</description>
      <version>0.90.7,0.92.2,0.94.2,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6384" opendate="2012-7-12 00:00:00" fixdate="2012-7-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbck should group together those sidelined regions need to be bulk loaded later</summary>
      <description>Currently, hbck sidelines some regions to break big overlap groups to avoid possible compaction and region split. These sidelined regions should bebulk loaded back later. Information about these regions is in the output.It will be much easier to group them together under the same sideline rootdir,for example, /hbase/.hbck/to_be_loaded/. If so, even we lose the outputfile, we still know what regions to load back.</description>
      <version>None</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="6409" opendate="2012-7-17 00:00:00" fixdate="2012-9-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create histogram class for metrics 2</summary>
      <description>Create the replacement for MetricsHistogram and PersistantTimeVaryingRate classes.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.metrics.MasterMetrics.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.DynamicMetricsRegistry.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.metrics.BaseMetricsSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.metrics.MasterMetricsSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-hadoop1-compat.src.main.java.org.apache.hadoop.metrics2.lib.DynamicMetricsRegistry.java</file>
      <file type="M">hbase-hadoop1-compat.src.main.java.org.apache.hadoop.hbase.metrics.BaseMetricsSourceImpl.java</file>
      <file type="M">hbase-hadoop1-compat.src.main.java.org.apache.hadoop.hbase.master.metrics.MasterMetricsSourceImpl.java</file>
      <file type="M">hbase-hadoop1-compat.pom.xml</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.metrics.BaseMetricsSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.master.metrics.MasterMetricsSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="6411" opendate="2012-7-17 00:00:00" fixdate="2012-8-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move Master Metrics to metrics 2</summary>
      <description>Move Master Metrics to metrics 2</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMXBean.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.metrics.ReplicationSourceMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.metrics.ReplicationSinkMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MXBeanImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MXBean.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.metrics.MasterMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-hadoop2-compat.src.test.java.org.apache.hadoop.hbase.replication.regionserver.metrics.ReplicationMetricsSourceImplTest.java</file>
      <file type="M">hbase-hadoop2-compat.src.test.java.org.apache.hadoop.hbase.metrics.BaseMetricsSourceImplTest.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.HBaseMetricsFactory.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.replication.regionserver.metrics.ReplicationMetricsSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.metrics.BaseMetricsSourceImpl.java</file>
      <file type="M">hbase-hadoop1-compat.src.test.java.org.apache.hadoop.hbase.replication.regionserver.metrics.ReplicationMetricsSourceImplTest.java</file>
      <file type="M">hbase-hadoop1-compat.src.test.java.org.apache.hadoop.hbase.metrics.BaseMetricsSourceImplTest.java</file>
      <file type="M">hbase-hadoop1-compat.src.main.java.org.apache.hadoop.hbase.replication.regionserver.metrics.ReplicationMetricsSourceImpl.java</file>
      <file type="M">hbase-hadoop1-compat.src.main.java.org.apache.hadoop.hbase.metrics.BaseMetricsSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.test.java.org.apache.hadoop.hbase.replication.regionserver.metrics.ReplicationMetricsSourceFactoryTest.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.replication.regionserver.metrics.ReplicationMetricsSourceFactory.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.replication.regionserver.metrics.ReplicationMetricsSource.java</file>
      <file type="M">hbase-hadoop-compat.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6412" opendate="2012-7-17 00:00:00" fixdate="2012-9-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move external servers to metrics2 (thrift,thrift2,rest)</summary>
      <description>Implement metrics2 for all the external servers: Thrift Thrift2 Rest</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.developer.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.thrift.TestThriftServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.thrift.TestCallQueue.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.thrift2.TestThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestCheckTestClasses.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestRowResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.ThriftMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.metrics.RESTStatistics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.metrics.RESTMetrics.java</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-hadoop2-compat.src.test.java.org.apache.hadoop.hbase.replication.regionserver.metrics.ReplicationMetricsSourceImplTest.java</file>
      <file type="M">hbase-hadoop2-compat.src.test.java.org.apache.hadoop.hbase.metrics.BaseMetricsSourceImplTest.java</file>
      <file type="M">hbase-hadoop2-compat.src.test.java.org.apache.hadoop.hbase.master.metrics.MasterMetricsSourceImplTest.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.DynamicMetricsRegistry.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.replication.regionserver.metrics.ReplicationMetricsSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.metrics.BaseMetricsSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.metrics.MasterMetricsSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.metrics.MasterMetricsSourceFactoryImpl.java</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-hadoop1-compat.src.test.java.org.apache.hadoop.hbase.replication.regionserver.metrics.ReplicationMetricsSourceImplTest.java</file>
      <file type="M">hbase-hadoop1-compat.src.test.java.org.apache.hadoop.hbase.metrics.BaseMetricsSourceImplTest.java</file>
      <file type="M">hbase-hadoop1-compat.src.test.java.org.apache.hadoop.hbase.master.metrics.MasterMetricsSourceImplTest.java</file>
      <file type="M">hbase-hadoop1-compat.src.main.java.org.apache.hadoop.metrics2.lib.DynamicMetricsRegistry.java</file>
      <file type="M">hbase-hadoop1-compat.src.main.java.org.apache.hadoop.hbase.metrics.BaseMetricsSourceImpl.java</file>
      <file type="M">hbase-hadoop1-compat.src.main.java.org.apache.hadoop.hbase.master.metrics.MasterMetricsSourceImpl.java</file>
      <file type="M">hbase-hadoop1-compat.src.main.java.org.apache.hadoop.hbase.master.metrics.MasterMetricsSourceFactoryImpl.java</file>
      <file type="M">hbase-hadoop1-compat.pom.xml</file>
      <file type="M">hbase-hadoop-compat.src.test.java.org.apache.hadoop.hbase.replication.regionserver.metrics.ReplicationMetricsSourceFactoryTest.java</file>
      <file type="M">hbase-hadoop-compat.src.test.java.org.apache.hadoop.hbase.master.metrics.MasterMetricsSourceFactoryTest.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.metrics.BaseMetricsSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.CompatibilitySingletonFactory.java</file>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  <bug id="6419" opendate="2012-7-18 00:00:00" fixdate="2012-9-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>PersistentMetricsTimeVaryingRate gets used for non-time-based metrics (part2 of HBASE-6220)</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.metrics.RegionServerMetrics.java</file>
    </fixedFiles>
  </bug>
  <bug id="6435" opendate="2012-7-20 00:00:00" fixdate="2012-8-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reading WAL files after a recovery leads to time lost in HDFS timeouts when using dead datanodes</summary>
      <description>HBase writes a Write-Ahead-Log to revover from hardware failure. This log is written on hdfs.Through ZooKeeper, HBase gets informed usually in 30s that it should start the recovery process. This means reading the Write-Ahead-Log to replay the edits on the other servers.In standards deployments, HBase process (regionserver) are deployed on the same box as the datanodes.It means that when the box stops, we've actually lost one of the edits, as we lost both the regionserver and the datanode.As HDFS marks a node as dead after ~10 minutes, it appears as available when we try to read the blocks to recover. As such, we are delaying the recovery process by 60 seconds as the read will usually fail with a socket timeout. If the file is still opened for writing, it adds an extra 20s + a risk of losing edits if we connect with ipc to the dead DN.Possible solutions are: shorter dead datanodes detection by the NN. Requires a NN code change. better dead datanodes management in DFSClient. Requires a DFS code change. NN customisation to write the WAL files on another DN instead of the local one. reordering the blocks returned by the NN on the client side to put the blocks on the same DN as the dead RS at the end of the priority queue. Requires a DFS code change or a kind of workaround.The solution retained is the last one. Compared to what was discussed on the mailing list, the proposed patch will not modify HDFS source code but adds a proxy. This for two reasons: Some HDFS functions managing block orders are static (MD5MD5CRC32FileChecksum). Implementing the hook in the DFSClient would require to implement partially the fix, change the DFS interface to make this function non static, or put the hook static. None of these solution is very clean. Adding a proxy allows to put all the code in HBase, simplifying dependency management.Nevertheless, it would be better to have this in HDFS. But this solution allows to target the last version only, and this could allow minimal interface changes such as non static methods.Moreover, writing the blocks to the non local DN would be an even better solution long term.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLog.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MiniHBaseCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ServerName.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.fs.HFileSystem.java</file>
    </fixedFiles>
  </bug>
  <bug id="6436" opendate="2012-7-20 00:00:00" fixdate="2012-8-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Netty should be moved off of snapshots.</summary>
      <description>Netty is currently at 3.5.0.final-SNAPSHOT the final 3.5.0.Final should be used when possible so that repositories aren't queried when not needed.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6437" opendate="2012-7-21 00:00:00" fixdate="2012-8-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Avoid admin.balance during master initialize</summary>
      <description>In HBASE-5850 many of the admin operations have been blocked till the master initializes. But the balancer is not. So this JIRA is to extend the PleaseHoldException in case of admin.balance() call before master is initialized.</description>
      <version>None</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="6438" opendate="2012-7-21 00:00:00" fixdate="2012-9-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RegionAlreadyInTransitionException needs to give more info to avoid assignment inconsistencies</summary>
      <description>Seeing some of the recent issues in region assignment, RegionAlreadyInTransitionException is one reason after which the region assignment may or may not happen(in the sense we need to wait for the TM to assign).In HBASE-6317 we got one problem due to RegionAlreadyInTransitionException on master restart.Consider the following case, due to some reason like master restart or external assign call, we try to assign a region that is already getting opened in a RS.Now the next call to assign has already changed the state of the znode and so the current assign that is going on the RS is affected and it fails. The second assignment that started also fails getting RAITE exception. Finally both assignments not carrying on. Idea is to find whether any such RAITE exception can be retried or not.Here again we have following cases like where-&gt; The znode is yet to transitioned from OFFLINE to OPENING in RS-&gt; RS may be in the step of openRegion.-&gt; RS may be trying to transition OPENING to OPENED.-&gt; RS is yet to add to online regions in the RS side.Here in openRegion() and updateMeta() any failures we are moving the znode to FAILED_OPEN. So in these cases getting an RAITE should be ok. But in other cases the assignment is stopped.The idea is to just add the current state of the region assignment in the RIT map in the RS side and using that info we can determine whether the assignment can be retried or not on getting an RAITE.Considering the current work going on in AM, pls do share if this is needed atleast in the 0.92/0.94 versions?</description>
      <version>None</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="6439" opendate="2012-7-22 00:00:00" fixdate="2012-10-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Ignore .archive directory as a table</summary>
      <description>From a recent test run:2012-07-22 02:27:30,699 WARN &amp;#91;IPC Server handler 0 on 47087&amp;#93; util.FSTableDescriptors(168): The following folder is in HBase's root directory and doesn't contain a table descriptor, do consider deleting it: .archiveWith the addition of HBASE-5547, table-level folders are no-longer all table folders. FSTableDescriptors needs to then have a 'gold-list' that we can update with directories that aren't tables so we don't have this kind of thing showing up in the logs.Currently, we have the following block: invocations++; if (HTableDescriptor.ROOT_TABLEDESC.getNameAsString().equals(tablename)) Unknown macro: { cachehits++; return HTableDescriptor.ROOT_TABLEDESC; } if (HTableDescriptor.META_TABLEDESC.getNameAsString().equals(tablename)) Unknown macro: { cachehits++; return HTableDescriptor.META_TABLEDESC; } to handle special cases, but that's a bit clunky and not clean in terms of table-level directories that need to be ignored.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHFileArchiveUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestFSTableDescriptors.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.cleaner.TestHFileCleaner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.example.TestZooKeeperTableArchiveClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HFileArchiveUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.HFileLink.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="6441" opendate="2012-7-22 00:00:00" fixdate="2012-9-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>MasterFS doesn&amp;#39;t set scheme for internal FileSystem</summary>
      <description>FSUtils.getRootDir() just takes a configuration object, which is used to:1) Get the name of the root directory2) Create a filesystem (based on the configured scheme)3) Qualify the root onto the filesystemHowever, the FileSystem from the master filesystem won't generate the correctly qualified root directory under hadoop-2.0 (though it works fine on hadoop-1.0). Seems to be an issue with the configuration parameters.</description>
      <version>0.94.2,0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
    </fixedFiles>
  </bug>
  <bug id="6445" opendate="2012-7-24 00:00:00" fixdate="2012-7-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>rat check fails if hs_err_pid26514.log dropped in tests</summary>
      <description>Let test fail because jvm crashed rather than because of rat license complaint</description>
      <version>None</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6460" opendate="2012-7-26 00:00:00" fixdate="2012-8-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbck "-repairHoles" usage inconsistent with "-fixHdfsOrphans"</summary>
      <description>According to the hbck's help info, shortcut - "-repairHoles" will enable "-fixHdfsOrphans" as below. -repairHoles Shortcut for -fixAssignments -fixMeta -fixHdfsHoles -fixHdfsOrphansHowever, in the implementation, the function "fsck.setFixHdfsOrphans(false);" is called in "-repairHoles". This is not consistent with the usage information.</description>
      <version>0.94.0,0.95.2</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="6466" opendate="2012-7-27 00:00:00" fixdate="2012-2-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable multi-thread for memstore flush</summary>
      <description>If the KV is large or Hlog is closed with high-pressure putting, we found memstore is often above the high water mark and block the putting.So should we enable multi-thread for Memstore Flush?Some performance test data for reference,1.test environment ： random writting；upper memstore limit 5.6GB;lower memstore limit 4.8GB;400 regions per regionserver；row len=50 bytes, value len=1024 bytes;5 regionserver, 300 ipc handler per regionserver;5 client, 50 thread handler per client for writing2.test results:one cacheFlush handler, tps: 7.8k/s per regionserver, Flush:10.1MB/s per regionserver, appears many aboveGlobalMemstoreLimit blockingtwo cacheFlush handlers, tps: 10.7k/s per regionserver, Flush:12.46MB/s per regionserver,200 thread handler per client &amp; two cacheFlush handlers, tps:16.1k/s per regionserver, Flush:18.6MB/s per regionserver</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRolling.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Threads.java</file>
    </fixedFiles>
  </bug>
  <bug id="6476" opendate="2012-7-30 00:00:00" fixdate="2012-12-30 01:00:00" resolution="Won&amp;#39;t Fix">
    <buginformation>
      <summary>Replace all occurrances of System.currentTimeMillis() with EnvironmentEdge equivalent</summary>
      <description>There are still some areas where System.currentTimeMillis() is used in HBase. In order to make all parts of the code base testable and (potentially) to be able to configure HBase's notion of time, this should be generally be replaced with EnvironmentEdgeManager.currentTimeMillis().How hard would it be to add a maven task that checks for that, so we do not introduce System.currentTimeMillis back in the future?</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperNodeTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.Sleeper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.MetaUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.Merge.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.JVMClusterUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HMerge.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsckRepair.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSHDFSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.Canary.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.TBoundedThreadPoolServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerResultGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.Client.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.metrics.ReplicationSourceMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.metrics.ReplicationSinkMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.RegionTransition.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Threads.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.catalog.CatalogTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.Chore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Delete.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.MetaScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ServerCallable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HServerInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseRPC.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.ProtobufRpcEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HFileOutputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.ImportTsv.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableRecordReaderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.DefaultLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.GeneralBulkAssigner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DeleteTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DisableTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.EnableTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionState.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.metrics.MetricsRate.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.MemoryBoundedLogMessageBuffer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.TaskMonitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.GetClosestRowBeforeTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Leases.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.LogRoller.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.metrics.RegionServerMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitLogWorker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
    </fixedFiles>
  </bug>
  <bug id="6477" opendate="2012-7-30 00:00:00" fixdate="2012-8-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use PB filter definitions in RPC</summary>
      <description>Use the filters introduced in HBASE-6454 in the rpc so they are extensible</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.protobuf.Filter.proto</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestSerialization.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.TestHbaseObjectWritable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestSingleColumnValueFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestRandomRowFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestPrefixFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestPageFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestInclusiveStopFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestFilterList.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestColumnPaginationFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorEndpoint.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScan.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestGet.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAttributes.java</file>
      <file type="M">hbase-server.src.main.protobuf.hbase.proto</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.HbaseObjectWritable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Append.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Get.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Row.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.RowMutations.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.BinaryComparator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.BinaryPrefixComparator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.BitComparator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.ColumnCountGetFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.ColumnPaginationFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.ColumnPrefixFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.ColumnRangeFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.CompareFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.DependentColumnFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.FamilyFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.Filter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.FilterBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.FilterList.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.FilterWrapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.FirstKeyOnlyFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.FirstKeyValueMatchingQualifiersFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.FuzzyRowFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.InclusiveStopFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.KeyOnlyFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.MultipleColumnPrefixFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.NullComparator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.PageFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.PrefixFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.QualifierFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.RandomRowFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.RegexStringComparator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.RowFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.SingleColumnValueExcludeFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.SingleColumnValueFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.SkipFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.SubstringComparator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.TimestampsFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.ValueFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.WhileMatchFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.WritableByteArrayComparable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ClientProtos.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.generated.FilterProtos.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlFilter.java</file>
      <file type="M">hbase-server.src.main.protobuf.Client.proto</file>
    </fixedFiles>
  </bug>
  <bug id="6489" opendate="2012-8-1 00:00:00" fixdate="2012-8-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Incorrect TaskTracker logfile name</summary>
      <description>http://hbase.apache.org/book/trouble.log.html"TaskTracker: $HADOOP_HOME/logs/hadoop-&lt;user&gt;jobtracker&lt;hostname&gt;.log"should be "TaskTracker: $HADOOP_HOME/logs/hadoop-&lt;user&gt;tasktracker&lt;hostname&gt;.log"</description>
      <version>0.90.7,0.92.2,0.92.3,0.94.2,0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.troubleshooting.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6496" opendate="2012-8-2 00:00:00" fixdate="2012-8-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Example ZK based scan policy</summary>
      <description>Provide an example of a RegionServer that listens to a ZK node to learn about what set of KVs can safely be deleted during a compaction.</description>
      <version>None</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.example.TestZooKeeperScanPolicyObserver.java</file>
    </fixedFiles>
  </bug>
  <bug id="652" opendate="2008-5-29 00:00:00" fixdate="2008-6-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>dropping table fails silently if table isn&amp;#39;t disabled</summary>
      <description>Rather than fail silently, hbase should throw an exception</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6553" opendate="2012-8-9 00:00:00" fixdate="2012-8-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove Avro Gateway</summary>
      <description>The avro gateway was deprected in 0.94. Remove it in 0.96</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">bin.hbase</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.avro.TestAvroUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.avro.TestAvroServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.avro.package.html</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.avro.AvroUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.avro.AvroServer.java</file>
      <file type="M">hbase-server.src.main.avro.hbase.avpr</file>
    </fixedFiles>
  </bug>
  <bug id="6574" opendate="2012-8-13 00:00:00" fixdate="2012-8-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add HBase Ref Card pointer to Ref Guide</summary>
      <description>The HBase Refcard is at http://refcardz.dzone.com/refcardz/hbaseMaybe it belongs to Appendix F? dmeil?</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6577" opendate="2012-8-14 00:00:00" fixdate="2012-6-14 01:00:00" resolution="Won&amp;#39;t Fix">
    <buginformation>
      <summary>RegionScannerImpl.nextRow() should seek to next row</summary>
      <description>RegionScannerImpl.nextRow() is called when a filter filters the entire row. In that case we should seek to the next row rather then iterating over all versions of all columns to get there.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="6585" opendate="2012-8-14 00:00:00" fixdate="2012-12-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Audit log messages should contain info about the higher level operation being executed</summary>
      <description>Currently, audit log messages contains the "action" for which access was checked; this is one of READ, WRITE, CREATE or ADMIN.These give very little information to the person digging into the logs about what was done, though. You can't ask "who deleted rows from table x?", because "delete" is translated to a "WRITE" action.It would be nice if the audit logs contained the higher-level operation, either replacing or in addition to the RWCA information.</description>
      <version>0.95.2</version>
      <fixedVersion>0.94.4,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">conf.log4j.properties</file>
    </fixedFiles>
  </bug>
  <bug id="6594" opendate="2012-8-16 00:00:00" fixdate="2012-8-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move tasks section above regions section in RegionServer UI</summary>
      <description>With the new RegionServer UI, at the top of the page is the server metrics tab, then the region list, then the task list, the software attributes. The region list could be lengthy, so scrolling down to find the task list can take some time. Every refresh of the page resets the view to &amp;#91;0,0&amp;#93;. Therefore "at a glance" information should come first, "above the fold", statistics at the top followed by the tasks section.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="6595" opendate="2012-8-16 00:00:00" fixdate="2012-8-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Wrong book author name on Other HBase Resource page</summary>
      <description>There is a typing miss of the HBase Administration Cookbook's author name on the Other HBase Resource page.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.resources.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6604" opendate="2012-8-17 00:00:00" fixdate="2012-8-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bump log4j to 1.2.17</summary>
      <description>Hadoop bumped to 1.2.17 log4j (HADOOP-8687), we should probably as well.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6606" opendate="2012-8-17 00:00:00" fixdate="2012-8-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Test for reconnecting with HBaseAdmin using unmanaged HConnection</summary>
      <description>HBASE-5058 allowed HBaseAdmin to work with an existing and unmanaged HConnection. The retry semantics of managed vs unmanaged connections are different. From the JIRA:"For an HConnection that is passed from the outside, it has to be possible to try again. So if the HConnection is managed we retain the old behavior (i.e. only try once, give up after that, even if that failed).For an unmanaged connection we try again unless we actually found a master. ."I couldn't find any test of this behavior, only that the HBaseAdmin works with an unmanaged connection, i.e. no retry testing.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
    </fixedFiles>
  </bug>
  <bug id="6677" opendate="2012-8-28 00:00:00" fixdate="2012-9-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Random ZooKeeper port in test can overrun max port</summary>
      <description>while (true) { try { standaloneServerFactory = new NIOServerCnxnFactory(); standaloneServerFactory.configure( new InetSocketAddress(tentativePort), configuration.getInt(HConstants.ZOOKEEPER_MAX_CLIENT_CNXNS, 1000)); } catch (BindException e) { LOG.debug("Failed binding ZK Server to client port: " + tentativePort); // This port is already in use, try to use another. tentativePort++; continue; } break; }In the case of failure and all the above ports have already been binded, you can extend past the max port. Need to check against a max value.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.java</file>
    </fixedFiles>
  </bug>
  <bug id="6679" opendate="2012-8-28 00:00:00" fixdate="2012-9-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RegionServer aborts due to race between compaction and split</summary>
      <description>In our nightlies, we have seen RS aborts due to compaction and split racing. Original parent file gets deleted after the compaction, and hence, the daughters don't find the parent data file. The RS kills itself when this happens. Will attach a snippet of the relevant RS logs.</description>
      <version>None</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="668" opendate="2008-6-5 00:00:00" fixdate="2008-6-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBASE-533 broke build</summary>
      <description>Build was broken when I committed HBASE-533. Bunch of tests started to fail (I didn't run tests before committing).</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.webapps.master.regionhistorian.jsp</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestRegionRebalancing.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestGlobalMemcacheLimit.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.RegionHistorian.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.RegionManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ProcessServerShutdown.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ProcessRegionOpen.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.BaseScanner.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6688" opendate="2012-8-29 00:00:00" fixdate="2012-9-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>folder referred by thrift demo app instructions is outdated</summary>
      <description>Due to the source tree module change for 0.96, the instructions in the thrift demo example don't match the folder structure any more.In the instruction, it is referring to:../../../src/main/resources/org/apache/hadoop/hbase/thrift/Hbase.thriftit should be../../hbase-server/src/main/resources/org/apache/hadoop/hbase/thrift/Hbase.thrift</description>
      <version>0.95.2</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.package.html</file>
      <file type="M">hbase-server.src.main.javadoc.org.apache.hadoop.hbase.thrift.package.html</file>
    </fixedFiles>
  </bug>
  <bug id="669" opendate="2008-6-6 00:00:00" fixdate="2008-8-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>MultiRegion transactions with Optimistic Concurrency Control</summary>
      <description>We have a need for ACID transactions across tables. This issue is about adding transactions which span multiple regions. We do not envision many competing writes, and will be read-dominated in general. This makes Optimistic Concurrency Control (OCC) seem like the way to go.</description>
      <version>None</version>
      <fixedVersion>0.18.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.transactional.TestHLogRecovery.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.HBaseTestCase.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HLogKey.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HLogEdit.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HLog.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HMerge.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.ServerCallable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6698" opendate="2012-8-30 00:00:00" fixdate="2012-9-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Refactor checkAndPut and checkAndDelete to use doMiniBatchMutation</summary>
      <description>Currently the checkAndPut and checkAndDelete api internally calls the internalPut and internalDelete. May be we can just call doMiniBatchMutationonly. This will help in future like if we have some hooks and the CPhandles certain cases in the doMiniBatchMutation the same can be done whiledoing a put thro checkAndPut or while doing a delete thro checkAndDelete.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="6742" opendate="2012-9-7 00:00:00" fixdate="2012-9-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change default test parallelisation level to 5</summary>
      <description>Tests will be faster.Not visible if a test hangs for 15 minutes. But they should not hang.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6746" opendate="2012-9-7 00:00:00" fixdate="2012-9-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Impacts of HBASE-6435 vs. HDFS 2.0 trunk</summary>
      <description>When using the trunk of HDFS branch 2, I had two errors linked to HBASE-6435: a missing test to null a method removed.This fixes it: add the test make the test case less dependant on HDFS internal.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.fs.TestBlockReorder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.fs.HFileSystem.java</file>
    </fixedFiles>
  </bug>
  <bug id="6765" opendate="2012-9-12 00:00:00" fixdate="2012-9-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>&amp;#39;Take a snapshot&amp;#39; interface</summary>
      <description>Add interfaces taking a snapshot. This is in hopes of cutting down on the overhead involved in reviewing snapshots.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.MasterAdminProtocol.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.MasterAdmin.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.hbase.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MasterAdminProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.java</file>
    </fixedFiles>
  </bug>
  <bug id="6766" opendate="2012-9-12 00:00:00" fixdate="2012-9-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove the Thread Dump link on Info pages</summary>
      <description>The Debug Dump page has the thread dump. Fewer links on the page would make things a little clearer for new users.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.zk.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.tablesDetailed.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="6777" opendate="2012-9-13 00:00:00" fixdate="2012-11-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Snapshot Restore interface</summary>
      <description>Add interfaces for restoring a snapshot</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.MasterAdmin.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MasterAdminProtos.java</file>
    </fixedFiles>
  </bug>
  <bug id="6780" opendate="2012-9-14 00:00:00" fixdate="2012-9-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>On the master status page the Number of Requests per second is incorrect for RegionServer&amp;#39;s</summary>
      <description>The number of requests per second is getting divided when it shouldn't be.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ServerLoad.java</file>
    </fixedFiles>
  </bug>
  <bug id="6783" opendate="2012-9-14 00:00:00" fixdate="2012-9-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make read short circuit the default</summary>
      <description>Per mailing discussion, read short circuit has little or no drawback, hence should used by default. As a consequence, we activate it on the default tests.It's possible to launch the test with -Ddfs.client.read.shortcircuit=false to execute the tests without the shortcircuit, it will be used for some builds on trunk.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestFSErrorsExposed.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
    </fixedFiles>
  </bug>
  <bug id="6793" opendate="2012-9-15 00:00:00" fixdate="2012-11-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make hbase-examples module</summary>
      <description>There are some examples under /examples/, which are not compiled as a part of the build. We can move them to an hbase-examples module.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.assembly.hadoop-two-compat.xml</file>
      <file type="M">src.assembly.hadoop-one-compat.xml</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.thrift.Hbase.thrift</file>
      <file type="M">examples.thrift.README.txt</file>
      <file type="M">examples.thrift.Makefile</file>
      <file type="M">examples.thrift.DemoClient.rb</file>
      <file type="M">examples.thrift.DemoClient.py</file>
      <file type="M">examples.thrift.DemoClient.pl</file>
      <file type="M">examples.thrift.DemoClient.php</file>
      <file type="M">examples.thrift.DemoClient.java</file>
      <file type="M">examples.thrift.DemoClient.cpp</file>
      <file type="M">examples.thrift2.DemoClient.py</file>
      <file type="M">examples.thrift2.DemoClient.java</file>
      <file type="M">examples.README.txt</file>
      <file type="M">examples.mapreduce.org.apache.hadoop.hbase.mapreduce.SampleUploader.java</file>
      <file type="M">examples.mapreduce.org.apache.hadoop.hbase.mapreduce.IndexBuilder.java</file>
      <file type="M">examples.mapreduce.index-builder-setup.rb</file>
    </fixedFiles>
  </bug>
  <bug id="6795" opendate="2012-9-15 00:00:00" fixdate="2012-9-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>mvn compile fails on a fresh checkout with empty ~/.m2/repo</summary>
      <description>I have noticed that mvn compile fails if your ~/m2/repository/ does not contain hbase test jars, however mvn test-compile, mvn install, etc works as expected. The patch for HBASE-6706 introduced test-jar dependency from hbase-server and hbase-hadoop1-compat to hbase-hadoop-compat test jar in the test scope. But stupid maven still tries to resolve the test jar when you do maven compile (notice that we are not even in the test scope).mvn test-compile, etc works b/c the test-jar for hbase-hadoop-compat is build before hbase-hadoop1-compat.One way to solve this is to push SNAPSHOT test-jars for hbase-hadoop-compat to the snapshot repository, so next time, they are referenced from there.Other alternative is to move classes under hbase-hadoop{|1|2}-compat/src/test to src/main, and remove the test-jar intra-module dependency. Still, it seems we might need intra-module test-jar dependency in the future. Any other suggestions are welcome.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6802" opendate="2012-9-17 00:00:00" fixdate="2012-11-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Export Snapshot</summary>
      <description>Export a snapshot to another cluster. Copy the .snapshot/name folder with all the references Copy the hfiles/hlogs needed by the snapshotOnce the other cluster has the files and the snapshot information it can restore the snapshot.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="6803" opendate="2012-9-17 00:00:00" fixdate="2012-9-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>script hbase should add JAVA_LIBRARY_PATH to LD_LIBRARY_PATH</summary>
      <description>Snappy SO fails to load properly if LD_LIBRARY_PATH does not include the path where snappy SO is.</description>
      <version>None</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug id="6804" opendate="2012-9-18 00:00:00" fixdate="2012-12-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[replication] lower the amount of logging to a more human-readable level</summary>
      <description>We need stop logging every time replication decides to do something. It used to be extremely useful when the code base was younger but now it should be possible to bring it down while keeping it relevant.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.ReplicationSourceDummy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.Replication.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.MetricsSink.java</file>
    </fixedFiles>
  </bug>
  <bug id="6816" opendate="2012-9-18 00:00:00" fixdate="2012-1-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[WINDOWS] line endings on checkout for .sh files</summary>
      <description>On code checkout from svn or git, we need to ensure that the line endings for .sh files are LF, so that they work with cygwin. This is important for getting src/saveVersion.sh to work.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.resources.images.hbase.logo.svg</file>
    </fixedFiles>
  </bug>
  <bug id="682" opendate="2008-6-12 00:00:00" fixdate="2008-6-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Regularize toString</summary>
      <description>Make all of our toStrings work the same. While at it, make them ruby Hash style so they play well in the (jruby) shell</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.TestToString.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.BaseScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Memcache.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6820" opendate="2012-9-18 00:00:00" fixdate="2012-11-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[WINDOWS] MiniZookeeperCluster should ensure that ZKDatabase is closed upon shutdown()</summary>
      <description>MiniZookeeperCluster.shutdown() shuts down the ZookeeperServer and NIOServerCnxnFactory. However, MiniZookeeperCluster uses a deprecated ZookeeperServer constructor, which in turn constructs its own FileTxnSnapLog, and ZKDatabase. Since ZookeeperServer.shutdown() does not close() the ZKDatabase, we have to explicitly close it in MiniZookeeperCluster.shutdown().Tests effected by this areTestSplitLogManagerTestSplitLogWorkerTestOfflineMetaRebuildBaseTestOfflineMetaRebuildHoleTestOfflineMetaRebuildOverlap</description>
      <version>0.94.3,0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.java</file>
    </fixedFiles>
  </bug>
  <bug id="6822" opendate="2012-9-18 00:00:00" fixdate="2012-11-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[WINDOWS] MiniZookeeperCluster multiple daemons bind to the same port</summary>
      <description>TestHBaseTestingUtility.testMiniZooKeeper() tests whether the mini zk cluster is working by launching 5 threads corresponding to zk servers. NIOServerCnxnFactory.configure() configures the socket as: this.ss = ServerSocketChannel.open(); ss.socket().setReuseAddress(true);setReuseAddress() is set, because it allows the server to come back up and bind to the same port before the socket is timed-out by the kernel.Under windows, the behavior on ServerSocket.setReuseAddress() is different than on linux, in which it allows any process to bind to an already-bound port. This causes ZK nodes starting on the same node, to be able to bind to the same port. The following part of the patch at https://issues.apache.org/jira/browse/HADOOP-8223 deals with this case for Hadoop:if(Shell.WINDOWS) {+ // result of setting the SO_REUSEADDR flag is different on Windows+ // http://msdn.microsoft.com/en-us/library/ms740621(v=vs.85).aspx+ // without this 2 NN's can start on the same machine and listen on + // the same port with indeterminate routing of incoming requests to them+ ret.setReuseAddress(false);+ }We should do the same in Zookeeper (I'll open a ZOOK issue). But in the meantime, we can fix hbase tests to not rely on BindException to resolve for bind errors. Especially, in MiniZKCluster.startup() when starting more than 1 servers, we already know that we have to increment the port number.</description>
      <version>0.94.3,0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.java</file>
    </fixedFiles>
  </bug>
  <bug id="6825" opendate="2012-9-19 00:00:00" fixdate="2012-1-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[WINDOWS] Java NIO socket channels does not work with Windows ipv6</summary>
      <description>While running the test TestAdmin.testCheckHBaseAvailableClosesConnection(), I noticed that it takes very long, since it sleeps for 2sec * 500, because of zookeeper retries. The root cause of the problem is that ZK uses Java NIO to create ServerSorcket's from ServerSocketChannels. Under windows, the ipv4 and ipv6 is implemented independently, and Java seems that it cannot reuse the same socket channel for both ipv4 and ipv6 sockets. We are getting "java.net.SocketException: Address family not supported by protocolfamily" exceptions. When, ZK client resolves "localhost", it gets both v4 127.0.0.1 and v6 ::1 address, but the socket channel cannot bind to both v4 and v6. The problem is reported as:http://bugs.sun.com/view_bug.do?bug_id=6230761http://stackoverflow.com/questions/1357091/binding-an-ipv6-server-socket-on-windowsAlthough the JDK bug is reported as resolved, I have tested with jdk1.6.0_33 without any success. Although JDK7 seems to have fixed this problem. In ZK, we can replace the ClientCnxnSocket implementation from ClientCnxnSocketNIO to a non-NIO one, but I am not sure that would be the way to go.Disabling ipv6 resolution of "localhost" is one other approach. I'll test it to see whether it will be any good.</description>
      <version>0.94.3,0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6836" opendate="2012-9-19 00:00:00" fixdate="2012-9-19 01:00:00" resolution="Later">
    <buginformation>
      <summary>[89-fb] Parallel deletes in HBase Thrift server</summary>
      <description>We need to expose server-side parallel batch deletes through the Thrift server.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotsFromAdmin.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSTableDescriptors.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.UnknownSnapshotException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotCreationException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.HBaseSnapshotException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.server.errorhandling.impl.ExceptionOrchestrator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.MasterAdminProtocol.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.executor.EventHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.MasterAdmin.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.hbase.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MasterAdminProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="6848" opendate="2012-9-20 00:00:00" fixdate="2012-9-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make hbase-hadoop-compat findbugs clean</summary>
      <description>There are a few findbugs errors in hbase-hadoop-compat, hbase-hadoop1-compat, and hbase-hadoop2-compat. Lets fix these up; since these are new modules it would be nice to keep them with 0 findbugs errors.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.util.MetricSampleQuantiles.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.metrics.BaseMetricsSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.metrics.MasterMetricsSourceImpl.java</file>
      <file type="M">hbase-hadoop1-compat.src.main.java.org.apache.hadoop.metrics2.util.MetricSampleQuantiles.java</file>
      <file type="M">hbase-hadoop1-compat.src.main.java.org.apache.hadoop.hbase.metrics.BaseMetricsSourceImpl.java</file>
      <file type="M">hbase-hadoop1-compat.src.main.java.org.apache.hadoop.hbase.master.metrics.MasterMetricsSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.metrics.MetricsExecutor.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.metrics.MetricHistogram.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.thrift.metrics.ThriftServerMetricsSourceFactory.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.thrift.metrics.ThriftServerMetricsSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.replication.regionserver.metrics.ReplicationMetricsSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.metrics.MBeanSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.metrics.BaseMetricsSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.master.metrics.MasterMetricsWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.master.metrics.MasterMetricsSourceFactory.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.master.metrics.MasterMetricsSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.CompatibilitySingletonFactory.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.CompatibilityFactory.java</file>
      <file type="M">dev-support.findbugs-exclude.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6849" opendate="2012-9-20 00:00:00" fixdate="2012-9-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make StochasticLoadBalancer the default</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.LoadBalancerFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="6875" opendate="2012-9-25 00:00:00" fixdate="2012-9-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove commons-httpclient, -component, and up versions on other jars (remove unused repository)</summary>
      <description></description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6876" opendate="2012-9-25 00:00:00" fixdate="2012-9-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up WARNs and log messages around startup</summary>
      <description>I was looking at our startup messages and some of the 'normal' messages are a bit frightening at face value.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileInlineToRootChunkConversion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ActiveMasterManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseRpcMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="6884" opendate="2012-9-26 00:00:00" fixdate="2012-9-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update documentation on unit tests</summary>
      <description>Points to address: we don't have anymore JUnit rules in the tests we should document how to run the test faster. some stuff is not used (run only a category) and should be removed from the doc imho.Below the proposal:&amp;#8211;15.6.2. Unit TestsHBase unit tests are subdivided into three categories: small, medium and large, with corresponding JUnit categories: SmallTests, MediumTests, LargeTests. JUnit categories are denoted using java annotations and look like this in your unit test code....@Category(SmallTests.class)public class TestHRegionInfo { @Test public void testCreateHRegionInfoName() throws Exception { // ... }}The above example shows how to mark a test as belonging to the small category. HBase uses a patched maven surefire plugin and maven profiles to implement its unit test characterizations. 15.6.2.4. Running testsBelow we describe how to run the HBase junit categories.15.6.2.4.1. Default: small and medium category testsRunningmvn testwill execute all small tests in a single JVM (no fork) and then medium tests in a separate JVM for each test instance. Medium tests are NOT executed if there is an error in a small test. Large tests are NOT executed. There is one report for small tests, and one report for medium tests if they are executed.15.6.2.4.2. Running all testsRunningmvn test -P runAllTestswill execute small tests in a single JVM then medium and large tests in a separate JVM for each test. Medium and large tests are NOT executed if there is an error in a small test. Large tests are NOT executed if there is an error in a small or medium test. There is one report for small tests, and one report for medium and large tests if they are executed15.6.2.4.3. Running a single test or all tests in a packageTo run an individual test, e.g. MyTest, domvn test -P localTests -Dtest=MyTestYou can also pass multiple, individual tests as a comma-delimited list:mvn test -P localTests -Dtest=MyTest1,MyTest2,MyTest3You can also pass a package, which will run all tests under the package:mvn test -P localTests -Dtest=org.apache.hadoop.hbase.client.*The -P localTests will remove the JUnit category effect (without this specific profile, the categories are taken into account). Each junit tests is executed in a separate JVM (A fork per test class). There is no parallelization when localTests profile is set. You will see a new message at the end of the report: "&amp;#91;INFO&amp;#93; Tests are skipped". It's harmless.15.6.2.4.4. Running test faster&amp;#91;replace previous chapter&amp;#93;By default, mvn test -P runAllTests runs 5 tests in parallel. It can be increased for many developper machine. Consider that you can have 2 tests in parallel per core, and you need about 2Gb of memory per test. Hence, if you have a 8 cores and 24Gb box, you can have 16 tests in parallel.The setting is:mvn test -P runAllTests -Dsurefire.secondPartThreadCount=12To increase the speed, you can as well use a ramdisk. You will need 2Gb of memory to run all the test. You will also need to delete the files between two test run.The typical way to configure a ramdisk on Linux is:sudo mkdir /ram2Gsudo mount -t tmpfs -o size=2048M tmpfs /ram2GYou can then use it to run all HBase tests with the command:mvn test -P runAllTests -Dsurefire.secondPartThreadCount=8 -Dtest.build.data.basedirectory=/ram2G</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.developer.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6889" opendate="2012-9-26 00:00:00" fixdate="2012-10-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Ignore source control files with apache-rat</summary>
      <description>Running 'mvn apache-rat:check' locally causes a failure because it finds the source control files, making it hard to check that you didn't include a file without a source header.</description>
      <version>None</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6896" opendate="2012-9-28 00:00:00" fixdate="2012-10-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>sync bulk and regular assigment handling socket timeout exception</summary>
      <description>In regular assignment, in case of socket network timeout, it tries to call openRegion again and again without change the region plan, ZK offline node,till the region is out of transition, in case the region server is still up.We may need to sync them up and make sure bulk assignment does the same in this case.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="6901" opendate="2012-9-29 00:00:00" fixdate="2012-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Store file compactSelection throws ArrayIndexOutOfBoundsException</summary>
      <description>When setting &lt;hbase.mapreduce.hfileoutputformat.compaction.exclude&gt; to true, and run compaction to exclude bulk loaded files could cause ArrayIndexOutOfBoundsException since all files are excluded.</description>
      <version>None</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="691" opendate="2008-6-16 00:00:00" fixdate="2008-6-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>get* and getScanner are different in how they treat column parameter</summary>
      <description>From the list, cure at xg dot pl there are group of methods "getRow" and group "getScanner" - both get as param array of collumns but in "getRow" methods we have to put it without ":" at the end of column family name, and for "getScanner" the colon is necessary. i think that it will be good to make it identical.</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6917" opendate="2012-10-2 00:00:00" fixdate="2012-10-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Trunk jdk7 build broke because we moved to zk 3.4.4</summary>
      <description>Chatted w/ Mahadev and he confirmed issues running 3.4.4 w/ jdk7. Will be fixed in zk3.4.5.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6951" opendate="2012-10-4 00:00:00" fixdate="2012-10-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow the master info server to be started in a read only mode.</summary>
      <description>There are some cases that a user could want a web ui to be accessible but might not want the split and compact functionality to be usable.Allowing the web ui to start in a readOnly mode would be good.</description>
      <version>None</version>
      <fixedVersion>0.92.3,0.94.3,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestInfoServers.java</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
    </fixedFiles>
  </bug>
  <bug id="696" opendate="2008-6-18 00:00:00" fixdate="2008-7-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make bloomfilter true/false and self-sizing</summary>
      <description>Remove bloomfilter options. Only one bloomfilter type makes sense in hbase context. Also, make bloomfilter self-sizing; you know size when flushing.Putting in 0.2 for now because its API change (for the simpler). We can punt later.</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.TestBloomFilters.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestTimestamp.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestHStoreFile.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.HBaseTestCase.java</file>
      <file type="M">src.java.org.onelab.filter.BloomFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.Migrate.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.MetaUtils.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.ThriftUtilities.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.TableHandler.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.MapFileCompactionReader.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStoreFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.CompactionReader.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.BloomFilterDescriptor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6962" opendate="2012-10-9 00:00:00" fixdate="2012-10-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade hadoop 1 dependency to hadoop 1.1</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6979" opendate="2012-10-11 00:00:00" fixdate="2012-10-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>recovered.edits file should not break distributed log splitting</summary>
      <description>Distributed log splitting fails in creating the recovered.edits folder during upgrade because there is a file called recovered.edits there.Instead of checking if the patch exists, we need to check if it exists and is a path.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLogSplit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
    </fixedFiles>
  </bug>
  <bug id="6994" opendate="2012-10-15 00:00:00" fixdate="2012-10-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>minor doc update about DEFAULT_ACCEPTABLE_FACTOR</summary>
      <description>Per trunk code, in LruBlockCache.java:static final float DEFAULT_ACCEPTABLE_FACTOR = 0.99f;but the site doc still :"number of region servers * heap size * hfile.block.cache.size * 0.85"seems the HBASE-6312 forgot to update this doc</description>
      <version>0.95.2</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7" opendate="2007-12-17 00:00:00" fixdate="2007-6-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbase] Provide a HBase checker and repair tool similar to fsck</summary>
      <description>We need a tool to verify (and repair) HBase much like fsck</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.check.meta.rb</file>
    </fixedFiles>
  </bug>
  <bug id="7000" opendate="2012-10-17 00:00:00" fixdate="2012-10-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix the "INT_VACUOUS_COMPARISON" WARNING in KeyValue class</summary>
      <description></description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="7002" opendate="2012-10-17 00:00:00" fixdate="2012-10-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix all 4 findbug performance warnings</summary>
      <description>Fix the perf warning from this report : https://builds.apache.org/job/PreCommit-HBASE-Build/3057//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html#Warnings_PERFORMANCE</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.IncrementCoalescer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="7005" opendate="2012-10-17 00:00:00" fixdate="2012-10-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade Thrift lib to 0.9.0</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.generated.TScan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.generated.TRowResult.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.generated.TRegionInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.generated.TIncrement.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.generated.TCell.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.generated.Mutation.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.generated.IOError.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.generated.IllegalArgument.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.generated.Hbase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.generated.ColumnDescriptor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.generated.BatchMutation.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.generated.AlreadyExists.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TTimeRange.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TScan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TResult.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TPut.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIOError.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIncrement.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIllegalArgument.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.THBaseService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TGet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TDeleteType.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TDelete.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumnValue.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumnIncrement.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumn.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.package.html</file>
      <file type="M">hbase-server.src.main.javadoc.org.apache.hadoop.hbase.thrift.package.html</file>
    </fixedFiles>
  </bug>
  <bug id="7006" opendate="2012-10-17 00:00:00" fixdate="2012-5-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[MTTR] Improve Region Server Recovery Time - Distributed Log Replay</summary>
      <description>Just saw interesting issue where a cluster went down hard and 30 nodes had 1700 WALs to replay. Replay took almost an hour. It looks like it could run faster that much of the time is spent zk'ing and nn'ing.Putting in 0.96 so it gets a look at least. Can always punt.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MockRegionServerServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestIOFencing.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLogSplit.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRSKilledWhenMasterInitializing.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterFileSystem.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithAbort.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALEdit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitLogWorker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.LastSequenceId.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MetricsMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.MetaServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.hbase.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Admin.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.AdminProtos.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterSourceImpl.java</file>
      <file type="M">hbase-hadoop1-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop1-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterSource.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationZookeeper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ServerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Mutation.java</file>
    </fixedFiles>
  </bug>
  <bug id="7008" opendate="2012-10-18 00:00:00" fixdate="2012-12-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Set scanner caching to a better default, disable Nagles</summary>
      <description>per http://search-hadoop.com/m/qaRu9iM2f02/Set+scanner+caching+to+a+better+default%253F&amp;subj=Set+scanner+caching+to+a+better+default+let's set to 100 by default</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.configuration.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannerTimeout.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="7019" opendate="2012-10-20 00:00:00" fixdate="2012-10-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Can&amp;#39;t pass SplitAlgo in hbase shell</summary>
      <description>hbase(main):002:0&gt; create 't1', 'f1', {NUMREGIONS =&gt; 15, SPLITALGO =&gt; 'HexStringSplit'}ERROR: uninitialized constant Hbase::Admin::RegionSplitter</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.ruby.hbase.admin.test.rb</file>
      <file type="M">hbase-server.src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug id="7032" opendate="2012-10-22 00:00:00" fixdate="2012-10-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove old IncrementColumnValue code.</summary>
      <description>IncrementColumnValue under the covers now uses Increment. We should remove the old code.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestAtomicOperation.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="7033" opendate="2012-10-23 00:00:00" fixdate="2012-10-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add hbase.lru.blockcache.acceptable.factor to configuration, akin to the min.factor added by HBASE-6312</summary>
      <description>Background: we want to make the change to block cache setting available on 0.94 without actually changing the defaults as was done in HBASE-6312, as this can be destabilizing.Thus, both of these would be configurable instead of just one, and the user would be able to switch to new values.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
    </fixedFiles>
  </bug>
  <bug id="7036" opendate="2012-10-23 00:00:00" fixdate="2012-10-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Exclude org.apache.hadoop.hbase.coprocessor.example.generated package from findbugs check</summary>
      <description></description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.findbugs-exclude.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7051" opendate="2012-10-25 00:00:00" fixdate="2012-10-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CheckAndPut should properly read MVCC</summary>
      <description>See, for example:// TODO: Use MVCC to make this set of increments atomic to readsHere's an example of what I can happen (would probably be good to write up a test case for each read/update):Concurrent update via increment and put.The put grabs the row lock first and updates the memstore, but releases the row lock before the MVCC is advanced. Then, the increment grabs the row lock and reads right away, reading the old value and incrementing based on that.There are a few options here:1) Waiting for the MVCC to advance for read/updates: the downside is that you have to wait for updates on other rows.2) Have an MVCC per-row (table configuration): this avoids the unnecessary contention of 1)3) Transform the read/updates to write-only with rollup on read.. E.g. an increment would just have the number of values to increment.</description>
      <version>0.95.2</version>
      <fixedVersion>0.94.3,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="7055" opendate="2012-10-25 00:00:00" fixdate="2012-6-25 01:00:00" resolution="Later">
    <buginformation>
      <summary>port HBASE-6371 tier-based compaction from 0.89-fb to trunk (with changes)</summary>
      <description>See HBASE-6371 for details.</description>
      <version>0.95.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestTierCompactSelection.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDefaultCompactSelection.java</file>
      <file type="M">hbase-server.src.main.resources.hbase-compactions.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.TierCompactionManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.TierCompactionConfiguration.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactionManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactionConfiguration.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompactSelection.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Compactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactSelection.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HFileOutputFormat.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HBaseConfiguration.java</file>
    </fixedFiles>
  </bug>
  <bug id="7070" opendate="2012-10-30 00:00:00" fixdate="2012-11-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scanner may retry forever after HBASE-5974</summary>
      <description>After the patch of HBASE-5974Suppose The process is as the following:1.A next request is very large, so first time it is failed because of timeout2.The second time it is failed again because of CallSequenceOutOfOrderException3.We will retry this next request again after reset scanner, so it is also very large and failed again because of timeout4.CallSequenceOutOfOrderException again5.Repeated the above forever...See the comment in HBASE-5974 for morehttps://issues.apache.org/jira/browse/HBASE-5974?focusedCommentId=13486658&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13486658</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestClientScannerRPCTimeout.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="7077" opendate="2012-10-31 00:00:00" fixdate="2012-10-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Test for: CheckAndPut should properly read MVCC</summary>
      <description>checkAndPut should integrate with MVCC, similar to how HBASE-4583 fixed appends and increments.Also need a test, here's one we could use (originally proposed in HBASE-7051):The current value of some cell is 10.I issue two concurrent requests:A) a check and put where check value = 10, put value = 11B) a put where put value = 50The only result at the end of these operations that seems reasonable to me is the value of the cell being 50. If A occurred first (ACID wise), then our values go 10-&gt;11-&gt;50. If B occurred first, then our values go 10-&gt;50 (and the checkAndPut fails)</description>
      <version>None</version>
      <fixedVersion>0.94.3,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHBase7051.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="7104" opendate="2012-11-6 00:00:00" fixdate="2012-11-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase includes multiple versions of netty: 3.5.0; 3.2.4; 3.2.2</summary>
      <description>We've got 3 of them on trunk.&amp;#91;INFO&amp;#93; org.apache.hbase:hbase-server:jar:0.95-SNAPSHOT&amp;#91;INFO&amp;#93; +- io.netty:netty:jar:3.5.0.Final:compile&amp;#91;INFO&amp;#93; +- org.apache.zookeeper:zookeeper:jar:3.4.3:compile&amp;#91;INFO&amp;#93; | &amp;#45; org.jboss.netty:netty:jar:3.2.2.Final:compile&amp;#91;INFO&amp;#93; org.apache.hbase:hbase-hadoop2-compat:jar:0.95-SNAPSHOT&amp;#91;INFO&amp;#93; +- org.apache.hadoop:hadoop-client:jar:2.0.2-alpha:compile&amp;#91;INFO&amp;#93; | +- org.apache.hadoop:hadoop-mapreduce-client-app:jar:2.0.2-alpha:compile&amp;#91;INFO&amp;#93; | | &amp;#45; org.jboss.netty:netty:jar:3.2.4.Final:compileThe patch attached: fixes this for hadoop 1 profile bump the netty version to 3.5.9 does not fix it for hadoop 2. I don't know why, but I haven't investigate: as it's still alpha may be they will change the version on hadoop side anyway.Tests are ok.I haven't really investigated the differences between netty 3.2 and 3.5. A quick search seems to say it's ok, but don't hesitate to raise a warning...</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7107" opendate="2012-11-6 00:00:00" fixdate="2012-11-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Snapshot References Utils (FileSystem Visitor)</summary>
      <description>Utils to traverse the table and snapshot directory.Used by Restore and Export and should be used by cleaner, and other that want to look inside the snapshot folder.It provides an abstraction to the "snapshot metadata" format, and allows to get information about files, logs and recovered.edits snapshotted.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="7109" opendate="2012-11-6 00:00:00" fixdate="2012-11-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>integration tests on cluster are not getting picked up from distribution</summary>
      <description>The method of finding test classes only works on local build (or its full copy), not if the distribution is used.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestCheckTestClasses.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestsDriver.java</file>
    </fixedFiles>
  </bug>
  <bug id="711" opendate="2008-6-26 00:00:00" fixdate="2008-12-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Complain if clock skew across the cluster is badly out of sync</summary>
      <description>hbase-710 and hbase-609 are issues where the system has broken in presence of clock skew over the cluster. Would be a nice service if master could flag very bad clock skew. Regionservers could report their local time when they ping the master. It could do a compare.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.overview.html</file>
    </fixedFiles>
  </bug>
  <bug id="7110" opendate="2012-11-7 00:00:00" fixdate="2012-11-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>refactor the compaction selection and config code similarly to 0.89-fb changes</summary>
      <description>Separate JIRA for refactoring changes from HBASE-7055 (and further ones after code review)</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDefaultCompactSelection.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreConfiguration.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompactSelection.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactSelection.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.java</file>
    </fixedFiles>
  </bug>
  <bug id="7121" opendate="2012-11-7 00:00:00" fixdate="2012-11-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix TestHFileOutputFormat after moving RS to metrics2</summary>
      <description>When spinning up lots of threads in a single jvm it's possible that the metrics wrapper can touch variables that are not initialized.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="7130" opendate="2012-11-8 00:00:00" fixdate="2012-11-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>NULL qualifier is ignored</summary>
      <description>HBASE-6206 ignored NULL qualifier so the qualifier list could be empty. But the request converter skips empty qualifier list too.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestAggregateProtocol.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScan.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestGet.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.AggregateImplementation.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Get.java</file>
    </fixedFiles>
  </bug>
  <bug id="7134" opendate="2012-11-9 00:00:00" fixdate="2012-11-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>incrementColumnValue hooks no longer called from anywhere</summary>
      <description>incrementColumnValue has been removed from RegionServer, the corresponding coprocessor hooks for this operation are no longer called.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionObserver.java</file>
    </fixedFiles>
  </bug>
  <bug id="7148" opendate="2012-11-12 00:00:00" fixdate="2012-11-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Some files in hbase-examples module miss license header</summary>
      <description>Trunk build 3530 got to building hbase-examples module but failed:[INFO] HBase - Examples .................................. FAILURE [3.222s][INFO] ------------------------------------------------------------------------[INFO] BUILD FAILURE[INFO] ------------------------------------------------------------------------[INFO] Total time: 29:21.569s[INFO] Finished at: Sun Nov 11 15:17:35 UTC 2012[INFO] Final Memory: 68M/642M[INFO] ------------------------------------------------------------------------[ERROR] Failed to execute goal org.apache.rat:apache-rat-plugin:0.8:check (default) on project hbase-examples: Too many unapproved licenses: 20 -&gt; [Help 1]Looks like license headers are missing in some of the files in hbase-examples module</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7162" opendate="2012-11-14 00:00:00" fixdate="2012-11-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Prefix Compression - Trie data block encoding; hbase-common and hbase-server changes</summary>
      <description>These are the hbase-common and hbase-server changes for hbase-4676 Prefix Compression - Trie data block encoding.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestByteBufferUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.KeyValueTestUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileDataBlockEncoder.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestEncodedSeekers.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestDataBlockEncoders.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.RedundantKVGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.Strings.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ByteBufferUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.encoding.PrefixKeyDeltaEncoder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.encoding.HFileBlockDefaultEncodingContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.encoding.HFileBlockDefaultDecodingContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.encoding.FastDiffDeltaEncoder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.encoding.DiffKeyDeltaEncoder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestBytes.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.test.LoadTestKVGenerator.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Bytes.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.HFileBlockEncodingContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.DataBlockEncoder.java</file>
    </fixedFiles>
  </bug>
  <bug id="7167" opendate="2012-11-15 00:00:00" fixdate="2012-4-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thrift&amp;#39;s deleteMultiple() raises exception instead of returning list of failed deletes</summary>
      <description>Thrift API claims deleteMultiple() returns the list of failed Deletes, but the current implementation throws a TIOError instead.</description>
      <version>None</version>
      <fixedVersion>0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.thrift2.hbase.thrift</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftUtilities.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftHBaseServiceHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="7168" opendate="2012-11-15 00:00:00" fixdate="2012-11-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[dev] in the script called &amp;#39;hbase&amp;#39;, we don&amp;#39;t check for errors when generating the classpath with mvn</summary>
      <description>When it happens, it's difficult to guess. Let's fix this.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug id="7186" opendate="2012-11-19 00:00:00" fixdate="2012-12-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Split Classes for Client/Server module split.</summary>
      <description>Prepare classes for the coming hbase-client/hbase-server split.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.LoadTestTool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestHColumnDescriptor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.token.TestTokenAuthentication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSeekOptimizations.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestScanWithBloomError.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMultiColumnScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionInfo.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestFSErrorsExposed.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompoundBloomFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCacheOnWriteInSchema.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestBlocksRead.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.HFileReadWriteTest.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.EncodedSeekPerformanceTest.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.DataBlockEncodingTool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.CreateRandomStoreFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestHMasterRPCException.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestProtoBufRpc.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestDelayedRpc.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.RandomTimeoutRpcEngine.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.TestHbaseObjectWritable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestForceCacheImportantBlocks.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestCacheOnWrite.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.BloomFilterFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.ThriftUtilities.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlLists.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.ProtobufRpcEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseRPC.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.HbaseObjectWritable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.FirstKeyValueMatchingQualifiersFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ServerCallable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="7187" opendate="2012-11-19 00:00:00" fixdate="2012-12-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create empty hbase-client module</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.BackupMasterListTmpl.jamon</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-common.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7188" opendate="2012-11-19 00:00:00" fixdate="2012-2-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move classes into hbase-client</summary>
      <description></description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Mutation.java</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestMiniClusterLoadSequential.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestFSVisitor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestFSUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestFSTableDescriptors.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MockServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.LoadTestTool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestSerialization.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestMultiVersions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestHTableDescriptor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestHColumnDescriptor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestAcidGuarantees.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestRestoreFlushSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestFlushSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.SnapshotTestingUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestTablePermissions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessControlFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationQueueFailover.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRolling.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRollAbort.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLogSplit.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestServerCustomProtocol.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerNoMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestKeepDeletes.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionServerBulkLoad.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionInfo.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionBusyWait.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestGetClosestAtOrBefore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestEndToEndSplitTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.handler.TestOpenRegionHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.handler.TestCloseRegionHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.CreateRandomStoreFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestZKBasedOpenCloseRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestTableLockManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRestartCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestOpenedRegionHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterFailoverBalancerPersistence.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestHMasterRPCException.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestClockSkewDetection.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.Mocking.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.cleaner.TestSnapshotFromMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapred.TestTableInputFormat.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTimeRangeMapRed.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFilesSplitRecovery.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileDataBlockEncoder.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileBlockCompatibility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileBlock.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestChecksum.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.CacheTestUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestDataBlockEncoders.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestFilterWrapper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestFilterWithScanLimits.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.executor.TestExecutorService.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithRemove.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestMasterCoprocessorExceptionWithRemove.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorInterface.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.ColumnAggregationEndpoint.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.constraint.TestConstraint.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.constraint.RuntimeFailConstraint.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.constraint.AllFailConstraint.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotFromAdmin.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScan.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestRestoreSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestPutDotHas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestOperation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestGet.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestClientTimeouts.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAttributes.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.HConnectionTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.catalog.TestCatalogTracker.java</file>
      <file type="M">hbase-server.src.saveVersion.sh</file>
      <file type="M">hbase-server.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperNodeTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKTableReadOnly.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKLeaderManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKConfig.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKClusterId.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKAssign.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.RootRegionTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.MetaNodeTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.MasterAddressTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.LoadBalancerTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.HQuorumPeer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.EmptyWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ZooKeeperConnectionException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.YouAreDeadException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.Writables.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.Triple.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.SoftValueSortedMap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.Sleeper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RetryCounterFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RetryCounter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.PoolMap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.PairOfSameType.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.Pair.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.MurmurHash.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.Methods.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.Merge.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.JenkinsHash.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HMerge.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.hbck.HFileCorruptionChecker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsckRepair.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HasThread.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.Hash.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSTableDescriptors.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FileSystemVersionException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.Classes.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.Addressing.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.UnknownScannerException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.UnknownRegionException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.Canary.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.TableNotFoundException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.TableNotEnabledException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.TableNotDisabledException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.TableInfoMissingException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.TableExistsException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.Stoppable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.SplitLogTask.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.UnknownSnapshotException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.TakeSnapshotUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.TablePartiallyOpenException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.TableInfoCopyTask.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotExistsException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotDoesNotExistException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotCreationException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.RestoreSnapshotException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.HBaseSnapshotException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.ExportSnapshotException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.ExportSnapshot.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.CorruptedSnapshotException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ServerName.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ServerLoad.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.Server.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.User.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.TokenProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.AuthenticationTokenSelector.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.AuthenticationTokenIdentifier.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.TokenInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.KerberosInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.HBaseSaslRpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.HBaseSaslRpcClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.UserPermission.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.TablePermission.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.TableAuthManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.Permission.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlLists.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.AccessDeniedException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.SchemaResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerResultGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RowResultGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RowResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RegionsResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.ReplicationZookeeper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.ReplicationStateInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.ReplicationStateImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.RemoteExceptionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.RegionTransition.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.RegionTooBusyException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.WrongRegionException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.OrphanHLogAfterSplitException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FailedLogCloseException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitLogWorker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.snapshot.RegionServerSnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.snapshot.FlushSnapshotSubprocedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RowProcessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerStoppedException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerRunningException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionOpeningState.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MultiRowMutationProcessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.LogRoller.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Leases.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.LeaseException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionThriftServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.ParallelSeekHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenRootHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenMetaHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseRootHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseMetaHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.BloomType.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.RegionMovedException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.RegionLoad.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.RegionException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.ResponseConverter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.package.html</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.PleaseHoldException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.OutOfOrderScannerNextException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.NotServingRegionException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.NotAllMetaRegionsOnlineException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableLockManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.RestoreSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.MasterSnapshotVerifier.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.EnabledTableSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.DisabledTableSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.CloneSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionState.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMasterCommandLine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableModifyFamilyHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableEventHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableDeleteFamilyHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableAddFamilyHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.SplitRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.OpenedRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ModifyTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.MetaServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.EnableTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DisableTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DeleteTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.CreateTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ClosedRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ActiveMasterManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.MasterProtocol.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.MasterNotRunningException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.MasterMonitorProtocol.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.MasterAdminProtocol.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.Import.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HFileOutputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.LockTimeoutException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.UnknownProtocolException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.ServerRpcController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.ServerNotRunningYetException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcClientEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcCallContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RegionCoprocessorRpcChannel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.ProtobufRpcServerEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.ProtobufRpcClientEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.MasterCoprocessorRpcChannel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseClientRPC.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.CoprocessorRpcChannel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.CallerDisconnectedException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.BlockingRpcCallback.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.IpcProtocol.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.TimeRange.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.InvalidHFileException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CorruptHFileException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.encoding.PrefixKeyDeltaEncoder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.encoding.FastDiffDeltaEncoder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.encoding.EncoderBufferTooSmallException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.encoding.EncodedDataBlock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.encoding.DiffKeyDeltaEncoder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.encoding.CopyKeyDataBlockEncoder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.encoding.CompressionState.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.InvalidFamilyOperationException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HRegionLocation.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HBaseIOException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HBaseException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.WhileMatchFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.ValueFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.TimestampsFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.SubstringComparator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.SkipFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.SingleColumnValueFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.SingleColumnValueExcludeFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.RowFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.RegexStringComparator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.RandomRowFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.QualifierFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.PrefixFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.ParseFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.ParseConstants.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.PageFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.package-info.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.NullComparator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.MultipleColumnPrefixFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.KeyOnlyFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.InvalidRowFilterException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.IncompatibleFilterException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.InclusiveStopFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.FuzzyRowFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.FirstKeyValueMatchingQualifiersFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.FirstKeyOnlyFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.FilterWrapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.FilterList.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.FilterBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.Filter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.FamilyFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.DependentColumnFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.CompareFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.ColumnRangeFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.ColumnPrefixFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.ColumnPaginationFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.ColumnCountGetFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.ByteArrayComparable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.BitComparator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.BinaryPrefixComparator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.BinaryComparator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.FailedSanityCheckException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.executor.ExecutorService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.executor.EventHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.DroppedSnapshotException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.DoNotRetryIOException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.DeserializationException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.ColumnInterpreter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseRowProcessorEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.AggregateImplementation.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.CoprocessorEnvironment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.Coprocessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.constraint.package-info.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.constraint.ConstraintException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.constraint.Constraint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ClusterStatus.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ClusterId.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ClockOutOfSyncException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ZooKeeperKeepAliveConnection.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.UnmodifyableHTableDescriptor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.UnmodifyableHRegionInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.UnmodifyableHColumnDescriptor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ServerCallable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ScannerTimeoutException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.RowMutations.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Row.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.RetriesExhaustedException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ResultScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Result.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.replication.ReplicationAdmin.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.RegionOfflineException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Put.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.package-info.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.OperationWithAttributes.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Operation.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.NoServerForRegionException.java</file>
      <file type="M">hbase-client.pom.xml</file>
      <file type="M">hbase-common.pom.xml</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.HFileBlockDefaultEncodingContext.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.coprocessor.example.BulkDeleteEndpoint.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.coprocessor.example.RowCountEndpoint.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.DistributedHBaseCluster.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hbase.codec.prefixtree.scanner.CellScanner.java</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.Abortable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.example.HFileArchiveManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.example.TableHFileArchiveTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.catalog.CatalogTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.catalog.MetaEditor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.catalog.MetaMigrationConvertingToPB.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.catalog.MetaReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.Chore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.AbstractClientScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Action.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.AdminProtocol.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Append.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Attributes.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ClientProtocol.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.coprocessor.AggregationClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.coprocessor.Batch.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.coprocessor.LongColumnInterpreter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.coprocessor.package-info.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.coprocessor.SecureBulkLoadClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Delete.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Get.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HConnection.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HTableFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HTableInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HTableInterfaceFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HTableMultiplexer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HTablePool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HTableUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Increment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.IsolationLevel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.MasterAdminKeepAliveConnection.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.MasterMonitorKeepAliveConnection.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.MetaScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.metrics.ScanMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.MultiAction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.MultiResponse.java</file>
    </fixedFiles>
  </bug>
  <bug id="7200" opendate="2012-11-21 00:00:00" fixdate="2012-11-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>create integration test for balancing regions and killing region servers</summary>
      <description>See related JIRA</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.LoadTestTool.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.util.ChaosMonkey.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestDataIngestWithChaosMonkey.java</file>
    </fixedFiles>
  </bug>
  <bug id="7202" opendate="2012-11-21 00:00:00" fixdate="2012-12-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Family Store Files are not archived on admin.deleteColumn()</summary>
      <description>using HBaseAdmin.deleteColumn() the files are not archived but deleted directory.This causes problems with snapshots, and other systems that relies on files to be archived.</description>
      <version>0.94.2,0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestHFileArchiving.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.HFileArchiver.java</file>
    </fixedFiles>
  </bug>
  <bug id="7203" opendate="2012-11-21 00:00:00" fixdate="2012-11-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move example CoProcessor into hbase-examples</summary>
      <description>Move the example co-processor into the hbase-examples module. Also move the protobuf definition files into the module.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.example.TestZooKeeperScanPolicyObserver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.example.TestRowCountEndpoint.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.example.TestBulkDeleteProtocol.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.example.ZooKeeperScanPolicyObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.example.RowCountEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.example.generated.ExampleProtos.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.example.generated.BulkDeleteProtos.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.example.BulkDeleteEndpoint.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Examples.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.BulkDelete.proto</file>
      <file type="M">hbase-examples.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7204" opendate="2012-11-21 00:00:00" fixdate="2012-11-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make hbck ErrorReporter pluggable</summary>
      <description>Make hbck ErrorReporter pluggable so that it can be replaced dynamically.</description>
      <version>None</version>
      <fixedVersion>0.94.4,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="7223" opendate="2012-11-27 00:00:00" fixdate="2012-11-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[refguide] Addition to SchemaDesign - RowKey design about understanding keyspace and region splits</summary>
      <description>Adding an entry in the RowKey design section in the Schema Design chapter about understanding the keyspace and splits when pre-splitting tables.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7225" opendate="2012-11-28 00:00:00" fixdate="2012-11-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>on trunk, integration tests are not packaged into distribution</summary>
      <description></description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.assembly.components.xml</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7228" opendate="2012-11-28 00:00:00" fixdate="2012-11-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[refguide] Addition to SchemaDesign -added entry to "Rows as Columns"</summary>
      <description>There are two schema design approaches in the RefGuide currently, rows vs. versions and rows vs. columns. But as OpenTSDB demonstrates there is a third: rows as columns.Adding a reference to that "middle" approach.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7239" opendate="2012-11-29 00:00:00" fixdate="2012-4-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Verify protobuf serialization is correctly chunking upon read to avoid direct memory OOMs</summary>
      <description>Result.readFields() used to read from the input stream in 8k chunks to avoid OOM issues with direct memory.(Reading variable sized chunks into direct memory prevent the JVM from reusing the allocated direct memory and direct memory is only collected during full GCs)This is just to verify protobufs parseFrom type methods do the right thing as well so that we do not reintroduce this problem.</description>
      <version>None</version>
      <fixedVersion>0.95.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.IPCUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.HBaseClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="7250" opendate="2012-11-30 00:00:00" fixdate="2012-12-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>create integration test for balancing regions and killing region servers - 2</summary>
      <description>The original test is too general; need another one that would be more targeted and would test master logic in particular (e.g. not kill master). I re-discovered HBASE-6060 using it on the first run</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.util.ChaosMonkey.java</file>
    </fixedFiles>
  </bug>
  <bug id="7262" opendate="2012-12-3 00:00:00" fixdate="2012-12-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move HBaseRPC metrics to metrics2</summary>
      <description>HBase RPC is the last thing still publishing through metrics1. We should move this into metrics2.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRpcMetrics.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerMetrics.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.ProtobufRpcEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseRPCStatistics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseRpcMetrics.java</file>
      <file type="M">hbase-hadoop2-compat.src.test.java.org.apache.hadoop.hbase.test.MetricsAssertHelperImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.metrics.BaseSourceImpl.java</file>
      <file type="M">hbase-hadoop1-compat.src.test.java.org.apache.hadoop.hbase.test.MetricsAssertHelperImpl.java</file>
      <file type="M">hbase-hadoop1-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop1-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop1-compat.src.main.java.org.apache.hadoop.hbase.metrics.BaseSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.metrics.BaseSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="7264" opendate="2012-12-3 00:00:00" fixdate="2012-12-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve Snappy installation documentation</summary>
      <description>Snappy installation process is lacking some details. I tried to give some.There is also some mistakes "it's" vs "its".</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.developer.xml</file>
      <file type="M">src.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7265" opendate="2012-12-3 00:00:00" fixdate="2012-12-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make Maven skip module test properties consistent</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-it.pom.xml</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-hadoop1-compat.pom.xml</file>
      <file type="M">hbase-hadoop-compat.pom.xml</file>
      <file type="M">hbase-examples.pom.xml</file>
      <file type="M">hbase-common.pom.xml</file>
      <file type="M">hbase-client.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7268" opendate="2012-12-4 00:00:00" fixdate="2012-1-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>correct local region location cache information can be overwritten (or deleted) w/stale information from an old server</summary>
      <description>Discovered via HBASE-7250; related to HBASE-5877.Test is writing from multiple threads.Server A has region R; client knows that.R gets moved from A to server B.B gets killed.R gets moved by master to server C.~15 seconds later, client tries to write to it (on A?).Multiple client threads report from RegionMoved exception processing logic "R moved from C to B", even though such transition never happened (neither in nor before the sequence described below). Not quite sure how the client learned of the transition to C, I assume it's from meta from some other thread...Then, put fails (it may fail due to accumulated errors that are not logged, which I am investigating... but the bogus cache update is there nonwithstanding).I have a patch but not sure if it works, test still fails locally for yet unknown reason.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MultiThreadedWriter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MockRegionServerServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestHRegionLocation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.catalog.TestCatalogTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.OnlineRegions.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.RegionMovedException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HRegionLocation.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.catalog.MetaEditor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="7271" opendate="2012-12-4 00:00:00" fixdate="2012-12-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Have a single executor for all zkWorkers in the assignment manager</summary>
      <description>The current strategy is to have an array of monothreaded executor, and hash the zk path to ensure that there are no two events on the same region executed in parallel I think a single executor, as presented in the attached patch, is better because: we're guaranteed to use all threads at any time if managing one of the event takes longer that expected, the slowness is limited to this region, and not to all regions that have the same hashed/moduloed code For the nodeChildrenChanged, there is no need to choose randomly one of the worker (or, once again, the risk to get stuck if one of the event takes time to be managed).</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="7304" opendate="2012-12-7 00:00:00" fixdate="2012-12-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>assembly:assembly doesn&amp;#39;t include the correct hbase-hadoop compat jars for hadoop 2</summary>
      <description>When executing mvn clean package assembly:assembly -Dhadoop.profile=2.0hbase-hadoop1-compat is placed in the tar.gz erroneously.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.assembly.hadoop-two-compat.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7305" opendate="2012-12-8 00:00:00" fixdate="2012-2-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ZK based Read/Write locks for table operations</summary>
      <description>This has started as forward porting of HBASE-5494 and HBASE-5991 from the 89-fb branch to trunk, but diverged enough to have it's own issue. The idea is to implement a zk based read/write lock per table. Master initiated operations should get the write lock, and region operations (region split, moving, balance?, etc) acquire a shared read lock.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MultithreadedTestUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">hbase-server.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.CloneSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableModifyFamilyHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableEventHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableDeleteFamilyHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableAddFamilyHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ModifyTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.EnableTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DisableTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DeleteTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.CreateTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.executor.EventHandler.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.ZooKeeper.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos.java</file>
    </fixedFiles>
  </bug>
  <bug id="7311" opendate="2012-12-10 00:00:00" fixdate="2012-12-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add snapshot information to hbase master webui</summary>
      <description>Similarly to how tables are listed in the web interface, snapshots should be listed as well.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="7314" opendate="2012-12-10 00:00:00" fixdate="2012-12-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Can&amp;#39;t start REST/Thrift server if HBASE_JMX_OPTS not set</summary>
      <description>By default JMX is enabled for REST server and Thrift server. However, if HBASE_JMX_OPTS is not set, and JMX remote access rule is not set, we can't bring up the REST/Thrift server due to JMX remote access rule errors.We need to enhance the hbase script not to enable JMX for REST/Thrift server is HBASE_JMX_OPTS is not set.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase-config.sh</file>
    </fixedFiles>
  </bug>
  <bug id="732" opendate="2008-7-9 00:00:00" fixdate="2008-7-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>shell formatting error with the describe command</summary>
      <description>The formatting of the output of the shell command "describe" repeats some of the text. The following is an example of the problem:hbase(main):001:0&gt; describe 'table2'NAME =&gt; 'table2', FAMILIES =&gt; [{NAME =&gt; 'fam3', VERSIONS =&gt; 3, COMPRESSION =&gt; 'NONE', IN_MEMORY =&gt; false, BLOCKCACHE =&gt; false, LENGTH =&gt; 2147483647, TTL =&gt; FOREVER, BLOOMFILTER =&gt; NONE}, {NAME =&gt; 'fam2', VERSIONS =&gt; 6, COMPRESSION =&gt; 'NONE', IN_MEMORY =&gt; false, BLOCKCACHE =&gt; false, LENGTH =&gt; 2147483647, TTL =&gt; FOREVER, BLOOMFILTOMPRESSION =&gt; 'NONE', IN_MEMORY =&gt; false, BLOCKCACHE =&gt; false, LENGTH =&gt; 2147483647, TTL =&gt; FOREVER, BLOOMFILTER =&gt; NONE}, {NAME =&gt; 'fam1', VERSIONS =&gt; 5, COMPRESSION =&gt; 'NONE', IN_MEMORY =&gt; false, BLOCKCACHE =&gt; false, LENGTH =&gt; 2147483647, TTL =&gt; FOREVER, BLOOMFILTER =&gt; NONE}]ER =&gt; NONE}, {NAME =&gt; 'fam1', VERSIONS =&gt; 5, COMPRESSION =&gt; 'NONE', IN_MEMORY =&gt; false, BLOCKCACHE =&gt; false, LENGTH =&gt; 2147483647, TTL =&gt; FOREVER, BLOOMFILTER =&gt; NONE}]ENGTH =&gt; 2147483647, TTL =&gt; FOREVER, BLOOMFILTER =&gt; NONE}] 1 row(s) in 0.2520 seconds</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.Formatter.rb</file>
    </fixedFiles>
  </bug>
  <bug id="7321" opendate="2012-12-11 00:00:00" fixdate="2012-1-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Simple Flush Snapshot</summary>
      <description>This snapshot style just issues a region flush and then "snapshots" the region. This is a simple implementation that gives the equivalent of copytable consistency. While by most definitions of consistency if a client writes A and then write B to different region servers, only neither, only A, or both A+B writes should be present, this one allows the only B case.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.snapshot.RegionServerSnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="7329" opendate="2012-12-11 00:00:00" fixdate="2012-1-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>remove flush-related records from WAL and make locking more granular</summary>
      <description>Comments from many people in HBASE-6466 and HBASE-6980 indicate that flush records in WAL are not useful. If so, they should be removed.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestDrainBarrier.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.DrainBarrier.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALActionsListener.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.WALPlayer.java</file>
    </fixedFiles>
  </bug>
  <bug id="7342" opendate="2012-12-12 00:00:00" fixdate="2012-12-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Split operation without split key incorrectly finds the middle key in off-by-one error</summary>
      <description>I took a deeper look into issues I was having using region splitting when specifying a region (but not a key for splitting).The midkey calculation is off by one and when there are 2 rows, will pick the 0th one. This causes the firstkey to be the same as midkey and the split will fail. Removing the -1 causes it work correctly, as per the test I've added.Looking into the code here is what goes on:1. Split takes the largest storefile2. It puts all the keys into a 2-dimensional array called blockKeys[][]. Key i resides as blockKeys&amp;#91;i&amp;#93;3. Getting the middle root-level index should yield the key in the middle of the storefile4. In step 3, we see that there is a possible erroneous (-1) to adjust for the 0-offset indexing.5. In a result with where there are only 2 blockKeys, this yields the 0th block key. 6. Unfortunately, this is the same block key that 'firstKey' will be.7. This yields the result in HStore.java:1873 ("cannot split because midkey is the same as first or last row")8. Removing the -1 solves the problem (in this case).</description>
      <version>0.94.1,0.94.2,0.94.3,0.95.2</version>
      <fixedVersion>0.94.4,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
    </fixedFiles>
  </bug>
  <bug id="7351" opendate="2012-12-14 00:00:00" fixdate="2012-1-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Periodic health check chore</summary>
      <description>Similar to MAPREDUCE-211, region server should also have a mechanism to check the health of the node. It should run the health check script periodically and if there is any errors, it should stop itself gracefully.</description>
      <version>0.95.2</version>
      <fixedVersion>0.94.4,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="7356" opendate="2012-12-14 00:00:00" fixdate="2012-12-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix all javadoc warnings in all modules but hbase-server</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.mapreduce.JobUtil.java</file>
      <file type="M">hbase-hadoop1-compat.src.main.java.org.apache.hadoop.hbase.mapreduce.JobUtil.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceFactory.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hbase.Cell.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteBufferUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValueTool.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
    </fixedFiles>
  </bug>
  <bug id="7363" opendate="2012-12-15 00:00:00" fixdate="2012-1-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix javadocs warnings for hbase-server packages from master to end</summary>
      <description></description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.RootRegionTracker.java</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.MasterAdminProtocol.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.DefaultLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.RegionLocationFinder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ExplicitColumnTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.GetClosestRowBeforeTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Leases.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitLogWorker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.Compressor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RESTServlet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.ZKPermissionWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ChecksumFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ChecksumType.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsckRepair.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HFileArchiveUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.SoftValueSortedMap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.Writables.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.DrainingServerTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKAssign.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKTableReadOnly.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.GeneralBulkAssigner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RowProcessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessControllerProtocol.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlLists.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.TableAuthManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="7365" opendate="2012-12-16 00:00:00" fixdate="2012-2-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Safer table creation and deletion using .tmp dir</summary>
      <description>Currently tables are created in the root directory, and the removal works on the root directory.Change the code to use a /hbase/.tmp directory to make the creation and removal a bit saferTable Creation steps Create the table descriptor (table folder, in /hbase/.tmp/) Create the table regions (always in temp) Move the table from temp to the root folder Add the regions to meta Trigger assignment Set enable flag in ZooKeeperTable Deletion steps Wait for regions in transition Remove regions from meta (use bulk delete) Move the table in /hbase/.tmp Remove the table from the descriptor cache Remove table from zookeeper Archive the tableThe main changes in the current code are: Writing to /hbase/.tmp and then rename using bulk delete in DeletionTableHandler</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHFileArchiveUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ModifyRegionUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HFileArchiveUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DeleteTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.CreateTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.catalog.MetaEditor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.HFileArchiver.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="7367" opendate="2012-12-17 00:00:00" fixdate="2012-12-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Snapshot coprocessor and ACL security</summary>
      <description>Currently snapshot don't care about ACL...and in the first draft snapshots should be disabled if the ACL coprocessor is enabled.After the first step, we can discuss how to handle the snapshot/restore/clone.Is saving and restoring the acl related rights, the right way? maybe after 3 months we don't want to give the access the guys listed in the old acl...</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestMasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.java</file>
    </fixedFiles>
  </bug>
  <bug id="7390" opendate="2012-12-19 00:00:00" fixdate="2012-12-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add extra test cases for assignement on the region server and fix the related issues</summary>
      <description>We don't have a lot of tests on the region server itself.Here are some.Some of them are failing, feedback welcome.See as well the attached state diagram for the ZK nodes on assignment.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MockRegionServerServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.handler.TestOpenRegionHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKAssign.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="7391" opendate="2012-12-19 00:00:00" fixdate="2012-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Review/improve HLog compression&amp;#39;s memory consumption</summary>
      <description>From Ram in http://mail-archives.apache.org/mod_mbox/hbase-dev/201205.mbox/%3C00bc01cd31e6$7caf1320$760d3960$%25vasudevan@huawei.com%3E:One small observation after giving +1 on the RC.The WAL compression feature causes OOME and causes Full GC.The problem is, if we have 1500 regions and I need to create recovered.editsfor each of the region (I don’t have much data in the regions (~300MB)).Now when I try to build the dictionary there is a Node object gettingcreated.Each node object occupies 32 bytes.We have 5 such dictionaries.Initially we create indexToNodes array and its size is 32767.So now we have 32*5*32767 = ~5MB.Now I have 1500 regions.So 5MB*1500 = ~7GB.(Excluding actual data). This seems to a very highinitial memory foot print and this never allows me to split the logs and Iam not able to make the cluster up at all.Our configured heap size was 8GB, tested in 3 node cluster with 5000regions, very less data( 1GB in hdfs cluster including replication), somesmall data is spread evenly across all regions.The formula is 32(Node object size)*5(No of dictionary)*32767(no of nodeobjects)*noofregions.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLRUDictionary.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestKeyValueCompression.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestCompressor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.ReaderBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.LRUDictionary.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.Dictionary.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.CompressionContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WriterBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="7415" opendate="2012-12-20 00:00:00" fixdate="2012-4-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[snapshots] Add task information to snapshot operation</summary>
      <description>Snapshot operations should have some sort of progresss information available via the WebUI so admins can track progress of operations. This should go a long way to enable 'good' admins to not hose their clusters by running concurrent snapshot operations (e.g. rename while a clone is in progress).</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.94.7,0.95.1</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestRestoreSnapshotHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.RestoreSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.DisabledTableSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.CloneSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableEventHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="7417" opendate="2012-12-21 00:00:00" fixdate="2012-12-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestReplication is flaky</summary>
      <description>See discussion at the end of HBASE-5778.TestReplication failed in all recent 0.94 jenkins builds.</description>
      <version>None</version>
      <fixedVersion>0.94.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7419" opendate="2012-12-21 00:00:00" fixdate="2012-1-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>revisit hfilelink file name format.</summary>
      <description>Valid table names are concatted with a '.' to a valid regions names is also a valid table name, and lead to the incorrect interpretation.true hfile name constraints: [0-9]+(?:_SeqID_[0-9]+)?region name constraints : [a-f0-9]{16} (but we currently just use [a-f0-9]+.)table name constraints : [a-zA-Z0-9_][a-zA-Z0-9_.-]*Notice that the table name constraints completely covers all region name constraints and true hfile name constraints. (a valid hfile name is a valid part of a table name, and a valid enc region name is a valid part of a table name.Currently the hfilelink filename convention is &lt;hfile&gt;&lt;region&gt;&lt;table&gt;. Unfortunately, making a ref to this uses the name &lt;hfile&gt;&lt;region&gt;&lt;table&gt;.&lt;parentregion&gt; &amp;#8211; the contactnation of &lt;table&gt;.&lt;parentregion&gt; is a valid table name used to get interpreted as such. The fix in HBASE-7339 requires a FileNotFoundException before going down the hfile link resolution path. Regardless of what we do, we need to add some char invalid for table names to the hfilelink or reference filename convention.Suggestion: if we changed the order of the hfile-link name we could avoid some of the confusion &amp;#8211; &lt;table&gt;@&lt;region&gt;-&lt;hfile&gt;.&lt;parentregion&gt; (or some other separator char than '@') could be used to avoid handling on the initial filenotfoundexception but I think we'd still need a good chunk of the logic to handle opening half-storefile reader throw a hfilelink.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.HFileLink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
    </fixedFiles>
  </bug>
  <bug id="7425" opendate="2012-12-21 00:00:00" fixdate="2012-12-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move to the newest BootStrap css and js for the webui.</summary>
      <description></description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.js.tab.js</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.js.jquery.min.js</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.js.bootstrap.min.js</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.js.bootstrap.js</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.css.hbase.css</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.css.bootstrap.min.css</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.css.bootstrap.css</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.css.bootstrap-responsive.min.css</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.css.bootstrap-responsive.css</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.zk.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.tablesDetailed.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.RegionServerListTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="7426" opendate="2012-12-21 00:00:00" fixdate="2012-12-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix PreCheckin script to error out when there are Javadoc errors.</summary>
      <description>Currently the script stays green for up to ~130 javadoc errors. Since these errors have been fixed the number should be lowered.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.TokenProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationHLogReaderManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.ChecksumUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.FirstKeyValueMatchingQualifiersFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.coprocessor.Batch.java</file>
      <file type="M">dev-support.test-patch.properties</file>
    </fixedFiles>
  </bug>
  <bug id="7443" opendate="2012-12-27 00:00:00" fixdate="2012-12-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>More findbugs fixes</summary>
      <description>It adds the dependency to findbugs for the annotations. It's a compile only dependency. License is LGPL. suppresses a few not critical warnings fixes a few othersLocally, I'm now at 144.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.Canary.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.StorageClusterStatusModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.LogMonitoring.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HFileOutputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.DependentColumnFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.CompareFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.ByteArrayComparable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.catalog.MetaReader.java</file>
      <file type="M">dev-support.findbugs-exclude.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.HBasePolicyProvider.java</file>
    </fixedFiles>
  </bug>
  <bug id="7464" opendate="2012-12-30 00:00:00" fixdate="2012-1-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[REST] Sending HTML for errors is unhelpful</summary>
      <description>The large HTML 404 page returned by Stargate is not helpful. The REST interface is not intended for humans to read, esp. when the client is known to be a program because it's asking for binary, but really any time. Nice big readable error pages use bandwidth and clutter network traces to no purpose.Please allow the 404 and other error pages to be configured away, or just stop sending them (my preference). If some body must be sent, a simple text/plain "Not found" would be fine, I think.</description>
      <version>0.94.5,0.95.2</version>
      <fixedVersion>0.94.4,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.StorageClusterVersionResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.StorageClusterStatusResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.SchemaResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerInstanceResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RowResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RootResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RegionsResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.MultiRowResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ExistsResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.Constants.java</file>
    </fixedFiles>
  </bug>
  <bug id="7469" opendate="2012-12-31 00:00:00" fixdate="2012-12-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[REST] Share a HBaseAdmin instance</summary>
      <description>Simplification.</description>
      <version>0.94.5,0.95.2</version>
      <fixedVersion>0.94.4,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.TableResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.StorageClusterVersionResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.StorageClusterStatusResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.SchemaResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RootResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RESTServlet.java</file>
    </fixedFiles>
  </bug>
  <bug id="7472" opendate="2012-12-31 00:00:00" fixdate="2012-1-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[REST] Support MIME type application/protobuf</summary>
      <description>Protobuf representation is currently selected with 'application/x-protobuf'. We should also consider supporting 'application/protobuf' because it appears in an IETF draft. See http://tools.ietf.org/id/draft-rfernando-protocol-buffers-00.txt</description>
      <version>0.94.5,0.95.2</version>
      <fixedVersion>0.94.4,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestVersionResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestTableResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestStatusResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestSchemaResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestScannersWithFilters.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestScannerResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestRowResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestMultiRowResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.VersionResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.StorageClusterStatusResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.SchemaResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerInstanceResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RowResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RootResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RegionsResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.provider.producer.ProtobufMessageBodyProducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.provider.consumer.ProtobufMessageBodyConsumer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.MultiRowResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ExistsResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.Constants.java</file>
    </fixedFiles>
  </bug>
  <bug id="7498" opendate="2013-1-4 00:00:00" fixdate="2013-1-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make REST server thread pool size configurable</summary>
      <description>Currently, the REST server thread pool size is the default: 250. It can't be configured. We need to make it configurable so that it can be adjusted per traffic/load so that REST server is less likely to OOM and die.</description>
      <version>0.94.5,0.95.2</version>
      <fixedVersion>0.94.5,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RESTServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="7508" opendate="2013-1-7 00:00:00" fixdate="2013-1-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix simple findbugs</summary>
      <description></description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.EmptyWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ServerName.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.Permission.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.KeyPrefixRegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.SplitRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HLogInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HealthCheckChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.executor.EventHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.AggregateImplementation.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.OperationWithAttributes.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.thrift.DemoClient.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.coprocessor.example.ZooKeeperScanPolicyObserver.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.JVM.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">dev-support.test-patch.properties</file>
      <file type="M">dev-support.findbugs-exclude.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7512" opendate="2013-1-8 00:00:00" fixdate="2013-1-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document the findbugs library annotation</summary>
      <description>See HBASE-7508</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.developer.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7527" opendate="2013-1-10 00:00:00" fixdate="2013-1-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>integration tests STILL won&amp;#39;t run from tar.gz in trunk</summary>
      <description>The problem is that the class used to find test classes sits in common test jar, which is not included in the package.However, if we move the class to the common jar itself, we'll have a JUnit dependency.And if we cannot just move it to integration tests, because a test that verifies test categories makes use of it too.This is all very sad.I will see if there's any way to not have junit dependency (we already seem to deploy junit so it might not be such a big deal).</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.assembly.components.xml</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7529" opendate="2013-1-10 00:00:00" fixdate="2013-1-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Wrong ExecutorType for EventType.M_RS_OPEN_ROOT in trunk</summary>
      <description>M_RS_OPEN_ROOT (21, ExecutorType.RS_OPEN_REGION), // Master asking RS to open rootIt's a mistake only in trunk, causing ROOT couldn't be online for a long long time:1.ROOT wait open-region-thread to handle opening it.2.Opening regions wait for ROOT to online, but occupy the threads...</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.executor.EventHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="7546" opendate="2013-1-11 00:00:00" fixdate="2013-3-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Obtain a table read lock on region split operations</summary>
      <description>As discussed in the parent issue HBASE-7305, we should be coordinating between splits and table operations to ensure that they don't happen at the same time. In this issue we will acquire shared read locks for region splits.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MockRegionServerServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestTableLockManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableLockManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="7555" opendate="2013-1-14 00:00:00" fixdate="2013-1-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Kill the remaining processus from other builds in the precommit env</summary>
      <description>We have some process surviving hdfs builds.Let's kill them before starting our own build.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  <bug id="7558" opendate="2013-1-14 00:00:00" fixdate="2013-1-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Client not able to access /hbase/unassigned in secure cluster</summary>
      <description>HBASE-6068, /hbase/unassigned is not listed as open nodeand catalogTracker tries to read from both: RootRegionTracker (/hbase/root-region-server) and MetaNodeTracker (/hbase/unassigned)Unable to get data of znode /hbase/unassigned/1028785192org.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth for /hbase/unassigned/1028785192</description>
      <version>0.94.4,0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="7559" opendate="2013-1-14 00:00:00" fixdate="2013-1-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add additional Snapshots Unit Test Coverage</summary>
      <description>Add additional testing for Snapshots. In particular, we should add tests to verify that operations on cloned tables do not affect the original (and vice versa). Also, we should do testing on table describes before and after snapshot/restore operations. Finally, we should add testing for the HBase shell.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.SnapshotTestingUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="7574" opendate="2013-1-15 00:00:00" fixdate="2013-1-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Migrate to JUnit 4.11</summary>
      <description></description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7577" opendate="2013-1-16 00:00:00" fixdate="2013-1-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Review names of all znodes in zk to make sure they are sensible before 0.96</summary>
      <description>HBASE-4451 was a rename we needed. My guess is we could do a few more now we have the opportunity (e.g. unassigned as name of dir for regions in transition..).</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.zookeeper.TestRecoverableZooKeeper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
    </fixedFiles>
  </bug>
  <bug id="7586" opendate="2013-1-16 00:00:00" fixdate="2013-1-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix two findbugs warnings to get our count down to the tolerated number again</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.FirstKeyOnlyFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="759" opendate="2008-7-22 00:00:00" fixdate="2008-12-22 01:00:00" resolution="Won&amp;#39;t Fix">
    <buginformation>
      <summary>TestMetaUtils failing on hudson</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.util.DisabledTestMetaUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="7590" opendate="2013-1-16 00:00:00" fixdate="2013-3-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a costless notifications mechanism from master to regionservers &amp; clients</summary>
      <description>t would be very useful to add a mechanism to distribute some information to the clients and regionservers. Especially It would be useful to know globally (regionservers + clients apps) that some regionservers are dead. This would allow: to lower the load on the system, without clients using staled information and going on dead machines to make the recovery faster from a client point of view. It's common to use large timeouts on the client side, so the client may need a lot of time before declaring a region server dead and trying another one. If the client receives the information separatly about a region server states, it can take the right decision, and continue/stop to wait accordingly.We can also send more information, for example instructions like 'slow down' to instruct the client to increase the retries delay and so on. Technically, the master could send this information. To lower the load on the system, we should: have a multicast communication (i.e. the master does not have to connect to all servers by tcp), with once packet every 10 seconds or so. receivers should not depend on this: if the information is available great. If not, it should not break anything. it should be optional.So at the end we would have a thread in the master sending a protobuf message about the dead servers on a multicast socket. If the socket is not configured, it does not do anything. On the client side, when we receive an information that a node is dead, we refresh the cache about it.</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestMultiVersions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTimeRangeMapRed.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestFilterWrapper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestFilterWithScanLimits.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.HConnectionTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.catalog.TestMetaReaderEditorNoCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.IncrementCoalescer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMasterCommandLine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.DeadServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClientEngine.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.ProtobufRpcClientEngine.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.HBaseClientRPC.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.HBaseClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ClusterStatus.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ServerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.Chore.java</file>
      <file type="M">hbase-client.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7639" opendate="2013-1-21 00:00:00" fixdate="2013-8-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable online schema update by default</summary>
      <description>After we get HBASE-7305 and HBASE-7546, things will become stable enough to enable online schema update to be enabled by default. &lt;property&gt; &lt;name&gt;hbase.online.schema.update.enable&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;description&gt; Set true to enable online schema changes. This is an experimental feature.·· There are known issues modifying table schemas at the same time a region split is happening so your table needs to be quiescent or else you have to be running with splits disabled. &lt;/description&gt; &lt;/property&gt;</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7646" opendate="2013-1-22 00:00:00" fixdate="2013-1-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make forkedProcessTimeoutInSeconds configurable</summary>
      <description>Command line property "surefire.timeout" somehow doesn't work. It may be because forkedProcessTimeoutInSeconds is hard-coded to 900.</description>
      <version>None</version>
      <fixedVersion>0.94.5,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7656" opendate="2013-1-24 00:00:00" fixdate="2013-1-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up line endings to be LF in the repo</summary>
      <description>After HBASE-6816, there are still 2 files in the repo with CRLF line endings. We should change recommit them with LF line endings.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.zookeeper.TestRecoverableZooKeeper.java</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.js.jquery.min.js</file>
    </fixedFiles>
  </bug>
  <bug id="7657" opendate="2013-1-24 00:00:00" fixdate="2013-1-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make ModifyTableHandler synchronous</summary>
      <description>This is along the lines of other admin operations such as modifyColumnFamily, AddColumnFamily to make it a synchronous op.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableEventHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="7674" opendate="2013-1-25 00:00:00" fixdate="2013-1-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>add shell documentation for HBASE-7571</summary>
      <description>When the patch was split from HBASE-7236, shell documentation (e.g. how to use the new thing and examples) fell thru the cracks. Need to add it...</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.ruby.shell.commands.create.rb</file>
      <file type="M">hbase-server.src.main.ruby.shell.commands.alter.rb</file>
    </fixedFiles>
  </bug>
  <bug id="7678" opendate="2013-1-26 00:00:00" fixdate="2013-2-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>make storefile management pluggable, together with compaction</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDefaultCompactSelection.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.compactions.PerfTestCompactionPolicies.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.Compactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionPolicy.java</file>
    </fixedFiles>
  </bug>
  <bug id="7679" opendate="2013-1-26 00:00:00" fixdate="2013-10-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>implement store file management for stripe compactions</summary>
      <description>Needs loving. Moving out for now. Can pull in on point release after goes into trunk.</description>
      <version>None</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDefaultCompactSelection.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
    </fixedFiles>
  </bug>
  <bug id="770" opendate="2008-7-23 00:00:00" fixdate="2008-7-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update HBaseRPC to match hadoop 0.17 RPC</summary>
      <description>Hadoop RPC has had some improvements done. Copied them down to our version of hadoop RPC, HBaseRPC in the hbase.ipc package.</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HbaseRPC.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7757" opendate="2013-2-4 00:00:00" fixdate="2013-2-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add web UI to REST server and Thrift server</summary>
      <description>Add Hadoop HttpServer (web UI) to REST server and Thrift server. The Hadoop HttpServer supports metrics/jmx/conf/logLevel/stacks, which is useful to monitor REST/Thrift server.For REST server, use a separate listener/context to avoid path mapping conflicts.</description>
      <version>None</version>
      <fixedVersion>0.94.5,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RESTServer.java</file>
      <file type="M">hbase-server.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7758" opendate="2013-2-4 00:00:00" fixdate="2013-2-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update book to include documentation of CellCounter utility</summary>
      <description>The book documents RowCounter but not cell counter. Describe them together.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7778" opendate="2013-2-6 00:00:00" fixdate="2013-2-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[snapshot 130201 merge] Tests with sleep after minicluster shutdown fail due to interrupt flag.</summary>
      <description>Something in the merge has set the interrupted flag on the main test threads of TestReplicationDisabledinactivePeer, TestRestartCluster, and TestCatalogTrackerOnCluster. These unacceptable hacks make the tests run and pass: diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/catalog/TestCatalogTrackerOnCluster.java b/hbase-server/src/test/java/orindex f3e57d6..a8d2ef7 100644--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/catalog/TestCatalogTrackerOnCluster.java+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/catalog/TestCatalogTrackerOnCluster.java@@ -47,6 +47,7 @@ public class TestCatalogTrackerOnCluster { // Shutdown hbase. UTIL.shutdownMiniHBaseCluster(); // Give the various ZKWatchers some time to settle their affairs.+ Thread.interrupted(); // HACK clear interrupt state. Thread.sleep(1000); // Mess with the root location in the running zk. Set it to be nonsense.diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestRestartCluster.java b/hbase-server/src/test/java/org/apache/hindex 15225e1..9f7f526 100644--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestRestartCluster.java+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestRestartCluster.java@@ -108,6 +108,7 @@ public class TestRestartCluster { UTIL.shutdownMiniHBaseCluster(); LOG.info("\n\nSleeping a bit");+ Thread.interrupted(); // HACK clear interrupt state. Thread.sleep(2000); LOG.info("\n\nStarting cluster the second time");diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationDisableInactivePeer.java b/hbase-server/src/tindex b089fbe..8162f4b 100644--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationDisableInactivePeer.java+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationDisableInactivePeer.java@@ -50,6 +50,7 @@ public class TestReplicationDisableInactivePeer extends TestReplicationBase { // enabling and shutdown the peer admin.enablePeer("2"); utility2.shutdownMiniHBaseCluster();+ Thread.interrupted(); // HACK clear interrupted flag. byte[] rowkey = Bytes.toBytes("disable inactive peer"); Put put = new Put(rowkey);On the snapshot branch and on the trunk branch before the merge, these tests passed. Need to figure out how they combination caused this behavior change.</description>
      <version>hbase-7290,0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.JVMClusterUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="7779" opendate="2013-2-6 00:00:00" fixdate="2013-2-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[snapshot 130201 merge] Fix TestMultiParallel</summary>
      <description>TestMultiParallel has three tests that always fail on the merged branch: #testFlushCommitsWithAbort, #testActiveThreadsCount and #testflushCommitsNoAbort. There were some changes introduced in HBASE-7299 which happend on trunk before the merge and are likely related. (that patch addresses problems on the same tests).</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotMetadata.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="7788" opendate="2013-2-7 00:00:00" fixdate="2013-2-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[snapshot 130201 merge] Fix flakey TestRestore*SnapshotFromClient#testCloneSnapshot</summary>
      <description>In the current implementation the clone call waits until after the newly created table isTableEnabled. However there is another state (apparently orthogonal) that a newly created table is assumed to be – isTableAvailable (all regions assigned). The logic for checking after table creation and after clone creation are slightly different – creation does the equivalent of isTableAvailable but clone does not check this availability condition.This causes flaky failures in tests that quickly try to use/delete a newly cloned table.TestRestoreSnapshotFromClient#testCloneSnapshotTestRestoreFlushSnapshotFromCleitn#testCloneSnapshotI believe there also are race conditions because of the postTableCreateHandler corpco and postTableDeleteHandler coproc hooks.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="779" opendate="2008-7-26 00:00:00" fixdate="2008-7-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Test changing hbase.hregion.memcache.block.multiplier to 2</summary>
      <description>Currently its set to 1. Under load, seeing fill-cache/pause-while-cache-is-flushed cycle. Changing multiplier to 2 could make hbase take on load faster (Was set to 1 because compactions used to overwhelm the system but now HBASE-745 added a not-so-dumb compaction algorithim, we might be able to run w/ a value of 2).</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7791" opendate="2013-2-8 00:00:00" fixdate="2013-4-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compaction USER_PRIORITY is slightly broken</summary>
      <description>The code to get compaction priority is as such: public int getCompactPriority(int priority) { // If this is a user-requested compaction, leave this at the highest priority if(priority == Store.PRIORITY_USER) { return Store.PRIORITY_USER; } else { return this.blockingStoreFileCount - this.storefiles.size(); } }.PRIORITY_USER is 1.The priorities are compared as numbers in HRegion, so compactions of blocking stores will override user priority (probably intended); also, if you have blockingFiles minus one, your priority is suddenly PRIORITY_USER, which may cause at least this: LOG.debug("Warning, compacting more than " + comConf.getMaxFilesToCompact() + " files because of a user-requested major compaction");as well as some misleading logging.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultStoreFileManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="7795" opendate="2013-2-8 00:00:00" fixdate="2013-2-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Race in the Restore Archiving</summary>
      <description>Restore uses archiveStoreFile() that has the same problem fixed in HBASE-7643.Change archiveStoreFile() to use the fixed resolveAndArchiveFile()</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.HFileArchiver.java</file>
    </fixedFiles>
  </bug>
  <bug id="780" opendate="2008-7-28 00:00:00" fixdate="2008-7-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Can&amp;#39;t scan &amp;#39;.META.&amp;#39; from new shell</summary>
      <description>Need scan of .META. debugging.</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.UnmodifyableHTableDescriptor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7800" opendate="2013-2-9 00:00:00" fixdate="2013-2-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RegionMovedException can cause servers to play ping pong with client</summary>
      <description>I need to double check the code, but from some logs it appears that if region moves from A to B, then from B to A, and then closed on A for reason that is not move (not clear what), and is assigned to C, A and B will play ping-pong with the client for a while until some serendipitous occasion refreshes meta.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="7803" opendate="2013-2-9 00:00:00" fixdate="2013-3-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[REST] Support caching on scan</summary>
      <description>I have a YCSB client using the REST API. My testing shows the performance for scan with REST API is much worse than that with the java client API. We need to look into it and find out the root cause, either the test issue, or our REST API issue.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestScannerModel.java</file>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.ScannerMessage.proto</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerResultGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.ScannerMessage.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.ScannerModel.java</file>
    </fixedFiles>
  </bug>
  <bug id="7842" opendate="2013-2-14 00:00:00" fixdate="2013-4-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add compaction policy that explores more storefile groups</summary>
      <description>Some workloads that are not as stable can have compactions that are too large or too small using the current storefile selection algorithm.Currently: Find the first file that Size(fi) &lt;= Sum(0, i-1, FileSize(fx)) Ensure that there are the min number of files (if there aren't then bail out) If there are too many files keep the larger ones.I would propose something like: Find all sets of storefiles where every file satisfies FileSize(fi) &lt;= Sum(0, i-1, FileSize(fx)) Num files in set =&lt; max Num Files in set &gt;= min Then pick the set of files that maximizes ((# storefiles in set) / Sum(FileSize(fx)))The thinking is that the above algorithm is pretty easy reason about, all files satisfy the ratio, and should rewrite the least amount of data to get the biggest impact in seeks.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDefaultStoreEngine.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDefaultCompactSelection.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.compactions.PerfTestCompactionPolicies.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultStoreEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactionPolicy.java</file>
    </fixedFiles>
  </bug>
  <bug id="7845" opendate="2013-2-14 00:00:00" fixdate="2013-3-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>optimize hfile index key</summary>
      <description>Leveldb uses ByteWiseComparatorImpl::FindShortestSeparator() &amp; FindShortSuccessor() to reduce index key size, it would be helpful under special conditions.</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestBlocksRead.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileWriterV2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileWriterV2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderV2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestKeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="7846" opendate="2013-2-14 00:00:00" fixdate="2013-12-14 01:00:00" resolution="Won&amp;#39;t Fix">
    <buginformation>
      <summary>Add support for merging implicit regions in Merge tool</summary>
      <description>Currently org.apache.hadoop.hbase.util.Merge needs 2 region names to be explicitly specified to perform a merge. This can be cumbersome.One idea for improvement is to have Merge to figure out all the adjacent regions and perform the merges. For example:regions before merge: row-10, row-20, row-30, row-40, row-50regions after merge: row-10, row-30, row-50In the above example, region names of "row-10" and "row-20" are merged to become a new bigger region of "row-10".</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.stop-hbase.sh</file>
    </fixedFiles>
  </bug>
  <bug id="7847" opendate="2013-2-14 00:00:00" fixdate="2013-1-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use zookeeper multi to clear znodes</summary>
      <description>In ZKProcedureUtil, clearChildZNodes() and clearZNodes(String procedureName) should utilize zookeeper multi so that they're atomic</description>
      <version>None</version>
      <fixedVersion>1.1.0,0.98.14,1.0.2,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKMulti.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="7848" opendate="2013-2-14 00:00:00" fixdate="2013-3-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use ZK-based read/write lock to make flush-type snapshot robust against table enable/disable/alter</summary>
      <description>Current region split following flush would fail snapshot.We can utilize ZK-based read/write lock to make flush-type snapshot robust</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.EnabledTableSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.DisabledTableSnapshotHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="7849" opendate="2013-2-14 00:00:00" fixdate="2013-2-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Provide administrative limits around bulkloads of files into a single region</summary>
      <description>Given the current mechanism, it is possible for users to flood a single region with 1k+ store files via the bulkload API and basically cause the region to become a flying dutchman - never getting assigned successfully again.Ideally, an administrative limit could solve this. If the bulkload RPC call can check if the region already has X store files, then it can reject the request to add another and throw a failure at the client with an appropriate message.This may be an intrusive change, but seems necessary in perfecting the gap between devs and ops in managing a HBase clusters. This would especially prevent abuse in form of unaware devs not pre-splitting tables before bulkloading things in. Currently, this leads to ops pain, as the devs think HBase has gone non-functional and begin complaining.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.98.1,0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestSecureLoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
    </fixedFiles>
  </bug>
  <bug id="7861" opendate="2013-2-15 00:00:00" fixdate="2013-2-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use the ServerName in the Connection#getClient and Connection#getAdmin code</summary>
      <description>This is again a subpart of HBASE-7590. The patch already in HBASE-7590 contains a bad fix for this (confusion with seq number). This JIRA tries to fix it correctly.The client code mostly uses hostname:port to get the connection to the region server. As a side effect if a server dies and comeback, the client won't notice. This is in theory, because the regions it's looking for are likely to be somewhere else.In any case, if we add some dead server management in the client (HBASE-7590), we need to manage do the distinction between the server, to be sure that we're not declaring dead a server that has restarted.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestHRegionLocation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionServerBulkLoad.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFilesSplitRecovery.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide3.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.HConnectionTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.catalog.TestMetaReaderEditorNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.catalog.TestCatalogTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsckRepair.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.RegionMovedException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HRegionLocation.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ServerCallable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HConnection.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.catalog.CatalogTracker.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.DistributedHBaseCluster.java</file>
    </fixedFiles>
  </bug>
  <bug id="7875" opendate="2013-2-19 00:00:00" fixdate="2013-7-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>introduce a compaction switch in HBase Shell</summary>
      <description>A trivial patch to add an per-table compaction switch. it would be helpful for OPS or manual testing in real cluster, etc.Usage:hbase(main):016:0&gt; alter 'YCSBTest', {METHOD =&gt; 'table_att', COMPACTION_ENABLE =&gt; 'FALSE'}Updating all regions with the new schema...64/64 regions updated.Done.0 row(s) in 1.1290 secondshbase(main):017:0&gt; describe 'YCSBTest'DESCRIPTION ENABLED {NAME =&gt; 'YCSBTest', COMPACTION_ENABLE =&gt; 'false', SPLIT_POLICY =&gt; 'org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPoli true cy', FAMILIES =&gt; [{NAME =&gt; 'test', DATA_BLOCK_ENCODING =&gt; 'NONE', BLOOMFILTER =&gt; 'NONE', REPLICATION_SCOPE =&gt; '0', COMPRESSION =&gt; 'S NAPPY', VERSIONS =&gt; '1', TTL =&gt; '2147483647', MIN_VERSIONS =&gt; '0', KEEP_DELETED_CELLS =&gt; 'false', BLOCKSIZE =&gt; '65536', ENCODE_ON_DI SK =&gt; 'true', IN_MEMORY =&gt; 'false', BLOCKCACHE =&gt; 'true'}]} 1 row(s) in 0.0210 seconds</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.ruby.hbase.admin.rb</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="7883" opendate="2013-2-20 00:00:00" fixdate="2013-2-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update memstore size when removing the entries in append operation</summary>
      <description>In case of Appends/Increments with VERSION of CF set to 1, the memstore size is not updated when the previous entries are removed from the memstore.</description>
      <version>0.95.2</version>
      <fixedVersion>0.94.6,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="7923" opendate="2013-2-25 00:00:00" fixdate="2013-4-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>force unassign can confirm region online on any RS to get rid of double assignments.</summary>
      <description>Presently in force unassign we are offlining a region from AM and reassigning it, which may cause double assignments. this.assignmentManager.regionOffline(hri); assignRegion(hri);Any way if a region is not served by any RS we are offlining the region from AM. if (t instanceof NotServingRegionException) { if (transitionInZK) { deleteClosingOrClosedNode(region); } regionOffline(region); return; } We can change as below just to confirm whether region online on any RS.this.assignmentManager.unassign(hri,force);if(!this.assignmentManager.getRegionStates().isRegionInTransition(hri) &amp;&amp; !this.assignmentManager.getRegionStates().isRegionAssigned(hri) ){ assignRegion(hri);}</description>
      <version>None</version>
      <fixedVersion>0.95.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="7926" opendate="2013-2-25 00:00:00" fixdate="2013-2-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>SmallTests pollute the META descriptor</summary>
      <description>Running tests on my jenkins I've noticed that the META_TABLEDESC at some point gets changed, and gets SNAPPY encoding and other settings.A couple of SmallTest take the META_TABLEDESC as base and change it directly, to verify the serialization, without creating a copy.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestHTableDescriptor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestHColumnDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="8058" opendate="2013-3-9 00:00:00" fixdate="2013-3-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade site plugin; fix assembly doc up on jenkins builds</summary>
      <description>Up on jenkins, we currently make assemblies but there no doc in them. The site goal runs last. You can't run it anywhere else else build fails. Upgrading the site plugin helps. Upgrading site plugin I notice that there are a bunch of extra reports generated that would be no harm showing on the web site; e.g. dependencies transitively included, what dependencies we have, etc. This issue is about upgrading site plugin to fix jenkins assemblies and to expose reports we are generating anyways (at least one report is new w/ the info-report upgrade from earlier today).</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8060" opendate="2013-3-10 00:00:00" fixdate="2013-6-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>"Num compacting KVs" diverges from "num compacted KVs" over time</summary>
      <description>I have been running what amounts to an ingestion test for a day or so. This is an all-in-one cluster launched with './bin/hbase master start' from sources. In the RS stats on the master UI, the "num compacting KVs" has diverged from "num compacted KVs" even though compaction has been completed from perspective of selection, no compaction tasks are running on the RS. I think this could be confusing &amp;#8211; is compaction happening or not?Or maybe I'm misunderstanding what this is supposed to show?</description>
      <version>0.94.6,0.95.0,0.95.2</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.Compactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionProgress.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.HalfStoreFileReader.java</file>
    </fixedFiles>
  </bug>
  <bug id="8137" opendate="2013-3-18 00:00:00" fixdate="2013-3-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add failed to open/close region state</summary>
      <description>Since we are going to remove assignment timeout monitor, we should add some state to show if a region failed to open/close after max retries.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.Mocking.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DisableTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DeleteTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.ClusterStatus.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.master.RegionState.java</file>
    </fixedFiles>
  </bug>
  <bug id="8138" opendate="2013-3-18 00:00:00" fixdate="2013-3-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Using [packed=true] for repeated field of primitive numeric types (types which use the varint, 32-bit, or 64-bit wire types)</summary>
      <description>It's recommended to do the following for numeric primitive typesFor historical reasons, repeated fields of basic numeric types aren't encoded as efficiently as they could be. New code should use the special option &amp;#91;packed=true&amp;#93; to get a more efficient encodingSee details at https://developers.google.com/protocol-buffers/docs/proto</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-protocol.src.main.protobuf.Filter.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.FilterProtos.java</file>
    </fixedFiles>
  </bug>
  <bug id="8139" opendate="2013-3-18 00:00:00" fixdate="2013-9-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow job names to be overridden</summary>
      <description>As a general feature, we should allow mr job names to be overridden by the user. See also HBASE-8077.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.WALPlayer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.RowCounter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.ImportTsv.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.Import.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.Export.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.CopyTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.CellCounter.java</file>
    </fixedFiles>
  </bug>
  <bug id="8141" opendate="2013-3-18 00:00:00" fixdate="2013-3-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove accidental uses of org.mortbay.log.Log</summary>
      <description>Remove accidental uses of org.mortbay.log.Log. Eclipse autocomplete is probably the culprit.</description>
      <version>0.94.6,0.95.0,0.95.2</version>
      <fixedVersion>0.94.6,0.95.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestDelayedRpc.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileSeek.java</file>
      <file type="M">hbase-prefix-tree.src.test.java.org.apache.hadoop.hbase.codec.prefixtree.builder.TestTreeDepth.java</file>
    </fixedFiles>
  </bug>
  <bug id="8205" opendate="2013-3-27 00:00:00" fixdate="2013-4-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBCK support for table locks</summary>
      <description>Table locks have been introduced in HBASE-7305, HBASE-7546, and others (see the design doc at HBASE-7305). This issue adds support in HBCK to report and fix possible conditions about table locks. Namely, if due to some bug, the table lock remains not-released, then HBCK should be able to report it, and remove the lock, so that normal table operations will continue. Also see the comments in HBASE-7977.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.HbckTestingUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestTableLockManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessWriteLock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessReadLock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessLockBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableLockManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.InterProcessReadWriteLock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.InterProcessLock.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.ZooKeeper.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos.java</file>
    </fixedFiles>
  </bug>
  <bug id="821" opendate="2008-8-12 00:00:00" fixdate="2008-8-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>UnknownScanner happens too often.</summary>
      <description>Jean-Daniel up on the list in an exchange with Dru Jensen solved an issue by recommending longer lease for client scanners in a MR job. Lets make change to conf. This lessens the impact of Andrew Purtell added retry on USE in HBASE-816 in TableMap but will help in MR tasks that don't subclass TableMap.</description>
      <version>None</version>
      <fixedVersion>0.2.1,0.18.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="8236" opendate="2013-4-1 00:00:00" fixdate="2013-4-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Set finalName property in hbase-assembly else basename is hbase-assembly rather than hbase.</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-assembly.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8241" opendate="2013-4-2 00:00:00" fixdate="2013-4-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix the bad dependency on netty from HDFS</summary>
      <description>Even if it's fixed on trunk &amp; branch-2, the current version of hdfs still has a previous version of netty, with a different group id. Let's fix this.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.1,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8262" opendate="2013-4-3 00:00:00" fixdate="2013-4-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add testcase to verify HBASE-7876&amp;#39;s empty region split semantics change</summary>
      <description>HBASE-7678 change the semantics of splits and removed a test case but didn't not add one to verify behavior. We'll add one here.</description>
      <version>0.98.0,0.94.6,0.95.0,0.95.2</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="8267" opendate="2013-4-4 00:00:00" fixdate="2013-4-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add some resources checker for tests</summary>
      <description>This may help to understand why precommit is often ok while trunk is always bad.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.1,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.ResourceCheckerJUnitListener.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.HBaseCommonTestingUtility.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.JVM.java</file>
    </fixedFiles>
  </bug>
  <bug id="8496" opendate="2013-5-6 00:00:00" fixdate="2013-9-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement tags and the internals of how a tag should look like</summary>
      <description>The intent of this JIRA comes from HBASE-7897.This would help us to decide on the structure and format of how the tags should look like.</description>
      <version>0.98.0,0.95.2</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFile.java</file>
      <file type="M">hbase-server.src.test.resources.mapred-site.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestMiniClusterLoadSequential.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestMiniClusterLoadParallel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.RestartMetaTest.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MultiThreadedWriterBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MultiThreadedWriter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MultiThreadedUpdater.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MultiThreadedReader.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MultiThreadedAction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.LoadTestTool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestKeyValueCompression.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionServerBulkLoad.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestFSErrorsExposed.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompoundBloomFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCacheOnWriteInSchema.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.HFileReadWriteTest.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.DataBlockEncodingTool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.CreateRandomStoreFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.TestHalfStoreFileReader.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestSeekTo.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestReseekTo.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileWriterV2.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileSeek.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFilePerformance.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileInlineToRootChunkConversion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileDataBlockEncoder.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileBlockIndex.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileBlockCompatibility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileBlock.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestFixedFileTrailer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestChecksum.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestCacheOnWrite.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.CacheTestUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestPrefixTreeEncoding.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestEncodedSeekers.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestDataBlockEncoders.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HFilePerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.CompressionTest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ChecksumType.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALCellCodec.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.KeyValueCompression.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogPrettyPrinter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.Compactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.ReplicationProtbufUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HFileOutputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.NoOpDataBlockEncoder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileWriterV2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderV2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ChecksumFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Mutation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Put.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.CellCodec.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.CopyKeyDataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.DataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.DiffKeyDeltaEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.EncodedDataBlock.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.FastDiffDeltaEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.HFileBlockDecodingContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.HFileBlockDefaultDecodingContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.HFileBlockDefaultEncodingContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.HFileBlockEncodingContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.PrefixKeyDeltaEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValueTestUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValueUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.test.RedundantKVGenerator.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.codec.TestCellCodec.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestKeyValue.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestIngest.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestLazyCfLoading.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.column.ColumnNodeReader.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.column.ColumnReader.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.DecoderFactory.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayReversibleScanner.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArraySearcher.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeCell.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.row.RowNodeReader.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.column.ColumnNodeWriter.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.column.ColumnSectionWriter.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.PrefixTreeEncoder.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.row.RowNodeWriter.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeCodec.java</file>
      <file type="M">hbase-prefix-tree.src.test.java.org.apache.hadoop.hbase.codec.keyvalue.TestKeyValueTool.java</file>
      <file type="M">hbase-prefix-tree.src.test.java.org.apache.hadoop.hbase.codec.prefixtree.column.TestColumnBuilder.java</file>
      <file type="M">hbase-prefix-tree.src.test.java.org.apache.hadoop.hbase.codec.prefixtree.row.TestRowData.java</file>
      <file type="M">hbase-prefix-tree.src.test.java.org.apache.hadoop.hbase.codec.prefixtree.row.TestRowEncoder.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.CellProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ClientProtos.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Cell.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Client.proto</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.AbstractHFileReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.AbstractHFileWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.ChecksumUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.java</file>
    </fixedFiles>
  </bug>
  <bug id="8532" opendate="2013-5-12 00:00:00" fixdate="2013-6-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[Webui] Bootstrap based webui compatibility for IE and also fix some page format issues.</summary>
      <description>HBASE-7425 brings bootstrap based webui to hbase. While trying on trunk version, Firefox works well, but IE 8/9 layout and style look strange due to compatibility issue. Add "&lt;!DOCTYPE html ...&gt;" at the beginning of all jamon html/jsp templates to fix it.Seems HBase-2110 had a work to comment out the DOCTYPE for all .jsp to make the browser run the pages in Quirks mode (http://en.wikipedia.org/wiki/Quirks_mode) due to jetty issue at that time?To support the compatibility of webui across browsers (IE/Firefox/Chrome, etc.), there are some guidelines for choosing rendering the page under standard mode or quirk mode:http://en.wikipedia.org/wiki/Quirks_modehttp://hsivonen.iki.fi/doctype/According to document, "&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd"&gt;" has the most extensive compatibility even for HTML 5. According to my test, add this could make webui works in IE (standard mode), while Firefox could not work well with styles. Looks like if in Firefox, we still need the quirk mode (no DOCTYPE declaration). So just adding conditional DOCTYPE declaration for IE,&lt;!--&amp;#91;if IE&amp;#93;&gt;&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd"&gt;&lt;!&amp;#91;endif&amp;#93;--&gt;this could make webui works for both IE and Firefox, also for Chrome and other browsers.</description>
      <version>0.98.0,0.95.0,0.95.2</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.thrift.thrift.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.rest.rest.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.zk.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.tablesDetailed.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.snapshot.jsp</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="8534" opendate="2013-5-13 00:00:00" fixdate="2013-9-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix coverage for org.apache.hadoop.hbase.mapreduce</summary>
      <description>fix coverage org.apache.hadoop.hbase.mapreducepatch HBASE-8534-0.94.patch for branch-0.94patch HBASE-8534-trunk.patch for branch-0.95 and trunk</description>
      <version>0.94.8,0.95.2</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableMapReduceUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestDriver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestWALPlayer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestRowCounter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestImportExport.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestCopyTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="8543" opendate="2013-5-14 00:00:00" fixdate="2013-10-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>fix coverage org.apache.hadoop.hbase.rest.client</summary>
      <description>fix coverage org.apache.hadoop.hbase.rest.client</description>
      <version>0.94.8,0.95.2</version>
      <fixedVersion>0.98.0,0.96.1,0.94.14</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.client.TestRemoteTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="8642" opendate="2013-5-29 00:00:00" fixdate="2013-7-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[Snapshot] List and delete snapshot by table</summary>
      <description>Support list and delete snapshots by table names.User scenario:A user wants to delete all the snapshots which were taken in January month for a table 't' where snapshot names starts with 'Jan'.</description>
      <version>0.98.0,0.95.0,0.95.1,0.95.2</version>
      <fixedVersion>0.98.14,1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.shell.rb</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotFromClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
    </fixedFiles>
  </bug>
  <bug id="8643" opendate="2013-5-29 00:00:00" fixdate="2013-5-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Do not log full classnames in logs, just the last two levels</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.log4j.properties</file>
    </fixedFiles>
  </bug>
  <bug id="8800" opendate="2013-6-25 00:00:00" fixdate="2013-6-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Return non-zero exit codes when a region server aborts</summary>
      <description>There's a few exit code-related jiras flying around, but it seems that at least for the region server we have a bigger problem: it always returns 0 when exiting once it's started.I also saw that we have a couple -1 as exit codes, AFAIK this should be 1 (or at least a positive number).</description>
      <version>None</version>
      <fixedVersion>0.95.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMasterCommandLine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.java</file>
    </fixedFiles>
  </bug>
  <bug id="8845" opendate="2013-7-2 00:00:00" fixdate="2013-7-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add integration test for split, online merge, and compaction</summary>
      <description>We should add an integration test for online merge to exercise online merging while chaos money kills/restarts region servers, moves regions around. We need to make sure there is no data loss no matter online merge succeeds/fails.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.util.ChaosMonkey.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedListWithChaosMonkey.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestDataIngestWithChaosMonkey.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestDataIngestSlowDeterministic.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IngestIntegrationTestBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="8882" opendate="2013-7-5 00:00:00" fixdate="2013-7-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create an Integration Test to Test MTTR</summary>
      <description></description>
      <version>0.98.0,0.95.2</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.AbstractHBaseTool.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.util.ChaosMonkey.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestRebalanceAndKillServersTargeted.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.mttr.IntegrationTestMTTR.java</file>
    </fixedFiles>
  </bug>
  <bug id="8942" opendate="2013-7-13 00:00:00" fixdate="2013-4-13 01:00:00" resolution="Not A Problem">
    <buginformation>
      <summary>DFS errors during a read operation (get/scan), may cause write outliers</summary>
      <description>This is a similar issue as discussed in HBASE-82281) A scanner holds the Store.ReadLock() while opening the store files ... encounters errors. Thus, takes a long time to finish.2) A flush is completed, in the mean while. It needs the write lock to commit(), and update scanners. Hence ends up waiting.3+) All Puts (and also Gets) to the CF, which will need a read lock, will have to wait for 1) and 2) to complete. Thus blocking updates to the system for the DFS timeout.Fix: Open Store files outside the read lock. getScanners() already tries to do this optimisation. However, Store.getScanner() which calls this functions through the StoreScanner constructor, redundantly tries to grab the readLock. Causing the readLock to be held while the storeFiles are being opened, and seeked. We should get rid of the readLock() in Store.getScanner(). This is not required. The constructor for StoreScanner calls getScanners(xxx, xxx, xxx). This has the required locking already.</description>
      <version>0.89-fb,0.95.2</version>
      <fixedVersion>0.89-fb,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="8943" opendate="2013-7-13 00:00:00" fixdate="2013-6-13 01:00:00" resolution="Won&amp;#39;t Fix">
    <buginformation>
      <summary>Split Thrift2&amp;#39;s ThriftServer into separate classes for easier testing and modularization</summary>
      <description>Currently the ThriftServer class in Thrift 2 sets up and starts the actual server. Better follow a similar pattern to Thrift 1 where there is some factory setting up the server, and a separate start section. That way it is easier to test if the setup of the server is picking up everything it needs.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DispatchMergingRegionHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="8962" opendate="2013-7-16 00:00:00" fixdate="2013-7-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up code and remove regular log splitting</summary>
      <description>Distributed log splitting has been out there for a while and it is kind of stable. It's about time to get rid of the regular log splitting and clean up the code a little bit.</description>
      <version>0.98.0,0.95.2</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLogSplit.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLogMethods.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLog.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestSplitLogManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestWALObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKSplitLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.OrphanHLogAfterSplitException.java</file>
    </fixedFiles>
  </bug>
  <bug id="8994" opendate="2013-7-19 00:00:00" fixdate="2013-7-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Adding log to chaos monkey actions to show what&amp;#39;re performed</summary>
      <description>I realized that not much is logged in the new chaos monkey actions introduced in HBASE-8845.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.util.ChaosMonkey.java</file>
    </fixedFiles>
  </bug>
  <bug id="9049" opendate="2013-7-26 00:00:00" fixdate="2013-7-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Generalize ServerCallable creation to support custom callables</summary>
      <description>Currently, sever callables are instantiated via direct calls. Instead, we can use a single factory and that allows more specialized callable implementations, for instance, using a circuit-breaker pattern (or the Hystrix implementation!) to minimize attempts to contact the server.</description>
      <version>0.98.0,0.95.2,0.94.11</version>
      <fixedVersion>0.98.0,0.95.2,0.94.11</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionServerBulkLoad.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALEditsReplaySink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestAsyncProcess.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RegionCoprocessorRpcChannel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
    </fixedFiles>
  </bug>
  <bug id="9099" opendate="2013-7-31 00:00:00" fixdate="2013-8-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>logReplay could trigger double region assignment</summary>
      <description>The symptom is the first region assignment submitted in SSH is in progress while when am.waitOnRegionToClearRegionsInTransition times out we will re-submitted another SSH which will invoke another region assignment for the region. It will cause the region get stuck in RIT status.</description>
      <version>0.98.0,0.95.2</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.MetaServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="910" opendate="2008-10-1 00:00:00" fixdate="2008-11-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scanner misses columns / rows when the scanner is obtained durring a memcache flush</summary>
      <description>I first noticed that some columns for a row were missing if they are coming from a scanner that was obtained while a memecache flush on the region was in progress. I tried to write a simple unit test to reproduce, however the problem I get in the unit test is that some rows are being missed.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStoreScanner.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9110" opendate="2013-8-1 00:00:00" fixdate="2013-8-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Meta region edits not recovered while migrating to 0.96.0</summary>
      <description>I was doing the migration testing from 0.94.11-snapshot to 0.95.0, and faced this issue.1) Do some edits in meta table (for eg, create a table).2) Kill the cluster.(I used kill because we would be doing log splitting when upgrading anyway).3) There is some dependency on WALs. Upgrade the bits to 0.95.2-snapshot. Start the cluster.Every thing comes up. I see log splitting happening as expected. But, the WAL-data for meta table is missing.I could see recovered.edits file for meta created, and placed at the right location. It is just that the new HMaster code tries to recover meta by looking at meta prefix in the log name, and if it didn't find one, just opens the meta region. So, the recovered.edits file, created afterwards, is not honored.Opening this jira to let folks give their opinions about how to tackle this migration issue.</description>
      <version>0.95.2,0.94.10</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.migration.UpgradeTo96.java</file>
    </fixedFiles>
  </bug>
  <bug id="9119" opendate="2013-8-2 00:00:00" fixdate="2013-8-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase.mapreduce.hfileoutputformat.blocksize should configure with blocksize of a table</summary>
      <description>Forward port the HBASE-8949 0.94 issue.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HFileOutputFormat.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9178" opendate="2013-8-9 00:00:00" fixdate="2013-8-9 01:00:00" resolution="Duplicate">
    <buginformation>
      <summary>Hanging tests from Jenkins build job since namespaces went in</summary>
      <description>Below are list hanging tests from various build jobs(which aren't reported as failures).From hbase-0.95 last three runs======= 420 skipped(Or don't have) following tests =======org.apache.hadoop.hbase.client.testadminorg.apache.hadoop.hbase.mapreduce.testsecureloadincrementalhfilessplitrecoveryorg.apache.hadoop.hbase.mapreduce.testsecureloadincrementalhfiles======= 421 skipped(Or don't have) following tests =======org.apache.hadoop.hbase.mapreduce.testsecureloadincrementalhfilessplitrecoveryorg.apache.hadoop.hbase.mapreduce.testsecureloadincrementalhfiles======= 422 skipped(Or don't have) following tests =======org.apache.hadoop.hbase.client.testadminorg.apache.hadoop.hbase.mapreduce.testsecureloadincrementalhfilessplitrecoveryorg.apache.hadoop.hbase.mapreduce.testsecureloadincrementalhfilesFrom hbase-0.95-on-hadoop2======= 225 skipped(Or don't have) following tests =======org.apache.hadoop.hbase.catalog.testmetamigrationconvertingtopborg.apache.hadoop.hbase.mapreduce.testsecureloadincrementalhfilessplitrecoveryorg.apache.hadoop.hbase.mapreduce.testsecureloadincrementalhfiles======= 226 skipped(Or don't have) following tests =======org.apache.hadoop.hbase.client.testadminorg.apache.hadoop.hbase.catalog.testmetamigrationconvertingtopborg.apache.hadoop.hbase.mapreduce.testsecureloadincrementalhfilessplitrecoveryorg.apache.hadoop.hbase.mapreduce.testsecureloadincrementalhfiles======= 227 skipped(Or don't have) following tests =======org.apache.hadoop.hbase.client.testadminorg.apache.hadoop.hbase.catalog.testmetamigrationconvertingtopborg.apache.hadoop.hbase.mapreduce.testsecureloadincrementalhfilessplitrecoveryorg.apache.hadoop.hbase.mapreduce.testsecureloadincrementalhfiles</description>
      <version>0.95.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint.java</file>
    </fixedFiles>
  </bug>
  <bug id="9181" opendate="2013-8-9 00:00:00" fixdate="2013-8-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix javadoc warnings introduce by namespaces</summary>
      <description>javadoc is failing in hadoopqa because we have lingering javadoc warnings.</description>
      <version>0.98.0,0.95.2</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableNamespaceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="9184" opendate="2013-8-9 00:00:00" fixdate="2013-8-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Ignore zk assign event if region is not known in transition</summary>
      <description>This is a follow up of HBASE-9161. Currently, if a region is in transition, we ignore any unexpected zk assign event and log a warning. For example, a zk closing event will be ignored if the region is pending open actually. However, if the region is not in transition, we will accept such events. For events not related to split/merge, we should ignore them and log a warning too, to tighten up the region state transition. During normal operation, this (ensuring region is in transition before accepting transition related events) is fine. During master failover, this is fine as long as we don't do region transition bypass ZK. We should also make sure to watch assignment znodes after user region states are recovered, so that we don't log many such warnings.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="9185" opendate="2013-8-10 00:00:00" fixdate="2013-8-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>mvn site target fails when building with Maven 3.1</summary>
      <description>mvn site fails when building with mvn 3.1 due to various class changes inside maven. They promise that switching to new versions of some mvn modules will result in builds that work in both 3.0.x and 3.1:https://cwiki.apache.org/confluence/display/MAVEN/AetherClassNotFound</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9187" opendate="2013-8-10 00:00:00" fixdate="2013-8-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBaseAdmin#testTableExists can go zombie</summary>
      <description>See it here as a zombie in hadoopqa: https://builds.apache.org/job/PreCommit-HBASE-Build/6687/consoleTextLooking at it, we seem stuck in here:"RpcServer.handler=1,port=51776" daemon prio=10 tid=0x72001400 nid=0x17ea waiting on condition [0x71cd4000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:150) - locked &lt;0x81042070&gt; (a org.apache.hadoop.hbase.client.RpcRetryingCaller) at org.apache.hadoop.hbase.client.HTable.get(HTable.java:732) at org.apache.hadoop.hbase.master.TableNamespaceManager.get(TableNamespaceManager.java:111) - locked &lt;0x7f71ba70&gt; (a org.apache.hadoop.hbase.master.TableNamespaceManager) at org.apache.hadoop.hbase.master.HMaster.getNamespaceDescriptor(HMaster.java:3076) at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:1779) at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:1820) at org.apache.hadoop.hbase.protobuf.generated.MasterAdminProtos$MasterAdminService$2.callBlockingMethod(MasterAdminProtos.java:26698) at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2068) at org.apache.hadoop.hbase.ipc.RpcServer$CallRunner.run(RpcServer.java:1807) at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.consumerLoop(SimpleRpcScheduler.java:165) at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.access$000(SimpleRpcScheduler.java:41) at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler$1.run(SimpleRpcScheduler.java:113) at java.lang.Thread.run(Thread.java:662)This lock is held: 0x7f71ba70 We are doing retries against the new ns table.A bunch other threads are trying to get in here while we are retrying:"RpcServer.handler=0,port=51776" daemon prio=10 tid=0x72000400 nid=0x17e9 waiting for monitor entry [0x71d25000] java.lang.Thread.State: BLOCKED (on object monitor) at org.apache.hadoop.hbase.master.TableNamespaceManager.get(TableNamespaceManager.java:111) - waiting to lock &lt;0x7f71ba70&gt; (a org.apache.hadoop.hbase.master.TableNamespaceManager) at org.apache.hadoop.hbase.master.HMaster.getNamespaceDescriptor(HMaster.java:3076) at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:1779) at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:1820) at org.apache.hadoop.hbase.protobuf.generated.MasterAdminProtos$MasterAdminService$2.callBlockingMethod(MasterAdminProtos.java:26698) at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2068) at org.apache.hadoop.hbase.ipc.RpcServer$CallRunner.run(RpcServer.java:1807) at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.consumerLoop(SimpleRpcScheduler.java:165) at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.access$000(SimpleRpcScheduler.java:41) at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler$1.run(SimpleRpcScheduler.java:113) at java.lang.Thread.run(Thread.java:662)..."RpcServer.handler=4,port=51776" daemon prio=10 tid=0x72cc9000 nid=0x17ed waiting for monitor entry [0x71be1000] java.lang.Thread.State: BLOCKED (on object monitor) at org.apache.hadoop.hbase.master.TableNamespaceManager.get(TableNamespaceManager.java:111) - waiting to lock &lt;0x7f71ba70&gt; (a org.apache.hadoop.hbase.master.TableNamespaceManager) at org.apache.hadoop.hbase.master.HMaster.getNamespaceDescriptor(HMaster.java:3076) at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:1779) at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:1820) at org.apache.hadoop.hbase.protobuf.generated.MasterAdminProtos$MasterAdminService$2.callBlockingMethod(MasterAdminProtos.java:26698) at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2068) at org.apache.hadoop.hbase.ipc.RpcServer$CallRunner.run(RpcServer.java:1807) at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.consumerLoop(SimpleRpcScheduler.java:165) at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.access$000(SimpleRpcScheduler.java:41) at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler$1.run(SimpleRpcScheduler.java:113) at java.lang.Thread.run(Thread.java:662)"RpcServer.handler=3,port=51776" daemon prio=10 tid=0x72cc7800 nid=0x17ec waiting for monitor entry [0x71c32000] java.lang.Thread.State: BLOCKED (on object monitor) at org.apache.hadoop.hbase.master.TableNamespaceManager.get(TableNamespaceManager.java:111) - waiting to lock &lt;0x7f71ba70&gt; (a org.apache.hadoop.hbase.master.TableNamespaceManager) at org.apache.hadoop.hbase.master.HMaster.getNamespaceDescriptor(HMaster.java:3076) at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:1779) at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:1820) at org.apache.hadoop.hbase.protobuf.generated.MasterAdminProtos$MasterAdminService$2.callBlockingMethod(MasterAdminProtos.java:26698) at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2068) at org.apache.hadoop.hbase.ipc.RpcServer$CallRunner.run(RpcServer.java:1807) at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.consumerLoop(SimpleRpcScheduler.java:165) at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.access$000(SimpleRpcScheduler.java:41) at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler$1.run(SimpleRpcScheduler.java:113) at java.lang.Thread.run(Thread.java:662)"RpcServer.handler=2,port=51776" daemon prio=10 tid=0x72002c00 nid=0x17eb waiting for monitor entry [0x71c83000] java.lang.Thread.State: BLOCKED (on object monitor) at org.apache.hadoop.hbase.master.TableNamespaceManager.get(TableNamespaceManager.java:111) - waiting to lock &lt;0x7f71ba70&gt; (a org.apache.hadoop.hbase.master.TableNamespaceManager) at org.apache.hadoop.hbase.master.HMaster.getNamespaceDescriptor(HMaster.java:3076) at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:1779) at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:1820) at org.apache.hadoop.hbase.protobuf.generated.MasterAdminProtos$MasterAdminService$2.callBlockingMethod(MasterAdminProtos.java:26698) at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2068) at org.apache.hadoop.hbase.ipc.RpcServer$CallRunner.run(RpcServer.java:1807) at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.consumerLoop(SimpleRpcScheduler.java:165) at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.access$000(SimpleRpcScheduler.java:41) at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler$1.run(SimpleRpcScheduler.java:113) at java.lang.Thread.run(Thread.java:662)I'd guess no one is getting in here till we finish our 35 retryings (almost ten minutes, which makes us look like a zombie).Seems like we need to be able to interrupt in here when done or at least add logging why we are in here having trouble trying to get from the ns table?</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="920" opendate="2008-10-11 00:00:00" fixdate="2008-10-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make region balancing sloppier</summary>
      <description>The region load balancer is exacting. Here's the logic: if (avgLoad &gt; 2.0 &amp;&amp; thisServersLoad.getNumberOfRegions() &gt; avgLoad) { if (LOG.isDebugEnabled()) { LOG.debug("Server " + serverName + " is overloaded. Server load: " + thisServersLoad.getNumberOfRegions() + " avg: " + avgLoad); }...On a cluster of thousands of regions, especially around startup or if there's been a crash, the above makes for a bunch of churn as load balancer closes and opens nodes to achieve an exact balance (all nodes must be &lt;= to average).I'd suggest that nodes should be left alone if they are within some percentage of the average &amp;#8211; say 10% (should be configurable).</description>
      <version>None</version>
      <fixedVersion>0.18.1,0.19.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStoreFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.RegionManager.java</file>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9210" opendate="2013-8-13 00:00:00" fixdate="2013-8-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>"hbase shell -d" doesn&amp;#39;t print out exception stack trace</summary>
      <description>when starting shell with "-d" specified, the following line doesn't print anything because debug isn't set when shell is constructed."Backtrace: #{e.backtrace.join("\n ")}" if debugIn addition, the existing code prints the outer most exception while we normally need the root cause exception.</description>
      <version>0.98.0,0.95.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.ruby.shell.commands.rb</file>
      <file type="M">bin.region.status.rb</file>
      <file type="M">bin.region.mover.rb</file>
      <file type="M">bin.hirb.rb</file>
    </fixedFiles>
  </bug>
  <bug id="9224" opendate="2013-8-14 00:00:00" fixdate="2013-8-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Print out name of the method we do not support rather than throw NPE</summary>
      <description>If a client is trying to invoke a method we do not support, we just NPE, rather than return an unsupported exception w/ name of the method we do not support. Makes it hard debugging what client is doing wrong.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="9246" opendate="2013-8-16 00:00:00" fixdate="2013-8-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove ROOT_TABLEDESC, ROOT_REGIONINFO, and ROOT_TABLE_NAME</summary>
      <description>ROOT has been removed from trunk / 0.95 but is still present in namespaces code and in unit tests. This culls these references.</description>
      <version>0.95.2,0.96.0</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestMergeTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestFSTableDescriptors.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestHRegionLocation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestStorageClusterStatusModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRollingRestart.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRestartCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestClientScannerRPCTimeout.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSTableDescriptors.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.TableName.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
    </fixedFiles>
  </bug>
  <bug id="9247" opendate="2013-8-16 00:00:00" fixdate="2013-8-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cleanup Key/KV/Meta/MetaKey Comparators</summary>
      <description>HBASE-9164 converted KVComparator's KeyCompare#compare guts from one that assumed a contiguous array backing a KV to one that used the Cell interface which doesn't have this assumption.There is now duplicate code that should be cleaned up.</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMemStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestSeekTo.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestReseekTo.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileWriterV2.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileSeek.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFilePerformance.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileBlockIndex.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestFixedFileTrailer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestPrefixTreeEncoding.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestDataBlockEncoders.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.CompoundBloomFilterWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.CompoundBloomFilterBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.CompoundBloomFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ByteBloomFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.BloomFilterFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.BloomFilterBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.GetClosestRowBeforeTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileWriterV2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderV2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.AbstractHFileWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.AbstractHFileReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.HalfStoreFileReader.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeCodec.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestKeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Bytes.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.TableName.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.PrefixKeyDeltaEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.FastDiffDeltaEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.DiffKeyDeltaEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.DataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.CopyKeyDataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Result.java</file>
    </fixedFiles>
  </bug>
  <bug id="9248" opendate="2013-8-16 00:00:00" fixdate="2013-8-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Place holders for tags in 0.96 to accommodate tags in 0.98</summary>
      <description>This JIRA is focused on adding placeholders for tags in 0.96 so that 0.98 would be easier to accommodate tags.Changes would be in WAL Encoders/decoders with compression.PrefixTree codec. (Had an offline discussion with Matt Corgan on this).If anything else would be needed I can add it in this JIRA.</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.trace.SpanReceiverHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALCellCodec.java</file>
      <file type="M">hbase-prefix-tree.src.test.java.org.apache.hadoop.hbase.codec.prefixtree.blockmeta.TestBlockMeta.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeBlockMeta.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeCell.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.Cell.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.ipc.TestPayloadCarryingRpcController.java</file>
    </fixedFiles>
  </bug>
  <bug id="9253" opendate="2013-8-16 00:00:00" fixdate="2013-8-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up IT test code</summary>
      <description>Make sure that tests don't override conf values Clean up formatting remove dead code clean up warnings.</description>
      <version>0.98.0,0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestLoadAndVerify.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.mttr.IntegrationTestMTTR.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.mapreduce.IntegrationTestImportTsv.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.mapreduce.IntegrationTestBulkLoad.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestsDriver.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestManyRegions.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestLazyCfLoading.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.monkies.PolicyBasedChaosMonkey.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.monkies.ChaosMonkey.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.RestartRandomRsAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.RemoveColumnAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.CompactTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.AddColumnAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.Action.java</file>
    </fixedFiles>
  </bug>
  <bug id="9259" opendate="2013-8-18 00:00:00" fixdate="2013-9-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update hadoop versions grid in refguide adding hadoop-2.1.x and a note on hadoop-2.0.x versions</summary>
      <description>Need to update our hadoop versions grid. Add notes on hadoop-2.1 and hadoop-2.0 (we do the former, not the latter)</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.preface.xml</file>
      <file type="M">src.main.docbkx.getting.started.xml</file>
      <file type="M">src.main.docbkx.configuration.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9268" opendate="2013-8-19 00:00:00" fixdate="2013-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Client doesn&amp;#39;t recover from a stalled region server</summary>
      <description>Got this testing the 0.95.2 RC.I killed -STOP a region server and let it stay like that while running PE. The clients didn't find the new region locations and in the jstack were stuck doing RPC. Eventually I killed -CONT and the client printed these:Exception in thread "TestClient-6" java.lang.RuntimeException: org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException: Failed 128 actions: IOException: 90 times, SocketTimeoutException: 38 times,</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="9276" opendate="2013-8-20 00:00:00" fixdate="2013-8-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>List tables API should filter with isSystemTable</summary>
      <description></description>
      <version>0.98.0,0.95.2,0.96.0</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="9277" opendate="2013-8-20 00:00:00" fixdate="2013-8-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>REST should use listTableNames to list tables</summary>
      <description></description>
      <version>0.98.0,0.95.2,0.94.12,0.96.0</version>
      <fixedVersion>0.98.0,0.94.12,0.96.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RootResource.java</file>
    </fixedFiles>
  </bug>
  <bug id="9279" opendate="2013-8-20 00:00:00" fixdate="2013-8-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thrift should use listTableNames to list tables</summary>
      <description></description>
      <version>0.98.0,0.95.2,0.94.11,0.96.0</version>
      <fixedVersion>0.98.0,0.94.12,0.96.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
    </fixedFiles>
  </bug>
  <bug id="9282" opendate="2013-8-20 00:00:00" fixdate="2013-8-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Minor logging cleanup; shorten logs, remove redundant info</summary>
      <description>Minor log cleanup; trying to get it so hbase logs can be read on a laptop screen w/o having to scroll right.</description>
      <version>None</version>
      <fixedVersion>0.96.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Threads.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKAssign.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
    </fixedFiles>
  </bug>
  <bug id="9285" opendate="2013-8-21 00:00:00" fixdate="2013-8-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>User who created table cannot scan the same table due to Insufficient permissions</summary>
      <description>User hrt_qa has been given 'C' permission.create 'te', {NAME =&gt; 'f1', VERSIONS =&gt; 5}...hbase(main):003:0&gt; listTABLEhbase:aclhbase:namespacete6 row(s) in 0.0570 secondshbase(main):004:0&gt; scan 'te'ROW COLUMN+CELL2013-08-21 02:21:00,921 DEBUG [main] token.AuthenticationTokenSelector: No matching token found2013-08-21 02:21:00,921 DEBUG [main] security.HBaseSaslRpcClient: Creating SASL GSSAPI client. Server's Kerberos principal name is hbase/hor16n13.gq1.ygridcore.net@HORTON.YGRIDCORE.NET2013-08-21 02:21:00,923 DEBUG [main] security.HBaseSaslRpcClient: Have sent token of size 582 from initSASLContext.2013-08-21 02:21:00,926 DEBUG [main] security.HBaseSaslRpcClient: Will read input token of size 0 for processing by initSASLContext2013-08-21 02:21:00,926 DEBUG [main] security.HBaseSaslRpcClient: Will send token of size 0 from initSASLContext.2013-08-21 02:21:00,926 DEBUG [main] security.HBaseSaslRpcClient: Will read input token of size 53 for processing by initSASLContext2013-08-21 02:21:00,927 DEBUG [main] security.HBaseSaslRpcClient: Will send token of size 53 from initSASLContext.2013-08-21 02:21:00,927 DEBUG [main] security.HBaseSaslRpcClient: SASL client context established. Negotiated QoP: auth2013-08-21 02:21:00,935 WARN [main] client.RpcRetryingCaller: Call exception, tries=0, retries=7, retryTime=-14msorg.apache.hadoop.hbase.security.AccessDeniedException: org.apache.hadoop.hbase.security.AccessDeniedException: Insufficient permissions for user 'hrt_qa' for scanner open on table te at org.apache.hadoop.hbase.security.access.AccessController.preScannerOpen(AccessController.java:1116) at org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preScannerOpen(RegionCoprocessorHost.java:1294) at org.apache.hadoop.hbase.regionserver.HRegionServer.scan(HRegionServer.java:3007) at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:26847)...Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(org.apache.hadoop.hbase.security.AccessDeniedException): org.apache.hadoop.hbase.security.AccessDeniedException: Insufficient permissions for user 'hrt_qa' for scanner open on table te at org.apache.hadoop.hbase.security.access.AccessController.preScannerOpen(AccessController.java:1116) at org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preScannerOpen(RegionCoprocessorHost.java:1294) at org.apache.hadoop.hbase.regionserver.HRegionServer.scan(HRegionServer.java:3007)Here was related entries in hbase:acl table:hbase(main):001:0&gt; scan 'hbase:acl'ROW COLUMN+CELL hbase:acl column=l:hrt_qa, timestamp=1377045996685, value=C te column=l:hrt_qa, timestamp=1377051648649, value=RWXCA</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlLists.java</file>
    </fixedFiles>
  </bug>
  <bug id="9294" opendate="2013-8-21 00:00:00" fixdate="2013-3-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>NPE in /rs-status during RS shutdown</summary>
      <description>While hitting reload to see when a kill-initiated RS shutdown would make the Web UI go away, I got a stack trace from an NPE</description>
      <version>0.95.2</version>
      <fixedVersion>0.96.2,0.98.1,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSStatusServlet.java</file>
    </fixedFiles>
  </bug>
  <bug id="9298" opendate="2013-8-22 00:00:00" fixdate="2013-8-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ns checker runs too frequently; too much mention in master logs</summary>
      <description>Make ns checker run every 5 minutes instead of every 30 seconds.Also fix a bit more logging. Can make the asyncprocess messages shorter by removing redundnate info like tablename.Did pass removing 'region' and 'server' and META qualifiers where they are not needed.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.NamespaceJanitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.catalog.MetaEditor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.HFileArchiver.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
    </fixedFiles>
  </bug>
  <bug id="9301" opendate="2013-8-22 00:00:00" fixdate="2013-9-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Default hbase.dynamic.jars.dir to hbase.rootdir/jars</summary>
      <description>A reasonable default for hbase.dynamic.jars.dir would be hbase.rootdir/jars so that folks aren't forced to edit their hbase-sites.xml to take advantage of the new, cool feature to load coprocessor/custom filter jars out of HDFS.</description>
      <version>0.98.0,0.95.2,0.94.12,0.96.0</version>
      <fixedVersion>0.98.0,0.94.12,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.migration.NamespaceUpgrade.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="9303" opendate="2013-8-22 00:00:00" fixdate="2013-8-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Snapshot restore of table which splits after snapshot was taken encounters &amp;#39;Region is not online&amp;#39;</summary>
      <description>Take snapshot of a table ('tablethree' in the log).Put some data in the table and split the table.Restore snapshot.Table cannot be enabled due to:Thu Aug 22 19:37:20 UTC 2013, org.apache.hadoop.hbase.client.RpcRetryingCaller@47a6ac39, org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: Region is not online: c32e63d8c8a1a94b68966645b956d86d at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2557) at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:3921) at org.apache.hadoop.hbase.regionserver.HRegionServer.scan(HRegionServer.java:2996) at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:26847)</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.94.12,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.RestoreSnapshotHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="9309" opendate="2013-8-22 00:00:00" fixdate="2013-8-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The links in the backup masters template are bad</summary>
      <description>If you try to go to a backup master web UI's, it doesn't work because the link is is missing "http://".</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.BackupMasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="9310" opendate="2013-8-22 00:00:00" fixdate="2013-8-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove slop for Stochastic load balancer</summary>
      <description>The new load balancer already has the idea of some slop built in. We shouldn't have two layers of it.</description>
      <version>0.98.0,0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
    </fixedFiles>
  </bug>
  <bug id="9311" opendate="2013-8-22 00:00:00" fixdate="2013-8-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create a migration script that will move data from 0.94.x to 0.96</summary>
      <description>We need a script to migrate zk, introduce namespaces, etc. Himanshu has done it up in the parent issue but parent issue is broader than just the script. Let this subtask be used to commit his first cut at the script.</description>
      <version>None</version>
      <fixedVersion>0.96.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.migration.TestNamespaceUpgrade.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HFileV1Detector.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.migration.NamespaceUpgrade.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationStateZKBase.java</file>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug id="9319" opendate="2013-8-23 00:00:00" fixdate="2013-8-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Apply &amp;#39;HBASE-7685 Closing socket connection can&amp;#39;t be removed from SecureClient&amp;#39; to trunk</summary>
      <description>liuxiong notes we failed to apply hbase-7685 to trunk (over in HBASE-7685). This issue fixes this oversight.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="9333" opendate="2013-8-23 00:00:00" fixdate="2013-10-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase.hconnection.threads.max should not be configurable else you get RejectedExecutionException</summary>
      <description>Trying to set hbase.hconnection.threads.max to a lower number than its default of Integer.MAX_VALUE simply results in a RejectedExecutionException when the max is reached. It seems there's no good reason to keep this configurable.</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="9337" opendate="2013-8-26 00:00:00" fixdate="2013-8-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>shell &amp;#39;user_permission&amp;#39; throws no method &amp;#39;toStringBinary&amp;#39; for (o.a.h.h.TableName)</summary>
      <description>the user_permission shell code is trying to convert a TableName object to a string, and it throwshbase(main):010:0&gt; user_permission User Table,Family,Qualifier:Permission ERROR: no method 'toStringBinary' for arguments (org.apache.hadoop.hbase.TableName) on Java::OrgApacheHadoopHbaseUtil::Bytes available overloads: (java.nio.ByteBuffer) (byte[])</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.ruby.hbase.security.rb</file>
    </fixedFiles>
  </bug>
  <bug id="9340" opendate="2013-8-26 00:00:00" fixdate="2013-8-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>revoke &amp;#39;user&amp;#39; throws ArrayIndexOutOfBoundsException</summary>
      <description>Trying to revoke a global rights throwshbase(main):004:0&gt; revoke 'test'Java::JavaLang::ArrayIndexOutOfBoundsException: 3The problem is that jruby is not able to do the bind with revoke(..., Permission.Action... actions)</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.ruby.hbase.security.rb</file>
    </fixedFiles>
  </bug>
  <bug id="9342" opendate="2013-8-26 00:00:00" fixdate="2013-8-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>WebUI fixes after bootstrap 3.0 update</summary>
      <description></description>
      <version>0.98.0,0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.rest.rest.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.zk.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.tablesDetailed.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.snapshot.jsp</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="937" opendate="2008-10-19 00:00:00" fixdate="2008-10-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thrift getRow does not support specifying columns</summary>
      <description>Thrift interface has a getRow function but it does not support asking for specific columns.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.thrift.TestThriftServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.Hbase.thrift</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.generated.Hbase.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9370" opendate="2013-8-28 00:00:00" fixdate="2013-8-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add logging to Schema change Chaos actions.</summary>
      <description></description>
      <version>0.98.0,0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.RemoveColumnAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.ChangeVersionsAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.ChangeEncodingAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.AddColumnAction.java</file>
    </fixedFiles>
  </bug>
  <bug id="9379" opendate="2013-8-29 00:00:00" fixdate="2013-8-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Doc that localfs is not durable</summary>
      <description>Lets at least doc. that localfs is not durable. qwertymaniac put up a patch on the parent issue.</description>
      <version>None</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.getting.started.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9382" opendate="2013-8-29 00:00:00" fixdate="2013-8-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>replicateWALEntry doesn&amp;#39;t use the replication handlers</summary>
      <description>By default we assign 3 handlers for replication, but as far as I can tell the replication traffic uses the normal handlers in 0.96</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.QosFunction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
    </fixedFiles>
  </bug>
  <bug id="9387" opendate="2013-8-29 00:00:00" fixdate="2013-9-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Region could get lost during assignment</summary>
      <description>I observed test timeout running against hadoop 2.1.0 with distributed log replay turned on.Looks like region state for 1588230740 became inconsistent between master and the surviving region server:2013-08-29 22:15:34,180 INFO [AM.ZK.Worker-pool2-t4] master.RegionStates(299): Onlined 1588230740 on kiyo.gq1.ygridcore.net,57016,1377814510039...2013-08-29 22:15:34,587 DEBUG [Thread-221] client.HConnectionManager$HConnectionImplementation(1269): locateRegionInMeta parentTable=hbase:meta, metaLocation={region=hbase:meta,,1.1588230740, hostname=kiyo.gq1.ygridcore.net,57016,1377814510039, seqNum=0}, attempt=2 of 35 failed; retrying after sleep of 302 because: org.apache.hadoop.hbase.exceptions.RegionOpeningException: Region is being opened: 1588230740 at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2574) at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:3949) at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:2733) at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:26965) at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2063) at org.apache.hadoop.hbase.ipc.RpcServer$CallRunner.run(RpcServer.java:1800) at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.consumerLoop(SimpleRpcScheduler.java:165) at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.access$000(SimpleRpcScheduler.java:41)</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestFullLogReconstruction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.handler.TestOpenRegionHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MockRegionServerServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="9388" opendate="2013-8-30 00:00:00" fixdate="2013-9-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[replication] ZK Dump prints the raw PBUF for the HLog positions</summary>
      <description>Looking at the ZK dump in the master's web ui, I can see that we're not trying to parse the positions for the HLogs so it looks like "PBU���"</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="9390" opendate="2013-8-30 00:00:00" fixdate="2013-10-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>coprocessors observers are not called during a recovery with the new log replay algorithm</summary>
      <description>See the patch to reproduce the issue: If we activate log replay we don't have the events on WAL restore.Pinging jeffreyz, we discussed this offline.</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALEditsReplaySink.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Admin.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.AdminProtos.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.HLogPerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.SimpleRegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="9394" opendate="2013-8-30 00:00:00" fixdate="2013-8-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[replication] size accounting is completely off in the source</summary>
      <description>I was under the impression that I was sending way more data than I was expecting, so adding some more tracing I can see how much data I read VS how I much I think I'm sending:Seeking at position 163771687Replicating 2 entries of total size 2790Seeking at position 166723643That's about 2MB of data, not 2KB.</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="9400" opendate="2013-8-30 00:00:00" fixdate="2013-9-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[UI] Catalog tables section isn&amp;#39;t aligned</summary>
      <description>I attached a picture of what I got. You can see it doesn't look right.One more thing is that the page doesn't auto-refresh when you switch tabs. For example, click Catalog tables, create a new table, click User tables, you don't see the new table. You need to refresh the page to see it.</description>
      <version>0.95.2,0.96.0</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.css.hbase.css</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="9428" opendate="2013-9-4 00:00:00" fixdate="2013-9-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Regex filters are at least an order of magnitude slower since 0.94.3</summary>
      <description>I found this issue after debugging a performance problem on an OpenTSDB cluster, it was basically unusable after an upgrade from 0.94.2 to 0.94.6. It was caused by HBASE-7279 (ping lhofhansl).The easiest way to see it is to run a simple 1 client PE:$ ./bin/hbase org.apache.hadoop.hbase.PerformanceEvaluation sequentialWrite 1Then in the shell do a filter scan (flush the table first and make sure if fits in your blockcache if you want stable numbers).Pre HBASE-7279:hbase(main):028:0&gt; scan 'TestTable', {FILTER =&gt; "(RowFilter (=, 'regexstring:0000055872') )"}ROW COLUMN+CELL 0000055872 column=info:data, timestamp=1378248850191, value=(blanked) 1 row(s) in 1.2780 secondsPost HBASE-7279hbase(main):037:0* scan 'TestTable', {FILTER =&gt; "(RowFilter (=, 'regexstring:0000055872') )"}ROW COLUMN+CELL 0000055872 column=info:data, timestamp=1378248850191, value=(blanked) 1 row(s) in 24.2940 secondsI tried a bunch of 0.94, up to 0.94.11, and the tip of 0.96. They are all slow like this.It seems that since that jira went in we do a lot more row matching, and running the regex gets super expensive.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.94.12,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.RegexStringComparator.java</file>
    </fixedFiles>
  </bug>
  <bug id="9435" opendate="2013-9-4 00:00:00" fixdate="2013-10-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix jersey serialization/deserialization of json objects</summary>
      <description>Stargate uses the default json marshaller/unmarshaller in natural mode. In this mode the unmarshaller has trouble unmarshalling json instances. This patch fixes this issue by using jackson as the marshaller/unmarshaller instead. I've also updated all the model unit tests to test json serialization/deserialization. Backwards compatibilty can be verified by modify the test base class to use the original marshaller/unmarshaller and see that model tests pass.The patch is backward compatible except for StorageClusterStatusModel, which is broken anyway. It only shows one node in the liveNodes field.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestStatusResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestSchemaResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestVersionModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestTableSchemaModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestTableRegionModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestTableListModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestTableInfoModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestStorageClusterVersionModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestStorageClusterStatusModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestScannerModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestRowModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestColumnSchemaModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestCellSetModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestCellModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.TableSchemaModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.StorageClusterVersionModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.RowModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.ColumnSchemaModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.CellSetModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.CellModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="945" opendate="2008-10-21 00:00:00" fixdate="2008-10-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Be consistent in use of qualified/unqualified mapfile paths</summary>
      <description>A store that was made up in hdfs can't be examined using local filesystem because we &amp;#8211; or hadoop &amp;#8211; is inconsistent.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9450" opendate="2013-9-5 00:00:00" fixdate="2013-9-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestDistributedLogSplitting fails</summary>
      <description>Would you mind taking a look at a recent set of failures please jeffreyz? It seems to be failing more recently of late:https://issues.apache.org/jira/browse/HBASE-9438?page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel&amp;focusedCommentId=13759275#comment-13759275https://builds.apache.org/job/PreCommit-HBASE-Build/7060//testReport/https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/703/Thank you.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="9451" opendate="2013-9-6 00:00:00" fixdate="2013-9-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Meta remains unassigned when the meta server crashes with the ClusterStatusListener set</summary>
      <description>While running tests described in HBASE-9338, ran into this problem. The hbase.status.listener.class was set to org.apache.hadoop.hbase.client.ClusterStatusListener$MultiCastListener.1. I had the meta server coming down2. The metaSSH got triggered. The call chain: 2.1 verifyAndAssignMetaWithRetries 2.2 verifyMetaRegionLocation 2.3 waitForMetaServerConnection 2.4 getMetaServerConnection 2.5 getCachedConnection 2.6 HConnectionManager.getAdmin(serverName, false) 2.7 isDeadServer(serverName) -&gt; This is hardcoded to return 'false' when the clusterStatusListener field is null. If clusterStatusListener is not null (in my test), then it could return true in certain cases (and in this case, indeed it should return true since the server is down). I am trying to understand why it's hardcoded to 'false' for former case.3. When isDeadServer returns true, the method HConnectionManager.getAdmin(ServerName, boolean) throws RegionServerStoppedException.4. Finally, after the retries are over verifyAndAssignMetaWithRetries gives up and the master aborts.The methods in the above call chain don't handle RegionServerStoppedException. Maybe something to look at...</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.catalog.CatalogTracker.java</file>
    </fixedFiles>
  </bug>
  <bug id="9456" opendate="2013-9-6 00:00:00" fixdate="2013-9-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Meta doesn&amp;#39;t get assigned in a master failure scenario</summary>
      <description>The flow:1. Cluster is up, meta is assigned to some server2. Master is killed3. Master is brought up, it is initializing. It learns about the Meta server (in assignMeta).4. Server holding meta is killed5. Meta never gets reassigned since the SSH wasn't enabled</description>
      <version>None</version>
      <fixedVersion>0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="946" opendate="2008-10-21 00:00:00" fixdate="2008-10-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Row with 55k deletes timesout scanner lease</summary>
      <description>Made a blocker because it was found by Jon Gray (smile)So, Jon Gray has a row with 55k deletes all in the same row. When he tries to scan, his scanner timesout when it gets to this row. The root cause is the mechanism we use to make sure a delete in a new store file overshadows an entry at same address in an old file. We accumulate a List of all deletes encountered. Before adding a delete to the List, we check if already a deleted. This check is whats killing us. One issue is that its doing super inefficient check of whether table is root but even fixing this inefficency &amp;#8211; and then removing the check for root since its redundant we're still too slow.Chatting with Jim K, he suggested that ArrayList check is linear. Changing the aggregation of deletes to instead use HashSet makes all run an order of magnitude faster.Also part of this issue, need to figure why on compaction we are not letting go of these deletes.Filing this issue against 0.18.1 so it gets into the RC2 (after chatting w/ J-D and JK &amp;#8211; J-D is seeing the issue also).</description>
      <version>None</version>
      <fixedVersion>0.18.1,0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestHStoreFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStoreScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.BeforeThisStoreKey.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HStoreKey.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9461" opendate="2013-9-7 00:00:00" fixdate="2013-9-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Some doc and cleanup in RPCServer</summary>
      <description>RPC is a dog to follow. I want to do buffer pooling for reading requests but its tough drawing the diagram of who is doing what when. HBASE-8884 seems to have made it more involved still. This issue is about doing a bit of untangling.</description>
      <version>None</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestIPC.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServerInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RequestContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.FifoRpcScheduler.java</file>
    </fixedFiles>
  </bug>
  <bug id="9487" opendate="2013-9-10 00:00:00" fixdate="2013-9-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>create_namespace with property value throws error</summary>
      <description>Creating a namespace with properties fails from shell: hbase(main):002:0&gt; create_namespace 'ns1',{'PROERTY_NAME'=&gt;'PROPERTY_VALUE'}ERROR: undefined method `addProperty' for #&lt;Java::OrgApacheHadoopHbase::NamespaceDescriptor::Builder:0x71b98cbb&gt;Here is some help for this command:Create namespace; pass namespace name,and optionally a dictionary of namespace configuration.Examples:hbase&gt; create_namespace 'ns1'hbase&gt; create_namespace 'ns1', {'PROERTY_NAME'=&gt;'PROPERTY_VALUE'}</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug id="9489" opendate="2013-9-10 00:00:00" fixdate="2013-12-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add cp hooks in online merge before and after setting PONR</summary>
      <description>As we need to merge index region along with user region we need the hooks before and after setting PONR in region merge transtion.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionMergeTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionMergeTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionServerObserver.java</file>
    </fixedFiles>
  </bug>
  <bug id="949" opendate="2008-10-22 00:00:00" fixdate="2008-10-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add an HBase Manual</summary>
      <description>HBase needs a Manual. Manual can be checked in under docs and evolve as hbase does (Hopefully we get to a state where new feature can't be closed unless manual has been updated to include mention and howto). Let this issue be about adding under docs an outline with some basic getting started info. Thereafter, we can open individual issues to add "chapters" or topics.Made it a blocker on 0.20.0.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docs.src.documentation.content.xdocs.site.xml</file>
      <file type="M">docs.skin.images.rc-t-r-5-1header-2tab-unselected-3tab-unselected.png</file>
      <file type="M">docs.skin.images.rc-t-r-5-1header-2tab-selected-3tab-selected.png</file>
      <file type="M">docs.skin.images.rc-t-r-5-1header-2searchbox-3searchbox.png</file>
      <file type="M">docs.skin.images.rc-t-r-15-1body-2menu-3menu.png</file>
      <file type="M">docs.skin.images.rc-t-l-5-1header-2tab-unselected-3tab-unselected.png</file>
      <file type="M">docs.skin.images.rc-t-l-5-1header-2tab-selected-3tab-selected.png</file>
      <file type="M">docs.skin.images.rc-t-l-5-1header-2searchbox-3searchbox.png</file>
      <file type="M">docs.skin.images.rc-b-r-5-1header-2tab-selected-3tab-selected.png</file>
      <file type="M">docs.skin.images.rc-b-r-15-1body-2menu-3menu.png</file>
      <file type="M">docs.skin.images.rc-b-l-15-1body-2menu-3menu.png</file>
      <file type="M">docs.linkmap.pdf</file>
      <file type="M">docs.linkmap.html</file>
      <file type="M">docs.index.html</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9497" opendate="2013-9-10 00:00:00" fixdate="2013-9-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Old .META. .tableinfo file kills HMaster</summary>
      <description>In pre-0.96, .META. has .tableinfo files which refer to .META. On startup, master tries to read it and aborts since the table name has changed. The .META. .tableinfo files are not being created in 0.94.x (fixed for 96 in HBASE-6971; but this can be reproduced when migrating from 0.92 -&gt; 0.94 -&gt; 0.96. Our old users would be affected by this.java.lang.IllegalArgumentException: .META. no longer exists. The table has been renamed to hbase:meta at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:291) at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:283) at org.apache.hadoop.hbase.HTableDescriptor.readFields(HTableDescriptor.java:960) at org.apache.hadoop.hbase.util.Writables.getWritable(Writables.java:131) at org.apache.hadoop.hbase.util.Writables.getWritable(Writables.java:101) at org.apache.hadoop.hbase.HTableDescriptor.parseFrom(HTableDescriptor.java:1407) at org.apache.hadoop.hbase.util.FSTableDescriptors.readTableDescriptor(FSTableDescriptors.java:521) at org.apache.hadoop.hbase.util.FSTableDescriptors.createTableDescriptorForTableDirectory(FSTableDescriptors.java:707) at org.apache.hadoop.hbase.util.FSTableDescriptors.createTableDescriptor(FSTableDescriptors.java:683) at org.apache.hadoop.hbase.util.FSTableDescriptors.createTableDescriptor(FSTableDescriptors.java:670) at org.apache.hadoop.hbase.master.MasterFileSystem.checkRootDir(MasterFileSystem.java:485) at org.apache.hadoop.hbase.master.MasterFileSystem.createInitialFileSystemLayout(MasterFileSystem.java:145) at org.apache.hadoop.hbase.master.MasterFileSystem.&lt;init&gt;(MasterFileSystem.java:129) at org.apache.hadoop.hbase.master.HMaster.finishInitialization(HMaster.java:761)</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.migration.NamespaceUpgrade.java</file>
    </fixedFiles>
  </bug>
  <bug id="9517" opendate="2013-9-12 00:00:00" fixdate="2013-9-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Include only InterfaceAudiencePublic elements in generated Javadoc</summary>
      <description>We should generate two sets of javadoc a la HADOOP-6658 &amp;#8211; one for api users that excludes all InterfaceAudiencePrivate apis, and one for hbase core developers. Eventually when we tighten up the other modules we might add another for coproc developers, and other custom 3rd party pluggable elements.</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.site.site.xml</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9523" opendate="2013-9-12 00:00:00" fixdate="2013-9-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Audit of hbase-common @InterfaceAudience.Public apis.</summary>
      <description>Do an audit of all public classes to make suare we are only publicly exposing what must be exposed. This was done by comparing the Public only version of the javadoc generated by HBASE-9517 to a local javadoc for the hbase-common module (cd hbase-common; mvn javadoc:javadoc).</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Threads.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Strings.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.SoftValueSortedMap.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Methods.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.JVM.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.EnvironmentEdgeManager.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.EnvironmentEdge.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.DefaultEnvironmentEdge.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ClassSize.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Classes.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Bytes.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteBufferArray.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Base64.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Addressing.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedBlobVar.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.DataBlockEncoding.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.compress.Compression.java</file>
    </fixedFiles>
  </bug>
  <bug id="9524" opendate="2013-9-13 00:00:00" fixdate="2013-12-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Multi row get does not return any results even if any one of the rows specified in the query is missing and improve exception handling</summary>
      <description>When a client tries to retrieve multiple rows using REST API, even if one of the specified rows does not exist, 404 is returned. The correct way should be to return the result for the found rows and ignore the non-existent ones. Also, in the current code base, only some exceptions are handled, if some exception like Access denied or no column found exception is throws by the APIs, 500 ( server not found) is returned to user. This is leaves the end user wondering what caused the rest command to fail.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.2,0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestRowResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestMultiRowResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.client.TestRemoteTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.SchemaResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RowResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RootResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ResourceBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.MultiRowResource.java</file>
    </fixedFiles>
  </bug>
  <bug id="9525" opendate="2013-9-13 00:00:00" fixdate="2013-9-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>"Move" region right after a region split is dangerous</summary>
      <description>I ran into a situation where the CM issued a move for a region just after a region was split. The master went bonkers since the master honored the CM request, and assigned the split region, but subsequently all the region state assumptions on this (split)region was messed up. I started seeing log lines lines like "THIS SHOULD NOT HAPPEN". Also, it created other problems - a compaction on original region happened on the new assignee, and then the daughter regions started seeing issues to do with store files missing, etc., etc. I will upload the logs shortly.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionMergeTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="9536" opendate="2013-9-15 00:00:00" fixdate="2013-9-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix minor javadoc warnings</summary>
      <description>I applied the trunk patch. Let me check 0.96 for warnings too.</description>
      <version>None</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="9539" opendate="2013-9-15 00:00:00" fixdate="2013-9-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Handle post namespace snapshot files when checking for HFile V1</summary>
      <description>When checking for HFileV1 before upgrading to 96, the snapshot file links tries to read from post-namespace locations. The migration script needs to be run on 94 cluster, and it requires reading the old (94) layout to check for HFileV1.Got exception while reading trailer for file: hdfs://xxx:41020/cops/cluster_collection_events_snapshot/2086db948c484be62dcd76c170fe0b17/meta/cluster_collection_event=42037b88dbc34abff6cbfbb1fde2c900-c24b358ddd2f4429a7287258142841a2java.io.FileNotFoundException: Unable to open link: org.apache.hadoop.hbase.io.HFileLink locations=[hdfs://xxx:41020/hbase-96/data/default/cluster_collection_event/42037b88dbc34abff6cbfbb1fde2c900/meta/c24b358ddd2f4429a7287258142841a2, hdfs://xxx:41020/hbase-96/.tmp/data/default/cluster_collection_event/42037b88dbc34abff6cbfbb1fde2c900/meta/c24b358ddd2f4429a7287258142841a2, hdfs://xxx:41020/hbase-96/archive/data/default/cluster_collection_event/42037b88dbc34abff6cbfbb1fde2c900/meta/c24b358ddd2f4429a7287258142841a2]</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.migration.TestUpgradeTo96.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HFileV1Detector.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.migration.UpgradeTo96.java</file>
    </fixedFiles>
  </bug>
  <bug id="9570" opendate="2013-9-18 00:00:00" fixdate="2013-10-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>With AccessDeniedException, HBase shell would be better to just display the error message to be user friendly</summary>
      <description>When access unauthorized resource like table, AccessDeniedException will be thrown. In HBase shell, the error message with stack trace will be displayed as follows. It would be better to just display the error message avoiding the stack trace to be user friendly. ERROR: org.apache.hadoop.hbase.security.AccessDeniedException: Insufficient permissions for user 'u1' for scanner open on table t1 at org.apache.hadoop.hbase.security.access.AccessController.preScannerOpen(AccessController.java:1116) at org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preScannerOpen(RegionCoprocessorHost.java:1293) at org.apache.hadoop.hbase.regionserver.HRegionServer.scan(HRegionServer.java:3026) at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:26971) at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2083) at org.apache.hadoop.hbase.ipc.RpcServer$CallRunner.run(RpcServer.java:1820) at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.consumerLoop(SimpleRpcScheduler.java:165) at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.access$000(SimpleRpcScheduler.java:41) at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler$1.run(SimpleRpcScheduler.java:113) at java.lang.Thread.run(Thread.java:662)</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.rb</file>
    </fixedFiles>
  </bug>
  <bug id="9577" opendate="2013-9-18 00:00:00" fixdate="2013-9-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Log process environment variable on HBase service startup</summary>
      <description>HBase services already logs information related to JVM properties and command line arguments used to start the services which have been immensely helpful to investigate issues.One thing that they do not log is the environment variables and an unintended variable in the environment could lead to a scenario not reproducible anywhere else including its original location if the service is restarted differently.We should log environment variables (excluding those which may contains credentials) on service startup with option to disable this logging.</description>
      <version>0.95.2,0.94.11</version>
      <fixedVersion>0.96.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ServerCommandLine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMasterCommandLine.java</file>
    </fixedFiles>
  </bug>
  <bug id="9579" opendate="2013-9-19 00:00:00" fixdate="2013-9-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Sanity check visiblity and audience for server-side modules.</summary>
      <description>Similar to HBASE-9495 we should audit the hbase-hadoop*-compat, hbase-prefix-tree, hbase-protocol and hbase server-modules. I'll go through each module first making most things private, and then do a second pass using some sort of LimitedPrivate marking for apis that we'd expect coprocs or advanced tests to use.This is less urgent that the work for the client facing apis.</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.Driver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.SortedCopyOnWriteSet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.JvmVersion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsckRepair.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HashedBytes.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.DirectMemoryUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.TableDescriptors.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AuthResult.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RowProcessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MiniBatchOperationInProgress.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureMemberRpcs.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureCoordinatorRpcs.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.SubprocedureFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ProcedureMemberRpcs.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ProcedureMember.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ProcedureCoordinatorRpcs.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ProcedureCoordinator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.Procedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.LoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableSplit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableReduce.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableRecordReaderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableRecordReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableOutputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableMapReduceUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableMap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableInputFormatBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.RowCounter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.IdentityTableReduce.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.IdentityTableMap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.HRegionPartitioner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.GroupingTableMap.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Action.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.thrift.MetricsThriftServerSource.java</file>
      <file type="M">hbase-hadoop1-compat.src.main.java.org.apache.hadoop.metrics2.lib.MetricMutableQuantiles.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceFactoryImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.balancer.MetricsBalancerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsAssignmentManagerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterFilesystemSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterSourceFactoryImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsSnapshotSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.metrics.BaseSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.metrics.MBeanSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionAggregateSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceFactoryImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.wal.MetricsEditsReplaySourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.wal.MetricsWALSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.replication.regionserver.MetricsReplicationSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.rest.MetricsRESTSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.thrift.MetricsThriftServerSourceFactoryImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.thrift.MetricsThriftServerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.impl.JmxCacheBuster.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.DynamicMetricsRegistry.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.MetricMutableQuantiles.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.MetricsExecutorImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.MutableHistogram.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.scanner.CellScannerPosition.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.example.ZKTableArchiveClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.coprocessor.RowProcessorClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.codec.MessageCodec.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.AggregateImplementation.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseRowProcessorEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.ObserverContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.WALCoprocessorEnvironment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.WALObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.errorhandling.ForeignExceptionSnare.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.errorhandling.TimeoutExceptionInjector.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.UniqueIndexMap.java</file>
    </fixedFiles>
  </bug>
  <bug id="9580" opendate="2013-9-19 00:00:00" fixdate="2013-5-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document the meaning of @InterfaceAudience in hbase ref guide</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.developer.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9656" opendate="2013-9-25 00:00:00" fixdate="2013-9-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove decimal places from Requests Per Second stats</summary>
      <description>The Requests Per Second stats on the Master and RegionServer UI pages would look better without decimal places.</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.RegionServerListTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="9661" opendate="2013-9-26 00:00:00" fixdate="2013-9-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Consistent log severity level guards and statements</summary>
      <description>A log statement should be guarded by its matching severity level. A log statement like if (LOG.isTraceEnabled()) { LOG.debug(identifier + " opening connection to ZooKeeper ensemble=" + ensemble);doesn't make much sense because the log message is only printed out when TRACE-level is enabled. This inconsistency was possibly introduced when developers demoted the original log statement from DEBUG but forgot to change its corresponding log severity level.</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.catalog.CatalogTracker.java</file>
    </fixedFiles>
  </bug>
  <bug id="969" opendate="2008-10-28 00:00:00" fixdate="2008-10-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Won&amp;#39;t when storefile &gt; 2G (WAS -&gt; Won&amp;#39;t split under load)</summary>
      <description>Looks like a new bug where we won't split when under load. Some recent refactoring seems to have dropped our split provoker.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.io.BlockFSInputStream.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9699" opendate="2013-10-2 00:00:00" fixdate="2013-10-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>For Downstreamers using HBaseTestingUtility is hard.</summary>
      <description>Maven doesn't seem to play well with trasitive dependencies from -test jars. We should follow the lead of hadoop-common and create a module for test utilities.</description>
      <version>0.98.0,0.95.2,0.96.0</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-thrift.pom.xml</file>
      <file type="M">hbase-shell.pom.xml</file>
      <file type="M">hbase-it.pom.xml</file>
      <file type="M">hbase-examples.pom.xml</file>
      <file type="M">hbase-assembly.pom.xml</file>
      <file type="M">hbase-testing-util.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="970" opendate="2008-10-29 00:00:00" fixdate="2008-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update the copy/rename scripts to go against change API</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.rename.table.rb</file>
      <file type="M">bin.copy.table.rb</file>
    </fixedFiles>
  </bug>
  <bug id="9710" opendate="2013-10-4 00:00:00" fixdate="2013-11-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use the region name, not the encoded name, when region is not on current server</summary>
      <description>When we throw a RegionOpeningException or a NotServingRegionException we put the encoded region name in the exception, which isn't super useful. I propose putting the region name instead.</description>
      <version>0.95.2,0.96.0</version>
      <fixedVersion>0.98.0,0.96.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="9711" opendate="2013-10-4 00:00:00" fixdate="2013-10-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve HBASE-9428 - avoid copying bytes for RegexFilter unless necessary</summary>
      <description>Parent patch copies input for RegexFilter unconditionally.We should only do this if the KV portion into the passed byte[] is &lt; 1/2 of the passed byte[]. Otherwise we waste cycles.Patch is trivial and will be coming momentarily.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.0,0.94.13</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.RegexStringComparator.java</file>
    </fixedFiles>
  </bug>
  <bug id="9745" opendate="2013-10-11 00:00:00" fixdate="2013-10-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Append HBASE_CLASSPATH to end of Java classpath and use another env var for prefix</summary>
      <description>HBASE-9097 changed the behavior to prefix HBASE_CLASSPATH to end of Java classpath instead of appending it. This break existing behavior (read more on HBASE-9097).We should revert to existing behavior and provide another way to prefix certain jars to the classpath.</description>
      <version>0.98.0,0.95.2,0.94.11</version>
      <fixedVersion>0.98.0,0.94.13,0.96.1,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug id="9748" opendate="2013-10-11 00:00:00" fixdate="2013-10-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Address outstanding comments raised for HBASE-9696</summary>
      <description>This is a follow-up issue of HBASE-9696.There are some outstanding review comments in https://reviews.apache.org/r/14470/ that haven't been addressed. I will address them later in this jira.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerNoMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.handler.TestCloseRegionHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionMergeTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DeleteTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.BulkReOpen.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.master.RegionState.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKAssign.java</file>
    </fixedFiles>
  </bug>
</bugrepository>
