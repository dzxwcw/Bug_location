<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="13776" opendate="2015-5-26 00:00:00" fixdate="2015-5-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Setting illegal versions for HColumnDescriptor does not throw IllegalArgumentException</summary>
      <description>HColumnDescriptor hcd = new HColumnDescriptor( new HColumnDescriptor(HConstants.CATALOG_FAMILY) .setInMemory(true) .setScope(HConstants.REPLICATION_SCOPE_LOCAL) .setBloomFilterType(BloomType.NONE) .setCacheDataInL1(true)); final int minVersions = 123; final int maxVersions = 234; hcd.setMaxVersions(minVersions); hcd.setMinVersions(maxVersions);//no exception throw</description>
      <version>0.98.14,1.0.2,1.2.0,1.1.1,2.0.0</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="13846" opendate="2015-6-4 00:00:00" fixdate="2015-6-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Run MiniCluster on top of other MiniDfsCluster</summary>
      <description>Similar to how we don't start a mini-zk cluster when we already have one specified, this will skip starting a mini-dfs cluster if the user specifies a different one.</description>
      <version>0.98.14,1.2.0,1.1.1,2.0.0</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
    </fixedFiles>
  </bug>
  <bug id="14086" opendate="2015-7-15 00:00:00" fixdate="2015-7-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>remove unused bundled dependencies</summary>
      <description>We have some files with compatible non-ASL licenses that don't appear to be used, so remove them.</description>
      <version>None</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.2,1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.site.resources.css.freebsd.docbook.css</file>
      <file type="M">src.main.asciidoc.asciidoctor.css</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="14087" opendate="2015-7-15 00:00:00" fixdate="2015-8-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ensure correct ASF policy compliant headers on source/docs</summary>
      <description>we have a couple of files that are missing their headers. we have one file using old-style ASF copyrights</description>
      <version>None</version>
      <fixedVersion>1.0.2,1.2.0,1.1.2,1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-native-client.src.rpc.CMakeLists.txt</file>
      <file type="M">src.main.xslt.configuration.to.asciidoc.chapter.xsl</file>
      <file type="M">src.main.site.xdoc.sponsors.xml</file>
      <file type="M">src.main.site.xdoc.resources.xml</file>
      <file type="M">src.main.site.xdoc.replication.xml</file>
      <file type="M">src.main.site.xdoc.pseudo-distributed.xml</file>
      <file type="M">src.main.site.xdoc.old.news.xml</file>
      <file type="M">src.main.site.xdoc.metrics.xml</file>
      <file type="M">src.main.site.xdoc.index.xml</file>
      <file type="M">src.main.site.xdoc.export.control.xml</file>
      <file type="M">src.main.site.xdoc.cygwin.xml</file>
      <file type="M">src.main.site.xdoc.bulk-loads.xml</file>
      <file type="M">src.main.site.xdoc.acid-semantics.xml</file>
      <file type="M">src.main.site.asciidoc.sponsors.adoc</file>
      <file type="M">src.main.site.asciidoc.resources.adoc</file>
      <file type="M">src.main.site.asciidoc.replication.adoc</file>
      <file type="M">src.main.site.asciidoc.pseudo-distributed.adoc</file>
      <file type="M">src.main.site.asciidoc.old.news.adoc</file>
      <file type="M">src.main.site.asciidoc.metrics.adoc</file>
      <file type="M">src.main.site.asciidoc.index.adoc</file>
      <file type="M">src.main.site.asciidoc.export.control.adoc</file>
      <file type="M">src.main.site.asciidoc.cygwin.adoc</file>
      <file type="M">src.main.site.asciidoc.bulk-loads.adoc</file>
      <file type="M">src.main.site.asciidoc.acid-semantics.adoc</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.HttpAuthenticationException.java</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.enable.table.replication.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.disable.table.replication.rb</file>
      <file type="M">hbase-server.src.test.resources.org.apache.hadoop.hbase.PerformanceEvaluation.Counter.properties</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestPrefetch.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestNullComparator.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestFuzzyRowAndColumnRangeFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestBitComparator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ProtoUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationLoad.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.JarFinder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HealthChecker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HealthCheckChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.EndpointObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseRegionServerObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.model.TestModelBase.java</file>
      <file type="M">hbase-native-client.src.sync.CMakeLists.txt</file>
      <file type="M">bin.considerAsDead.sh</file>
      <file type="M">bin.graceful.stop.sh</file>
      <file type="M">bin.hbase</file>
      <file type="M">bin.hbase-config.sh</file>
      <file type="M">bin.hbase-daemon.sh</file>
      <file type="M">bin.hbase-daemons.sh</file>
      <file type="M">bin.local-master-backup.sh</file>
      <file type="M">bin.local-regionservers.sh</file>
      <file type="M">bin.master-backup.sh</file>
      <file type="M">bin.regionservers.sh</file>
      <file type="M">bin.rolling-restart.sh</file>
      <file type="M">bin.start-hbase.sh</file>
      <file type="M">bin.stop-hbase.sh</file>
      <file type="M">bin.zookeepers.sh</file>
      <file type="M">conf.hadoop-metrics2-hbase.properties</file>
      <file type="M">conf.hbase-env.sh</file>
      <file type="M">conf.log4j.properties</file>
      <file type="M">dev-support.hbase.docker.README.md</file>
      <file type="M">dev-support.hbase.jdiff.acrossSingularityTemplate.xml</file>
      <file type="M">dev-support.hbase.jdiff.afterSingularityTemplate.xml</file>
      <file type="M">dev-support.hbase.jdiff.template.xml</file>
      <file type="M">dev-support.jdiffHBasePublicAPI.sh</file>
      <file type="M">dev-support.jdiffHBasePublicAPI.common.sh</file>
      <file type="M">dev-support.jenkinsEnv.sh</file>
      <file type="M">dev-support.publish.hbase.website.sh</file>
      <file type="M">dev-support.rebase.all.git.branches.sh</file>
      <file type="M">dev-support.smart-apply-patch.sh</file>
      <file type="M">dev-support.test-patch.sh</file>
      <file type="M">dev-support.test-util.sh</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RetriesExhaustedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.Coprocessor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.CoprocessorEnvironment.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.DroppedSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableExistsException.java</file>
      <file type="M">hbase-client.src.main.resources.META-INF.services.org.apache.hadoop.security.token.TokenIdentifier</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.LimitInputStream.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.AbstractByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.SimpleMutableByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.SimplePositionedMutableByteRange.java</file>
      <file type="M">hbase-examples.src.main.cpp.DemoClient.cpp</file>
      <file type="M">hbase-examples.src.main.cpp.Makefile</file>
      <file type="M">hbase-examples.src.main.perl.DemoClient.pl</file>
      <file type="M">hbase-examples.src.main.php.DemoClient.php</file>
      <file type="M">hbase-native-client.CMakeLists.txt</file>
      <file type="M">hbase-native-client.cmake.modules.FindGTest.cmake</file>
      <file type="M">hbase-native-client.cmake.modules.FindLibEv.cmake</file>
      <file type="M">hbase-native-client.README.md</file>
      <file type="M">hbase-native-client.src.async.CMakeLists.txt</file>
      <file type="M">hbase-native-client.src.core.CMakeLists.txt</file>
    </fixedFiles>
  </bug>
  <bug id="14199" opendate="2015-8-7 00:00:00" fixdate="2015-8-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>maven-remote-resources-plugin failure processing NOTICE.vm in hbase-assembly</summary>
      <description>Only seen when building 0.98 with -Dhadoop.profile=1.1. Happens with both JDK 6 and 7. [ERROR] Failed to execute goal org.apache.maven.plugins:maven-remote-resources-plugin:1.5:process(default) on project hbase-assembly: Error rendering velocity resource. Error invoking method'get(java.lang.Integer)' in java.util.ArrayList at META-INF/NOTICE.vm[line 275, column 22]:InvocationTargetException: Index: 0, Size: 0 -&gt; [Help 1]From later comment by busbey:"Use -Dlicense.debug.print.included=true and then to examine the generated LICENSE file to see what transitive dependency doesn't have license information.""</description>
      <version>0.98.14</version>
      <fixedVersion>0.98.14</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-resource-bundle.src.main.resources.supplemental-models.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1420" opendate="2009-5-13 00:00:00" fixdate="2009-5-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>add abliity to add and remove (table) indexes on existing tables</summary>
      <description>A first cut at adding/removing indexes to existing tables. Tested with small tables, and will not scale very good as is (should be a map/reduce).Factored out index maintenance stuff into indexMaintenanceUtils</description>
      <version>None</version>
      <fixedVersion>0.20.0,0.19.3</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.tableindexed.IndexedRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.tableindexed.IndexedTableAdmin.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="14209" opendate="2015-8-11 00:00:00" fixdate="2015-8-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestShell visibility tests failing</summary>
      <description>This is after HBASE-14105 but we've seen this earlier where adding ruby units to the shell tests can cause the visibility tests to fail inexplicably. We can't just avoid adding ruby units to TestShell in 0.98 so figure out the root cause and fix or disable these. 1) Error:test_The_get/put_methods_should_work_for_data_written_with_Visibility(Hbase::VisibilityLabelsAdminMethodsTest):NativeException: junit.framework.AssertionFailedError: Waiting timed out after [10,000] msec junit/framework/Assert.java:57:in `fail' org/apache/hadoop/hbase/Waiter.java:193:in `waitFor' org/apache/hadoop/hbase/Waiter.java:128:in `waitFor' org/apache/hadoop/hbase/HBaseTestingUtility.java:3514:in `waitFor' org/apache/hadoop/hbase/HBaseTestingUtility.java:3576:in `waitLabelAvailable' ./src/test/ruby/hbase/visibility_labels_admin_test.rb:73:in `test_The_get/put_methods_should_work_for_data_written_with_Visibility' org/jruby/RubyProc.java:270:in `call' org/jruby/RubyKernel.java:2105:in `send' org/jruby/RubyArray.java:1620:in `each' org/jruby/RubyArray.java:1620:in `each' 2) Error:test_The_set/clear_methods_should_work_with_authorizations(Hbase::VisibilityLabelsAdminMethodsTest):NativeException: junit.framework.AssertionFailedError: Waiting timed out after [10,000] msec junit/framework/Assert.java:57:in `fail' org/apache/hadoop/hbase/Waiter.java:193:in `waitFor' org/apache/hadoop/hbase/Waiter.java:128:in `waitFor' org/apache/hadoop/hbase/HBaseTestingUtility.java:3514:in `waitFor' org/apache/hadoop/hbase/HBaseTestingUtility.java:3576:in `waitLabelAvailable' ./src/test/ruby/hbase/visibility_labels_admin_test.rb:52:in `test_The_set/clear_methods_should_work_with_authorizations' org/jruby/RubyProc.java:270:in `call' org/jruby/RubyKernel.java:2105:in `send' org/jruby/RubyArray.java:1620:in `each' org/jruby/RubyArray.java:1620:in `each'</description>
      <version>0.98.14</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.2,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityLabelsCache.java</file>
    </fixedFiles>
  </bug>
  <bug id="1421" opendate="2009-5-13 00:00:00" fixdate="2009-5-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Processing a regionserver message -- OPEN, CLOSE, SPLIT, etc. -- and if we&amp;#39;re carrying more than one message in payload, if exception, all messages that follow are dropped on floor</summary>
      <description>Just saw this in pset cluster. Marking blocker. We had an incidence of HBASE-1344 on our 0.19.x era hbase cluster. The report from the regionserver was carrying at least two open messages. The first provoked the exception, the second open message was never processed. Regionserver thought it had successfully opened region. Master didn't know anything about it.</description>
      <version>None</version>
      <fixedVersion>0.20.0,0.19.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.RegionServerOperation.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.RegionManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ProcessRegionOpen.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="14247" opendate="2015-8-19 00:00:00" fixdate="2015-10-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Separate the old WALs into different regionserver directories</summary>
      <description>Currently all old WALs of regionservers are achieved into the single directory of oldWALs. In big clusters, because of long TTL of WAL or disabled replications, the number of files under oldWALs may reach the max-directory-items limit of HDFS, which will make the hbase cluster crashed.Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.FSLimitException$MaxDirectoryItemsExceededException): The directory item limit of /hbase/lgprc-xiaomi/.oldlogs is exceeded: limit=1048576 items=1048576A simple solution is to separate the old WALs into different directories according to the server name of the WAL.Suggestions are welcomed~ Thanks</description>
      <version>None</version>
      <fixedVersion>2.0.0-alpha-4,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationKillSlaveRS.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationKillMasterRS.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.ReplicationSourceDummy.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestWALEntryStream.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManagerZkImpl.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.cleaner.TestLogsCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.FSHLogProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.AsyncFSWALProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.AbstractFSWALProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.WALEntryStream.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.RecoveredReplicationSource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.DumpReplicationQueues.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.FileCleanerDelegate.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.CleanerChore.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueueInfo.java</file>
    </fixedFiles>
  </bug>
  <bug id="1430" opendate="2009-5-16 00:00:00" fixdate="2009-5-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Read the logs in batches during log splitting to avoid OOME</summary>
      <description>During log splitting, in the worst case we can read 64 logs of 64MB which will surely bust any heap. Instead we should read the logs in batches of 5-10 that we write right away.</description>
      <version>None</version>
      <fixedVersion>0.20.0,0.19.3</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HLog.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="14532" opendate="2015-10-1 00:00:00" fixdate="2015-11-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[book] dfs.client.read.shortcircuit is referenced as hbase-site.xml config and not described in section 7</summary>
      <description>After trying to figure out whether shortcircuit reads would work on my system, I studied the book and found conflicting information.It's suggested in section 92.2, that dfs.client.read.shortcircuit is an option in hbase-site.xml, but the supposedly complete default configuration in section 7 does not include this setting. This leads to confusion on whether it's sufficient to enable this setting in hdfs-site.xml, or whether it needs to be added to both configurations.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="14822" opendate="2015-11-17 00:00:00" fixdate="2015-12-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Renewing leases of scanners doesn&amp;#39;t work</summary>
      <description></description>
      <version>0.98.14</version>
      <fixedVersion>1.2.0,1.3.0,1.0.3,1.1.3,0.98.17,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestLeaseRenewal.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide3.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Client.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ClientProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="1489" opendate="2009-6-5 00:00:00" fixdate="2009-6-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Basic git ignores for people who use git and eclipse</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>
