<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="14250" opendate="2015-8-19 00:00:00" fixdate="2015-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>branch-1.1 hbase-server test-jar has incorrect LICENSE</summary>
      <description>test-jar LICENSE file for hbase-server claims jquery and the orca logo are present in the jar, when they are not.</description>
      <version>1.2.0,1.1.2,1.3.0,0.98.15,1.0.3,2.0.0</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.2,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="14251" opendate="2015-8-19 00:00:00" fixdate="2015-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>javadoc jars use LICENSE/NOTICE from primary artifact</summary>
      <description>Our generated javadoc jars have the same LICENSE/NOTICE files as our primary artifacts but do not include a copy of hte full source.the following modules end up with incorrect artifacts: hbase-server hbase-common (maybe? depends on the are-apis-copyrightable court case) hbase-thrift</description>
      <version>1.2.0,1.1.2,0.98.15,1.0.3,2.0.0</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.2,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.pom.xml</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-common.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="14348" opendate="2015-8-31 00:00:00" fixdate="2015-4-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update download mirror link</summary>
      <description>Where we refer to www.apache.org/dyn/closer.cgi, we need to refer towww.apache.org/dyn/closer.lua instead .</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.old.news.xml</file>
      <file type="M">src.site.xdoc.index.xml</file>
      <file type="M">src.site.site.xml</file>
      <file type="M">src.site.resources.doap.Hbase.rdf</file>
      <file type="M">src.site.asciidoc.old.news.adoc</file>
      <file type="M">src.main.asciidoc..chapters.getting.started.adoc</file>
      <file type="M">README.txt</file>
    </fixedFiles>
  </bug>
  <bug id="14349" opendate="2015-9-1 00:00:00" fixdate="2015-10-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>pre-commit zombie finder is overly broad</summary>
      <description>Zombie detector is flagging processes from builds that aren't ours.ex from HBASE-14337:-1 core zombie tests. There are 4 zombie test(s): at org.apache.reef.io.network.DeprecatedNetworkConnectionServiceTest.testMultithreadedSharedConnMessagingNetworkConnServiceRate(DeprecatedNetworkConnectionServiceTest.java:343)</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  <bug id="1458" opendate="2009-5-29 00:00:00" fixdate="2009-5-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>64 commit logs as upper bound is too many -- make it half</summary>
      <description>Running an upload, 64 commit logs as upper bound before we force flushes to clear the oldest edit is too much. I can see an upload running in my little cluster and even after running for an hour we still have not hit the 64 logs max. The more logs we have, the longer recovery on crash. We should halve the number I'd say.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HLog.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="14594" opendate="2015-10-13 00:00:00" fixdate="2015-10-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use new DNS API introduced in HADOOP-12437</summary>
      <description>HADOOP-12437 introduced a new API to org.apache.hadoop.net.DNS: getDefaultHost(String, String, boolean).The purpose of this method (the boolean argument really) is to change the functionality so that when rDNS fails, InetAddress#getCanonicalHostName() is consulted which includes resolution via the hosts file.The direct application of this new method is relevant on hosts with multiples NICs and Kerberos enabled.Sadly, this method only exists in 2.8.0-SNAPSHOT, so to benefit from the fix without great pain, some reflection is required.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,1.0.3,1.1.3,0.98.16,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.mapreduce.SweepJob.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.RESTServer.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.filter.AuthFilter.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.AuthUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.HQuorumPeer.java</file>
    </fixedFiles>
  </bug>
  <bug id="14605" opendate="2015-10-14 00:00:00" fixdate="2015-12-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Split fails due to &amp;#39;No valid credentials&amp;#39; error when SecureBulkLoadEndpoint#start tries to access hdfs</summary>
      <description>During recent testing in secure cluster (with HBASE-14475), we found the following when user X (non-super user) split a table with region replica:2015-10-12 10:58:18,955 ERROR [FifoRpcScheduler.handler1-thread-9] master.HMaster: Region server hbase-4-4.novalocal,60020,1444645588137 reported a fatal error:ABORTING region server hbase-4-4.novalocal,60020,1444645588137: The coprocessor org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint threw an unexpected exceptionCause:java.lang.IllegalStateException: Failed to get FileSystem instance at org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint.start(SecureBulkLoadEndpoint.java:148) at org.apache.hadoop.hbase.coprocessor.CoprocessorHost$Environment.startup(CoprocessorHost.java:415) at org.apache.hadoop.hbase.coprocessor.CoprocessorHost.loadInstance(CoprocessorHost.java:257) at org.apache.hadoop.hbase.coprocessor.CoprocessorHost.loadSystemCoprocessors(CoprocessorHost.java:160) at org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.&lt;init&gt;(RegionCoprocessorHost.java:192) at org.apache.hadoop.hbase.regionserver.HRegion.&lt;init&gt;(HRegion.java:701) at org.apache.hadoop.hbase.regionserver.HRegion.&lt;init&gt;(HRegion.java:608)...Caused by: java.io.IOException: Failed on local exception: java.io.IOException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]; Host Details : local host is: "hbase-4-4/172.22.66.186"; destination host is: "os-r6- okarus-hbase-4-2.novalocal":8020; at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772) at org.apache.hadoop.ipc.Client.call(Client.java:1473) at org.apache.hadoop.ipc.Client.call(Client.java:1400) at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232) at com.sun.proxy.$Proxy18.mkdirs(Unknown Source) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:555) at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187) at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) at com.sun.proxy.$Proxy19.mkdirs(Unknown Source) at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2775) at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2746) at org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:967) at org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:963) at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)The cause was that SecureBulkLoadEndpoint#start tried to create staging dir in hdfs as user X but didn't pass authentication.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,1.0.3,1.1.3,0.98.16,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestEndToEndSplitTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransactionImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitRequest.java</file>
    </fixedFiles>
  </bug>
  <bug id="14678" opendate="2015-10-22 00:00:00" fixdate="2015-3-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Experiment: Temporarily disable balancer and a few others to see if root of crashed/timedout JVMs</summary>
      <description>Looking at recent builds of 1.2, I see a few of the runs finishing with kills and notice that a JVM exited without reporting back state. Running the hanging test finder, I can see at least that in one case that the balancer tests seem to be outstanding; looking in test output, seems to be still going on.... A few others are reported as hung but they look like they have just started running and are just killed by surefire.This issue is about trying to disable a few of the problematics like balancer tests to see if our overall stability improves. If so, I can concentrate on stabilizing these few tests. Else will just undo the experiment and put the tests back on line.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMobSnapshotCloneIndependence.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotCloneIndependence.java</file>
      <file type="M">hbase-shell.src.test.java.org.apache.hadoop.hbase.client.TestShell.java</file>
      <file type="M">hbase-shell.src.test.java.org.apache.hadoop.hbase.client.TestReplicationShell.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestPartialResultsFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMasterFailoverWithProcedures.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestStochasticLoadBalancer2.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestStochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestMobFlushSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestWALSplitCompressed.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestWALSplit.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
    </fixedFiles>
  </bug>
  <bug id="14758" opendate="2015-11-4 00:00:00" fixdate="2015-11-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add UT case for unchecked error/exception thrown in AsyncProcess#sendMultiAction</summary>
      <description>This is an addendum for HBASE-14359, open a new JIRA to trigger HadoopQA run</description>
      <version>1.1.2,0.98.15</version>
      <fixedVersion>1.2.0,1.3.0,1.0.3,1.1.3,0.98.17,2.0.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestAsyncProcess.java</file>
    </fixedFiles>
  </bug>
  <bug id="14761" opendate="2015-11-4 00:00:00" fixdate="2015-11-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Deletes with and without visibility expression do not delete the matching mutation</summary>
      <description>This is from the user list as reported by Anoop Sharma running into an issue related to visibility expressions and delete.Example run from hbase shell is listed below.Will appreciate any help on this issue.thanks.In the example below, user running queries has ‘MANAGER’ authorization.*First example:* add a column with visib expr ‘MANAGER’ delete it by passing in visibility of ‘MANAGER’ This works and scan doesn’t return anything.*Second example:* add a column with visib expr ‘MANAGER’ delete it by not passing in any visibility. This doesn’t delete the column. Scan doesn’t return the row but RAW scan shows the column marked as deleteColumn. Now if delete is done again with visibility of ‘MANAGER’, it still doesn’t delete it and scan returns the original column.*Example 1:*hbase(main):096:0&gt; create 'HBT1', 'cf'hbase(main):098:0* *put 'HBT1', 'John', 'cf:a', 'CA',{VISIBILITY=&gt;'MANAGER'}*hbase(main):099:0&gt; *scan 'HBT1'*ROWCOLUMN+CELL John column=cf:a, timestamp=1446154722055,value=CA1 row(s) in 0.0030 secondshbase(main):100:0&gt; *delete 'HBT1', 'John', 'cf:a', {VISIBILITY=&gt;'MANAGER'}*0 row(s) in 0.0030 secondshbase(main):101:0&gt; *scan 'HBT1'*ROWCOLUMN+CELL0 row(s) in 0.0030 seconds*Example 2:*hbase(main):010:0* *put 'HBT1', 'John', 'cf:a', 'CA',{VISIBILITY=&gt;'MANAGER'}*0 row(s) in 0.0040 secondshbase(main):011:0&gt; *scan 'HBT1'*ROWCOLUMN+CELL John column=cf:a, timestamp=1446155346473,value=CA1 row(s) in 0.0060 secondshbase(main):012:0&gt; *delete 'HBT1', 'John', 'cf:a'*0 row(s) in 0.0090 secondshbase(main):013:0&gt; *scan 'HBT1'*ROWCOLUMN+CELL John column=cf:a, timestamp=1446155346473,value=CA1 row(s) in 0.0050 secondshbase(main):014:0&gt; *scan 'HBT1', {RAW =&gt; true}*ROWCOLUMN+CELL John column=cf:a, timestamp=1446155346519,type=DeleteColumn1 row(s) in 0.0060 secondshbase(main):015:0&gt; *delete 'HBT1', 'John', 'cf:a', {VISIBILITY=&gt;'MANAGER'}*0 row(s) in 0.0030 secondshbase(main):016:0&gt; *scan 'HBT1'*ROWCOLUMN+CELL John column=cf:a, timestamp=1446155346473,value=CA1 row(s) in 0.0040 secondshbase(main):017:0&gt; *scan 'HBT1', {RAW =&gt; true}*ROWCOLUMN+CELL John column=cf:a, timestamp=1446155346601,type=DeleteColumn1 row(s) in 0.0060 seconds</description>
      <version>1.0.0,1.0.1,1.1.0,1.0.2,1.1.2,0.98.15</version>
      <fixedVersion>1.2.0,1.3.0,1.0.3,1.1.3,0.98.17,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithDeletes.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityScanDeleteTracker.java</file>
    </fixedFiles>
  </bug>
  <bug id="14821" opendate="2015-11-16 00:00:00" fixdate="2015-11-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CopyTable should allow overriding more config properties for peer cluster</summary>
      <description>When using CopyTable across two separate clusters, you can specify the ZK quorum for the destination cluster, but not much else in configuration overrides. This can be a problem when the cluster configurations differ, such as when using security with different configurations for server principals.We should provide a general way to override configuration properties for the peer / destination cluster. One option would be to allow use of a prefix for command line properties ("peer.property."). Properties matching this prefix will be stripped and merged to the peer configuration.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableOutputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestHBaseConfiguration.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HBaseConfiguration.java</file>
    </fixedFiles>
  </bug>
  <bug id="15977" opendate="2016-6-7 00:00:00" fixdate="2016-6-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Failed variable substitution on home page</summary>
      <description>Check out the top-left of hbase.apache.org, there's an unevaluated variable $banner.name leaking through.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.site.site.xml</file>
    </fixedFiles>
  </bug>
  <bug id="17514" opendate="2017-1-23 00:00:00" fixdate="2017-4-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Warn when Thrift Server 1 is configured for proxy users but not the HTTP transport</summary>
      <description>The config hbase.thrift.support.proxyuser is ignored if the Thrift Server 1 isn't configured to use an HTTP transport with hbase.regionserver.thrift.http.We should emit a warning if our configs request proxy user support but don't specify that HTTP should be used for the transport.</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.2.6,1.3.2,1.1.11,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
    </fixedFiles>
  </bug>
  <bug id="17516" opendate="2017-1-23 00:00:00" fixdate="2017-3-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Table quota not taking precedence over namespace quota</summary>
      <description>Romil Choksi found a bug in the current patch-set where a more restrictive table quota did not take priority over a less-restrictive namespace quota.Turns out some of the logic to handle this case was incorrect.</description>
      <version>None</version>
      <fixedVersion>HBASE-16961,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestSpaceQuotas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestQuotaStatusRPCs.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestQuotaObserverChoreWithMiniCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaObserverChore.java</file>
    </fixedFiles>
  </bug>
  <bug id="17518" opendate="2017-1-24 00:00:00" fixdate="2017-4-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase Reference Guide has a syntax error</summary>
      <description>The image of "HFile Version 2 Structure" in Appendix F of HBase Reference Guide (pdf) is missing because of a wrong asciidoc syntax:image:hfilev2.png&amp;#91;HFile Version 2&amp;#93;modified as:image::hfilev2.png&amp;#91;HFile Version 2&amp;#93;it should be a double colon instead of single one</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.appendix.hfile.format.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="17520" opendate="2017-1-24 00:00:00" fixdate="2017-3-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement isTableEnabled/Disabled/Available methods</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTableAdminApi.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.AsyncMetaTableAccessor.java</file>
    </fixedFiles>
  </bug>
  <bug id="17522" opendate="2017-1-24 00:00:00" fixdate="2017-2-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RuntimeExceptions from MemoryMXBean should not take down server process</summary>
      <description>RegionServer died after MemoryMXBean threw an IllegalArgumentException while attempting to create a MemoryUsage object for the heap during construction of the server load.We shouldn't allow failure to get load information to take down the RS.</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.1,1.2.5,1.1.9,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDefaultMemStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestCacheConfig.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HeapMemoryManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.util.MemorySizeUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl.jamon</file>
    </fixedFiles>
  </bug>
</bugrepository>
