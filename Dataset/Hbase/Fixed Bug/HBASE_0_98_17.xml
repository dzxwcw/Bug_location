<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="15134" opendate="2016-1-20 00:00:00" fixdate="2016-7-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add visibility into Flush and Compaction queues</summary>
      <description>On busy spurts we can see regionservers start to see large queues for compaction. It's really hard to tell if the server is queueing a lot of compactions for the same region, lots of compactions for lots of regions, or just falling behind.For flushes much the same. There can be flushes in queue that aren't being run because of delayed flushes. There's no way to know from the metrics how many flushes are for each region, how many are delayed. Etc.We should add either more metrics around this ( num per region, max per region, min per region ) or add on a UI page that has the list of compactions and flushes.Or both.</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0-alpha-2,1.3.3,2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperStub.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplit.java</file>
      <file type="M">hbase-hadoop2-compat.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="15135" opendate="2016-1-20 00:00:00" fixdate="2016-2-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add metrics for storefile age</summary>
      <description>In order to make sure that compactions are fully up to date it would be nice to have metrics on: Max storefile age Min storefile age Average storefile age Number of reference filesIf we could have those metrics per region and per regionserver it would be awesome.</description>
      <version>None</version>
      <fixedVersion>1.3.0,0.98.18,2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerMetrics.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsRegionServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperStub.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperStub.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-hadoop2-compat.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="15136" opendate="2016-1-20 00:00:00" fixdate="2016-3-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Explore different queuing behaviors while busy</summary>
      <description>http://queue.acm.org/detail.cfm?id=2839461</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapperStub.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.FifoRpcScheduler.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSource.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ReflectionUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="15172" opendate="2016-1-26 00:00:00" fixdate="2016-1-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support setting storage policy in bulkload</summary>
      <description>When using tiered HFile storage, we should be able to generating hfile with correct storage type during bulkload. This JIRA is targeting at making it possible.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.java</file>
    </fixedFiles>
  </bug>
  <bug id="15173" opendate="2016-1-26 00:00:00" fixdate="2016-1-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Execute mergeRegions RPC call as the request user</summary>
      <description>This is follow up to HBASE-15132Master currently sends mergeRegions RPC to region server under user 'hbase'.This issue is to execute mergeRegions RPC call as the request userSee tail of HBASE-15132 for related discussion.</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin1.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DispatchMergingRegionHandler.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="15174" opendate="2016-1-26 00:00:00" fixdate="2016-6-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Client Public API should not have PB objects in 2.0</summary>
      <description>Some more cleanup for the parent jira. We have leaked some PB structs in Admin (and possible other places). We should clean up these API before 2.0.Examples include: AdminProtos.GetRegionInfoResponse.CompactionState getCompactionState(final TableName tableName) throws IOException; .... void snapshot(final String snapshotName, final TableName tableName, HBaseProtos.SnapshotDescription.Type type) throws IOException, SnapshotCreationException, IllegalArgumentException; .... MasterProtos.SnapshotResponse takeSnapshotAsync(HBaseProtos.SnapshotDescription snapshot) throws IOException, SnapshotCreationException;</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Triple.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.TestInterfaceAudienceAnnotations.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ServerLoad.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionLoad.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionLoadStats.java</file>
    </fixedFiles>
  </bug>
  <bug id="15200" opendate="2016-2-1 00:00:00" fixdate="2016-2-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ZooKeeper znode ACL checks should only compare the shortname</summary>
      <description>After HBASE-13768 we check at startup in secure configurations if our znodes have the correct ACLs. However when checking the ACL we compare the Kerberos fullname, which includes the host component. We should only compare the shortname, the principal. Otherwise in a multimaster configuration we will unnecessarily reset ACLs whenever any master running on a host other than the one that initialized the ACLs makes the check. You can imagine this happening multiple times in a rolling restart scenario.</description>
      <version>1.2.0,1.0.3,1.1.3,0.98.17,2.0.0</version>
      <fixedVersion>1.2.0,1.3.0,1.1.4,1.0.4,0.98.18,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
    </fixedFiles>
  </bug>
  <bug id="15201" opendate="2016-2-1 00:00:00" fixdate="2016-2-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add hbase-spark to hbase assembly</summary>
      <description>hbase-spark currently is missing from hbase assembly.We should add it.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.pom.xml</file>
      <file type="M">hbase-assembly.src.main.assembly.hadoop-two-compat.xml</file>
      <file type="M">hbase-assembly.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="15203" opendate="2016-2-2 00:00:00" fixdate="2016-2-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reduce garbage created by path.toString() during Checksum verification</summary>
      <description>When we try to read a block we do checksum verification for which we need the file name in which the block belongs to. So we do Path.toString() every time. This seems to create around 163MB of char[] that is garbage collected in a simple scan run. It is also visible in writes but the impact is lesser. In overall write/read profile the top 2 factors are byte[] and char[]. This toString() can easily be avoided and reduce its share from the total. To make it more precise in 1 min of profiling, among the 1.8G of garbage created by StringBuilder.toString - this path.toString() was contributing around 3.5%. After the patch this is totally not there.</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.ChecksumUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="15206" opendate="2016-2-2 00:00:00" fixdate="2016-2-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Flakey testSplitDaughtersNotInMeta test</summary>
      <description>Run into the following failure with hbase 1.0.0.Stacktracejava.lang.AssertionError: nullat org.junit.Assert.fail(Assert.java:86)at org.junit.Assert.assertTrue(Assert.java:41)at org.junit.Assert.assertNotNull(Assert.java:712)at org.junit.Assert.assertNotNull(Assert.java:722)at org.apache.hadoop.hbase.util.TestHBaseFsck.testSplitDaughtersNotInMeta(TestHBaseFsck.java:1723)From the log, the ntp issue caused clock skew and it woke up CatalogJanitor earlier. The CatalogJanitor cleaned up the parent region. It could happen with master branch as well. The fix is to disable CatalogJanitor to make sure this will not happen.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,1.1.4,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsckOneRS.java</file>
    </fixedFiles>
  </bug>
  <bug id="15255" opendate="2016-2-11 00:00:00" fixdate="2016-2-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add pointer to linkedin blog on putting jvm logs on fast disk</summary>
      <description>Add pointer to linked in blog: https://engineering.linkedin.com/blog/2016/02/eliminating-large-jvm-gc-pauses-caused-by-background-io-trafficIIRC, tsdb says to do similar.Also add into perf section note on native crc.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.performance.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="15259" opendate="2016-2-12 00:00:00" fixdate="2016-2-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>WALEdits under replay will also be replicated</summary>
      <description>I need to verify this but seeing the codetry { // We are about to append this edit; update the region-scoped sequence number. Do it // here inside this single appending/writing thread. Events are ordered on the ringbuffer // so region sequenceids will also be in order. regionSequenceId = entry.stampRegionSequenceId(); // Edits are empty, there is nothing to append. Maybe empty when we are looking for a // region sequence id only, a region edit/sequence id that is not associated with an actual // edit. It has to go through all the rigmarole to be sure we have the right ordering. if (entry.getEdit().isEmpty()) { return; } // Coprocessor hook. if (!coprocessorHost.preWALWrite(entry.getHRegionInfo(), entry.getKey(), entry.getEdit())) { if (entry.getEdit().isReplay()) { // Set replication scope null so that this won't be replicated entry.getKey().setScopes(null); } } if (!listeners.isEmpty()) { for (WALActionsListener i: listeners) { // TODO: Why does listener take a table description and CPs take a regioninfo? Fix. i.visitLogEntryBeforeWrite(entry.getHTableDescriptor(), entry.getKey(), entry.getEdit()); } }When a WALEdit is in replay we set the Logkey to null. But in the visitLogEntryBeforeWrite() we again set the LogKey based on the replication scope associated with the cells. So the previous step of setting null does not work here?</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationSmallTests.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.Replication.java</file>
    </fixedFiles>
  </bug>
  <bug id="1526" opendate="2009-6-15 00:00:00" fixdate="2009-6-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>mapreduce fixup</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.test.org.apache.hadoop.hbase.HBaseTestCase.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.mapred.DisabledTestTableMapReduce.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableSplit.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableReduce.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableOutputFormat.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableMapReduceUtil.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableMap.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableInputFormatBase.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableInputFormat.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.RowCounter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.LuceneDocumentWrapper.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.IndexTableReduce.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.IndexOutputFormat.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.IndexConfiguration.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.IdentityTableReduce.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.IdentityTableMap.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.HRegionPartitioner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.GroupingTableMap.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.Driver.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.BuildTableIndex.java</file>
    </fixedFiles>
  </bug>
  <bug id="15261" opendate="2016-2-12 00:00:00" fixdate="2016-3-12 01:00:00" resolution="Not A Problem">
    <buginformation>
      <summary>Make Throwable t in DaughterOpener volatile</summary>
      <description>In the region split process, daughter regions are opened in different threads, Throwable t is set in these threads and it is checked in the calling thread. Need to make it volatile so the checking will not miss any exceptions from opening daughter regions.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransactionImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="15393" opendate="2016-3-4 00:00:00" fixdate="2016-3-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable table replication command will fail when parent znode is not default in peer cluster</summary>
      <description>Enable table replication command will fail when parent znode is not /hbase(default) in peer cluster and there is only one peer cluster added in the source cluster.</description>
      <version>1.0.3,0.98.17</version>
      <fixedVersion>1.3.0,1.2.1,0.98.18,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.replication.TestReplicationAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.replication.ReplicationAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="15635" opendate="2016-4-12 00:00:00" fixdate="2016-8-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Mean age of Blocks in cache (seconds) on webUI should be greater than zero</summary>
      <description></description>
      <version>0.98.17</version>
      <fixedVersion>1.0.4,1.4.0,1.1.6,1.3.1,1.2.3,0.98.22,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheStats.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.BlockCacheUtil.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="15644" opendate="2016-4-13 00:00:00" fixdate="2016-4-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add maven-scala-plugin for scaladoc</summary>
      <description>Added scala-tools.org to repository (as a side effect, all common artifacts get downloaded twice now, once from apache repo and once from scala-tools)This fixes scala:doc precommit.The patch 'bogus-scala-change' adds a blank line to a scala file to trigger scala:doc precommit. As expected, the target failed for master and passed for the patch.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
</bugrepository>
