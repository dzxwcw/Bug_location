<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="10201" opendate="2013-12-18 00:00:00" fixdate="2013-12-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Port &amp;#39;Make flush decisions per column family&amp;#39; to trunk</summary>
      <description>Currently the flush decision is made using the aggregate size of all column families. When large and small column families co-exist, this causes many small flushes of the smaller CF. We need to make per-CF flush decisions.</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestWALFactory.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestDefaultWALProvider.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestIOFencing.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestFSHLog.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHeapMemoryManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestFlushRegionEntry.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WAL.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.DisabledWALProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSWALEntry.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.LogRoller.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.FlushRequester.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestPerColumnFamilyFlush.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
    </fixedFiles>
  </bug>
  <bug id="11195" opendate="2014-5-16 00:00:00" fixdate="2014-1-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Potentially improve block locality during major compaction for old regions</summary>
      <description>This might be a specific use case. But we have some regions which are no longer written to (due to the key). Those regions have 1 store file and they are very old, they haven't been written to in a while. We still use these regions to read from so locality would be nice. I propose putting a configuration option: something likehbase.hstore.min.locality.to.skip.major.compact &amp;#91;between 0 and 1&amp;#93;such that you can decide whether or not to skip major compaction for an old region with a single store file.I'll attach a patch, let me know what you guys think.</description>
      <version>1.0.0,0.94.26,0.98.10,2.0.0</version>
      <fixedVersion>1.0.0,0.98.10,0.94.27</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.RatioBasedCompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration.java</file>
    </fixedFiles>
  </bug>
  <bug id="11196" opendate="2014-5-16 00:00:00" fixdate="2014-5-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update description of -ROOT- in ref guide</summary>
      <description>Since the resolution of HBASE-3171, &amp;#45;ROOT- is no longer used to store the location(s) of .META. . Unfortunately, not all of our documentation has been updated to reflect this change in architecture.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11339" opendate="2014-6-13 00:00:00" fixdate="2014-7-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase MOB</summary>
      <description>It's quite useful to save the medium binary data like images, documents into Apache HBase. Unfortunately directly saving the binary MOB(medium object) to HBase leads to a worse performance since the frequent split and compaction. In this design, the MOB data are stored in an more efficient way, which keeps a high write/read performance and guarantees the data consistency in Apache HBase.</description>
      <version>2.0.0</version>
      <fixedVersion>hbase-11339,2.0.0</fixedVersion>
      <type>Umbrella</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.hbase.mob.xml</file>
      <file type="M">src.main.asciidoc.book.adoc</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HMobStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.mapreduce.SweepJob.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ExpiredMobFileCleanerChore.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">src.main.asciidoc..chapters.hbase.mob.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="11340" opendate="2014-6-13 00:00:00" fixdate="2014-6-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove references to xcievers in documentation</summary>
      <description>While most references to xcievers were removed in HBase as part of HBASE-5697, the ref guide still contains a few stray references.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.troubleshooting.xml</file>
      <file type="M">src.main.docbkx.configuration.xml</file>
      <file type="M">src.main.docbkx.case.studies.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11463" opendate="2014-7-3 00:00:00" fixdate="2014-7-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>(findbugs) HE: Class defines equals() and uses Object.hashCode()</summary>
      <description>Findbugs warns that several classes define equals but not hashcode:HE: Class defines equals() and uses Object.hashCode() (HE_EQUALS_USE_HASHCODE)This class overrides equals(Object), but does not override hashCode(), and inherits the implementation of hashCode() from java.lang.Object (which returns the identity hash code, an arbitrary value assigned to the object by the VM). Therefore, the class is very likely to violate the invariant that equal objects must have equal hashcodes.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapred.TestSplitTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.AuthenticationKey.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionPlan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.ServerAndLoad.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableSplit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruCachedBlock.java</file>
      <file type="M">hbase-hadoop2-compat.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSourceImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="1147" opendate="2009-1-21 00:00:00" fixdate="2009-1-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Modify the scripts to use Zookeeper</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.hbase-env.sh</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.stop-hbase.sh</file>
      <file type="M">bin.start-hbase.sh</file>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug id="11474" opendate="2014-7-7 00:00:00" fixdate="2014-7-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[Thrift2] support authentication/impersonation</summary>
      <description>This is to do the same as HBASE-11349 for Thrift2.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.4</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift2.TestThriftHBaseServiceHandlerWithLabels.java</file>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift2.TestThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ConnectionCache.java</file>
    </fixedFiles>
  </bug>
  <bug id="11476" opendate="2014-7-8 00:00:00" fixdate="2014-8-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expand &amp;#39;Conceptual View&amp;#39; section of Data Model chapter</summary>
      <description>Could use some updating and expansion to emphasize the differences between HBase and an RDBMS. I found http://jimbojw.com/wiki/index.php?title=Understanding_Hbase_and_BigTable which is just excellent and we should link to it.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11487" opendate="2014-7-9 00:00:00" fixdate="2014-7-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ScanResponse carries non-zero cellblock for CloseScanRequest (ScanRequest with close_scanner = true)</summary>
      <description>After upgrading hbase from 0.94 to 0.96, we've found that our asynchbase client keep throwing errors during normal scan. It turns out these errors are due to Scanner.close call in asynchbase. Since asynchbase assumes the ScanResponse of CloseScannerRequest should never carry any cellblocks, it will throw an exception if there is a violation.In the asynchbase client (1.5.0), it constructs a CloseScannerRequest in the following way, ScanRequest.newBuilder() .setScannerId(scanner_id) .setCloseScanner(true) .build();Note, it does not set numOfRows, which kind of make sense. Why a close scanner request cares about number of rows to scan ?However, after narrowing down the CloseScannerRequest code path, it seems the issue is on regionserver side. In RsRpcServices.scan, we always init numOfRows to scan to 1 and we do this even for ScanRequest with close_scanner = true. This causes response for CloseScannerRequest will carry a cellBlock (if scan stops before the end row and this could happen in many normal scenarios)There are two fixes, either we always set numOfRows in asynchbase client side when constructing a CloseScannerRequest or we fix the default value in the server side.From a hbase client side point of view, it seems make less sense that server will send you a cellBlock for your close scanner request, unless the request explicitly asks for. We've made the change in our server code and the asynchbase client errors goes away. In addition to this issue, I want to know if we have any specifications for our hbase rpc. Like if close_scanner = true in ScanRequest and numOfRows is not set, ScanResponse guarantees that there is no cellBlock in the response. Since we moved to protobuf and many fields are optional for compatibility consideration, it might be helpful to have such specification which helps people to develop code that depends on hbase rpc.</description>
      <version>0.96.2,0.99.0,2.0.0</version>
      <fixedVersion>0.99.0,0.98.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="11502" opendate="2014-7-11 00:00:00" fixdate="2014-7-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Track down broken images in Ref Guide</summary>
      <description>I realized that image support was broken in the Ref Guide. I fixed it by making some changes to the pom.xml (in HBASE-11400). I need to track down what images are broken besides the new ones I added, find out where they are, and make them work again.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.site.resources.images.timeline.consitency.png</file>
    </fixedFiles>
  </bug>
  <bug id="11513" opendate="2014-7-14 00:00:00" fixdate="2014-7-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Combine SingleMultiple Queue RpcExecutor into a single class</summary>
      <description>Its a little odd that we use multiple classes, leading to mutliple if-else conditions for rpc execution when we could just combine them into one. Makes the logic and also puts the code into one place</description>
      <version>0.99.0,0.98.4,2.0.0</version>
      <fixedVersion>0.99.0,0.98.4</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SingleQueueRpcExecutor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.MultipleQueueRpcExecutor.java</file>
    </fixedFiles>
  </bug>
  <bug id="11527" opendate="2014-7-16 00:00:00" fixdate="2014-8-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cluster free memory limit check should consider L2 block cache size also when L2 cache is onheap.</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHeapMemoryManager.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.util.HeapMemorySizeUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestCacheConfig.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestBlockCacheReporting.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreChunkPool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HeapMemoryManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultHeapMemoryTuner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HBaseConfiguration.java</file>
    </fixedFiles>
  </bug>
  <bug id="11555" opendate="2014-7-21 00:00:00" fixdate="2014-7-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TableSnapshotRegionSplit should be public</summary>
      <description>This class extends Writable and so should be public so it can be used outside of the existing code line we ship. This will be consistent with TableSplit, which is also public.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.5</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat.java</file>
    </fixedFiles>
  </bug>
  <bug id="11564" opendate="2014-7-22 00:00:00" fixdate="2014-7-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve cancellation management in the rpc layer</summary>
      <description>The current client code depends on interrupting the thread for canceling a request. It's actually possible to rely on a callback in protobuf.The patch includes as well various performance improvements in replica management. On a version before HBASE-11492 the perf was ~35% better. I will redo the test with the last version.</description>
      <version>1.0.0,2.0.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestIPC.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.Subprocedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.BufferChain.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestRegionReplicaPerf.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ExceptionUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.TimeLimitedRpcController.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCaller.java</file>
    </fixedFiles>
  </bug>
  <bug id="11585" opendate="2014-7-24 00:00:00" fixdate="2014-8-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>PE: Allows warm-up</summary>
      <description>When we measure the latency, warm-up helps to get repeatable and useful measures.</description>
      <version>1.0.0,2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
    </fixedFiles>
  </bug>
  <bug id="11591" opendate="2014-7-25 00:00:00" fixdate="2014-8-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scanner fails to retrieve KV from bulk loaded file with highest sequence id than the cell&amp;#39;s mvcc in a non-bulk loaded file</summary>
      <description>See discussion in HBASE-11339.When we have a case where there are same KVs in two files one produced by flush/compaction and the other thro the bulk load.Both the files have some same kvs which matches even in timestamp.Steps:Add some rows with a specific timestamp and flush the same. Bulk load a file with the same data.. Enusre that "assign seqnum" property is set.The bulk load should use HFileOutputFormat2 (or ensure that we write the bulk_time_output key).This would ensure that the bulk loaded file has the highest seq num.Assume the cell in the flushed/compacted store file is row1,cf,cq,ts1, value1 and the cell in the bulk loaded file isrow1,cf,cq,ts1,value2 (There are no parallel scans).Issue a scan on the table in 0.96. The retrieved value is row1,cf1,cq,ts1,value2But the same in 0.98 will retrieve row1,cf1,cq,ts2,value1. This is a behaviour change. This is because of this code public int compare(KeyValueScanner left, KeyValueScanner right) { int comparison = compare(left.peek(), right.peek()); if (comparison != 0) { return comparison; } else { // Since both the keys are exactly the same, we break the tie in favor // of the key which came latest. long leftSequenceID = left.getSequenceID(); long rightSequenceID = right.getSequenceID(); if (leftSequenceID &gt; rightSequenceID) { return -1; } else if (leftSequenceID &lt; rightSequenceID) { return 1; } else { return 0; } } }Here in 0.96 case the mvcc of the cell in both the files will have 0 and so the comparison will happen from the else condition . Where the seq id of the bulk loaded file is greater and would sort out first ensuring that the scan happens from that bulk loaded file.In case of 0.98+ as we are retaining the mvcc+seqid we are not making the mvcc as 0 (remains a non zero positive value). Hence the compare() sorts out the cell in the flushed/compacted file. Which means though we know the lateset file is the bulk loaded file we don't scan the data.Seems to be a behaviour change. Will check on other corner cases also but we are trying to know the behaviour of bulk load because we are evaluating if it can be used for MOB design.</description>
      <version>0.99.0,2.0.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestScanWithBloomError.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="11610" opendate="2014-7-29 00:00:00" fixdate="2014-8-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enhance remote meta updates</summary>
      <description>Currently, if the meta region is on a regionserver instead of the master, meta update is synchronized on one HTable instance. We should be able to do better.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.6</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStateStore.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCallerFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="11611" opendate="2014-7-29 00:00:00" fixdate="2014-8-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up ZK-based region assignment</summary>
      <description>We can clean up the ZK-based region assignment code and use the ZK-less one in the master branch, to make the code easier to understand and maintain.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildOverlap.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildHole.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestZooKeeper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestMetaTableAccessor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestIOFencing.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestDrainingServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestZKLessSplitOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestZKLessMergeOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerNoMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionReplicas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionMergeTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestEndToEndSplitTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.handler.TestOpenRegionHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.handler.TestCloseRegionHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.migration.TestUpgradeTo96.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.migration.TestNamespaceUpgrade.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestZKLessAMOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestZKBasedOpenCloseRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRollingRestart.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRestartCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestOpenedRegionHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterRestartAfterDisablingTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.master.RegionState.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionTransition.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKAssign.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.ZooKeeper.proto</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.BaseCoordinatedStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.CloseRegionCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.OpenRegionCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.RegionMergeCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.SplitTransactionCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZkCloseRegionCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZkOpenRegionCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZkRegionMergeCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZKSplitTransactionCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignCallable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ClosedRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.OpenedRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.OfflineCallback.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStateStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.migration.UpgradeTo96.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseMetaHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenMetaHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionMergeTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ConfigUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsckRepair.java</file>
      <file type="M">hbase-server.src.test.data.TestNamespaceUpgrade.tgz</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestReplicasClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannersFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestChangingEncoding.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.Mocking.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
    </fixedFiles>
  </bug>
  <bug id="11659" opendate="2014-8-4 00:00:00" fixdate="2014-8-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Region state RPC call is not idempotent</summary>
      <description>Here is the scenario on 0.98 with zk-less assignmentThe master gets an OPEN RPC call from region server.So, it moves the region state from PENDING_OPEN to OPEN.But, the call timeouts on the region server and region server retries sending the OPEN call. However, now the master throws an Exception saying the region is not PENDING_OPEN. So, the region servers aborts the region on receiving that exception and sends FAILED_OPEN to master. But the master cannot change its state from FAILED_OPEN to OPEN, so eventually the master keeps the state as OPEN while the actual region is no longer open on region server.The master should not throw an exception on receiving OPEN RPC calls multiple times.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="11681" opendate="2014-8-6 00:00:00" fixdate="2014-8-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update and move doc about disabling the WAL</summary>
      <description>Move the docs about disabling the WAL from the Performance section to the WAL section, point to the new location, and add info about getDurability and setDurability methods. Leave the big fat warnings about data loss in both the Performance and WAL sections.</description>
      <version>0.99.0,2.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.performance.xml</file>
      <file type="M">src.main.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11682" opendate="2014-8-6 00:00:00" fixdate="2014-8-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Explain hotspotting</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.schema.design.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11683" opendate="2014-8-6 00:00:00" fixdate="2014-10-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Metrics for MOB</summary>
      <description>We need to make sure to capture metrics about mobs.Some basic ones include: of mob writes of mob reads avg size of mob mob files of mob compactions / sweeps</description>
      <version>2.0.0</version>
      <fixedVersion>hbase-11339,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerMetrics.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperStub.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ReversedMobStoreScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MobStoreScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HMobStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.MobFileCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.MobCacheConfig.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.DefaultMobStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.DefaultMobCompactor.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="11687" opendate="2014-8-6 00:00:00" fixdate="2014-8-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>No need to abort on postOpenDeployTasks exception if region opening is cancelled</summary>
      <description>With ZK-less region assignment, if region opening is in postOpenDeployTasks step and the opening is cancelled, the region server will abort because it can't report the transition to the master. We should cancel postOpenDeployTasks instead. At least, there is no need to abort.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="11689" opendate="2014-8-6 00:00:00" fixdate="2014-8-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Track meta in transition</summary>
      <description>With ZK-less region assignment, user regions in transition are tracked in meta. We need a way to track meta in transition too.</description>
      <version>1.0.0,2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestMetaTableLocator.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStateStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.MetaServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.ZooKeeper.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.MetaTableLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ServerName.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.master.RegionState.java</file>
    </fixedFiles>
  </bug>
  <bug id="11705" opendate="2014-8-8 00:00:00" fixdate="2014-8-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>callQueueSize should be decremented in a fail-fast scenario</summary>
      <description>Discussed on the user@hbase mailing list (http://markmail.org/thread/w3cqjxwo2smkn2jw). If a client disconnects the call queue size is not decremented causing new calls to get rejected with a CallQueueTooBigException.</description>
      <version>0.98.0,0.99.0,2.0.0</version>
      <fixedVersion>0.99.0,0.98.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.CallRunner.java</file>
    </fixedFiles>
  </bug>
  <bug id="11719" opendate="2014-8-11 00:00:00" fixdate="2014-8-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove some unused paths in AsyncClient</summary>
      <description>sershe you're ok with these changes?</description>
      <version>1.0.0,2.0.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
    </fixedFiles>
  </bug>
  <bug id="11726" opendate="2014-8-12 00:00:00" fixdate="2014-8-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Master should fail-safe if starting with a pre 0.96 layout</summary>
      <description>We recently saw this: If user inadvertently starts the HBase Master after deploying new HBase binaries (any version that supports namespaces), the HMaster will start the migration to PBs the the hbase.version file per HBASE-5453 and that will write a new version file PB-serialized but with the old version number. Further restarts of the master will fail because the hbase version file has been migrated to PBs and there will be version mismatch. The right approach should be to fail safe the master if we find an old hbase.version file in order to force user to run upgrade tool.</description>
      <version>0.96.2,0.99.0,0.98.5,2.0.0</version>
      <fixedVersion>0.99.0,0.98.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="11727" opendate="2014-8-12 00:00:00" fixdate="2014-8-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Assignment wait time error in case of ServerNotRunningYetException</summary>
      <description>maxWaitTime = this.server.getConfiguration(). getLong("hbase.regionserver.rpc.startup.waittime", 60000);It should add the current time.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="11732" opendate="2014-8-13 00:00:00" fixdate="2014-8-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Should not preemptively offline a region</summary>
      <description>Clean up force region unassignment.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionMergeTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.UnAssignCallable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DisableTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.BulkReOpen.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="11734" opendate="2014-8-14 00:00:00" fixdate="2014-8-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document changed behavior of hbase.hstore.time.to.purge.deletes</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.book.xml</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11757" opendate="2014-8-15 00:00:00" fixdate="2014-8-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Provide a common base abstract class for both RegionObserver and MasterObserver</summary>
      <description>Some security coprocessors extend both RegionObserver and MasterObserver, unfortunately only one of the two can use the available base abstract class implementations. Provide a common base abstract class for both the RegionObserver and MasterObserver interfaces. Update current coprocessors that extend both interfaces to use the new common base abstract class.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.6</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug id="11788" opendate="2014-8-20 00:00:00" fixdate="2014-11-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase is not deleting the cell when a Put with a KeyValue, KeyValue.Type.Delete is submitted</summary>
      <description>Code executed: @Test public void testHbasePutDeleteCell() throws Exception { TableName tableName = TableName.valueOf("my_test"); Configuration configuration = HBaseConfiguration.create(); HTableInterface table = new HTable(configuration, tableName); final String rowKey = "12345"; final byte[] familly = Bytes.toBytes("default"); // put one row Put put = new Put(Bytes.toBytes(rowKey)); put.add(familly, Bytes.toBytes("A"), Bytes.toBytes("a")); put.add(familly, Bytes.toBytes("B"), Bytes.toBytes("b")); put.add(familly, Bytes.toBytes("C"), Bytes.toBytes("c")); table.put(put); // get row back and assert the values Get get = new Get(Bytes.toBytes(rowKey)); Result result = table.get(get); Assert.isTrue(Bytes.toString(result.getValue(familly, Bytes.toBytes("A"))).equals("a"), "Column A value should be a"); Assert.isTrue(Bytes.toString(result.getValue(familly, Bytes.toBytes("B"))).equals("b"), "Column B value should be b"); Assert.isTrue(Bytes.toString(result.getValue(familly, Bytes.toBytes("C"))).equals("c"), "Column C value should be c"); // put the same row again with C column deleted put = new Put(Bytes.toBytes(rowKey)); put.add(familly, Bytes.toBytes("A"), Bytes.toBytes("a")); put.add(familly, Bytes.toBytes("B"), Bytes.toBytes("b")); put.add(new KeyValue(Bytes.toBytes(rowKey), familly, Bytes.toBytes("C"), HConstants.LATEST_TIMESTAMP, KeyValue.Type.DeleteColumn)); table.put(put); // get row back and assert the values get = new Get(Bytes.toBytes(rowKey)); result = table.get(get); Assert.isTrue(Bytes.toString(result.getValue(familly, Bytes.toBytes("A"))).equals("a"), "Column A value should be a"); Assert.isTrue(Bytes.toString(result.getValue(familly, Bytes.toBytes("B"))).equals("b"), "Column A value should be b"); Assert.isTrue(result.getValue(familly, Bytes.toBytes("C")) == null, "Column C should not exists"); }This assertion fails, the cell is not deleted but rather the value is empty:hbase(main):029:0&gt; scan 'my_test'ROW COLUMN+CELL 12345 column=default:A, timestamp=1408473082290, value=a 12345 column=default:B, timestamp=1408473082290, value=b 12345 column=default:C, timestamp=1408473082290, value= This behavior is different than previous 4.8.x Cloudera version and is currently corrupting all hive queries involving is null or is not null operators on the columns mapped to hbase</description>
      <version>0.99.0,0.96.1.1,0.98.5,2.0.0</version>
      <fixedVersion>0.99.0,0.98.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="11804" opendate="2014-8-22 00:00:00" fixdate="2014-10-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Raise default heap size if unspecified</summary>
      <description>On master running pe randomWrite with ten threads and the default heap size crashes the system. This works on 0.98 and before.It's been a long time that 1000mb has been our default. Maybe we should start looking at raising that limit on master.</description>
      <version>2.0.0</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug id="11826" opendate="2014-8-26 00:00:00" fixdate="2014-9-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Split each tableOrRegionName admin methods into two targetted methods</summary>
      <description>Purpose of this is two implement enis's suggestion to strongly type the methods that take "tableOrRegionName" as an argument.For instance:void compact(final String tableNameOrRegionName)void compact(final byte[] tableNameOrRegionName)becomes@Deprecatedvoid compact(final String tableNameOrRegionName)@Deprecatedvoid compact(final byte[] tableNameOrRegionName)void compact(TableName table)void compactRegion(final byte[] regionName)</description>
      <version>None</version>
      <fixedVersion>0.99.0,1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestTableResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsckEncryption.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestNamespace.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityWithCheckAuths.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithDeletes.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestTablePermissions.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.AddColumnAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.ChangeBloomFilterAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.ChangeCompressionAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.ChangeEncodingAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.ChangeVersionsAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.CompactRandomRegionOfTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.CompactTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.FlushRandomRegionOfTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.FlushTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.MergeRandomAdjacentRegionsOfTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.MoveRandomRegionOfTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.MoveRegionsOfTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.RemoveColumnAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.SnapshotTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.SplitRandomRegionOfTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.factories.MonkeyFactory.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestBase.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestIngest.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestIngestWithEncryption.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestRegionReplicaPerf.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.mapreduce.IntegrationTestBulkLoad.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.mapreduce.IntegrationTestTableSnapshotInputFormat.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.mttr.IntegrationTestMTTR.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestLoadAndVerify.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestTimeBoundedRequestsWithRegionReplicas.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestWithCellVisibilityLoadAndVerify.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.trace.IntegrationTestSendTraceRequests.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestReplicaWithCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotCloneIndependence.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestTableSnapshotScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverScannerOpenHook.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestPrefixTree.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatTestBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentListener.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestTableLockManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestEncryptionKeyRotation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestEncryptionRandomKeying.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestEndToEndSplitTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionMergeTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerMetrics.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestTags.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRolling.java</file>
    </fixedFiles>
  </bug>
  <bug id="11835" opendate="2014-8-27 00:00:00" fixdate="2014-10-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Wrong managenement of non expected calls in the client</summary>
      <description>If a call is purged or canceled we try to skip the reply from the server, but we read the wrong number of bytes so we corrupt the tcp channel. It's hidden as it triggers retry and so on, but it's bad for performances obviously.It happens with cell blocks.ram_krish_86, saint.ack@gmail.com, you know this part better than me, do you agree with the analysis and the patch?The changes in rpcServer are not fully related: as the client close the connections in such situation, I observed both ClosedChannelException and CancelledKeyException.</description>
      <version>1.0.0,0.98.6,2.0.0</version>
      <fixedVersion>0.99.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="11847" opendate="2014-8-28 00:00:00" fixdate="2014-9-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HFile tool should be able to print block headers</summary>
      <description>Printing the block index is helpful, but sometimes you want to see more info about the blocks themselves.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.7</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter.java</file>
    </fixedFiles>
  </bug>
  <bug id="11849" opendate="2014-8-28 00:00:00" fixdate="2014-8-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up orphaned private audience classes</summary>
      <description>We have some classes in master that are private audience and no longer used internally. We should remove them.I'll build a list for server-side modules along with when they got orphaned so we can decide on removal from older branches.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.OrphanHLogAfterSplitException.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.ThreadLocalEncoderPool.java</file>
    </fixedFiles>
  </bug>
  <bug id="11855" opendate="2014-8-28 00:00:00" fixdate="2014-9-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase handbook chapter 18.9 out of date</summary>
      <description>Recently posix4e committed a change HBASE-4955 renaming Dsurefire.*PartThreadCount to Dsurefire.*PartForkCount for the 2.0 version.I'm excited to help with documentation and the webpage going forward. Can someone help mentor me with the process? Thanks.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.developer.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11858" opendate="2014-8-28 00:00:00" fixdate="2014-9-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Audit regionserver classes that are missing InterfaceAudience</summary>
      <description>There are ~20 classes in regionserver that are missing InterfaceAudience markers.Most are probably private, but HBASE-10378 has already hit atleast one that should be LimitedPrivate(COPROC), so it's worth checking and cleaning things up.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.7</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SecureWALCellCodec.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.KeyValueCompression.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StripeStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StripeMultiFileWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StorefileRefresherChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RpcSchedulerFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RowTooBigException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RowProcessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MultiRowMutationProcessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DisabledRegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.StripeCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.BaseRowProcessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.AnnotationReadingPriorityFunction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.PriorityFunction.java</file>
    </fixedFiles>
  </bug>
  <bug id="11859" opendate="2014-8-28 00:00:00" fixdate="2014-8-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>&amp;#39;hadoop jar&amp;#39; references in documentation should mention hbase-server.jar, not hbase.jar</summary>
      <description>There are various org.apache.hadoop.util.Tool implementations mentioned in the documentation as being run with "hadoop jar hbase-VERSION.jar &lt;toolname&gt;". These classes now live in in the hbase-server module, so that jar name should be hbase-server-VERSION.jar.The same applies to the documentation on running MapReduce jobs against HBase.</description>
      <version>0.99.0,0.98.6,2.0.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.troubleshooting.xml</file>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
      <file type="M">src.main.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1186" opendate="2009-2-5 00:00:00" fixdate="2009-3-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Memory-aware Maps with LRU eviction for Cell Cache</summary>
      <description>Caching is key for 0.20. We need a set of memory-aware data structures to manage our caches.I propose two initial classes: LruHashMap and LruBlockMapLruHashMap is currently being used over in HBASE-80 for the Cell cache. Erik Holstad has done extensive testing and benchmarking and will post results over in this issue. Memory-aware Fixed size LRU evictionLruBlockMap can be used for the block caching of the new file format in HBASE-61. It should try to use all available memory, but must contend with Memcaches so is resizable to deal with heap pressure. Adding high priority blocks (evicted last) gives us in-memory functionality as described in bigtable paper. Memory-aware Fully resizable LRU eviction (with some additions) High priority blocks Optional: Scan resistant algorithmPart of this issue is also solving how we will determine the size of cached objects.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.io.HeapSize.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11861" opendate="2014-8-29 00:00:00" fixdate="2014-2-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Native MOB Compaction mechanisms.</summary>
      <description>Currently, the first cut of mob will have external processes to age off old mob data (the ttl cleaner), and to compact away deleted or over written data (the sweep tool). From an operational point of view, having two external tools, especially one that relies on MapReduce is undesirable. In this issue we'll tackle integrating these into hbase without requiring external processes.</description>
      <version>2.0.0</version>
      <fixedVersion>hbase-11339,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.MobUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.MobConstants.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11864" opendate="2014-8-30 00:00:00" fixdate="2014-4-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enhance HLogPrettyPrinter to print information from WAL Header</summary>
      <description>HBASE-11620 and HBASE-11762 added Writer classname and Cell Codec classname to WALHeader.This issue is to enhance HLogPrettyPrinter such that it prints the classnames, if such information is available in WALHeader.</description>
      <version>2.0.0</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALPrettyPrinter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader.java</file>
    </fixedFiles>
  </bug>
  <bug id="11897" opendate="2014-9-4 00:00:00" fixdate="2014-9-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add append and remove peer table-cfs cmds for replication</summary>
      <description>HBASE-8751 introduces the tables/table-column families config for a replication peer. It's very flexible for practical replication in hbase clusters.But it is easy to make mistakes during add or remove a table/table-column family for a existing peer, especially when the table-cfs is very long, for we need to copy the current table-cfs of the peer first, and then add or remove a table/table-column family to/from the table-cfs, at last set back the table-cfs using the cmd: set_peer_tableCFs. So we implements two new cmds: append_peer_tableCFs and remove_peer_tableCFs to do the operation of adding and removing a table/table-column family. They are useful operation tools.</description>
      <version>2.0.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.shell.rb</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.replication.admin.rb</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationWALEntryFilters.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestPerTableCFReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.replication.TestReplicationAdmin.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.TableCfWALEntryFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeerZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeersZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeers.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.replication.ReplicationAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="11906" opendate="2014-9-6 00:00:00" fixdate="2014-9-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Meta data loss with distributed log replay</summary>
      <description>In the attached log, you can see, before log replaying, the region is open on e1205:A3. 2014-09-05 16:38:46,705 INFO [B.defaultRpcServer.handler=5,queue=2,port=20020] master.RegionStateStore: Updating row IntegrationTestBigLinkedList,\x90Jy\x04\xA7\x90Jp,1409959495482.cbb0d736ebfabcf4a07e5a7b395fcdf7. with state=OPEN&amp;openSeqNum=40118237&amp;server=e1205.halxg.cloudera.com,20020,1409960280431After the log replay, we got from meta the region is open on e1209A4. 2014-09-05 16:41:12,257 INFO [ActiveMasterManager] master.AssignmentManager: Loading from meta: {cbb0d736ebfabcf4a07e5a7b395fcdf7 state=OPEN, ts=1409960472257, server=e1209.halxg.cloudera.com,20020,1409959391651}The replayed edits show the log does have the edit expected:2014-09-05 16:41:11,862 INFO [B.defaultRpcServer.handler=18,queue=0,port=20020] regionserver.RSRpcServices: Meta replay edit type=PUT,mutation={"totalColumns":4,"families":{"info":[{"timestamp":1409960326705,"tag":["3:\\x00\\x00\\x00\\x00\\x02bad"],"value":"e1205.halxg.cloudera.com:20020","qualifier":"server","vlen":30},{"timestamp":1409960326705,"tag":["3:\\x00\\x00\\x00\\x00\\x02bad"],"value":"\\x00\\x00\\x01HH.\\x81o","qualifier":"serverstartcode","vlen":8},{"timestamp":1409960326705,"tag":["3:\\x00\\x00\\x00\\x00\\x02bad"],"value":"\\x00\\x00\\x00\\x00\\x02d'\\xDD","qualifier":"seqnumDuringOpen","vlen":8},{"timestamp":1409960326706,"tag":["3:\\x00\\x00\\x00\\x00\\x02bad"],"value":"OPEN","qualifier":"state","vlen":4}]},"row":"IntegrationTestBigLinkedList,\\x90Jy\\x04\\xA7\\x90Jp,1409959495482.cbb0d736ebfabcf4a07e5a7b395fcdf7."}Why we picked up a wrong value with an older time stamp?2014-09-05 16:41:11,063 INFO [B.defaultRpcServer.handler=9,queue=0,port=20020] regionserver.RSRpcServices: Meta replay edit type=PUT,mutation={"totalColumns":4,"families":{"info":[{"timestamp":1409959994634,"tag":["3:\\x00\\x00\\x00\\x00\\x00\\x00\\x09\\x99"],"value":"e1209.halxg.cloudera.com:20020","qualifier":"server","vlen":30},{"timestamp":1409959994634,"tag":["3:\\x00\\x00\\x00\\x00\\x00\\x00\\x09\\x99"],"value":"\\x00\\x00\\x01HH \\xF1\\xA3","qualifier":"serverstartcode","vlen":8},{"timestamp":1409959994634,"tag":["3:\\x00\\x00\\x00\\x00\\x00\\x00\\x09\\x99"],"value":"\\x00\\x00\\x00\\x00\\x00\\x01\\xB7\\xAB","qualifier":"seqnumDuringOpen","vlen":8},{"timestamp":1409959994634,"tag":["3:\\x00\\x00\\x00\\x00\\x00\\x00\\x09\\x99"],"value":"OPEN","qualifier":"state","vlen":4}]},"row":"IntegrationTestBigLinkedList,\\x90Jy\\x04\\xA7\\x90Jp,1409959495482.cbb0d736ebfabcf4a07e5a7b395fcdf7."}</description>
      <version>0.99.0,2.0.0</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="11908" opendate="2014-9-7 00:00:00" fixdate="2014-1-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Region replicas should be added to the meta table at the time of table creation</summary>
      <description>While testing async replication handling and failover handling for region replicas, we've found that sometimes the secondary region replicas do not open and update meta quickly enough, and hence meta would not contain any information about the region replica id. If a reader caches the meta row before all region replicas are open the first time (such as the async wal replication endpoint), then it may miss the region replica and won't know about it until it refreshes it's cache again. Instead, we should add entries to the meta for all of the region replicas at the time of create table (just like primary regions).</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestMetaTableAccessor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMetaScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.RestoreSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.CloneSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStateStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TruncateTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.CreateTableHandler.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MetaTableAccessor.java</file>
    </fixedFiles>
  </bug>
  <bug id="11909" opendate="2014-9-8 00:00:00" fixdate="2014-9-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Region count listed by HMaster UI and hbck are different</summary>
      <description>The count displayed in the HMaster UI can be lower than the count of regions as done by hbck or by counting subdirectories of /hbase/&lt;table&gt;. This is explained in the comments &amp;#91;1&amp;#93; but I think it should be documented as well&amp;#91;1&amp;#93; https://git-wip-us.apache.org/repos/asf?p=hbase.git;a=blob;f=hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java#l578</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11976" opendate="2014-9-15 00:00:00" fixdate="2014-9-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Server startcode is not checked for bulk region assignment</summary>
      <description>I got the following failure yesterday. It looks like sending open region request, the region server failed to check the server start code.2014-09-14 19:36:45,565 ERROR [B.defaultRpcServer.handler=24,queue=0,port=20020] master.AssignmentManager: Failed to transition region from {2706f577540a7d1b53b5a8f66178fbf2 state=PENDING_OPEN, ts=1410748604803, server=a2428.halxg.cloudera.com,20020,1410746518223} on OPENED by a2428.halxg.cloudera.com,20020,1410748599408: 2706f577540a7d1b53b5a8f66178fbf2 is not opening on a2428.halxg.cloudera.com,20020,1410748599408ABORTING region server a2428.halxg.cloudera.com,20020,1410748599408: Exception running postOpenDeployTasks; region=2706f577540a7d1b53b5a8f66178fbf2</description>
      <version>2.0.0</version>
      <fixedVersion>0.99.0,0.98.6.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
    </fixedFiles>
  </bug>
  <bug id="11985" opendate="2014-9-16 00:00:00" fixdate="2014-12-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document sizing rules of thumb</summary>
      <description>I'm looking for tuning/sizing rules of thumb to put in the Ref Guide.Info I have gleaned so far:A reasonable region size is between 10 GB and 50 GB.A reasonable maximum cell size is 1 MB to 10 MB. If your cells are larger than 10 MB, consider storing the cell contents in HDFS and storing a reference to the location in HBase. Pending MOB work for 10 MB - 64 MB window.When you size your regions and cells, keep in mind that a region cannot split across a row. If your row size is too large, or your region size is too small, you can end up with a single row per region, which is not a good pattern. It is also possible that one big column causes splits while other columns are tiny, and this may not be great.A large # of columns probably means you are doing it wrong.Column names need to be short because they get stored for every value (barring encoding). Don't need to be self-documenting like in RDBMS.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.schema.design.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="11986" opendate="2014-9-16 00:00:00" fixdate="2014-9-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document MOB in Ref Guide</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>hbase-11339,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.hbase.mob.xml</file>
      <file type="M">src.main.docbkx.schema.design.xml</file>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
      <file type="M">src.main.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11988" opendate="2014-9-16 00:00:00" fixdate="2014-9-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>AC/VC system table create on postStartMaster fails too often in test</summary>
      <description>See for example2014-09-16 04:02:08,833 ERROR [ActiveMasterManager] master.HMaster(633): Coprocessor postStartMaster() hook failedjava.io.IOException: Table Namespace Manager not ready yet, try again later at org.apache.hadoop.hbase.master.HMaster.checkNamespaceManagerReady(HMaster.java:1669) at org.apache.hadoop.hbase.master.HMaster.getNamespaceDescriptor(HMaster.java:1852) at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:1096) at org.apache.hadoop.hbase.security.access.AccessControlLists.init(AccessControlLists.java:143) at org.apache.hadoop.hbase.security.access.AccessController.postStartMaster(AccessController.java:1059) at org.apache.hadoop.hbase.master.MasterCoprocessorHost$58.call(MasterCoprocessorHost.java:692) at org.apache.hadoop.hbase.master.MasterCoprocessorHost.execOperation(MasterCoprocessorHost.java:861) at org.apache.hadoop.hbase.master.MasterCoprocessorHost.postStartMaster(MasterCoprocessorHost.java:688) at org.apache.hadoop.hbase.master.HMaster.finishActiveMasterInitialization(HMaster.java:631) at org.apache.hadoop.hbase.master.HMaster.access$500(HMaster.java:155) at org.apache.hadoop.hbase.master.HMaster$1.run(HMaster.java:1244) at java.lang.Thread.run(Thread.java:744)</description>
      <version>None</version>
      <fixedVersion>0.98.7,0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableNamespaceManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
    </fixedFiles>
  </bug>
  <bug id="11990" opendate="2014-9-16 00:00:00" fixdate="2014-10-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make setting the start and stop row for a specific prefix easier</summary>
      <description>If you want to set a scan from your application to scan for a specific row prefix this is actually quite hard.As described in several places you can set the startRow to the prefix; yet the stopRow should be set to the prefix '+1'If the prefix 'ASCII' put into a byte[] then this is easy because you can simply increment the last byte of the array. But if your application uses real binary rowids you may run into the scenario that your prefix is something like { 0x12, 0x23, 0xFF, 0xFF } Then the increment should be { 0x12, 0x24 }I have prepared a proposed patch that makes setting these values correctly a lot easier.</description>
      <version>None</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.book.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestFilterWithScanLimits.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
    </fixedFiles>
  </bug>
  <bug id="11991" opendate="2014-9-16 00:00:00" fixdate="2014-9-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Region states may be out of sync</summary>
      <description>Region states could be out of sync under a rare scenario. The regions hosted by a server could be wrong.</description>
      <version>None</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
    </fixedFiles>
  </bug>
  <bug id="12005" opendate="2014-9-17 00:00:00" fixdate="2014-9-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Split/merge fails if master restarts before PONR</summary>
      <description>This applies to RPC based assignment. The root cause is that we don't persist the state of the new region(s). If we do persist it, we need to clean it up if the split/merge fails.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionMergeTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.master.RegionState.java</file>
    </fixedFiles>
  </bug>
  <bug id="12007" opendate="2014-9-17 00:00:00" fixdate="2014-9-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>StochasticBalancer should avoid putting user regions on master</summary>
      <description>We should enhance how StochasticBalancer picks up a random server so that it can avoid putting user regions on master, because regions on master are handled differently in a separate method.</description>
      <version>None</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestRegionRebalancing.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestStochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
    </fixedFiles>
  </bug>
  <bug id="12010" opendate="2014-9-17 00:00:00" fixdate="2014-9-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use TableName.META_TABLE_NAME instead of indirectly from HTableDescriptor</summary>
      <description>Currently code accessed meta table name via HTableDescriptor.META_TABLEDESC.getTableName(), but we have TableName.META_TABLE_NAME already. It is better to use from one place.</description>
      <version>2.0.0</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.OfflineMetaRebuildTestCore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationWALEntryFilters.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRollingNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSTableDescriptors.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MetaTableAccessor.java</file>
    </fixedFiles>
  </bug>
  <bug id="12011" opendate="2014-9-17 00:00:00" fixdate="2014-10-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add namespace column during display of user tables</summary>
      <description>Currently, the namespaces are not being explicitly stated while displaying the user tables. This will help in decoupling the table names and their corresponding namespaces.</description>
      <version>None</version>
      <fixedVersion>0.98.7,0.99.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="12012" opendate="2014-9-17 00:00:00" fixdate="2014-12-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve cancellation for the scan RPCs</summary>
      <description>Similar to HBASE-11564 but for scans.</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestReplicasClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="12016" opendate="2014-9-18 00:00:00" fixdate="2014-10-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reduce number of versions in Meta table. Make it configurable</summary>
      <description>Currently meta keeps up to 10 versions of each KV. For big metas it leads to substantial memory overhead and scan slowdowns.(see https://issues.apache.org/jira/browse/HBASE-11165 )Need to keep reasonable number of versions (suggested value is 3). Number of versions configurable via parameter: hbase.meta.versions</description>
      <version>2.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestMergeTool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestMergeTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestFSTableDescriptors.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestTableDescriptor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestFSTableDescriptorForceCreation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationWALEntryFilters.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRollingNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionInfo.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestGetClosestAtOrBefore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestCase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.MetaUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSTableDescriptors.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.TableDescriptor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotManifest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.migration.NamespaceUpgrade.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.TestHTableDescriptor.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.TestHColumnDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="12035" opendate="2014-9-20 00:00:00" fixdate="2014-2-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Keep table state in META</summary>
      <description>HBASE-7767 moved table enabled|disabled state to be kept in hdfs instead of zookeeper. isTableDisabled() which is used in HConnectionImplementation.relocateRegion() now became a master RPC call rather than a zookeeper client call. Since we do relocateRegion() calls everytime we want to relocate a region (region moved, RS down, etc) this implies that when the master is down, the some of the clients for uncached regions will be affected. See HBASE-7767 and HBASE-11974 for some more background.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestFSTableDescriptors.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestCoprocessorScanPolicy.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.OfflineMetaRebuildTestCore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestMetaTableAccessor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRegionStates.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterOperationsForRegionReplicas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestReplicaWithCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMetaWithReplicas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin1.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSTableDescriptors.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.TableDescriptor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotManifest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SnapshotOfRegionAssignmentFromMeta.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStateStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.LoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TruncateTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.CreateTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.HBase.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MetaTableAccessor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.TableState.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="12038" opendate="2014-9-21 00:00:00" fixdate="2014-9-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace internal uses of signatures with byte[] and String tableNames to use the TableName equivalents.</summary>
      <description>Signatures with byte[] and String table name variables were deprecated in favor of a TableName input. Replace all byte[] and String table name variables with TableName types.</description>
      <version>0.99.1,2.0.0</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestTablePermissions.java</file>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift2.TestHTablePool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestRegionSplitter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestProcessBasedCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestMultiVersions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestAcidGuarantees.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestSecureExportSnapshot.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithDefaultVisLabelService.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithACL.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTableFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityClient.java</file>
      <file type="M">hbase-examples.src.test.java.org.apache.hadoop.hbase.coprocessor.example.TestBulkDeleteProtocol.java</file>
      <file type="M">hbase-examples.src.test.java.org.apache.hadoop.hbase.coprocessor.example.TestRowCountEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.MultiTableInputFormatBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.MultiTableOutputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.HRegionPartitioner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableOutputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.Canary.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionSplitter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMultiParallel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestClassLoading.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestFilterWithScanLimits.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestFilterWrapper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat2.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestSecureLoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestSecureLoadIncrementalHFilesSplitRecovery.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableMapReduceBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTimeRangeMapRed.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterOperationsForRegionReplicas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRegionPlacement.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRestartCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestTableLockManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestQuotaAdmin.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestQuotaTableUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestQuotaThrottle.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestEncryptionKeyRotation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestFSErrorsExposed.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestJoinedScanners.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestMasterReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestMultiSlaveReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestPerTableCFReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationSmallTests.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationSyncUpTool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationWithTags.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.SecureTestUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController2.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestCellACLs.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestCellACLWithMultipleVersions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestScanEarlyTermination.java</file>
    </fixedFiles>
  </bug>
  <bug id="12042" opendate="2014-9-21 00:00:00" fixdate="2014-9-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace internal uses of HTable(Configuration, String) with HTable(Configuration, TableName)</summary>
      <description>Replace internal uses of HTable(Configuration, String) with HTable(Configuration, TableName)</description>
      <version>0.99.1,2.0.0</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompactionState.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestRegionSplitter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsckEncryption.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.trace.TestHTraceHooks.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestZooKeeper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestMultiVersions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestInfoServers.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestHBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestGlobalMemStoreSize.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestFullLogReconstruction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityWithCheckAuths.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithDeletes.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSink.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRollPeriod.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRolling.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRollAbort.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestServerCustomProtocol.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestScannerWithBulkload.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerNoMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerMetrics.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionReplicas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionServerBulkLoad.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestEncryptionRandomKeying.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MetaTableAccessor.java</file>
      <file type="M">hbase-examples.src.test.java.org.apache.hadoop.hbase.coprocessor.example.TestRowCountEndpoint.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.RestartRsHoldingTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.mapreduce.IntegrationTestImportTsv.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestLoadAndVerify.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HRegionPartitioner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.Import.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.ImportTsv.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableOutputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.WALPlayer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.Canary.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestClientScannerRPCTimeout.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide3.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMultiParallel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannersFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannerTimeout.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotCloneIndependence.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestTimestampsFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestHTableWrapper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestOpenTableInCoprocessor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestColumnRangeFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestFuzzyRowAndColumnRangeFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.fs.TestBlockReorder.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestChangingEncoding.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestCopyTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestHRegionPartitioner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestImportExport.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestImportTsv.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestImportTSVWithOperationAttributes.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestImportTSVWithVisibilityLabels.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFilesSplitRecovery.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestMultiTableInputFormat.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestMultithreadedTableMapper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestRowCounter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScanBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableMapReduce.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableMapReduceBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestWALPlayer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapred.TestTableInputFormat.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapred.TestTableMapReduce.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapred.TestTableMapReduceUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterTransitions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRestartCluster.java</file>
    </fixedFiles>
  </bug>
  <bug id="12076" opendate="2014-9-24 00:00:00" fixdate="2014-9-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move InterfaceAudience imports to hbase-annotations</summary>
      <description></description>
      <version>0.98.7,0.99.1,2.0.0</version>
      <fixedVersion>0.98.7,0.99.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Query.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftUtilities.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftMetrics.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.TBoundedThreadPoolServer.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.HThreadedSelectorServerArgs.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.HbaseHandlerMetricsProxy.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.CallQueue.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftUtilities.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.HTablePool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.test.LoadTestDataGeneratorWithACL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.test.LoadTestDataGenerator.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.StoppableImplementation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.LoadTestDataGeneratorWithTags.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.LoadTestDataGeneratorWithVisibilityLabels.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.LabelFilteringScanLabelGenerator.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.ExpAsStringVisibilityLabelServiceImpl.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.HBaseKerberosUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.HLogPerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MiniHBaseCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.codec.CodecPerformance.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKSplitLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKServerTool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.RegionServerTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.RecoveringRegionWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessWriteLock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessReadWriteLock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessReadLock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessLockBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.LoadBalancerTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.DrainingServerTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.DeletionListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ClusterStatusTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ZKNamespaceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.SortedCopyOnWriteSet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ServerCommandLine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionSplitCalculator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionSizeCalculator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ProtoUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.MunkresAssignment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.MultiHConnection.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ModifyRegionUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.MetaUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.Merge.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ManualEnvironmentEdge.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.KeyRange.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.JvmVersion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.JvmPauseMonitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.JVMClusterUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.InfoServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.IdLock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HMerge.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.hbck.OfflineMetaRepair.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.hbck.HFileCorruptionChecker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsckRepair.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseConfTool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HashedBytes.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSVisitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSTableDescriptors.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSRegionScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSMapRUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSHDFSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.DirectMemoryUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ConnectionCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.CompressionTest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.CompoundBloomFilterWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.CompoundBloomFilterBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.CompoundBloomFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.CollectionBackedScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.CancelableProgressable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ByteBloomFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.BloomFilterWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.BloomFilterFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.BloomFilterBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.BloomFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.AbstractHBaseTool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.TableDescriptors.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.TableDescriptor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.SplitLogTask.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.SplitLogCounters.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotManifestV2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotManifestV1.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotManifest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.ExportSnapshot.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.Server.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.ZKVisibilityLabelWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityScanDeleteTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityLabelServiceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityLabelService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityLabelsCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityLabelOrdinalProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityLabelFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityExpEvaluator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.SimpleScanLabelGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.ScanLabelGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.ParseException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.expression.Operator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.expression.NonLeafExpressionNode.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.expression.LeafExpressionNode.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.expression.ExpressionNode.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.ExpressionParser.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.ExpressionExpander.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.EnforcingScanLabelGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.DefaultVisibilityLabelServiceImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.DefaultScanLabelGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.ZKSecretWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.TokenUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.TokenProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.FsDelegationToken.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.AuthenticationTokenSecretManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.AuthenticationKey.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.SecurityUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.HBaseSaslRpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.HBasePolicyProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.ZKPermissionWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.TableAuthManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.HbaseObjectWritableFor96Migration.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.CodeToClassAndBackFor96Migration.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AuthResult.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlLists.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.VersionResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.TableScanResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.TableResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.StorageClusterVersionResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.StorageClusterStatusResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.SchemaResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerResultGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerInstanceResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RowSpec.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RowResultGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RowResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RootResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ResultGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RESTServletContainer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RESTServlet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RESTServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ResourceConfig.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ResourceBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RegionsResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.provider.producer.ProtobufMessageBodyProducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.provider.producer.PlainTextMessageBodyProducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.provider.JAXBContextResolver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.provider.consumer.ProtobufMessageBodyConsumer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ProtobufMessageHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.MultiRowResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.VersionModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.TableSchemaModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.TableRegionModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.TableModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.TableListModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.TableInfoModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.StorageClusterVersionModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.StorageClusterStatusModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.ScannerModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.RowModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.ColumnSchemaModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.CellSetModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.CellModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.MetricsREST.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.filter.GZIPResponseWrapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.filter.GZIPResponseStream.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.filter.GZIPRequestWrapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.filter.GZIPRequestStream.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.filter.GzipFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ExistsResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.Constants.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.Response.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteAdmin.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.Cluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.Client.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.WALEntryFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.SystemTableWALEntryFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.ScopeWALEntryFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.ReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationThrottler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationHLogReaderManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.Replication.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.MetricsSource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.MetricsSink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.HBaseReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.ChainWALEntryFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.BaseReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WriterBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALEditsReplaySink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALEdit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALCellCodec.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALActionsListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SyncFuture.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SecureWALCellCodec.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.RingBufferTruck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.ReaderBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.MetricsWALEditsReplay.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.MetricsWAL.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.KeyValueCompression.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogPrettyPrinter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogKey.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSWALEntry.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.Compressor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.CompressionContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.UnexpectedStateException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.TimeRangeTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StripeStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StripeStoreFileManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StripeStoreEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StripeStoreConfig.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StripeMultiFileWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFlushContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StorefileRefresherChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreConfigInformation.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitLogWorker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.snapshot.RegionServerSnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.snapshot.FlushSnapshotSubprocedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SimpleRpcSchedulerFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ShutdownHook.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ServerNonceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SequenceId.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ScanWildcardColumnTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ScanType.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ScanInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ScanDeleteTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSStatusServlet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSDumpServlet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RpcSchedulerFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RowTooBigException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RowProcessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ReversedStoreScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ReversedRegionScannerImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ReversedKeyValueHeap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ReplicationSourceService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ReplicationSinkService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ReplicationService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerAccounting.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionMergeTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionMergeRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.OperationStatus.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.OnlineRegions.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.NoOpHeapMemoryTuner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.NonReversedNonLazyKeyValueScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.NonLazyKeyValueScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MultiVersionConsistencyControl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MultiRowMutationProcessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MiniBatchOperationInProgress.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetaLogRoller.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreSnapshot.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreLAB.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreChunkPool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.LruHashMap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.LogRoller.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Leases.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.LeaseListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.LastSequenceId.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.KeyValueSkipListSet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.KeyValueScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.KeyValueHeap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.KeyPrefixRegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.InternalScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.InternalScan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HeapMemStoreLAB.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HeapMemoryTuner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HeapMemoryManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.ParallelSeekHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenMetaHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.HLogSplitterHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseMetaHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.GetClosestRowBeforeTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.FlushRequestListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.FlushRequester.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.FavoredNodesForRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ExplicitColumnTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DisabledRegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DelimitedKeyPrefixRegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DeleteTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultStoreFileManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultStoreEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultMemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultHeapMemoryTuner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactionTool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.StripeCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.RatioBasedCompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.OffPeakHours.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CurrentHourProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.Compactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionProgress.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactionRequestor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ColumnTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ColumnCount.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ChangedReadersObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.BaseRowProcessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.AnnotationReadingPriorityFunction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.UserQuotaState.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.TimeBasedLimiter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.RegionServerQuotaManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.RateLimiter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaState.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaLimiterFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaLimiter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.OperationQuota.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.NoopQuotaLimiter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.NoopOperationQuota.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.MasterQuotaManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.DefaultOperationQuota.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.ReplicationProtbufUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureMemberRpcs.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureCoordinatorRpcs.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.SubprocedureFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.RegionServerProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ProcedureMemberRpcs.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ProcedureMember.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ProcedureManagerHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ProcedureCoordinatorRpcs.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ProcedureCoordinator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.Procedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.MasterProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.flush.RegionServerFlushTableProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.flush.MasterFlushTableProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.flush.FlushTableSubprocedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.ThreadMonitoring.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.TaskMonitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.StateDumpServlet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.MonitoredTask.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.MonitoredRPCHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.MemoryBoundedLogMessageBuffer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.LogMonitoring.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.UnAssignCallable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableNamespaceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableLockManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotLogCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.RestoreSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.MasterSnapshotVerifier.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.EnabledTableSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.DisabledTableSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.CloneSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SnapshotSentinel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SnapshotOfRegionAssignmentFromMeta.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStateStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionPlan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionPlacementMaintainer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RackManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MetricsMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterStatusServlet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterDumpServlet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.LoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMasterCommandLine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TruncateTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TotesHRegionInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableModifyFamilyHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableEventHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableDeleteFamilyHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableAddFamilyHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ModifyTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.MetaServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.LogReplayHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.EnableTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DispatchMergingRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DisableTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DeleteTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.CreateTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.GeneralBulkAssigner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.DeadServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ClusterStatusPublisher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.LogCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.HFileLinkCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.HFileCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.FileCleanerDelegate.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.BaseLogCleanerDelegate.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.BaseHFileCleanerDelegate.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.BulkReOpen.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.BulkAssigner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.SimpleLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.ServerAndLoad.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.LoadBalancerFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.FavoredNodeLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.FavoredNodeAssignmentHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.ClusterStatusChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BalancerChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentVerificationReport.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignCallable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ActiveMasterManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableSplit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableReduce.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableRecordReaderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableRecordReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableOutputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableMapReduceUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableMap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableInputFormatBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.RowCounter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.IdentityTableReduce.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.IdentityTableMap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.HRegionPartitioner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.GroupingTableMap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.Driver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.WALPlayer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.VisibilityExpressionResolver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TsvImporterTextMapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TsvImporterMapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TextSortReducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableSplit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableReducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableRecordReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableOutputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableOutputCommitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.SimpleTotalOrderPartitioner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.RowCounter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.PutSortReducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.PutCombiner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.MultiTableOutputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.MultiTableInputFormatBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.MultiTableInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.KeyValueSortReducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.ImportTsv.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.Import.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.IdentityTableReducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.IdentityTableMapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HRegionPartitioner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HLogInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HFileOutputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.GroupingTableMapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.Export.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.Driver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.DefaultVisibilityExpressionResolver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.CopyTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.CellCreator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.CellCounter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.LocalHBaseCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServerInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcSchedulerContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcExecutor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RequestContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.PriorityFunction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseRPCErrorHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.Delayable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.CallRunner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.BufferChain.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.BalancedQueueRpcExecutor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.WritableWithSize.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.Reference.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.HLogLink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.ResizableBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.NoOpDataBlockEncoder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruCachedBlockQueue.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruCachedBlock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.InvalidHFileException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.InlineBlockWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileWriterV3.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileWriterV2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderV3.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderV2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CorruptHFileException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheStats.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CachedBlock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheableDeserializerIdManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheableDeserializer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.Cacheable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.UniqueIndexMap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.IOEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.FileIOEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.CacheFullException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.CachedEntryQueue.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.ByteBufferIOEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketCacheStats.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocatorException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.BlockCacheUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.BlockCachesIterator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.BlockCacheKey.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.BlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.AbstractHFileWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.AbstractHFileReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.HFileLink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.HalfStoreFileReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.FileLink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.InterProcessReadWriteLock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.InterProcessLock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.ServerConfigurationKeys.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.NoCacheFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.log.LogLevel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.lib.StaticUserWebFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.lib.package-info.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.InfoServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.HttpServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.HttpConfig.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.conf.ConfServlet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.AdminAuthorizedServlet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HDFSBlocksDistribution.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.executor.ExecutorService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.executor.EventHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.errorhandling.TimeoutExceptionInjector.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.errorhandling.TimeoutException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.errorhandling.ForeignExceptionSnare.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.errorhandling.ForeignExceptionListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.errorhandling.ForeignException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.WALObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.WALCoprocessorEnvironment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.ObserverContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.EndpointObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseWALObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseRowProcessorEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseRegionServerObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.AggregateImplementation.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.SplitLogWorkerCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.SplitLogManagerCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.BaseCoordinatedStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.CoordinatedStateManagerFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.CoordinatedStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.constraint.Constraints.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.constraint.ConstraintProcessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.constraint.ConstraintException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.constraint.Constraint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.constraint.BaseConstraint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.codec.MessageCodec.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.TableSnapshotScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.coprocessor.RowProcessorClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.CoprocessorHConnection.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ClientSideRegionScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.example.ZKTableArchiveClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.example.TableHFileArchiveTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.example.LongTermArchivingHFileCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.example.HFileArchiveManager.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.util.vint.UVLongTool.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.util.vint.UVIntTool.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.util.vint.UFIntTool.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.util.byterange.impl.ByteRangeTreeSet.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.util.byterange.impl.ByteRangeHashSet.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.util.byterange.ByteRangeSet.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.scanner.ReversibleCellScanner.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.scanner.CellSearcher.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.scanner.CellScannerPosition.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeCodec.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeBlockMeta.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.tokenize.TokenizerRowSearchResult.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.tokenize.TokenizerRowSearchPosition.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.tokenize.TokenizerNode.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.tokenize.Tokenizer.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.tokenize.TokenDepthComparator.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.row.RowSectionWriter.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.row.RowNodeWriter.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.PrefixTreeEncoder.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.other.LongEncoder.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.other.ColumnNodeType.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.other.CellTypeEncoder.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.EncoderPoolImpl.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.EncoderPool.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.EncoderFactory.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.column.ColumnSectionWriter.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.column.ColumnNodeWriter.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.timestamp.TimestampDecoder.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.timestamp.MvccVersionDecoder.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.row.RowNodeReader.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeCell.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArraySearcher.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayReversibleScanner.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.DecoderFactory.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.column.ColumnReader.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.column.ColumnNodeReader.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.ArraySearcherPool.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.StripeCompactionsPerformanceEvaluation.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.HBaseClusterManager.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.DistributedHBaseCluster.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.ClusterManager.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.util.MetricSampleQuantiles.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.util.MetricQuantile.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.MutableHistogram.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.MetricsExecutorImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.MetricMutableQuantiles.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.DynamicMetricsRegistry.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.impl.JmxCacheBuster.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.thrift.MetricsThriftServerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.thrift.MetricsThriftServerSourceFactoryImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.rest.MetricsRESTSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.replication.regionserver.MetricsReplicationSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.wal.MetricsWALSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.wal.MetricsEditsReplaySourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceFactoryImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionAggregateSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.metrics.MBeanSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.metrics.BaseSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsSnapshotSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterSourceFactoryImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterFilesystemSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsAssignmentManagerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.balancer.MetricsBalancerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.mapreduce.JobUtil.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceFactoryImpl.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.Waiter.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.HBaseCommonTestingUtility.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.VersionAnnotation.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.VersionInfo.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Triple.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Threads.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.test.RedundantKVGenerator.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.test.LoadTestKVGenerator.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Strings.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.SimplePositionedMutableByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.SimplePositionedByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.SimpleMutableByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.RetryCounterFactory.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.RetryCounter.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ReflectionUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.PrettyPrinter.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.PositionedByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.PairOfSameType.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Pair.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.OrderedBytes.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Order.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.MurmurHash.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Methods.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.MD5Hash.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.KeyLocker.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.JVM.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.JenkinsHash.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.IterableUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.IncrementingEnvironmentEdge.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Hash.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.EnvironmentEdgeManager.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.EnvironmentEdge.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.DynamicClassLoader.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.DrainBarrier.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.DefaultEnvironmentEdge.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Counter.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.CoprocessorClassLoader.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ConcurrentIndex.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.CollectionUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ClassSize.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ClassLoaderBase.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Classes.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Bytes.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteRangeUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteBufferUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteBufferArray.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Base64.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ArrayUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Addressing.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.Union4.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.Union3.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.Union2.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.TerminatedWrapper.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.StructIterator.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.StructBuilder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.Struct.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawStringTerminated.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawStringFixedLength.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawString.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawShort.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawLong.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawInteger.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawFloat.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawDouble.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawBytesTerminated.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawBytesFixedLength.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawBytes.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawByte.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedString.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedNumeric.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedInt8.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedInt64.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedInt32.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedInt16.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedFloat64.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedFloat32.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedBytesBase.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedBlobVar.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedBlob.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.FixedLengthWrapper.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.DataType.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.TagType.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.Tag.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.TableName.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.SettableSequenceId.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.security.UserProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.security.User.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.NamespaceDescriptor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValueUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValueTestUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.util.StreamUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.util.LRUDictionary.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.util.HeapMemorySizeUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.util.Dictionary.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.TimeRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.TagCompressionContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.SizedCellScanner.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.ImmutableBytesWritable.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileContextBuilder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.hfile.BlockType.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.HeapSize.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.PrefixKeyDeltaEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.HFileBlockEncodingContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.HFileBlockDefaultEncodingContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.HFileBlockDefaultDecodingContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.HFileBlockDecodingContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.FastDiffDeltaEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.EncodingState.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.EncoderBufferTooSmallException.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.EncodedDataBlock.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.DiffKeyDeltaEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.DataBlockEncoding.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.DataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.CopyKeyDataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.CompressionState.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.KeyStoreKeyProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.KeyProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.Encryptor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.Encryption.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.DefaultCipherProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.Decryptor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.Context.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.CipherProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.Cipher.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.aes.AESEncryptor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.aes.AESDecryptor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.aes.AES.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.compress.ReusableStreamGzipCodec.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.compress.Compression.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.CellOutputStream.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.ByteBufferOutputStream.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HBaseIOException.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HBaseInterfaceAudience.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HBaseConfiguration.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CompoundConfiguration.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.KeyValueCodecWithTags.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.KeyValueCodec.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.CodecException.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.Codec.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.CellCodecWithTags.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.CellCodec.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.BaseEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.BaseDecoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellScanner.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellScannable.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellComparator.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.Cell.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperNodeTracker.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperListener.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKLeaderManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKConfig.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKClusterId.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.MetaTableLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.MasterAddressTracker.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.HQuorumPeer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.EmptyWatcher.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ZooKeeperConnectionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.YouAreDeadException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.util.Writables.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.util.Sleeper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.util.PoolMap.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.util.JsonMapper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.util.HasThread.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.util.FileSystemVersionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.UnknownScannerException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.UnknownRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableNotFoundException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableNotEnabledException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableNotDisabledException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableInfoMissingException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableExistsException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.Stoppable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.UnknownSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.TablePartiallyOpenException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotExistsException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotDoesNotExistException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotCreationException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.RestoreSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.HBaseSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.ExportSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.CorruptedSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.ClientSnapshotDescriptionUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ServerName.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ServerLoad.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityLabelsValidator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityControllerNotReadyException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.LabelAlreadyExistsException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.InvalidLabelException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.CellVisibility.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.Authorizations.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.token.AuthenticationTokenSelector.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.token.AuthenticationTokenIdentifier.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.SecurityInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.SecureBulkLoadUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.SaslUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.SaslStatus.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.HBaseSaslRpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.EncryptionUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.AuthMethod.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.UserPermission.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.TablePermission.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.Permission.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.AccessDeniedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationTracker.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueues.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeerZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeers.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeerConfig.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationListener.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionTooBusyException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.WrongRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FailedSyncBeforeLogCloseException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FailedLogCloseException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerStoppedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerRunningException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.RegionOpeningState.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.LeaseException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.BloomType.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionLocations.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionLoad.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.ThrottleType.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.ThrottleSettings.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaType.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaTableUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaSettingsFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaSettings.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaScope.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaRetriever.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ResponseConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.PleaseHoldException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.NotServingRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.NotAllMetaRegionsOnlineException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.NamespaceNotFoundException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.NamespaceExistException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MetaTableAccessor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.master.RegionState.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MasterNotRunningException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.WrongVersionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.UnsupportedCompressionCodecException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.UnsupportedCellCodecException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.StoppedRpcClientException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.ServerNotRunningYetException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RegionCoprocessorRpcChannel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.PayloadCarryingRpcController.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.MasterCoprocessorRpcChannel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.FatalConnectionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.CoprocessorRpcChannel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.CallerDisconnectedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.BlockingRpcCallback.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.BadAuthException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.InvalidFamilyOperationException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HRegionLocation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.WhileMatchFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ValueFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.TimestampsFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.SubstringComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.SkipFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.SingleColumnValueFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.SingleColumnValueExcludeFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.RowFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.RegexStringComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.RandomRowFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.QualifierFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.PrefixFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ParseFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ParseConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.PageFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.NullComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.MultipleColumnPrefixFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.KeyOnlyFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.InvalidRowFilterException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.IncompatibleFilterException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.InclusiveStopFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FuzzyRowFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FirstKeyValueMatchingQualifiersFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FirstKeyOnlyFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FilterWrapper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FilterList.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FilterBase.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.Filter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FamilyFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.DependentColumnFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.CompareFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ColumnRangeFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ColumnPrefixFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ColumnPaginationFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ColumnCountGetFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ByteArrayComparable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.BitComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.BinaryPrefixComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.BinaryComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.executor.ExecutorType.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.executor.EventType.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.RegionOpeningException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.RegionMovedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.RegionInRecoveryException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.OutOfOrderScannerNextException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.OperationConflictException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.MergeRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.HBaseException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.DeserializationException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.DroppedSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.DoNotRetryIOException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.coprocessor.ColumnInterpreter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.CoprocessorEnvironment.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.Coprocessor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.CoordinatedStateException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ClusterStatus.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ClusterId.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ClockOutOfSyncException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.WrongRowIOException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.UnmodifyableHTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.UnmodifyableHRegionInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.TableState.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Table.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerTimeoutException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RowTooBigException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RowMutations.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Row.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RetryingCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RetriesExhaustedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ResultScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Result.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.replication.ReplicationAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionServerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionReplicaUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionOfflineException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionCoprocessorServiceExec.java</file>
      <file type="M">hbase-annotations.src.main.java.org.apache.hadoop.hbase.classification.tools.ExcludePrivateAnnotationsStandardDoclet.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.Abortable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.Chore.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AbstractClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Action.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Append.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Attributes.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientIdGenerator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallReversedScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClusterConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClusterStatusListener.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Connection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionAdapter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Consistency.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.AggregationClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.Batch.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.BigDecimalColumnInterpreter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.DoubleColumnInterpreter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.LongColumnInterpreter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.SecureBulkLoadClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Delete.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Durability.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Get.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnectable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTableFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTableInterfaceFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTableMultiplexer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Increment.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.IsolationLevel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MetaCache.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MetaScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.metrics.ScanMetrics.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MultiAction.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MultiResponse.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Mutation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.NonceGenerator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.NoServerForRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Operation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.OperationWithAttributes.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.PerClientRandomNonceGenerator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Put.java</file>
    </fixedFiles>
  </bug>
  <bug id="12080" opendate="2014-9-24 00:00:00" fixdate="2014-9-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Shorten the run time of integration test by default when using mvn failsafe:integration-test</summary>
      <description>By default, using "mvn failsafe:integration-test" to execute the integration test with MOB will run more than 10 minutes. In this JIRA, we'll shorten this run time by default.</description>
      <version>2.0.0</version>
      <fixedVersion>hbase-11339,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestIngestWithMOB.java</file>
    </fixedFiles>
  </bug>
  <bug id="1210" opendate="2009-2-23 00:00:00" fixdate="2009-2-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow truncation of output for scan and get commands in shell</summary>
      <description>Allow to chop the output of the values to be able to scan a table for specific rows and columns but without having the shell dump all the content of the cell value as it can potentially be very large. I suggest a hash called MAXLENGTH that can be added to the commands. For example:get 'docs', 'ABCDE', { COLUMNS =&gt; 'contents:', MAXLENGTH =&gt; 150 }and scan 'docs', { COLUMNS =&gt; 'contents:', MAXLENGTH =&gt; 150 }</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.HBase.rb</file>
    </fixedFiles>
  </bug>
  <bug id="12102" opendate="2014-9-26 00:00:00" fixdate="2014-2-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Duplicate keys in HBase.RegionServer metrics JSON</summary>
      <description>The JSON returned by /jmx on the RegionServer contains duplicate 'tag.Context' keys for various HBase.RegionServer metrics. Regions:{ "name" : "Hadoop:service=HBase,name=RegionServer,sub=Regions", "modelerType" : "RegionServer,sub=Regions", "tag.Context" : "regionserver", "tag.Context" : "regionserver", "tag.Hostname" : "some.host.name", ...}Server:"name" : "Hadoop:service=HBase,name=RegionServer,sub=Server", "modelerType" : "RegionServer,sub=Server", "tag.Context" : "regionserver", "tag.zookeeperQuorum" : "some.zookeeper.quorum.peers", "tag.serverName" : "some.server.name", "tag.clusterId" : "88c186ea-2308-4713-8b5f-5a3e829cbb10", "tag.Context" : "regionserver", ...}IPC:{ "name" : "Hadoop:service=HBase,name=IPC,sub=IPC", "modelerType" : "IPC,sub=IPC", "tag.Context" : "ipc", "tag.Context" : "ipc", "tag.Hostname" : "some.host.name", ...}This can cause issues with some JSON parsers. We should avoid emitting duplicate keys if it is under our control.</description>
      <version>1.0.0,0.98.10,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.11,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionAggregateSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="12109" opendate="2014-9-26 00:00:00" fixdate="2014-10-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>user_permission command for namespace does not return correct result</summary>
      <description>The existing user_permission command does not return permissions related to namespace. The permissions exist in the acl table, but the user_permission.rb does not handle namespaces.</description>
      <version>2.0.0</version>
      <fixedVersion>0.98.8,0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.security.rb</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="12130" opendate="2014-10-1 00:00:00" fixdate="2014-10-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBASE-11980 calls hflush and hsync doing near double the syncing work</summary>
      <description>The HBASE-11980 change has us doing hflush and hsync every time we call sync (noticed profiling). Fix. Let me expose as config calling one or the other.</description>
      <version>0.99.1,2.0.0</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.java</file>
    </fixedFiles>
  </bug>
  <bug id="12145" opendate="2014-10-1 00:00:00" fixdate="2014-10-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix javadoc and findbugs so new folks aren&amp;#39;t freaked when they see them</summary>
      <description>Misc set of fixes to get these attributes green again.</description>
      <version>None</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.SchemaResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RowTooBigException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.RatioBasedCompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableRecordReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.PrettyPrinter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeersZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionAdminServiceCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="12160" opendate="2014-10-2 00:00:00" fixdate="2014-10-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make Surefire&amp;#39;s argLine configurable in the command line</summary>
      <description>On tests machines with larger sets of ram it can really help to reduce test time to run with larger heaps. Lets make that a property so that mvn command line can set it.</description>
      <version>0.99.1,0.98.6.1,2.0.0</version>
      <fixedVersion>0.98.7,0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="12181" opendate="2014-10-6 00:00:00" fixdate="2014-10-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Some tests create a table and try to use it before regions get assigned</summary>
      <description>I inadvertently did some unit test stress testing this weekend by running mvn test -P runAllTests on a machine that also had other processes going on. The overall sluggishness led to a number of failed tests that were caused by a table being created using HBaseAdmin#createTable, which only blocks for meta to get updated and not for the region to actually get assigned a RegionServer. Quick fix is to use HBaseTestingUtility#createTable whenever possible.</description>
      <version>1.0.0,0.98.6.1,2.0.0</version>
      <fixedVersion>0.98.8,0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
    </fixedFiles>
  </bug>
  <bug id="12198" opendate="2014-10-7 00:00:00" fixdate="2014-10-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix the bug of not updating location cache</summary>
      <description>Fix the bug of not updating location cache.Add a testcase for it.</description>
      <version>1.0.0,0.98.7,2.0.0</version>
      <fixedVersion>0.98.8,0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTableMultiplexer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
    </fixedFiles>
  </bug>
  <bug id="12207" opendate="2014-10-8 00:00:00" fixdate="2014-10-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>A script to help keep your Git repo fresh</summary>
      <description>I have a script that does a git pull --rebase on each tracking branch, and then attempts an automatic rebase of each local branch against its tracking branch. It also prompts you to delete local branches for HBASE- JIRAs that have been closed. I think this script may help to enforce good Git practices. It may be a good candidate to be included in dev-support/.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.developer.xml</file>
    </fixedFiles>
  </bug>
  <bug id="12210" opendate="2014-10-9 00:00:00" fixdate="2014-10-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Avoid KeyValue in Prefix Tree</summary>
      <description>Avoid KeyValue recreate where all possible in the PrefixTree module.</description>
      <version>None</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestPrefixTree.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeCell.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellComparator.java</file>
    </fixedFiles>
  </bug>
  <bug id="12251" opendate="2014-10-14 00:00:00" fixdate="2014-10-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[book] Hadoop compat matrix 0.94 section needs cleaned up</summary>
      <description>The compatibility matrix has instructions for compiling 0.94 vs Hadoop 2.2 inline in the table. These should sit outside the compatibility matrix table as a referenced section.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.configuration.xml</file>
    </fixedFiles>
  </bug>
  <bug id="12261" opendate="2014-10-15 00:00:00" fixdate="2014-10-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add checkstyle to HBase build process</summary>
      <description>We should add checkstyle to hadoop qa for our builds. That would free committers up from checking patches for stylistic issues and leave them free to check the real meat of the patches.Additionally we should have the check for empty try catch blocks running so that we can't regress on catching exceptions.</description>
      <version>2.0.0</version>
      <fixedVersion>0.98.8,0.99.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  <bug id="12263" opendate="2014-10-15 00:00:00" fixdate="2014-10-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RegionServer listens on localhost in distributed cluster when DNS is unavailable</summary>
      <description>When DNS is unavailable, the new started regionservers will listen on localhost(127.0.0.1) in a distributed cluster, which results that the hmaster will fail to assign regions to those regionservers.2014-10-15,04:26:42,273 WARN org.apache.hadoop.net.DNS: Unable to determine local hostname -falling back to "localhost"java.net.UnknownHostException: xx-hadoop-srv-st01.bj: xx-hadoop-srv-st01.bj at java.net.InetAddress.getLocalHost(InetAddress.java:1360) at org.apache.hadoop.net.DNS.resolveLocalHostname(DNS.java:260) at org.apache.hadoop.net.DNS.&lt;clinit&gt;(DNS.java:58) at org.apache.hadoop.hbase.regionserver.HRegionServer.&lt;init&gt;(HRegionServer.java:472)$ netstat -nap | grep 13748tcp 0 0 127.0.0.1:12610 0.0.0.0:* LISTEN 13748/java tcp 0 0 0.0.0.0:12611 0.0.0.0:* LISTEN 13748/javaIn this situation, I think we shoud throw an exception and make the startup of regionservers failed.</description>
      <version>2.0.0</version>
      <fixedVersion>0.99.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="12283" opendate="2014-10-17 00:00:00" fixdate="2014-10-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up some checkstyle errors</summary>
      <description></description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestEndToEndSplitTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.CleanerChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HealthCheckChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.DaemonThreadFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.CoordinatedStateManagerFactory.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HBaseInterfaceAudience.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HBaseConfiguration.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CompoundConfiguration.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellKey.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HRegionLocation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ClusterStatus.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.Chore.java</file>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  <bug id="12307" opendate="2014-10-21 00:00:00" fixdate="2014-10-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove unused Imports in hbase-client and hbase-common</summary>
      <description>Remove all of the unused imports. I'll be using eclipse to do that.</description>
      <version>0.99.2,2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.Waiter.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestThreads.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestShowProperties.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestKeyLocker.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestFastLongHistogram.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestEnvironmentEdgeManager.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestDrainBarrier.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestConcatenatedLists.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestByteRangeWithKVSerialization.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestBase64.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.ResourceCheckerJUnitListener.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.ResourceChecker.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.io.util.TestLRUDictionary.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.io.TestTagCompressionContext.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.io.crypto.TestKeyProvider.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.io.crypto.TestEncryption.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.io.crypto.TestCipherProvider.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.io.crypto.KeyProviderForTesting.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.io.crypto.aes.TestAES.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.HBaseCommonTestingUtility.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.codec.TestKeyValueCodecWithTags.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.codec.TestCellCodecWithTags.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.codec.TestCellCodec.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.ClassTestFinder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.VersionAnnotation.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.VersionInfo.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.test.RedundantKVGenerator.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.PrettyPrinter.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Hash.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.DynamicClassLoader.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.CoprocessorClassLoader.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ConcurrentIndex.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ConcatenatedLists.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ChecksumFactory.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Base64.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.PBType.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.TableName.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.security.UserProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.security.User.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.NamespaceDescriptor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValueUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.util.HeapMemorySizeUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.TagCompressionContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.SizedCellScanner.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.LimitInputStream.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.ImmutableBytesWritable.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileContextBuilder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.PrefixKeyDeltaEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.FastDiffDeltaEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.EncodingState.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.EncodedDataBlock.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.DiffKeyDeltaEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.DataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.CopyKeyDataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.CompressionState.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.KeyStoreKeyProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.Encryption.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.DefaultCipherProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.Context.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.CipherProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.compress.Compression.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.CellOutputStream.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HBaseIOException.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HBaseConfiguration.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CompoundConfiguration.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.KeyValueCodecWithTags.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.KeyValueCodec.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.CodecException.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.Codec.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.CellCodecWithTags.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.CellCodec.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.BaseEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.BaseDecoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellScanner.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.TestHColumnDescriptor.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.security.TestEncryptionUtil.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.ipc.TestIPCUtil.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotFromAdmin.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestScan.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestOperation.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestGet.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestClientNoCluster.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestAsyncProcess.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperNodeTracker.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKLeaderManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKConfig.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKClusterId.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.MetaTableLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.MasterAddressTracker.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.HQuorumPeer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ZooKeeperConnectionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.YouAreDeadException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.util.Writables.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.util.Sleeper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.util.HasThread.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableNotFoundException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableNotEnabledException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableNotDisabledException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableExistsException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.TablePartiallyOpenException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.HBaseSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.ClientSnapshotDescriptionUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ServerLoad.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.LabelAlreadyExistsException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.InvalidLabelException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.token.AuthenticationTokenSelector.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.token.AuthenticationTokenIdentifier.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.SecureBulkLoadUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.SaslUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.HBaseSaslRpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.EncryptionUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.AuthMethod.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.UserPermission.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.TablePermission.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.Permission.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.AccessDeniedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationTracker.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueuesZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueueInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeerZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeersZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeers.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.WrongRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FailedLogCloseException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.LeaseException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.ThrottlingException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.ThrottleSettings.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaTableUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaSettingsFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaSettings.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaRetriever.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ResponseConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.PleaseHoldException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.NotServingRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MetaTableAccessor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.master.RegionState.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MasterNotRunningException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.TimeLimitedRpcController.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.StoppedRpcClientException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.ServerRpcController.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.ServerNotRunningYetException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RegionServerCoprocessorRpcChannel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RegionCoprocessorRpcChannel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.PayloadCarryingRpcController.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.MasterCoprocessorRpcChannel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.FatalConnectionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.CoprocessorRpcChannel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.InvalidFamilyOperationException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.WhileMatchFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ValueFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.TimestampsFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.SubstringComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.SkipFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.SingleColumnValueFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.SingleColumnValueExcludeFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.RowFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.RegexStringComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.RandomRowFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.QualifierFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.PrefixFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ParseFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ParseConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.PageFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.MultipleColumnPrefixFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.KeyOnlyFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.InclusiveStopFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FuzzyRowFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FirstKeyValueMatchingQualifiersFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FirstKeyOnlyFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FilterWrapper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FilterList.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FilterBase.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.Filter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FamilyFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.DependentColumnFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.CompareFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ColumnRangeFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ColumnPrefixFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ColumnPaginationFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ColumnCountGetFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ByteArrayComparable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.BitComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.BinaryPrefixComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.BinaryComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.RegionOpeningException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.RegionMovedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.RegionInRecoveryException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.OutOfOrderScannerNextException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.OperationConflictException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.MergeRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.DroppedSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.DoNotRetryIOException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.coprocessor.ColumnInterpreter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.CoprocessorEnvironment.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ClusterStatus.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ClusterId.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ZooKeeperRegistry.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ZooKeeperKeepAliveConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.WrongRowIOException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.UnmodifyableHTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.UnmodifyableHRegionInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.TableState.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Table.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerTimeoutException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RowTooBigException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Action.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Append.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Attributes.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientIdGenerator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallReversedScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClusterConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClusterStatusListener.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Connection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionAdapter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.AggregationClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.Batch.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.BigDecimalColumnInterpreter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.DoubleColumnInterpreter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.LongColumnInterpreter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.SecureBulkLoadClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Delete.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Get.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnectable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTableFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTableInterfaceFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Increment.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MetaCache.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MetaScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MultiAction.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MultiResponse.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Mutation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.NoServerForRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.OperationWithAttributes.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.PerClientRandomNonceGenerator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Put.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Query.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionCoprocessorServiceExec.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionOfflineException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionReplicaUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionServerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Registry.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.replication.ReplicationAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Result.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ResultScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RetriesExhaustedException.java</file>
    </fixedFiles>
  </bug>
  <bug id="12308" opendate="2014-10-21 00:00:00" fixdate="2014-10-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix typo in hbase-rest profile name</summary>
      <description>Change skipRestTets to skipRestTests.</description>
      <version>0.99.2,2.0.0</version>
      <fixedVersion>0.98.8,0.99.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-rest.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="12314" opendate="2014-10-21 00:00:00" fixdate="2014-10-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add chaos monkey policy to execute two actions concurrently</summary>
      <description>Right now most of the Chaos Monkies execute one action at a time. It might happen that two are running at the same time but not always. Lets create a policy that will test running two things concurrently.</description>
      <version>2.0.0</version>
      <fixedVersion>0.98.8,0.99.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.factories.SlowDeterministicMonkeyFactory.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.factories.MonkeyFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="12322" opendate="2014-10-22 00:00:00" fixdate="2014-10-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add clean up command to ITBLL</summary>
      <description>Right now ITBLL can leave a table and some files on HDFS. It's then up to the user to clean them up. This can be a little messy. Lets give a single command to do that.</description>
      <version>2.0.0</version>
      <fixedVersion>0.99.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
    </fixedFiles>
  </bug>
  <bug id="12328" opendate="2014-10-23 00:00:00" fixdate="2014-10-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Need to separate JvmMetrics for Master and RegionServer</summary>
      <description>tag.ProcessName of JvmMetrics is "IPC".It is same both Master and RegionServer.HBase(Master and RegionServer)'s Metrics Dump..."name": "Hadoop:service=HBase,name=JvmMetrics","modelerType": "JvmMetrics","tag.Context": "jvm","tag.ProcessName": "IPC","tag.SessionId": "",...When I use HBase with Ganglia,I wrote tagsForPrefix.jvm=ProcessName in hadoop-metrics2-hbase.properties.hadoop-metrics2-hbase.properties...*.sink.ganglia.class=org.apache.hadoop.metrics2.sink.ganglia.GangliaSink31hbase.sink.ganglia.tagsForPrefix.jvm=ProcessName...But, Ganglia generate only one RRD file because tag.ProcessName is "IPC" both Master and Regionserver.I think it need to separate JvmMetrics for Master and RegionServer.</description>
      <version>None</version>
      <fixedVersion>0.99.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestRpcMetrics.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceFactoryImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="12378" opendate="2014-10-29 00:00:00" fixdate="2014-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a test to verify that the read-replica is able to read after a compaction</summary>
      <description>Add a unit test that verify that the secondary read-replica is still able to read all the data even when the files on the primary are archived and the store file refresh is not executed.basically is to have a test that verifies that the file-link logic is not removed.(there are a couple of test that probably wants to do that.. but since they operate on small data they will never trigger the file-link reopen)</description>
      <version>0.99.1,2.0.0</version>
      <fixedVersion>0.99.2</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionReplicas.java</file>
    </fixedFiles>
  </bug>
  <bug id="12379" opendate="2014-10-29 00:00:00" fixdate="2014-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Try surefire 2.18-SNAPSHOT</summary>
      <description>Hopefully has a fix for:&amp;#91;ERROR&amp;#93; Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.17:test (secondPartTestsExecution) on project hbase-server: ExecutionException: java.lang.RuntimeException: java.lang.RuntimeException: java.io.IOException: Stream Closed -&gt; &amp;#91;Help 1&amp;#93;eclark says its been working for him and crew.</description>
      <version>None</version>
      <fixedVersion>0.99.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="12381" opendate="2014-10-30 00:00:00" fixdate="2014-10-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add maven enforcer rules for build assumptions</summary>
      <description>our ref guide says that you need maven 3 to build. add an enforcer rule so that people find out early that they have the wrong maven version, rather then however things fall over if someone tries to build with maven 2.</description>
      <version>None</version>
      <fixedVersion>0.98.8,0.94.25,0.99.2</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="12382" opendate="2014-10-30 00:00:00" fixdate="2014-11-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Restore incremental compilation</summary>
      <description>The build changes in HBASE-11912 required an upgrade of the Maven compiler plugin from 2.5.1 to something &gt;= 3.0. We're now using 3.2. We also switch from whatever Maven does by default with an embedding of tools.jar to invocation of javac. We are no longer getting incremental builds due to Maven bugs hit by these changes. http://jira.codehaus.org/browse/MCOMPILER-209 suggests paradoxically setting useIncrementalCompilation to 'false' will restore incremental compilation behavior.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-thrift.pom.xml</file>
      <file type="M">hbase-shell.pom.xml</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-hadoop-compat.pom.xml</file>
      <file type="M">hbase-examples.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="12397" opendate="2014-10-31 00:00:00" fixdate="2014-11-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CopyTable fails to compile with the Hadoop 1 profile</summary>
      <description>&amp;#91;ERROR&amp;#93; /usr/src/hbase/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/CopyTable.java:&amp;#91;88,17&amp;#93; error: cannot find symbolThis was introduced in f31edd80commit f31edd8004226c795ee46fbe9e93d10671ab895aAuthor: Ted Yu &lt;tedyu@apache.org&gt;Date: Thu Oct 9 15:52:18 2014 +0000 HBASE-11997 CopyTable with bulkload (Yi Deng)tedyu, daviddengcn, please have a look at this or I will revert it on 0.98.</description>
      <version>None</version>
      <fixedVersion>0.98.8,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.configuration.xml</file>
    </fixedFiles>
  </bug>
  <bug id="12409" opendate="2014-11-3 00:00:00" fixdate="2014-11-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add actual tunable parameters for finding optimal # of regions per RS</summary>
      <description>http://hbase.apache.org/book/ops.capacity.html#ops.capacity.regions.count should mention:HBase 0.94:(RS Xmx)(hbase.regionserver.global.memstore.upperLimit)/((hbase.hregion.memstore.flush.size)(# column families))HBase 0.98+: replace upperLimit with hbase.regionserver.global.memstore.size</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1241" opendate="2009-3-5 00:00:00" fixdate="2009-5-5 01:00:00" resolution="Invalid">
    <buginformation>
      <summary>HBase additions to ZooKeeper</summary>
      <description>This issue is to batch all of the edits and additions we make to ZooKeeper for its use in HBase. Rather than wasting lots of our (and ZK's) time with little edit patches, we will send them batch patches from here when things stabilize.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.MiniZooKeeperCluster.java</file>
      <file type="M">lib.zookeeper-3.0.1.jar</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12411" opendate="2014-11-3 00:00:00" fixdate="2014-11-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Optionally enable p-reads and private readers for compactions</summary>
      <description>In the light of HDFS-6735 we might want to consider refraining from seek + read completely and only perform preads.For example currently a compaction can lock out every other scanner over the file which the compaction is currently reading for compaction.At the very least we can introduce an option to avoid seek + read, so we can allow testing this in various scenarios.This will definitely be of great importance for projects like Phoenix which parallelize queries intra region (and hence readers will used concurrently by multiple scanner with high likelihood.)</description>
      <version>None</version>
      <fixedVersion>0.98.9,0.99.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor.java</file>
    </fixedFiles>
  </bug>
  <bug id="12412" opendate="2014-11-3 00:00:00" fixdate="2014-2-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>update the ref guide(currently Example 10.2) to show "update an existing CF" with the new API modifyFamily in master</summary>
      <description>In the new implementation of HTableDescriptor, updating an existing CF doesn't use the addFamily any more(An IllegalArgumentException is thrown in such a case.), the new API modifyFamily is used instead.We need to update the ref guide (currently Example 10.2) to show "update an existing CF" with the new API modifyFamily in master.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.hbase.apis.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="12424" opendate="2014-11-4 00:00:00" fixdate="2014-11-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Finer grained logging and metrics for split transactions</summary>
      <description>A split transaction is a complex orchestration of activity between the RegionServer, Master, ZooKeeper, and HDFS NameNode. We have some visibility into the time taken by various phases of the split transaction in the logs. We will see "Starting split of region $PARENT" before the transaction begins, before the parent is offlined. Later we will see "Opening $DAUGHTER" as one of the last steps in the transaction, this is after the parent has been flushed, offlined, and closed. Finally ""Region split, hbase:meta updated, and report to master ... Split took $TIME" after all steps are complete and including the total running time of the transaction. For debugging the cause(s) of long running split transactions it would be useful to know the distribution of time spent in all of the phases of the split transaction.</description>
      <version>None</version>
      <fixedVersion>0.98.8,0.99.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="12425" opendate="2014-11-4 00:00:00" fixdate="2014-2-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document the phases of the split transaction</summary>
      <description>See PDF document attached to parent issue</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="12496" opendate="2014-11-17 00:00:00" fixdate="2014-11-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>A blockedRequestsCount metric</summary>
      <description>blockedRequestsCount counts for requests blocked because mem size is greater than blockingMemStoreSize.</description>
      <version>1.0.0,0.98.7,2.0.0</version>
      <fixedVersion>0.98.9,0.99.2</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperStub.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="12529" opendate="2014-11-18 00:00:00" fixdate="2014-11-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use ThreadLocalRandom for RandomQueueBalancer</summary>
      <description>looks like the Random in RandomQueueBalancer is now the main cause of contention in the rpc queue insertion. we should replace that Random with a ThreadLocalRandom.</description>
      <version>0.99.1,0.98.6.1,2.0.0</version>
      <fixedVersion>0.98.9,0.99.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcExecutor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.BalancedQueueRpcExecutor.java</file>
    </fixedFiles>
  </bug>
  <bug id="12537" opendate="2014-11-19 00:00:00" fixdate="2014-12-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase should log the remote host on replication error</summary>
      <description>Replication source was getting 'queue full' but didn't say which server was suffering the full queue. Makes it hard to debug...</description>
      <version>None</version>
      <fixedVersion>0.98.9,0.99.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="12553" opendate="2014-11-21 00:00:00" fixdate="2014-12-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>request value is not consistent for restoreSnapshot in audit logs</summary>
      <description>requirePermission("restoreSnapshot", hTableDescriptor.getTableName(), null, null, Permission.Action.ADMIN); } else { requirePermission("restore", Action.ADMIN);</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug id="12568" opendate="2014-11-25 00:00:00" fixdate="2014-12-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Adopt Semantic Versioning and document it in the book</summary>
      <description>See http://search-hadoop.com/m/DHED4LFNzP/semantic+versioning&amp;subj=Re+HBase+Semantic+VersioningWe should put that in the book.</description>
      <version>None</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.upgrading.xml</file>
    </fixedFiles>
  </bug>
  <bug id="12600" opendate="2014-11-29 00:00:00" fixdate="2014-12-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove REPLAY tag dependency in Distributed Replay Mode</summary>
      <description>After HBASE-11315 &amp; HBASE-8763, each edit has a unique 'version' i.e. its SequenceId(or old mvcc value). Therefore, we don't need replay tag to handle out of order same version updates.</description>
      <version>0.99.1,2.0.0</version>
      <fixedVersion>0.99.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.StripeCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.TagType.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellComparator.java</file>
    </fixedFiles>
  </bug>
  <bug id="12615" opendate="2014-12-2 00:00:00" fixdate="2014-10-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document GC conserving guidelines for contributors</summary>
      <description>LinkedIn put up a blog post with a nice concise list of GC conserving techniques we should document for contributors. Additionally, when we're at a point our build supports custom error-prone plugins, we can develop warnings for some of them. Source: http://engineering.linkedin.com/performance/linkedin-feed-faster-less-jvm-garbage Be careful with Iterators Estimate the size of a collection when initializing Defer expression evaluation Compile the regex patterns in advance Cache it if you can String Interns are useful but dangerousAll good advice and practice that I know we aim for.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="12622" opendate="2014-12-3 00:00:00" fixdate="2014-12-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>user_permission should require global admin to display global and ns permissions</summary>
      <description>user_permission check the user permission only on the table level (requiring at least a table-level admin)global and namespace permission listing is done without checking anything.but only a global admins should be able to perform this operations.</description>
      <version>0.98.8,0.99.2,2.0.0</version>
      <fixedVersion>1.0.0,0.98.9</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestNamespaceCommands.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug id="12623" opendate="2014-12-3 00:00:00" fixdate="2014-12-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove pre-0.96 to 0.96 upgrade code</summary>
      <description>Since we require a cluster to be 1.0+ prior to upgrading to 2.0, we should remove code that is only used for handling upgrades prior to that version.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ZKDataMigrator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.migration.NamespaceUpgrade.java</file>
    </fixedFiles>
  </bug>
  <bug id="12663" opendate="2014-12-9 00:00:00" fixdate="2014-12-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>unify getTableDescriptors() and listTableDescriptorsByNamespace()</summary>
      <description>currently we have getTableDescriptors()/listTableNames()and listTableDescriptorsByNamespace()/listTableNamesByNamespace()which are just filtering by namespace.The first two are already able to filter tables by regex,and there is also an ACL check which shows only the table the user have access to,while the namespace version just return a list without any ACLs check.to me there is no point to keep the *ByNamespace() version on the server side, since the "base" version must be able to do the filtering bynamespace and the ACLs check must be the same for both anyway.or at least we can just call the base version with the ns filtering.</description>
      <version>1.0.0,2.0.0</version>
      <fixedVersion>1.0.0,0.98.19</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestNamespaceCommands.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestMasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Master.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MasterProtos.java</file>
    </fixedFiles>
  </bug>
  <bug id="12674" opendate="2014-12-11 00:00:00" fixdate="2014-12-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add permission check to getNamespaceDescriptor()</summary>
      <description>Add permission check to getNamespaceDescriptor()</description>
      <version>1.0.0,2.0.0</version>
      <fixedVersion>1.0.0,0.98.19</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestNamespaceCommands.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestMasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.java</file>
    </fixedFiles>
  </bug>
  <bug id="12675" opendate="2014-12-11 00:00:00" fixdate="2014-12-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use interface methods in shell scripts</summary>
      <description>There are places in the shell script code that use methods from HTable or HConnection or etc. This patch will fix at least some of them.</description>
      <version>None</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.table.rb</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.security.rb</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug id="12677" opendate="2014-12-12 00:00:00" fixdate="2014-12-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update replication docs to clarify terminology</summary>
      <description>Remove use of master-master and cyclical replication and just talk about topologies</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
      <file type="M">hbase-server.src.main.javadoc.org.apache.hadoop.hbase.replication.package.html</file>
    </fixedFiles>
  </bug>
  <bug id="12678" opendate="2014-12-12 00:00:00" fixdate="2014-12-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBCK should print command line arguments</summary>
      <description>While looking at the output from an HBCK run, I've noticed that it does not list the arguments it is running with. We should add it.</description>
      <version>None</version>
      <fixedVersion>1.0.0,0.98.9</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.hbck.OfflineMetaRepair.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="12681" opendate="2014-12-13 00:00:00" fixdate="2014-12-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>truncate_preserve command fails with undefined method `getTable&amp;#39; error</summary>
      <description>hbase(main):002:0&gt; truncate_preserve 'a'Truncating 'a' table (it may take a while):ERROR: undefined method `getTable' for nil:NilClassHere is some help for this command: Disables, drops and recreates the specified table while still maintaing the previous region boundaries.</description>
      <version>0.99.2,2.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug id="12683" opendate="2014-12-14 00:00:00" fixdate="2014-12-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compilation with hadoop-2.7.0-SNAPSHOT is broken</summary>
      <description>HADOOP-11389 changed ReflectionUtils.printThreadInfo() signature, which breaks compilation.</description>
      <version>None</version>
      <fixedVersion>1.0.0,0.98.9</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.JVMClusterUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSDumpServlet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterDumpServlet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.HttpServer.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Threads.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="12687" opendate="2014-12-15 00:00:00" fixdate="2014-12-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Book is missing styling</summary>
      <description>The online book is intended to be styled, there's a file freebsd_docbook.css. It's not being applied; fix that.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="12693" opendate="2014-12-15 00:00:00" fixdate="2014-12-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[docs] nit fix in HBase and MapReduce section</summary>
      <description>trivial nit fix</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="12695" opendate="2014-12-16 00:00:00" fixdate="2014-12-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>JDK 1.8 compilation broken</summary>
      <description>Looks like trunk only.https://code.google.com/p/error-prone/issues/detail?id=240https://code.google.com/p/error-prone/issues/detail?id=246</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-thrift.pom.xml</file>
      <file type="M">hbase-shell.pom.xml</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-prefix-tree.pom.xml</file>
      <file type="M">hbase-it.pom.xml</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-hadoop-compat.pom.xml</file>
      <file type="M">hbase-examples.pom.xml</file>
      <file type="M">hbase-common.pom.xml</file>
      <file type="M">hbase-client.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="12701" opendate="2014-12-17 00:00:00" fixdate="2014-2-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document how to set the split policy on a given table</summary>
      <description>Need to document in the ref guide how to set/change the region split policy for a single table user the API and the HBase shell as noted below as an example.Using Java:HTableDescriptor tableDesc = new HTableDescriptor("test");tableDesc.setValue(HTableDescriptor.SPLIT_POLICY, ConstantSizeRegionSplitPolicy.class.getName());tableDesc.addFamily(new HColumnDescriptor(Bytes.toBytes("cf1")));admin.createTable(tableDesc);Using HBase Shell:create 'test', {METHOD =&gt; 'table_att', CONFIG =&gt; {'SPLIT_POLICY' =&gt; 'org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy'}},{NAME =&gt; 'cf1'}</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="12708" opendate="2014-12-18 00:00:00" fixdate="2014-1-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document newly introduced params for using Thrift-over-HTTPS.</summary>
      <description>Per the description.</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.security.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="12709" opendate="2014-12-18 00:00:00" fixdate="2014-12-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[mvn] Add unit test excludes command line flag to the build.</summary>
      <description>I've added a simple way to specify unit test classes to skip when executing unit test runs. I've added a -D variable called test.exclude.pattern that you can using like this:mvn test -Dtest.exclude.pattern=**/TestFoo.java,**/TestBar.javato exclude the unit tests form TestFoo and TestBar in this run. By default there is nothing excluded.</description>
      <version>1.0.0,0.98.10,2.0.0</version>
      <fixedVersion>1.0.0,hbase-11339,0.98.10,1.1.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1271" opendate="2009-3-20 00:00:00" fixdate="2009-4-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow multiple tests to run on one machine</summary>
      <description>Currently, if we try to run two tests on one machine (e.g. in two checkouts) the second one will fail because its servers won't be able to bind to ports. We should use random ports in our servers in the tests to fix this.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.MiniZooKeeperCluster.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.MiniHBaseCluster.java</file>
      <file type="M">src.test.hbase-site.xml</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HServerInfo.java</file>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12711" opendate="2014-12-18 00:00:00" fixdate="2014-12-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix new findbugs warnings in hbase-thrift module</summary>
      <description>From https://builds.apache.org/job/PreCommit-HBASE-Build/12121/artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html , there were 5 findbugs warnings introduced.This issue fixes the new warnings.</description>
      <version>None</version>
      <fixedVersion>1.0.0,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftHttpServlet.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="12716" opendate="2014-12-18 00:00:00" fixdate="2014-12-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>A bug in RegionSplitter.UniformSplit algorithm</summary>
      <description>Welcome to the review board: https://reviews.apache.org/r/29424/diff/#I`m working for another issues HBASE-12590 and trying to use the UniformSplit algorithm in RegionSplitter. When the last bytes of start key and end key are adjacent in alphabetical order or ASCII order, the UniformSplit algorithm meet an NPE.Like startkey: aaa, endkey :aab startkey:1111 endkey: 1112For example, we write this simple test code:import org.apache.hadoop.hbase.util.RegionSplitter.UniformSplit;......byte[] a1 = { 'a', 'a', 'a' };byte[] a2 = { 'a', 'a', 'b' };UniformSplit us = new UniformSplit();byte[] mid = us.split(a1, a2);......We will get the ERROR:Exception in thread "main" java.lang.NullPointerException at org.apache.hadoop.hbase.util.RegionSplitter$UniformSplit.split(RegionSplitter.java:986)We hope this algorithm should be able to calculate the split point with an additional byte. for example:"aaa" and "aab", split point= "aaaP""1111" and "1112", split point ="1111P" review board:https://reviews.apache.org/r/29424/</description>
      <version>0.98.6,2.0.0</version>
      <fixedVersion>1.0.0,0.98.10,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestRegionSplitter.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestBytes.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Bytes.java</file>
    </fixedFiles>
  </bug>
  <bug id="1272" opendate="2009-3-20 00:00:00" fixdate="2009-5-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unreadable log messages -- "... to the only server localhost_1237525439599_56094" &lt;- You&amp;#39;d have to be perverse to recognize that as a hostname, startcode, and port number.</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.HServerInfo.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12735" opendate="2014-12-20 00:00:00" fixdate="2014-12-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Refactor TAG so it can live as unit test and as an integration test</summary>
      <description>Parent task moved TAG to IT wholesale. This is about keeping a bit of ACID coverage going in UT. Jon offered to refactor TAG so can live in IT and UT.</description>
      <version>None</version>
      <fixedVersion>1.0.0,1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestAcidGuarantees.java</file>
    </fixedFiles>
  </bug>
  <bug id="12738" opendate="2014-12-22 00:00:00" fixdate="2014-12-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Chunk Ref Guide into file-per-chapter</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.upgrading.xml</file>
      <file type="M">src.main.docbkx.performance.xml</file>
      <file type="M">src.main.docbkx.book.xml</file>
      <file type="M">src.main.docbkx.hbase-default.xml</file>
      <file type="M">src.main.docbkx.configuration.xml</file>
    </fixedFiles>
  </bug>
  <bug id="12751" opendate="2014-12-23 00:00:00" fixdate="2014-11-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow RowLock to be reader writer</summary>
      <description>Right now every write operation grabs a row lock. This is to prevent values from changing during a read modify write operation (increment or check and put). However it limits parallelism in several different scenarios.If there are several puts to the same row but different columns or stores then this is very limiting.If there are puts to the same column then mvcc number should ensure a consistent ordering. So locking is not needed.However locking for check and put or increment is still needed.</description>
      <version>1.3.0,2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.FaultyFSLog.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.WALPerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestWALReaderOnSecureWAL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestWALFactory.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestSecureWAL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestDefaultWALProviderWithHLogKey.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestDefaultWALProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.NamespacesInstanceModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.NamespacesModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSWALEntry.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogKey.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.ReplayHLogKey.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALEdit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HashedBytes.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.DisabledWALProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WAL.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALKey.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALSplitter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestReplicasClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverStacking.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestWALObserver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestHLogRecordReader.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestWALRecordReader.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestServerCrashProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestSplitLogManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestAtomicOperation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestBulkLoad.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDefaultMemStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionReplayEvents.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestKeepDeletes.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMultiVersionConcurrencyControl.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMultiVersionConcurrencyControlBasic.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestPerColumnFamilyFlush.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionReplicaFailover.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreFileRefresherChore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestWALLockup.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestFSHLog.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRollAbort.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRollingNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALActionsListener.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationWALReaderManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithDistributedLogReplay.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestFullLogReconstruction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestIOFencing.java</file>
    </fixedFiles>
  </bug>
  <bug id="12768" opendate="2014-12-29 00:00:00" fixdate="2014-1-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support enable cache_data_on_write in Shell while creating table</summary>
      <description>A simple approach to support cache_data_on_write while creating table in shell.</description>
      <version>1.0.0,0.94.27,2.0.0</version>
      <fixedVersion>1.0.0,0.98.10,1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug id="12770" opendate="2014-12-29 00:00:00" fixdate="2014-8-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Don&amp;#39;t transfer all the queued hlogs of a dead server to the same alive server</summary>
      <description>When a region server is down(or the cluster restart), all the hlog queues will be transferred by the same alive region server. In a shared cluster, we might create several peers replicating data to different peer clusters. There might be lots of hlogs queued for these peers caused by several reasons, such as some peers might be disabled, or errors from peer cluster might prevent the replication, or the replication sources may fail to read some hlog because of hdfs problem. Then, if the server is down or restarted, another alive server will take all the replication jobs of the dead server, this might bring a big pressure to resources(network/disk read) of the alive server and also is not fast enough to replicate the queued hlogs. And if the alive server is down, all the replication jobs including that takes from other dead servers will once again be totally transferred to another alive server, this might cause a server have a large number of queued hlogs(in our shared cluster, we find one server might have thousands of queued hlogs for replication). As an optional way, is it reasonable that the alive server only transfer one peer's hlogs from the dead server one time? Then, other alive region servers might have the opportunity to transfer the hlogs of rest peers. This may also help the queued hlogs be processed more fast. Any discussion is welcome.</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,1.3.1,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationStateHBaseImpl.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationStateBasic.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManagerZkImpl.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.TableBasedReplicationQueuesImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueuesZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueues.java</file>
    </fixedFiles>
  </bug>
  <bug id="12785" opendate="2014-12-30 00:00:00" fixdate="2014-1-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use FutureTask to timeout the attempt to get the lock for hbck</summary>
      <description>In reviewing HBASE-12607, Sean pointed out:It would be nice if we used a FutureTask to timeout the attempt to get the lock rather than wait the whole period and then fail.This issue is to address Sean's review comment.</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="12802" opendate="2015-1-4 00:00:00" fixdate="2015-1-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove unnecessary Table.flushCommits()</summary>
      <description>It looks like there are a lot of places where flushCommits() are called on tables that do not have autoFlush turned on. That might be a legacy concern from pre-autoFlush days. HBASE-12728 will likely result in removing the flushCommits() method from Table. The patch for this issue should remove all unnecessary calls to flushCommit() to prepare for the full fix.flushCommits() are only necessary after a setAutoFlushTo(false) is called. Here's the relevant code from HTable.java:HTable.java @Override public void put(final Put put) throws InterruptedIOException, RetriesExhaustedWithDetailsException { doPut(put); if (autoFlush) { flushCommits(); } } /** * {@inheritDoc} */ @Override public void put(final List&lt;Put&gt; puts) throws InterruptedIOException, RetriesExhaustedWithDetailsException { for (Put put : puts) { doPut(put); } if (autoFlush) { flushCommits(); } }Puts have implicit flushCommits() calls when autoFlush is true. Deletes are not affected by autoFlush() and are not directly impacted by flushCommits() since deletes are not added to the writeAysncBuffer.</description>
      <version>1.0.0,2.0.0</version>
      <fixedVersion>1.0.0,1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestWALFiltering.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.OfflineMetaRebuildTestCore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithDeletes.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabels.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationSmallTests.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerMetrics.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestEndToEndSplitTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompactionState.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTimeRangeMapRed.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestImportExport.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestPrefixTree.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestChangingEncoding.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverScannerOpenHook.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestOpenTableInCoprocessor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotCloneIndependence.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide3.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFastFail.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.TestScannersWithLabels.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.TestScannerResource.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.mttr.IntegrationTestMTTR.java</file>
    </fixedFiles>
  </bug>
  <bug id="12831" opendate="2015-1-9 00:00:00" fixdate="2015-1-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Changing the set of vis labels a user has access to doesn&amp;#39;t generate an audit log event</summary>
      <description>Right now, the AccessController makes sure that (when users care about audit events) we generate an audit log event for any access change, like granting or removing a permission from a user.When the set of labels a user has access to is altered, it gets handled by the VisibilityLabelService and we don't log anything to the audit log.</description>
      <version>1.0.0,0.98.6,2.0.0</version>
      <fixedVersion>1.0.0,0.98.10,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityController.java</file>
      <file type="M">conf.log4j.properties</file>
    </fixedFiles>
  </bug>
  <bug id="1284" opendate="2009-3-23 00:00:00" fixdate="2009-3-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>drop table drops all disabled tables</summary>
      <description>To reproduce in the shell:create 'A'create 'B'disable 'A'disable 'B'drop 'B'enable 'A' -&gt; exception table 'A' not found</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.master.TableDelete.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12848" opendate="2015-1-13 00:00:00" fixdate="2015-1-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Utilize Flash storage for WAL</summary>
      <description>One way to improve data ingestion rate is to make use of Flash storage.HDFS is doing the heavy lifting - see HDFS-7228.We assume an environment where:1. Some servers have a mix of flash, e.g. 2 flash drives and 4 traditional drives.2. Some servers have all traditional storage.3. RegionServers are deployed on both profiles within one HBase cluster.This JIRA allows WAL to be managed on flash in a mixed-profile environment.</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="1285" opendate="2009-3-24 00:00:00" fixdate="2009-3-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Forcing compactions should be available via thrift.</summary>
      <description>It would be useful to be able to trigger compactions via thrift just as we can with the ruby shell.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12891" opendate="2015-1-21 00:00:00" fixdate="2015-4-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Parallel execution for Hbck checkRegionConsistency</summary>
      <description>We have a lot of regions on our cluster ~500k and noticed that hbck took quite some time in checkAndFixConsistency(). davelatham patched our cluster to do this check in parallel to speed things up. I'll attach the patch.</description>
      <version>0.98.10,1.1.0,2.0.0</version>
      <fixedVersion>1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="12892" opendate="2015-1-21 00:00:00" fixdate="2015-1-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a class to allow taking a snapshot from the command line</summary>
      <description>It's easier to automate taking a snapshot from the command line than from the hbase shell. We should provide a command that can be called to snapshot a table.</description>
      <version>2.0.0</version>
      <fixedVersion>1.0.0,0.98.10,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug id="12897" opendate="2015-1-21 00:00:00" fixdate="2015-2-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Minimum memstore size is a percentage</summary>
      <description>We have a cluster which is optimized for random reads. Thus we have a large block cache and a small memstore. Currently our heap is 20GB and we wanted to configure the memstore to take 4% or 800MB. Right now the minimum memstore size is 5%. What do you guys think about reducing the minimum size to 1%? Suppose we log a warning if the memstore is below 5% but allow it?What do you folks think?</description>
      <version>0.98.10,1.1.0,2.0.0</version>
      <fixedVersion>1.0.0,1.1.0,0.98.11</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.util.HeapMemorySizeUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="12916" opendate="2015-1-26 00:00:00" fixdate="2015-1-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>No access control for replicating WAL entries</summary>
      <description>Currently, there is no access control for replicating WAL entries in secure HBase cluster. Any authenticated user can write any data they want to any table of a secure cluster by using the replication api.Simple solution is to add permission check before replicating WAL entries. And only user with global write permission can replicate WAL entries to this cluster.Another option is adding "Replication" action in hbase and only user with "Replication" permission can replicate WAL entries to this cluster?apurtell What's your suggestion? Thanks</description>
      <version>0.94.26,0.98.12,2.0.0</version>
      <fixedVersion>1.0.0,0.98.10,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionServerObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseRegionServerObserver.java</file>
    </fixedFiles>
  </bug>
  <bug id="12961" opendate="2015-2-3 00:00:00" fixdate="2015-2-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Negative values in read and write region server metrics</summary>
      <description>HMaster web page ui, shows the read/write request per region server. They are currently displayed by using 32 bit integers. Hence, if the servers are up for a long time the values can be shown as negative.</description>
      <version>2.0.0</version>
      <fixedVersion>1.1.0,0.98.11,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestServerLoad.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ServerLoad.java</file>
    </fixedFiles>
  </bug>
  <bug id="12985" opendate="2015-2-7 00:00:00" fixdate="2015-2-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Javadoc warning and findbugs fixes to get us green again</summary>
      <description>A few findbugs fixes to get us under our findbugs warning number again and a javadoc warning fix.</description>
      <version>2.0.0</version>
      <fixedVersion>1.0.0,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.SplitLogCounters.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.ZKSecretWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALCellCodec.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.flush.FlushTableSubprocedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ClientSideRegionScanner.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.thrift.HttpDoAsClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="12987" opendate="2015-2-8 00:00:00" fixdate="2015-4-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBCK should print status while scanning over many regions</summary>
      <description>Running simple commands like hbck -summary on a large table can take some time. We should print some information to let it be known how things are progressing.</description>
      <version>None</version>
      <fixedVersion>1.1.0,0.98.13,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="12988" opendate="2015-2-9 00:00:00" fixdate="2015-9-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[Replication]Parallel apply edits across regions</summary>
      <description>we can apply edits to slave cluster in parallel on table-level to speed up replication .update : per conversation blow , it's better to apply edits on row-level in parallel</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="12991" opendate="2015-2-9 00:00:00" fixdate="2015-2-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use HBase 1.0 interfaces in hbase-rest</summary>
      <description>hbase-rest uses HTable and HBaseAdmin under the covers. They should use the new hbase 1.0 interfaces instead.</description>
      <version>None</version>
      <fixedVersion>1.0.0,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.TestTableResource.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.TestStatusResource.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.TestScannersWithFilters.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.TestGzipFilter.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.RowResourceBase.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.TableResource.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.SchemaResource.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.RESTServlet.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="12999" opendate="2015-2-10 00:00:00" fixdate="2015-2-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make foreground_start return the correct exit code</summary>
      <description></description>
      <version>1.1.0,0.98.11,2.0.0</version>
      <fixedVersion>1.1.0,0.98.11,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase-daemon.sh</file>
    </fixedFiles>
  </bug>
  <bug id="13002" opendate="2015-2-10 00:00:00" fixdate="2015-2-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make encryption cipher configurable</summary>
      <description>Make encryption cipher configurable currently it is hard coded to AES, so that user can configure his/her own algorithm.</description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,0.98.11,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsckEncryption.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestEncryptionTest.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestEncryptionRandomKeying.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestEncryptionKeyRotation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileEncryption.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.io.crypto.TestEncryption.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.io.crypto.TestCipherProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.Encryption.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.security.TestEncryptionUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.EncryptionUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="13006" opendate="2015-2-10 00:00:00" fixdate="2015-3-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document visibility label support for groups</summary>
      <description>This is to document the changes added from HBASE-12745.</description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.security.adoc</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.set.auths.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.get.auths.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.clear.auths.rb</file>
    </fixedFiles>
  </bug>
  <bug id="13014" opendate="2015-2-11 00:00:00" fixdate="2015-11-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Java Tool For Region Moving</summary>
      <description>As per discussion on HBASE-12989 we should move the functionality of region_mover.rb into a Java tool and use region_mover.rb only only as a wrapper around it.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestRegionMover.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionMover.java</file>
    </fixedFiles>
  </bug>
  <bug id="13016" opendate="2015-2-11 00:00:00" fixdate="2015-2-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up remnants of table states stored in table descriptors</summary>
      <description>We didn't released 2.0 version with states in table descriptors, so we don't need to keep things compatible with lower versions. Hence it will be much better to remove state from descriptors entirely and support only migration zk &lt;-&gt; meta storage introduced in HBASE-12035.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestTableDescriptor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.TableDescriptor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableStateManager.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.HBase.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.TableState.java</file>
    </fixedFiles>
  </bug>
  <bug id="13026" opendate="2015-2-12 00:00:00" fixdate="2015-2-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Wrong error message in case incorrect snapshot name OR Incorrect table name</summary>
      <description>hbase(main):009:0&gt; snapshot 't1', '.t1Snapshot'ERROR: Illegal first character &lt;46&gt; at 0. Namespaces can only start with alphanumeric characters': i.e. &amp;#91;a-zA-Z_0-9&amp;#93;: t1Snapshothbase(main):008:0&gt; create '-test' , 'cf1'ERROR: Illegal first character &lt;45&gt; at 0.Namespaces can only start with alphanumeric characters': i.e. &amp;#91;a-zA-Z_0-9&amp;#93;: -test&gt;&gt; As per message "Namespaces" is wrong. But in this scenario, snapshot / table name start character is wrong.Its because in the code the message is as belowif (qualifierName[start] == '.' || qualifierName[start] == '-') { throw new IllegalArgumentException("Illegal first character &lt;" + qualifierName[0] + "&gt; at 0. Namespaces can only start with alphanumeric " + "characters': i.e. [a-zA-Z_0-9]: " + Bytes.toString(qualifierName));The correct code should be as belowif (qualifierName[start] == '.' || qualifierName[start] == '-') { throw new IllegalArgumentException("Illegal first character &lt;" + qualifierName[start] + "&gt; at 0. " + (isSnapshot ? "Snapshot" : "User-space table") + " qualifiers can only start with 'alphanumeric " + "characters': i.e. [a-zA-Z_0-9]: " + Bytes.toString(qualifierName, start, end));</description>
      <version>2.0.0</version>
      <fixedVersion>1.0.0,0.98.11</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.TableName.java</file>
    </fixedFiles>
  </bug>
  <bug id="13044" opendate="2015-2-13 00:00:00" fixdate="2015-2-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Configuration option for disabling coprocessor loading</summary>
      <description>Some users would like complete assurance coprocessors cannot be loaded. Add a configuration option that prevents coprocessors from ever being loaded by ignoring any load directives found in the site file or table metadata.</description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,0.98.11,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorHost.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="13062" opendate="2015-2-18 00:00:00" fixdate="2015-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add documentation coverage for configuring dns server with thrift and rest gateways</summary>
      <description>Currently, the documentation doesn't cover about configuring DNS with thrift or rest gateways, though code base does provide provision for doing so. The following parameters are being used for accomplishing the same.For REST: hbase.rest.dns.interface hbase.rest.dns.nameserverFor Thrift: hbase.thrift.dns.interface hbase.thrift.dns.nameserver</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.security.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="13063" opendate="2015-2-18 00:00:00" fixdate="2015-3-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow to turn off memstore replication for region replicas</summary>
      <description>HBASE-11568 allows to use replication to send wal edits from the primary to the replicas.sometimes the memstore replication is not required, so it will be nice have a flag to disable it.the result will be more or less the same to what we have in phase-1, but with the row-level consistency provided by the "flush" edit transfered via replication to refresh the hfiles.create 't1', 'f', {REGION_REPLICATION =&gt; 2, REGION_MEMSTORE_REPLICATION =&gt; false}</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestRegionReplicaReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.ReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALEdit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ServerRegionReplicaUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionReplicaUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="13065" opendate="2015-2-18 00:00:00" fixdate="2015-2-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Increasing -Xmx when running TestDistributedLogSplitting</summary>
      <description>Found this in PreCommit Build reportshttps://builds.apache.org/job/PreCommit-HBASE-Build/12885/artifact/hbase-server/target/surefire-reports/org.apache.hadoop.hbase.master.TestDistributedLogSplitting-output.txt2015-02-18 03:45:42,141 WARN [RS:4;asf901:41265] util.Sleeper(97): We slept 59018ms instead of 1000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired2015-02-18 03:45:26,750 WARN [JvmPauseMonitor] util.JvmPauseMonitor$Monitor(167): Detected pause in JVM or host machine (eg GC): pause of approximately 39767msGC pool 'PS MarkSweep' had collection(s): count=65 time=47720msMaybe we should increase the max heap size since this test starts 6 regionservers.</description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,0.98.11,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="13067" opendate="2015-2-18 00:00:00" fixdate="2015-2-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix caching of stubs to allow IP address changes of restarted remote servers</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="13074" opendate="2015-2-19 00:00:00" fixdate="2015-5-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cleaned up usage of hbase.master.lease.thread.wakefrequency</summary>
      <description>While checking for configs to tweak, I ran into hbase.master.lease.thread.wakefrequency, but it has been deprecated. There are however still references of it in a few tests classes so just cleaning it up..</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.test.resources.hbase-site.xml</file>
      <file type="M">hbase-spark.src.test.resources.hbase-site.xml</file>
      <file type="M">hbase-server.src.test.resources.hbase-site2.xml</file>
      <file type="M">hbase-server.src.test.resources.hbase-site.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorInterface.java</file>
      <file type="M">hbase-rest.src.test.resources.hbase-site.xml</file>
    </fixedFiles>
  </bug>
  <bug id="13081" opendate="2015-2-20 00:00:00" fixdate="2015-2-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Branch precommit builds are not updating to branch head before patch application</summary>
      <description>See for example https://builds.apache.org/job/PreCommit-HBASE-Build/12922//consolegit checkout 0.98Previous HEAD position was 03d8918... HBASE-13069 Thrift Http Server returns an error code of 500 instead of 401 when authentication fails (Srikanth Srungarapu)Switched to branch '0.98'Your branch is behind 'origin/0.98' by 48 commits, and can be fast-forwarded. (use "git pull" to update your local branch)git statusOn branch 0.98Your branch is behind 'origin/0.98' by 48 commits, and can be fast-forwarded. (use "git pull" to update your local branch)Untracked files: (use "git add &lt;file&gt;..." to include in what will be committed) patchprocess/nothing added to commit but untracked files present (use "git add" to track)Because the local tree is 48 commits behind the head of the 0.98 branch, the contributor's patch based on the head of 0.98 branch cannot cleanly apply.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  <bug id="13085" opendate="2015-2-23 00:00:00" fixdate="2015-2-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Security issue in the implementation of Rest gataway &amp;#39;doAs&amp;#39; proxy user support</summary>
      <description>When 'hbase.rest.support.proxyuser' is turned on, HBase Rest gateway support 'doAs' proxy user from the Rest client.The current implementation checks to see if the 'rest server user' is authorized to impersonate the 'doAs' user (the user in the 'doAs' Rest query string).if (doAsUserFromQuery != null) { Configuration conf = servlet.getConfiguration(); if (!servlet.supportsProxyuser()) { throw new ServletException("Support for proxyuser is not configured"); } UserGroupInformation ugi = servlet.getRealUser(); // create and attempt to authorize a proxy user (the client is attempting // to do proxy user) ugi = UserGroupInformation.createProxyUser(doAsUserFromQuery, ugi); // validate the proxy user authorization try { ProxyUsers.authorize(ugi, request.getRemoteAddr(), conf); } catch(AuthorizationException e) { throw new ServletException(e.getMessage()); } servlet.setEffectiveUser(doAsUserFromQuery); } The current implementation allows anyone from the rest client side to impersonate another user by 'doAs'. For example, potentially, 'user1' can 'doAs=admin'The correct implementation should check to see if the rest client user is authorized to do impersonation.</description>
      <version>1.0.0,0.98.10,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.11,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.RESTServletContainer.java</file>
    </fixedFiles>
  </bug>
  <bug id="13086" opendate="2015-2-23 00:00:00" fixdate="2015-2-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Show ZK root node on Master WebUI</summary>
      <description>Currently we show a well-formed ZK quorum on the master webUI but not the root node. Root node can be changed based on deployment, so we should list it here explicitly. This information is helpful for folks playing around with phoenix.</description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,0.98.11,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
    </fixedFiles>
  </bug>
  <bug id="13093" opendate="2015-2-25 00:00:00" fixdate="2015-3-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Local mode HBase instance doesn&amp;#39;t shut down.</summary>
      <description>bin/start-hbase.shbin/stop-hbase.shThat hangs forever. Here's the jstacks:2015-02-24 16:37:55Full thread dump Java HotSpot(TM) 64-Bit Server VM (24.60-b09 mixed mode):"Attach Listener" daemon prio=5 tid=0x00007fb130813800 nid=0xfd07 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE"DestroyJavaVM" prio=5 tid=0x00007fb12ba7c800 nid=0x1303 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE"pool-5-thread-1" prio=5 tid=0x00007fb12bb88800 nid=0x19903 waiting on condition [0x0000000121a1b000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at io.netty.util.HashedWheelTimer$Worker.waitForNextTick(HashedWheelTimer.java:461) at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:360) at java.lang.Thread.run(Thread.java:745)"HBase-Metrics2-1" daemon prio=5 tid=0x00007fb12c040000 nid=0x19703 waiting on condition [0x0000000121918000] java.lang.Thread.State: TIMED_WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x0000000724cc9780&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082) at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1090) at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:807) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745)"snapshot-hfile-cleaner-cache-refresher" daemon prio=5 tid=0x00007fb12bc91000 nid=0x18703 in Object.wait() [0x000000012160f000] java.lang.Thread.State: TIMED_WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x0000000724caa588&gt; (a java.util.TaskQueue) at java.util.TimerThread.mainLoop(Timer.java:552) - locked &lt;0x0000000724caa588&gt; (a java.util.TaskQueue) at java.util.TimerThread.run(Timer.java:505)"snapshot-log-cleaner-cache-refresher" daemon prio=5 tid=0x00007fb12bbc8000 nid=0x18503 in Object.wait() [0x000000012150c000] java.lang.Thread.State: TIMED_WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x0000000724deb178&gt; (a java.util.TaskQueue) at java.util.TimerThread.mainLoop(Timer.java:552) - locked &lt;0x0000000724deb178&gt; (a java.util.TaskQueue) at java.util.TimerThread.run(Timer.java:505)"localhost:57343.activeMasterManager-EventThread" daemon prio=5 tid=0x00007fb12c072000 nid=0x18303 waiting on condition [0x0000000121409000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x0000000724f10150&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:494)"localhost:57343.activeMasterManager-SendThread(fe80:0:0:0:0:0:0:1%1:2181)" daemon prio=5 tid=0x00007fb12c053000 nid=0x18103 waiting on condition [0x0000000121306000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:101) at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:940) at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1003)"Timer for 'HBase' metrics system" daemon prio=5 tid=0x00007fb12de54800 nid=0x7903 in Object.wait() [0x00000001187df000] java.lang.Thread.State: TIMED_WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x0000000724b4f150&gt; (a java.util.TaskQueue) at java.util.TimerThread.mainLoop(Timer.java:552) - locked &lt;0x0000000724b4f150&gt; (a java.util.TaskQueue) at java.util.TimerThread.run(Timer.java:505)"Service Thread" daemon prio=5 tid=0x00007fb12e002000 nid=0x5503 runnable [0x0000000000000000] java.lang.Thread.State: RUNNABLE"C2 CompilerThread1" daemon prio=5 tid=0x00007fb12d92e000 nid=0x5303 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE"C2 CompilerThread0" daemon prio=5 tid=0x00007fb12b832800 nid=0x5103 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE"Signal Dispatcher" daemon prio=5 tid=0x00007fb12b80f800 nid=0x4f03 runnable [0x0000000000000000] java.lang.Thread.State: RUNNABLE"Surrogate Locker Thread (Concurrent GC)" daemon prio=5 tid=0x00007fb12d90c000 nid=0x400b waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE"Finalizer" daemon prio=5 tid=0x00007fb12b824800 nid=0x3b03 in Object.wait() [0x00000001145b9000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x00000007247cf250&gt; (a java.lang.ref.ReferenceQueue$Lock) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:135) - locked &lt;0x00000007247cf250&gt; (a java.lang.ref.ReferenceQueue$Lock) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:151) at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:209)"Reference Handler" daemon prio=5 tid=0x00007fb12d902800 nid=0x3903 in Object.wait() [0x00000001144b6000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x00000007247c43a0&gt; (a java.lang.ref.Reference$Lock) at java.lang.Object.wait(Object.java:503) at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:133) - locked &lt;0x00000007247c43a0&gt; (a java.lang.ref.Reference$Lock)"VM Thread" prio=5 tid=0x00007fb12b824000 nid=0x3703 runnable "Gang worker#0 (Parallel GC Threads)" prio=5 tid=0x00007fb12d801000 nid=0x2103 runnable "Gang worker#1 (Parallel GC Threads)" prio=5 tid=0x00007fb12d80d800 nid=0x2303 runnable "Gang worker#2 (Parallel GC Threads)" prio=5 tid=0x00007fb12d80e000 nid=0x2503 runnable "Gang worker#3 (Parallel GC Threads)" prio=5 tid=0x00007fb12d80e800 nid=0x2703 runnable "Gang worker#4 (Parallel GC Threads)" prio=5 tid=0x00007fb12d80f800 nid=0x2903 runnable "Gang worker#5 (Parallel GC Threads)" prio=5 tid=0x00007fb12d810000 nid=0x2b03 runnable "Gang worker#6 (Parallel GC Threads)" prio=5 tid=0x00007fb12d810800 nid=0x2d03 runnable "Gang worker#7 (Parallel GC Threads)" prio=5 tid=0x00007fb12d811000 nid=0x2f03 runnable "Concurrent Mark-Sweep GC Thread" prio=5 tid=0x00007fb12d8d3800 nid=0x3503 runnable "Gang worker#0 (Parallel CMS Threads)" prio=5 tid=0x00007fb12d8d2800 nid=0x3103 runnable "Gang worker#1 (Parallel CMS Threads)" prio=5 tid=0x00007fb12d8d3000 nid=0x3303 runnable "VM Periodic Task Thread" prio=5 tid=0x00007fb12d92d800 nid=0x5703 waiting on condition JNI global references: 177</description>
      <version>2.0.0</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.AsyncRpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.AsyncRpcChannel.java</file>
    </fixedFiles>
  </bug>
  <bug id="13109" opendate="2015-2-26 00:00:00" fixdate="2015-3-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make better SEEK vs SKIP decisions during scanning</summary>
      <description>I'm re-purposing this issue to add a heuristic as to when to SEEK and when to SKIP Cells. This has come up in various issues, and I think I have a way to finally fix this now. HBASE-9778, HBASE-12311, and friends are related.&amp;#8212; Old description &amp;#8212;This is a continuation of HBASE-9778.We've seen a scenario of a very slow scan over a region using a timerange that happens to fall after the ts of any Cell in the region.Turns out we spend a lot of time seeking.Tested with a 5 column table, and the scan is 5x faster when the timerange falls before all Cells' ts.We can use the lookahead hint introduced in HBASE-9778 to do opportunistic SKIPing before we actually seek.</description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestQueryMatcher.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestExplicitColumnTracker.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestBlocksRead.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.NonLazyKeyValueScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.KeyValueScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.KeyValueHeap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderV2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.BlockWithScanInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.HalfStoreFileReader.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ExplicitColumnTracker.java</file>
    </fixedFiles>
  </bug>
  <bug id="13111" opendate="2015-2-26 00:00:00" fixdate="2015-2-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>truncate_preserve command is failing with undefined method error</summary>
      <description>hbase(main):001:0&gt; truncate_preserve 't1'Truncating 't1' table (it may take a while):ERROR: undefined method `getTable' for nil:NilClassHere is some help for this command: Disables, drops and recreates the specified table while still maintaing the previous region boundaries.</description>
      <version>1.0.0,1.1.0,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.11,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug id="13115" opendate="2015-2-26 00:00:00" fixdate="2015-3-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix the usage of remote user in thrift doAs implementation.</summary>
      <description>This issue is similar to HBASE-13085 fixed in REST gateway recently. This change factors in the usage of remote user. Besides this, I also added the following changes. Adding response headers to strictly adhere to RFC specifcations. Made changes to demo client to get rid of hard codings.</description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftHttpServlet.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.thrift.HttpDoAsClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="13123" opendate="2015-2-27 00:00:00" fixdate="2015-3-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Minor bug in ROW bloom filter</summary>
      <description>While checking the code for Bloom filter found that while checking if a key passes the ROW bloom check we try to create a bloom key. The bloom key should be constructed only with the row part of the key. But try to form the bloom key including the meta data part of the key.</description>
      <version>1.0.0,1.1.0,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.11,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
    </fixedFiles>
  </bug>
  <bug id="13127" opendate="2015-2-27 00:00:00" fixdate="2015-8-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add timeouts on all tests so less zombie sightings</summary>
      <description>Apache9 and octo47 have been working hard at trying to get our builds passing again. They are almost there. TRUNK just failed with a zombie TestMasterObserver. Help the lads out by adding timeouts on all tests so less zombie incidence... will help identify the frequent failing issues.</description>
      <version>None</version>
      <fixedVersion>1.0.2,1.2.0,1.3.0,1.1.3,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
    </fixedFiles>
  </bug>
  <bug id="13128" opendate="2015-2-27 00:00:00" fixdate="2015-3-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make HBCK&amp;#39;s lock file retry creation and deletion</summary>
      <description>When hbck runs it creates a lock file to ensure that no two hbck instances are running. We've been seeing creating and removing that file fail sometimes.This improvement should make the creation, closing of the file, and the deletion retry multiple times. This should allow our alerting which uses this command to be more reliable and have fewer false positives.</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="13132" opendate="2015-3-1 00:00:00" fixdate="2015-3-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve RemoveColumn action debug message</summary>
      <description>Trivial fix for this unsightly log message:2015-02-22 14:04:46,357 DEBUG [TwoConcurrentAction-1-thread-2] actions.Action: Performing action: Removing [B@64275127 from TestAcidGuarantees</description>
      <version>2.0.0</version>
      <fixedVersion>hbase-11339,1.0.1,1.1.0,0.98.13,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.RemoveColumnAction.java</file>
    </fixedFiles>
  </bug>
  <bug id="13135" opendate="2015-3-2 00:00:00" fixdate="2015-3-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move replication ops mgmt stuff from Javadoc to Ref Guide</summary>
      <description>As per discussion with jmhsieh and saint.ack@gmail.com</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
      <file type="M">hbase-server.src.main.javadoc.org.apache.hadoop.hbase.replication.package.html</file>
    </fixedFiles>
  </bug>
  <bug id="13149" opendate="2015-3-3 00:00:00" fixdate="2015-4-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase MR is broken on Hadoop 2.5+ Yarn</summary>
      <description>Running the server MR tools is not working on Yarn version 2.5+.Running org.apache.hadoop.hbase.mapreduce.Export:Exception in thread "main" java.lang.NoSuchMethodError: org.codehaus.jackson.map.ObjectMapper.setSerializationInclusion(Lorg/codehaus/jackson/map/annotate/JsonSerialize$Inclusion;)Lorg/codehaus/jackson/map/ObjectMapper; at org.apache.hadoop.yarn.webapp.YarnJacksonJaxbJsonProvider.configObjectMapper(YarnJacksonJaxbJsonProvider.java:59) at org.apache.hadoop.yarn.util.timeline.TimelineUtils.&lt;clinit&gt;(TimelineUtils.java:47) at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.serviceInit(YarnClientImpl.java:166) at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163) at org.apache.hadoop.mapred.ResourceMgrDelegate.serviceInit(ResourceMgrDelegate.java:102) at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163) at org.apache.hadoop.mapred.ResourceMgrDelegate.&lt;init&gt;(ResourceMgrDelegate.java:96) at org.apache.hadoop.mapred.YARNRunner.&lt;init&gt;(YARNRunner.java:112) at org.apache.hadoop.mapred.YarnClientProtocolProvider.create(YarnClientProtocolProvider.java:34) at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:95) at org.apache.hadoop.mapreduce.Cluster.&lt;init&gt;(Cluster.java:82) at org.apache.hadoop.mapreduce.Cluster.&lt;init&gt;(Cluster.java:75) at org.apache.hadoop.mapreduce.Job$9.run(Job.java:1266) at org.apache.hadoop.mapreduce.Job$9.run(Job.java:1262) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628) at org.apache.hadoop.mapreduce.Job.connect(Job.java:1261) at org.apache.hadoop.mapreduce.Job.submit(Job.java:1290) at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1314) at org.apache.hadoop.hbase.mapreduce.Export.main(Export.java:189)The problem seems to be the jackson jar version. HADOOP-10104 updated jackson version to 1.9.13. YARN-2092 reported a problem as well.HBase is using jackson 1.8.8. This version of the jar in the classpath seem to cause the problem.Should we upgrade to jackson 1.9.13?</description>
      <version>1.0.0,0.98.10.1,2.0.0</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="13156" opendate="2015-3-5 00:00:00" fixdate="2015-3-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix minor rat violation recently introduced (asciidoctor.css).</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="13170" opendate="2015-3-7 00:00:00" fixdate="2015-3-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow block cache to be external</summary>
      <description>Allow an external service to provide the block cache. This has the nice property of allowing failover/upgrades to happen without causing a fully cold cache.Additionally this allows read replicas to share some of the same memory.</description>
      <version>2.0.0</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestCacheConfig.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl.jamon</file>
      <file type="M">hbase-server.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="13177" opendate="2015-3-8 00:00:00" fixdate="2015-3-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document HBASE-13012</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>hbase-11339,2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.hbase.mob.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="13196" opendate="2015-3-11 00:00:00" fixdate="2015-3-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add info about default number of versions when using the export tool</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="13199" opendate="2015-3-11 00:00:00" fixdate="2015-3-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Some small improvements on canary tool</summary>
      <description>Improvements Make the sniff of region and regionserver parallel to support large cluster with 10000+ region and 500+ regionservers using thread pool. Set cacheblock to false in get and scan to avoid influence to block cache. Add FirstKeyOnlyFilter to get and scan to avoid read and translate too many data from HBase. There may be many column under a column family in a flat-wide table. Select the region randomly when sniffing a regionserver. Make the sink class of canary configurablestackSuggestions are welcomed. Thanks~Another question is that why to check each column family with separate requests when sniffing a region? Can we just check a column family of a region?</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.Canary.java</file>
    </fixedFiles>
  </bug>
  <bug id="1320" opendate="2009-4-12 00:00:00" fixdate="2009-4-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase-1234 broke filter tests</summary>
      <description>HBASE-1234 changed the filter interface. Tests have been disabled. Fix filters and reenable.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.util.TestBytes.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestScanner.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.filter.DisabledTestWhileMatchRowFilter.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.filter.DisabledTestStopRowFilter.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.filter.DisabledTestRowFilterAfterWrite.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.filter.DisabledTestColumnValueFilter.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.client.TestGetRowVersions.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.Keying.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableInputFormat.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.StopRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.RowFilterSet.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.RegExpRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.ColumnValueFilter.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13200" opendate="2015-3-11 00:00:00" fixdate="2015-3-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improper configuration can leads to endless lease recovery during failover</summary>
      <description>When a node (DN+RS) has machine/OS level failure, another RS will try to do lease recovery for the log file. It will retry for every hbase.lease.recovery.dfs.timeout (default to 61s) from the second time. When the hdfs configuration is not properly configured (e.g. socket connection timeout) and without patch HDFS-4721, the lease recovery time can exceeded the timeout specified by hbase.lease.recovery.dfs.timeout. This will lead to endless retries and preemptions until the final timeout.</description>
      <version>None</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSHDFSUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="13202" opendate="2015-3-11 00:00:00" fixdate="2015-4-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - core framework</summary>
      <description>core package, part of HBASE-12439this is just the proc-v2 submodule. it depends only on hbase-common.https://reviews.apache.org/r/27703/</description>
      <version>1.1.0,2.0.0</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.ProcedureTestingUtility.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureFairRunQueues.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.TestProcedureStoreTracker.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.ProcedureStoreTracker.java</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-protocol.pom.xml</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.util.StreamUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="13203" opendate="2015-3-11 00:00:00" fixdate="2015-4-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - master create/delete table</summary>
      <description>master side, part of HBASE-12439starts up the procedure executor on the masterand replaces the create/delete table handlers with the procedure version.</description>
      <version>1.1.0,2.0.0</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ModifyRegionUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.MasterQuotaManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableNamespaceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcCallContext.java</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-protocol.pom.xml</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MetaTableAccessor.java</file>
    </fixedFiles>
  </bug>
  <bug id="13204" opendate="2015-3-11 00:00:00" fixdate="2015-4-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - client create/delete table sync</summary>
      <description>client side, part of HBASE-12439/HBASE-13203it uses the new procedure code to be know when the procedure is completed, and have a proper sync behavior on create/delete table.Review: https://reviews.apache.org/r/32391/</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Master.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MasterProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
    </fixedFiles>
  </bug>
  <bug id="13206" opendate="2015-3-11 00:00:00" fixdate="2015-3-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix TableLock tableName log format</summary>
      <description>The TableName log from Table Lock result in something like:[tableName=^Gdefault^R^Cfoo, lockOwner=localhost,60000because it uses tableNameProto.toByteArray()the fix will result in the proper view[tableName=default:testMissingLastRegion, lockOwner=localh</description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.hbck.TableLockChecker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableLockManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="13208" opendate="2015-3-11 00:00:00" fixdate="2015-3-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Patch build should match the patch filename and not the whole relative URL in findBranchNameFromPatchName</summary>
      <description>In HBASE-1319 we saw that the patch got applied to the wrong branch, the problem is findBranchNameFromPatchName matching a regex that contains wildcard symbols against the whole URL, in this case the regex is 0.94 and the relativePatchURL is /jira/secure/attachment/12703942/HBASE-13193-v4.patch where 0394 is a match.Thanks to jonathan.lawlor for reporting this.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  <bug id="13209" opendate="2015-3-11 00:00:00" fixdate="2015-4-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure V2 - master Add/Modify/Delete Column Family</summary>
      <description>master side, part of HBASE-12439starts up the procedure executor on the masterand replaces the add/modify/delete handlers with the procedure version.</description>
      <version>1.1.0,2.0.0</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.AddColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestTableLockManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.handler.TestTableDescriptorModification.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.handler.TestTableDeleteFamilyHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableDeleteFamilyHandler.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.MasterProcedure.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.java</file>
    </fixedFiles>
  </bug>
  <bug id="1321" opendate="2009-4-12 00:00:00" fixdate="2009-4-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase-1234 broke TestCompaction; fix and reenable</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.DisableTestCompaction.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13210" opendate="2015-3-11 00:00:00" fixdate="2015-4-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure V2 - master Modify table</summary>
      <description>master side, part of HBASE-12439starts up the procedure executor on the masterand replaces the modify table handlers with the procedure version.</description>
      <version>1.1.0,2.0.0</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.MasterProcedure.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.java</file>
    </fixedFiles>
  </bug>
  <bug id="13211" opendate="2015-3-11 00:00:00" fixdate="2015-4-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure V2 - master Enable/Disable table</summary>
      <description>master side, part of HBASE-12439starts up the procedure executor on the masterand replaces the enable/disable table handlers with the procedure version.</description>
      <version>1.1.0,2.0.0</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMasterFailoverWithProcedures.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureTestingUtility.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.TableProcedureInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.MasterProcedure.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.java</file>
    </fixedFiles>
  </bug>
  <bug id="13212" opendate="2015-3-11 00:00:00" fixdate="2015-8-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure V2 - master Create/Modify/Delete namespace</summary>
      <description>master side, part of HBASE-12439starts up the procedure executor on the masterand replaces the create/modify/delete namespace handlers with the procedure version.</description>
      <version>2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureTestingUtility.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ZKNamespaceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableNamespaceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.MasterProcedure.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Master.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MasterProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.java</file>
    </fixedFiles>
  </bug>
  <bug id="13213" opendate="2015-3-11 00:00:00" fixdate="2015-3-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Split out locality metrics among primary and secondary region</summary>
      <description>This task provides the ability to track locality of primary and secondary region replicas.We already have percentFilesLocal metric.There should be two sets of metrics - one for primaries and another for secondary / tertiary regions.</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerMetrics.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsRegionServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperStub.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl.jamon</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="13218" opendate="2015-3-12 00:00:00" fixdate="2015-3-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Correct the syntax shown for using ExportSnapshot tool in the book</summary>
      <description>It is $ bin/hbase class org.apache.hadoop.hbase.snapshot.ExportSnapshot -snapshot MySnapshot -copy-to hdfs://srv2:8082/hbase -mappers 16It should be$ bin/hbase org.apache.hadoop.hbase.snapshot.ExportSnapshot -snapshot MySnapshot -copy-to hdfs://srv2:8082/hbase -mappers 16</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="1322" opendate="2009-4-12 00:00:00" fixdate="2009-4-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase-1234 broke TestAtomicIncrement; fix and reenable</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.DisabledTestAtomicIncrement.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Memcache.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13226" opendate="2015-3-13 00:00:00" fixdate="2015-3-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document enable_table_replication and disable_table_replication shell commands</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="13227" opendate="2015-3-13 00:00:00" fixdate="2015-3-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LoadIncrementalHFile should skip non-files inside a possible family-dir</summary>
      <description>if we have random files/dirs inside the bulkload family dir, we should try to skip them.</description>
      <version>1.0.0,1.1.0,0.98.11,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
    </fixedFiles>
  </bug>
  <bug id="13228" opendate="2015-3-13 00:00:00" fixdate="2015-3-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create procedure v2 branch and add it to QA branch list</summary>
      <description>to develop Procedure V2 quickly, we are going to commit stuff to an hbase-12439 branch.In theory we can have QA running if the patch name is HBASE-xyz-hbase-12439.patch</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.properties</file>
    </fixedFiles>
  </bug>
  <bug id="13232" opendate="2015-3-13 00:00:00" fixdate="2015-3-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ConnectionManger : Batch pool threads and metaLookup pool threads should use different name pattern</summary>
      <description>This is a small issue happened with HBASE-13036. Passing different names to getThreadPool as nameHint but it is not been used. By checking HBASE-13219 found this small issue.</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="13233" opendate="2015-3-13 00:00:00" fixdate="2015-3-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>add hbase-11339 branch to the patch testing script</summary>
      <description>adding hbase-11339 to the BRANCH_NAMES so we can use the apache bot to test patches on that branch.</description>
      <version>hbase-11339,2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.properties</file>
    </fixedFiles>
  </bug>
  <bug id="13234" opendate="2015-3-13 00:00:00" fixdate="2015-3-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve the obviousness of the download link on hbase.apache.org</summary>
      <description>Update the hbase.apache.org homepage to include a very obvious section describing how a user can "Download HBase Software Here" with a link.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.site.xdoc.index.xml</file>
    </fixedFiles>
  </bug>
  <bug id="13235" opendate="2015-3-13 00:00:00" fixdate="2015-3-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Revisit the security auditing semantics.</summary>
      <description>More specifically, the following things need a closer look. (Will include more based on feedback and/or suggestions) Table name (say test) instead of fully qualified table name(default:test) being used. Right now, we're using the scope to be similar to arguments for operation. Would be better to decouple the arguments for operation and scope involved in checking. For e.g. say for createTable, we have the following audit logAccess denied for user esteban; reason: Insufficient permissions; remote address: /10.20.30.1; request: createTable; context: (user=srikanth@XXX, scope=default, action=CREATE)The scope was rightly being used as default namespace, but we're missing out the information like operation params for CREATE which we used to log prior to HBASE-12511.Would love to hear inputs on this!</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AuthResult.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.TableName.java</file>
    </fixedFiles>
  </bug>
  <bug id="13237" opendate="2015-3-13 00:00:00" fixdate="2015-3-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve trademark marks on the hbase.apache.org homepage</summary>
      <description>Ensure trademark marks are next to first and prominent uses of "HBase" on the hbase.apache.org homepage</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.site.xdoc.index.xml</file>
    </fixedFiles>
  </bug>
  <bug id="13244" opendate="2015-3-15 00:00:00" fixdate="2015-3-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Test delegation token generation with kerberos enabled</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.HBaseKerberosUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="13255" opendate="2015-3-16 00:00:00" fixdate="2015-4-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bad grammar in RegionServer status page</summary>
      <description>Noticed on the rs-status page, the blurb under the Regions section could use some grammatical improvements.</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="13262" opendate="2015-3-17 00:00:00" fixdate="2015-3-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ResultScanner doesn&amp;#39;t return all rows in Scan</summary>
      <description>Tried to write a simple Java client again 1.1.0-SNAPSHOT. Write 1M rows, each row with 1 family, and 10 qualifiers (values &amp;#91;0-9&amp;#93;), for a total of 10M cells written Read back the data from the table, ensure I saw 10M cellsRunning it against 04ac1891 (and earlier) yesterday, I would get ~20% of the actual rows. Running against 1.0.0, returns all 10M records as expected.Code I was running for the curious.</description>
      <version>1.1.0,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Client.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ClientProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallReversedScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="13265" opendate="2015-3-17 00:00:00" fixdate="2015-3-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make thrift2 usable from c++</summary>
      <description>Currently the c++ code generated from our thrift2 idl doesn't compile. Mostly this is a naming issue for parameters.</description>
      <version>1.0.0,1.1.0,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.resources.org.apache.hadoop.hbase.thrift2.hbase.thrift</file>
    </fixedFiles>
  </bug>
  <bug id="13281" opendate="2015-3-19 00:00:00" fixdate="2015-3-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>&amp;#39;hbase.bucketcache.size&amp;#39; description in hbase book is not correct</summary>
      <description>The description about 'hbase.bucketcache.size' is not correct. We either specify it as a float or in MB's and the default value that is mentioned is never used.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.hbase-default.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="13289" opendate="2015-3-19 00:00:00" fixdate="2015-4-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>typo in splitSuccessCount metric</summary>
      <description>Our split metrics have a misspelled Count and it shows up in our jmx metrics "splitSuccessCounnt" : 0,</description>
      <version>1.0.0,0.98.10,1.1.0,0.98.11,0.98.12,0.98.10.1,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="13290" opendate="2015-3-19 00:00:00" fixdate="2015-4-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - client enable/disable table sync</summary>
      <description>client side, part of HBASE-12439/HBASE-13211it uses the new procedure code to be know when the procedure is completed, and have a proper sync/async behavior on enable/disable table. For 1.1, It has to be binary compatible (1.0 client can talk to 1.1 server &amp;&amp; 1.1 client can talk to 1.0 server). Binary compatible is TBD for 2.0.</description>
      <version>1.1.0,2.0.0</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Master.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MasterProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="13307" opendate="2015-3-21 00:00:00" fixdate="2015-4-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Making methods under ScannerV2#next inlineable, faster</summary>
      <description>See parent issue for patch and evidence.I was looking at graphs of our scan and found that methods were 'too big' to be inlined (looking at jvm compilation and inlining output flags &amp;#8211; see parent for list). Changing method size helped some. Let me commit the resultant patch.</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestTags.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Bytes.java</file>
    </fixedFiles>
  </bug>
  <bug id="13309" opendate="2015-3-21 00:00:00" fixdate="2015-3-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Some tests do not reset EnvironmentEdgeManager</summary>
      <description>while playing with client timeouts, I hit lots of flakys in HBaseFsck. the cause was just an EnvironmentEdge.inject() not followed by a reset().looks like TestFsUtils and TestHRegion are the only other two that have a missing reset(). all the other tests using inject() seems to be written properly.</description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestFSUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="1331" opendate="2009-4-20 00:00:00" fixdate="2009-4-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Lower the default scanner caching value</summary>
      <description>The current default value for the scanner caching is 30; this causing headaches to many new users who may use a row from a scanner for more than 60 seconds. Let's set it at 1, then folks will be able to optimize.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13310" opendate="2015-3-22 00:00:00" fixdate="2015-3-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix high priority findbugs warnings</summary>
      <description>See here.https://builds.apache.org/job/HBase-TRUNK-jacoco/25/findbugsResult/HIGH/High priority warnings usually introduce bugs or have very bad impact on performace. Let's fix them.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.HbckTestingUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.hbck.OfflineMetaRepair.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.TableAuthManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMasterCommandLine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.RowSpec.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.RowResource.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.RESTServer.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.TableSchemaModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.TableRegionModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.StorageClusterStatusModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.ScannerModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.ColumnSchemaModel.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Threads.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.PrettyPrinter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="13316" opendate="2015-3-23 00:00:00" fixdate="2015-3-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reduce the downtime on planned moves of regions</summary>
      <description>The current behavior of a region move shuts down a region and then starts is up in another regionserver. This causes increased latency and possibly timeouts till the new region's cache is fully warmed up. We can make a region move less disruptive by warming the cache in the destination region server before shutting dow the old region.</description>
      <version>1.0.1,1.1.0,2.0.0</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Admin.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.AdminProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="13322" opendate="2015-3-24 00:00:00" fixdate="2015-12-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace explicit HBaseAdmin creation with connection#getAdmin()</summary>
      <description></description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.LoadTestTool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestMasterReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.FilterTestingCluster.java</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.tablesDetailed.jsp</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionSizeCalculator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HMerge.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMasterCommandLine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestWithCellVisibilityLoadAndVerify.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedListWithVisibility.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
    </fixedFiles>
  </bug>
  <bug id="13325" opendate="2015-3-24 00:00:00" fixdate="2015-3-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Protocol Buffers 2.5 no longer available for download on code.google.com</summary>
      <description>Same as HADOOP-11738Google recently switched off Google Code. They transferred the Protocol Buffers project to GitHub, and binaries are available from Google's developer page. However, only the most recent version is available. We use version 2.5 to be compatible with Hadoop. That version isn't available for download.Let the fun begin</description>
      <version>2.0.0</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.rpc.adoc</file>
      <file type="M">hbase-protocol.README.txt</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.package.html</file>
    </fixedFiles>
  </bug>
  <bug id="13328" opendate="2015-3-24 00:00:00" fixdate="2015-3-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LoadIncrementalHFile.doBulkLoad(Path,HTable) should handle managed connections</summary>
      <description>This seems to be a regression from HBASE-12783 discovered in testing Phoenix with 1.1.0-SNAPSHOT. Phoenix uses an HTable (with managed connection) to pass to doBulkLoad() which throws NeedUnmanagedConnectionException (see IndexToolIT.java and IndexTool.java in Phoenix).</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
    </fixedFiles>
  </bug>
  <bug id="13337" opendate="2015-3-26 00:00:00" fixdate="2015-7-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Table regions are not assigning back, after restarting all regionservers at once.</summary>
      <description>Regions of the table are continouly in state=FAILED_CLOSE.Region State RIT time (ms)8f62e819b356736053e06240f7f7c6fd t1,55555555,1427362431330.8f62e819b356736053e06240f7f7c6fd. state=FAILED_CLOSE, ts=Thu Mar 26 15:05:36 IST 2015 (113s ago), server=VM1,16040,1427362531818 113929caf59209ae65ea80fca6bdc6996a7d68 t1,dddddddd,1427362431330.caf59209ae65ea80fca6bdc6996a7d68. state=FAILED_CLOSE, ts=Thu Mar 26 15:05:36 IST 2015 (113s ago), server=VM2,16040,1427362533691 113929db52a74988f71e5cf257bbabf31f26f3 t1,44444444,1427362431330.db52a74988f71e5cf257bbabf31f26f3. state=FAILED_CLOSE, ts=Thu Mar 26 15:05:36 IST 2015 (113s ago), server=VM3,16040,1427362533691 11392043f3a65b9f9ff283f598c5450feab1f8 t1,88888888,1427362431330.43f3a65b9f9ff283f598c5450feab1f8. state=FAILED_CLOSE, ts=Thu Mar 26 15:05:36 IST 2015 (113s ago), server=VM1,16040,1427362531818 113920Steps to reproduce:1. Start HBase cluster with more than one regionserver.2. Create a table with precreated regions. (lets say 15 regions)3. Make sure the regions are well balanced.4. Restart all the Regionservers process at once across the cluster, except HMaster process5. After restarting the Regionservers, successfully will connect to the HMaster.Bug:But no regions are assigning back to the Regionservers.Master log shows as follows:2015-03-26 15:05:36,201 INFO [VM2,16020,1427362216887-GeneralBulkAssigner-0] master.RegionStates: Transition {8f62e819b356736053e06240f7f7c6fd state=OFFLINE, ts=1427362536106, server=VM2,16040,1427362242602} to {8f62e819b356736053e06240f7f7c6fd state=PENDING_OPEN, ts=1427362536201, server=VM1,16040,1427362531818}2015-03-26 15:05:36,202 INFO [VM2,16020,1427362216887-GeneralBulkAssigner-0] master.RegionStateStore: Updating row t1,55555555,1427362431330.8f62e819b356736053e06240f7f7c6fd. with state=PENDING_OPEN&amp;sn=VM1,16040,14273625318182015-03-26 15:05:36,244 DEBUG [VM2,16020,1427362216887-GeneralBulkAssigner-0] master.AssignmentManager: Force region state offline {8f62e819b356736053e06240f7f7c6fd state=PENDING_OPEN, ts=1427362536201, server=VM1,16040,1427362531818}2015-03-26 15:05:36,244 INFO [VM2,16020,1427362216887-GeneralBulkAssigner-0] master.RegionStates: Transition {8f62e819b356736053e06240f7f7c6fd state=PENDING_OPEN, ts=1427362536201, server=VM1,16040,1427362531818} to {8f62e819b356736053e06240f7f7c6fd state=PENDING_CLOSE, ts=1427362536244, server=VM1,16040,1427362531818}2015-03-26 15:05:36,244 INFO [VM2,16020,1427362216887-GeneralBulkAssigner-0] master.RegionStateStore: Updating row t1,55555555,1427362431330.8f62e819b356736053e06240f7f7c6fd. with state=PENDING_CLOSE2015-03-26 15:05:36,248 INFO [VM2,16020,1427362216887-GeneralBulkAssigner-0] master.AssignmentManager: Server VM1,16040,1427362531818 returned java.nio.channels.ClosedChannelException for t1,55555555,1427362431330.8f62e819b356736053e06240f7f7c6fd., try=1 of 102015-03-26 15:05:36,248 INFO [VM2,16020,1427362216887-GeneralBulkAssigner-0] master.AssignmentManager: Server VM1,16040,1427362531818 returned java.nio.channels.ClosedChannelException for t1,55555555,1427362431330.8f62e819b356736053e06240f7f7c6fd., try=2 of 102015-03-26 15:05:36,249 INFO [VM2,16020,1427362216887-GeneralBulkAssigner-0] master.AssignmentManager: Server VM1,16040,1427362531818 returned java.nio.channels.ClosedChannelException for t1,55555555,1427362431330.8f62e819b356736053e06240f7f7c6fd., try=3 of 102015-03-26 15:05:36,249 INFO [VM2,16020,1427362216887-GeneralBulkAssigner-0] master.AssignmentManager: Server VM1,16040,1427362531818 returned java.nio.channels.ClosedChannelException for t1,55555555,1427362431330.8f62e819b356736053e06240f7f7c6fd., try=4 of 102015-03-26 15:05:36,249 INFO [VM2,16020,1427362216887-GeneralBulkAssigner-0] master.AssignmentManager: Server VM1,16040,1427362531818 returned java.nio.channels.ClosedChannelException for t1,55555555,1427362431330.8f62e819b356736053e06240f7f7c6fd., try=5 of 102015-03-26 15:05:36,250 INFO [VM2,16020,1427362216887-GeneralBulkAssigner-0] master.AssignmentManager: Server VM1,16040,1427362531818 returned java.nio.channels.ClosedChannelException for t1,55555555,1427362431330.8f62e819b356736053e06240f7f7c6fd., try=6 of 102015-03-26 15:05:36,250 INFO [VM2,16020,1427362216887-GeneralBulkAssigner-0] master.AssignmentManager: Server VM1,16040,1427362531818 returned java.nio.channels.ClosedChannelException for t1,55555555,1427362431330.8f62e819b356736053e06240f7f7c6fd., try=7 of 102015-03-26 15:05:36,250 INFO [VM2,16020,1427362216887-GeneralBulkAssigner-0] master.AssignmentManager: Server VM1,16040,1427362531818 returned java.nio.channels.ClosedChannelException for t1,55555555,1427362431330.8f62e819b356736053e06240f7f7c6fd., try=8 of 102015-03-26 15:05:36,251 INFO [VM2,16020,1427362216887-GeneralBulkAssigner-0] master.AssignmentManager: Server VM1,16040,1427362531818 returned java.nio.channels.ClosedChannelException for t1,55555555,1427362431330.8f62e819b356736053e06240f7f7c6fd., try=9 of 102015-03-26 15:05:36,251 INFO [VM2,16020,1427362216887-GeneralBulkAssigner-0] master.AssignmentManager: Server VM1,16040,1427362531818 returned java.nio.channels.ClosedChannelException for t1,55555555,1427362431330.8f62e819b356736053e06240f7f7c6fd., try=10 of 102015-03-26 15:05:36,251 WARN [VM2,16020,1427362216887-GeneralBulkAssigner-0] master.RegionStates: Failed to open/close 8f62e819b356736053e06240f7f7c6fd on VM1,16040,1427362531818, set to FAILED_CLOSE2015-03-26 15:05:36,251 INFO [VM2,16020,1427362216887-GeneralBulkAssigner-0] master.RegionStates: Transition {8f62e819b356736053e06240f7f7c6fd state=PENDING_CLOSE, ts=1427362536244, server=VM1,16040,1427362531818} to {8f62e819b356736053e06240f7f7c6fd state=FAILED_CLOSE, ts=1427362536251, server=VM1,16040,1427362531818}2015-03-26 15:05:36,251 INFO [VM2,16020,1427362216887-GeneralBulkAssigner-0] master.RegionStateStore: Updating row t1,55555555,1427362431330.8f62e819b356736053e06240f7f7c6fd. with state=FAILED_CLOSE</description>
      <version>2.0.0</version>
      <fixedVersion>1.2.0,1.1.2,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.AsyncRpcClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="13339" opendate="2015-3-26 00:00:00" fixdate="2015-8-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update default Hadoop version to latest for master</summary>
      <description>Current default Hadoop version is getting a little long in the tooth. We should update to the latest version. The latest version is backwards compatible with 2.5.1's dfs and mr so this should be painless.</description>
      <version>1.1.0,2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
      <file type="M">dev-support.test-patch.properties</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="13342" opendate="2015-3-26 00:00:00" fixdate="2015-3-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix incorrect interface annotations</summary>
      <description>Still some old annotations. Have slipped in. Lets remove them and add in a patch check for them.</description>
      <version>1.1.0,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.ReplayHLogKey.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.RegionReplicaFlushHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.RegionStateListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.namespace.NamespaceTableAndRegionInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.namespace.NamespaceStateManager.java</file>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  <bug id="13344" opendate="2015-3-26 00:00:00" fixdate="2015-6-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add enforcer rule that matches our JDK support statement</summary>
      <description>The ref guide gives a list of JDKs that we expect our hbase versions to work with at runtime.Let's add in the extra-enforcer-rules mojo and start using the bytecode version rule to make sure that the result of our builds on a given branch won't fail out because of a misconfigured target jdk version (or a dependency that targets a later jdk).</description>
      <version>2.0.0</version>
      <fixedVersion>0.94.28,0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="13355" opendate="2015-3-28 00:00:00" fixdate="2015-3-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>QA bot reports checking javac twice</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  <bug id="13357" opendate="2015-3-28 00:00:00" fixdate="2015-3-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>If maxTables/maxRegions exceeds quota in a namespace, throw QuotaExceededException</summary>
      <description>If maximum number of tables or regions count exceeds in a namespace we are throwing DoNotRetryIOException instead we should throw QuotaExceededException.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.namespace.TestNamespaceAuditor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.namespace.NamespaceStateManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="13364" opendate="2015-3-30 00:00:00" fixdate="2015-3-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make using the default javac on by default</summary>
      <description>Errorprone doesn't work with java 8 and java 8 is becoming more and more standard everywhere.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-thrift.pom.xml</file>
      <file type="M">hbase-shell.pom.xml</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-prefix-tree.pom.xml</file>
      <file type="M">hbase-it.pom.xml</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-hadoop-compat.pom.xml</file>
      <file type="M">hbase-examples.pom.xml</file>
      <file type="M">hbase-common.pom.xml</file>
      <file type="M">hbase-client.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="13366" opendate="2015-3-31 00:00:00" fixdate="2015-4-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Throw DoNotRetryIOException instead of read only IOException</summary>
      <description>Currently, the read only region just throws an IOException to the clients who send write requests to it. This will cause the clients retry for configured times or until operation timeout.Changing this exception to DoNotRetryIOException will make the client failed fast.Suggestions are welcomed~ Thanks</description>
      <version>None</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="13372" opendate="2015-4-1 00:00:00" fixdate="2015-4-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unit tests for SplitTransaction and RegionMergeTransaction listeners</summary>
      <description>We have new Listener interfaces in SplitTransaction and RegionMergeTransaction. There are no use cases for these yet, nor unit tests. We should have unit tests for these that do something just a bit nontrivial so as to provide a useful example.</description>
      <version>1.1.0,2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionMergeTransaction.java</file>
    </fixedFiles>
  </bug>
  <bug id="13374" opendate="2015-4-1 00:00:00" fixdate="2015-4-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Small scanners (with particular configurations) do not return all rows</summary>
      <description>I recently ran into a couple data loss issues with small scans. Similar to HBASE-13262, these issues only appear when scans are configured in such a way that the max result size limit is reached before the caching limit is reached. As far as I can tell, this issue affects branches 0.98+I should note that after investigation it looks like the root cause of these issues is not the same as HBASE-13262. Rather, these issue are caused by errors in the small scanner logic (I will explain in more depth below). Furthermore, I do know that the solution from HBASE-13262 has not made its way into small scanners (it is being addressed in HBASE-13335). As a result I made sure to test these issues with the patch from HBASE-13335 applied and I saw that they were still present.The following two issues have been observed (both lead to data loss):1. When a small scan is configured with a caching value of Integer.MAX_VALUE, and a maxResultSize limit that is reached before the region is exhausted, integer overflow will occur. This eventually leads to a preemptive skip of the regions.2. When a small scan is configured with a maxResultSize that is smaller than the size of a single row, the small scanner will jump between regions preemptively. This issue seems to be because small scanners assume that, unless a region is exhausted, at least 2 rows will be returned from the server. This assumption isn't clearly state in the small scanners but is implied through the use of skipRowOfFirstResult.Again, I would like to stress that the root cause of these issues is NOT related to the cause of HBASE-13262. These issues occur because of inappropriate assumption made in the small scanner logic. The inappropriate assumptions are:1. Integer overflow will not occur when incrementing caching2. At least 2 rows will be returned from the server unless the region has been exhaustedI am attaching a patch that contains tests to display these issues. If these issues should be split into separate JIRAs please let me know.</description>
      <version>1.0.0,1.1.0,0.98.13,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannersFromClientSide.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallReversedScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="13375" opendate="2015-4-1 00:00:00" fixdate="2015-5-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Provide HBase superuser higher priority over other users in the RPC handling</summary>
      <description>HBASE-13351 annotates Master RPCs so that RegionServer RPCs are treated with a higher priority compared to user RPCs (and they are handled by a separate set of handlers, etc.). It may be good to stretch this to users too - hbase superuser (configured via hbase.superuser) gets higher priority over other users in the RPC handling. That way the superuser can always perform administrative operations on the cluster even if all the normal priority handlers are occupied (for example, we had a situation where all the master's handlers were tied up with many simultaneous createTable RPC calls from multiple users and the master wasn't able to perform any operations initiated by the admin). (Discussed this some with enis and elserj).Does this make sense to others?</description>
      <version>None</version>
      <fixedVersion>1.2.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestQosFunction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestPriorityRpc.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterPriorityRpc.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.AnnotationReadingPriorityFunction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.PriorityFunction.java</file>
    </fixedFiles>
  </bug>
  <bug id="13383" opendate="2015-4-1 00:00:00" fixdate="2015-4-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestRegionServerObserver.testCoprocessorHooksInRegionsMerge zombie after HBASE-12975</summary>
      <description>Stuck here:"main" prio=10 tid=0x00007f3ff4008000 nid=0x6183 waiting on condition [0x00007f3ffa49e000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at org.apache.hadoop.hbase.coprocessor.TestRegionServerObserver.testCoprocessorHooksInRegionsMerge(TestRegionServerObserver.java:100)</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="13397" opendate="2015-4-3 00:00:00" fixdate="2015-4-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Purge duplicate rpc request thread local</summary>
      <description>Serverside, in a few locations, code wants access to RPC context to get user and remote client address. A thread local makes it so this info is accessible anywhere on the processing chain.Turns out we have this mechanism twice (noticed by our Matteo). This patch purges one of the thread locals.</description>
      <version>None</version>
      <fixedVersion>1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.token.TestTokenAuthentication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestCallRunner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.TokenProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.RegionServerQuotaManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.CreateTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcCallContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RequestContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.CallRunner.java</file>
    </fixedFiles>
  </bug>
  <bug id="13398" opendate="2015-4-3 00:00:00" fixdate="2015-5-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document HBase Quota</summary>
      <description>As part of this we should document HBASE-11598 and HBASE-8410</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="13409" opendate="2015-4-6 00:00:00" fixdate="2015-4-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add categories to uncategorized tests</summary>
      <description>A couple tests without categories were flagged recently by TestCheckTestClasses in a precommit build.</description>
      <version>1.1.0,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.filter.TestLongComparator.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestClientExponentialBackoff.java</file>
    </fixedFiles>
  </bug>
  <bug id="1341" opendate="2009-4-23 00:00:00" fixdate="2009-5-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create HTable Pooler</summary>
      <description>A client class that takes care of properly pooling HTable references for use in multi-threaded, low-latency Java clients.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13411" opendate="2015-4-6 00:00:00" fixdate="2015-4-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Misleading error message when request size quota limit exceeds</summary>
      <description>User will get the same error message when either number of requests exceeds or request size exceeds. So its better we differentiate them.Thanks to mbertozzi for confirming the same offline.</description>
      <version>2.0.0</version>
      <fixedVersion>1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.TimeBasedLimiter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.ThrottlingException.java</file>
    </fixedFiles>
  </bug>
  <bug id="13412" opendate="2015-4-6 00:00:00" fixdate="2015-4-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Region split decisions should have jitter</summary>
      <description>Whenever a region splits it causes lots of IO (compactions are queued for a while). Because of this it's important to make sure that well distributed tables don't have all of their regions split at exactly the same time.This is basically the same as our compaction jitter.</description>
      <version>1.0.0,2.0.0</version>
      <fixedVersion>1.1.0,0.98.13,2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy.java</file>
    </fixedFiles>
  </bug>
  <bug id="13413" opendate="2015-4-6 00:00:00" fixdate="2015-4-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create an integration test for Replication</summary>
      <description>We want to have an end-to-end test for replication. it can write data into one cluster (with replication setup) and then read data from the other. The test should be capable of running for a long time and be reliant even under chaos monkey testing.</description>
      <version>1.0.0,2.0.0</version>
      <fixedVersion>1.1.0,0.98.13,2.0.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="13425" opendate="2015-4-8 00:00:00" fixdate="2015-12-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Documentation nit in REST Gateway impersonation section</summary>
      <description>In section "55.8. REST Gateway Impersonation Configuration", there is another property that needs to be set (and thus documented).After this sentence ("To enable REST gateway impersonation, add the following to the hbase-site.xml file for every REST gateway."), we should add :&lt;property&gt; &lt;name&gt;hbase.rest.support.proxyuser&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;It not set, doing a curl call on the rest gateway gives the error "support for proxyuser is not configured".</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.security.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="13455" opendate="2015-4-11 00:00:00" fixdate="2015-4-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure V2 - master truncate table</summary>
      <description>master side, part of HBASE-12439and replaces the truncate table handlers with the procedure version.https://reviews.apache.org/r/33102</description>
      <version>1.1.0,2.0.0</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMasterFailoverWithProcedures.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.MasterProcedure.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.java</file>
    </fixedFiles>
  </bug>
  <bug id="13468" opendate="2015-4-14 00:00:00" fixdate="2015-11-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase.zookeeper.quorum supports ipv6 address</summary>
      <description>I put ipv6 address in hbase.zookeeper.quorum, by the time this string went to zookeeper code, the address is messed up, i.e. only '[1234' left. I started using pseudo mode with embedded zk = true.I downloaded 1.0.0, not sure which affected version should be here.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-zookeeper.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKMainServer.java</file>
      <file type="M">hbase-shaded.pom.xml</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKConfig.java</file>
      <file type="M">hbase-common.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="13473" opendate="2015-4-15 00:00:00" fixdate="2015-4-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>deleted cells come back alive after the stripe compaction</summary>
      <description>during the STRIPE compaction,deletes(tombstones) are being dropped in 2 cases.1. Compaction including L0 (includeL0 == true)2. L0 has no files (canDropDeletesWithoutL0 == true)To drop delete marker and keep the consistency during compaction, All of HFiles in the stripe has to be selected, just like major compaction.otherwise, after the compaction only delete markers would be gone, and deleted cells (which is in the not-selected HFiles) are going to be alive again.In my cluster, there was no file on L0(canDropDeletesWithoutL0==true) and not all files are selected for compaction, so some of deleted rows have come back alive and appears when i get or scan after compactions.I made a patch about it.it checks if all files are selected before we set the majorRange of compaction request .</description>
      <version>1.0.1,1.1.0,0.98.12,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.13,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.compactions.TestStripeCompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy.java</file>
    </fixedFiles>
  </bug>
  <bug id="13477" opendate="2015-4-15 00:00:00" fixdate="2015-4-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create metrics on failed requests</summary>
      <description>Add a metric on how many requests failed/errored out.</description>
      <version>1.0.0,2.0.0</version>
      <fixedVersion>1.1.0,0.98.13,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestRpcMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServer.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceFactoryImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="13478" opendate="2015-4-15 00:00:00" fixdate="2015-11-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document the change of default master ports being used .</summary>
      <description>In 1.0.x, master by default binds to the region server ports. But in 1.1 and 2.0 branches, we have undone this changes and brought back the usage of old master ports to make the migration from 0.98 -&gt; 1.1 hassle free. Please see the parent jira for more background.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="13481" opendate="2015-4-15 00:00:00" fixdate="2015-4-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Master should respect master (old) DNS/bind related configurations</summary>
      <description>This is a continuation of parent HBASE-13453. We should continue respecting the following parameters that 1.0.0 does not: hbase.master.dns.interfacehbase.master.dns.nameserverhbase.master.ipc.addressCredit goes to jerryhe for pointing that out.</description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.RatioBasedCompactionPolicy.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerHostname.java</file>
    </fixedFiles>
  </bug>
  <bug id="13483" opendate="2015-4-15 00:00:00" fixdate="2015-8-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[docs] onheap is not a valid bucket cache IO engine.</summary>
      <description>From the HBase book: http://hbase.apache.org/book.html#hbase_default_configurations:hbase.bucketcache.ioengineDescriptionWhere to store the contents of the bucketcache. One of: *onheap*, offheap, or file. If a file, set it to file:PATH_TO_FILE. See https://hbase.apache.org/apidocs/org/apache/hadoop/hbase/io/hfile/CacheConfig.html for more information.Instead of onheap it should be heap.</description>
      <version>2.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="13487" opendate="2015-4-16 00:00:00" fixdate="2015-4-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Doc KEEP_DELETED_CELLS</summary>
      <description>Let me doc this nice feature that has been around a long time but is not explained other than in Lars lectures. I was talking to someone and could not explain this feature myself until Lars set me straight.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.schema.design.adoc</file>
      <file type="M">src.main.asciidoc..chapters.datamodel.adoc</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.create.rb</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="13518" opendate="2015-4-21 00:00:00" fixdate="2015-4-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Typo in hbase.hconnection.meta.lookup.threads.core parameter</summary>
      <description>A possible typo coming from patch in HBASE-13036. I think we want hbase.hconnection.meta.lookup.threads.core, not hbase.hconnection.meta.lookup.threads.max.core to be in line with the regular thread pool configuration. //To start with, threads.max.core threads can hit the meta (including replicas). //After that, requests will get queued up in the passed queue, and only after //the queue is full, a new thread will be started this.metaLookupPool = getThreadPool( conf.getInt("hbase.hconnection.meta.lookup.threads.max", 128), conf.getInt("hbase.hconnection.meta.lookup.threads.max.core", 10),</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
    </fixedFiles>
  </bug>
  <bug id="13527" opendate="2015-4-22 00:00:00" fixdate="2015-4-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The default value for hbase.client.scanner.max.result.size is never actually set on Scans</summary>
      <description>Now that max result size is driven from the client side like caching (HBASE-13362), we also need to set Scan.maxResultSize to the default value of hbase.client.scanner.max.result.size which is never performed. I think this has gone unnoticed because the server used to read the configuration hbase.client.scanner.max.result.size for itself, but now we expect the serialized Scan sent from the client side to contain this information. Realistically this should have been set on the Scans even before HBASE-13362, it's surprising that it's not as the scanner code seems to indicate otherwise.Ultimately, the end result is that, by default, scan RPC's are limited by hbase.server.scanner.max.result.size (note this is the new server side config not the client side config) which has a default value of 100 MB. The scan RPC's should instead be limited by hbase.client.scanner.max.result.size which has a default value of 2 MB.The reason why this issue occurs is because, by default, a new Scan() initializes Scan.maxResultSize to -1. This initial value of -1 will never be changed unless Scan#setMaxResultSize() is called. In the event that this value is not changed, the Scan that is serialized and sent to the server will also have Scan.maxResultSize = -1. Then, when the server is deciding what size limit should be enforced, it sees that Scan.maxResultSize = -1 so it uses the most relaxed size restriction possible, which is hbase.server.scanner.max.result.size (default value 100 MB).</description>
      <version>1.0.0,1.1.0,0.98.12,1.2.0,2.0.0</version>
      <fixedVersion>1.1.0,0.98.12,1.0.2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannersFromClientSide.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.TableConfiguration.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="13529" opendate="2015-4-22 00:00:00" fixdate="2015-4-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - WAL Improvements</summary>
      <description>from the discussion in HBASE-12439 the wal was resulting slow. there is an error around the awake of the slotCond.await(), causing more wait then necessary ArrayBlockingQueue is dog slow, replace it with ConcurrentLinkedQueue roll the wal only if reaches a threshold (conf ops) to amortize the cost hsync() is used by default, when the normal wal is using just hflush() make it tunable via conf</description>
      <version>1.1.0,2.0.0</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.TestProcedureStoreTracker.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.util.StringUtils.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.ProcedureStoreTracker.java</file>
    </fixedFiles>
  </bug>
  <bug id="13537" opendate="2015-4-23 00:00:00" fixdate="2015-4-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure V2 - Change the admin interface for async operations to return Future (incompatible with branch-1.x)</summary>
      <description>At the moment, the async operations are returning void. This task aims to change the return type to Future and remove the aysnc wrapper methods.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
    </fixedFiles>
  </bug>
  <bug id="13538" opendate="2015-4-23 00:00:00" fixdate="2015-10-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - client add/delete/modify column family sync (incompatible with branch-1.x)</summary>
      <description>Client side part of HBASE-13209.It uses the new procedure code to be know when the procedure is completed, and have a proper sync/async behavior on add/modify/delete column family.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Master.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MasterProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
    </fixedFiles>
  </bug>
  <bug id="13554" opendate="2015-4-24 00:00:00" fixdate="2015-4-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update book clarifying API stability guarantees</summary>
      <description>From the "Clarifying interface evolution freedom in patch releases" thread on dev@h.a.oSeems we have consensus that "HBase uses Semantic Versioning" isn't quite correct (or desired) at the moment. Update the documentation to make sure we're not misrepresenting any guarantees to users.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="13560" opendate="2015-4-25 00:00:00" fixdate="2015-6-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Large compaction queue should steal from small compaction queue when idle</summary>
      <description>If you tune compaction threads so that a server is never over commited when large and small compaction threads are busy then it should be possible to have the large compactions steal work.</description>
      <version>1.2.0,2.0.0</version>
      <fixedVersion>1.2.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
    </fixedFiles>
  </bug>
  <bug id="13561" opendate="2015-4-25 00:00:00" fixdate="2015-7-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ITBLL.Verify doesn&amp;#39;t actually evaluate counters after job completes</summary>
      <description>Was digging through ITBLL and noticed this oddity:The Verify Tool doesn't actually call Verify#verify(long) like the Loop Tool does. Granted, it doesn't know the total number of KVs that were written given the current arguments, it's not even checking to see if there things like UNDEFINED records found.It seems to me that Verify should really be doing some checking on the counters like Loop does and not just leaving it up to the visual inspection of whomever launched the task.Am I missing something?</description>
      <version>1.0.0,1.1.0,0.98.12,2.0.0</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
    </fixedFiles>
  </bug>
  <bug id="13563" opendate="2015-4-25 00:00:00" fixdate="2015-4-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add missing table owner to AC tests.</summary>
      <description>As per the description.</description>
      <version>None</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
    </fixedFiles>
  </bug>
  <bug id="13571" opendate="2015-4-27 00:00:00" fixdate="2015-5-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - client modify table sync (incompatible with branch-1.x)</summary>
      <description>Client side part of HBASE-13210. It uses the new procedure code to be know when the procedure is completed, and have a proper sync/async behavior on modify table.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Master.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MasterProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
    </fixedFiles>
  </bug>
  <bug id="13572" opendate="2015-4-27 00:00:00" fixdate="2015-4-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - client truncate table sync (incompatible with branch-1.x)</summary>
      <description>Client side part of HBASE-13455.It uses the new procedure code to be know when the procedure is completed, and have a proper sync/async behavior on truncate table.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Master.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MasterProtos.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestProcedureFuture.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
    </fixedFiles>
  </bug>
  <bug id="13586" opendate="2015-4-28 00:00:00" fixdate="2015-4-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update book on Hadoop and Java supported versions for 1.1.x</summary>
      <description>Should update http://hbase.apache.org/book.html#basic.prerequisites with the latest info.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="1359" opendate="2009-4-30 00:00:00" fixdate="2009-7-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>After a large truncating table HBase becomes unresponsive</summary>
      <description>If you see **** I removed and ip or something for security reasonsOnce I truncate the table, hbase freaks out for about 10 seconds and all the thrift servers die.Thrift server log:2009-04-02 12:09:08,971 INFO org.apache.hadoop.ipc.HBaseClass: Retrying connect to server: /*****:60020. Already tried 0 time(s).You see this a bunch of times and then it times outThe hbase shellnhbase(main):001:0&gt; truncate 't2'09/04/30 13:01:08 INFO zookeeper.ZooKeeperWrapper: Quorum servers: ****Truncating t2; it may take a whileDisabling table...09/04/30 13:01:19 INFO client.HBaseAdmin: Disabled t20 row(s) in 10.3417 secondsDropping table...09/04/30 13:01:19 INFO client.HBaseAdmin: Deleted t20 row(s) in 0.1592 secondsCreating table...0 row(s) in 14.7567 secondshbase(main):002:0&gt; lsitNameError: undefined local variable or method `lsit' for #&lt;Object:0x3bbe9a50&gt; from (hbase):3hbase(main):003:0&gt; lsitNameError: undefined local variable or method `lsit' for #&lt;Object:0x3bbe9a50&gt; from (hbase):4hbase(main):004:0&gt; listNativeException: java.lang.NullPointerException: null from org/apache/hadoop/hbase/client/HConnectionManager.java:344:in `processRow' from org/apache/hadoop/hbase/client/MetaScanner.java:64:in `metaScan' from org/apache/hadoop/hbase/client/MetaScanner.java:29:in `metaScan' from org/apache/hadoop/hbase/client/HConnectionManager.java:351:in `listTables' from org/apache/hadoop/hbase/client/HBaseAdmin.java:121:in `listTables' from sun/reflect/NativeMethodAccessorImpl.java:-2:in `invoke0' from sun/reflect/NativeMethodAccessorImpl.java:39:in `invoke' from sun/reflect/DelegatingMethodAccessorImpl.java:25:in `invoke' from java/lang/reflect/Method.java:597:in `invoke' from org/jruby/javasupport/JavaMethod.java:298:in `invokeWithExceptionHandling' from org/jruby/javasupport/JavaMethod.java:259:in `invoke' from org/jruby/java/invokers/InstanceMethodInvoker.java:36:in `call' from org/jruby/runtime/callsite/CachingCallSite.java:260:in `cacheAndCall' from org/jruby/runtime/callsite/CachingCallSite.java:75:in `call' from org/jruby/ast/CallNoArgNode.java:61:in `interpret' from org/jruby/ast/ForNode.java:101:in `interpret'... 113 levels... from org/jruby/internal/runtime/methods/DynamicMethod.java:226:in `call' from org/jruby/internal/runtime/methods/CompiledMethod.java:216:in `call' from org/jruby/internal/runtime/methods/CompiledMethod.java:71:in `call' from org/jruby/runtime/callsite/CachingCallSite.java:260:in `cacheAndCall' from org/jruby/runtime/callsite/CachingCallSite.java:75:in `call' from home/fds/ts/hadoop/hbase/bin/$dot_dot/bin/hirb.rb:441:in `_file_' from home/fds/ts/hadoop/hbase/bin/$dot_dot/bin/hirb.rb:-1:in `_file_' from home/fds/ts/hadoop/hbase/bin/$dot_dot/bin/hirb.rb:-1:in `load' from org/jruby/Ruby.java:564:in `runScript' from org/jruby/Ruby.java:467:in `runNormally' from org/jruby/Ruby.java:340:in `runFromMain' from org/jruby/Main.java:214:in `run' from org/jruby/Main.java:100:in `run' from org/jruby/Main.java:84:in `main' from /home/fds/ts/hadoop/hbase/bin/../bin/hirb.rb:300:in `list' from (hbase):5hbase(main):005:0&gt;hbase(main):006:0*</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13614" opendate="2015-5-4 00:00:00" fixdate="2015-6-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Avoid temp KeyOnlyKeyValue temp objects creations in read hot path</summary>
      <description>As part of HBASE-10800, move to new CellComparator, we are temp creating a Cell out of byte[]s so that the Comparator can compare. In read hot path, we can try minimize the object creations. The parent Jira added some such cases, which we can solve. This Jira will solve all such cases.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
    </fixedFiles>
  </bug>
  <bug id="13618" opendate="2015-5-5 00:00:00" fixdate="2015-5-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ReplicationSource is too eager to remove sinks</summary>
      <description>Looking at the replication for some other reason I noticed that the replication source might be a bit too eager to remove sinks from the list of valid sinks.The current logic allows a sink to fail N times (default 3) and then it will be remove from the sinks. But note that this failure count is never reduced, so given enough runtime and some network glitches every sink will eventually be removed. When all sink are removed the source pick new sinks and the counter is set to 0 for all of them.I think we should change to reset the counter each time we successfully replicate something to the sink (which proves the sink isn't dead). Or we could decrease the counter each time we successfully replication, that might be better - if we consistently fail more attempts than we succeed the sink should be removed.</description>
      <version>None</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSinkManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSinkManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint.java</file>
    </fixedFiles>
  </bug>
  <bug id="13630" opendate="2015-5-6 00:00:00" fixdate="2015-5-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove dead code in BufferedDataEncoder</summary>
      <description>Remove the dead code pointed out in HBASE-10800 as part of high prioirty findbugs.https://issues.apache.org/jira/browse/HBASE-10800?focusedCommentId=14529659&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14529659</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
    </fixedFiles>
  </bug>
  <bug id="13647" opendate="2015-5-8 00:00:00" fixdate="2015-6-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Default value for hbase.client.operation.timeout is too high</summary>
      <description>Default value for hbase.client.operation.timeout is too high, it is LONG.Max.That value will block any service calls to coprocessor endpoints indefinitely.Should we introduce better default value for that?</description>
      <version>1.0.1,0.98.13,1.2.0,1.1.1,2.0.0</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="13662" opendate="2015-5-11 00:00:00" fixdate="2015-5-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RSRpcService.scan() throws an OutOfOrderScannerNext if the scan has a retriable failure</summary>
      <description>while fixing HBASE-13651 I noticed that if we have a failure inside the RSRpcService.scan(), when the request has a hasNextCallSeq() the nextCallSeq is incremented and not rolledback, which means that the client retry will send a request with a nextCallSeq not up to date, which result in an OutOfOrderScannerNextException.if (rows &gt; 0) { if (request.hasNextCallSeq()) { if (request.getNextCallSeq() != rsh.nextCallSeq) { throw new OutOfOrderScannerNextException(...) } // Increment the nextCallSeq value which is the next expected from client. rsh.nextCallSeq++; }}try { ...scan code...}after the scanner heartbeat patches HBASE-13090, we seems to be able to recover from that OutOfOrder exception, but the error show up anyway.After a discussion with saint.ack@gmail.com we ended up saying that decrementing the callSeq on exception seems to be fine. but we had the open question about having that nextCallSeq to be atomic, if that was supposed to prevent concurrent requests with the same id. any thoughts?</description>
      <version>1.0.1,1.1.0,0.98.10.1,2.0.0</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="13694" opendate="2015-5-15 00:00:00" fixdate="2015-5-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CallQueueSize is incorrectly decremented until the response is sent</summary>
      <description>We should decrement the CallQueueSize as soon as we no longer need the call around, e.g. after RpcServer.CurCall.set(null) otherwise we will be only pushing back other client requests while we send the response back to the client that originated the call.</description>
      <version>1.1.0,0.98.12,1.0.2,1.2.0,2.0.0</version>
      <fixedVersion>1.2.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.CallRunner.java</file>
    </fixedFiles>
  </bug>
  <bug id="13698" opendate="2015-5-15 00:00:00" fixdate="2015-5-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add RegionLocator methods to Thrift2 proxy.</summary>
      <description>Thrift2 doesn't provide the same functionality as the java client for getting region locations. We should change that.</description>
      <version>1.1.0,2.0.0</version>
      <fixedVersion>1.2.0,2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.resources.org.apache.hadoop.hbase.thrift2.hbase.thrift</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftUtilities.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TMutation.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.THBaseService.java</file>
      <file type="M">hbase-thrift.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="13699" opendate="2015-5-15 00:00:00" fixdate="2015-5-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expand information about HBase quotas</summary>
      <description>See HBASE-13398 and http://blog.cloudera.com/blog/2014/12/new-in-cdh-5-2-improvements-for-running-multiple-workloads-on-a-single-hbase-cluster/.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="1373" opendate="2009-5-5 00:00:00" fixdate="2009-1-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update Thrift to use compact/framed protocol</summary>
      <description>TCompactProtocol/TFramedTransport and nonblocking server option promises better efficiency and performance improvements. Consider moving HBase Thrift bits to this when full platform support is ready for TCompactProtocol.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.package.html</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13746" opendate="2015-5-22 00:00:00" fixdate="2015-5-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>list_replicated_tables command is not listing table in hbase shell.</summary>
      <description>IN HBase shell prompt execute the following commandlist_replicated_tableshbase(main):014:0&gt; list_replicated_tablesTABLE:COLUMNFAMILY ReplicationTypeERROR: undefined method `TNAME' for Java::OrgApacheHadoopHbaseClientReplication::ReplicationAdmin:ClassHere is some help for this command:List all the tables and column families replicated from this cluster hbase&gt; list_replicated_tables hbase&gt; list_replicated_tables 'abc.*' list.select {|s| pattern.match(s.get(ReplicationAdmin.TNAME))}</description>
      <version>1.1.0,0.98.13,1.0.2,2.0.0</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.replication.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug id="13759" opendate="2015-5-24 00:00:00" fixdate="2015-5-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve procedure yielding</summary>
      <description>Adds the ability to yield the procedure every execution step.by default, a procedure will try to go begin to end without stopping.This allows procedures to be nice to other procedures.one usage example is ServerShutdownHandler where we want everyone to make some progress.Allows procedure to throw InterruptedException, the default handling will be:"ask the master if there is an abort of stop. If there is, stop executions and exit. Else, clear the IE and carryon executing. the interruted procedure will retry".If the procedure implementor wants a different behavior, the IE can be catched and custom handling can be performed.</description>
      <version>1.2.0,2.0.0</version>
      <fixedVersion>1.2.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.TruncateTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.EnableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DisableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.AddColumnFamilyProcedure.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.StateMachineProcedure.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.SequentialProcedure.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureExecutor.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.Procedure.java</file>
    </fixedFiles>
  </bug>
  <bug id="13760" opendate="2015-5-24 00:00:00" fixdate="2015-5-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cleanup Findbugs keySet iterator warnings</summary>
      <description>Cleanup Findbugs keySet iterator warnings</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="13767" opendate="2015-5-25 00:00:00" fixdate="2015-5-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow ZKAclReset to set and not just clear ZK ACLs</summary>
      <description>The ZKAclReset tool allows to clear ZK ACLs, which is useful if you are migrating from a secure to unsecure cluster setup.If you want to make sure that your znode ACLs are correct, a -set-acls option, which allows to enforce the proper ACLs on the znodes in a secure setup, can be useful too.</description>
      <version>1.2.0,2.0.0</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZkAclReset.java</file>
    </fixedFiles>
  </bug>
  <bug id="13768" opendate="2015-5-25 00:00:00" fixdate="2015-5-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ZooKeeper znodes are bootstrapped with insecure ACLs in a secure configuration</summary>
      <description>A logic error causes HBase in most secure configuration deployments to handle its coordination state in ZooKeeper via insecure ACLs. Anyone with remote unauthenticated network access to the ZooKeeper quorum, which by definition includes all HBase clients, can make use of this opening to violate the operational integrity of the system. For example, critical znodes can be deleted, causing outages. It is possible to introduce rogue replication endpoints. It is possible to direct the distributed log splitting facility to split arbitrary files in HDFS.</description>
      <version>None</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,0.98.12.1,1.0.1.1,1.1.0.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.java</file>
    </fixedFiles>
  </bug>
  <bug id="1377" opendate="2009-5-6 00:00:00" fixdate="2009-5-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RS address is null in master web UI</summary>
      <description>My patch in HBASE-1279 was targeted for branch 0.19 and was missing a line to make it work for trunk in the copy constructor of HSI.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.HServerInfo.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13770" opendate="2015-5-25 00:00:00" fixdate="2015-10-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Programmatic JAAS configuration option for secure zookeeper may be broken</summary>
      <description>While verifying the patch fix for HBASE-13768 we were unable to successfully test the programmatic JAAS configuration option for secure ZooKeeper integration. Unclear if that was due to a bug or incorrect test configuration.Update the security section of the online book with clear instructions for setting up the programmatic JAAS configuration option for secure ZooKeeper integration.Verify it works.Fix as necessary.</description>
      <version>1.0.1,1.1.0,0.98.13,1.2.0,2.0.0</version>
      <fixedVersion>1.2.0,1.3.0,0.98.15,1.0.3,1.1.3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZooKeeperACL.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMasterCommandLine.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.HQuorumPeer.java</file>
    </fixedFiles>
  </bug>
  <bug id="13776" opendate="2015-5-26 00:00:00" fixdate="2015-5-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Setting illegal versions for HColumnDescriptor does not throw IllegalArgumentException</summary>
      <description>HColumnDescriptor hcd = new HColumnDescriptor( new HColumnDescriptor(HConstants.CATALOG_FAMILY) .setInMemory(true) .setScope(HConstants.REPLICATION_SCOPE_LOCAL) .setBloomFilterType(BloomType.NONE) .setCacheDataInL1(true)); final int minVersions = 123; final int maxVersions = 234; hcd.setMaxVersions(minVersions); hcd.setMinVersions(maxVersions);//no exception throw</description>
      <version>0.98.14,1.0.2,1.2.0,1.1.1,2.0.0</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="13780" opendate="2015-5-26 00:00:00" fixdate="2015-5-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Default to 700 for HDFS root dir permissions for secure deployments</summary>
      <description>Secure mode deployments should protect the files under HDFS root dir. We should check and set the root dirs permissions on a kerberos setup so that users does not have to. We have hbase.data.umask.enable and hbase.data.umask for data files, but those are not that useful since we should protect dir listing, and access to WAL files, snapshot files, etc. See HBASE-13768 which has an integration test for this.</description>
      <version>None</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.security.adoc</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="13789" opendate="2015-5-28 00:00:00" fixdate="2015-6-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ForeignException should not be sent to the client</summary>
      <description>ForeignException is in hbase-server so the client will not be able to deserialize it, and also it will hide the DoNotRetryException of the cause.I haven't found an easy way to test it, aside manually looking at the logs. and this stuff will go away with proc-v2. so for now the easy workaround is catch the ForeignException in the master which are just the few places related to proc-v1 and throw the cause to the client</description>
      <version>0.98.13,1.0.1.1,1.1.0.1,2.0.0</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="13801" opendate="2015-5-28 00:00:00" fixdate="2015-5-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hadoop src checksum is shown instead of HBase src checksum in master / RS UI</summary>
      <description>Simple bug. We are showing the Hadoop's source MD5 checksum in the master UI instead of the HBase's one.</description>
      <version>None</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="1381" opendate="2009-5-6 00:00:00" fixdate="2009-5-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove onelab and bloom filters files from hbase</summary>
      <description>Bloom filters were broken in 0.19 hbase. They probably won't be in 0.20.0 because discussion and experimentation has them using lots of RAM for questionable benefit. We'll reexamine in 0.21. Meantime, purge the onelab stuff and the bloom filter map files from hbase. They haven't been working and when we go back to bloomfilters, we'll pick up the onelab from the hadoop core project (or use jgrays' bloomfilter implementation because it might be more efficient).</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.onelab.test.TestFilter.java</file>
      <file type="M">src.test.org.onelab.test.StringKey.java</file>
      <file type="M">src.java.org.onelab.filter.RetouchedBloomFilter.java</file>
      <file type="M">src.java.org.onelab.filter.RemoveScheme.java</file>
      <file type="M">src.java.org.onelab.filter.Key.java</file>
      <file type="M">src.java.org.onelab.filter.HashFunction.java</file>
      <file type="M">src.java.org.onelab.filter.Filter.java</file>
      <file type="M">src.java.org.onelab.filter.DynamicBloomFilter.java</file>
      <file type="M">src.java.org.onelab.filter.CountingBloomFilter.java</file>
      <file type="M">src.java.org.onelab.filter.BloomFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.Hash.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.HalfMapFileReader.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.BloomFilterMapFile.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13812" opendate="2015-5-30 00:00:00" fixdate="2015-5-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Deleting of last Column Family of a table should not be allowed</summary>
      <description>In this test run (without master killing) of IntegrationTestDDLMasterFailover of HBASE-13470, the DeleteColumnFamilyAction tries to delete one of the column families of a selected table. When there is only 1 column family left, the delete didn't fail.console_tue_nokill_r3.log2015-05-20 02:34:30,934 INFO [Thread-5] hbase.IntegrationTestMasterFailover: Deleting column family: {NAME =&gt; 'cf-882743293', DATA_BLOCK_ENCODING =&gt; 'PREFIX', BLOOMFILTER =&gt; 'ROW', REPLICATION_SCOPE =&gt; '0', COMPRESSION =&gt; 'NONE', VERSIONS =&gt; '1', TTL =&gt; 'FOREVER', MIN_VERSIONS =&gt; '0', KEEP_DELETED_CELLS =&gt; 'FALSE', BLOCKSIZE =&gt; '65536', IN_MEMORY =&gt; 'false', BLOCKCACHE =&gt; 'true'} from table: ittable-0296278350...2015-05-20 02:34:35,269 INFO [Thread-5] hbase.IntegrationTestMasterFailover: Deleted column family: {NAME =&gt; 'cf-882743293', DATA_BLOCK_ENCODING =&gt; 'PREFIX', BLOOMFILTER =&gt; 'ROW', REPLICATION_SCOPE =&gt; '0', COMPRESSION =&gt; 'NONE', VERSIONS =&gt; '1', TTL =&gt; 'FOREVER', MIN_VERSIONS =&gt; '0', KEEP_DELETED_CELLS =&gt; 'FALSE', BLOCKSIZE =&gt; '65536', IN_MEMORY =&gt; 'false', BLOCKCACHE =&gt; 'true'} from table: ittable-0296278350...2015-05-20 02:34:35,383 INFO [Thread-14] hbase.IntegrationTestMasterFailover: No column families in table: 'ittable-0296278350'...Number of Tables: 49 Table: ittable-0372763896 rw families: 1 Table: ittable-0824340809 rw families: 1 Table: ittable-1400154361 rw families: 1 Table: ittable-1625415605 rw families: 0 Table: ittable-1501441540 rw families: 1 Table: ittable-0296278350 rw families: 0This should not be allowed.</description>
      <version>None</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin1.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestHFileArchiving.java</file>
    </fixedFiles>
  </bug>
  <bug id="13821" opendate="2015-6-1 00:00:00" fixdate="2015-6-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>WARN if hbase.bucketcache.percentage.in.combinedcache is set</summary>
      <description>HBASE-11520 improved configuration of bucket cache to no longer require hbase.bucketcache.percentage.in.combinedcache. This was done rather aggressively, with this previously mandatory configuration being ignored. This can result in RS crashes for unsuspecting users. We should add a WARN when hbase.bucketcache.percentage.in.combinedcache is set to make debugging the crash more straight forward.</description>
      <version>1.0.0,1.1.0,1.2.0,2.0.0</version>
      <fixedVersion>1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
    </fixedFiles>
  </bug>
  <bug id="13826" opendate="2015-6-2 00:00:00" fixdate="2015-6-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unable to create table when group acls are appropriately set.</summary>
      <description>Steps for reproducing the issue. Create user 'test' and group 'hbase-admin'. Grant global create permissions to 'hbase-admin'. Add user 'test' to 'hbase-admin' group. Create table operation for 'test' user will throw ADE.</description>
      <version>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.TableAuthManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="13846" opendate="2015-6-4 00:00:00" fixdate="2015-6-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Run MiniCluster on top of other MiniDfsCluster</summary>
      <description>Similar to how we don't start a mini-zk cluster when we already have one specified, this will skip starting a mini-dfs cluster if the user specifies a different one.</description>
      <version>0.98.14,1.2.0,1.1.1,2.0.0</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
    </fixedFiles>
  </bug>
  <bug id="13865" opendate="2015-6-8 00:00:00" fixdate="2015-8-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Increase the default value for hbase.hregion.memstore.block.multipler from 2 to 4 (part 2)</summary>
      <description>Its 4 in the book and 2 in a current master.</description>
      <version>2.0.0</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.2,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMinorCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMajorCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestClientPushback.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="13866" opendate="2015-6-8 00:00:00" fixdate="2015-6-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add endpoint coprocessor to the section hbase.coprocessor.region.classes in HBase book</summary>
      <description>hbase.coprocessor.region.classes Description A comma-separated list of Coprocessors that are loaded by default on all tables. For any override coprocessor method, these classes will be called in order. After implementing your own Coprocessor, just put it in HBase’s classpath and add the fully qualified class name here. A coprocessor can also be loaded on demand by setting HTableDescriptor.This must be more specific: not Coprocessors, but Region observers and endpoint coprocessors.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="13867" opendate="2015-6-8 00:00:00" fixdate="2015-10-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add endpoint coprocessor guide to HBase book</summary>
      <description>Endpoint coprocessors are very poorly documented.Coprocessor section of HBase book must be updated either with its own endpoint coprocessors HOW-TO guide or, at least, with the link(s) to some other guides. There is good description here:http://www.3pillarglobal.com/insights/hbase-coprocessors</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.cp.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="13868" opendate="2015-6-8 00:00:00" fixdate="2015-9-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Correct "Disable automatic splitting" section in HBase book</summary>
      <description>This recommendation is not correct for IncreasingToUpperBoundRegionSplitPolicy (which is default now)Disable Automatic SplittingTo disable automatic splitting, set hbase.hregion.max.filesize to a very large value, such as 100 GB It is not recommended to set it to its absolute maximum value of Long.MAX_VALUE.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0-alpha-3,2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="13869" opendate="2015-6-9 00:00:00" fixdate="2015-6-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix typo in HBase book</summary>
      <description>Typo in section's title:42.1.4. Variangle Length or Fixed Length Rowkeys</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.schema.design.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="1387" opendate="2009-5-7 00:00:00" fixdate="2009-6-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Before release verify all object sizes using Ryans&amp;#39; instrumented JVM trick</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.io.hfile.TestHFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.Bytes.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.LruHashMap.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HLogKey.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.hfile.HFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.HeapSize.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.Put.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13877" opendate="2015-6-9 00:00:00" fixdate="2015-6-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Interrupt to flush from TableFlushProcedure causes dataloss in ITBLL</summary>
      <description>ITBLL with 1.25B rows failed for me (and Stack as reported in https://issues.apache.org/jira/browse/HBASE-13811?focusedCommentId=14577834&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14577834) HBASE-13811 and HBASE-13853 fixed an issue with WAL edit filtering. The root cause this time seems to be different. It is due to procedure based flush interrupting the flush request in case the procedure is cancelled from an exception elsewhere. This leaves the memstore snapshot intact without aborting the server. The next flush, then flushes the previous memstore with the current seqId (as opposed to seqId from the memstore snapshot). This creates an hfile with larger seqId than what its contents are. Previous behavior in 0.98 and 1.0 (I believe) is that after flush prepare and interruption / exception will cause RS abort.</description>
      <version>None</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.snapshot.RegionServerSnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionMergeRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Region.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.flush.RegionServerFlushTableProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.flush.FlushTableSubprocedure.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
    </fixedFiles>
  </bug>
  <bug id="13883" opendate="2015-6-10 00:00:00" fixdate="2015-2-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix Memstore Flush section in HBase book</summary>
      <description>65.7.2. MemStore FlushA MemStore flush can be triggered under any of the conditions listed below. The minimum flush unit is per region, not at individual MemStore level. // SKIPPED 3. When the number of WAL per region server reaches the value specified in hbase.regionserver.max.logs, MemStores from various regions will be flushed out to disk to reduce WAL count. The flush order is based on time. Regions with the oldest MemStores are flushed first until WAL count drops below hbase.regionserver.max.logs.Section 3. requires clarification (reference to HBase version which supports this). Is it MultiWAL feature in 1.0?</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="13884" opendate="2015-6-10 00:00:00" fixdate="2015-3-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix Compactions section in HBase book</summary>
      <description>http://hbase.apache.org/book.html#_compactionBeing StuckWhen the MemStore gets too large, it needs to flush its contents to a StoreFile. However, a Store can only have hbase.hstore.blockingStoreFiles files, so the MemStore needs to wait for the number of StoreFiles to be reduced by one or more compactions. However, if the MemStore grows larger than hbase.hregion.memstore.flush.size, it is not able to flush its contents to a StoreFile. If the MemStore is too large and the number of StoreFiles is also too high, the algorithm is said to be "stuck". The compaction algorithm checks for this "stuck" situation and provides mechanisms to alleviate it.According to source code, this "stuck" situation has nothingg to do with MemStore size. // Stuck and not compacting enough (estimate). It is not guaranteed that we will be // able to compact more if stuck and compacting, because ratio policy excludes some // non-compacting files from consideration during compaction (see getCurrentEligibleFiles). int futureFiles = filesCompacting.isEmpty() ? 0 : 1; boolean mayBeStuck = (candidateFiles.size() - filesCompacting.size() + futureFiles) &gt;= storeConfigInfo.getBlockingFileCount();If the number of store files which are not being compacted yet exceeds blocking file count +(potentially)1 - we say that compaction may be stuck.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="13899" opendate="2015-6-14 00:00:00" fixdate="2015-6-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Jacoco instrumentation fails under jdk8</summary>
      <description>Moving the post-commit build for master to also cover jdk8 shows failures when attempting to instrument test for jacoco coverage.example: Exception in thread "main" java.lang.reflect.InvocationTargetException at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:483) at sun.instrument.InstrumentationImpl.loadClassAndStartAgent(InstrumentationImpl.java:386) at sun.instrument.InstrumentationImpl.loadClassAndCallPremain(InstrumentationImpl.java:401)Caused by: java.lang.RuntimeException: Class java/util/UUID could not be instrumented. at org.jacoco.agent.rt.internal_5d10cad.core.runtime.ModifiedSystemClassRuntime.createFor(ModifiedSystemClassRuntime.java:138) at org.jacoco.agent.rt.internal_5d10cad.core.runtime.ModifiedSystemClassRuntime.createFor(ModifiedSystemClassRuntime.java:99) at org.jacoco.agent.rt.internal_5d10cad.PreMain.createRuntime(PreMain.java:51) at org.jacoco.agent.rt.internal_5d10cad.PreMain.premain(PreMain.java:43) ... 6 moreCaused by: java.lang.NoSuchFieldException: $jacocoAccess at java.lang.Class.getField(Class.java:1695) at org.jacoco.agent.rt.internal_5d10cad.core.runtime.ModifiedSystemClassRuntime.createFor(ModifiedSystemClassRuntime.java:136) ... 9 moreFATAL ERROR in native method: processing of -javaagent failedAborted</description>
      <version>1.2.0,2.0.0</version>
      <fixedVersion>0.98.14,1.2.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="13913" opendate="2015-6-16 00:00:00" fixdate="2015-6-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RAT exclusion list missing asciidoctor support files</summary>
      <description>Add src/main/asciidoc/asciidoctor.css to RAT exclusion list in POM</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="13915" opendate="2015-6-16 00:00:00" fixdate="2015-6-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove EOL HBase versions from java and hadoop prereq tables</summary>
      <description>We don't need to know what Hadoop and Java versions we recommend / test one EOL versions in the current docs. That information is still in the old releases.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="13916" opendate="2015-6-16 00:00:00" fixdate="2015-6-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create MultiByteBuffer an aggregation of ByteBuffers</summary>
      <description>This is an aggregation of N ByteBuffers. The block when served directly by block cache buckets memory, we have the block data split across multiple byte buffers. This aggregate type (like ByteBuffer) will serve the HFileBlock data.This jira wil just provide the new data structure</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestByteBufferUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteBufferUtils.java</file>
      <file type="M">dev-support.test-patch.properties</file>
    </fixedFiles>
  </bug>
  <bug id="13917" opendate="2015-6-16 00:00:00" fixdate="2015-6-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove string comparison to identify request priority</summary>
      <description>We have a couple of if (methodName.equalsIgnoreCase("scan")) { ScanRequest req = (ScanRequest)parm; } we can replace that string comparison with an instanceof</description>
      <version>None</version>
      <fixedVersion>1.2.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.AnnotationReadingPriorityFunction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor.java</file>
    </fixedFiles>
  </bug>
  <bug id="13930" opendate="2015-6-18 00:00:00" fixdate="2015-6-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Exclude Findbugs packages from shaded jars</summary>
      <description>Looking at 1.1.1RC0 shaded artifacts, looks like classes from find bugs are under the edu prefix and are not shaded. We should exclude find bugs from the shaded builds, and/or shade shade the edu prefix as well.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.1.2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shaded.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="13933" opendate="2015-6-18 00:00:00" fixdate="2015-6-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>DBE&amp;#39;s seekBefore with tags corrupts the tag&amp;#39;s offset information thus leading to incorrect results</summary>
      <description>The problem occurs with moveToPrevious() case and incase of tags we copy the previous pointer's tag info to the current because already decoded the tags.Will check once again before I post other details. I have a test case to reproduce the problem. Found this while working with MultibyteBuffers and verified if this is present in trunk - it is in all branches where we have tags compression (I suppose) will verify</description>
      <version>1.0.0,1.0.1,1.1.0,0.98.13,1.0.1.1,1.1.0.1,2.0.0</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.1,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestSeekTo.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
    </fixedFiles>
  </bug>
  <bug id="13950" opendate="2015-6-23 00:00:00" fixdate="2015-6-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a NoopProcedureStore for testing</summary>
      <description>Add a NoopProcedureStore and an helper in ProcedureTestingUtil to submitAndWait() a procedure without having to do anything else.This is useful to avoid extra code like in case of TestAssignmentManager.processServerShutdownHandler()</description>
      <version>1.2.0,2.0.0</version>
      <fixedVersion>1.2.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.ProcedureTestingUtility.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="13954" opendate="2015-6-23 00:00:00" fixdate="2015-7-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove HTableInterface#getRowOrBefore related server side code</summary>
      <description>As part of HBASE-13214 review, anoop.hbase had a review comment on the review board to remove all the server side related code for getRowOrBefore.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.resources.org.apache.hadoop.hbase.thrift.Hbase.thrift</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.Hbase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestWithDisabledAuthorization.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMinVersions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestGetClosestAtOrBefore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.SimpleRegionObserver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSideNoCodec.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Region.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.GetClosestRowBeforeTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultMemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HTableWrapper.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Client.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ClientProtos.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestGet.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestClientNoCluster.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Get.java</file>
    </fixedFiles>
  </bug>
  <bug id="13956" opendate="2015-6-23 00:00:00" fixdate="2015-6-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add myself as 1.1 release manager</summary>
      <description>Just saw we have an RM section. Add myself.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="1399" opendate="2009-5-9 00:00:00" fixdate="2009-5-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cant delete tables since 1398</summary>
      <description>since my patch, I cant drop tables.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.master.TableOperation.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="14013" opendate="2015-7-2 00:00:00" fixdate="2015-7-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Retry when RegionServerNotYetRunningException rather than go ahead with assign so for sure we don&amp;#39;t skip WAL replay</summary>
      <description>Patches are copied from parent. They were done by enis +1 from. They continue the theme of the parent applying it to RegionServerNotYetRunningException as well as the new region aborting exception .. added in parent issue.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.1.2,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="14058" opendate="2015-7-10 00:00:00" fixdate="2015-7-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Stabilizing default heap memory tuner</summary>
      <description>The memory tuner works well in general cases but when we have a work load that is both read heavy as well as write heavy the tuner does too many tuning. We should try to control the number of tuner operation and stabilize it. The main problem was that the tuner thinks it is in steady state even if it sees just one neutral tuner period thus does too many tuning operations and too many reverts that too with large step sizes(step size was set to maximum even after one neutral period). So to stop this I have thought of these steps:1) The division created by μ + δ/2 and μ - δ/2 is too small. Statistically ~62% periods will lie outside this range, which means 62% of the data points are considered either high or low which is too much. Use μ + δ*0.8 and μ - δ*0.8 instead. On expectations it will decrease number of tuner operations per 100 periods from 19 to just 10. If we use δ/2 then 31% of data values will be considered to be high and 31% will be considered to be low (2*0.31 * 0.31 = 0.19), on the other hand if we use δ*0.8 then 22% will be low and 22% will be high(2*0.22*0.22 ~ 0.10).2) Defining proper steady state by looking at past few periods(it is equal to hbase.regionserver.heapmemory.autotuner.lookup.periods) rather than just last tuner operation. We say tuner is in steady state when last few tuner periods were NEUTRAL. We keep decreasing step size unless it is extremely low. Then leave system in that state for some time.3) Rather then decreasing step size only while reverting, decrease the magnitude of step size whenever we are trying to revert tuning done in last few periods(sum the changes of last few periods and compare to current step) rather than just looking at last period. When its magnitude gets too low then make tuner steps NEUTRAL(no operation). This will cause step size to continuously decrease unless we reach steady state. After that tuning process will restart (tuner step size rests again when we reach steady state).4) The tuning done in last few periods will be decaying sum of past tuner steps with sign. This parameter will be positive for increase in memstore and negative for increase in block cache. Rather than using arithmetic mean we use this to give more priority to recent tuner steps.Please see the attachments. One represents the size of memstore(green) and size of block cache(blue) adjusted by tuner without these modification and other with the above modifications. The x-axis is time axis and y-axis is the fraction of heap memory available to memstore and block cache at that time(it always sums up to 80%). I configured min/max ranges for both components to 0.1 and 0.7 respectively(so in the plots the y-axis min and max is 0.1 and 0.7). In both cases the tuner tries to distribute memory by giving ~15% to memstore and ~65% to block cache. But the modified one does it much more smoothly.I got these results from YCSB test. The test was doing approximately 5000 inserts and 500 reads per second (for one region server). The results can be further fine tuned and number of tuner operation can be reduced with these changes in configuration.For more fine tuning:a) lower max step size (suggested = 4%)b) lower min step size ( default if also fine )To further decrease frequency of tuning operations:c) increase the number of lookup periods ( in the tests it was just 10, default is 60 )d) increase tuner period ( in the tests it was just 20 secs, default is 60secs)I used smaller tuner period/ number of look up periods to get more data points.</description>
      <version>1.2.0,1.3.0,2.0.0</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultHeapMemoryTuner.java</file>
    </fixedFiles>
  </bug>
  <bug id="14073" opendate="2015-7-14 00:00:00" fixdate="2015-7-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestRemoteTable.testDelete failed in the latest trunk code</summary>
      <description>TestRemoteTable.testDelete failed in the latest trunk code."excepted null, but was: &lt;B@615c4156&gt;"</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="14077" opendate="2015-7-14 00:00:00" fixdate="2015-7-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add package to hbase-protocol protobuf files.</summary>
      <description>c++ generated code is currently in the default namespace. That's bad practice; so lets fix it</description>
      <version>1.2.0,1.3.0,2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-protocol.src.main.protobuf.MapReduce.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.ZooKeeper.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.WAL.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.VisibilityLabels.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Tracing.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Snapshot.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.SecureBulkLoad.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.RPC.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.RowProcessor.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.RegionServerStatus.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Quota.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Procedure.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.MultiRowMutation.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.MasterProcedure.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Master.proto</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.coprocessor.example.generated.BulkDeleteProtos.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.coprocessor.example.generated.ExampleProtos.java</file>
      <file type="M">hbase-examples.src.main.protobuf.BulkDelete.proto</file>
      <file type="M">hbase-examples.src.main.protobuf.Examples.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.AdminProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.AggregateProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.AuthenticationProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.CellProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ClientProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.EncryptionProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ErrorHandlingProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.FilterProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.FSProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.HFileProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.LoadBalancerProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MapReduceProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MasterProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MultiRowMutationProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ProcedureProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.RowProcessorProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.RPCProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.SecureBulkLoadProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.TracingProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.VisibilityLabelsProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.WALProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.AccessControl.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Admin.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Aggregate.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Authentication.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Cell.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Client.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.ClusterId.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.ClusterStatus.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Comparator.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Encryption.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.ErrorHandling.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Filter.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.FS.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.HBase.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.HFile.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.LoadBalancer.proto</file>
    </fixedFiles>
  </bug>
  <bug id="14086" opendate="2015-7-15 00:00:00" fixdate="2015-7-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>remove unused bundled dependencies</summary>
      <description>We have some files with compatible non-ASL licenses that don't appear to be used, so remove them.</description>
      <version>None</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.2,1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.site.resources.css.freebsd.docbook.css</file>
      <file type="M">src.main.asciidoc.asciidoctor.css</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="14087" opendate="2015-7-15 00:00:00" fixdate="2015-8-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ensure correct ASF policy compliant headers on source/docs</summary>
      <description>we have a couple of files that are missing their headers. we have one file using old-style ASF copyrights</description>
      <version>None</version>
      <fixedVersion>1.0.2,1.2.0,1.1.2,1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-native-client.src.rpc.CMakeLists.txt</file>
      <file type="M">src.main.xslt.configuration.to.asciidoc.chapter.xsl</file>
      <file type="M">src.main.site.xdoc.sponsors.xml</file>
      <file type="M">src.main.site.xdoc.resources.xml</file>
      <file type="M">src.main.site.xdoc.replication.xml</file>
      <file type="M">src.main.site.xdoc.pseudo-distributed.xml</file>
      <file type="M">src.main.site.xdoc.old.news.xml</file>
      <file type="M">src.main.site.xdoc.metrics.xml</file>
      <file type="M">src.main.site.xdoc.index.xml</file>
      <file type="M">src.main.site.xdoc.export.control.xml</file>
      <file type="M">src.main.site.xdoc.cygwin.xml</file>
      <file type="M">src.main.site.xdoc.bulk-loads.xml</file>
      <file type="M">src.main.site.xdoc.acid-semantics.xml</file>
      <file type="M">src.main.site.asciidoc.sponsors.adoc</file>
      <file type="M">src.main.site.asciidoc.resources.adoc</file>
      <file type="M">src.main.site.asciidoc.replication.adoc</file>
      <file type="M">src.main.site.asciidoc.pseudo-distributed.adoc</file>
      <file type="M">src.main.site.asciidoc.old.news.adoc</file>
      <file type="M">src.main.site.asciidoc.metrics.adoc</file>
      <file type="M">src.main.site.asciidoc.index.adoc</file>
      <file type="M">src.main.site.asciidoc.export.control.adoc</file>
      <file type="M">src.main.site.asciidoc.cygwin.adoc</file>
      <file type="M">src.main.site.asciidoc.bulk-loads.adoc</file>
      <file type="M">src.main.site.asciidoc.acid-semantics.adoc</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.HttpAuthenticationException.java</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.enable.table.replication.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.disable.table.replication.rb</file>
      <file type="M">hbase-server.src.test.resources.org.apache.hadoop.hbase.PerformanceEvaluation.Counter.properties</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestPrefetch.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestNullComparator.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestFuzzyRowAndColumnRangeFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestBitComparator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ProtoUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationLoad.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.JarFinder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HealthChecker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HealthCheckChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.EndpointObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseRegionServerObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.model.TestModelBase.java</file>
      <file type="M">hbase-native-client.src.sync.CMakeLists.txt</file>
      <file type="M">bin.considerAsDead.sh</file>
      <file type="M">bin.graceful.stop.sh</file>
      <file type="M">bin.hbase</file>
      <file type="M">bin.hbase-config.sh</file>
      <file type="M">bin.hbase-daemon.sh</file>
      <file type="M">bin.hbase-daemons.sh</file>
      <file type="M">bin.local-master-backup.sh</file>
      <file type="M">bin.local-regionservers.sh</file>
      <file type="M">bin.master-backup.sh</file>
      <file type="M">bin.regionservers.sh</file>
      <file type="M">bin.rolling-restart.sh</file>
      <file type="M">bin.start-hbase.sh</file>
      <file type="M">bin.stop-hbase.sh</file>
      <file type="M">bin.zookeepers.sh</file>
      <file type="M">conf.hadoop-metrics2-hbase.properties</file>
      <file type="M">conf.hbase-env.sh</file>
      <file type="M">conf.log4j.properties</file>
      <file type="M">dev-support.hbase.docker.README.md</file>
      <file type="M">dev-support.hbase.jdiff.acrossSingularityTemplate.xml</file>
      <file type="M">dev-support.hbase.jdiff.afterSingularityTemplate.xml</file>
      <file type="M">dev-support.hbase.jdiff.template.xml</file>
      <file type="M">dev-support.jdiffHBasePublicAPI.sh</file>
      <file type="M">dev-support.jdiffHBasePublicAPI.common.sh</file>
      <file type="M">dev-support.jenkinsEnv.sh</file>
      <file type="M">dev-support.publish.hbase.website.sh</file>
      <file type="M">dev-support.rebase.all.git.branches.sh</file>
      <file type="M">dev-support.smart-apply-patch.sh</file>
      <file type="M">dev-support.test-patch.sh</file>
      <file type="M">dev-support.test-util.sh</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RetriesExhaustedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.Coprocessor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.CoprocessorEnvironment.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.DroppedSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableExistsException.java</file>
      <file type="M">hbase-client.src.main.resources.META-INF.services.org.apache.hadoop.security.token.TokenIdentifier</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.LimitInputStream.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.AbstractByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.SimpleMutableByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.SimplePositionedMutableByteRange.java</file>
      <file type="M">hbase-examples.src.main.cpp.DemoClient.cpp</file>
      <file type="M">hbase-examples.src.main.cpp.Makefile</file>
      <file type="M">hbase-examples.src.main.perl.DemoClient.pl</file>
      <file type="M">hbase-examples.src.main.php.DemoClient.php</file>
      <file type="M">hbase-native-client.CMakeLists.txt</file>
      <file type="M">hbase-native-client.cmake.modules.FindGTest.cmake</file>
      <file type="M">hbase-native-client.cmake.modules.FindLibEv.cmake</file>
      <file type="M">hbase-native-client.README.md</file>
      <file type="M">hbase-native-client.src.async.CMakeLists.txt</file>
      <file type="M">hbase-native-client.src.core.CMakeLists.txt</file>
    </fixedFiles>
  </bug>
  <bug id="14092" opendate="2015-7-15 00:00:00" fixdate="2015-8-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbck should run without locks by default and only disable the balancer when necessary</summary>
      <description>HBCK is sometimes used as a way to check the health of the cluster. When doing that it's not necessary to turn off the balancer. As such it's not needed to lock other runs of hbck out.We should add the --no-lock and --no-balancer command line flags.</description>
      <version>1.3.0,2.0.0</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="14097" opendate="2015-7-16 00:00:00" fixdate="2015-7-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Log link to client scan troubleshooting section when scanner exceptions happen.</summary>
      <description>As per description.</description>
      <version>None</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.2,1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="14098" opendate="2015-7-16 00:00:00" fixdate="2015-8-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow dropping caches behind compactions</summary>
      <description></description>
      <version>1.3.0,2.0.0</version>
      <fixedVersion>1.2.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStripeCompactor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestReversibleScanners.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMobStoreCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestFSErrorsExposed.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.compactions.TestStripeCompactionPolicy.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mob.compactions.TestPartitionedMobCompactor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestCacheOnWrite.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StripeStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.StripeCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.Compactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.MobFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.DefaultMobStoreCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.compactions.PartitionedMobCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.FSDataInputStreamWrapper.java</file>
    </fixedFiles>
  </bug>
  <bug id="14100" opendate="2015-7-16 00:00:00" fixdate="2015-7-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix high priority findbugs warnings</summary>
      <description>See here:https://builds.apache.org/job/HBase-TRUNK/6654/findbugsResult/HIGH/We have 6 high priority findbugs warnings. A high priority findbugs warning is usually a bug.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.1.2,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.BloomFilterUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.RateLimiter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.FixedIntervalRateLimiter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.AverageIntervalRateLimiter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.normalizer.SimpleRegionNormalizer.java</file>
    </fixedFiles>
  </bug>
  <bug id="14102" opendate="2015-7-16 00:00:00" fixdate="2015-7-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add thank you to our thanks page for vectorportal.com</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.site.asciidoc.sponsors.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="14123" opendate="2015-7-20 00:00:00" fixdate="2015-3-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase Backup/Restore Phase 2</summary>
      <description>Phase 2 umbrella JIRA. See HBASE-7912 for design document and description.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Umbrella</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.procedure.TestZKProcedureControllers.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.procedure.TestZKProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.procedure.SimpleMasterProcedureManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.AbstractFSWALProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureCoordinatorRpcs.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.flush.MasterFlushTableProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.WALPlayer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.WALInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.BaseCoordinatedStateManager.java</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProtos.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.AbstractHBaseTool.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug id="1413" opendate="2009-5-12 00:00:00" fixdate="2009-5-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>fall back to filesystem block size default if hbase.regionserver.hlog.blocksize is not specified</summary>
      <description>Fall back to filesystem block size default if hbase.regionserver.hlog.blocksize is not specified.</description>
      <version>None</version>
      <fixedVersion>0.19.3</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HLog.java</file>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="14135" opendate="2015-7-21 00:00:00" fixdate="2015-8-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase Backup/Restore Phase 3: Merge backup images</summary>
      <description>User can merge incremental backup images into single incremental backup image. Merge supports only incremental images Merge supports only images for the same backup destinationsCommand:hbase backup merge image1,image2,..imageKExample:hbase backup merge backup_143126764557,backup_143126764456 When operation is complete, only the most recent backup image will be kept (in above example - backup_143126764557) as a merged backup image, all other images will be deleted from both: file system and backup system tables, corresponding backup manifest for the merged backup image will be updated to remove dependencies from deleted images. Merged backup image will contains all the data from original image and from deleted images.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestRepairAfterFailedDelete.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.util.BackupUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.mapreduce.MapReduceRestoreJob.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.mapreduce.HFileSplitterJob.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.impl.RestoreTablesClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupSystemTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupManifest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupCommands.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupAdminImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.HBackupFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupRestoreFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupDriver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="14144" opendate="2015-7-22 00:00:00" fixdate="2015-8-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bloomfilter path to work with Byte buffered cells</summary>
      <description>This JIRA is to check if there will be a need to make the bloom filters to work with ByteBuffer cells. During POC this path created lot of duplicated code but considering other refactorings done in this path may lead to less duplication. This JIRA is a placeholder.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CompoundBloomFilter.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="14152" opendate="2015-7-23 00:00:00" fixdate="2015-7-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix the warnings in Checkstyle and FindBugs brought in by merging hbase-11339</summary>
      <description>There are some new warnings in Checkstyle and FindBugs brought in by merging the feature branch hbase-11339 to trunk.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HMobStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.mapreduce.SweepJob.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ExpiredMobFileCleanerChore.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="14156" opendate="2015-7-26 00:00:00" fixdate="2015-7-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix test failure in TestOpenTableInCoprocessor</summary>
      <description>This is after HBASE-12295 went in</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="14158" opendate="2015-7-28 00:00:00" fixdate="2015-10-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add documentation for Initial Release for HBase-Spark Module integration</summary>
      <description>Add documentation for Initial Release for HBase-Spark Module integration</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,connector-1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc.book.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="14162" opendate="2015-7-28 00:00:00" fixdate="2015-7-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fixing maven target for regenerating thrift classes fails against 0.9.2</summary>
      <description>HBASE-14045 updated the thrift version, but our enforcer rule is still checking 0.9.0.$ git checkout masterSwitched to branch 'master'Your branch is up-to-date with 'origin/master'.$ mvn compile -Pcompile-thrift -DskipTests[INFO] Scanning for projects...... SNIP ...[INFO] ------------------------------------------------------------------------[INFO] Building HBase - Thrift 2.0.0-SNAPSHOT[INFO] ------------------------------------------------------------------------[INFO] [INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce) @ hbase-thrift ---[INFO] [INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-thrift-version) @ hbase-thrift ---[WARNING] Rule 0: org.apache.maven.plugins.enforcer.RequireProperty failed with message:--[FATAL] ==========================================================================================[FATAL] HBase Thrift requires the thrift generator version 0.9.0.[FATAL] Setting it to something else needs to be reviewed for wire and behavior compatibility.[FATAL] ==========================================================================================--[INFO] ------------------------------------------------------------------------[INFO] Reactor Summary:[INFO] [INFO] HBase .............................................. SUCCESS [ 2.897 s][INFO] HBase - Checkstyle ................................. SUCCESS [ 0.554 s][INFO] HBase - Annotations ................................ SUCCESS [ 0.940 s][INFO] HBase - Protocol ................................... SUCCESS [ 15.454 s][INFO] HBase - Common ..................................... SUCCESS [ 8.984 s][INFO] HBase - Procedure .................................. SUCCESS [ 1.982 s][INFO] HBase - Client ..................................... SUCCESS [ 6.805 s][INFO] HBase - Hadoop Compatibility ....................... SUCCESS [ 0.202 s][INFO] HBase - Hadoop Two Compatibility ................... SUCCESS [ 1.393 s][INFO] HBase - Prefix Tree ................................ SUCCESS [ 1.233 s][INFO] HBase - Server ..................................... SUCCESS [ 13.841 s][INFO] HBase - Testing Util ............................... SUCCESS [ 2.979 s][INFO] HBase - Thrift ..................................... FAILURE [ 0.234 s][INFO] HBase - Shell ...................................... SKIPPED[INFO] HBase - Integration Tests .......................... SKIPPED[INFO] HBase - Examples ................................... SKIPPED[INFO] HBase - Rest ....................................... SKIPPED[INFO] HBase - Assembly ................................... SKIPPED[INFO] HBase - Shaded ..................................... SKIPPED[INFO] HBase - Shaded - Client ............................ SKIPPED[INFO] HBase - Shaded - Server ............................ SKIPPED[INFO] Apache HBase - Spark ............................... SKIPPED[INFO] ------------------------------------------------------------------------[INFO] BUILD FAILURE[INFO] ------------------------------------------------------------------------[INFO] Total time: 01:00 min[INFO] Finished at: 2015-07-28T12:36:15-05:00[INFO] Final Memory: 84M/1038M[INFO] ------------------------------------------------------------------------[ERROR] Failed to execute goal org.apache.maven.plugins:maven-enforcer-plugin:1.3.1:enforce (enforce-thrift-version) on project hbase-thrift: Some Enforcer rules have failed. Look above for specific messages explaining why the rule failed. -&gt; [Help 1][ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.[ERROR] Re-run Maven using the -X switch to enable full debug logging.[ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles:[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException[ERROR] [ERROR] After correcting the problems, you can resume the build with the command[ERROR] mvn &lt;goals&gt; -rf :hbase-thrift</description>
      <version>1.3.0,2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="14172" opendate="2015-7-30 00:00:00" fixdate="2015-11-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade existing thrift binding using thrift 0.9.3 compiler.</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TScan.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TRowResult.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TRegionInfo.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TIncrement.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TColumn.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TCell.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TAppend.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.Mutation.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.IOError.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.IllegalArgument.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.Hbase.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.ColumnDescriptor.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.BatchMutation.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.AlreadyExists.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TTimeRange.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TServerName.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TScan.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TRowMutations.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TResult.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TPut.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TMutation.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIOError.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIncrement.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIllegalArgument.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.THRegionLocation.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.THRegionInfo.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.THBaseService.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TGet.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TDurability.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TDeleteType.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TDelete.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumnValue.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumnIncrement.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumn.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TCellVisibility.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TAuthorization.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TAppend.java</file>
      <file type="M">hbase-thrift.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="14201" opendate="2015-8-10 00:00:00" fixdate="2015-8-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbck should not take a lock unless fixing errors</summary>
      <description>By default, hbck is run in a read-only checker mode. In this case, it issensible to let others run. By default, the balancer is left alone,which may cause spurious errors, but cannot leave the balancer in a badstate. It is dangerous to leave the balancer by accident, so it is onlyever enabled after fixing, it will never be forced off because ofracing.When hbck is run in fixer mode, it must take an exclusive lock anddisable the balancer, or all havoc will break loose.If you want to stop hbck from running in parallel, the -exclusive flagwill create the lock file. If you want to force -disableBalancer, thatoption is available too. This makes more semantic sense than -noLock and-noSwitchBalancer, respectively.This task is related to HBASE-14092.</description>
      <version>1.3.0,2.0.0</version>
      <fixedVersion>1.2.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.HbckTestingUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="14208" opendate="2015-8-11 00:00:00" fixdate="2015-8-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove yarn dependencies on -common and -client</summary>
      <description>They aren't really needed since MR can't be used without server.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.security.User.java</file>
      <file type="M">hbase-common.pom.xml</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.token.TokenUtil.java</file>
      <file type="M">hbase-client.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="14211" opendate="2015-8-11 00:00:00" fixdate="2015-10-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add more rigorous integration tests of splits</summary>
      <description>Add a chaos action that will turn down region size. Eventually this will cause regions to split a lot. It will need to have a min region size.Add a chaos monkey action that will change split policy Change between Uniform and SplittingUpTo and backAdd chaos monkey action that will request splits of every region. When regions all reach the size a the exact same time the compactions add a lot of work. This simulates a very well distributed write pattern reaching the region size.Add the ability to start with fewer regions than normal to ITBLL</description>
      <version>1.2.0,2.0.0</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.factories.StressAssignmentManagerMonkeyFactory.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.factories.SlowDeterministicMonkeyFactory.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.factories.MonkeyConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="14212" opendate="2015-8-11 00:00:00" fixdate="2015-9-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add IT test for procedure-v2-based namespace DDL</summary>
      <description>Integration test for proc-v2-based table DDLs was created in HBASE-12439 during HBASE 1.1 release. With HBASE-13212, proc-v2-based namespace DDLs are introduced. We need to enhanced the IT from HBASE-12429 to include namespace DDLs.</description>
      <version>1.3.0,2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestDDLMasterFailover.java</file>
    </fixedFiles>
  </bug>
  <bug id="14224" opendate="2015-8-14 00:00:00" fixdate="2015-8-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix coprocessor handling of duplicate classes</summary>
      <description>While discussing with misty over on HBASE-13907 we noticed some inconsistency when copros are loaded. Sometimes you can load them more than once, sometimes you can not. Need to consolidate.</description>
      <version>1.0.1,1.2.0,1.1.1,2.0.0</version>
      <fixedVersion>1.0.2,1.2.0,1.3.0,0.98.15,1.1.3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorHost.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.TestHTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="14249" opendate="2015-8-19 00:00:00" fixdate="2015-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>shaded jar modules create spurious source and test jars with incorrect LICENSE/NOTICE info</summary>
      <description>the shaded jar modules don't need to create a source or test jar (because the jars contain nothing other than META-INF)currently we create the test jars are missing LICENSE source jars have LICENSE/NOTICE files that claim all the bundled works in the normal jar.hbase-1.1.2-rc0 busbey$ find hbase-shaded-server-1.1.2-sources.jar/hbase-shaded-server-1.1.2-sources.jar/hbase-shaded-server-1.1.2-sources.jar//META-INFhbase-shaded-server-1.1.2-sources.jar//META-INF/LICENSEhbase-shaded-server-1.1.2-sources.jar//META-INF/MANIFEST.MFhbase-shaded-server-1.1.2-sources.jar//META-INF/NOTICEhbase-1.1.2-rc0 busbey$ find hbase-shaded-client-1.1.2-sources.jar/hbase-shaded-client-1.1.2-sources.jar/hbase-shaded-client-1.1.2-sources.jar//META-INFhbase-shaded-client-1.1.2-sources.jar//META-INF/LICENSEhbase-shaded-client-1.1.2-sources.jar//META-INF/MANIFEST.MFhbase-shaded-client-1.1.2-sources.jar//META-INF/NOTICEhbase-1.1.2-rc0 busbey$ find hbase-shaded-client-1.1.2-tests.jar/hbase-shaded-client-1.1.2-tests.jar/hbase-shaded-client-1.1.2-tests.jar//META-INFhbase-shaded-client-1.1.2-tests.jar//META-INF/NOTICEhbase-1.1.2-rc0 busbey$ find hbase-shaded-server-1.1.2-tests.jar/hbase-shaded-server-1.1.2-tests.jar/hbase-shaded-server-1.1.2-tests.jar//META-INFhbase-shaded-server-1.1.2-tests.jar//META-INF/NOTICE</description>
      <version>1.2.0,1.1.2,1.3.0,2.0.0</version>
      <fixedVersion>1.2.0,1.1.2,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shaded.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="14250" opendate="2015-8-19 00:00:00" fixdate="2015-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>branch-1.1 hbase-server test-jar has incorrect LICENSE</summary>
      <description>test-jar LICENSE file for hbase-server claims jquery and the orca logo are present in the jar, when they are not.</description>
      <version>1.2.0,1.1.2,1.3.0,0.98.15,1.0.3,2.0.0</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.2,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="14251" opendate="2015-8-19 00:00:00" fixdate="2015-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>javadoc jars use LICENSE/NOTICE from primary artifact</summary>
      <description>Our generated javadoc jars have the same LICENSE/NOTICE files as our primary artifacts but do not include a copy of hte full source.the following modules end up with incorrect artifacts: hbase-server hbase-common (maybe? depends on the are-apis-copyrightable court case) hbase-thrift</description>
      <version>1.2.0,1.1.2,0.98.15,1.0.3,2.0.0</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.2,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.pom.xml</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-common.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="14253" opendate="2015-8-19 00:00:00" fixdate="2015-9-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>update docs + build for maven 3.0.4+</summary>
      <description>our new hbase-spark module raises our minimum maven version from 3.0.0 (though I've only tried 3.0.3) to 3.0.4:[ERROR] Failed to execute goal net.alchim31.maven:scala-maven-plugin:3.2.0:add-source (scala-compile-first) on project hbase-spark: The plugin net.alchim31.maven:scala-maven-plugin:3.2.0 requires Maven version 3.0.4 -&gt; [Help 1]Update the docs to call out 3.0.4 and add an enforcer rule so that this failure can happen at the start of a build rather than 15 minutes in.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="14260" opendate="2015-8-19 00:00:00" fixdate="2015-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>don&amp;#39;t build javadocs for hbase-protocol module</summary>
      <description>I'm not sure I have all the affected versions, but it seems that something is amiss in making our javadocs: mvn -Papache-release -Prelease -DskipTests clean package... SNIP ...[INFO] ------------------------------------------------------------------------[INFO] Reactor Summary:[INFO] [INFO] Apache HBase ....................................... SUCCESS [ 11.149 s][INFO] Apache HBase - Checkstyle .......................... SUCCESS [ 1.249 s][INFO] Apache HBase - Resource Bundle ..................... SUCCESS [ 0.539 s][INFO] Apache HBase - Annotations ......................... SUCCESS [ 4.438 s][INFO] Apache HBase - Protocol ............................ SUCCESS [10:15 min][INFO] Apache HBase - Common .............................. SUCCESS [ 48.465 s][INFO] Apache HBase - Procedure ........................... SUCCESS [ 14.375 s][INFO] Apache HBase - Client .............................. SUCCESS [ 45.187 s][INFO] Apache HBase - Hadoop Compatibility ................ SUCCESS [ 6.998 s][INFO] Apache HBase - Hadoop Two Compatibility ............ SUCCESS [ 14.891 s][INFO] Apache HBase - Prefix Tree ......................... SUCCESS [ 14.214 s][INFO] Apache HBase - Server .............................. SUCCESS [02:01 min][INFO] Apache HBase - Testing Util ........................ SUCCESS [ 12.779 s][INFO] Apache HBase - Thrift .............................. SUCCESS [01:15 min][INFO] Apache HBase - Shell ............................... SUCCESS [ 6.649 s][INFO] Apache HBase - Integration Tests ................... SUCCESS [ 6.429 s][INFO] Apache HBase - Examples ............................ SUCCESS [ 13.200 s][INFO] Apache HBase - Rest ................................ SUCCESS [ 27.831 s][INFO] Apache HBase - Assembly ............................ SUCCESS [ 19.400 s][INFO] Apache HBase - Shaded .............................. SUCCESS [ 0.419 s][INFO] Apache HBase - Shaded - Client ..................... SUCCESS [ 23.707 s][INFO] Apache HBase - Shaded - Server ..................... SUCCESS [ 43.654 s][INFO] Apache HBase - Spark ............................... SUCCESS [02:22 min][INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 21:13 min[INFO] Finished at: 2015-08-19T15:48:00-05:00[INFO] Final Memory: 181M/1513M[INFO] ------------------------------------------------------------------------</description>
      <version>0.98.0,1.0.0,1.1.0,1.2.0,2.0.0</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.2,1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-protocol.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="14261" opendate="2015-8-19 00:00:00" fixdate="2015-9-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enhance Chaos Monkey framework by adding zookeeper and datanode fault injections.</summary>
      <description>One of the shortcomings of existing ChaosMonkey framework is lack of fault injections for hbase dependencies like zookeeper, hdfs etc. This patch attempts to solve this problem partially by adding datanode and zk node fault injections.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,0.98.15,1.0.3,1.1.3,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MiniHBaseCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseCluster.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.RESTApiClusterManager.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.HBaseClusterManager.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.DistributedHBaseCluster.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.ClusterManager.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.factories.MonkeyFactory.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.RestartActionBaseAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.Action.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKServerTool.java</file>
    </fixedFiles>
  </bug>
  <bug id="14271" opendate="2015-8-20 00:00:00" fixdate="2015-10-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve Nexus staging instructions</summary>
      <description>Refine the Nexus staging instructions a bit. (A promise I made a long time ago.)</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="14292" opendate="2015-8-22 00:00:00" fixdate="2015-10-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Call Me Maybe HBase links haved moved</summary>
      <description>The links to the Yammer engineering blog have moved.Please use the following links in section 83.5. Network Consistency and Partition Tolerancehttp://old.eng.yammer.com/call-me-maybe-hbase/http://old.eng.yammer.com/call-me-maybe-hbase-addendum/Thanks</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.performance.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="14302" opendate="2015-8-24 00:00:00" fixdate="2015-8-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TableSnapshotInputFormat should not create back references when restoring snapshot</summary>
      <description>TableSnapshotInputFormat restores the snapshot to a temporary directory that is outside the HBase's root directory so that it can read from the restored snapshot and also refer to hfiles in the actual root directory. In restoring the snapshot, we create new hfilelinks in the ephemeral location. Creating new hfile links also creates "back references" for GC. These back references are dangling since the restore location is outside the root dir, and requires a WRITE permission to the root dir (as opposed to just READ permission) to be able to run the MR-over-snapshot job.</description>
      <version>None</version>
      <fixedVersion>1.0.2,1.2.0,1.3.0,1.1.3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapred.TestTableSnapshotInputFormat.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableSnapshotInputFormat.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatTestBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ModifyRegionUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.HFileLink.java</file>
    </fixedFiles>
  </bug>
  <bug id="14325" opendate="2015-8-27 00:00:00" fixdate="2015-8-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add snapshotinfo command to hbase script</summary>
      <description>Since we already have commands like hbck, hfile, wal etc. that are used for getting various types of information about HBase components it make sense to me to add SnapshotInfo tool to collection. If nobody objects i would add patch for this.</description>
      <version>1.2.0,2.0.0</version>
      <fixedVersion>1.2.0,0.98.15,1.0.3,1.1.3,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug id="14326" opendate="2015-8-27 00:00:00" fixdate="2015-10-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase book: fix definition of max min size to compact</summary>
      <description>I think we need to change wording/definition of these config parameters in HBase book, they are misleading:hbase.hstore.compaction.min.sizeDescriptionA StoreFile smaller than this size will always be eligible for minor compaction. HFiles this size or larger are evaluated by hbase.hstore.compaction.ratio to determine if they are eligible. Because this limit represents the "automatic include"limit for all StoreFiles smaller than this value, this value may need to be reduced in write-heavy environments where many StoreFiles in the 1-2 MB range are being flushed, because every StoreFile will be targeted for compaction and the resulting StoreFiles may still be under the minimum size and require further compaction. If this parameter is lowered, the ratio check is triggered more quickly. This addressed some issues seen in earlier versions of HBase but changing this parameter is no longer necessary in most situations. Default: 128 MB expressed in bytes.Default134217728hbase.hstore.compaction.max.sizeDescriptionA StoreFile larger than this size will be excluded from compaction. The effect of raising hbase.hstore.compaction.max.size is fewer, larger StoreFiles that do not get compacted often. If you feel that compaction is happening too often without much benefit, you can try raising this value. Default: the value of LONG.MAX_VALUE, expressed in bytes.hbase.hstore.compaction.ratioDescriptionFor minor compaction, this ratio is used to determine whether a given StoreFile which is larger than hbase.hstore.compaction.min.size is eligible for compaction. Its effect is to limit compaction of large StoreFiles. The value of hbase.hstore.compaction.ratio is expressed as a floating-point decimal. A large ratio, such as 10, will produce a single giant StoreFile. Conversely, a low value, such as .25, will produce behavior similar to the BigTable compaction algorithm, producing four StoreFiles. A moderate value of between 1.0 and 1.4 is recommended. When tuning this value, you are balancing write costs with read costs. Raising the value (to something like 1.4) will have more write costs, because you will compact larger StoreFiles. However, during reads, HBase will need to seek through fewer StoreFiles to accomplish the read. Consider this approach if you cannot take advantage of Bloom filters. Otherwise, you can lower this value to something like 1.0 to reduce the background cost of writes, and use Bloom filters to control the number of StoreFiles touched during reads. For most cases, the default value is appropriate.Default1.2FFor details, see HBASE-14263.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="14332" opendate="2015-8-28 00:00:00" fixdate="2015-9-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Show the table state when we encounter exception while disabling / enabling table</summary>
      <description>This patch is a advice for good user experiencereason:When we disable a table and the table is not enabled,we receive a exception,but the exception is too brief,some time we want to know what state is the table in,so that we can know why the table can't be disable.For example,I once encountered a problem the table is neither disable nor enable when my region server crash down,if we give the table state,I will find the problem more quickly .</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.EnableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DisableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.EnableTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DisableTableHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="14338" opendate="2015-8-30 00:00:00" fixdate="2015-9-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>License notification misspells &amp;#39;Asciidoctor&amp;#39;</summary>
      <description>our License file contains 'asciidoctor' but with three "i"This project bundles a derivative of portions of the 'Asciiidoctor' projectunder the terms of the MIT license.</description>
      <version>1.2.0,1.1.2,1.3.0,2.0.0</version>
      <fixedVersion>1.2.0,1.3.0,1.0.3,1.1.3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">LICENSE.txt</file>
    </fixedFiles>
  </bug>
  <bug id="14340" opendate="2015-8-30 00:00:00" fixdate="2015-11-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add second bulk load option to Spark Bulk Load to send puts as the value</summary>
      <description>The initial bulk load option for Spark bulk load sends values over one by one through the shuffle. This is the similar to how the original MR bulk load worked.How ever the MR bulk loader have more then one bulk load option. There is a second option that allows for all the Column Families, Qualifiers, and Values or a row to be combined in the map side.This only works if the row is not super wide.But if the row is not super wide this method of sending values through the shuffle will reduce the data and work the shuffle has to deal with.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,connector-1.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.src.test.scala.org.apache.hadoop.hbase.spark.BulkLoadSuite.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.HBaseRDDFunctions.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.HBaseContext.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.BulkLoadPartitioner.scala</file>
    </fixedFiles>
  </bug>
  <bug id="14346" opendate="2015-8-31 00:00:00" fixdate="2015-10-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Typo in FamilyFilter</summary>
      <description>I think there's a typo. "qualifier name" should read "column family name"Family Filter This filter takes a compare operator and a comparator. It compares each qualifier name with the comparator using the compare operator and if the comparison returns true, it returns all the key-values in that column.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.thrift.filter.language.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="14348" opendate="2015-8-31 00:00:00" fixdate="2015-4-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update download mirror link</summary>
      <description>Where we refer to www.apache.org/dyn/closer.cgi, we need to refer towww.apache.org/dyn/closer.lua instead .</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.old.news.xml</file>
      <file type="M">src.site.xdoc.index.xml</file>
      <file type="M">src.site.site.xml</file>
      <file type="M">src.site.resources.doap.Hbase.rdf</file>
      <file type="M">src.site.asciidoc.old.news.adoc</file>
      <file type="M">src.main.asciidoc..chapters.getting.started.adoc</file>
      <file type="M">README.txt</file>
    </fixedFiles>
  </bug>
  <bug id="14349" opendate="2015-9-1 00:00:00" fixdate="2015-10-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>pre-commit zombie finder is overly broad</summary>
      <description>Zombie detector is flagging processes from builds that aren't ours.ex from HBASE-14337:-1 core zombie tests. There are 4 zombie test(s): at org.apache.reef.io.network.DeprecatedNetworkConnectionServiceTest.testMultithreadedSharedConnMessagingNetworkConnServiceRate(DeprecatedNetworkConnectionServiceTest.java:343)</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  <bug id="1438" opendate="2009-5-19 00:00:00" fixdate="2009-5-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBASE-1421 broke the build (#602 up on hudson).</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="14380" opendate="2015-9-8 00:00:00" fixdate="2015-9-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Correct data gets skipped along with bad data in importTsv bulk load thru TsvImporterTextMapper</summary>
      <description>Cosider the input data is as below ROWKEY, TIEMSTAMP, Col_Valuer1,1,v1 &gt;&gt; Correct liner1 &gt;&gt; Bad liner1,3,v3 &gt;&gt; Correct liner1,4,v4 &gt;&gt; Correct lineWhen data is bulk loaded using importTsv with mapper as TsvImporterTextMapper , All the lines are getting ignored even though skipBadLines is set to true.</description>
      <version>2.0.0</version>
      <fixedVersion>1.2.0,1.3.0,1.0.3,1.1.3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestImportTsv.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TextSortReducer.java</file>
    </fixedFiles>
  </bug>
  <bug id="14385" opendate="2015-9-9 00:00:00" fixdate="2015-9-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Close the sockets that is missing in connection closure.</summary>
      <description>As per heading. Due credit to one of our awesome customers for digging into this and helping me craft the unit test.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,1.0.3,1.1.3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClientImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="14387" opendate="2015-9-9 00:00:00" fixdate="2015-11-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compaction improvements: Maximum off-peak compaction size</summary>
      <description>Make max compaction size for peak and off peak separate config options.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerOnlineConfigChange.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.RatioBasedCompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration.java</file>
    </fixedFiles>
  </bug>
  <bug id="14398" opendate="2015-9-10 00:00:00" fixdate="2015-9-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create the fake keys required in the scan path to avoid copy to byte[]</summary>
      <description>Already we have created some fake keys for the ByteBufferedCells so that we can avoid the copy requried to create fake keys. This JIRA aims to fill up all such places so that the Offheap BBs are not copied to onheap byte[].</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="14406" opendate="2015-9-11 00:00:00" fixdate="2015-10-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The dataframe datasource filter is wrong, and will result in data loss or unexpected behavior</summary>
      <description>Following condition will result in the same filter. It will have data loss with the current filter construction.col1 &gt; 4 &amp;&amp; col2 &lt; 3col1 &gt; 4 || col2 &lt; 3</description>
      <version>2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,connector-1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.src.test.scala.org.apache.hadoop.hbase.spark.HBaseDStreamFunctionsSuite.scala</file>
      <file type="M">hbase-spark.src.test.scala.org.apache.hadoop.hbase.spark.DefaultSourceSuite.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.DefaultSource.scala</file>
      <file type="M">hbase-spark.src.main.java.org.apache.hadoop.hbase.spark.SparkSQLPushDownFilter.java</file>
      <file type="M">hbase-spark.pom.xml</file>
      <file type="M">hbase-protocol.src.main.protobuf.Filter.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.FilterProtos.java</file>
    </fixedFiles>
  </bug>
  <bug id="14433" opendate="2015-9-14 00:00:00" fixdate="2015-9-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Set down the client executor core thread count from 256 in tests</summary>
      <description>HBASE-10449 upped our core count from 0 to 256 (max is 256). Looking in a recent test run core dump, I see up to 256 threads per client and all are idle. At a minimum it makes it hard reading test thread dumps. Trying to learn more about why we went a core of 256 over in HBASE-10449. Meantime will try setting down configs for test.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.resources.hbase-site.xml</file>
      <file type="M">hbase-client.src.test.resources.hbase-site.xml</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
    </fixedFiles>
  </bug>
  <bug id="14462" opendate="2015-9-22 00:00:00" fixdate="2015-12-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>rolling_restart.sh --master-only throws "line 142: test: 0: unary operator expected"</summary>
      <description>I was trying to run this on distributed cluster (master branch build) and ended up with this error. Looking in to this,</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.rolling-restart.sh</file>
    </fixedFiles>
  </bug>
  <bug id="14464" opendate="2015-9-22 00:00:00" fixdate="2015-9-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Removed unused fs code</summary>
      <description>remove unused code related to fs</description>
      <version>2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestFSVisitor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestNamespace.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestMobExportSnapshot.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestExportSnapshot.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.snapshot.TestSnapshotManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.snapshot.TestSnapshotLogCleaner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.snapshot.TestSnapshotFileCache.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestMasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSVisitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotManifestV2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotManifestV1.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotManifest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.ExportSnapshot.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotLogCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
    </fixedFiles>
  </bug>
  <bug id="14466" opendate="2015-9-23 00:00:00" fixdate="2015-9-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove duplicated code from MOB snapshot tests</summary>
      <description>mob snapshots tests are just a copy paste of the base test with a different createTable to include mobs. remove the duplicated code and extend the base tests</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestRestoreSnapshotHelper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestRestoreFlushSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestMobRestoreSnapshotHelper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestMobRestoreFlushSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestMobFlushSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestMobExportSnapshot.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestFlushSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestExportSnapshot.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.SnapshotTestingUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.MobSnapshotTestingUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotCloneIndependence.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestRestoreSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMobSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMobSnapshotCloneIndependence.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMobRestoreSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMobCloneSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestCloneSnapshotFromClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="14468" opendate="2015-9-23 00:00:00" fixdate="2015-1-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compaction improvements: FIFO compaction policy</summary>
      <description>FIFO CompactionIntroductionFIFO compaction policy selects only files which have all cells expired. The column family MUST have non-default TTL. Essentially, FIFO compactor does only one job: collects expired store files. These are some applications which could benefit the most: Use it for very high volume raw data which has low TTL and which is the source of another data (after additional processing). Example: Raw time-series vs. time-based rollup aggregates and compacted time-series. We collect raw time-series and store them into CF with FIFO compaction policy, periodically we run task which creates rollup aggregates and compacts time-series, the original raw data can be discarded after that. Use it for data which can be kept entirely in a a block cache (RAM/SSD). Say we have local SSD (1TB) which we can use as a block cache. No need for compaction of a raw data at all.Because we do not do any real compaction, we do not use CPU and IO (disk and network), we do not evict hot data from a block cache. The result: improved throughput and latency both write and read.See: https://github.com/facebook/rocksdb/wiki/FIFO-compaction-styleTo enable FIFO compaction policyFor table:HTableDescriptor desc = new HTableDescriptor(tableName); desc.setConfiguration(DefaultStoreEngine.DEFAULT_COMPACTION_POLICY_CLASS_KEY, FIFOCompactionPolicy.class.getName()); For CF:HColumnDescriptor desc = new HColumnDescriptor(family); desc.setConfiguration(DefaultStoreEngine.DEFAULT_COMPACTION_POLICY_CLASS_KEY, FIFOCompactionPolicy.class.getName());From HBase shell:create 'x',{NAME=&gt;'y', TTL=&gt;'30'}, {CONFIGURATION =&gt; {'hbase.hstore.defaultengine.compactionpolicy.class' =&gt; 'org.apache.hadoop.hbase.regionserver.compactions.FIFOCompactionPolicy', 'hbase.hstore.blockingStoreFiles' =&gt; 1000}}Although region splitting is supported, for optimal performance it should be disabled, either by setting explicitly DisabledRegionSplitPolicy or by setting ConstantSizeRegionSplitPolicy and very large max region size. You will have to increase to a very large number store's blocking file number : hbase.hstore.blockingStoreFiles as well (there is a sanity check on table/column family configuration in case of FIFO compaction and minimum value for number of blocking file is 1000).LimitationsDo not use FIFO compaction if : Table/CF has MIN_VERSION &gt; 0 Table/CF has TTL = FOREVER (HColumnDescriptor.DEFAULT_TTL)</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,0.98.17,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="14469" opendate="2015-9-23 00:00:00" fixdate="2015-9-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix some comment, validation and logging around memstore lower limit configuration</summary>
      <description>Trivial code cleanup around memstore lower limit configuration.</description>
      <version>None</version>
      <fixedVersion>1.2.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.util.HeapMemorySizeUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="1447" opendate="2009-5-26 00:00:00" fixdate="2009-6-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Take last version of the hbase-1249 design doc. and make documentation out of it</summary>
      <description>hbase-1249 finishes with the API design we all voted on for hbase-880. This issue is about adding documentation of the new API into javadoc packages and wiki.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestScanner.java</file>
      <file type="M">src.java.overview.html</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.MinorCompactingStoreScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.GetDeleteTracker.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.package-info.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="14478" opendate="2015-9-24 00:00:00" fixdate="2015-9-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>A ThreadPoolExecutor with a LinkedBlockingQueue cannot execute tasks concurrently</summary>
      <description>In FlushTableSubprocedurePool and SnapshotSubprocedurePool, the ThreadPoolExecutor with a LinkedBlockingQueue is used, and it's corePoolSize and maximumPoolSize are not the same, which can cause the if the number of tasks is larger than corePoolSize, those tasks cannot be executed until old tasks are finished and the number of running tasks is less than corePoolSize. We should use the same value for the corePoolSize and maximumPoolSize if the LinkedBlockingQueue is used.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.snapshot.RegionServerSnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.flush.RegionServerFlushTableProcedureManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="1448" opendate="2009-5-26 00:00:00" fixdate="2009-6-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a node in ZK to tell all masters to shutdown.</summary>
      <description>Currently, shutting down a multi-master HBase is a bit of a mess since the backup masters aren't pinged by the stop-hbase script. To shut them down, you have to do a hbase-daemons.sh stop master. Also, with master failover in place, the backup masters may try to come alive. This can be solved by adding a "shutdown node" in ZK on which all masters should be listening.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ZKMasterAddressWatcher.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="14481" opendate="2015-9-24 00:00:00" fixdate="2015-11-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Decommission HBase wiki</summary>
      <description>We have an awesome community resource in our online book. It's maintained and looked after with diligence. We also have an HBase section on the hadoop wiki that hasn't been updated since 2012. Let's sift through the pages of the wiki, bring over any content that's still relevant and not already present in the book, and kill the wiki.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.thrift.filter.language.adoc</file>
      <file type="M">src.main.asciidoc..chapters.preface.adoc</file>
      <file type="M">hbase-thrift.src.main.resources.hbase-webapps.thrift.thrift.jsp</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestZooKeeper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.thrift.thrift.jsp</file>
      <file type="M">hbase-server.src.main.javadoc.overview.html</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">hbase-rest.src.main.resources.hbase-webapps.rest.rest.jsp</file>
      <file type="M">conf.hbase-env.sh</file>
      <file type="M">conf.hbase-env.cmd</file>
    </fixedFiles>
  </bug>
  <bug id="14489" opendate="2015-9-25 00:00:00" fixdate="2015-9-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>postScannerFilterRow consumes a lot of CPU</summary>
      <description>During an unrelated test I found that when scanning a tall table with CQ only and filtering most results at the server, 50% of time is spend in postScannerFilterRow, even though the coprocessor does nothing in that hook.We need to find a way not to call this hook when not needed, or to question why we have this hook at all.I think ram_krish added the hook (or maybe anoop.hbase). I am also not sure whether Phoenix uses this hook (giacomotaylor?)</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,0.98.15,1.0.3,1.1.3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.SimpleRegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
    </fixedFiles>
  </bug>
  <bug id="1449" opendate="2009-5-26 00:00:00" fixdate="2009-6-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update to latest ZooKeeper trunk</summary>
      <description>The latest ZooKeeper trunk has many improvements and is much more clean. Since we are working on integrating better with ZooKeeper (e.g. shell and JNI) we should run off their latest and greatest.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.zookeeper.HQuorumPeerTest.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.zookeeper.HQuorumPeer.java</file>
      <file type="M">lib.zookeeper-3.1.0-hbase-1241.jar</file>
    </fixedFiles>
  </bug>
  <bug id="14492" opendate="2015-9-25 00:00:00" fixdate="2015-9-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Increase REST server header buffer size from 8k to 64k</summary>
      <description>@HBASE-13608 increased rest server http header size to 8k. We saw http header size exceeding 7k with kerberos authentication. Increase it to 64k to avoid possible future 413 error.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,0.98.15,1.0.3,1.1.3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.RESTServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="14498" opendate="2015-9-28 00:00:00" fixdate="2015-1-28 01:00:00" resolution="Unresolved">
    <buginformation>
      <summary>Master stuck in infinite loop when all Zookeeper servers are unreachable (and RS may run after losing its znode)</summary>
      <description>We met a weird scenario in our production environment.In a HA cluster,&gt; Active Master (HM1) is not able to connect to any Zookeeper server (due to N/w breakdown on master machine network with Zookeeper servers).2015-09-26 15:24:47,508 INFO [HM1-Host:16000.activeMasterManager-SendThread(ZK-Host:2181)] zookeeper.ClientCnxn: Client session timed out, have not heard from server in 33463ms for sessionid 0x104576b8dda0002, closing socket connection and attempting reconnect2015-09-26 15:24:47,877 INFO [HM1-Host:16000.activeMasterManager-SendThread(ZK-Host1:2181)] client.FourLetterWordMain: connecting to ZK-Host1 21812015-09-26 15:24:48,236 INFO [main-SendThread(ZK-Host1:2181)] client.FourLetterWordMain: connecting to ZK-Host1 21812015-09-26 15:24:49,879 WARN [HM1-Host:16000.activeMasterManager-SendThread(ZK-Host1:2181)] zookeeper.ClientCnxn: Can not get the principle name from server ZK-Host12015-09-26 15:24:49,879 INFO [HM1-Host:16000.activeMasterManager-SendThread(ZK-Host1:2181)] zookeeper.ClientCnxn: Opening socket connection to server ZK-Host1/ZK-IP1:2181. Will not attempt to authenticate using SASL (unknown error)2015-09-26 15:24:50,238 WARN [main-SendThread(ZK-Host1:2181)] zookeeper.ClientCnxn: Can not get the principle name from server ZK-Host12015-09-26 15:24:50,238 INFO [main-SendThread(ZK-Host1:2181)] zookeeper.ClientCnxn: Opening socket connection to server ZK-Host1/ZK-Host1:2181. Will not attempt to authenticate using SASL (unknown error)2015-09-26 15:25:17,470 INFO [main-SendThread(ZK-Host1:2181)] zookeeper.ClientCnxn: Client session timed out, have not heard from server in 30023ms for sessionid 0x2045762cc710006, closing socket connection and attempting reconnect2015-09-26 15:25:17,571 WARN [master/HM1-Host/HM1-IP:16000] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=ZK-Host:2181,ZK-Host1:2181,ZK-Host2:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/master2015-09-26 15:25:17,872 INFO [main-SendThread(ZK-Host:2181)] client.FourLetterWordMain: connecting to ZK-Host 21812015-09-26 15:25:19,874 WARN [main-SendThread(ZK-Host:2181)] zookeeper.ClientCnxn: Can not get the principle name from server ZK-Host2015-09-26 15:25:19,874 INFO [main-SendThread(ZK-Host:2181)] zookeeper.ClientCnxn: Opening socket connection to server ZK-Host/ZK-IP:2181. Will not attempt to authenticate using SASL (unknown error)&gt; Since HM1 was not able to connect to any ZK, so session timeout didnt happen at Zookeeper server side and HM1 didnt abort.&gt; On Zookeeper session timeout standby master (HM2) registered himself as an active master. &gt; HM2 is keep on waiting for region server to report him as part of active master intialization. 2015-09-26 15:24:44,928 | INFO | HM2-Host:21300.activeMasterManager | Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms. | org.apache.hadoop.hbase.master.ServerManager.waitForRegionServers(ServerManager.java:1011)------2015-09-26 15:32:50,841 | INFO | HM2-Host:21300.activeMasterManager | Waiting for region servers count to settle; currently checked in 0, slept for 483913 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms. | org.apache.hadoop.hbase.master.ServerManager.waitForRegionServers(ServerManager.java:1011)&gt; At other end, region servers are reporting to HM1 on 3 sec interval. Here region server retrieve master location from zookeeper only when they couldn't connect to Master (ServiceException).Region Server will not report HM2 as per current design until unless HM1 abort,so HM2 will exit(InitializationMonitor) and again wait for region servers in loop.</description>
      <version>3.0.0-alpha-1,1.5.0,2.0.0,2.2.0</version>
      <fixedVersion>3.0.0-beta-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZooKeeperWatcher.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
    </fixedFiles>
  </bug>
  <bug id="14500" opendate="2015-9-28 00:00:00" fixdate="2015-9-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove load of deprecated MOB ruby scripts after HBASE-14227</summary>
      <description></description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.shell.rb</file>
    </fixedFiles>
  </bug>
  <bug id="14532" opendate="2015-10-1 00:00:00" fixdate="2015-11-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[book] dfs.client.read.shortcircuit is referenced as hbase-site.xml config and not described in section 7</summary>
      <description>After trying to figure out whether shortcircuit reads would work on my system, I studied the book and found conflicting information.It's suggested in section 92.2, that dfs.client.read.shortcircuit is an option in hbase-site.xml, but the supposedly complete default configuration in section 7 does not include this setting. This leads to confusion on whether it's sufficient to enable this setting in hdfs-site.xml, or whether it needs to be added to both configurations.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="14547" opendate="2015-10-2 00:00:00" fixdate="2015-10-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add more debug/trace to zk-procedure</summary>
      <description>add more debug/trace logs to the zk-procedure/online-snapshot flow</description>
      <version>1.2.0,2.0.0</version>
      <fixedVersion>1.2.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.snapshot.RegionServerSnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.snapshot.FlushSnapshotSubprocedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureCoordinatorRpcs.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ProcedureMember.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ProcedureCoordinator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.Procedure.java</file>
    </fixedFiles>
  </bug>
  <bug id="14551" opendate="2015-10-5 00:00:00" fixdate="2015-10-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - Reimplement split</summary>
      <description>use the proc-v2 state machine for split. also update the logic to have a single meta-writer.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsckOneRS.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestWithDisabledAuthorization.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestEndToEndSplitTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.namespace.TestNamespaceAuditor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MockRegionServerServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockNoopMasterServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestMasterObserver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.java</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupAdminEndpoint.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.RegionServerStatus.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.MasterProcedure.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.Admin.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ResponseConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="14558" opendate="2015-10-6 00:00:00" fixdate="2015-10-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document ChaosMonkey enhancements from HBASE-14261</summary>
      <description></description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="14575" opendate="2015-10-7 00:00:00" fixdate="2015-12-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Relax region read lock for compactions</summary>
      <description>Per devaraj's idea on parent issue, let's see if we can reduce the scope of critical section under which compactions hold the region read lock.Here is summary from parent issue:Another idea is we can reduce the scope of when the read lock is held during compaction. In theory the compactor only needs a region read lock while deciding what files to compact and at the time of committing the compaction. We're protected from the case of region close events because compactions are checking (every 10k bytes written) if the store has been closed in order to abort in such a case.</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionServerBulkLoad.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="14581" opendate="2015-10-8 00:00:00" fixdate="2015-10-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Znode cleanup throws auth exception in secure mode</summary>
      <description>When the master process or region server process dies on Linux, we invoke: if [ -f ${HBASE_ZNODE_FILE} ]; then if [ "$command" = "master" ]; then $bin/hbase master clear &gt; /dev/null 2&gt;&amp;1 else #call ZK to delete the node ZNODE=`cat ${HBASE_ZNODE_FILE}` $bin/hbase zkcli delete ${ZNODE} &gt; /dev/null 2&gt;&amp;1 fi rm ${HBASE_ZNODE_FILE} fiWe delete its znode from the process which started the server JVM for faster crash recovery.In secure deployment however, the second process does not authenticate to zookeeper properly and fails to delete the znode: 2015-06-11 11:05:06,238 WARN [main-SendThread(ip-172-31-32-230.ec2.internal:2181)] client.ZooKeeperSaslClient: Could not login: the client is being asked for a password, but the Zookeeper client code does not currently support obtaining a password from the user. Make sure that the client is configured to use a ticket cache (using the JAAS config2015-06-11 11:05:06,248 WARN [main-SendThread(ip-172-31-32-230.ec2.internal:2181)] zookeeper.ClientCnxn: SASL configuration failed: javax.security.auth.login.LoginException: No password provided Will continue connection to Zookeeper server without SASL authentication, if Zookeeper server allows it.2015-06-11 11:05:06,251 INFO [main-SendThread(ip-172-31-32-230.ec2.internal:2181)] zookeeper.ClientCnxn: Opening socket connection to server ip-172-31-32-230.ec2.internal/172.31.32.230:21812015-06-11 11:05:06,263 INFO [main-SendThread(ip-172-31-32-230.ec2.internal:2181)] zookeeper.ClientCnxn: Socket connection established to ip-172-31-32-230.ec2.internal/172.31.32.230:2181, initiating session2015-06-11 11:05:06,294 INFO [main-SendThread(ip-172-31-32-230.ec2.internal:2181)] zookeeper.ClientCnxn: Session establishment complete on server ip-172-31-32-230.ec2.internal/172.31.32.230:2181, sessionid = 0x14de1dd0f3200cf, negotiated timeout = 400002015-06-11 11:05:06,664 WARN [main] util.HeapMemorySizeUtil: hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size2015-06-11 11:05:09,070 WARN [main] zookeeper.ZooKeeperNodeTracker: Can't get or delete the master znodeorg.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth for /hbase-secure/master at org.apache.zookeeper.KeeperException.create(KeeperException.java:113) at org.apache.zookeeper.KeeperException.create(KeeperException.java:51) at org.apache.zookeeper.ZooKeeper.delete(ZooKeeper.java:873) at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.delete(RecoverableZooKeeper.java:179) at org.apache.hadoop.hbase.zookeeper.ZKUtil.deleteNode(ZKUtil.java:1345) at org.apache.hadoop.hbase.zookeeper.MasterAddressTracker.deleteIfEquals(MasterAddressTracker.java:270) at org.apache.hadoop.hbase.ZNodeClearer.clear(ZNodeClearer.java:149)This is due to REGIONSERVER_OPTS / HBASE_MASTER_OPTS not being passed for invoking the zkcli command.Thanks to Enis who spotted the issue.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,1.0.3,1.1.3,0.98.16,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase-daemon.sh</file>
    </fixedFiles>
  </bug>
  <bug id="14582" opendate="2015-10-8 00:00:00" fixdate="2015-10-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Regionserver status webpage bucketcache list can become huge</summary>
      <description>The regionserver status page, such as http://127.0.0.1:60030/rs-status always downloads information about every bucket in the cache. In some cases this can be hundreds of thousands of buckets, causing megabytes of info to need to be downloaded and significant browser instability and memory usage:wc -l HBase-Region-Server-hb22.html2010116 HBase-Region-Server-hb22.htmlls -lah HBase-Region-Server-hb22.html32M Oct 6 19:23 HBase-Region-Server-hb22.htmlFirefox "about:memory":1,330.18 MB (48.22%) &amp;#8211; top(http://hb22:60030/rs-status#bc_l2, id=2010)1,329.61 MB (48.20%) &amp;#8211; active/window(http://hb22:60030/rs-status#bc_l2)</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,1.0.3,1.1.3,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="14583" opendate="2015-10-9 00:00:00" fixdate="2015-6-9 01:00:00" resolution="Won&amp;#39;t Fix">
    <buginformation>
      <summary>Enabled client-side metrics by default</summary>
      <description>Enabling this feature by default for master and branch-1.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
    </fixedFiles>
  </bug>
  <bug id="14597" opendate="2015-10-13 00:00:00" fixdate="2015-10-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix Groups cache in multi-threaded env</summary>
      <description>UGI doesn't hash based on the user as expected so since we have lots of ugi potentially created the cache doesn't do it's job.</description>
      <version>1.2.0,1.3.0,2.0.0</version>
      <fixedVersion>1.2.0,1.3.0,0.98.17,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.TestUser.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.security.UserProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.security.User.java</file>
    </fixedFiles>
  </bug>
  <bug id="14608" opendate="2015-10-15 00:00:00" fixdate="2015-10-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>testWalRollOnLowReplication has some risk to assert failed after HBASE-14600</summary>
      <description>After HBASE-14600, we catch runtime exception if dn recover slowly, but it has some risk to assert failed.For example, https://builds.apache.org/job/HBase-TRUNK/6907/testReport/The reason is we catch the exception, but in WALProcedureStore, it will still stop the Procedure. So when we assert stop.isRunning, it will failed.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestWALProcedureStoreOnHDFS.java</file>
    </fixedFiles>
  </bug>
  <bug id="14627" opendate="2015-10-16 00:00:00" fixdate="2015-10-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move Stargate docs to Ref Guide</summary>
      <description></description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.external.apis.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="14633" opendate="2015-10-16 00:00:00" fixdate="2015-10-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Try fluid width UI</summary>
      <description>Our UI is often too long. Lets give it more room if available.</description>
      <version>1.2.0,2.0.0</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.resources.hbase-webapps.thrift.thrift.jsp</file>
      <file type="M">hbase-thrift.src.main.resources.hbase-webapps.static.css.hbase.css</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.thrift.thrift.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.css.hbase.css</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.zk.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.tablesDetailed.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.snapshot.jsp</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">hbase-rest.src.main.resources.hbase-webapps.rest.rest.jsp</file>
    </fixedFiles>
  </bug>
  <bug id="14636" opendate="2015-10-17 00:00:00" fixdate="2015-10-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clear HFileScannerImpl#prevBlocks in between Compaction flow</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.Compactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
    </fixedFiles>
  </bug>
  <bug id="14638" opendate="2015-10-19 00:00:00" fixdate="2015-11-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move Jython info from the Wiki to the Ref Guide</summary>
      <description></description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.external.apis.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="14639" opendate="2015-10-19 00:00:00" fixdate="2015-11-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move Scala info from Wiki to Ref Guide</summary>
      <description></description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.external.apis.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="14640" opendate="2015-10-19 00:00:00" fixdate="2015-11-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move Cascading info from Wiki to Ref Guide</summary>
      <description></description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.mapreduce.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="14641" opendate="2015-10-19 00:00:00" fixdate="2015-11-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move JDO example from Wiki to Ref Guide</summary>
      <description></description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.external.apis.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="14643" opendate="2015-10-19 00:00:00" fixdate="2015-10-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Avoid Splits from once again opening a closed reader for fetching the first and last key</summary>
      <description>Currently split flow is such that we close the parent region and all its store file readers are also closed. After that inorder to split the reference files we need the first and last keys for which once again open the readers on those store files. This could be costlier operation considering the fact that it has to contact the HDFS for this close and open operation. This JIRA is to see if we can improve this.</description>
      <version>2.0.0</version>
      <fixedVersion>1.2.0,1.3.0,1.0.3,1.1.3,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionFileSystem.java</file>
    </fixedFiles>
  </bug>
  <bug id="14644" opendate="2015-10-19 00:00:00" fixdate="2015-6-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Region in transition metric is broken</summary>
      <description>ritCount stays 0 no matter what</description>
      <version>None</version>
      <fixedVersion>1.3.0,1.2.2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MetricsAssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="14657" opendate="2015-10-20 00:00:00" fixdate="2015-10-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove unneeded API from EncodedSeeker</summary>
      <description>See parent. We do not need getKeyValueBuffer. It's only used for tests, and parent patch fixes all tests to use getKeyValue instead.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,1.0.3,1.1.3,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestDataBlockEncoders.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.DataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
    </fixedFiles>
  </bug>
  <bug id="14669" opendate="2015-10-21 00:00:00" fixdate="2015-10-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>remove unused import and fix javadoc</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.FilterTestingCluster.java</file>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift2.TestThriftHBaseServiceHandlerWithLabels.java</file>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift2.TestThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftUtilities.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.zookeeper.TestRecoverableZooKeeper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestSecureWAL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestBoundedRegionGroupingStrategy.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.FaultyFSLog.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestRegionSplitter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestMiniClusterLoadSequential.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestMergeTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestFSVisitor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestFSUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestFSTableDescriptors.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.ProcessBasedLocalHBaseCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MultiThreadedWriterWithACL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MultiThreadedReaderWithACL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.OfflineMetaRebuildTestCore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.BaseTestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.trace.TestHTraceHooks.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestTableDescriptor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestNamespace.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestMetaTableAccessor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestHBaseOnOtherDfsCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestGlobalMemStoreSize.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestMobRestoreSnapshotHelper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestMobRestoreFlushSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestMobFlushSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestMobExportSnapshot.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestExportSnapshot.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.SnapshotTestingUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.MobSnapshotTestingUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabels.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestEnforcingScanLabelGenerator.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestTablePermissions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationWALEntryFilters.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationSource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationKillRS.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestMultiSlaveReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALActionsListener.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestReadOldRootAndMetaEdits.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRollPeriod.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestServerCustomProtocol.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSCVFWithMiniCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestScannerWithBulkload.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestScannerRetriableFailure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerReportForDuty.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerOnlineConfigChange.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerNoMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerHostname.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionReplicas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionFavoredNodes.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRecoveredEdits.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestPerColumnFamilyFlush.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestJoinedScanners.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHMobStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHeapMemoryManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.compactions.TestCompactionWithThroughputController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.compactions.MockStoreFileGenerator.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestQuotaThrottle.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestQuotaState.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestQuotaAdmin.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.namespace.TestNamespaceAuditor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestTableLockManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRollingRestart.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRegionStates.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRegionPlacement.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterRestartAfterDisablingTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestGetLastFlushedSequenceId.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.snapshot.TestSnapshotManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.snapshot.TestSnapshotFileCache.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestWALProcedureStoreOnHDFS.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.handler.TestEnableTableHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.cleaner.TestSnapshotFromMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapred.TestTableMapReduce.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapred.TestTableInputFormat.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableMapReduceBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableMapReduce.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScanBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableInputFormat.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestSyncTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestRowCounter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestMultithreadedTableMapper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestMultiTableInputFormat.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFilesSplitRecovery.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestHashTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestCopyTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestCellCounter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.MultiTableInputFormatTestBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestGlobalEventLoopGroup.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileBlockCompatibility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestChecksum.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestCacheConfig.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.CacheTestUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestLoadAndSwitchEncodeOnDisk.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.http.TestHttpServerLifecycle.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestFilterWrapper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSimpleScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestClientExponentialBackoff.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ProcedureInfo.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.CategoryBasedTimeout.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.codec.TestCellCodec.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestChoreService.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestTimeout.java</file>
      <file type="M">hbase-examples.src.test.java.org.apache.hadoop.hbase.coprocessor.example.TestBulkDeleteProtocol.java</file>
      <file type="M">hbase-examples.src.test.java.org.apache.hadoop.hbase.coprocessor.example.TestRowCountEndpoint.java</file>
      <file type="M">hbase-examples.src.test.java.org.apache.hadoop.hbase.coprocessor.example.TestZooKeeperScanPolicyObserver.java</file>
      <file type="M">hbase-examples.src.test.java.org.apache.hadoop.hbase.types.TestPBCell.java</file>
      <file type="M">hbase-hadoop2-compat.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.test.java.org.apache.hadoop.hbase.test.MetricsAssertHelperImpl.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.RestartRsHoldingTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.TruncateTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestLazyCfLoading.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestMetaReplicas.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestTimeBoundedMultiGetRequestsWithRegionReplicas.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestTimeBoundedRequestsWithRegionReplicas.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.wal.TestWALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.TestYieldProcedures.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.package-info.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.CopyTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactionRequestor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.snapshot.FlushSnapshotSubprocedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.Merge.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionSizeCalculator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.DisabledWALProvider.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestClientTimeouts.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFastFail.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMobRestoreSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMobSnapshotCloneIndependence.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMobSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestReplicaWithCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestResultSizeEstimation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.codec.TestCellMessageCodec.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.constraint.TestConstraint.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestAggregateProtocol.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestBatchCoprocessorEndpoint.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestBigDecimalColumnInterpreter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorEndpoint.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorHost.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestDoubleColumnInterpreter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverBypass.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithAbort.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithRemove.java</file>
    </fixedFiles>
  </bug>
  <bug id="14673" opendate="2015-10-21 00:00:00" fixdate="2015-1-21 01:00:00" resolution="Unresolved">
    <buginformation>
      <summary>Remove duplicated code between IntegrationTestBigLinkedList and IntegrationTestLoadAndVerify</summary>
      <description>IntegrationTestBigLinkedList and IntegrationTestLoadAndVerify have some classes and methods duplicated</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftUtilities.java</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.table.rb</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MultiThreadedUpdater.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithDeletes.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.ExpAsStringVisibilityLabelServiceImpl.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestCellACLWithMultipleVersions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestCellACLs.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationSmallTests.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestPerTableCFReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSeekOptimizations.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMultiColumnScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMinorCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMajorCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestKeepDeletes.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestBlocksRead.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestAtomicOperation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterOperationsForRegionReplicas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestWALPlayer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestImportTSVWithVisibilityLabels.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestImportExport.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestTimestampsFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannersFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestPutDeleteEtcCellIteration.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMultipleTimestamps.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMultiParallel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaUtil.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.TestScannersWithFilters.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.RowResource.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedListWithVisibility.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.coprocessor.example.BulkDeleteEndpoint.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestOperation.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestDeleteTimeStamp.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Delete.java</file>
    </fixedFiles>
  </bug>
  <bug id="14681" opendate="2015-10-22 00:00:00" fixdate="2015-10-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade Checkstyle plugin to 2.16</summary>
      <description>We are getting a NPE in checkstyle when running mvn:site. It seems to be MCHECKSTYLE-288 or MCHECKSTYLE-250. Updating maven-checkstyle-plugin from 2.13 to 2.16 seems to fix it.Or maybe not.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="14688" opendate="2015-10-24 00:00:00" fixdate="2015-10-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cleanup MOB tests</summary>
      <description>remove the copy-paste stuff and use MobUtil instead of redoing concatenation and extraction by hand.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.BaseTestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMobStoreScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMobStoreCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDeleteMobTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mob.TestMobFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mob.TestMobDataBlockEncoding.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mob.TestExpiredMobFileCleaner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mob.TestDefaultMobStoreFlusher.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mob.TestCachedMobFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mob.MobTestUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mob.compactions.TestPartitionedMobCompactor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mob.compactions.TestMobCompactor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
    </fixedFiles>
  </bug>
  <bug id="14689" opendate="2015-10-24 00:00:00" fixdate="2015-11-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Addendum and unit test for HBASE-13471</summary>
      <description>One of our customers ran into HBASE-13471, which resulted in all the handlers getting blocked and various other issues. While backporting the issue, I noticed that there is one more case where we might go into infinite loop. In case a row lock cannot be acquired (due to a previous leak for example which we have seen in Phoenix before) this will cause similar infinite loop.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,1.0.3,1.1.3,0.98.16,0.98.17,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="14690" opendate="2015-10-24 00:00:00" fixdate="2015-10-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix css so there&amp;#39;s no left/right scroll bar</summary>
      <description>2 em of extra padding needs to be reomved.</description>
      <version>1.2.0,1.3.0,2.0.0</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.resources.hbase-webapps.static.css.hbase.css</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.css.hbase.css</file>
    </fixedFiles>
  </bug>
  <bug id="14693" opendate="2015-10-24 00:00:00" fixdate="2015-11-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add client-side metrics for received pushback signals</summary>
      <description>HBASE-12911 added client side metrics. HBASE-5162 added a mechanism for sending advisory backpressure signals to clients when the server is heavily loaded, and HBASE-12702 and subtasks backported this to all active branches. Add client-side metrics for received pushback signal.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,0.98.16,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestClientPushback.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MetricsConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
    </fixedFiles>
  </bug>
  <bug id="14695" opendate="2015-10-25 00:00:00" fixdate="2015-10-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix some easy HTML warnings</summary>
      <description>There are a few links to top-level pages but missing the trailing /, and a few please where we link to pages like replication.html even though we have a single-page book now. There are also a few broken links in the APIdocs, probably due to code we have specifically filtered out of the Javadoc:#------------------------------------------------------------# ERROR 4 files had broken links#------------------------------------------------------------/devapidocs/org/apache/hadoop/hbase/wal/NamespaceGroupingStrategy.htmlhad 1 broken link /devapidocs/org/apache/hadoop/hbase/wal/RegionGroupingProvider.RegionGroupingStrategy.html/devapidocs/org/apache/hadoop/hbase/wal/package-tree.htmlhad 1 broken link /devapidocs/org/apache/hadoop/hbase/wal/RegionGroupingProvider.RegionGroupingStrategy.html/devapidocs/overview-tree.htmlhad 2 broken links /devapidocs/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.SeekerState.html /devapidocs/org/apache/hadoop/hbase/wal/RegionGroupingProvider.RegionGroupingStrategy.html/devapidocs/serialized-form.htmlhad 26 broken links /devapidocs/src-html/com/google/protobuf/DescriptorProtos.DescriptorProto.ExtensionRange.html /devapidocs/src-html/com/google/protobuf/DescriptorProtos.DescriptorProto.html /devapidocs/src-html/com/google/protobuf/DescriptorProtos.EnumDescriptorProto.html /devapidocs/src-html/com/google/protobuf/DescriptorProtos.EnumOptions.html /devapidocs/src-html/com/google/protobuf/DescriptorProtos.EnumValueDescriptorProto.html /devapidocs/src-html/com/google/protobuf/DescriptorProtos.EnumValueOptions.html /devapidocs/src-html/com/google/protobuf/DescriptorProtos.FieldDescriptorProto.html /devapidocs/src-html/com/google/protobuf/DescriptorProtos.FieldOptions.html /devapidocs/src-html/com/google/protobuf/DescriptorProtos.FileDescriptorProto.html /devapidocs/src-html/com/google/protobuf/DescriptorProtos.FileDescriptorSet.html /devapidocs/src-html/com/google/protobuf/DescriptorProtos.FileOptions.html /devapidocs/src-html/com/google/protobuf/DescriptorProtos.MessageOptions.html /devapidocs/src-html/com/google/protobuf/DescriptorProtos.MethodDescriptorProto.html /devapidocs/src-html/com/google/protobuf/DescriptorProtos.MethodOptions.html /devapidocs/src-html/com/google/protobuf/DescriptorProtos.ServiceDescriptorProto.html /devapidocs/src-html/com/google/protobuf/DescriptorProtos.ServiceOptions.html /devapidocs/src-html/com/google/protobuf/DescriptorProtos.SourceCodeInfo.Location.html /devapidocs/src-html/com/google/protobuf/DescriptorProtos.SourceCodeInfo.html /devapidocs/src-html/com/google/protobuf/DescriptorProtos.UninterpretedOption.NamePart.html /devapidocs/src-html/com/google/protobuf/DescriptorProtos.UninterpretedOption.html /devapidocs/src-html/com/google/protobuf/GeneratedMessage.html /devapidocs/src-html/com/google/protobuf/GeneratedMessageLite.html /devapidocs/src-html/org/apache/hadoop/hbase/spark/ColumnFilter$.html /devapidocs/src-html/org/apache/hadoop/hbase/spark/HBaseContext$.html /devapidocs/src-html/org/apache/hadoop/hbase/spark/RowKeyFilter$.html /devapidocs/src-html/org/apache/hadoop/hbase/spark/SchemaQualifierDefinition$.html</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.site.xdoc.index.xml</file>
      <file type="M">src.main.site.site.xml</file>
      <file type="M">src.main.asciidoc..chapters.performance.adoc</file>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSMapRUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.BloomFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.package-info.java</file>
    </fixedFiles>
  </bug>
  <bug id="14696" opendate="2015-10-26 00:00:00" fixdate="2015-10-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support setting allowPartialResults in mapreduce Mappers</summary>
      <description>It is currently impossible to get partial results in mapreduce mapper jobs.When setting setAllowPartialResults(true) for scan jobs, they still fail with OOME on large rows.The reason is that Scan field allowPartialResults is lost during job creation: 1. User creates a Job and sets a scan object via TableMapReduceUtil.initTableMapperJob(table_name, scanObj,...) -&gt; which puts a result of TableMapReduceUtil.convertScanToString(scanObj) to the job config. 2. When the job starts - method TableInputFormat.setConfig retrieves a scan string from config and converts it to Scan object by calling TableMapReduceUtil.convertStringToScan - which results in a Scan object with a field allowPartialResults always set to false.I have tried to experiment and modify a TableInputFormat method setConfig() by forcing all scans to allow partial results and after this all jobs succeeded with no more OOME and I also noticed that mappers began to get partial results (Result.isPartial()).My use case is very simple - I just have large rows and expect a mapper to get them partially - to get same rowid several times with different key/value records.This would allow me not to worry about implementing my own result partitioning solution, which i would encounter in case the big amount of result key values could be transparently returned for a single large row.And from the other side - if a Scan object can return several records for the same rowid (partial results), perhaps the mapper should do the same.</description>
      <version>1.1.0,2.0.0</version>
      <fixedVersion>1.2.0,1.3.0,1.1.3,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-protocol.src.main.protobuf.Client.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ClientProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="14712" opendate="2015-10-28 00:00:00" fixdate="2015-11-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>MasterProcWALs never clean up</summary>
      <description>MasterProcWALs directory grows pretty much un-bounded. Because of that when master failover happens the NN is flooded with connections and everything grinds to a halt.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,1.1.3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.wal.TestWALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.TestProcedureStoreTracker.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALFormatReader.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALFile.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.ProcedureStoreTracker.java</file>
    </fixedFiles>
  </bug>
  <bug id="14714" opendate="2015-10-28 00:00:00" fixdate="2015-10-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>some cleanup to snapshot code</summary>
      <description>move out some common code and use helpers</description>
      <version>None</version>
      <fixedVersion>1.2.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestRestoreSnapshotHelper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestRestoreFlushSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestFlushSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.SnapshotTestingUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.MobSnapshotTestingUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mob.TestMobFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mob.TestCachedMobFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.cleaner.TestSnapshotFromMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotManifest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.TableSnapshotScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="14719" opendate="2015-10-29 00:00:00" fixdate="2015-12-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add metric for number of MasterProcWALs</summary>
      <description>Lets add monitoring to this so that we can see when it starts.</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterMetricsWrapper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MetricsMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALFile.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="14731" opendate="2015-10-30 00:00:00" fixdate="2015-11-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add -DuseMob option to ITBLL</summary>
      <description>Previously, I would test mob by creating a table, altering to use mob and then running ITBLL. This simplifies it by allowing for a command line arg to enable mob on table creation.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
    </fixedFiles>
  </bug>
  <bug id="14734" opendate="2015-10-31 00:00:00" fixdate="2015-10-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>BindException when setting up MiniKdc</summary>
      <description>Root cause : Port for kdc service gets selected in the constructor, but we bind to it later in MiniKdc.start()--&gt;MiniKdc.initKDCServer() --&gt; KdcServer.start(). In meantime, some other service can capture the port which results in BindException. The solution here is to catch the exception and retry.From https://builds.apache.org/view/H-L/view/HBase/job/HBase-1.2/330/jdk=latest1.7,label=Hadoop/testReport/junit/org.apache.hadoop.hbase.security.token/TestGenerateDelegationToken/org_apache_hadoop_hbase_security_token_TestGenerateDelegationToken/Error MessageAddress already in useStacktracejava.net.BindException: Address already in use at sun.nio.ch.Net.bind0(Native Method) at sun.nio.ch.Net.bind(Net.java:444) at sun.nio.ch.Net.bind(Net.java:436) at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214) at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74) at org.apache.mina.transport.socket.nio.NioSocketAcceptor.open(NioSocketAcceptor.java:198) at org.apache.mina.transport.socket.nio.NioSocketAcceptor.open(NioSocketAcceptor.java:51) at org.apache.mina.core.polling.AbstractPollingIoAcceptor.registerHandles(AbstractPollingIoAcceptor.java:547) at org.apache.mina.core.polling.AbstractPollingIoAcceptor.access$400(AbstractPollingIoAcceptor.java:68) at org.apache.mina.core.polling.AbstractPollingIoAcceptor$Acceptor.run(AbstractPollingIoAcceptor.java:422) at org.apache.mina.util.NamePreservingRunnable.run(NamePreservingRunnable.java:64) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745)Can this utility be made to not fail if address taken? Try another?</description>
      <version>None</version>
      <fixedVersion>1.3.0,1.2.4,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.token.SecureTestCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.TestUsersOperationsWithSecureHadoop.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.TestSecureIPC.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.asyncfs.TestSaslFanOutOneBlockAsyncDFSOutput.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
    </fixedFiles>
  </bug>
  <bug id="14755" opendate="2015-11-4 00:00:00" fixdate="2015-11-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix some broken links and HTML problems</summary>
      <description>Problems seen in https://builds.apache.org/view/H-L/view/HBase/job/HBase%20Website%20Link%20Ckecker/3/artifact/link_report/index.html</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.site.xdoc.poweredbyhbase.xml</file>
      <file type="M">src.main.asciidoc..chapters.security.adoc</file>
      <file type="M">src.main.asciidoc..chapters.performance.adoc</file>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
      <file type="M">src.main.asciidoc..chapters.datamodel.adoc</file>
      <file type="M">src.main.asciidoc..chapters.cp.adoc</file>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
      <file type="M">src.main.asciidoc..chapters.appendix.hfile.format.adoc</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HRegionPartitioner.java</file>
    </fixedFiles>
  </bug>
  <bug id="1476" opendate="2009-6-2 00:00:00" fixdate="2009-5-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>scaling compaction with multiple threads</summary>
      <description>Was thinking we should build in support to be able to handle more then one thread for compactions this will allow us to keep up with compactions when we get to the point where we store Tb's of data per node and may regionsMaybe a configurable setting to set how many threads a region server can use for compactions.With compression turned on my compactions are limited by cpu speed with multi cores then it would be nice to be able to scale compactions to 2 or more cores.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="14764" opendate="2015-11-4 00:00:00" fixdate="2015-11-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Stop using post-site target</summary>
      <description>We don't really need to use the post-site target. This patch re-orders the POM so we don't need it. Otherwise, you have to run post-site before site:stage and that can be confusing.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="14765" opendate="2015-11-4 00:00:00" fixdate="2015-11-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove snappy profile</summary>
      <description>Snappy is provided by hadoop and has been for, a long while.</description>
      <version>1.3.0,2.0.0</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-shell.pom.xml</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-common.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="14766" opendate="2015-11-5 00:00:00" fixdate="2015-11-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>In WALEntryFilter, cell.getFamily() needs to be replaced with the new low-cost implementation</summary>
      <description>Cell's getFamily() gets an array copy of the cell's family, while in the filter function, it just needs to peek into the family and do a compare. Replace Bytes.toString(cell.getFamily())with Bytes.toString(cell.getFamilyArray(), cell.getFamilyOffset(), cell.getFamilyLength())</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.TableCfWALEntryFilter.java</file>
    </fixedFiles>
  </bug>
  <bug id="1478" opendate="2009-6-2 00:00:00" fixdate="2009-6-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove hbase master options from shell</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.hirb.rb</file>
    </fixedFiles>
  </bug>
  <bug id="14780" opendate="2015-11-6 00:00:00" fixdate="2015-12-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Integration Tests that run with ChaosMonkey need to specify CFs</summary>
      <description>Been running some IT tests and found that some failed because getcfs was null and didn't protecte cfs that were assumed to go unmolested.</description>
      <version>2.0.0</version>
      <fixedVersion>1.2.0,1.0.3,1.1.3,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.mapreduce.IntegrationTestTableSnapshotInputFormat.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.mapreduce.IntegrationTestBulkLoad.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestRegionReplicaPerf.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestDDLMasterFailover.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="14781" opendate="2015-11-6 00:00:00" fixdate="2015-11-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Turn per cf flushing on for ITBLL by default</summary>
      <description></description>
      <version>1.2.0,1.3.0,2.0.0</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
    </fixedFiles>
  </bug>
  <bug id="14797" opendate="2015-11-11 00:00:00" fixdate="2015-11-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Last round of CSS fix-ups</summary>
      <description></description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.site.resources.repo.org.apache.maven.skins.maven-fluido-skin.maven-metadata-local.xml</file>
      <file type="M">src.main.site.resources.css.site.css</file>
    </fixedFiles>
  </bug>
  <bug id="14799" opendate="2015-11-12 00:00:00" fixdate="2015-11-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Commons-collections object deserialization remote command execution vulnerability</summary>
      <description>Read: http://foxglovesecurity.com/2015/11/06/what-do-weblogic-websphere-jboss-jenkins-opennms-and-your-application-have-in-common-this-vulnerability/TL;DR: If you have commons-collections on your classpath and accept and process Java object serialization data, then you probably have an exploitable remote command execution vulnerability. 0.94 and earlier HBase releases are vulnerable because we might read in and rehydrate serialized Java objects out of RPC packet data in HbaseObjectWritable using ObjectInputStream#readObject (see https://hbase.apache.org/0.94/xref/org/apache/hadoop/hbase/io/HbaseObjectWritable.html#714) and we have commons-collections on the classpath on the server.0.98 also carries some limited exposure to this problem through inclusion of backwards compatible deserialization code in HbaseObjectWritableFor96Migration. This is used by the 0.94-to-0.98 migration utility, and by the AccessController when reading permissions from the ACL table serialized in legacy format by 0.94. Unprivileged users cannot run the tool nor access the ACL table.Unprivileged users can however attack a 0.94 installation. An attacker might be able to use the method discussed on that blog post to capture valid HBase RPC payloads for 0.94 and prior versions, rewrite them to embed an exploit, and replay them to trigger a remote command execution with the privileges of the account under which the HBase RegionServer daemon is running.We need to make a patch release of 0.94 that changes HbaseObjectWritable to disallow processing of random Java object serializations. This will be a compatibility break that might affect old style coprocessors, which quite possibly may rely on this catch-all in HbaseObjectWritable for custom object (de)serialization. We can introduce a new configuration setting, "hbase.allow.legacy.object.serialization", defaulting to false.To be thorough, we can also use the new configuration setting "hbase.allow.legacy.object.serialization" (defaulting to false) in 0.98 to prevent the AccessController from falling back to the vulnerable legacy code. This turns out to not affect the ability to migrate permissions because TablePermission implements Writable, which is safe, not Serializable.</description>
      <version>None</version>
      <fixedVersion>0.94.28,1.2.0,1.3.0,1.0.3,1.1.3,0.98.17,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1480" opendate="2009-6-4 00:00:00" fixdate="2009-6-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>compaction file not cleaned up after a crash/OOME server</summary>
      <description>We do not clean up compaction files after a crash/OOME of a region server.I am not sure how the compaction file naming is anymore if its not reproducable some how we should let the master or the server with the root region check every so often and delete old files say older then 24 hours in the compaction dir's of the tables</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="14800" opendate="2015-11-12 00:00:00" fixdate="2015-12-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expose checkAndMutate via Thrift2</summary>
      <description>Had a user ask why checkAndMutate wasn't exposed via Thrift2.I see no good reason (since checkAndPut and checkAndDelete are already there), so let's add it.</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift2.TestThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-thrift.src.main.resources.org.apache.hadoop.hbase.thrift2.hbase.thrift</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TScan.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TRowResult.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TRegionInfo.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TIncrement.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TColumn.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TCell.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TAppend.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.Mutation.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.IOError.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.IllegalArgument.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.Hbase.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.ColumnDescriptor.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.BatchMutation.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.AlreadyExists.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftUtilities.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TTimeRange.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TServerName.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TScan.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TRowMutations.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TResult.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TPut.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIOError.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIncrement.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIllegalArgument.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.THRegionLocation.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.THRegionInfo.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.THBaseService.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TGet.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TDelete.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumnValue.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumnIncrement.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumn.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TCellVisibility.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TAuthorization.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TAppend.java</file>
    </fixedFiles>
  </bug>
  <bug id="14801" opendate="2015-11-12 00:00:00" fixdate="2015-3-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enhance the Spark-HBase connector catalog with json format</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.src.test.scala.org.apache.hadoop.hbase.spark.DefaultSourceSuite.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.DefaultSource.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.datasources.HBaseTableScanRDD.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.datasources.HBaseSparkConf.scala</file>
      <file type="M">hbase-spark.src.main.java.org.apache.hadoop.hbase.spark.SparkSQLPushDownFilter.java</file>
    </fixedFiles>
  </bug>
  <bug id="14815" opendate="2015-11-15 00:00:00" fixdate="2015-11-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestMobExportSnapshot.testExportFailure timeout occasionally</summary>
      <description>On master, TestMobExportSnapshot.testExportFailure timeout occasionally.Seehttps://builds.apache.org/job/PreCommit-HBASE-Build/16514//testReport/org.apache.hadoop.hbase.snapshot/TestMobExportSnapshot/testExportFailure/https://builds.apache.org/job/PreCommit-HBASE-Build/16511//testReport/org.apache.hadoop.hbase.snapshot/TestMobExportSnapshot/testExportFailure/</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestExportSnapshot.java</file>
    </fixedFiles>
  </bug>
  <bug id="14823" opendate="2015-11-17 00:00:00" fixdate="2015-11-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase Ref Guide Refactoring</summary>
      <description>Refactor some tables, links, and other things that don't look quite right in the output.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.zookeeper.adoc</file>
      <file type="M">src.main.asciidoc..chapters.unit.testing.adoc</file>
      <file type="M">src.main.asciidoc..chapters.tracing.adoc</file>
      <file type="M">src.main.asciidoc..chapters.security.adoc</file>
      <file type="M">src.main.asciidoc..chapters.schema.design.adoc</file>
      <file type="M">src.main.asciidoc..chapters.rpc.adoc</file>
      <file type="M">src.main.asciidoc..chapters.performance.adoc</file>
      <file type="M">src.main.asciidoc..chapters.other.info.adoc</file>
      <file type="M">src.main.asciidoc..chapters.hbck.in.depth.adoc</file>
      <file type="M">src.main.asciidoc..chapters.hbase.history.adoc</file>
      <file type="M">src.main.asciidoc..chapters.hbase-default.adoc</file>
      <file type="M">src.main.asciidoc..chapters.getting.started.adoc</file>
      <file type="M">src.main.asciidoc..chapters.faq.adoc</file>
      <file type="M">src.main.asciidoc..chapters.datamodel.adoc</file>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
      <file type="M">src.main.asciidoc..chapters.compression.adoc</file>
      <file type="M">src.main.asciidoc..chapters.community.adoc</file>
      <file type="M">src.main.asciidoc..chapters.asf.adoc</file>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
      <file type="M">src.main.asciidoc..chapters.appendix.hfile.format.adoc</file>
      <file type="M">src.main.asciidoc..chapters.appendix.acl.matrix.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="14826" opendate="2015-11-17 00:00:00" fixdate="2015-11-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Small improvement in KVHeap seek() API</summary>
      <description>Currently in seek/reseek() APIs we tend to do lot of priorityqueue related operations. We initially add the current scanner to the heap, then poll and again add the scanner back if the seekKey is greater than the topkey in that scanner. Since the KVs are always going to be in increasing order and in ideal scan flow every seek/reseek is followed by a next() call it should be ok if we start with checking the current scanner and then do a poll to get the next scanner. Just avoid the initial PQ.add(current) call. This could save some comparisons.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.KeyValueHeap.java</file>
    </fixedFiles>
  </bug>
  <bug id="14832" opendate="2015-11-18 00:00:00" fixdate="2015-12-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Ensure write paths work with ByteBufferedCells in case of compaction</summary>
      <description>Currently any cell coming out of offheap Bucketcache while compaction does a copy using the getXXXArray() API since write path does not work with BBCells. This JIRA is aimed at changing the write path to support BBCells so that this copy is avoided.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileDataBlockEncoder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.NoOpDataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.test.RedundantKVGenerator.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteBufferUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.PrefixKeyDeltaEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.FastDiffDeltaEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.DiffKeyDeltaEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.CopyKeyDataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="14849" opendate="2015-11-19 00:00:00" fixdate="2015-12-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add option to set block cache to false on SparkSQL executions</summary>
      <description>I was working at a client with a ported down version of the Spark module for HBase and realized we didn't add an option to turn of block cache for the scans. At the client I just disabled all caching with Spark SQL, this is an easy but very impactful fix.The fix for this patch will make this configurable</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,connector-1.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.src.test.scala.org.apache.hadoop.hbase.spark.DefaultSourceSuite.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.DefaultSource.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.datasources.SerializableConfiguration.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.datasources.HBaseTableScanRDD.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.datasources.Bound.scala</file>
    </fixedFiles>
  </bug>
  <bug id="14851" opendate="2015-11-19 00:00:00" fixdate="2015-12-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add test showing how to use TTL from thrift</summary>
      <description></description>
      <version>2.0.0</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift2.TestThriftHBaseServiceHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="1486" opendate="2009-6-5 00:00:00" fixdate="2009-6-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>BLOCKCACHE always on even when disabled</summary>
      <description>Comes from Billy Pearson up on list.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestStoreFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="14862" opendate="2015-11-20 00:00:00" fixdate="2015-11-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add support for reporting p90 for histogram metrics</summary>
      <description>Currently there is support for reporting p75, p95, and p99 for histogram metrics. This JIRA is to add support for reporting p90.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,0.98.17,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.MutableHistogram.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.DynamicMetricsRegistry.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.metrics2.MetricHistogram.java</file>
    </fixedFiles>
  </bug>
  <bug id="14877" opendate="2015-11-24 00:00:00" fixdate="2015-6-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>maven archetype: client application</summary>
      <description></description>
      <version>2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="14878" opendate="2015-11-24 00:00:00" fixdate="2015-6-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>maven archetype: client application with shaded jars</summary>
      <description>Add new archetype for generation of hbase-shaded-client dependent project.</description>
      <version>2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-archetypes.README.md</file>
      <file type="M">hbase-archetypes.pom.xml</file>
      <file type="M">hbase-archetypes.hbase-archetype-builder.pom.xml</file>
      <file type="M">hbase-archetypes.hbase-archetype-builder.installArchetypes.sh</file>
      <file type="M">hbase-archetypes.hbase-archetype-builder.createArchetypes.sh</file>
    </fixedFiles>
  </bug>
  <bug id="1488" opendate="2009-6-5 00:00:00" fixdate="2009-6-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>After 1304 goes in, fix and reenable test of thrift, mr indexer, and merge tool</summary>
      <description>In 1304 patch, these tests are disabled. This issue is about making them work again after 1304 goes in.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.mapred.DisabledTestTableIndex.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.util.DisabledTestMergeTool.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="14898" opendate="2015-11-30 00:00:00" fixdate="2015-4-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Correct Bloom filter documentation in the book</summary>
      <description>In section 96.4. Bloom Filters: Since HBase 0.96, row-based Bloom filters are enabled by default. (HBASE-) --&gt; in HBASE-8450In section 94.4.3. Configuring Server-Wide Behavior of Bloom Filters: io.hfile.bloom.enabled --&gt; io.storefile.bloom.enabled Master switch to enable Bloom filtersio.hfile.bloom.max.fold --&gt; io.storefile.bloom.max.foldio.hfile.bloom.error.rate --&gt; io.storefile.bloom.error.rateio.storefile.bloom.block.size --&gt; default is 128*1024 = 131072These properties are probably not tuned usually, but should still be fixed in the doc.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.performance.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="1490" opendate="2009-6-5 00:00:00" fixdate="2009-6-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update ZooKeeper library</summary>
      <description>ZooKeeper folks have committed ZOOKEEPER-431, which includes our updates from HBASE-1449. We should upgrade our ZK jar to their latest so we can remove the need for our patches.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">lib.zookeeper-r780828-hbase-1449.jar</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="14922" opendate="2015-12-3 00:00:00" fixdate="2015-12-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Delayed flush doesn&amp;#39;t work causing flush storms.</summary>
      <description>Starting all regionservers at the same time will mean that most PeriodicMemstoreFlusher's will be running at the same time. So all of these threads will queue flushes at about the same time.This was supposed to be mitigated by Delayed. However that isn't nearly enough. This results in the immediate filling up and then draining of the flush queues every hour.</description>
      <version>1.2.0,1.1.2,2.0.0</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestChoreService.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ChoreService.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.JitterScheduledThreadPoolExecutorImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="14928" opendate="2015-12-4 00:00:00" fixdate="2015-12-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Start row should be set for query through HBase REST gateway involving globbing option</summary>
      <description>As Ben Sutton reported in the thread, Slow response on HBase REST api using globbing option, query through the Rest API with a globbing option i.e. http://&lt;HBase_Rest&gt;:&lt;HBase_Rest_Port&gt;/table/key&amp;#42; executes extremely slowly.Jerry He pointed out that PrefixFilter is used for query involving globbing option.This issue is to fix this bug by setting start row for such queries.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,1.1.3,0.98.17,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.TableResource.java</file>
    </fixedFiles>
  </bug>
  <bug id="14942" opendate="2015-12-7 00:00:00" fixdate="2015-12-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow turning off BoundedByteBufferPool</summary>
      <description>The G1 does a great job of compacting, there's no reason to use the BoundedByteBufferPool when the JVM can it for us. So we should allow turning this off for people who are running new jvm's where the G1 is working well.</description>
      <version>1.2.0,1.3.0,2.0.0</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="14946" opendate="2015-12-8 00:00:00" fixdate="2015-12-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Don&amp;#39;t allow multi&amp;#39;s to over run the max result size.</summary>
      <description>If a user puts a list of tons of different gets into a table we will then send them along in a multi. The server un-wraps each get in the multi. While no single get may be over the size limit the total might be.We should protect the server from this. We should batch up on the server side so each RPC is smaller.</description>
      <version>1.2.0,1.3.0,2.0.0</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ProcedurePrepareLatch.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcCallContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServer.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSource.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Result.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RetryImmediatelyException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MultiActionResultTooLarge.java</file>
    </fixedFiles>
  </bug>
  <bug id="14949" opendate="2015-12-8 00:00:00" fixdate="2015-2-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Resolve name conflict when splitting if there are duplicated WAL entries</summary>
      <description>The AsyncFSHLog introduced in HBASE-14790 may write same WAL entries to different WAL files. WAL entry itself is idempotent so replay is not a problem but the intermediate file name and final name when splitting is constructed using the lowest or highest sequence id of the WAL entries written, so it is possible that different WAL files will have same intermediate or final file name when splitting. In the currentm implementation, this will cause split fail or data loss. We need to solve this.</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALSplitter.java</file>
    </fixedFiles>
  </bug>
  <bug id="14952" opendate="2015-12-8 00:00:00" fixdate="2015-12-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase-assembly source artifact has some incorrect modules</summary>
      <description>After generating a tarball we noticed: that hbase-external-blockcache was missing. that hbase-spark is missing that there are duplicate hbase-shaded-{client,server} modules</description>
      <version>1.2.0,2.0.0</version>
      <fixedVersion>1.2.0,1.3.0,1.1.3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-assembly.src.main.assembly.src.xml</file>
    </fixedFiles>
  </bug>
  <bug id="14969" opendate="2015-12-13 00:00:00" fixdate="2015-2-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add throughput controller for flush</summary>
      <description>In HBASE-8329 we added a throughput controller for compaction, to avoid spike caused by huge IO pressure like network/disk overflow. However, even with this control on, we are still observing disk utils near 100%, and by analysis we think this is caused by flush, especially when we increase the setting of hbase.hstore.flusher.countIn this JIRA, we propose to add throughput control feature for flush, as a supplement of HBASE-8329 to better control IO pressure.</description>
      <version>1.3.0,2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.throttle.TestFlushWithThroughputController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestIOFencing.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStripeStoreEngine.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStripeCompactor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionReplayEvents.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHMobStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompactSplitThread.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.compactions.TestStripeCompactionPolicy.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.compactions.TestCompactionWithThroughputController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MockRegionServerServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverScannerOpenHook.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StripeStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StripeStoreEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HMobStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultStoreEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactionTool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.StripeCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.PressureAwareCompactionThroughputController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.NoLimitCompactionThroughputController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.Compactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionThroughputControllerFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionThroughputController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.DefaultMobStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.DefaultMobStoreCompactor.java</file>
    </fixedFiles>
  </bug>
  <bug id="14978" opendate="2015-12-15 00:00:00" fixdate="2015-12-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Don&amp;#39;t allow Multi to retain too many blocks</summary>
      <description>Scans and Multi's have limits on the total size of cells that can be returned. However if those requests are not all pointing at the same blocks then the KeyValues can keep alive a lot more data than their size.Take the following example:A multi with a list of 10000 gets to a fat row. Each column being returned in in a different block. Each column is small 32 bytes or so.So the total cell size will be 32 * 10000 = ~320kb. However if each block is 128k then total retained heap size will be almost 2gigs.</description>
      <version>1.2.0,1.3.0,2.0.0</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMultiRespectsLimits.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcCallContext.java</file>
    </fixedFiles>
  </bug>
  <bug id="14984" opendate="2015-12-15 00:00:00" fixdate="2015-12-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow memcached block cache to set optimze to false</summary>
      <description>In order to keep latency consistent it might not be good to allow the spy memcached client to optimize.</description>
      <version>1.2.0,1.3.0,2.0.0</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-external-blockcache.src.main.java.org.apache.hadoop.hbase.io.hfile.MemcachedBlockCache.java</file>
    </fixedFiles>
  </bug>
  <bug id="14994" opendate="2015-12-16 00:00:00" fixdate="2015-12-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up some broken links and references to old APIs</summary>
      <description>Clean up broken links and references to old APIs found in https://builds.apache.org/job/HBase%20Website%20Link%20Ckecker/14/artifact/link_report/errorX.html</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.schema.design.adoc</file>
      <file type="M">src.main.asciidoc..chapters.hbase-default.adoc</file>
      <file type="M">src.main.asciidoc..chapters.appendix.hfile.format.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="14999" opendate="2015-12-17 00:00:00" fixdate="2015-12-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove ref to org.mortbay.log.Log</summary>
      <description>I could see some 2 or 3 src files and many test files referring to org.mortbay.log.Log instead of commons Log. Patch correct all such places</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitWalDataLoss.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerNoMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestDataBlockEncoders.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHBaseAdminNoCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ClientSideRegionScanner.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestClassFinder.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.FlushRegionCallable.java</file>
    </fixedFiles>
  </bug>
  <bug id="15015" opendate="2015-12-18 00:00:00" fixdate="2015-12-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Checktyle plugin shouldn&amp;#39;t check Jamon-generated Java classes</summary>
      <description></description>
      <version>1.2.0,1.3.0,2.0.0</version>
      <fixedVersion>1.2.0,1.3.0,0.98.17,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-checkstyle.src.main.resources.hbase.checkstyle-suppressions.xml</file>
    </fixedFiles>
  </bug>
  <bug id="15021" opendate="2015-12-21 00:00:00" fixdate="2015-12-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hadoopqa doing false positives</summary>
      <description>https://builds.apache.org/job/PreCommit-HBASE-Build/16930/consoleText says: +1 core tests. The patch passed unit tests in ....but here is what happened:...Results :Tests in error: org.apache.hadoop.hbase.regionserver.TestRSStatusServlet.testBasic(org.apache.hadoop.hbase.regionserver.TestRSStatusServlet) Run 1: TestRSStatusServlet.testBasic:105 � NullPointer Run 2: TestRSStatusServlet.testBasic:105 � NullPointer Run 3: TestRSStatusServlet.testBasic:105 � NullPointerorg.apache.hadoop.hbase.regionserver.TestRSStatusServlet.testWithRegions(org.apache.hadoop.hbase.regionserver.TestRSStatusServlet) Run 1: TestRSStatusServlet.testWithRegions:119 � NullPointer Run 2: TestRSStatusServlet.testWithRegions:119 � NullPointer Run 3: TestRSStatusServlet.testWithRegions:119 � NullPointerTests run: 1033, Failures: 0, Errors: 2, Skipped: 21...[INFO] Apache HBase - Server ............................. FAILURE [17:54.559s]...Why we reporting pass when it failed?</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,1.1.3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  <bug id="15036" opendate="2015-12-23 00:00:00" fixdate="2015-1-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update HBase Spark documentation to include bulk load with thin records</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.spark.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="15050" opendate="2015-12-29 00:00:00" fixdate="2015-12-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Block Ref counting does not work in Region Split cases.</summary>
      <description>The reference counting on the blocks does not work correctly when the HalfStorefileReader is used for compaction/scans. The reason is that getFirstKey and getLastKey API create a new scanner but does not do the needed close() call and because of that we do not decrement the count on the blocks. The same impact will also be observed on the ref count that we maintain on the reader. Issue found when I was trying to test some other feature with lot of evictions.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestBlockEvictionFromClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.HalfStoreFileReader.java</file>
    </fixedFiles>
  </bug>
  <bug id="15063" opendate="2016-1-1 00:00:00" fixdate="2016-1-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bug in MultiByteBuf#toBytes</summary>
      <description>In MutliByteBuff there are couple of inconsistencies, one is in the toBytes function where the offset for copying in the initial element is not being reset with respect to the element public byte[] toBytes(int offset, int length) { byte[] output = new byte[length]; int itemIndex = getItemIndex(offset); ByteBuffer item = this.items[itemIndex]; // the offset has to be reset here to the items offset // should be offset = offset - itemBeingPos[itemIndex] int toRead = item.limit() - offset; int destinationOffset = 0; . . . .Since there is already an existing function get to copy to an byte array it is better we reuse the function here, I attached a patch with a corresponding unit test. (HBASE-XXXX.patch)Another inconsistency I noticed is that there is lack of some consistency in using the position marker of the bytebuffers passed, In the constructor we noting the beginning offsets of each bytebuffer in the itemBeginPos array we are using these position markers in most of the absolute index functions such as get(index), put(index, byte), toBytes, get(int,byte[],int,int) to find the current item to access. There are two problems with this The array itemBeginPos is not being updated whenever there are some writes to internal bytebuffers (remember itemBeginPos depends on the bytebuffer.position() of the internal bytebuffers and the position marker is changed whenever some writes happen to bytebuffers) Also the position marker is not being used in any of the index functions for example here in the get function @Override public byte get(int index) { int itemIndex = getItemIndex(index); return ByteBufferUtils.toByte(this.items[itemIndex], index - this.itemBeginPos[itemIndex]); } where the the index I think should be index - this.itemBeginPos[itemIndex] + items[itemIndex].position() because we are using the position marker to calculate the offsets.There are two solutions I think for this The simple solution I feel for this should be probably ignoring the position marker while calculating the itemBeginPos array which will unify the semantics Not use this array at all and iterate over bytebuffers every time for the getItemIndex function and also use the position marker before calling the ByteBufferUtils functionsI can put up a patch for the second part if we decide which way to go.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.nio.TestMultiByteBuff.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.nio.MultiByteBuff.java</file>
    </fixedFiles>
  </bug>
  <bug id="15068" opendate="2016-1-4 00:00:00" fixdate="2016-1-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add metrics for region normalization plans</summary>
      <description>Currently there is no metric for region normalization plans.This JIRA would add metrics for the following:number of region split plans executednumber of region merge plans executedThese metrics would allow admin to know the impact of region normalization on production cluster</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterMetricsWrapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="1507" opendate="2009-6-9 00:00:00" fixdate="2009-6-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>iCMS as default JVM</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">conf.hbase-env.sh</file>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug id="15101" opendate="2016-1-13 00:00:00" fixdate="2016-1-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Leaked References to StoreFile.Reader after HBASE-13082</summary>
      <description>We observed this production that after a region server dies there are huge number of hfiles in that region for the region server running the version with HBASE-13082, In the doc it is given that it is expected to happen, but we found a one place where scanners are not being closed. If the scanners are not closed their references are not decremented and that is leading to the issue of huge number of store files not being finalizedAll I was able to find is in the selectScannersFrom, where we discard some of the scanners and we are not closing them. I am attaching a patch for that.Also to avoid these issues should the files that are done be logged and finalized (moved to archive) as a part of region close operation. This will solve any leaks that can happen and does not cause any dire consequences?</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="15106" opendate="2016-1-14 00:00:00" fixdate="2016-1-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure V2 - Procedure Queue pass Procedure for better debuggability</summary>
      <description>Changes the various acquire/release methods to take the Procedure as argument.That allows better debuggability. (The patch it is just a refactor, it does not introduce any new thing)https://reviews.apache.org/r/42271/</description>
      <version>1.3.0,2.0.0</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMasterProcedureScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.TruncateTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.EnableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DisableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CreateNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.AddColumnFamilyProcedure.java</file>
    </fixedFiles>
  </bug>
  <bug id="15115" opendate="2016-1-15 00:00:00" fixdate="2016-1-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix findbugs complaints in hbase-client</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,0.98.21,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClientImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.MultiRowRangeFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.LongComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FuzzyRowFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.BinaryPrefixComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.BinaryComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RetriesExhaustedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MetricsConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnectable.java</file>
    </fixedFiles>
  </bug>
  <bug id="15163" opendate="2016-1-25 00:00:00" fixdate="2016-2-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add sampling code and metrics for get/scan/multi/mutate count separately</summary>
      <description>This way we could see QPS of different kinds of requests, to better analyze what's causing hot spot in system</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperStub.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="15172" opendate="2016-1-26 00:00:00" fixdate="2016-1-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support setting storage policy in bulkload</summary>
      <description>When using tiered HFile storage, we should be able to generating hfile with correct storage type during bulkload. This JIRA is targeting at making it possible.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.java</file>
    </fixedFiles>
  </bug>
  <bug id="15173" opendate="2016-1-26 00:00:00" fixdate="2016-1-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Execute mergeRegions RPC call as the request user</summary>
      <description>This is follow up to HBASE-15132Master currently sends mergeRegions RPC to region server under user 'hbase'.This issue is to execute mergeRegions RPC call as the request userSee tail of HBASE-15132 for related discussion.</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin1.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DispatchMergingRegionHandler.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="15174" opendate="2016-1-26 00:00:00" fixdate="2016-6-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Client Public API should not have PB objects in 2.0</summary>
      <description>Some more cleanup for the parent jira. We have leaked some PB structs in Admin (and possible other places). We should clean up these API before 2.0.Examples include: AdminProtos.GetRegionInfoResponse.CompactionState getCompactionState(final TableName tableName) throws IOException; .... void snapshot(final String snapshotName, final TableName tableName, HBaseProtos.SnapshotDescription.Type type) throws IOException, SnapshotCreationException, IllegalArgumentException; .... MasterProtos.SnapshotResponse takeSnapshotAsync(HBaseProtos.SnapshotDescription snapshot) throws IOException, SnapshotCreationException;</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Triple.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.TestInterfaceAudienceAnnotations.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ServerLoad.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionLoad.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionLoadStats.java</file>
    </fixedFiles>
  </bug>
  <bug id="15200" opendate="2016-2-1 00:00:00" fixdate="2016-2-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ZooKeeper znode ACL checks should only compare the shortname</summary>
      <description>After HBASE-13768 we check at startup in secure configurations if our znodes have the correct ACLs. However when checking the ACL we compare the Kerberos fullname, which includes the host component. We should only compare the shortname, the principal. Otherwise in a multimaster configuration we will unnecessarily reset ACLs whenever any master running on a host other than the one that initialized the ACLs makes the check. You can imagine this happening multiple times in a rolling restart scenario.</description>
      <version>1.2.0,1.0.3,1.1.3,0.98.17,2.0.0</version>
      <fixedVersion>1.2.0,1.3.0,1.1.4,1.0.4,0.98.18,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
    </fixedFiles>
  </bug>
  <bug id="15201" opendate="2016-2-1 00:00:00" fixdate="2016-2-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add hbase-spark to hbase assembly</summary>
      <description>hbase-spark currently is missing from hbase assembly.We should add it.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.pom.xml</file>
      <file type="M">hbase-assembly.src.main.assembly.hadoop-two-compat.xml</file>
      <file type="M">hbase-assembly.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="15203" opendate="2016-2-2 00:00:00" fixdate="2016-2-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reduce garbage created by path.toString() during Checksum verification</summary>
      <description>When we try to read a block we do checksum verification for which we need the file name in which the block belongs to. So we do Path.toString() every time. This seems to create around 163MB of char[] that is garbage collected in a simple scan run. It is also visible in writes but the impact is lesser. In overall write/read profile the top 2 factors are byte[] and char[]. This toString() can easily be avoided and reduce its share from the total. To make it more precise in 1 min of profiling, among the 1.8G of garbage created by StringBuilder.toString - this path.toString() was contributing around 3.5%. After the patch this is totally not there.</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.ChecksumUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="15206" opendate="2016-2-2 00:00:00" fixdate="2016-2-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Flakey testSplitDaughtersNotInMeta test</summary>
      <description>Run into the following failure with hbase 1.0.0.Stacktracejava.lang.AssertionError: nullat org.junit.Assert.fail(Assert.java:86)at org.junit.Assert.assertTrue(Assert.java:41)at org.junit.Assert.assertNotNull(Assert.java:712)at org.junit.Assert.assertNotNull(Assert.java:722)at org.apache.hadoop.hbase.util.TestHBaseFsck.testSplitDaughtersNotInMeta(TestHBaseFsck.java:1723)From the log, the ntp issue caused clock skew and it woke up CatalogJanitor earlier. The CatalogJanitor cleaned up the parent region. It could happen with master branch as well. The fix is to disable CatalogJanitor to make sure this will not happen.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,1.1.4,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsckOneRS.java</file>
    </fixedFiles>
  </bug>
  <bug id="15222" opendate="2016-2-5 00:00:00" fixdate="2016-2-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use less contended classes for metrics</summary>
      <description>Running the benchmarks now, but it looks like the results are pretty extreme. The locking in our histograms is pretty extreme.</description>
      <version>1.2.0,1.3.0,2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheStats.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketCacheStats.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.BlockCacheUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.AgeSnapshot.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl.jamon</file>
      <file type="M">hbase-hadoop2-compat.src.test.java.org.apache.hadoop.hbase.metrics.TestBaseSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.MutableTimeHistogram.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.MutableSizeHistogram.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.MutableRangeHistogram.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.MutableHistogram.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.MetricsExecutorImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.MetricMutableQuantiles.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.DynamicMetricsRegistry.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.thrift.MetricsThriftServerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.rest.MetricsRESTSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.replication.regionserver.MetricsReplicationSourceSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.replication.regionserver.MetricsReplicationSinkSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.replication.regionserver.MetricsReplicationGlobalSourceSource.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.wal.MetricsWALSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.metrics.BaseSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsSnapshotSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterFilesystemSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsAssignmentManagerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.balancer.MetricsBalancerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.metrics2.MetricHistogram.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.metrics.BaseSource.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestFastLongHistogram.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.FastLongHistogram.java</file>
    </fixedFiles>
  </bug>
  <bug id="15248" opendate="2016-2-10 00:00:00" fixdate="2016-6-10 01:00:00" resolution="Won&amp;#39;t Fix">
    <buginformation>
      <summary>BLOCKSIZE 4k should result in 4096 bytes on disk; i.e. fit inside a BucketCache &amp;#39;block&amp;#39; of 4k</summary>
      <description>Chatting w/ a gentleman named Daniel Pol who is messing w/ bucketcache, he wants blocks to be the size specified in the configuration and no bigger. His hardware set ups fetches pages of 4k and so a block that has 4k of payload but has then a header and the header of the next block (which helps figure whats next when scanning) ends up being 4203 bytes or something, and this then then translates into two seeks per block fetch.This issue is about what it would take to stay inside our configured size boundary writing out blocks.If not possible, give back better signal on what to do so you could fit inside a particular constraint.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="15255" opendate="2016-2-11 00:00:00" fixdate="2016-2-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add pointer to linkedin blog on putting jvm logs on fast disk</summary>
      <description>Add pointer to linked in blog: https://engineering.linkedin.com/blog/2016/02/eliminating-large-jvm-gc-pauses-caused-by-background-io-trafficIIRC, tsdb says to do similar.Also add into perf section note on native crc.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.performance.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="15259" opendate="2016-2-12 00:00:00" fixdate="2016-2-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>WALEdits under replay will also be replicated</summary>
      <description>I need to verify this but seeing the codetry { // We are about to append this edit; update the region-scoped sequence number. Do it // here inside this single appending/writing thread. Events are ordered on the ringbuffer // so region sequenceids will also be in order. regionSequenceId = entry.stampRegionSequenceId(); // Edits are empty, there is nothing to append. Maybe empty when we are looking for a // region sequence id only, a region edit/sequence id that is not associated with an actual // edit. It has to go through all the rigmarole to be sure we have the right ordering. if (entry.getEdit().isEmpty()) { return; } // Coprocessor hook. if (!coprocessorHost.preWALWrite(entry.getHRegionInfo(), entry.getKey(), entry.getEdit())) { if (entry.getEdit().isReplay()) { // Set replication scope null so that this won't be replicated entry.getKey().setScopes(null); } } if (!listeners.isEmpty()) { for (WALActionsListener i: listeners) { // TODO: Why does listener take a table description and CPs take a regioninfo? Fix. i.visitLogEntryBeforeWrite(entry.getHTableDescriptor(), entry.getKey(), entry.getEdit()); } }When a WALEdit is in replay we set the Logkey to null. But in the visitLogEntryBeforeWrite() we again set the LogKey based on the replication scope associated with the cells. So the previous step of setting null does not work here?</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationSmallTests.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.Replication.java</file>
    </fixedFiles>
  </bug>
  <bug id="1526" opendate="2009-6-15 00:00:00" fixdate="2009-6-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>mapreduce fixup</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.test.org.apache.hadoop.hbase.HBaseTestCase.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.mapred.DisabledTestTableMapReduce.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableSplit.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableReduce.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableOutputFormat.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableMapReduceUtil.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableMap.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableInputFormatBase.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableInputFormat.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.RowCounter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.LuceneDocumentWrapper.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.IndexTableReduce.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.IndexOutputFormat.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.IndexConfiguration.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.IdentityTableReduce.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.IdentityTableMap.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.HRegionPartitioner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.GroupingTableMap.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.Driver.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.BuildTableIndex.java</file>
    </fixedFiles>
  </bug>
  <bug id="15261" opendate="2016-2-12 00:00:00" fixdate="2016-3-12 01:00:00" resolution="Not A Problem">
    <buginformation>
      <summary>Make Throwable t in DaughterOpener volatile</summary>
      <description>In the region split process, daughter regions are opened in different threads, Throwable t is set in these threads and it is checked in the calling thread. Need to make it volatile so the checking will not miss any exceptions from opening daughter regions.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransactionImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="15271" opendate="2016-2-15 00:00:00" fixdate="2016-3-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Spark Bulk Load: Need to write HFiles to tmp location then rename to protect from Spark Executor Failures</summary>
      <description>With the current code if an executor failure before the HFile is close it will cause problems. This jira will have the files first write out to a file that starts with an underscore. Then when the HFile is complete it will be renamed and the underscore will be removed.The underscore is important because the load bulk functionality will skip files with an underscore.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.HBaseContext.scala</file>
    </fixedFiles>
  </bug>
  <bug id="15278" opendate="2016-2-17 00:00:00" fixdate="2016-9-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>AsyncRPCClient hangs if Connection closes before RPC call response</summary>
      <description>The test for HBASE-15212 discovered an issue with Async RPC Client. In that test, we are closing the connection if an RPC call writes a call larger than max allowed size, the server closes the connection. However the async client does not seem to handle connection closes with outstanding RPC calls. The client just hangs. Marking this blocker against 2.0 since it is default there.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.AbstractTestIPC.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.AsyncServerResponseHandler.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.AsyncRpcChannel.java</file>
    </fixedFiles>
  </bug>
  <bug id="1528" opendate="2009-6-15 00:00:00" fixdate="2009-6-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Ensure scanners work across memcache snapshot</summary>
      <description>We have hole in scanning where if a snapshot, we'll stop seeing in-memory results.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestScanner.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestMemcache.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.MultiRegionTable.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.HBaseTestCase.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.client.TestClient.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Memcache.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="15282" opendate="2016-2-17 00:00:00" fixdate="2016-2-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bump hbase-spark to use Spark 1.6.0</summary>
      <description>The latest stable Spark is spark 1.6. &amp;#91;1&amp;#93; Let's bump the version.&amp;#91;1&amp;#93; http://spark.apache.org/news/spark-1-6-0-released.html</description>
      <version>2.0.0</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.src.test.scala.org.apache.hadoop.hbase.spark.DefaultSourceSuite.scala</file>
      <file type="M">hbase-spark.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="15285" opendate="2016-2-17 00:00:00" fixdate="2016-2-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Forward-port respect for isReturnResult from HBASE-15095</summary>
      <description>This issue is about forward-porting the bug fix done in HBASE-15095 so we respect the isReturnResult properly in append and increment.</description>
      <version>1.2.0,2.0.0</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Mutation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Increment.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Append.java</file>
    </fixedFiles>
  </bug>
  <bug id="15289" opendate="2016-2-18 00:00:00" fixdate="2016-2-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add details about how to get usage instructions for Import and Export utilities</summary>
      <description>Some folks don't realize that you can specify options for the Import and Export commands, like limiting the column families or applying filters. Document how to see the usage.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="15297" opendate="2016-2-20 00:00:00" fixdate="2016-9-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>error message is wrong when a wrong namspace is specified in grant in hbase shell</summary>
      <description>In HBase shell, specify a non-existing namespace in "grant" command, such ashbase(main):001:0&gt; grant 'a1', 'R', '@aaa' &lt;--- there is no namespace called "aaa"The error message issued is not correctERROR: Unknown namespace a1!a1 is the user name, not the namespace.The following error message would be betterERROR: Unknown namespace aaa!orCan't find a namespace: aaa</description>
      <version>1.2.0,2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.security.rb</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
    </fixedFiles>
  </bug>
  <bug id="15298" opendate="2016-2-20 00:00:00" fixdate="2016-2-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix missing or wrong asciidoc anchors in the reference guide</summary>
      <description>There are some missing or wrong asciidoc anchors in the reference guide.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.zookeeper.adoc</file>
      <file type="M">src.main.asciidoc..chapters.ycsb.adoc</file>
      <file type="M">src.main.asciidoc..chapters.unit.testing.adoc</file>
      <file type="M">src.main.asciidoc..chapters.troubleshooting.adoc</file>
      <file type="M">src.main.asciidoc..chapters.security.adoc</file>
      <file type="M">src.main.asciidoc..chapters.schema.design.adoc</file>
      <file type="M">src.main.asciidoc..chapters.preface.adoc</file>
      <file type="M">src.main.asciidoc..chapters.performance.adoc</file>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
      <file type="M">src.main.asciidoc..chapters.faq.adoc</file>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
      <file type="M">src.main.asciidoc..chapters.datamodel.adoc</file>
      <file type="M">src.main.asciidoc..chapters.cp.adoc</file>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
      <file type="M">src.main.asciidoc..chapters.compression.adoc</file>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
      <file type="M">src.main.asciidoc..chapters.appendix.contributing.to.documentation.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="15302" opendate="2016-2-22 00:00:00" fixdate="2016-6-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reenable the other tests disabled by HBASE-14678</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALSplitter.java</file>
    </fixedFiles>
  </bug>
  <bug id="15310" opendate="2016-2-23 00:00:00" fixdate="2016-2-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase-spark module has compilation failures with clover profile</summary>
      <description>running with a clover profile enabled will fail due to cross compilation ordering issues with the hbase-spark module. 21:07:47 [ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.5.1:compile (default-compile) on project hbase-spark: Compilation failure: Compilation failure:21:07:47 [ERROR] /data/jenkins/workspace/CDH5.7.0-HBase-1.2.0-Clover/hbase-spark/target/clover/src-instrumented/org/apache/hadoop/hbase/spark/example/hbasecontext/JavaHBaseBulkDeleteExample.java:[23,36] error: cannot find symbol21:07:47 [ERROR] symbol: class JavaHBaseContext21:07:47 [ERROR] location: package org.apache.hadoop.hbase.spark21:07:47 [ERROR] /data/jenkins/workspace/CDH5.7.0-HBase-1.2.0-Clover/hbase-spark/target/clover/src-instrumented/org/apache/hadoop/hbase/spark/example/hbasecontext/JavaHBaseDistributedScan.java:[27,36] error: cannot find symbol.... (many classes)Apparently this is a known issue and this page shows a remedy. https://confluence.atlassian.com/display/CLOVERKB/Java-+Scala+cross-compilation+error+-+cannot+find+symbol</description>
      <version>2.0.0</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1532" opendate="2009-6-17 00:00:00" fixdate="2009-6-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>UI Visibility into ZooKeeper</summary>
      <description>Add ZooKeeper information/administration to UI.Discussion showed particular interest in a tree-viewer application, something like ZOOKEEPER-418.There was talk between Lars/JimK about how often the viewer should update its data.See HBASE-1329 for more information.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.webapps.master.master.jsp</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="15332" opendate="2016-2-25 00:00:00" fixdate="2016-2-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document how to take advantage of HDFS-6133 in HBase</summary>
      <description></description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.troubleshooting.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="15333" opendate="2016-2-25 00:00:00" fixdate="2016-5-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbase-spark] Enhance dataframe filters to handle naively encoded short, integer, long, float and double</summary>
      <description>Currently, the range filter is based on the order of bytes. But for java primitive type, such as short, int, long, double, float, etc, their order is not consistent with their byte order, extra manipulation has to be in place to take care of them correctly.For example, for the integer range (-100, 100), the filter &lt;= 1, the current filter will return 0 and 1, and the right return value should be (-100, 1]</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,connector-1.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.src.test.scala.org.apache.hadoop.hbase.spark.DynamicLogicExpressionSuite.scala</file>
      <file type="M">hbase-spark.src.test.scala.org.apache.hadoop.hbase.spark.DefaultSourceSuite.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.spark.sql.datasources.hbase.HBaseTableCatalog.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.DynamicLogicExpression.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.DefaultSource.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.datasources.package.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.datasources.HBaseSparkConf.scala</file>
      <file type="M">hbase-spark.src.main.protobuf.Filter.proto</file>
      <file type="M">hbase-spark.src.main.java.org.apache.hadoop.hbase.spark.SparkSQLPushDownFilter.java</file>
      <file type="M">hbase-spark.src.main.java.org.apache.hadoop.hbase.spark.protobuf.generated.FilterProtos.java</file>
    </fixedFiles>
  </bug>
  <bug id="15334" opendate="2016-2-25 00:00:00" fixdate="2016-3-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add avro support for spark hbase connector</summary>
      <description>Avro is a popular format for hbase storage. User may want the support natively in the connector.With the support, user can save serialized avro into hbase table, and then query on top of it using spark sql. The conversion between avro and catalyst datatype will be handled automatically. This is one way of support complex data types. Otherwise, user has to define their own customized Serdes to support complex data types.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.src.test.scala.org.apache.hadoop.hbase.spark.DefaultSourceSuite.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.spark.sql.datasources.hbase.HBaseTableCatalog.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.DefaultSource.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.datasources.Utils.scala</file>
      <file type="M">hbase-spark.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="15354" opendate="2016-2-26 00:00:00" fixdate="2016-3-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use same criteria for clearing meta cache for all operations</summary>
      <description>Currently we do not clear/update meta cache for some special exceptions if the operation went through AsyncProcess#submit like HTable#put calls. But, we clear meta cache without checking for these special exceptions in case of other operations like gets, deletes etc because they directly go through the RpcRetryingCaller#callWithRetries instead of the AsyncProcess.</description>
      <version>1.2.0,1.3.0,2.0.0</version>
      <fixedVersion>1.3.0,1.2.1,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMetaCache.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionServerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionAdminServiceCallable.java</file>
    </fixedFiles>
  </bug>
  <bug id="15356" opendate="2016-2-27 00:00:00" fixdate="2016-3-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove unused Imports</summary>
      <description>Remove unused Imports.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift.TestThriftHttpServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsckTwoRS.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MultiThreadedUpdaterWithACL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MultiThreadedAction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.OfflineMetaRebuildTestCore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestNamespace.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.MobSnapshotTestingUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRollPeriod.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestCustomWALCellCodec.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestScannerRetriableFailure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestQueryMatcher.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestEndToEndSplitTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompactSplitThread.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestQuotaState.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.procedure.TestProcedureMember.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestWALProcedureStoreOnHDFS.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMasterProcedureScheduler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMasterProcedureEvents.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestBaseLoadBalancer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapred.TestTableInputFormat.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat2.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.TestHFileLink.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestChangingEncoding.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestMasterObserver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMultiParallel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMobRestoreSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHTableMultiplexerFlushCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.TokenUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.model.TestNamespacesInstanceModel.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.TestYieldProcedures.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.wal.TestWALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.TestProcedureStoreTracker.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.mapreduce.IntegrationTestBulkLoad.java</file>
      <file type="M">hbase-hadoop2-compat.src.test.java.org.apache.hadoop.hbase.metrics.TestBaseSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.test.java.org.apache.hadoop.hbase.master.TestMetricsMasterSourceFactory.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKConfig.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.CategoryBasedTimeout.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKUtil.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.security.TestEncryptionUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="15358" opendate="2016-2-29 00:00:00" fixdate="2016-2-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>canEnforceTimeLimitFromScope should use timeScope instead of sizeScope</summary>
      <description>A small but maybe critical bug</description>
      <version>1.2.0,1.3.0,1.1.3,1.4.0,2.0.0</version>
      <fixedVersion>1.3.0,1.2.1,1.1.4,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ScannerContext.java</file>
    </fixedFiles>
  </bug>
  <bug id="15366" opendate="2016-3-1 00:00:00" fixdate="2016-4-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add doc, trace-level logging, and test around hfileblock</summary>
      <description>What hfileblock is doing &amp;#8211; that it overreads when pulling in from hdfs to fetch the header of the next block to save on seeks; that it caches the block and overread and then adds an extra 13 bytes to the cached entry; that buckets in bucketcache have at least four hfileblocks in them and so on &amp;#8211; was totally baffling me. This patch docs the class, adds some trace-level logging so you can see if you are doing the right thing, and then adds a test of file-backed bucketcache that checks that persistence is working.</description>
      <version>2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestBlocksRead.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileBlockCompatibility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileBlock.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestForceCacheImportantBlocks.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestChecksum.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestSeekToBlockWithEncoders.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestDataBlockEncoders.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileWriterImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.DataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="1537" opendate="2009-6-17 00:00:00" fixdate="2009-10-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Intra-row scanning</summary>
      <description>To continue scaling numbers of columns or versions in a single row, we need a mechanism to scan within a row so we can return some columns at a time. Currently, an entire row must come back as one piece.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestWideScanner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.MinorCompactingStoreScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.KeyValueHeap.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.InternalScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.regionserver.transactional.TransactionState.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="15371" opendate="2016-3-1 00:00:00" fixdate="2016-3-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure V2 - Completed support parent-child procedure</summary>
      <description>In Procedure-V2 Phase 1 (HBASE-14336), some infrastructure of supporting child procedure exists. However, there is no need in Phase 1 (master DDL) to have multi-level procedures. This JIRA implements adding child procedures to procedure execution list and execute them before parent procedure can make further progress.</description>
      <version>1.3.0,2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.TestProcedureRecovery.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.StateMachineProcedure.java</file>
    </fixedFiles>
  </bug>
  <bug id="15376" opendate="2016-3-2 00:00:00" fixdate="2016-3-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ScanNext metric is size-based while every other per-operation metric is time based</summary>
      <description>We have per-operation metrics for Get, Mutate, Delete, Increment, and ScanNext. The metrics are emitted like: "Get_num_ops" : 4837505, "Get_min" : 0, "Get_max" : 296, "Get_mean" : 0.2934618155433431, "Get_median" : 0.0, "Get_75th_percentile" : 0.0, "Get_95th_percentile" : 1.0, "Get_99th_percentile" : 1.0,... "ScanNext_num_ops" : 194705, "ScanNext_min" : 0, "ScanNext_max" : 18441, "ScanNext_mean" : 7468.274651395701, "ScanNext_median" : 583.0, "ScanNext_75th_percentile" : 583.0, "ScanNext_95th_percentile" : 13481.0, "ScanNext_99th_percentile" : 13481.0,The problem is that all of Get,Mutate,Delete,Increment,Append,Replay are time based tracking how long the operation ran, while ScanNext is tracking returned response sizes (returned cell-sizes to be exact). Obviously, this is very confusing and you would only know this subtlety if you read the metrics collection code. Not sure how useful is the ScanNext metric as it is today. We can deprecate it, and introduce a time based one to keep track of scan request latencies. ps. Shamelessly using the parent jira (since these seem relavant).</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegion.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="15377" opendate="2016-3-2 00:00:00" fixdate="2016-3-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Per-RS Get metric is time based, per-region metric is size-based</summary>
      <description>We have metrics for Get operations at the region server level and region level. "Get_num_ops" : 4837505, "Get_min" : 0, "Get_max" : 296, "Get_mean" : 0.2934618155433431, "Get_median" : 0.0, "Get_75th_percentile" : 0.0, "Get_95th_percentile" : 1.0, "Get_99th_percentile" : 1.0,and "Namespace_hbase_table_meta_region_1588230740_metric_get_num_ops" : 103, "Namespace_hbase_table_meta_region_1588230740_metric_get_min" : 450, "Namespace_hbase_table_meta_region_1588230740_metric_get_max" : 470, "Namespace_hbase_table_meta_region_1588230740_metric_get_mean" : 450.19417475728153, "Namespace_hbase_table_meta_region_1588230740_metric_get_median" : 460.0, "Namespace_hbase_table_meta_region_1588230740_metric_get_75th_percentile" : 470.0, "Namespace_hbase_table_meta_region_1588230740_metric_get_95th_percentile" : 470.0, "Namespace_hbase_table_meta_region_1588230740_metric_get_99th_percentile" : 470.0,The problem is that the report values for the region server shows the latency, versus the reported values for the region shows the response sizes. There is no way of telling this without reading the source code. I think we should deprecate response size histograms in favor of latency histograms. See also HBASE-15376.</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="1538" opendate="2009-6-17 00:00:00" fixdate="2009-6-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Up zookeeper timeout from 10 seconds to 30 seconds to cut down on hbase-user traffic</summary>
      <description>See hbase-dev and search for topic "Should we up the zk default time out from default 10 seconds to twenty or so?" to see discussion that arrives at yes, we should up the default from 10 seconds to 30 seconds.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="15385" opendate="2016-3-3 00:00:00" fixdate="2016-3-3 01:00:00" resolution="Invalid">
    <buginformation>
      <summary>A failed atomic folder rename operation can never recovery for the destination file is deleted in Wasb filesystem</summary>
      <description>When using Wsab file system, we found that a failed atomic folder rename operation can never recovery for the destination file deleted in Wasb filesystem. {quota}ls: Attempting to complete rename of file hbase/azurtst-xiaomi/data/default/YCSBTest/.tabledesc during folder rename redo, and file was not found in source or destination.The reason is the the file is renamed to the destination file before the crash, and the destination file is deleted by another process after crash. So the recovery is blocked during finishing the rename operation of this file when found the source and destination files all don't exist.See: NativeAzureFileSystem.java #finishSingleFileRenameAnother serious problem is that the recovery of atomic rename operation may delete new created file which is same name as the source file, because the file system don't check if there are rename operation need be redo.Suggestions are welcomed~</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.performance.adoc</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestPrefetch.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
    </fixedFiles>
  </bug>
  <bug id="15434" opendate="2016-3-9 00:00:00" fixdate="2016-3-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[findbugs] Exclude scala generated source and protobuf generated code in hbase-spark module</summary>
      <description>Findbugs against Scala compiler generated bytecode is known to generate false positives and spurious warnings. &amp;#91;1&amp;#93; Protobuf generated code has similar issues. This patch excludes these from the hbase-spark module&amp;#91;1&amp;#93; https://github.com/sbt/findbugs4sbt/issues/4</description>
      <version>2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,connector-1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.findbugs-exclude.xml</file>
    </fixedFiles>
  </bug>
  <bug id="15435" opendate="2016-3-9 00:00:00" fixdate="2016-3-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add WAL (in bytes) written metric</summary>
      <description>We have a histogram metrics related to wal bytes written, but we do not have a single metric to track the WAL in bytes written as a count per regionserver.</description>
      <version>None</version>
      <fixedVersion>1.3.0,0.98.18,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestMetricsWAL.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.MetricsWAL.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.wal.MetricsWALSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.wal.MetricsWALSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="15451" opendate="2016-3-13 00:00:00" fixdate="2016-3-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove unnecessary wait in MVCC</summary>
      <description>Currently the return value of MVCC#complete indicates whether readPoint already advanced over write number of the given WriteEntry:return readPoint.get() &gt;= writeEntry.getWriteNumber();While in MVCC#checkAndWait we never take usage of this but always call waitForRead which will acquire and release lock on readWaiters and cause additional context switch. This JIRA will improve this logic and remove the unnecessary wait.</description>
      <version>1.2.0,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.java</file>
    </fixedFiles>
  </bug>
  <bug id="15460" opendate="2016-3-14 00:00:00" fixdate="2016-3-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix infer issues in hbase-common</summary>
      <description></description>
      <version>1.2.0,2.0.0</version>
      <fixedVersion>1.3.0,0.98.19,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.test.LoadTestKVGenerator.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.JVM.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.DynamicClassLoader.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ClassSize.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Base64.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.nio.SingleByteBuff.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.HFileBlockDefaultDecodingContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.EncodedDataBlock.java</file>
    </fixedFiles>
  </bug>
  <bug id="15461" opendate="2016-3-14 00:00:00" fixdate="2016-8-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ref guide has bad links to blogs originally posted on cloudera website</summary>
      <description>The ref guide section on "Secure Client Access to Apache HBase" starts with a link to a blog post from Matteo, but the link is broken.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.troubleshooting.adoc</file>
      <file type="M">src.main.asciidoc..chapters.security.adoc</file>
      <file type="M">src.main.asciidoc..chapters.other.info.adoc</file>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="15463" opendate="2016-3-14 00:00:00" fixdate="2016-3-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Region normalizer should check whether split/merge is enabled</summary>
      <description>HBASE-15128 added switch for disabling split / merge.When split / merge switch is turned off, region normalizer should not perform split / merge operation, respectively.</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.normalizer.TestSimpleRegionNormalizer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.normalizer.SimpleRegionNormalizer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.normalizer.RegionNormalizer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="15464" opendate="2016-3-15 00:00:00" fixdate="2016-3-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Flush / Compaction metrics revisited</summary>
      <description>We can add a couple of metrics related to flushes and compactions: flush memstore and output file size histogram: This will allow seeing whether we are flushing too early due to memory pressure, too many regions, etc. Tracking flush memstore size vs output file size is useful in understanding the block encoding compression benefits. total flushed output bytes: This will allow to monitor the IO / throughput from flushers. You can use this to set num flushers, flush throttle, etc. smallCompactionQueueLength / large...: This is tracked, but not emitted anymore due to a bug. compaction time histogram: similar to flush time histogram, how long compactions are taking. compaction input num files / output num files histogram: How many files on average we are compacting. Stripe compaction / date tiered compaction can use the num output files metric. compaction input / output data sizes histogram: How much data on average we are compacting. compaction input / output total bytes: Measure compaction IO / throughput. measure write amplification, enables to set compaction throttle. Breakdown for above for major compactions</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStripeStoreEngine.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsRegionServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MockRegionServerServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StripeStoreEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFlushContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultStoreEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.flush.FlushTableSubprocedure.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="15473" opendate="2016-3-17 00:00:00" fixdate="2016-7-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Documentation for the usage of hbase dataframe user api (JSON, Avro, etc)</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,connector-1.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.spark.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="15479" opendate="2016-3-17 00:00:00" fixdate="2016-3-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>No more garbage or beware of autoboxing</summary>
      <description>Quick journey with JMC in a profile mode revealed very interesting and unexpected heap polluter on a client side. Patch will shortly follow.</description>
      <version>1.1.0,1.2.0,2.0.0</version>
      <fixedVersion>1.3.0,1.2.1,0.98.19,1.1.5,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
    </fixedFiles>
  </bug>
  <bug id="15502" opendate="2016-3-21 00:00:00" fixdate="2016-3-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Skeleton unit test to copy/paste</summary>
      <description>Add to our docs a skeleton unit test to copy/paste with all the vitals already filled out such as category and categorybasetimeout @Rule.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="15513" opendate="2016-3-22 00:00:00" fixdate="2016-11-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase.hregion.memstore.chunkpool.maxsize is 0.0 by default</summary>
      <description>That results in excessive MemStoreLAB chunk allocations because we can not reuse them. Not sure, why it has been disabled, by default. May be the code has not been tested well?</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMemStoreLAB.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreChunkPool.java</file>
    </fixedFiles>
  </bug>
  <bug id="15515" opendate="2016-3-22 00:00:00" fixdate="2016-3-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve LocalityBasedCandidateGenerator in Balancer</summary>
      <description>There are some problems which need to fix.1. LocalityBasedCandidateGenerator.getLowestLocalityRegionOnServer should skip empty region.2. When use LocalityBasedCandidateGenerator to generate Cluster.Action, it should add random operation instead of pickLowestLocalityServer(cluster). Because the search function may stuck here if it always generate the same Cluster.Action.3. getLeastLoadedTopServerForRegion should get least loaded server which have better locality than current server.</description>
      <version>1.3.0,2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.RegionLocationFinder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
    </fixedFiles>
  </bug>
  <bug id="15518" opendate="2016-3-22 00:00:00" fixdate="2016-4-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add Per-Table metrics back</summary>
      <description>We used to have per-table metrics, but it was removed in some restructuring. We have per-region metrics, and per-regionserver metrics, but nothing in between. For majority of users, per-region is too granular, they are mostly interested in table level aggregates. This is especially useful in multi-tenant cases where a table's disk usage, number of requests, etc can be made much more visible. In this jira, we'll add the basic infrastructure to add a single (or a few) per-table metrics. Than we can improve on that by adding remaining metrics from the region server level. The plan is to NOT aggregate per-table metrics at master for now. Just aggregation of per-region metrics at the per-table level for every regionserver.</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceFactoryImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="15521" opendate="2016-3-23 00:00:00" fixdate="2016-4-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure V2 - RestoreSnapshot and CloneSnapshot</summary>
      <description>Implement procedure-v2 based restore snapshot and clone snapshot (both server and client side change).</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestProcedureAdmin.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMasterFailoverWithProcedures.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestDeleteTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestCreateTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotCloneIndependence.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.RestoreSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.CloneSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterDDLOperationHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.MasterProcedure.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Master.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MasterProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureExecutor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
    </fixedFiles>
  </bug>
  <bug id="15537" opendate="2016-3-26 00:00:00" fixdate="2016-4-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make multi WAL work with WALs other than FSHLog</summary>
      <description>The multi WAL should not be bound with FSHLog.</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestBoundedRegionGroupingStrategy.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.multiwal.TestReplicationSyncUpToolWithMultipleWAL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.multiwal.TestReplicationKillMasterRSCompressedWithMultipleWAL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.multiwal.TestReplicationEndpointWithMultipleWAL.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.RegionGroupingProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.AbstractFSWALProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.java</file>
    </fixedFiles>
  </bug>
  <bug id="15538" opendate="2016-3-26 00:00:00" fixdate="2016-3-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement secure async protobuf wal writer</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestSecureWAL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.IOTestProvider.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.InstrumentedLogWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.AsyncFSWALProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AbstractProtobufLogWriter.java</file>
    </fixedFiles>
  </bug>
  <bug id="15586" opendate="2016-4-1 00:00:00" fixdate="2016-4-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unify human readable numbers in the web UI</summary>
      <description>I was looking at something else in the regionserver web ui trying to understand the WAL size, and we are reporting that as raw bytes, not in MB / GB range. Did a quick sweep to unify all the human-readable representations in the UI.</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.RegionServerListTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="15597" opendate="2016-4-6 00:00:00" fixdate="2016-3-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up configuration keys used in hbase-spark module</summary>
      <description>This should be considered a blocker for backport to branch-1 since it will impact our compatibility.The constants we expose in configuration should all start with "hbase". Since our configurations keys for the spark integration all relate to that system, the prefix for all configuration keys (excluding those cases where we need to do something special due to restrictions in how properties are handled by e.g. spark) should be "hbase.spark".Before publishing a public api labeled version of our spark integration we should review all of our configuration keys to make sure they either conform to the "hbase.spark" prefix or they have a comment documenting why they need to be otherwise.</description>
      <version>2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,connector-1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.src.test.scala.org.apache.hadoop.hbase.spark.PartitionFilterSuite.scala</file>
      <file type="M">hbase-spark.src.test.scala.org.apache.hadoop.hbase.spark.HBaseTestSource.scala</file>
      <file type="M">hbase-spark.src.test.scala.org.apache.hadoop.hbase.spark.DynamicLogicExpressionSuite.scala</file>
      <file type="M">hbase-spark.src.test.scala.org.apache.hadoop.hbase.spark.DefaultSourceSuite.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.HBaseConnectionCache.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.DefaultSource.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.datasources.HBaseSparkConf.scala</file>
    </fixedFiles>
  </bug>
  <bug id="15605" opendate="2016-4-7 00:00:00" fixdate="2016-4-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove PB references from HCD and HTD for 2.0</summary>
      <description>This task is sub-task for HBASE-15174.</description>
      <version>2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestSnapshotManifest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.TableDescriptor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotManifest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.TruncateTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.RestoreSnapshotProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CloneSnapshotProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.AddColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
    </fixedFiles>
  </bug>
  <bug id="15608" opendate="2016-4-7 00:00:00" fixdate="2016-5-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove PB references from SnapShot related Exceptions</summary>
      <description>This is a sub-task for HBASE-15174.</description>
      <version>2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotManifest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.MasterSnapshotVerifier.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CloneSnapshotProcedure.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotExistsException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotDoesNotExistException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotCreationException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.RestoreSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.HBaseSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.CorruptedSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.SnapshotDescription.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="15613" opendate="2016-4-7 00:00:00" fixdate="2016-5-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestNamespaceCommand times out</summary>
      <description>We think that the root cause maybe HBASE-15295. Will inspect more. Seehttps://issues.apache.org/jira/browse/HBASE-15537?page=com.atlassian.jira.plugin.system.issuetabpanels:all-tabpanel</description>
      <version>None</version>
      <fixedVersion>1.3.0,1.1.5,1.2.2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.resources.hbase-site.xml</file>
    </fixedFiles>
  </bug>
  <bug id="15623" opendate="2016-4-9 00:00:00" fixdate="2016-4-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update refguide to change hadoop &lt;= 2.3.x from NT to X for hbase-1.2.x</summary>
      <description>This issue is about updating our hadoop supported versions grid in the prerequisites section of refguide. Here is thread proposing this change up on dev list: http://osdir.com/ml/general/2016-04/msg09194.html</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="15628" opendate="2016-4-11 00:00:00" fixdate="2016-4-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement an AsyncOutputStream which can work with any FileSystem implementation</summary>
      <description>Used for testcase only.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestSaslFanOutOneBlockAsyncDFSOutput.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestFanOutOneBlockAsyncDFSOutput.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.FanOutOneBlockAsyncDFSOutputFlushHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestAsyncProtobufLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FanOutOneBlockAsyncDFSOutputSaslHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FanOutOneBlockAsyncDFSOutputHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FanOutOneBlockAsyncDFSOutput.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AsyncProtobufLogWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputHelper.java</file>
    </fixedFiles>
  </bug>
  <bug id="15646" opendate="2016-4-13 00:00:00" fixdate="2016-5-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add some docs about exporting and importing snapshots using S3</summary>
      <description>Got a request to add this and wrote something up using the info I could scrounge together.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="15664" opendate="2016-4-17 00:00:00" fixdate="2016-4-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use Long.MAX_VALUE instead of HConstants.FOREVER in CompactionPolicy</summary>
      <description>The TTL per CF is in seconds, we will convert it to milliseconds when construct HStore. And if it is HConstants.FOREVER, we will set it to Long.MAX_VALUE.HStore.java public static long determineTTLFromFamily(final HColumnDescriptor family) { // HCD.getTimeToLive returns ttl in seconds. Convert to milliseconds. long ttl = family.getTimeToLive(); if (ttl == HConstants.FOREVER) { // Default is unlimited ttl. ttl = Long.MAX_VALUE; } else if (ttl == -1) { ttl = Long.MAX_VALUE; } else { // Second -&gt; ms adjust for user data ttl *= 1000; } return ttl; }</description>
      <version>1.3.0,0.98.19,1.4.0,2.0.0</version>
      <fixedVersion>1.3.0,0.98.19,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.RatioBasedCompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.DateTieredCompactionPolicy.java</file>
    </fixedFiles>
  </bug>
  <bug id="15684" opendate="2016-4-21 00:00:00" fixdate="2016-10-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix the broken log file size accounting</summary>
      <description>long oldFileLen = 0L; doReplaceWriter(oldPath, newPath, nextWriter);Should belong oldFileLen = doReplaceWriter(oldPath, newPath, nextWriter);</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.AbstractTestLogRolling.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.AbstractFSWALProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.java</file>
    </fixedFiles>
  </bug>
  <bug id="15685" opendate="2016-4-21 00:00:00" fixdate="2016-4-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Typo in REST documentation</summary>
      <description>The Chapter - REST of HBase Book has a few typo in the provided example links, like "http://example.com:8000&lt;table&gt;/&lt;row&gt;/&lt;column&gt;:&lt;qualifier&gt;?v=&lt;num-versions&gt;" which misses a forward slash between the port number 8000 and table name.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.external.apis.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="15707" opendate="2016-4-25 00:00:00" fixdate="2016-4-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ImportTSV bulk output does not support tags with hfile.format.version=3</summary>
      <description>Running the following command:hbase hbase org.apache.hadoop.hbase.mapreduce.ImportTsv \ -Dhfile.format.version=3 \ -Dmapreduce.map.combine.minspills=1 \ -Dimporttsv.separator=, \ -Dimporttsv.skip.bad.lines=false \ -Dimporttsv.columns="HBASE_ROW_KEY,cf1:a,HBASE_CELL_TTL" \ -Dimporttsv.bulk.output=/tmp/testttl/output/1 \ testttl \ /tmp/testttl/input The content of input is like:row1,data1,00000060 row2,data2,00000660 row3,data3,00000060 row4,data4,00000660When running hfile tool with the output hfile, there is no ttl tag.</description>
      <version>1.3.0,1.0.4,1.4.0,1.1.5,1.2.2,2.0.0</version>
      <fixedVersion>1.3.0,0.98.20,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.HBaseContext.scala</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.java</file>
    </fixedFiles>
  </bug>
  <bug id="15728" opendate="2016-4-27 00:00:00" fixdate="2016-3-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add remaining per-table region / store / flush / compaction related metrics</summary>
      <description>Continuing on the work for per-table metrics, HBASE-15518 and HBASE-15671. We need to add some remaining metrics at the per-table level, so that we will have the same metrics reported at the per-regionserver, per-region and per-table levels. After this patch, most of the metrics at the RS and all of the per-region level are also reported at the per-table level.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsTableAggregate.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsRegionServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.MetricsTableWrapperStub.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperStub.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregateImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-hadoop2-compat.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsTableSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsTableAggregateSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregate.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsTableSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsTableAggregateSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsTableSourceImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="15729" opendate="2016-4-27 00:00:00" fixdate="2016-5-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove old JDiff wrapper scripts in dev-support</summary>
      <description>Since HBASE-12808, we've been using the Java API Compliance Checker instead of JDiff to look at API compatibility. Probably makes sense to remove the old wrapper scripts that aren't being used anymore.</description>
      <version>None</version>
      <fixedVersion>1.3.0,1.2.2,1.1.6,0.98.21,2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.jdiffHBasePublicAPI.common.sh</file>
      <file type="M">dev-support.jdiffHBasePublicAPI.sh</file>
      <file type="M">dev-support.hbase.jdiff.template.xml</file>
      <file type="M">dev-support.hbase.jdiff.afterSingularityTemplate.xml</file>
      <file type="M">dev-support.hbase.jdiff.acrossSingularityTemplate.xml</file>
    </fixedFiles>
  </bug>
  <bug id="15732" opendate="2016-4-28 00:00:00" fixdate="2016-4-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase-rsgroups should be in the assembly</summary>
      <description>hbase-rsgroup is a new module that does not appear in the assembly. The binary tarball still contains the jars through dependencies, but we need the test-jar as well for running the IntegrationTestRSGroup. toffer can you take a quick look.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-assembly.src.main.assembly.src.xml</file>
      <file type="M">hbase-assembly.src.main.assembly.hadoop-two-compat.xml</file>
      <file type="M">hbase-assembly.src.main.assembly.components.xml</file>
      <file type="M">hbase-assembly.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="15735" opendate="2016-4-29 00:00:00" fixdate="2016-5-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Tightening of the CP contract</summary>
      <description>This is after the discussion in dev@ under 'DISCUSSION: A tightening of the CP contract in hbase 2.0.0'"CPs can read Cells passed them on a CP hook invocation butthey must not retain references beyond the life of the invocation; theymust copy Cells if they intend to retain them beyond the invocation, passthe Cells off to upper tiers, or return them otherwise to clients."Also this Jira will cleanup some code which was doing the copy of the Cells while passing to CP hooks assuming it might keep cell refs. Now as we say it explicitly in CP APIs, we dont need this copy.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestScannerHeartbeatMessages.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestSeekTo.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestScannerFromBucketCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ReversedRegionScannerImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionObserver.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ShareableMemory.java</file>
    </fixedFiles>
  </bug>
  <bug id="15744" opendate="2016-5-1 00:00:00" fixdate="2016-5-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Port over small format/text improvements from HBASE-13784</summary>
      <description>I want to close HBASE-13784 so I am breaking it up in smaller subissues. This issue addresses the smaller code/text improvements in the patch. They are trivial but it is a shame to have them lost.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCaller.java</file>
    </fixedFiles>
  </bug>
  <bug id="15754" opendate="2016-5-3 00:00:00" fixdate="2016-5-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add testcase for AES encryption</summary>
      <description>As discussed in mailing list.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.asyncfs.TestSaslFanOutOneBlockAsyncDFSOutput.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputSaslHelper.java</file>
    </fixedFiles>
  </bug>
  <bug id="15767" opendate="2016-5-4 00:00:00" fixdate="2016-5-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade httpclient dependency</summary>
      <description>Currently commons-httpclient 3.1 is used.This is already end-of-life by apache.We should move to 4.3.6 or later.Details:https://issues.apache.org/jira/browse/HADOOP-12767https://issues.apache.org/jira/browse/HADOOP-10105https://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2015-5262 : http/conn/ssl/SSLConnectionSocketFactory.java in Apache HttpComponents HttpClient before 4.3.6 ignores the http. socket.timeout configuration setting during an SSL handshake, which allows remote attackers to cause a denial of service (HTTPS call hang) via unspecified vectors.https://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2012-6153https://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2012-5783Apache Commons HttpClient 3.x, as used in Amazon Flexible Payments Service (FPS) merchant Java SDK and other products, does not verify that the server hostname matches a domain name in the subject's Common Name (CN) or subjectAltName field of the X.509 certificate, which allows man-in-the-middle attackers to spoof SSL servers via an arbitrary valid certificate.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-rest.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="15768" opendate="2016-5-4 00:00:00" fixdate="2016-5-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>fix capitalization of ZooKeeper usage</summary>
      <description>Apache ZooKeeper is a proper name (ref), figured I'd fix mentions of "Zookeeper" that appear throughout the codebase and documentation.Ignoring camelcase function names, focused primarily on visible errors, logs, comments, and UI strings.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.zookeeper.adoc</file>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
      <file type="M">src.main.asciidoc..chapters.getting.started.adoc</file>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZooKeeperACL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestIPv6NIOServerSocketChannel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestFilterWrapper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.FilterTestingCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestMasterCoprocessorExceptionWithRemove.java</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.zk.jsp</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessLockBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ZNodeClearer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ZKNamespaceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.ZKVisibilityLabelWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.AuthenticationTokenSecretManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.ZKPermissionWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSyncUp.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HMobStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.mapreduce.SweepJobNodeTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.mapreduce.SweepJob.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CreateNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestZKAndFSPermissions.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.HBaseClusterManager.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.DistributedHBaseCluster.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterSource.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationTrackerZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueuesZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeersZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ZooKeeperRegistry.java</file>
      <file type="M">hbase-archetypes.hbase-shaded-client-project.src.main.java.org.apache.hbase.archetypes.exemplars.shaded.client.HelloHBase.java</file>
      <file type="M">hbase-archetypes.hbase-client-project.src.main.java.org.apache.hbase.archetypes.exemplars.client.HelloHBase.java</file>
      <file type="M">conf.hbase-env.sh</file>
      <file type="M">conf.hbase-env.cmd</file>
      <file type="M">bin.hbase.cmd</file>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug id="1577" opendate="2009-6-23 00:00:00" fixdate="2009-6-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move memcache to ConcurrentSkipListMap from ConcurrentSkipListSet</summary>
      <description>The CSLM will replace old entry with a new when you put. The CSLS will NOT replace if existent key making for a test, and if present, remove semantic which to be safe needs synchronizing (Replacement is a Ryan Rawson suggestion).</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestStore.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestMemStore.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.client.TestOldAPIGetRowVersions.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.MemStore.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestMemcache.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Memcache.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.BaseScanner.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="15776" opendate="2016-5-5 00:00:00" fixdate="2016-5-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace master.am.getTableStateManager() with the direct master.getTableStateManager()</summary>
      <description>Replace the double lookup master.getAssignmentManager().getTableStateManager() with the direct master.getTableStateManager().this also because I'd like to remove the TableStateManager instance from the new AM.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterRestartAfterDisablingTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin1.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterDDLOperationHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.EnableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DisableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.AddColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="15784" opendate="2016-5-6 00:00:00" fixdate="2016-5-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Misuse core/maxPoolSize of LinkedBlockingQueue in ThreadPoolExecutor</summary>
      <description>LinkedBlockingQueue is usually used in ThreadPoolExecutor. It allows the thread pool not to be blocked if the number of running threads in the pool is less than the max pool size and the queue is not full.But when the core pool size of ThreadPoolExecutor is different from the max pool size, the things don't go as expected. When the number of running threads is the same with the core size, more requests of executions are added into the LinkedBlockingQueue. And the requests can be executed again only when LinkedBlockingQueue is full or some of running threads are finished.Thus it is better to use the same value for the core and max pool size when the LinkedBlockingQueue is used.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.TBoundedThreadPoolServer.java</file>
      <file type="M">hbase-server.src.test.resources.hbase-site.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsckTwoRS.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsckReplicas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsckOneRS.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsckMOB.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.MultiHConnection.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.HFileReplicator.java</file>
      <file type="M">hbase-client.src.test.resources.hbase-site.xml</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
    </fixedFiles>
  </bug>
  <bug id="15786" opendate="2016-5-6 00:00:00" fixdate="2016-11-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create DBB backed MSLAB pool</summary>
      <description>We can make use of MSLAB pool for this off heap memstore. Right now one can specify the global memstore size (heap size) as a % of max memory using a config. We will add another config with which one can specify the global off heap memstore size. This will be exact size not as %. When off heap memstore in use, we will give this entire area for the MSLAB pool and that will create off heap chunks. So when cells are added to memstore, the cell data gets copied into the off heap MSLAB chunk spaces. Note that when the pool size is not really enough and we need additional chunk creation, we wont use off heap area for that. We dony want to create so many on demand DBBs.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMemStoreLAB.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMemStoreChunkPool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHeapMemoryManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDefaultMemStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompactingMemStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCellFlatSet.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestSingleColumnValueFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SegmentFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreLAB.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreChunkPool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HeapMemStoreLAB.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HeapMemoryManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultHeapMemoryTuner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Chunk.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeCell.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestOffheapKeyValue.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestCellUtil.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestCellComparator.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.io.TestTagCompressionContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteBufferUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.OffheapKeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValueUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.util.HeapMemorySizeUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.RowIndexSeekerV1.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.AbstractDataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HBaseConfiguration.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ExtendedCell.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellComparator.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ByteBufferedKeyOnlyKeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ByteBufferedCell.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.filter.TestKeyOnlyFilter.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.filter.TestComparators.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.PrefixFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.KeyOnlyFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ColumnPrefixFilter.java</file>
    </fixedFiles>
  </bug>
  <bug id="15787" opendate="2016-5-6 00:00:00" fixdate="2016-12-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change the flush related heuristics to work with offheap size configured</summary>
      <description>With offheap MSLAB in place we may have to change the flush related heuristics to work with offheap size configured rather than the java heap size.Since we now have clear seperation of the memstore data size and memstore heap size, for offheap memstore-&gt; Decide if the global.offheap.memstore.size is breached for blocking updates and force flushes. -&gt; If the onheap global.memstore.size is breached (due to heap overhead) even then block updates and force flushes.-&gt; The global.memstore.size.lower.limit is now by default 95% of the global.memstore.size. So now we apply this 95% on the global.offheap.memstore.size and also on global.memstore.size (as it was done for onheap case).-&gt; We will have new FlushTypes introduced ABOVE_ONHEAP_LOWER_MARK, /* happens due to lower mark breach of onheap memstore settings An offheap memstore can even breach the onheap_lower_mark*/ ABOVE_ONHEAP_HIGHER_MARK,/* happens due to higher mark breach of onheap memstore settings An offheap memstore can even breach the onheap_higher_mark*/ ABOVE_OFFHEAP_LOWER_MARK,/* happens due to lower mark breach of offheap memstore settings*/ ABOVE_OFFHEAP_HIGHER_MARK;-&gt; regionServerAccounting does all the accounting.-&gt; HeapMemoryTuner is what is litte tricky here. First thing to note is that at no point it will try to increase or decrease the global.offheap.memstore.size. If there is a heap pressure then it will try to increase the memstore heap limit. In case of offheap memstore there is always a chance that the heap pressure does not increase. In that case we could ideally decrease the heap limit for memstore. The current logic of heapmemory tuner is such that things will naturally settle down. But on discussion what we thought is let us include the flush count that happens due to offheap pressure but give that a lesser weightage and thus ensure that the initial decrease on memstore heap limit does not happen. Currently that fraction is set as 0.5.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestGlobalMemStoreSize.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionReplayEvents.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHeapMemoryManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerAccounting.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsHeapMemoryManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreChunkPool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HeapMemoryManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultHeapMemoryTuner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.util.MemorySizeUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="15789" opendate="2016-5-6 00:00:00" fixdate="2016-10-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>PB related changes to work with offheap</summary>
      <description>This is an issue to brainstorm. Whether we go with pb 2.x or pb 3.0 and also depends on the shading of protobuf classes. We should also decide if we are going to fork the PB classes.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-protocol.pom.xml</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Utf8.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteBufferWriter.java</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-protocol-shaded.src.main.patches.HBASE-15789.V2.patch</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteInputByteString.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteInput.java</file>
      <file type="M">hbase-protocol-shaded.README.txt</file>
      <file type="M">hbase-protocol-shaded.pom.xml</file>
      <file type="M">hbase-assembly.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="15796" opendate="2016-5-7 00:00:00" fixdate="2016-5-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestMetaCache fails after HBASE-15745</summary>
      <description>HBASE-15745 broke TestMetaCache. Seems I made a mistake by committing the AsyncRpcChannelImpl of the patch version of the older HBASE-13784 instead of basing in on current code.(Checked the other abstracted classes and did not make the same mistake with the others)</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AbstractRegionServerCallable.java</file>
    </fixedFiles>
  </bug>
  <bug id="15801" opendate="2016-5-9 00:00:00" fixdate="2016-5-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade checkstyle for all branches</summary>
      <description>We should use the same checkstyle for all branches.</description>
      <version>1.3.0,1.2.1,1.0.3,0.98.19,1.4.0,1.1.5,2.0.0</version>
      <fixedVersion>1.3.0,1.0.4,1.2.2,0.98.20,1.1.6,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="15806" opendate="2016-5-9 00:00:00" fixdate="2016-8-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>An endpoint-based export tool</summary>
      <description>The time for exporting table can be reduced, if we use the endpoint technique to export the hdfs files by the region server rather than by hbase client.In my experiments, the elapsed time of endpoint-based export can be less than half of current export tool (enable the hdfs compression)But the shortcomings is we need to alter table for deploying the endpointany comments about this? thanks</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.SecureTestUtil.java</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.mapreduce.TestImportExport.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.Export.java</file>
      <file type="M">hbase-endpoint.pom.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestImportExport.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.Export.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.ExportEndpoint.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Export.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ExportProtos.java</file>
      <file type="M">hbase-protocol.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1581" opendate="2009-6-24 00:00:00" fixdate="2009-6-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Run major compaction on .META. when table is dropped or truncated</summary>
      <description>Add to shell major compacting of .META. on drop or truncate. Implementing this workaround in scripts will narrow the number exposed to the issue where on recreate of a a just-dropped table, they can get erratic results querying meta.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.HBase.rb</file>
    </fixedFiles>
  </bug>
  <bug id="15816" opendate="2016-5-11 00:00:00" fixdate="2016-7-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Provide client with ability to set priority on Operations</summary>
      <description>First round will just be to expose the ability to set priorities for client operations. For more background: http://mail-archives.apache.org/mod_mbox/hbase-dev/201604.mbox/%3CCA+RK=_BG_o=q8HMptcP2WauAinmEsL+15f3YEJuz=qbpcya5-g@mail.gmail.com%3ENext step would be to remove AnnotationReadingPriorityFunction and have the client send priorities explicitly.</description>
      <version>2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionServerBulkLoadWithOldClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionServerBulkLoad.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestSpaceQuotas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFilesSplitRecovery.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.TestHeapSize.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestReplicaWithCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALEditsReplaySink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
      <file type="M">hbase-endpoint.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionServerBulkLoadWithOldSecureEndpoint.java</file>
      <file type="M">hbase-endpoint.src.test.java.org.apache.hadoop.hbase.client.TestRpcControllerFactory.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.IPCUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.HBaseRpcControllerImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.HBaseRpcController.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.SecureBulkLoadClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RowMutations.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionServerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionCoprocessorRpcChannel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.OperationWithAttributes.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.NoncedRegionServerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Mutation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MultiServerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MultiAction.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Increment.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Get.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Delete.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientServiceCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.CancellableRegionServerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRequestFutureImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Append.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Action.java</file>
    </fixedFiles>
  </bug>
  <bug id="1583" opendate="2009-6-25 00:00:00" fixdate="2009-7-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Start/Stop of large cluster untenable</summary>
      <description>Starting and stopping a loaded large cluster is way too flakey and takes too long. This is 0.19.x but same issues apply to TRUNK I'd say.At pset with our &gt; 100 nodes carrying 6k regions:+ shutdown takes way too long.... maybe ten minutes or so. We compact regions inline with shutdown. We should just go down. It doesn't seem like all regionservers go down everytime either.+ startup is a mess with our assigning out regions an rebalancing at same time. By time that the compactions on open run, it can be near an hour before whole thing settles down and becomes useable</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="15837" opendate="2016-5-16 00:00:00" fixdate="2016-5-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Memstore size accounting is wrong if postBatchMutate() throws exception</summary>
      <description>Over in PHOENIX-2883, I've been trying to figure out how to track down the root cause of an issue we were seeing where a negative memstoreSize was ultimately causing an RS to abort. The tl;dr version is Something causes memstoreSize to be negative (not sure what is doing this yet) All subsequent flushes short-circuit and don't run because they think there is no data to flush The region is eventually closed (commonly, for a move). A final flush is attempted on each store before closing (which also short-circuit for the same reason), leaving unflushed data in each store. The sanity check that each store's size is zero fails and the RS aborts.I have a little patch which I think should improve our failure case around this, preventing the RS abort safely (forcing a flush when memstoreSize is negative) and logging a calltrace when an update to memstoreSize make it negative (to find culprits in the future).</description>
      <version>None</version>
      <fixedVersion>1.3.0,1.2.2,0.98.20,1.1.6,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="15844" opendate="2016-5-17 00:00:00" fixdate="2016-7-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>We should respect hfile.block.index.cacheonwrite when write intermediate index Block</summary>
      <description>BlockIndexWriter#writeIntermediateBlock if (cacheConf != null) { HFileBlock blockForCaching = blockWriter.getBlockForCaching(cacheConf); cacheConf.getBlockCache().cacheBlock(new BlockCacheKey(nameForCaching, beginOffset, true, blockForCaching.getBlockType()), blockForCaching); }The if condition should be ?if (cacheConf != null &amp;&amp; cacheConf.shouldCacheIndexesOnWrite())</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
    </fixedFiles>
  </bug>
  <bug id="15864" opendate="2016-5-19 00:00:00" fixdate="2016-5-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reuse the testing helper to wait regions in transition</summary>
      <description>There are a bunch of unit test that do the same loop to wait for region in transitions. get rid of the duplicate code and call the helpers.</description>
      <version>1.3.0,1.2.1,2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsckOneRS.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildOverlap.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildHole.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestRegionRebalancing.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.handler.TestTableDeleteFamilyHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat2.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestMasterObserver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
    </fixedFiles>
  </bug>
  <bug id="15876" opendate="2016-5-22 00:00:00" fixdate="2016-5-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove doBulkLoad(Path hfofDir, final HTable table) though it has not been through a full deprecation cycle</summary>
      <description>HBASE-15875 purges the properly deprecated HTable. The method doBulkLoad(Path hfofDir, final HTable table), while it has a deprecated param, the method itself did not get a deprecation label; it is a public method in a public class marked stable. This issue is about getting consensus that it is ok to remove this method used by offline tooling that will break until updated on upgrade to 2.0 w/o a proper deprecation cycle (I think it will be ok to do this &amp;#8211; the benefit of our being able to remove HTable is worth this minor inconvenience). We'll do some ugly patching of this oversight by adding a late deprecation and flagging the removal of this offline method as an incompatible change in 2.0. We'll add the deprecation in a subissue.It is a problem removing doBulkLoad(Path hfofDir, final HTable table) ... since this is a public/stable Class.There is the alternate: public void doBulkLoad(Path hfofDir, final Admin admin, Table table, RegionLocator regionLocator) throws TableNotFoundException, IOException {The former calls the latter.The latter went in here:commit ac95cc1fbb951bb9db96f2738f621d1d7cd45739Author: tedyu &lt;yuzhihong@gmail.com&gt;Date: Fri Jan 2 19:48:06 2015 -0800 HBASE-12783 Create efficient RegionLocator implementation (Solomon Duskis)This was added in time for release 1.1.0.So, this method has not gone through a full major version of deprecation.It will break when someone moves to 2.0. But it is offline method. Not the end of the world.</description>
      <version>2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.compactions.PartitionedMobCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
    </fixedFiles>
  </bug>
  <bug id="15921" opendate="2016-5-31 00:00:00" fixdate="2016-10-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add first AsyncTable impl and create TableImpl based on it</summary>
      <description>First we create an AsyncTable interface with implementation without the Scan functionality. Those will land in a separate patch since they need a refactor of existing scans.Also added is a new TableImpl to replace HTable. It uses the AsyncTableImpl internally and should be a bit faster because it does jump through less hoops to do ProtoBuf transportation. This way we can run all existing tests on the AsyncTableImpl to guarantee its quality.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ReflectionUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.CollectionUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
    </fixedFiles>
  </bug>
  <bug id="15935" opendate="2016-6-1 00:00:00" fixdate="2016-7-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Have a separate Walker task running concurrently with Generator</summary>
      <description>Keep track of which linked lists have been flushed in an HBase table, so that we can concurrently Walk these lists during the Generation phase. This will allow us to test:1. HBase under concurrent read/writes2. Availability of data immediately after flushes (as opposed to waiting till the Verification phase)The review diff can be found at:https://reviews.apache.org/r/48294/</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestReplication.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedListWithVisibility.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
    </fixedFiles>
  </bug>
  <bug id="15938" opendate="2016-6-2 00:00:00" fixdate="2016-6-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>submit-patch.py: Don&amp;#39;t crash if there are tests with same name. Refactor: Split out html template to separate file.</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.report-flakies.py</file>
      <file type="M">dev-support.findHangingTests.py</file>
    </fixedFiles>
  </bug>
  <bug id="1594" opendate="2009-6-30 00:00:00" fixdate="2009-6-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix scan addcolumns after hbase-1385 commit (broken hudson build)</summary>
      <description>These are broken up on hudson after 1385 went in. Looking at whats failing, seems like issues with old style vs. new style specifying column names and that our addColumn should just handle them. Did some fix up.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.client.TestOldAPITimestamp.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TimestampTestBase.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestScanner.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.client.TestTimestamp.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="15943" opendate="2016-6-2 00:00:00" fixdate="2016-7-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add page displaying JVM process metrics</summary>
      <description>It would be useful to have page displaying some JVM metrics like PID, process owner. threads info, GC info, etc. This ticked will create two jsp pages (for master and rs) displaying stats listed above.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.regionserver.region.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.zk.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.tablesDetailed.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.snapshot.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.procedures.jsp</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="15944" opendate="2016-6-2 00:00:00" fixdate="2016-6-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Spark test flooding mvn output. Redirect test logs to file.</summary>
      <description>INFO] --- maven-jar-plugin:2.4:jar (default-jar) @ hbase-spark ---[INFO] Building jar: /Users/appy/apache/hbase/hbase-spark/target/hbase-spark-2.0.0-SNAPSHOT.jar[INFO][INFO] --- scalatest-maven-plugin:1.0:test (integration-test) @ hbase-spark ---Discovery starting.Discovery completed in 2 seconds, 434 milliseconds.Run starting. Expected test count is: 78HBaseDStreamFunctionsSuite:2016-06-02 01:04:05,208 INFO [ScalaTest-main-running-DiscoverySuite] hbase.HBaseTestingUtility(1029): Starting up minicluster with 1 master(s) and 1 regionserver(s) and 1 datanode(s)2016-06-02 01:04:05,216 INFO [ScalaTest-main-running-DiscoverySuite] hbase.HBaseTestingUtility(512): Created new mini-cluster data directory: /Users/appy/apache/hbase/hbase-spark/target/test-data/a075b24a-36fe-48a9-80c5-31b983a29a8e/dfscluster_d7a5357d-4269-4451-afc6-f456a2392469, deleteOnExit=true2016-06-02 01:04:05,217 INFO [ScalaTest-main-running-DiscoverySuite] hbase.HBaseTestingUtility(759): Setting test.cache.data to /Users/appy/apache/hbase/hbase-spark/target/test-data/a075b24a-36fe-48a9-80c5-31b983a29a8e/cache_data in system properties and HBase conf2016-06-02 01:04:05,217 INFO [ScalaTest-main-running-DiscoverySuite] hbase.HBaseTestingUtility(759): Setting hadoop.tmp.dir to /Users/appy/apache/hbase/hbase-spark/target/test-data/a075b24a-36fe-48a9-80c5-31b983a29a8e/hadoop_tmp in system properties and HBase conf2016-06-02 01:04:05,218 INFO [ScalaTest-main-running-DiscoverySuite] hbase.HBaseTestingUtility(759): Setting hadoop.log.dir to /Users/appy/apache/hbase/hbase-spark/target/test-data/a075b24a-36fe-48a9-80c5-31b983a29a8e/hadoop_logs in system properties and HBase conf2016-06-02 01:04:05,218 INFO [ScalaTest-main-running-DiscoverySuite] hbase.HBaseTestingUtility(759): Setting mapreduce.cluster.local.dir to /Users/appy/apache/hbase/hbase-spark/target/test-data/a075b24a-36fe-48a9-80c5-31b983a29a8e/mapred_local in system properties and HBase conf2016-06-02 01:04:05,219 INFO [ScalaTest-main-running-DiscoverySuite] hbase.HBaseTestingUtility(759): Setting mapreduce.cluster.temp.dir to /Users/appy/apache/hbase/hbase-spark/target/test-data/a075b24a-36fe-48a9-80c5-31b983a29a8e/mapred_temp in system properties and HBase conf</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.src.test.resources.log4j.properties</file>
    </fixedFiles>
  </bug>
  <bug id="15971" opendate="2016-6-6 00:00:00" fixdate="2016-6-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Regression: Random Read/WorkloadC slower in 1.x than 0.98</summary>
      <description>branch-1 is slower than 0.98 doing YCSB random read/workloadC. It seems to be doing about 1/2 the throughput of 0.98.In branch-1, we have low handler occupancy compared to 0.98. Hacking in reader thread occupancy metric, is about the same in both. In parent issue, hacking out the scheduler, I am able to get branch-1 to go 3x faster so will dig in here.</description>
      <version>1.3.0,2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
    </fixedFiles>
  </bug>
  <bug id="15991" opendate="2016-6-8 00:00:00" fixdate="2016-6-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CompactingMemstore#InMemoryFlushRunnable should implement Comparable/Comparator</summary>
      <description>Configuring CompactingMemstore for a table fails due to the following error2016-06-08 23:27:03,761 ERROR [B.defaultRpcServer.handler...2016-06-08 23:27:03,761 ERROR [B.defaultRpcServer.handler=38,queue=8,port=16041] ipc.RpcServer: Unexpected throwable objectjava.lang.ClassCastException: org.apache.hadoop.hbase.regionserver.CompactingMemStore$InMemoryFlushRunnable cannot be cast to java.lang.Comparable at java.util.concurrent.PriorityBlockingQueue.siftUpComparable(PriorityBlockingQueue.java:357) at java.util.concurrent.PriorityBlockingQueue.offer(PriorityBlockingQueue.java:489) at org.apache.hadoop.hbase.util.StealJobQueue$1.offer(StealJobQueue.java:56) at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1361) at org.apache.hadoop.hbase.regionserver.CompactingMemStore.checkActiveSize(CompactingMemStore.java:258) at org.apache.hadoop.hbase.regionserver.AbstractMemStore.internalAdd(AbstractMemStore.java:403) at org.apache.hadoop.hbase.regionserver.AbstractMemStore.add(AbstractMemStore.java:113) at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:630) at org.apache.hadoop.hbase.regionserver.HRegion.applyToMemstore(HRegion.java:3769) at org.apache.hadoop.hbase.regionserver.HRegion.applyFamilyMapToMemstore(HRegion.java:3740) at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutate(HRegion.java:3222) at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2954) at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2896) at org.apache.hadoop.hbase.regionserver.RSRpcServices.doBatchOp(RSRpcServices.java:868) at org.apache.hadoop.hbase.regionserver.RSRpcServices.doNonAtomicRegionMutation(RSRpcServices.java:830) at org.apache.hadoop.hbase.regionserver.RSRpcServices.multi(RSRpcServices.java:2307) at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:34826) It is a straight forward fix. But If we implement the Comparable the compareTo() should be based on what attribute? Should be based on the time?</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServicesForStores.java</file>
    </fixedFiles>
  </bug>
  <bug id="16004" opendate="2016-6-10 00:00:00" fixdate="2016-6-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update to Netty 4.1.1</summary>
      <description>Netty 4.1 is out and received first bug fix release so it seems good enough for hbase to migrate.It seems to have great performance improvements in Cassandra because of optimizations in cleaning direct buffers. (Now is on by default)https://issues.apache.org/jira/plugins/servlet/mobile#issue/CASSANDRA-11818/comment/15306030https://github.com/netty/netty/pull/5314</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.AsyncRpcClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="16008" opendate="2016-6-10 00:00:00" fixdate="2016-7-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>A robust way deal with early termination of HBCK</summary>
      <description>When HBCK is running, we want to disable Catalog Janitor, Balancer and Split/Merge. Today, the implementation is not robust. If HBCK is terminated earlier by Control-C, the changed state would not be reset to original. HBASE-15406 was trying to solve this problem for Split/Merge switch. The implementation is complicated, and it did not solve CJ and Balancer. The proposal to solve the problem is to use a znode to indicate that the HBCK is running. CJ, balancer, and Split/Merge switch all look for this znode before doing it operation.</description>
      <version>None</version>
      <fixedVersion>1.4.0,0.98.24,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsckOneRS.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockNoopMasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.SplitOrMergeTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Master.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MasterProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
    </fixedFiles>
  </bug>
  <bug id="16023" opendate="2016-6-14 00:00:00" fixdate="2016-6-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fastpath for the FIFO rpcscheduler</summary>
      <description>This is an idea copied from kudu where we skip queuing a request if there is a handler ready to go; we just do a direct handoff from reader to handler.Makes for close to a %20 improvement in random read workloadc testing moving the bottleneck to HBASE-15716 and to returning the results.</description>
      <version>1.3.0,2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcExecutor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.BalancedQueueRpcExecutor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.FifoWithFastPathBalancedQueueRpcExecutor.java</file>
    </fixedFiles>
  </bug>
  <bug id="16035" opendate="2016-6-15 00:00:00" fixdate="2016-6-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Nested AutoCloseables might not all get closed</summary>
      <description>Subtle problem in HBASE-15891:try (A myA = new A(new B()))An exception thrown between B starting to open an A finishing initialization may not result in B being closed. A safer syntax would be:try(B myB = new B(); A myA = newA(myB))</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.JarFinder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.log.LogLevel.java</file>
    </fixedFiles>
  </bug>
  <bug id="16056" opendate="2016-6-17 00:00:00" fixdate="2016-6-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - fix master crash for FileNotFound</summary>
      <description>syuanjiang and tedyu reported a backup master not able to start with FileNotFound during proc-v2 lease recovery. (another restart should have solved the problem)FileNotFoundException: File does not exist: /hbase/MasterProcWALs/state-000001.lognamenode.INodeFile.valueOf(INodeFile.java:61) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLease(FSNamesystem.java:2877) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.recoverLease(NameNodeRpcServer.java:753) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.recoverLease(ClientNamenodeProtocolServerSideTranslatorPB.java:671) this may happen when the other master is still active (e.g. GC) and tries to remove files while the other master tries to become active. This operation is retryable so the code should able to handle that.</description>
      <version>1.3.0,1.2.1,1.1.5,2.0.0</version>
      <fixedVersion>1.3.0,1.2.2,1.1.6,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.wal.TestWALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="16062" opendate="2016-6-17 00:00:00" fixdate="2016-6-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improper error handling in WAL Reader/Writer creation</summary>
      <description>If creation of WAL reader/ writer fails for some reason RS may leak hanging socket in CLOSE_WAIT state.</description>
      <version>2.0.0</version>
      <fixedVersion>1.3.0,1.2.2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.FSHLogProvider.java</file>
    </fixedFiles>
  </bug>
  <bug id="16068" opendate="2016-6-20 00:00:00" fixdate="2016-6-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - use consts for conf properties in tests</summary>
      <description>replace the hardcoded properties string conf.set("foo.key", v) in the tests with the use of the configuration property constants that we already have</description>
      <version>1.3.0,1.2.1,2.0.0</version>
      <fixedVersion>1.3.0,1.2.2,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestWALProcedureStoreOnHDFS.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMasterProcedureEvents.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMasterFailoverWithProcedures.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.TestProcedureReplayOrder.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.wal.TestStressWALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="16069" opendate="2016-6-20 00:00:00" fixdate="2016-6-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Typo "trapsparently" in item 3 of chapter 87.2 of Reference Guide</summary>
      <description>In Chapter 87.2. Coprocessor Implementation Overview...3. Call the coprocessor from your client-side code. HBase handles the coprocessor trapsparently....Correct "trapsparently" into "transparently"</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.cp.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="16076" opendate="2016-6-21 00:00:00" fixdate="2016-7-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cannot configure split policy in HBase shell</summary>
      <description>The reference guide explains how to configure split policy in HBase shell(link).Configuring the Split Policy On a Table Using HBase Shellhbase&gt; create 'test', {METHOD =&gt; 'table_att', CONFIG =&gt; {'SPLIT_POLICY' =&gt; 'org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy'}},{NAME =&gt; 'cf1'}But if run that command, shell complains 'An argument ignored (unknown or overridden): CONFIG', and the table description has no split policy.hbase(main):067:0* create 'test', {METHOD =&gt; 'table_att', CONFIG =&gt; {'SPLIT_POLICY' =&gt; 'org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy'}}, {NAME =&gt; 'cf1'}An argument ignored (unknown or overridden): CONFIGCreated table testTook 1.2180 secondshbase(main):068:0&gt; describe 'test'Table test is ENABLEDtestCOLUMN FAMILIES DESCRIPTION{NAME =&gt; 'cf1', DATA_BLOCK_ENCODING =&gt; 'NONE', BLOOMFILTER =&gt; 'ROW', REPLICATION_SCOPE =&gt; '0', COMPRESSION =&gt; 'NONE', VERSIONS =&gt; '1', TTL =&gt; 'FOREVER', MIN_VERSIONS =&gt; '0', IN_MEMORY_COMPACTION =&gt; 'false', KEEP_DELETED_CELLS =&gt; 'FALSE', BLOCKSIZE =&gt; '65536', IN_MEMORY =&gt; 'false', BLOCKCACHE =&gt; 'true'}1 row(s)Took 0.0200 seconds</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
    </fixedFiles>
  </bug>
  <bug id="16083" opendate="2016-6-22 00:00:00" fixdate="2016-6-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix table based replication related configs</summary>
      <description>Small style changes to make the new Table Based Replication configs match the other HBase configs</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationFactory.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationTableBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationStateHBaseImpl.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestTableBasedReplicationSourceManagerImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="16085" opendate="2016-6-22 00:00:00" fixdate="2016-6-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add on metric for failed compactions</summary>
      <description>Failing compactions doesn't stop the server so things can go un-noticed for quite a while if there are no metrics.</description>
      <version>None</version>
      <fixedVersion>1.3.0,0.98.21,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperStub.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
      <file type="M">hbase-hadoop2-compat.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="16087" opendate="2016-6-22 00:00:00" fixdate="2016-7-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replication shouldn&amp;#39;t start on a master if if only hosts system tables</summary>
      <description>System tables aren't replicated so we shouldn't start up a replication master if there are no user tables on the master.</description>
      <version>1.3.0,2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
    </fixedFiles>
  </bug>
  <bug id="16089" opendate="2016-6-22 00:00:00" fixdate="2016-6-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add on FastPath for CoDel</summary>
      <description>If this is all that awesome, so we should have it on CoDel too.</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.FifoWithFastPathBalancedQueueRpcExecutor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.CallRunner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.java</file>
    </fixedFiles>
  </bug>
  <bug id="16096" opendate="2016-6-23 00:00:00" fixdate="2016-7-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replication keeps accumulating znodes</summary>
      <description>If there is an error while creating the replication source on adding the peer, the source if not added to the in memory list of sources but the replication peer is. However, in such a scenario, when you remove the peer, it is deleted from zookeeper successfully but for removing the in memory list of peers, we wait for the corresponding sources to get deleted (which as we said don't exist because of error creating the source). The problem here is the ordering of operations for adding/removing source and peer. Modifying the code to always remove queues from the underlying storage, even if there exists no sources also requires a small refactoring of TableBasedReplicationQueuesImpl to not abort on removeQueues() of an empty queue</description>
      <version>1.2.0,1.3.0,2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="16110" opendate="2016-6-24 00:00:00" fixdate="2016-7-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>AsyncFS WAL doesn&amp;#39;t work with Hadoop 2.8+</summary>
      <description>The async wal implementation doesn't work with Hadoop 2.8+. Fails compilation and will fail running.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputSaslHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutput.java</file>
    </fixedFiles>
  </bug>
  <bug id="16111" opendate="2016-6-24 00:00:00" fixdate="2016-6-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Truncate preserve shell command is broken</summary>
      <description>On a recent version of master I get this:hbase(main):001:0&gt; truncate_preserve 'TestTable'ERROR: undefined local variable or method `table' for #&lt;Hbase::Admin:0x2fdf17dc&gt;Here is some help for this command: Disables, drops and recreates the specified table while still maintaing the previous region boundaries.Took 0.0290 secondshbase(main):002:0&gt; truncate 'TestTable'Truncating 'TestTable' table (it may take a while):Disabling table...Truncating table...Took 10.0040 seconds</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug id="16119" opendate="2016-6-27 00:00:00" fixdate="2016-12-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - Reimplement merge</summary>
      <description>use the proc-v2 state machine for merge. also update the logic to have a single meta-writer.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestSerialReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.namespace.TestNamespaceAuditor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestSplitTableRegionProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockNoopMasterServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionServerObserver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestMasterObserver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin1.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.SplitTableRegionProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.java</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupAdminEndpoint.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.MasterProcedure.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.Master.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.Admin.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.ProcedureTestingUtility.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ResponseConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
    </fixedFiles>
  </bug>
  <bug id="16135" opendate="2016-6-28 00:00:00" fixdate="2016-7-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>PeerClusterZnode under rs of removed peer may never be deleted</summary>
      <description>One of our cluster run out of space recently, and we found that the .oldlogs directory had almost the same size as the data directory.Finally we found the problem is that, we removed a peer abort 3 months ago, but there are still some replication queue znode under some rs nodes. This prevents the deletion of .oldlogs.</description>
      <version>1.3.0,1.4.0,1.1.5,1.2.2,0.98.20,2.0.0</version>
      <fixedVersion>1.3.0,1.1.6,0.98.21,1.2.3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestTableBasedReplicationSourceManagerImpl.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManagerZkImpl.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueuesZKImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="16143" opendate="2016-6-29 00:00:00" fixdate="2016-6-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change MemstoreScanner constructor to accept List&lt;KeyValueScanner&gt;</summary>
      <description>A minor change that helps in creating a memstore that avoids the compaction process and just allows to creates a pipeline of segments and on flush directly reads the segments in the pipeline and flushes it out after creating a snapshot of the pipeline. Based on test results and updated patch on HBASE-14921 (to be provided) will see how much flattening helps us.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SegmentScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultMemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactingMemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.AbstractMemStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="16144" opendate="2016-6-29 00:00:00" fixdate="2016-7-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replication queue&amp;#39;s lock will live forever if RS acquiring the lock has died prematurely</summary>
      <description>In default, we will use multi operation when we claimQueues from ZK. But if we set hbase.zookeeper.useMulti=false, we will add a lock first, then copy nodes, finally clean old queue and the lock. However, if the RS acquiring the lock crash before claimQueues done, the lock will always be there and other RS can never claim the queue.</description>
      <version>1.3.0,1.4.0,1.2.2,0.98.20,1.1.6,2.0.0</version>
      <fixedVersion>1.3.0,1.1.6,1.2.3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestMultiSlaveReplication.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.ReplicationZKLockCleanerChore.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueuesZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="16153" opendate="2016-6-30 00:00:00" fixdate="2016-6-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Correct the config name &amp;#39;hbase.memestore.inmemoryflush.threshold.factor&amp;#39;</summary>
      <description>A very minor change of renaming the config' hbase.memestore.inmemoryflush.threshold.factor' to 'hbase.memstore.inmemoryflush.threshold.factor'. The 'memstore' was misspelt.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactingMemStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="16159" opendate="2016-7-1 00:00:00" fixdate="2016-7-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>OutOfMemory exception when using AsyncRpcClient with encryption to read rpc response</summary>
      <description>Test the Get with encryption AsyncRpcClient with in infinity loop, will get the OOM exception. The root cause is the same as HBASE-16054.</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.SaslClientHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="1616" opendate="2009-7-6 00:00:00" fixdate="2009-7-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unit test of compacting referenced StoreFiles</summary>
      <description>We need a unit test for compactions of referenced StoreFiles. This broke in trunk but was not found in any existing tests.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.client.TestForceSplit.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="16162" opendate="2016-7-1 00:00:00" fixdate="2016-7-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compacting Memstore : unnecessary push of active segments to pipeline</summary>
      <description>We have flow like thisprotected void checkActiveSize() { if (shouldFlushInMemory()) { InMemoryFlushRunnable runnable = new InMemoryFlushRunnable(); } getPool().execute(runnable); } }private boolean shouldFlushInMemory() { if(getActive().getSize() &gt; inmemoryFlushSize) { // size above flush threshold return (allowCompaction.get() &amp;&amp; !inMemoryFlushInProgress.get()); } return false; }void flushInMemory() throws IOException { // Phase I: Update the pipeline getRegionServices().blockUpdates(); try { MutableSegment active = getActive(); pushActiveToPipeline(active); } finally { getRegionServices().unblockUpdates(); } // Phase II: Compact the pipeline try { if (allowCompaction.get() &amp;&amp; inMemoryFlushInProgress.compareAndSet(false, true)) { // setting the inMemoryFlushInProgress flag again for the case this method is invoked // directly (only in tests) in the common path setting from true to true is idempotent // Speculative compaction execution, may be interrupted if flush is forced while // compaction is in progress compactor.startCompaction(); }So every write of cell will produce the check checkActiveSize(). When we are at border of in mem flush, many threads doing writes to this memstore can get this checkActiveSize () to pass. Yes the AtomicBoolean is still false only. It is turned ON after some time once the new thread is started run and it push the active to pipeline etc.In the new thread code of inMemFlush, we dont have any size check. It just takes the active segment and pushes that to pipeline. Yes we dont allow any new writes to memstore at this time. But before that write lock on region, other handler thread also might have added entry to this thread pool. When the 1st one finishes, it releases the lock on region and handler threads trying for write to memstore, might get lock and add some data. Now this 2nd in mem flush thread may get a chance and get the lock and so it just takes current active segment and flush that in memory ! This will produce very small sized segments to pipeline.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactingMemStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="16164" opendate="2016-7-1 00:00:00" fixdate="2016-7-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Missing close of new compacted segments in few occasions which might leak MSLAB chunks from pool</summary>
      <description>An in memory compaction of N segments in progress. Inn between snapshot() call comes. We will stop the in progress compaction then. This just sets an AtomicBoolean. We check this boolean state in the compaction loop (while loop reading the cells from the segments) and before swapping the segments. But if this scenario comes, we are just ignoring the new newly compacted Segment. This is a problem maker when we work with MSLAB pool. The new segment would have acquired some chunks but when will they get released? As we dont close the segment this will leak them.Also in swap we havepublic boolean swap(VersionedSegmentsList versionedList, ImmutableSegment segment) { if(versionedList.getVersion() != version) { return false; } LinkedList&lt;ImmutableSegment&gt; suffix; synchronized (pipeline){ if(versionedList.getVersion() != version) { return false; }I dont see any possibility for this code flow to happen. Still for correctness, we should close the segment here too.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactionPipeline.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactingMemStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="16179" opendate="2016-7-5 00:00:00" fixdate="2016-3-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix compilation errors when building hbase-spark against Spark 2.0</summary>
      <description>I tried building hbase-spark module against Spark-2.0 snapshot and got the following compilation errors:http://pastebin.com/bg3w247aSome Spark classes such as DataTypeParser and Logging are no longer accessible to downstream projects.hbase-spark module should not depend on such classes.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,connector-1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.src.test.scala.org.apache.hadoop.hbase.spark.PartitionFilterSuite.scala</file>
      <file type="M">hbase-spark.src.test.scala.org.apache.hadoop.hbase.spark.HBaseRDDFunctionsSuite.scala</file>
      <file type="M">hbase-spark.src.test.scala.org.apache.hadoop.hbase.spark.HBaseDStreamFunctionsSuite.scala</file>
      <file type="M">hbase-spark.src.test.scala.org.apache.hadoop.hbase.spark.HBaseContextSuite.scala</file>
      <file type="M">hbase-spark.src.test.scala.org.apache.hadoop.hbase.spark.HBaseConnectionCacheSuite.scala</file>
      <file type="M">hbase-spark.src.test.scala.org.apache.hadoop.hbase.spark.HBaseCatalogSuite.scala</file>
      <file type="M">hbase-spark.src.test.scala.org.apache.hadoop.hbase.spark.DynamicLogicExpressionSuite.scala</file>
      <file type="M">hbase-spark.src.test.scala.org.apache.hadoop.hbase.spark.DefaultSourceSuite.scala</file>
      <file type="M">hbase-spark.src.test.scala.org.apache.hadoop.hbase.spark.BulkLoadSuite.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.spark.sql.datasources.hbase.Utils.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.spark.sql.datasources.hbase.HBaseTableCatalog.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.spark.sql.datasources.hbase.DataTypeParserWrapper.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.NewHBaseRDD.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.JavaHBaseContext.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.HBaseContext.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.HBaseConnectionCache.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.DefaultSource.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.datasources.NaiveEncoder.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.datasources.JavaBytesEncoder.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.datasources.HBaseTableScanRDD.scala</file>
      <file type="M">hbase-spark.src.main.java.org.apache.hadoop.hbase.spark.SparkSQLPushDownFilter.java</file>
      <file type="M">hbase-spark.pom.xml</file>
      <file type="M">hbase-spark-it.src.test.java.org.apache.hadoop.hbase.spark.IntegrationTestSparkBulkLoad.java</file>
      <file type="M">hbase-spark-it.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="16181" opendate="2016-7-5 00:00:00" fixdate="2016-4-5 01:00:00" resolution="Invalid">
    <buginformation>
      <summary>Allow snapshot of hbase:backup table</summary>
      <description>Snapshot of HBase system tables is not supported, we need either move hbase:backup into different name space or fix snapshots.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsAssignmentManagerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="16205" opendate="2016-7-11 00:00:00" fixdate="2016-7-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>When Cells are not copied to MSLAB, deep clone it while adding to Memstore</summary>
      <description>This is imp after HBASE-15180 optimization. After that we the cells flowing in write path will be backed by the same byte[] where the RPC read the request into. By default we have MSLAB On and so we have a copy operation while adding Cells to memstore. This copy might not be there if1. MSLAB is turned OFF2. Cell size is more than a configurable max size. This defaults to 256 KB3. If the operation is Append/Increment. In such cases, we should just clone the Cell into a new byte[] and then add to memstore. Or else we keep referring to the bigger byte[] chunk for longer time.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.AbstractMemStore.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.KeyValueCodecWithTags.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.KeyValueCodec.java</file>
    </fixedFiles>
  </bug>
  <bug id="1621" opendate="2009-7-7 00:00:00" fixdate="2009-1-7 01:00:00" resolution="Duplicate">
    <buginformation>
      <summary>merge tool should work on online cluster</summary>
      <description>taking down the entire cluster to merge 2 regions is a pain, i dont see why the table or regions specifically couldnt be taken offline, then merged then brought back up.this might need a new API to the regionservers so they can take direction from not just the master.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.ops.mgt.xml</file>
      <file type="M">src.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="16211" opendate="2016-7-11 00:00:00" fixdate="2016-7-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>JMXCacheBuster restarting the metrics system might cause tests to hang</summary>
      <description>JMXCacheBuster restarts the metrics system. In Phoenix we are manually injecting a sink to the metric system which gets lost when we restart the metric system. See PHOENIX-3062</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.impl.JmxCacheBuster.java</file>
    </fixedFiles>
  </bug>
  <bug id="16221" opendate="2016-7-13 00:00:00" fixdate="2016-7-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thrift server drops connection on long scans</summary>
      <description>Thrift servers use connection cache and we drop connections after hbase.thrift.connection.max-idletime milliseconds from the last time a connection object was accessed. However, we never update this last accessed time on scan path. By default, this will cause scanners to fail after 10 minutes, if the underlying connection object is not being used along other operation paths (like put).</description>
      <version>1.2.0,1.3.0,2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift2.TestThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ConnectionCache.java</file>
    </fixedFiles>
  </bug>
  <bug id="16266" opendate="2016-7-21 00:00:00" fixdate="2016-7-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Do not throw ScannerTimeoutException when catch UnknownScannerException</summary>
      <description>Now in scanner we have heartbeat to prevent timeout. The time blocked on ResultScanner.next() may much longer than scanner timeout. So it is no need any more to throw ScannerTimeoutException when server throws UnknownScannerException, we can just reset the scanner like NotServingRegionException</description>
      <version>1.3.0,1.4.0,1.2.2,1.1.6,2.0.0</version>
      <fixedVersion>1.3.0,1.1.6,1.2.3,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestPartialResultsFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannerTimeout.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="16283" opendate="2016-7-26 00:00:00" fixdate="2016-10-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Batch Append/Increment will always fail if set ReturnResults to false</summary>
      <description>If set Append/Increment's ReturnResult attribute to false, and batch the appends/increments to server. The batch operation will always return false.The reason is that, since return result is set to false, append/increment will return null instead of Result object. But in ResponseConverter#getResults, there is some check code if (requestRegionActionCount != responseRegionActionResultCount) { throw new IllegalStateException("Request mutation count=" + requestRegionActionCount + " does not match response mutation result count=" + responseRegionActionResultCount); }That means if the result count is not meet with request mutation count, it will fail the request.The solution is simple, instead of returning a null result, returning a empty result if ReturnResult set to false.</description>
      <version>1.1.5,1.2.2,2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestDurability.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestAtomicOperation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestIncrementsFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="16284" opendate="2016-7-26 00:00:00" fixdate="2016-8-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unauthorized client can shutdown the cluster</summary>
      <description>An unauthorized client can shutdown the cluster as AccessDeniedException is ignored during Admin.stopMaster and Admin.shutdown.</description>
      <version>None</version>
      <fixedVersion>1.3.0,0.98.21,1.2.3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.JVMClusterUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="16285" opendate="2016-7-26 00:00:00" fixdate="2016-8-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Drop RPC requests if it must be considered as timeout at client</summary>
      <description>After HBASE-15593, we have a timeout param in header of RPC requests. We can use it in more scenes.A straightforward scene is to drop requests if it has waited so long in RPC queue and has been dropped by client. Even if we handle this request and send the response back, it will not be used any more. And client may have sent a retry. In an extreme case, if the server is slow, all requests may be timeout or queue-full-exception because we should handle previous requests which have been dropped by client and many resources at server are wasted.</description>
      <version>1.3.0,1.4.0,2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServerInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.CallRunner.java</file>
    </fixedFiles>
  </bug>
  <bug id="16290" opendate="2016-7-27 00:00:00" fixdate="2016-10-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Dump summary of callQueue content; can help debugging</summary>
      <description>Being able to get a clue what is in a backedup callQueue could give insight on what is going on on a jacked server. Just needs to summarize count, sizes, call types. Useful debugging. In a servlet?</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.DelegatingRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSDumpServlet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcExecutor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.FifoRpcScheduler.java</file>
    </fixedFiles>
  </bug>
  <bug id="16302" opendate="2016-7-28 00:00:00" fixdate="2016-11-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>age of last shipped op and age of last applied op should be histograms</summary>
      <description>Replication exports metric ageOfLastShippedOp as an indication of how much replication is lagging. But, with multiwal enabled, it's not representative because replication could be lagging for a long time for one wal group (something wrong with a particular region) while being fine for others. The ageOfLastShippedOp becomes a useless metric for alerting in such a case.Also, since there is no mapping between individual replication sources and replication sinks, the age of last applied op can be a highly spiky metric if only certain replication sources are lagging.We should use histograms for these metrics and use maximum value of this histogram to report replication lag when building stats.</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.MetricsSource.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.MutableHistogram.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.replication.regionserver.MetricsReplicationSourceSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.replication.regionserver.MetricsReplicationSinkSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.replication.regionserver.MetricsReplicationGlobalSourceSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="16312" opendate="2016-8-1 00:00:00" fixdate="2016-7-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>update jquery version</summary>
      <description>the jquery version we bundle for our web ui is EOM. update to latest jquery 3.y.we can use the jquery migrate plugin to help update APIs.</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.resources.hbase-webapps.thrift.thrift.jsp</file>
      <file type="M">hbase-thrift.src.main.resources.hbase-webapps.static.js.jquery.min.js</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.thrift.thrift.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.js.jquery.min.js</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.regionserver.storeFile.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.regionserver.region.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.regionserver.processRS.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.zk.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.tablesDetailed.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.snapshotsStats.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.snapshot.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.processRS.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.processMaster.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.procedures.jsp</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">hbase-rest.src.main.resources.hbase-webapps.rest.rest.jsp</file>
    </fixedFiles>
  </bug>
  <bug id="16314" opendate="2016-8-1 00:00:00" fixdate="2016-4-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Retry on table snapshot failure during full backup</summary>
      <description>Table snapshot (during full backup) can fail with NotServingRegionException (splits, AM region moves). We need to add retry logic here.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.impl.FullTableBackupClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupRestoreConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="16315" opendate="2016-8-1 00:00:00" fixdate="2016-8-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RegionSizeCalculator prints region names as binary without escapes</summary>
      <description>Region start key is not escaped: 2016-05-20 01:35:04,646|beaver.machine|INFO|8984|140719733470976|MainThread|2016-05-20 01:35:04,637 DEBUG [main] util.RegionSizeCalculator: Region IntegrationTestBigLinkedList,��������,1463706056389.609c5d0e2a3a03eb3d93d608b9722fb9. has size 1300234242016-05-20 01:35:04,647|beaver.machine|INFO|8984|140719733470976|MainThread|2016-05-20 01:35:04,637 DEBUG [main] util.RegionSizeCalculator: Region IntegrationTestBigLinkedList,�"""""" ,1463706056389.6b2d56bc9f04339156a858595b237614. has size 1300234242016-05-20 01:35:04,647|beaver.machine|INFO|8984|140719733470976|MainThread|2016-05-20 01:35:04,637 DEBUG [main] util.RegionSizeCalculator: Region IntegrationTestBigLinkedList,��������,1463706056389.4eab8c5beba325cb8a2731151f8bbe77. has size 1342177282016-05-20 01:35:04,647|beaver.machine|INFO|8984|140719733470976|MainThread|2016-05-20 01:35:04,637 DEBUG [main] util.RegionSizeCalculator: Region IntegrationTestBigLinkedList,�wwwwwwh,1463706056389.406e8bbe17eabb4aca2b246d1242013c. has size 131072000</description>
      <version>None</version>
      <fixedVersion>1.3.0,1.1.6,1.2.3,0.98.22,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionLoad.java</file>
    </fixedFiles>
  </bug>
  <bug id="1632" opendate="2009-7-9 00:00:00" fixdate="2009-7-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Write documentation for configuring/managing ZooKeeper with HBase</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.overview.html</file>
    </fixedFiles>
  </bug>
  <bug id="1633" opendate="2009-7-9 00:00:00" fixdate="2009-7-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Can&amp;#39;t delete in TRUNK shell; makes it hard doing admin repairs</summary>
      <description>Because shell uses old API, it runs into the "Can't add deletes to a BatchUpdate" issue. Add new API to do shell delete and deleteAll. Just a few lines.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.HBase.rb</file>
    </fixedFiles>
  </bug>
  <bug id="16336" opendate="2016-8-2 00:00:00" fixdate="2016-12-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Removing peers seems to be leaving spare queues</summary>
      <description>I have been running IntegrationTestReplication repeatedly with the backported Replication Table changes. Every other iteration of the test fails with, but these queues should have been deleted when we removed the peers. I believe this may be related to HBASE-16096, HBASE-16208, or HBASE-16081.16/08/02 08:36:07 ERROR util.AbstractHBaseTool: Error running command-line toolorg.apache.hadoop.hbase.replication.ReplicationException: undeleted queue for peerId: TestPeer, replicator: hbase4124.ash2.facebook.com,16020,1470150251042, queueId: TestPeer at org.apache.hadoop.hbase.replication.ReplicationPeersZKImpl.checkQueuesDeleted(ReplicationPeersZKImpl.java:544) at org.apache.hadoop.hbase.replication.ReplicationPeersZKImpl.addPeer(ReplicationPeersZKImpl.java:127) at org.apache.hadoop.hbase.client.replication.ReplicationAdmin.addPeer(ReplicationAdmin.java:200) at org.apache.hadoop.hbase.test.IntegrationTestReplication$VerifyReplicationLoop.setupTablesAndReplication(IntegrationTestReplication.java:239) at org.apache.hadoop.hbase.test.IntegrationTestReplication$VerifyReplicationLoop.run(IntegrationTestReplication.java:325) at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70) at org.apache.hadoop.hbase.test.IntegrationTestReplication.runTestFromCommandLine(IntegrationTestReplication.java:418) at org.apache.hadoop.hbase.IntegrationTestBase.doWork(IntegrationTestBase.java:134) at org.apache.hadoop.hbase.util.AbstractHBaseTool.run(AbstractHBaseTool.java:112) at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70) at org.apache.hadoop.hbase.test.IntegrationTestReplication.main(IntegrationTestReplication.java:424)</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.hbck.ReplicationChecker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="16338" opendate="2016-8-2 00:00:00" fixdate="2016-10-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>update jackson to 2.y</summary>
      <description>Our jackson dependency is from ~3 years ago. Update to the jackson 2.y line, using 2.7.0+.</description>
      <version>None</version>
      <fixedVersion>2.0.0-alpha-4,2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.taskmonitor.rb</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-spark.pom.xml</file>
      <file type="M">dev-support.hbase-personality.sh</file>
      <file type="M">hbase-client.pom.xml</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.util.JsonMapper.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestOperation.java</file>
      <file type="M">hbase-it.pom.xml</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.RESTApiClusterManager.java</file>
      <file type="M">hbase-mapreduce.pom.xml</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.TestPerformanceEvaluation.java</file>
      <file type="M">hbase-resource-bundle.src.main.resources.supplemental-models.xml</file>
      <file type="M">hbase-rest.pom.xml</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.CellModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.ColumnSchemaModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.NamespacesModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.RowModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.ScannerModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.StorageClusterStatusModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.StorageClusterVersionModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.TableSchemaModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.ProtobufStreamingUtil.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.RESTServer.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.TableScanResource.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.HBaseRESTTestingUtility.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.model.TestColumnSchemaModel.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.model.TestModelBase.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.model.TestTableSchemaModel.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.RowResourceBase.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.TestDeleteRow.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.TestMultiRowResource.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.TestNamespacesInstanceResource.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.TestSchemaResource.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.TestTableScan.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.TestVersionResource.java</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.AgeSnapshot.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.BlockCacheUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.JSONBean.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.JSONMetricUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALPrettyPrinter.java</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.processMaster.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.processRS.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.regionserver.processRS.jsp</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestBlockCacheReporting.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestJSONMetricUtil.java</file>
      <file type="M">hbase-shaded.hbase-shaded-mapreduce.pom.xml</file>
      <file type="M">hbase-shaded.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="16341" opendate="2016-8-2 00:00:00" fixdate="2016-8-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Missing bit on "Regression: Random Read/WorkloadC slower in 1.x than 0.98"</summary>
      <description>larsgeorge found a missing bit in HBASE-15971 "Regression: Random Read/WorkloadC slower in 1.x than 0.98" Let me fix here. Let me quote the man:BTW, in constructor we do this``` String callQueueType = conf.get(CALL_QUEUE_TYPE_CONF_KEY, CALL_QUEUE_TYPE_FIFO_CONF_VALUE);```(edited)[8:19] but in `onConfigurationChange()` we do``` String callQueueType = conf.get(CALL_QUEUE_TYPE_CONF_KEY, CALL_QUEUE_TYPE_DEADLINE_CONF_VALUE);```(edited)</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
    </fixedFiles>
  </bug>
  <bug id="16347" opendate="2016-8-3 00:00:00" fixdate="2016-8-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unevaluated expressions in book</summary>
      <description>Have a look at the quickstart guide, step two$ tar xzvf hbase-&lt;?eval ${project.version}?&gt;-bin.tar.gz$ cd hbase-&lt;?eval ${project.version}?&gt;/</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.getting.started.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="16372" opendate="2016-8-8 00:00:00" fixdate="2016-10-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>References to previous cell in read path should be avoided</summary>
      <description>Came as part of review discussion in HBASE-15554. If there are references kept to previous cells in the read path, with the Ref count based eviction mechanism in trunk, then chances are there to evict a block backing the previous cell but the read path still does some operations on that garbage collected previous cell leading to incorrect results.Areas to target-&gt; Storescanner-&gt; Bloom filters (particularly in compaction path)Thanks to anoop.hbase to point out this in bloomfilter path. But we found it could be in other areas also.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RowColBloomContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RowBloomContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.BloomFilterWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.BloomContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.ScanWildcardColumnTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.ExplicitColumnTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.ColumnTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.Compactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.AbstractMultiFileWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.DefaultMobStoreCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileWriterImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CompoundBloomFilterWriter.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValueUtil.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.exceptions.TestClientExceptionsUtil.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestPut.java</file>
    </fixedFiles>
  </bug>
  <bug id="16417" opendate="2016-8-15 00:00:00" fixdate="2016-11-15 01:00:00" resolution="Resolved">
    <buginformation>
      <summary>In-Memory MemStore Policy for Flattening and Compactions</summary>
      <description>This Jira explores the performance of different memstore compaction policies.It presents the result of write-only workload evaluation as well as read performance in read-write workloads.We investigate several settings of hardware (SSD, HDD), key distribution (Zipf, uniform), with multiple settings of the system, and compare measures like write throughput, read latency, write volume, total gc time, etc.The submitted patch sets some system properties at the values yielding optimal performance. In addition we suggest a new Adaptive memstore compaction policy that shows good tradeoffs between write throughput and write volume.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestIOFencing.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestWalAndCompactingMemStoreFlush.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRecoveredEdits.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompactingToCellFlatMapMemStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompactingMemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.VersionedSegmentsList.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SegmentFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ImmutableSegment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactionPipeline.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactingMemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CellSet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CellChunkMap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CellChunkImmutableSegment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CellArrayImmutableSegment.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ClassSize.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MemoryCompactionPolicy.java</file>
    </fixedFiles>
  </bug>
  <bug id="16419" opendate="2016-8-16 00:00:00" fixdate="2016-8-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>check REPLICATION_SCOPE&amp;#39;s value more stringently</summary>
      <description>When create table or modify table, the master will check if the value of REPLICATION_SCOPE is less than 0, however the value of REPLICATION_SCOPE must be 0 or 1. Otherwise will lead to regionserver shutdown, so I think should be check the values of REPLICATION_SCOPE more stringent.Beginning I don't fully understand the usage of REPLICATION_SCOPE, then set REPLICATION_SCOPE to 2 by mistake.when I insert data to table,the regionservers abort one by one,finanlythe cluster abort，the exceptions as follow:2016-08-16 12:34:45,245 WARN &amp;#91;regionserver/host:60023.append-pool1-t1&amp;#93; wal.FSHLog: Append sequenceId=94, requesting roll of WALjava.lang.NullPointerException at org.apache.hadoop.hbase.protobuf.generated.WALProtos$FamilyScope$Builder.setScopeType(WALProtos.java:3939) at org.apache.hadoop.hbase.wal.WALKey.getBuilder(WALKey.java:618) at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.append(ProtobufLogWriter.java:118) at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1886) at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:1750) at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:1672) at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:128) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:744)2016-08-16 12:34:45,293 INFO &amp;#91;MemStoreFlusher.0&amp;#93; regionserver.HStore: Added hdfs://hbase-test-27/hbase1.2.2/data/default/usertable/2aa98c17845c9c6d5c8760b87b3ba09a/i/35825c94e72945c0bf7df3f0adefa1b6, entries=1161600, sequenceid=59, filesize=167.6 M2016-08-16 12:34:45,296 FATAL &amp;#91;MemStoreFlusher.0&amp;#93; regionserver.HRegionServer: ABORTING region server hbase-10-166-141-99,60023,1471262434177: Replay of WAL required. Forcing server shutdownorg.apache.hadoop.hbase.DroppedSnapshotException: region: usertable,,1471262560009.2aa98c17845c9c6d5c8760b87b3ba09a. at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushCacheAndCommit(HRegion.java:2427) at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2105) at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2067) at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:1958) at org.apache.hadoop.hbase.regionserver.HRegion.flush(HRegion.java:1884) at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:510) at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:471) at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.access$900(MemStoreFlusher.java:75) at org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushHandler.run(MemStoreFlusher.java:259) at java.lang.Thread.run(Thread.java:744)Caused by: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=94, requesting roll of WAL at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1898) at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:1750) at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:1672) at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:128) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) ... 1 moreCaused by: java.lang.NullPointerException at org.apache.hadoop.hbase.protobuf.generated.WALProtos$FamilyScope$Builder.setScopeType(WALProtos.java:3939) at org.apache.hadoop.hbase.wal.WALKey.getBuilder(WALKey.java:618) at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.append(ProtobufLogWriter.java:118) at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1886) ... 6 more</description>
      <version>1.2.2,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="16426" opendate="2016-8-17 00:00:00" fixdate="2016-8-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove company affiliations from committer list</summary>
      <description>An email thread on the dev mailing list came to the consensus that company affiliations in the committer list are difficult to keep up to date and not worth it. This JIRA is to track removing them.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="16434" opendate="2016-8-17 00:00:00" fixdate="2016-8-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve flaky dashboard</summary>
      <description>Sort list of tests in descending order of flakyness add date and flaky tests count local hrefs to job results</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.report-flakies.py</file>
      <file type="M">dev-support.flaky-dashboard-template.html</file>
      <file type="M">dev-support.findHangingTests.py</file>
    </fixedFiles>
  </bug>
  <bug id="16436" opendate="2016-8-17 00:00:00" fixdate="2016-5-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add the CellChunkMap variant</summary>
      <description>This sub-task is specifically to add the CellChunkMap created by anastas and eshcar with specific tests and integrate it with the in memory flush/compaction flow.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCellFlatSet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CellSet.java</file>
    </fixedFiles>
  </bug>
  <bug id="16446" opendate="2016-8-18 00:00:00" fixdate="2016-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>append_peer_tableCFs failed when there already have this table&amp;#39;s partial cfs in the peer</summary>
      <description>hbase(main):011:0&gt; list_peers PEER_ID CLUSTER_KEY STATE TABLE_CFS PROTOCOL BANDWIDTH 20 hbase://c3tst-pressure98 ENABLED default.test_replication:A NATIVE 01 row(s) in 0.0080 secondshbase(main):012:0&gt; append_peer_tableCFs '20', {"test_replication" =&gt; []}0 row(s) in 0.0060 secondshbase(main):013:0&gt; list_peers PEER_ID CLUSTER_KEY STATE TABLE_CFS PROTOCOL BANDWIDTH 20 hbase://c3tst-pressure98 ENABLED default.test_replication:A NATIVE 01 row(s) in 0.0030 seconds"test_replication" =&gt; [] means replication all cf of this table,so the result is not right. It should not just contain cf A after append_peer_tableCFs.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.replication.TestReplicationAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.replication.ReplicationAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="16450" opendate="2016-8-18 00:00:00" fixdate="2016-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Shell tool to dump replication queues</summary>
      <description>Currently there is no way to dump list of the configured queues and the replication queues when replication is enabled. Unfortunately the HBase master only offers an option to dump the whole content of the znodes but not details on the queues being processed on each RS.</description>
      <version>1.3.0,1.1.5,1.2.2,2.0.0</version>
      <fixedVersion>1.3.0,0.98.24,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueuesZKImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="16451" opendate="2016-8-19 00:00:00" fixdate="2016-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - Test WAL protobuf entry size limit</summary>
      <description>Add a test to make sure that we are able to read/write procedures with a big "data" size.</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.wal.TestWALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.wal.TestStressWALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.ProcedureTestingUtility.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.util.ByteSlot.java</file>
    </fixedFiles>
  </bug>
  <bug id="16474" opendate="2016-8-23 00:00:00" fixdate="2016-8-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove dfs.support.append related code and documentation</summary>
      <description>dfs.support.append not needed anymore in Hadoop-2.0+.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZooKeeperACL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestWALSplit.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestWALFactory.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestFSUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestZooKeeper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestIOFencing.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestFullLogReconstruction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelReplicationWithExpAsString.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationWithTags.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestPerTableCFReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestMultiSlaveReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestMasterReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSink.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRolling.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRollAbort.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.AbstractTestWALReplay.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.AbstractTestProtobufLog.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterTransitions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestDeleteColumnFamilyProcedureFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.fs.TestBlockReorder.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestWALObserver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="16495" opendate="2016-8-24 00:00:00" fixdate="2016-8-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>When accessed via Thrift, all column families have timeToLive equal to -1</summary>
      <description>When accessed via Thrift, all column families have timeToLive equal to -1. This happens because converter function colDescFromHbase forgets to copy timeToLive from HColumnDescriptor. One line change fixes that.</description>
      <version>None</version>
      <fixedVersion>1.4.0,0.98.22,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftUtilities.java</file>
    </fixedFiles>
  </bug>
  <bug id="16499" opendate="2016-8-25 00:00:00" fixdate="2016-4-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>slow replication for small HBase clusters</summary>
      <description>For small clusters 10-20 nodes we recently observed that replication is progressing very slowly when we do bulk writes and there is lot of lag accumulation on AgeOfLastShipped / SizeOfLogQueue. From the logs we observed that the number of threads used for shipping wal edits in parallel comes from the following equation in HBaseInterClusterReplicationEndpointint n = Math.min(Math.min(this.maxThreads, entries.size()/100+1), replicationSinkMgr.getSinks().size());... for (int i=0; i&lt;n; i++) { entryLists.add(new ArrayList&lt;HLog.Entry&gt;(entries.size()/n+1)); &lt;-- batch size }... for (int i=0; i&lt;entryLists.size(); i++) { ..... // RuntimeExceptions encountered here bubble up and are handled in ReplicationSource pool.submit(createReplicator(entryLists.get(i), i)); &lt;-- concurrency futures++; } }maxThreads is fixed &amp; configurable and since we are taking min of the three values n gets decided based replicationSinkMgr.getSinks().size() when we have enough edits to replicatereplicationSinkMgr.getSinks().size() is decided based on int numSinks = (int) Math.ceil(slaveAddresses.size() * ratio);where ratio is this.ratio = conf.getFloat("replication.source.ratio", DEFAULT_REPLICATION_SOURCE_RATIO);Currently DEFAULT_REPLICATION_SOURCE_RATIO is set to 10% so for small clusters of size 10-20 RegionServers the value we get for numSinks and hence n is very small like 1 or 2. This substantially reduces the pool concurrency used for shipping wal edits in parallel effectively slowing down replication for small clusters and causing lot of lag accumulation in AgeOfLastShipped. Sometimes it takes tens of hours to clear off the entire replication queue even after the client has finished writing on the source side. We are running tests by varying replication.source.ratio and have seen multi-fold improvement in total replication time (will update the results here). I wanted to propose here that we should increase the default value for replication.source.ratio also so that we have sufficient concurrency even for small clusters. We figured it out after lot of iterations and debugging so probably slightly higher default will save the trouble.</description>
      <version>None</version>
      <fixedVersion>1.5.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSinkManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSinkManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="16507" opendate="2016-8-26 00:00:00" fixdate="2016-9-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - Force DDL operation to always roll forward</summary>
      <description>Having rollback for DDLs was a bad idea. and it turns out to be an unexpected behavior for the user. DDLs only have transient errors (e.g. zk, hdfs, meta down)if we abort/rollback on a transient failure the user will get a failure,and it is not clear why the user needs to retry the command when the system can do that.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestTruncateTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestRestoreSnapshotProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestProcedureAdmin.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestModifyTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestModifyNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestModifyColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestEnableTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestDispatchMergingRegionsProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestDisableTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestDeleteTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestDeleteNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestDeleteColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestCreateTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestCreateNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestCloneSnapshotProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestAddColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureTestingUtility.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.TruncateTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.RestoreSnapshotProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.EnableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DisableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CreateNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CloneSnapshotProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.AddColumnFamilyProcedure.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.StateMachineProcedure.java</file>
    </fixedFiles>
  </bug>
  <bug id="16510" opendate="2016-8-28 00:00:00" fixdate="2016-8-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reset RpcController before retry</summary>
      <description>Later we will use RpcController to pass exceptions to upper layer, so we need to clear the exception info before retry.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestRpcControllerFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionServerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.NoncedRegionServerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MasterCallable.java</file>
    </fixedFiles>
  </bug>
  <bug id="16519" opendate="2016-8-29 00:00:00" fixdate="2016-9-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - Avoid sync wait on DDLs operation</summary>
      <description>Some operation ModifyColumnFamily, AddDeleteColumnFamily, DeleteColumnFamily, ModifyTable, TruncateTable are still synchronous on the master side. with a wait until the operation completes before returning. this was done to keep the sync behavior for old client. but instead of using the procLatch which recognize the client version and decide if the operation should be sync or not it just always wait. making the client side proc fault tolerance ineffective.also the add/delete/modifyColumnFamily operation does not seems to follow the Async() naming in master. and the comment claim to be async but everyone uses them as sync. (this is something from HBASE-13538)</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.TruncateTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ProcedureSyncWait.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ProcedurePrepareLatch.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.AddColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
    </fixedFiles>
  </bug>
  <bug id="16522" opendate="2016-8-29 00:00:00" fixdate="2016-8-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - Cache system user and avoid IOException</summary>
      <description>We can cache the system user and avoid the IOException that we have to carry around when we create procedures</description>
      <version>1.3.0,1.1.5,1.2.2,2.0.0</version>
      <fixedVersion>1.3.0,1.1.7,1.2.4,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.TruncateTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.RestoreSnapshotProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.EnableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DispatchMergingRegionsProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DisableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CreateNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CloneSnapshotProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.AddColumnFamilyProcedure.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.security.Superusers.java</file>
    </fixedFiles>
  </bug>
  <bug id="16524" opendate="2016-8-29 00:00:00" fixdate="2016-12-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - Compute WALs cleanup on wal modification and not on every sync</summary>
      <description>Fix performance regression introduced by HBASE-16094.Instead of scanning all the wals every time, we can rely on the insert/update/delete events we have.and since we want to delete the wals in order we can keep track of what is "holding" that wal, and take a hit on scanning all the trackers only when we remove the first log in the queue.e.g.WAL-1 &amp;#91;1, 2&amp;#93; WAL-2 &amp;#91;1&amp;#93; -&gt; "&amp;#91;2&amp;#93; is holding WAL-1"WAL-3 &amp;#91;2&amp;#93; -&gt; "WAL 1 can be removed, recompute what is holding WAL-2"</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.wal.TestWALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.TestProcedureStoreTracker.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALFormatReader.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.ProcedureStoreTracker.java</file>
    </fixedFiles>
  </bug>
  <bug id="16530" opendate="2016-8-30 00:00:00" fixdate="2016-9-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reduce DBE code duplication</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.NoOpDataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.RowIndexSeekerV1.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.RowIndexEncoderV1.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.RowIndexCodecV1.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.CopyKeyDataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
    </fixedFiles>
  </bug>
  <bug id="16532" opendate="2016-8-30 00:00:00" fixdate="2016-8-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure-V2: Enforce procedure ownership at submission</summary>
      <description>HBASE-16520 (for TableBackupProcedure) and HBASE-16528 (for ServerCrashProcedure) were two recent JIRAs where procedure ownership is set at time of construction.This JIRA continues the discussion toward the end of HBASE-16520.Proposal is to enforce procedure ownership for all the procedures.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-procedure.src.test.resources.hbase-site.xml</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureExecutor.java</file>
    </fixedFiles>
  </bug>
  <bug id="16533" opendate="2016-8-30 00:00:00" fixdate="2016-8-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - Extract chore from the executor</summary>
      <description>At the moment we have the CompletedProcedureCleaner chore as a special case in the executor. let's extract that and allow to have other chores. (I want to use it for the AM)</description>
      <version>2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.util.TestTimeoutBlockingQueue.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.util.TimeoutBlockingQueue.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureExecutor.java</file>
    </fixedFiles>
  </bug>
  <bug id="16534" opendate="2016-8-30 00:00:00" fixdate="2016-9-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - Perf Tool for Scheduler</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.ProcedureTestingUtility.java</file>
    </fixedFiles>
  </bug>
  <bug id="16535" opendate="2016-8-31 00:00:00" fixdate="2016-8-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use regex to exclude generated classes for findbugs</summary>
      <description>As I tried in HBASE-16526, &lt;Match&gt; &lt;Package name="org.apache.hadoop.hbase.ipc.protobuf.generated"/&gt; &lt;/Match&gt;This does not work.So I propose that we can use regex to match the class name to exclude the generated classes.</description>
      <version>1.3.0,1.4.0,1.1.6,0.98.21,1.2.3,2.0.0</version>
      <fixedVersion>1.3.0,0.98.22,1.1.7,1.2.4,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.findbugs-exclude.xml</file>
    </fixedFiles>
  </bug>
  <bug id="16538" opendate="2016-8-31 00:00:00" fixdate="2016-9-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Version mismatch in HBaseConfiguration.checkDefaultsVersion</summary>
      <description>org.apache.hadoop.hbase.procedure2.TestYieldProcedurestestYieldEachExecutionStep(org.apache.hadoop.hbase.procedure2.TestYieldProcedures) Time elapsed: 0.255 sec &lt;&lt;&lt; ERROR!java.lang.RuntimeException: hbase-default.xml file seems to be for an older version of HBase (2.0.0-SNAPSHOT), this version is Unknown at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:73) at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:83) at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:98) at org.apache.hadoop.hbase.HBaseCommonTestingUtility.&lt;init&gt;(HBaseCommonTestingUtility.java:46) at org.apache.hadoop.hbase.procedure2.TestYieldProcedures.setUp(TestYieldProcedures.java:63)(Exact test is not important)Reference run:https://builds.apache.org/view/All/job/HBase-Trunk_matrix/jdk=JDK%201.8%20(latest),label=yahoo-not-h2/1515/console</description>
      <version>None</version>
      <fixedVersion>1.0.4,1.4.0,0.98.22,1.1.7,1.2.4,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.saveVersion.sh</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.VersionAnnotation.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.VersionInfo.java</file>
    </fixedFiles>
  </bug>
  <bug id="16547" opendate="2016-9-1 00:00:00" fixdate="2016-9-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase-archetype-builder shell scripts assume bash is installed in /bin</summary>
      <description>There's no guarantee UNIX systems will have bash installed in /bin. HBase builds fail for me on FreeBSD. The hbase-archetype-builder scripts do not use any bash features so let's specify '/bin/sh' as interpreter instead.</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-archetypes.hbase-archetype-builder.installArchetypes.sh</file>
      <file type="M">hbase-archetypes.hbase-archetype-builder.createArchetypes.sh</file>
    </fixedFiles>
  </bug>
  <bug id="16554" opendate="2016-9-2 00:00:00" fixdate="2016-9-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure V2 - Recover &amp;#39;updated&amp;#39; part of WAL tracker if trailer is corrupted.</summary>
      <description>If the last wal was closed cleanly, the global tracker will be the last wal tracker (no rebuild needed)if the last wal does not have a tracker (corrupted/master-killed). on load() we will rebuild the global tracker.To compute quickly which files should be deleted, we also want the tracker of each file.if the wal was closed properly and has a tracker we are good, if not we need to rebuild the tracker for that file.each file tracker contains a bitmap about what is in the wal (the updated bitmap), which is easy to compute just by reading each entry of the wal.The 'deleted' bitmap keeps track of the "running procedures" up to that wal, however, it's not required by WAL cleaner, so we don't bother recovering it.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.wal.TestWALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALFormatReader.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALFormat.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALFile.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.ProcedureStoreTracker.java</file>
    </fixedFiles>
  </bug>
  <bug id="1656" opendate="2009-7-14 00:00:00" fixdate="2009-7-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>loadZooConfig can mask true error</summary>
      <description>try { properties.load(inputStream);} catch (IOException e) { String msg = "fail to read properties from " + ZOOKEEPER_CONFIG_NAME; LOG.fatal(msg); throw new IOException(msg);}This masks the actual error, if there is one.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.zookeeper.HQuorumPeer.java</file>
    </fixedFiles>
  </bug>
  <bug id="16562" opendate="2016-9-5 00:00:00" fixdate="2016-10-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ITBLL should fail to start if misconfigured</summary>
      <description>The number of nodes in ITBLL must a multiple of width*wrap (defaults to 25M, but can be configured by adding two more args to the test invocation) or else verification will fail. This can be very expensive in terms of time or hourly billing for on demand test resources. Check the sanity of test parameters before launching any MR jobs and fail fast if invariants aren't met with an indication what parameter(s) need fixing.</description>
      <version>None</version>
      <fixedVersion>1.0.4,1.4.0,1.3.1,1.1.7,0.98.23,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
    </fixedFiles>
  </bug>
  <bug id="16574" opendate="2016-9-7 00:00:00" fixdate="2016-11-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add backup / restore feature to refguide</summary>
      <description>This issue is to add backup / restore feature description to hbase refguide.The description should cover:scenarios where backup / restore is usedbackup / restore commands and sample usageconsiderations in setup</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc.book.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="1658" opendate="2009-7-14 00:00:00" fixdate="2009-7-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove UI refresh -- its annoying</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.webapps.regionserver.regionserver.jsp</file>
      <file type="M">src.webapps.master.table.jsp</file>
      <file type="M">src.webapps.master.master.jsp</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="16614" opendate="2016-9-12 00:00:00" fixdate="2016-9-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use daemon thread for netty event loop</summary>
      <description>As always use daemon thread in rpc implementation.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.NettyRpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.DefaultNettyEventLoopConfig.java</file>
    </fixedFiles>
  </bug>
  <bug id="16618" opendate="2016-9-12 00:00:00" fixdate="2016-9-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - Add base class for table and ns procedures</summary>
      <description>Now that we have a bunch of procedures implemented, we can add a base class for the Table and Namespace procedure with a couple of the common pattern used (e.g. basic locking, toString, ...).</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.TruncateTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.RestoreSnapshotProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterDDLOperationHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.EnableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DispatchMergingRegionsProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DisableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CreateNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CloneSnapshotProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.AddColumnFamilyProcedure.java</file>
    </fixedFiles>
  </bug>
  <bug id="16621" opendate="2016-9-12 00:00:00" fixdate="2016-2-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBCK should have -fixHFileLinks</summary>
      <description>Similar to -fixReferenceFiles, HBCK should be able to sideline dangling HFile Links as well. We have seen a couple of cases, where due to HDFS-level fsck run which deleted files with missing blocks, the cluster is left with dangling HFIle Links, and regions cannot be opened because of these. Only a manual and error-prone finding and clearing of HFileLinks can save the tables regions.</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsckTwoRS.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsckOneRS.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.HbckTestingUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="16622" opendate="2016-9-13 00:00:00" fixdate="2016-10-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix some issues with the HBase reference guide</summary>
      <description>1. if (admin.tableExists(tableName)) { System.out.println("Table does not exist."); System.exit(-1); }This should be if (!admin.tableExists(tableName)) {2. SNAPPY is not suitable for begginer. They may get exceptions like Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(org.apache.hadoop.hbase.DoNotRetryIOException): org.apache.hadoop.hbase.DoNotRetryIOException: Compression algorithm 'snappy' previously failed test. Set hbase.table.sanity.checks to false at conf or table descriptor if you want to bypass sanity checks at org.apache.hadoop.hbase.master.HMaster.warnOrThrowExceptionForFailure(HMaster.java:1701) at org.apache.hadoop.hbase.master.HMaster.sanityCheckTableDescriptor(HMaster.java:1569) at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:1491) at org.apache.hadoop.hbase.master.MasterRpcServices.createTable(MasterRpcServices.java:462) at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$2.callBlockingMethod(MasterProtos.java:55682) at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2178) at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:112) at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:133) at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108) at java.lang.Thread.run(Thread.java:745)So the code belowtable.addFamily(new HColumnDescriptor(CF_DEFAULT).setCompressionType(Algorithm.SNAPPY));it better to change intotable.addFamily(new HColumnDescriptor(CF_DEFAULT).setCompressionType(Algorithm.NONE));3.Before modify column family , get the table from connectionChangeHTableDescriptor table = new HTableDescriptor(tableName);intoTable table = connection.getTable(TableName.valueOf(tablename));4.In 143.1.1. Code Formattingit just saidStill in Preferences, click . Be sure the following options are selected:Apache HBase ™ Reference GuideBut nothing after click. It should be Java-&gt;Editor-&gt;Save Actions</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.hbase.apis.adoc</file>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="16624" opendate="2016-9-13 00:00:00" fixdate="2016-9-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>MVCC DeSerialization bug in the HFileScannerImpl</summary>
      <description>My colleague naggarwal found a bug in the deserialization of mvcc from HFile, As a part of the optimization of deserialization of VLong, we read a int at once but we forgot to convert it to unsigned one. This would cause issues because once we cross the integer threshold in sequenceId and a compaction happens we would write MAX_MEMSTORE_TS in the trailer as 0 (because we will be reading negative values from the file that got flushed with sequenceId &gt; Integer.MAX_VALUE). And once we have MAX_MEMSTORE_TS as 0, and there are sequenceId values present alongside with KeyValues the regionserver will now start failing to read the compacted file and thus corruption. Interestingly this would happen only on the tables that don't have DataBlockEncoding enabled and unfortunately in our case that turned out to be META and a another small table.Fix is small (~20 chars) and attached</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="1663" opendate="2009-7-16 00:00:00" fixdate="2009-7-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Request compaction only once instead of every time 500ms each time we cycle the hstore.getStorefilesCount() &gt; this.blockingStoreFilesNumber loop</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="16647" opendate="2016-9-16 00:00:00" fixdate="2016-9-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbck should do offline reference repair before online repair</summary>
      <description>hbck-fixReferenceFiles Try to offline lingering reference store filesMetadata Repair shortcuts-repair Shortcut for -fixAssignments -fixMeta -fixHdfsHoles -fixHdfsOrphans -fixHdfsOverlaps -fixVersionFile -sidelineBigOverlaps -fixReferenceFiles -fixTableLocks -fixOrphanedTableZnodesBad reference files prevent the region from coming online.If used in the shortcut combination, the reference files should be fixed before other online fix.I have seen repeated '-repair' did not work because bad reference files failed regions.</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="16648" opendate="2016-9-18 00:00:00" fixdate="2016-12-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[JDK8] Use computeIfAbsent instead of get and putIfAbsent</summary>
      <description></description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestSplitLogManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterShutdown.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.BoundedGroupingStrategy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.TableAuthManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SequenceIdAccounting.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.CollectionUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ServerStatisticTracker.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.PreemptiveFastFailInterceptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MetricsConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MetaCache.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
    </fixedFiles>
  </bug>
  <bug id="16651" opendate="2016-9-18 00:00:00" fixdate="2016-9-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LRUBlockCache#returnBlock should try return block to Victim Handler L2 cache.</summary>
      <description>In case of L1 and L2 cache usage with combinedMode = false, L2 is used as a victim handler cache for L1 cache. When a getBlock() request comes, L1 will see if block is in it and if not it will try to provide the block from L2 cache. In such a case, the return block must return the block to L2 cache and count down the ref count for the block. But right now we just ignore the returnBlock call in LRUCache</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.java</file>
    </fixedFiles>
  </bug>
  <bug id="16654" opendate="2016-9-19 00:00:00" fixdate="2016-9-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Better handle channelInactive and close for netty rpc client</summary>
      <description>We should pass the event to the next handler in the pipeline as channelInactive and close are usually used as the cleanup method of a ChannelHandler.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.SaslWrapHandler.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.SaslUnwrapHandler.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.AsyncHBaseSaslRpcClientHandler.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.AsyncHBaseSaslRpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.NettyRpcConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.BufferCallBeforeInitHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="16657" opendate="2016-9-20 00:00:00" fixdate="2016-10-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expose per-region last major compaction timestamp in RegionServer UI</summary>
      <description>HBASE-12859 added some tracking for the last major compaction completed for each region. However, this is currently only exposed through the cluster status reporting and the Admin API. Since the regionserver is already reporting this information, it would be nice to fold it in somewhere to the region listing in the regionserver UI.</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="16658" opendate="2016-9-20 00:00:00" fixdate="2016-9-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Optimize UTF8 string/byte conversions</summary>
      <description>String/byte conversions may take either a Charset instance or its canonical name. One might think a Charset instance would be faster due to avoiding a lookup and instantiation of a Charset, but it's not. The canonical string name variants will cache the string encoder/decoder (obtained from a Charset) resulting in better performance.See HDFS-10662</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Bytes.java</file>
    </fixedFiles>
  </bug>
  <bug id="16690" opendate="2016-9-23 00:00:00" fixdate="2016-10-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move znode path configs to a separated class</summary>
      <description>Which makes it easier to use curator at client in the future.And also, will try to fix the bad practise that declares masterMaintZNode as static but update it in a non-static method.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZooKeeperNodeTracker.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKMulti.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.zookeeper.lock.TestZKInterProcessReadWriteLock.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationTrackerZKImpl.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationStateZKImpl.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationStateHBaseImpl.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitLogWorker.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerHostname.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMasterAddressTracker.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mob.mapreduce.TestMobSweepReducer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mob.mapreduce.TestMobSweepMapper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestTableStateManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestTableLockManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestSplitLogManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMetaShutdownHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterWalManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterStatusServlet.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ZooKeeperRegistry.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationStateZKBase.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationTrackerZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.MasterAddressTracker.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.MetaTableLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZkAclReset.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKClusterId.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperNodeTracker.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZooKeeperWatcher.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestMetaReplicas.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestZKAndFSPermissions.java</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupInfoManagerImpl.java</file>
      <file type="M">hbase-rsgroup.src.test.java.org.apache.hadoop.hbase.rsgroup.VerifyingRSGroupAdminClient.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.example.ZKTableArchiveClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ActiveMasterManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterMetaBootstrap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableLockManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.mapreduce.SweepJob.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.HBaseReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.ZKPermissionWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.ZKSecretWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.ZKVisibilityLabelWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.hbck.ReplicationChecker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ZKDataMigrator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ZKNamespaceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ClusterStatusTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.DrainingServerTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.LoadBalancerTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.MasterMaintenanceModeTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.RecoveringRegionWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.RegionNormalizerTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.RegionServerTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.SplitOrMergeTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKSplitLog.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMetaWithReplicas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestActiveMasterManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestHMasterRPCException.java</file>
    </fixedFiles>
  </bug>
  <bug id="1670" opendate="2009-7-17 00:00:00" fixdate="2009-7-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>transactions / indexing fixes: trx deletes not handeled, index scan can&amp;#39;t specify stopRow</summary>
      <description>couple of things I missed in api refactor</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">src.contrib.transactional.src.test.org.apache.hadoop.hbase.client.transactional.TestTransactions.java</file>
      <file type="M">src.contrib.transactional.src.test.org.apache.hadoop.hbase.client.tableindexed.TestIndexedTable.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.regionserver.transactional.TransactionState.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegionServer.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegion.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.regionserver.transactional.THLog.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.regionserver.tableindexed.IndexMaintenanceUtils.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.regionserver.tableindexed.IndexedRegion.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.client.transactional.TransactionManager.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.client.transactional.TransactionalTable.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.client.transactional.JtaXAResource.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.client.tableindexed.IndexedTableDescriptor.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.client.tableindexed.IndexedTable.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="16700" opendate="2016-9-24 00:00:00" fixdate="2016-12-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow for coprocessor whitelisting</summary>
      <description>Today one can turn off all non-system coprocessors with hbase.coprocessor.user.enabled however, this disables very useful things like Apache Phoenix's coprocessors. Some tenants of a multi-user HBase may also need to run bespoke coprocessors. But as an operator I would not want wanton coprocessor usage. Ideally, one could do one of two things: Allow coprocessors defined in hbase-site.xml &amp;#8211; this can only be administratively changed in most cases Allow coprocessors from table descriptors but only if the coprocessor is whitelisted</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.cp.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="16704" opendate="2016-9-25 00:00:00" fixdate="2016-9-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scan will be broken while working with DBE and KeyValueCodecWithTags</summary>
      <description>scan will always broken if we set LIMIT more than 1 with rs hbase.client.rpc.codec set to org.apache.hadoop.hbase.codec.KeyValueCodecWithTags.How to reproduce:1. 1 master + 1 rs, codec use KeyValueCodecWithTags.2. create a table table_1024B_30g，1 cf and with only 1 qualifier, then load some data with ycsb，. Use Diff DataBlockEncoding3. scan 'table_1024B_30g', {LIMIT =&gt; 2, STARTROW =&gt; 'user5499'}, STARTROW is set any valid start row.4. scan failed.this should be bug in KeyValueCodecWithTags, after some investigations, I found some the key not serialized correctly.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestBufferedDataBlockEncoder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="16711" opendate="2016-9-27 00:00:00" fixdate="2016-9-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix hadoop-3.0 profile compile</summary>
      <description>The -Dhadoop.profile=3.0 build is failing currently due to code deprecated in hadoop2 and removed in hadoop3.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.IncrementCoalescer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestBulkLoad.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.HttpServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="16712" opendate="2016-9-27 00:00:00" fixdate="2016-10-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>fix hadoop-3.0 profile mvn install</summary>
      <description>After the compile is fixed, mvn install fails due to transitive dependencies coming from hadoop3.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-resource-bundle.src.main.resources.supplemental-models.xml</file>
      <file type="M">hbase-resource-bundle.src.main.resources.META-INF.NOTICE.vm</file>
      <file type="M">hbase-resource-bundle.src.main.resources.META-INF.LICENSE.vm</file>
    </fixedFiles>
  </bug>
  <bug id="16714" opendate="2016-9-27 00:00:00" fixdate="2016-9-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure V2 - use base class to remove duplicate set up test code in table DDL procedures</summary>
      <description>All table DDL procedure tests has the same set up. To avoid duplicate code and help maintain the existing test, we should move the same set up in a base class.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestTruncateTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestRestoreSnapshotProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestModifyTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestModifyColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestEnableTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestDisableTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestDeleteTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestDeleteColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestCreateTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestCloneSnapshotProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestAddColumnFamilyProcedure.java</file>
    </fixedFiles>
  </bug>
  <bug id="16716" opendate="2016-9-27 00:00:00" fixdate="2016-10-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>OfflineMetaRepair leaves empty directory inside /hbase/WALs which remains forever</summary>
      <description>OfflineMetaRepair rebuild Meta table, while creating meta region it creates it's own WAL (inside /hbase/WALs/hbck-meta-recovery-&lt;randomNumber&gt;) which wll be closed and archived after rebuilding Meta. hbase org.apache.hadoop.hbase.util.hbck.OfflineMetaRepair &gt;&gt; /hbase/WALs/hbck-meta-recovery-&lt;randomNumber&gt;It doesn't clear the empty dir, empty directory should be removed after success.</description>
      <version>2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="16722" opendate="2016-9-28 00:00:00" fixdate="2016-8-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document: Broken link in CatalogJanitor</summary>
      <description>A link in CatalogJanitor is broken. This should be linked to https://hbase.apache.org/book.html#arch.catalog.meta</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0-alpha-3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="16730" opendate="2016-9-29 00:00:00" fixdate="2016-7-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Exclude junit as a transitive dependency from hadoop-common</summary>
      <description>add exclusion to the hadoop-common dependency in hbase-client: exclude junit</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-spark.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="16733" opendate="2016-9-30 00:00:00" fixdate="2016-10-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>add hadoop 3.0.0-alpha1 to precommit checks</summary>
      <description>Been working on getting hadoop3 related build up and running and woudl ike to add a precommit check so that new commits don't break the mvn compile/install.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  <bug id="16735" opendate="2016-9-30 00:00:00" fixdate="2016-10-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - Fix yield while holding locks</summary>
      <description>Sched fix for proc holding locks. the proc was added back to the queue, but the queue was not re-added to the runq</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMasterProcedureScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.TableProcedureInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.java</file>
    </fixedFiles>
  </bug>
  <bug id="16738" opendate="2016-9-30 00:00:00" fixdate="2016-10-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>L1 cache caching shared memory HFile block when blocks promoted from L2 to L1</summary>
      <description>This is an issue when L1 and L2 cache used with combinedMode = false.See in getBlockif (victimHandler != null &amp;&amp; !repeat) { Cacheable result = victimHandler.getBlock(cacheKey, caching, repeat, updateCacheMetrics); // Promote this to L1. if (result != null &amp;&amp; caching) { cacheBlock(cacheKey, result, /* inMemory = */ false, /* cacheData = */ true); } return result; }When block is not there in L1 and have it in L2, we will return the block read from L2 and promote that block to L1 by adding it in LRUCache. But if the Block buffer is having shared memory (Off heap bucket cache for eg , we can not directly cache this block. The buffer memory area under this block can get cleaned up at any time. So we may get block data corruption.In such a case, we need to do a deep copy of the block (Including its buffer) and then add that to L1 cache.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
    </fixedFiles>
  </bug>
  <bug id="16759" opendate="2016-10-4 00:00:00" fixdate="2016-10-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Avoid ByteString.copyFrom usage wherever possible</summary>
      <description>We can use UnsafeByteOperations.unsafeWrap instead as we are moving to PB 3. Mostly it is this way through out code base but missing a few places. Patch addresses all such cases.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALKey.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALCellCodec.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.Procedure.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.CoprocessorRpcUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.replication.ReplicationSerDeHelper.java</file>
    </fixedFiles>
  </bug>
  <bug id="16763" opendate="2016-10-4 00:00:00" fixdate="2016-10-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove unintentional dependency on net.sf.ehcache.search.Results</summary>
      <description>HBASE-15638 introduced what looks like an inadvertent dependency on net.sf.ehcache.search.Results. This removes it.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="16774" opendate="2016-10-5 00:00:00" fixdate="2016-10-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[shell] Add coverage to TestShell when ZooKeeper is not reachable</summary>
      <description>While testing a couple of things in master I noticed that after some of the changes done in HBASE-16117 the hbase shell would die when there is no ZooKeeper server up or if we get another ZK exception. This is to add coverage to test the shell when ZK is not up or if we get another exception.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestClientTimeouts.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableOutputFormat.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ZooKeeperRegistry.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Registry.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
    </fixedFiles>
  </bug>
  <bug id="16776" opendate="2016-10-5 00:00:00" fixdate="2016-10-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove duplicated versions of countRow() in tests</summary>
      <description>A bunch of tests have their copy of countRow() use the ones in TestingUtility</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.BaseTestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionMergeTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMobStoreCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestServerCrashProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
    </fixedFiles>
  </bug>
  <bug id="16780" opendate="2016-10-6 00:00:00" fixdate="2016-3-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Since move to protobuf3.1, Cells are limited to 64MB where previous they had no limit</summary>
      <description>Change in protobuf behavior noticed by mbertozzi. His test TestStressWALProcedureStore#testEntrySizeLimit keeps upping size we write and he found that now we are bound at 64MB. Digging, yeah, there is a check in place that was not there before. Filed https://github.com/grpc/grpc-java/issues/2324 but making issue here in meantime in case we have to note a change-in-behavior in hbase-2.0.0</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.MethodOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.ZooKeeperProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.TracingProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.RegionNormalizerProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.ProcedureProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.LockServiceProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.LoadBalancerProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.HFileProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.FSProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.EncryptionProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterIdProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.BackupProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.ipc.protobuf.generated.TestProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.ipc.protobuf.generated.TestProcedureProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ValueOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Value.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSetLite.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.UInt64ValueOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.UInt64Value.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.UInt32ValueOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.UInt32Value.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.TypeProto.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.TypeOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Type.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.TimestampOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Timestamp.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Syntax.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Struct.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.StringValueOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.StringValue.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.SourceContextProto.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.SourceContextOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.SourceContext.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.SmallSortedMap.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.OptionOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Option.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.NullValue.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.MixinOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Mixin.java</file>
      <file type="M">hbase-protocol-shaded.pom.xml</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.AbstractMessageLite.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.AbstractParser.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Any.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.AnyOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Api.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ApiOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ApiProto.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.BoolValue.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.BoolValueOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteBufferWriter.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.BytesValue.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.BytesValueOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.compiler.PluginProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.DescriptorProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.DoubleValue.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.DoubleValueOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Duration.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.DurationOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.DynamicMessage.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Empty.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Enum.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.EnumOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.EnumValue.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.EnumValueOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistry.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Field.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.FieldMask.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.FieldMaskProto.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.FieldOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.FieldSet.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.FloatValue.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.FloatValueOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageLite.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Int32Value.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Int32ValueOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Int64Value.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Int64ValueOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.LazyFieldLite.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ListValue.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.MapEntry.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.MapFieldLite.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.MessageLiteToString.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Method.java</file>
    </fixedFiles>
  </bug>
  <bug id="16781" opendate="2016-10-6 00:00:00" fixdate="2016-10-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix flaky TestMasterProcedureWalLease</summary>
      <description>Attempt to fix the flaky TestMasterProcedureWalLease.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockNoopMasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="16784" opendate="2016-10-6 00:00:00" fixdate="2016-10-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make use of ExtendedCell#write(OutputStream os) for the default HFileWriter#append()</summary>
      <description>Initially this I was thinking we need to add an interface to represent the fact that the key is contiguous. But since Extendedcell is added encapsulating all the internal interfaces and adds a write(OutputStream , boolean) and tries to exploit the fact that the Cell is in KV serialized format. Hence we can make use of it in HFileWriter#append() code in case of No encoding case.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValueUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.NoneEncoder.java</file>
    </fixedFiles>
  </bug>
  <bug id="16785" opendate="2016-10-6 00:00:00" fixdate="2016-1-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>We are not running all tests</summary>
      <description>Noticed by mbertozziWe have some modules where we tried to 'skip' the running of the second part of tests &amp;#8211; medium and larges. That might have made sense once when the module was originally added when there may have been just a few small tests to run but as time goes by and the module accumulates more tests.... in a few cases we've added mediums and larges but we've not removed the 'skip' config.Matteo noticed this happened in hbase-procedure.In hbase-client, there is at least a medium test that is being skipped.Let me try purging this trick everywhere. It doesn't seem to save us anything going by build time.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.wal.TestStressWALProcedureStore.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestAsyncProcess.java</file>
      <file type="M">hbase-endpoint.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionServerBulkLoadWithOldSecureEndpoint.java</file>
      <file type="M">hbase-rsgroup.pom.xml</file>
      <file type="M">hbase-procedure.pom.xml</file>
      <file type="M">hbase-prefix-tree.pom.xml</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-hadoop-compat.pom.xml</file>
      <file type="M">hbase-external-blockcache.pom.xml</file>
      <file type="M">hbase-examples.pom.xml</file>
      <file type="M">hbase-endpoint.pom.xml</file>
      <file type="M">hbase-common.pom.xml</file>
      <file type="M">hbase-client.pom.xml</file>
      <file type="M">hbase-checkstyle.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="16793" opendate="2016-10-9 00:00:00" fixdate="2016-10-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Exclude shaded protobuf files from rat check</summary>
      <description></description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="16801" opendate="2016-10-10 00:00:00" fixdate="2016-10-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The Append/Increment may return the data from future</summary>
      <description>OperationContext maintains the mvcc as a static member, so any Append’s and Increment’s read point will be changed by others. That is, a retrying Append/Increment may “see” the future data.This is a master only issue.</description>
      <version>2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestServerNonceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ServerNonceManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="16802" opendate="2016-10-10 00:00:00" fixdate="2016-10-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - group procedure cleaning</summary>
      <description>group the cleaning of the evicted procedures</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.wal.TestWALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.ProcedureTestingUtility.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.ProcedureStore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.NoopProcedureStore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureExecutor.java</file>
    </fixedFiles>
  </bug>
  <bug id="16803" opendate="2016-10-10 00:00:00" fixdate="2016-10-10 01:00:00" resolution="Won&amp;#39;t Fix">
    <buginformation>
      <summary>Make hbase:acl table unsplittable</summary>
      <description>HBASE-16773 fixed a case where PriorityRpcServer handler threads are all occupied accessing hbase:acl table.However, the fix relies on the fact that there is single region in hbase:acl table so that the access can be local.As discussed at the end of HBASE-16773, we should disable split of hbase:acl table as well.hbase:meta is normally much larger than hbase:acl table and it has only one region.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlLists.java</file>
    </fixedFiles>
  </bug>
  <bug id="16811" opendate="2016-10-11 00:00:00" fixdate="2016-10-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove mob sweep job</summary>
      <description>Discussed here: http://mail-archives.apache.org/mod_mbox/hbase-dev/201610.mbox/%3CCAAjhxro%3Dt62K44dV2wUtq1hqYLogZ45M3oeNOFZPcnwcSY4_DQ%40mail.gmail.com%3E</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mob.mapreduce.TestMobSweepReducer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mob.mapreduce.TestMobSweepMapper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mob.mapreduce.TestMobSweepJob.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.mapreduce.SweepReducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.mapreduce.SweepMapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.mapreduce.SweepJobNodeTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.mapreduce.SweepJob.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.mapreduce.Sweeper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.mapreduce.MobFilePathHashPartitioner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.mapreduce.MemStoreWrapper.java</file>
    </fixedFiles>
  </bug>
  <bug id="16812" opendate="2016-10-12 00:00:00" fixdate="2016-1-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up the locks in MOB</summary>
      <description>Clean up the locks in MOB. Retain all the delete markers in mob-enabled columns until they are expired. Remove the locks from major compaction of mob-enabled columns.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMobStoreCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mob.TestMobFileName.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MobCompactionStoreScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HMobStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.Compactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.MobUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.DefaultMobStoreCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.compactions.PartitionedMobCompactor.java</file>
    </fixedFiles>
  </bug>
  <bug id="16835" opendate="2016-10-14 00:00:00" fixdate="2016-10-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Revisit the zookeeper usage at client side</summary>
      <description>Watcher or not.Curator or not.Keep connection or not....</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTableNoncedRetry.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ZKClusterRegistry.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClusterRegistryFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClusterRegistry.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncConnectionImpl.java</file>
      <file type="M">hbase-client.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="16836" opendate="2016-10-14 00:00:00" fixdate="2016-10-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement increment and append</summary>
      <description></description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMultiParallel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.CoprocessorHConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.PerClientRandomNonceGenerator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.NonceGenerator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncConnectionImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="16837" opendate="2016-10-14 00:00:00" fixdate="2016-10-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement checkAndPut and checkAndDelete</summary>
      <description></description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="1685" opendate="2009-7-22 00:00:00" fixdate="2009-7-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[stargate] package and wiki documentation</summary>
      <description>Write package and wiki documentation for the Stargate contrib. Convert spec and transaction examples into package javadoc. Render package javadoc into wiki markup. Write up instructions for starting the service in standalone mode and as a servlet.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.overview.html</file>
    </fixedFiles>
  </bug>
  <bug id="16856" opendate="2016-10-17 00:00:00" fixdate="2016-10-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Exception message in SyncRunner.run() should print currentSequence</summary>
      <description>A very small bug, a typo in exception message:if (syncFutureSequence &gt; currentSequence) { throw new IllegalStateException("currentSequence=" + syncFutureSequence + ", syncFutureSequence=" + syncFutureSequence); }It should print currentSequence and syncFutureSequence, but print two syncFutureSequence</description>
      <version>1.2.2,1.1.7,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
    </fixedFiles>
  </bug>
  <bug id="16865" opendate="2016-10-17 00:00:00" fixdate="2016-11-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - Inherit lock from root proc</summary>
      <description>At the moment we support inheriting locks from the parent procedure for a 2 level procedures, but in case of reopen table regions we have a 3 level procedures (ModifyTable -&gt; ReOpen -&gt; &amp;#91;Unassign/Assign&amp;#93;) and reopen does not have any locks on its own.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMasterProcedureScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.ProcedureTestingUtility.java</file>
    </fixedFiles>
  </bug>
  <bug id="16867" opendate="2016-10-18 00:00:00" fixdate="2016-1-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure V2 - Check ACLs for remote HBaseLock</summary>
      <description>HBaseLock was added in HBASE-16744 to allow clients to take locks on namespace/table/regions. Check acls for the 2 rpcs that were added.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug id="16869" opendate="2016-10-18 00:00:00" fixdate="2016-1-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Typo in "Disabling Blockcache" doc</summary>
      <description>The Disabling Blockcache section of the documentation refers to hbase.block.cache.size. Should it be hfile.block.cache.size?</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="16871" opendate="2016-10-18 00:00:00" fixdate="2016-10-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - add waiting procs back to the queue after restart</summary>
      <description>Procs in WAITING_TIMEOUT state don't get re-added to the queue after restart.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.TestProcedureEvents.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.ProcedureTestingUtility.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureExecutor.java</file>
    </fixedFiles>
  </bug>
  <bug id="16872" opendate="2016-10-18 00:00:00" fixdate="2016-10-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement mutateRow and checkAndMutate</summary>
      <description></description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="16875" opendate="2016-10-18 00:00:00" fixdate="2016-4-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Changed try-with-resources in the docs to recommended way</summary>
      <description>In a number of places, we show examples that lend themselves to using Java 7's try-with-resources statement, but we use the statement in a less-than-ideal nested way. Let's change our docs throughout to do it the recommended way.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.security.adoc</file>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="16884" opendate="2016-10-20 00:00:00" fixdate="2016-10-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add HBase-2.0.x to the hadoop version support matrix in our documentation</summary>
      <description></description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="16886" opendate="2016-10-20 00:00:00" fixdate="2016-12-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase-client: scanner with reversed=true and small=true gets no result</summary>
      <description>Assume HBase have four regions (-oo, b), [b, c), [c, d), [d,+oo) , and all rowKeys are located in region [d, +oo). using a Reversed Small Scanner will get no result.Attached file show this failed test case.</description>
      <version>1.3.0,1.4.0,1.2.3,1.1.7,0.98.23,2.0.0</version>
      <fixedVersion>1.4.0,1.3.1,1.2.5,1.1.8,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestClientSmallReversedScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallReversedScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="16887" opendate="2016-10-20 00:00:00" fixdate="2016-10-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow setting different hadoopcheck versions in precommit for different branches</summary>
      <description>http://hbase.apache.org/book.html#hadoopThe supportted hadoop versions are different for different HBase versions.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  <bug id="1689" opendate="2009-7-23 00:00:00" fixdate="2009-7-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix javadoc warnings and add overview on client classes to client package.</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.client.package-info.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.MetaUtils.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HServerLoad.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.ServerConnectionManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.ServerConnection.java</file>
      <file type="M">src.contrib.stargate.src.java.org.apache.hadoop.hbase.stargate.RESTServlet.java</file>
      <file type="M">src.contrib.stargate.src.java.org.apache.hadoop.hbase.stargate.model.TableSchemaModel.java</file>
      <file type="M">src.contrib.stargate.src.java.org.apache.hadoop.hbase.stargate.model.StorageClusterStatusModel.java</file>
      <file type="M">src.contrib.stargate.src.java.org.apache.hadoop.hbase.stargate.client.Client.java</file>
    </fixedFiles>
  </bug>
  <bug id="1693" opendate="2009-7-23 00:00:00" fixdate="2009-7-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>NPE close_region ".META." in shell</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.master.RegionManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.HBase.rb</file>
    </fixedFiles>
  </bug>
  <bug id="16932" opendate="2016-10-24 00:00:00" fixdate="2016-10-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement small scan</summary>
      <description>As said in HBASE-16838, we should have a scan method that returns a CompletaFuture for the whole result. It is suitable for a small scan.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallReversedScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncSingleRequestRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRpcRetryingCallerFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRegionLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncConnectionConfiguration.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="1694" opendate="2009-7-24 00:00:00" fixdate="2009-7-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add TOC to &amp;#39;Getting Started&amp;#39;, add references to THBase and ITHBase</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.overview.html</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.Migrate.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="16941" opendate="2016-10-25 00:00:00" fixdate="2016-12-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>FavoredNodes - Split/Merge code paths</summary>
      <description>This jira is to deal with the split/merge logic discussed as part of HBASE-15532. The design document can be seen at HBASE-15531. The specific changes are:Split and merged regions should inherit favored node information from parent regions. For splits also include some randomness so even if there are subsequent splits, the regions will be more or less distributed. For split, we include 2 FN from the parent and generate one random node.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRegionPlacement2.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRegionPlacement.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockNoopMasterServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestFavoredNodeAssignmentHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SnapshotOfRegionAssignmentFromMeta.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionPlacementMaintainer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.FavoredNodeLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.FavoredNodeAssignmentHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentVerificationReport.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ServerName.java</file>
    </fixedFiles>
  </bug>
  <bug id="16949" opendate="2016-10-26 00:00:00" fixdate="2016-10-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix RAT License complaint about the hbase-protocol-shaded/src/main/patches content</summary>
      <description>Noticed by @duo zhang over on HBASE-16835. Let me exclude the patches dir from rat check.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-protocol.README.txt</file>
      <file type="M">hbase-protocol-shaded.README.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1695" opendate="2009-7-24 00:00:00" fixdate="2009-7-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[stargate] differentiate PUT and POST processing for schema upload</summary>
      <description>The Stargate documentation states the following regarding PUT and POST to a table schema resource:PUT or POST creates table as necessary. PUT fully replaces schema. POST modifies schema (add or modify column family). Supply the full table schema for PUT or a well formed schema fragment for POST in the desired encoding.Current implementation punts and treats both PUT and POST as equivalent. Fix before release.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.contrib.stargate.src.java.org.apache.hadoop.hbase.stargate.SchemaResource.java</file>
    </fixedFiles>
  </bug>
  <bug id="16950" opendate="2016-10-27 00:00:00" fixdate="2016-10-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Print raw stats in the end of procedure performance tools for parsing results from scripts</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureSchedulerPerformanceEvaluation.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALPerformanceEvaluation.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALLoaderPerformanceEvaluation.java</file>
    </fixedFiles>
  </bug>
  <bug id="16955" opendate="2016-10-27 00:00:00" fixdate="2016-11-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fixup precommit protoc check to do new distributed protos and pb 3.1.0 build</summary>
      <description>HBASE-15638 Shade protobuf and a follow-ons changed how we do protobufs. One, protobufs are in the module they pertain to so distributed throughout the modules and secondly, we do 2.5.0 pb for externally consumed protobuf &amp;#8211; e.g. Coprocessor Endpoints &amp;#8211; but internally we use protobuf 3.1.0.A precommit check looks to see if any proto changes break protoc compile. This task is about updating the precommit to accommodate the changes brought about by HBASE-15638.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-protocol-shaded.pom.xml</file>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  <bug id="16956" opendate="2016-10-27 00:00:00" fixdate="2016-11-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Refactor FavoredNodePlan to use regionNames as keys</summary>
      <description>We would like to rely on the FNPlan cache whether a region is offline or not. Sticking to regionNames as keys makes that possible.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRegionPlacement.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionPlacementMaintainer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan.java</file>
    </fixedFiles>
  </bug>
  <bug id="16960" opendate="2016-10-28 00:00:00" fixdate="2016-11-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RegionServer hang when aborting</summary>
      <description>We see regionserver hang when aborting several times and cause all regions on this regionserver out of service and then all affected applications stop works.</description>
      <version>1.3.0,1.4.0,1.2.3,1.1.7,2.0.0</version>
      <fixedVersion>1.3.0,1.2.5,1.1.8,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestWALLockup.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SyncFuture.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.java</file>
    </fixedFiles>
  </bug>
  <bug id="16974" opendate="2016-10-31 00:00:00" fixdate="2016-10-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update os-maven-plugin to 1.4.1.final+ for building shade file on RHEL/CentOS</summary>
      <description>The current os-maven-plugin may export the profile with quote on certain versions of centos/RHEL, and it introduces the error when building shade file. The error message is shown below. [ERROR] Failed to execute goal org.apache.maven.plugins:maven-shade-plugin:2.4.3:shade (default) on project hbase-protocol-shaded: Error creating shaded jar: The name "os.detected.release.like."centos"" is not legal for JDOM/XML elements: XML names cannot contain the character """. -&gt; [Help 1]The error is caused by the /etc/os-release which contains some quote. The os-maven-plugin 1.4.1.final+ had fixed it. Therefore, we ought to update the os-maven-plugin to 1.4.1.final+ for the user who can’t change the content of the /etc/os-release.Any comment? Thanks.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-protocol-shaded.README.txt</file>
    </fixedFiles>
  </bug>
  <bug id="16976" opendate="2016-10-31 00:00:00" fixdate="2016-11-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase-protocol-shaded module generates classes to wrong directory</summary>
      <description>I've been fighting with getting master to import/build normally inside of Eclipse (a bit seems to have come in as a part of the shaded protocol work).Once thing I see definitely wrong is that Eclipse is balking at the source files being compiled in target/ instead of target/classes. This looks like an omission since there is no good reason to not use the standard convention of target/classes.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-protocol-shaded.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="16984" opendate="2016-11-1 00:00:00" fixdate="2016-11-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement getScanner</summary>
      <description>It will just return the old ResultScanner and work like the AsyncPrefetchClientScanner. I think we still need this as we can not do time consuming work in the ScanObserver introduced in HBASE-16838.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestCompleteResultScanResultCache.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTableScan.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.AbstractTestAsyncTableScan.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScanResultConsumer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncTableImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.CompleteScanResultCache.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncScanSingleRegionRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRpcRetryingCallerFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AllowPartialScanResultCache.java</file>
    </fixedFiles>
  </bug>
  <bug id="16985" opendate="2016-11-1 00:00:00" fixdate="2016-12-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestClusterId failed due to wrong hbase rootdir</summary>
      <description>https://builds.apache.org/job/PreCommit-HBASE-Build/4253/testReport/org.apache.hadoop.hbase.regionserver/TestClusterId/testClusterId/java.io.IOException: Shutting down at org.apache.hadoop.hbase.util.JVMClusterUtil.startup(JVMClusterUtil.java:230) at org.apache.hadoop.hbase.LocalHBaseCluster.startup(LocalHBaseCluster.java:409) at org.apache.hadoop.hbase.MiniHBaseCluster.init(MiniHBaseCluster.java:227) at org.apache.hadoop.hbase.MiniHBaseCluster.&lt;init&gt;(MiniHBaseCluster.java:96) at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniHBaseCluster(HBaseTestingUtility.java:1071) at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniHBaseCluster(HBaseTestingUtility.java:1037) at org.apache.hadoop.hbase.regionserver.TestClusterId.testClusterId(TestClusterId.java:85)The cluster can not start up because there are no active master. The active master can not finish initialing because the hbase:namespace region can not be assign. In TestClusterId unit test, TEST_UTIL.startMiniHBaseCluster set new hbase root dir. But the regionserver thread which stared first used a different hbase root dir. If assign hbase:namespace region to this regionserver, the region can not be assigned because there are no tableinfo on wrong hbase root dir.When regionserver report to master, it will get back some new config. But the FSTableDescriptors has been initialed so it's root dir didn't changed.if (LOG.isDebugEnabled()) { LOG.info("Config from master: " + key + "=" + value);} I thought FSTableDescriptors need update the rootdir when regionserver get report from master.The master branch has same problem, too. But the balancer always assign hbase:namesapce region to master. So this unit test can passed on master branch.</description>
      <version>1.3.0,1.4.0,1.1.7,1.2.4,2.0.0</version>
      <fixedVersion>1.4.0,1.2.5,1.1.9,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="16986" opendate="2016-11-1 00:00:00" fixdate="2016-11-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add note on how scanner caching has changed since 0.98 to refguid</summary>
      <description>Add note on how scanner caching config changed from 0.98 to the refguide (see parent issue for discussion but basics are we used to have default of 100 but not have unlimited as default)</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="17006" opendate="2016-11-2 00:00:00" fixdate="2016-11-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add names to threads for better debugability of thread dumps</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.3.0,1.0.4,1.2.5,1.1.8,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MultiThreadedWriterBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MultiThreadedAction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluationCommons.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ModifyRegionUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.JvmPauseMonitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.Canary.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ShutdownHook.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServicesForStores.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.LogRoller.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Leases.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterMobCompactionThread.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.PrefetchExecutor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.fs.HFileSystem.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.monkies.PolicyBasedChaosMonkey.java</file>
    </fixedFiles>
  </bug>
  <bug id="17012" opendate="2016-11-3 00:00:00" fixdate="2016-11-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Handle Offheap cells in CompressedKvEncoder</summary>
      <description>When we deal with off heap cells we will end up copying Cell components on heappublic void write(Cell cell) throws IOException {................. write(cell.getRowArray(), cell.getRowOffset(), cell.getRowLength(), compression.rowDict); write(cell.getFamilyArray(), cell.getFamilyOffset(), cell.getFamilyLength(), compression.familyDict); write(cell.getQualifierArray(), cell.getQualifierOffset(), cell.getQualifierLength(), compression.qualifierDict);...... out.write(cell.getValueArray(), cell.getValueOffset(), cell.getValueLength());...We need to avoid this.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestWALReaderOnSecureWAL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALCellCodecWithCompression.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestRpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALCellCodec.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SecureWALCellCodec.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.util.Dictionary.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.TagCompressionContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="17017" opendate="2016-11-4 00:00:00" fixdate="2016-11-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove the current per-region latency histogram metrics</summary>
      <description></description>
      <version>1.3.0,1.4.0,2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="17044" opendate="2016-11-8 00:00:00" fixdate="2016-11-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix merge failed before creating merged region leaves meta inconsistent</summary>
      <description>Similar to HBASE-16093. Rollback from failed merge should not offline the target region for the merge if it hasn't been created.</description>
      <version>None</version>
      <fixedVersion>1.3.0,1.2.5,0.98.24,1.1.8,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="17045" opendate="2016-11-8 00:00:00" fixdate="2016-1-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unify the implementation of small scan and regular scan</summary>
      <description>See enis's comment in HBASE-16838https://issues.apache.org/jira/browse/HBASE-16838?focusedCommentId=15637803&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15637803But there is another scenario that we need small scan is that, we do not know the stop row but we only want a small set of results. For example, in the implementation of region locator, we will use small scan and set caching to 1 as we only need one row.So I think we need to add a new option(maybe called limit?) for the scan object, and deprecate the small option. And the server side modification should also be committed to branch-1 to simplify the logic of async client in 2.0.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestMultiRowRangeFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestRawAsyncTableScan.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTableSmallScan.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.AbstractTestAsyncTableScan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Client.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ClientProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.Client.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawScanResultConsumer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncTableImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableBase.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncSmallScanRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncScanSingleRegionRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRpcRetryingCallerFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncNonMetaRegionLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncClientScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="17047" opendate="2016-11-8 00:00:00" fixdate="2016-11-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add an API to get HBase connection cache statistics</summary>
      <description>This patch will add a function "getStat" for the user to get the statistics of the HBase connection cache.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.src.test.scala.org.apache.hadoop.hbase.spark.HBaseConnectionCacheSuite.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.HBaseConnectionCache.scala</file>
    </fixedFiles>
  </bug>
  <bug id="17049" opendate="2016-11-8 00:00:00" fixdate="2016-11-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Do not issue sync request when there are still entries in ringbuffer</summary>
      <description>https://issues.apache.org/jira/browse/HBASE-16890?focusedCommentId=15647590&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15647590</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.java</file>
    </fixedFiles>
  </bug>
  <bug id="1705" opendate="2009-7-25 00:00:00" fixdate="2009-7-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thrift server: deletes in mutateRow/s don&amp;#39;t delete.</summary>
      <description>Simple bugs:In mutateRow we don't check the isDelete flag, it always assumes a put.In mutateRows we don't check if the delete has only the family specified.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="17050" opendate="2016-11-8 00:00:00" fixdate="2016-11-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade Apache CLI version from 1.2 to 1.3.1</summary>
      <description>http://mail-archives.apache.org/mod_mbox/hbase-dev/201611.mbox/%3CCAGHyZ6KNjTH6qnVN%2B%3Dd_rC%3DtkLEjELUCQf9pmqQ-ixJj%2BfbrOA%40mail.gmail.com%3E</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="17052" opendate="2016-11-9 00:00:00" fixdate="2016-11-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>compile-protobuf profile does not compile protobufs in some modules anymore</summary>
      <description>Due to recent changes, we are not compiling the protobuf files in hbase-endpoint, hbase-rsgroup, etc anymore. [INFO] --- protobuf-maven-plugin:0.5.0:compile (compile-protoc) @ hbase-rsgroup ---[INFO] /Users/enis/projects/hbase-sal/hbase-rsgroup/src/main/protobuf/,/Users/enis/projects/hbase-sal/hbase-rsgroup/../hbase-protocol/src/main/protobuf does not exist. Review the configuration or consider disabling the plugin.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-rsgroup.pom.xml</file>
      <file type="M">hbase-protocol-shaded.pom.xml</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.coprocessor.example.generated.BulkDeleteProtos.java</file>
      <file type="M">hbase-examples.pom.xml</file>
      <file type="M">hbase-endpoint.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="17056" opendate="2016-11-9 00:00:00" fixdate="2016-8-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove checked in PB generated files</summary>
      <description>Now that we have the new PB maven plugin, there is no need to have the PB files checked in to the repo. The reason we did that was to ease up developer env setup.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream.java</file>
      <file type="M">hbase-spark.src.main.java.org.apache.hadoop.hbase.spark.protobuf.generated.SparkFilterProtos.java</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.protobuf.generated.RSGroupProtos.java</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.protobuf.generated.RSGroupAdminProtos.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.VersionMessage.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.TableSchemaMessage.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.TableListMessage.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.TableInfoMessage.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.ScannerMessage.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.NamespacesMessage.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.NamespacePropertiesMessage.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.ColumnSchemaMessage.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.CellSetMessage.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.CellMessage.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.WALProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.VisibilityLabelsProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.TracingProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.RPCProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.RowProcessorProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MultiRowMutationProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MapReduceProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.LoadBalancerProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.HFileProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.FSProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.FilterProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ErrorHandlingProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.EncryptionProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ClientProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.CellProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.AuthenticationProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.AdminProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.ipc.protobuf.generated.TestRpcServiceProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.ipc.protobuf.generated.TestProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.ipc.protobuf.generated.TestProcedureProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.coprocessor.protobuf.generated.PingProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.ZooKeeperProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.TracingProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.RegionNormalizerProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.ProcedureProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.LockServiceProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.LoadBalancerProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.HFileProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.FSProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.EncryptionProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterIdProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.BackupProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.AccessControlProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.ipc.protobuf.generated.TestRpcServiceProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.ipc.protobuf.generated.TestProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.ipc.protobuf.generated.TestProcedureProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.WrappersProto.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.WireFormat.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ValueOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Value.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Utf8.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.UnsafeUtil.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.UnsafeByteOperations.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.UnmodifiableLazyStringList.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSetLite.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.UninitializedMessageException.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.UInt64ValueOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.UInt64Value.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.UInt32ValueOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.UInt32Value.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.TypeProto.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.TypeOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Type.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.TimestampProto.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.TimestampOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Timestamp.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.TextFormatParseLocation.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.TextFormatParseInfoTree.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.TextFormatEscaper.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.TextFormat.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Syntax.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.StructProto.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.StructOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Struct.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.StringValueOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.StringValue.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.SourceContextProto.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.SourceContextOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.SourceContext.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.SmallSortedMap.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.SingleFieldBuilderV3.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.SingleFieldBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ServiceException.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Service.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.RpcUtil.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.RpcController.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.RpcChannel.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.RpcCallback.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.RopeByteString.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.RepeatedFieldBuilderV3.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.RepeatedFieldBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ProtocolStringList.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ProtocolMessageEnum.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ProtobufArrayList.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Parser.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.OptionOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Option.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.NullValue.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.NioByteString.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.MutabilityOracle.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.MixinOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Mixin.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.MethodOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Method.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.MessageReflection.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.MessageOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.MessageLiteToString.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.MessageLiteOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.MessageLite.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Message.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.MapFieldLite.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.MapField.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.MapEntryLite.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.MapEntry.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.LongArrayList.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ListValueOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ListValue.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.LazyStringList.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.LazyStringArrayList.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.LazyFieldLite.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.LazyField.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Internal.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.IntArrayList.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Int64ValueOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Int64Value.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Int32ValueOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Int32Value.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageLite.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessage.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.FloatValueOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.FloatValue.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.FloatArrayList.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.FieldSet.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.FieldOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.FieldMaskProto.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.FieldMaskOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.FieldMask.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Field.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryFactory.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistry.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionLite.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Extension.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ExperimentalApi.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.EnumValueOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.EnumValue.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.EnumOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Enum.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.EmptyProto.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.EmptyOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Empty.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.DynamicMessage.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.DurationProto.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.DurationOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Duration.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.DoubleValueOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.DoubleValue.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.DoubleArrayList.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.DescriptorProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.compiler.PluginProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream.java</file>
      <file type="M">hbase-client.pom.xml</file>
      <file type="M">hbase-endpoint.pom.xml</file>
      <file type="M">hbase-endpoint.README.txt</file>
      <file type="M">hbase-examples.pom.xml</file>
      <file type="M">hbase-examples.README.txt</file>
      <file type="M">hbase-procedure.pom.xml</file>
      <file type="M">hbase-protocol-shaded.pom.xml</file>
      <file type="M">hbase-protocol-shaded.README.txt</file>
      <file type="M">hbase-protocol.pom.xml</file>
      <file type="M">hbase-protocol.README.txt</file>
      <file type="M">hbase-rest.pom.xml</file>
      <file type="M">hbase-rest.README.txt</file>
      <file type="M">hbase-rsgroup.pom.xml</file>
      <file type="M">hbase-rsgroup.README.txt</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-spark.pom.xml</file>
      <file type="M">hbase-spark.README.txt</file>
      <file type="M">pom.xml</file>
      <file type="M">src.main.asciidoc..chapters.protobuf.adoc</file>
      <file type="M">hbase-endpoint.src.main.java.org.apache.hadoop.hbase.coprocessor.example.generated.BulkDeleteProtos.java</file>
      <file type="M">hbase-endpoint.src.main.java.org.apache.hadoop.hbase.coprocessor.protobuf.generated.ColumnAggregationProtos.java</file>
      <file type="M">hbase-endpoint.src.main.java.org.apache.hadoop.hbase.coprocessor.protobuf.generated.ColumnAggregationWithErrorsProtos.java</file>
      <file type="M">hbase-endpoint.src.main.java.org.apache.hadoop.hbase.coprocessor.protobuf.generated.ColumnAggregationWithNullResponseProtos.java</file>
      <file type="M">hbase-endpoint.src.main.java.org.apache.hadoop.hbase.coprocessor.protobuf.generated.DummyRegionServerEndpointProtos.java</file>
      <file type="M">hbase-endpoint.src.main.java.org.apache.hadoop.hbase.coprocessor.protobuf.generated.IncrementCounterProcessorTestProtos.java</file>
      <file type="M">hbase-endpoint.src.main.java.org.apache.hadoop.hbase.protobuf.generated.AggregateProtos.java</file>
      <file type="M">hbase-endpoint.src.main.java.org.apache.hadoop.hbase.protobuf.generated.SecureBulkLoadProtos.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.coprocessor.example.generated.ExampleProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.AbstractMessage.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.AbstractMessageLite.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.AbstractParser.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.AbstractProtobufList.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Any.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.AnyOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.AnyProto.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.Api.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ApiOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ApiProto.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.BlockingRpcChannel.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.BlockingService.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.BooleanArrayList.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.BoolValue.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.BoolValueOrBuilder.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteBufferWriter.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteInput.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteInputByteString.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteOutput.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.BytesValue.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.com.google.protobuf.BytesValueOrBuilder.java</file>
    </fixedFiles>
  </bug>
  <bug id="17057" opendate="2016-11-9 00:00:00" fixdate="2016-2-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Minor compactions should also drop page cache behind reads</summary>
      <description>Long compactions currently drop cache behind reads/writes so that they don't pollute the page cache but short compactions don't do that. The bulk of the data is actually read during minor compactions instead of major compactions, and thrashes the page cache since it's mostly not needed. We should drop page cache behind minor compactions too.</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.1,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.Compactor.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="17058" opendate="2016-11-10 00:00:00" fixdate="2016-11-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Lower epsilon used for jitter verification from HBASE-15324</summary>
      <description>The current epsilon used is 1E-6 and its too big it might overflow the desiredMaxFileSize. A trivial fix is to lower the epsilon to 2^-52 or even 2^-53. An option to consider too is just to shift the jitter to always decrement hbase.hregion.max.filesize (MAX_FILESIZE) instead of increase the size of the region and having to deal with the round off.</description>
      <version>1.3.0,1.4.0,1.1.7,1.2.4,2.0.0</version>
      <fixedVersion>1.3.0,1.2.5,1.1.8,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy.java</file>
    </fixedFiles>
  </bug>
  <bug id="17068" opendate="2016-11-10 00:00:00" fixdate="2016-12-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - inherit region locks</summary>
      <description>Add support for inherited region locks. e.g. Split will have Assign/Unassign as child which will take the lock on the same region split is running on</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMasterProcedureScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.java</file>
    </fixedFiles>
  </bug>
  <bug id="17071" opendate="2016-11-11 00:00:00" fixdate="2016-11-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Do not initialize MemstoreChunkPool when use mslab option is turned off</summary>
      <description>This is a 2.0 only issue and induced by HBASE-16407. We are initializing MSLAB chunk pool along with RS start itself now. (To pass it as a HeapMemoryTuneObserver).When MSLAB is turned off (ie. hbase.hregion.memstore.mslab.enabled is configured false) we should not be initializing MSLAB chunk pool at all. By default the initial chunk count to be created will be 0 only. Still better to avoid.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMemStoreChunkPool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompactingMemStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCellFlatSet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SegmentFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreLAB.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreChunkPool.java</file>
    </fixedFiles>
  </bug>
  <bug id="17073" opendate="2016-11-11 00:00:00" fixdate="2016-11-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Increase the max number of buffers in ByteBufferPool</summary>
      <description>Before the HBASE-15525 issue fix, we had variable sized buffers in our buffer pool. The max size upto which one buffer can grow was 2 MB. Now we have changed it to be a fixed sized BBPool. By default 64 KB is the size of each buffer. But the max number of BBs allowed to be in the pool was not changed. ie. twice the number of handlers. May be we should be changing increasing it now? To make it equal to the way like 2 MB, we will need 32 * 2 * handlers. There is no initial #BBs any way. 2 MB is the default max response size what we have. And write reqs also, when it is Buffered mutator 2 MB is the default flush limit. We can make it to be 32 * #handlers as the def max #BBs I believe.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="17074" opendate="2016-11-11 00:00:00" fixdate="2016-11-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>PreCommit job always fails because of OOM</summary>
      <description>https://builds.apache.org/job/PreCommit-HBASE-Build/4434/artifact/patchprocess/patch-unit-hbase-server.txtException in thread "Thread-2369" java.lang.OutOfMemoryError: Java heap space at java.util.Arrays.copyOf(Arrays.java:3332) at java.lang.AbstractStringBuilder.ensureCapacityInternal(AbstractStringBuilder.java:124) at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:596) at java.lang.StringBuffer.append(StringBuffer.java:367) at java.io.BufferedReader.readLine(BufferedReader.java:370) at java.io.BufferedReader.readLine(BufferedReader.java:389) at org.apache.maven.surefire.shade.org.apache.maven.shared.utils.cli.StreamPumper.run(StreamPumper.java:66)Exception in thread "Thread-2357" java.lang.OutOfMemoryError: Java heap spaceException in thread "Thread-2365" java.lang.OutOfMemoryError: Java heap spaceRunning org.apache.hadoop.hbase.filter.TestFuzzyRowFilterEndToEndRunning org.apache.hadoop.hbase.filter.TestFilterListOrOperatorWithBlkCntException in thread "Thread-2383" java.lang.OutOfMemoryError: Java heap spaceException in thread "Thread-2397" java.lang.OutOfMemoryError: Java heap spaceException in thread "Thread-2401" java.lang.OutOfMemoryError: Java heap spaceRunning org.apache.hadoop.hbase.TestHBaseTestingUtilityException in thread "Thread-2407" java.lang.OutOfMemoryError: Java heap spaceException in thread "Thread-2411" java.lang.OutOfMemoryError: Java heap spaceException in thread "Thread-2413" java.lang.OutOfMemoryError: Java heap spaceThe OOM happens in the surefire plugin when reading the stdout or stderr of the running test...</description>
      <version>1.3.0,1.4.0,1.1.7,0.98.23,1.2.4,2.0.0</version>
      <fixedVersion>1.3.0,1.2.5,0.98.24,1.1.8,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.docker.Dockerfile</file>
    </fixedFiles>
  </bug>
  <bug id="17077" opendate="2016-11-12 00:00:00" fixdate="2016-11-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Don&amp;#39;t copy the replication queue belonging to the peer which has been deleted</summary>
      <description>When a region server is dead, then other live region servers will transfer the dead rs's replication queue to their own queue. Now the live rs first copy the wals queue to its own znode, then create a new replication source to replicate the wals. But if the queue belong to a peer has been deleted, it copy the queue, too. The current steps is:1. copy the queue to its own znode2. found the queue belong to a peer has been deleted3. remove the queue and don't create a new replication source for itThere is a small improvement. The live region server doesn't need to copy the queue to its own znode. The new steps is:1. found the queue belong to a peer has been deleted2. remove the queue directly instead of copy it</description>
      <version>None</version>
      <fixedVersion>1.4.0,0.98.24,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueuesZKImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="17079" opendate="2016-11-12 00:00:00" fixdate="2016-1-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase build fails on windows, hbase-archetype-builder is reason for failure</summary>
      <description>HBase buid fails on windows, hbase-archetype-builder is reason for failure. Cygwin is installed so the shell scripts should execute successfully.Here is build failure log[INFO] Apache HBase - Archetype builder ................... FAILURE [ 1.014 s][INFO] ------------------------------------------------------------------------[INFO] BUILD FAILURE[INFO] ------------------------------------------------------------------------[INFO] Total time: 06:13 min[INFO] Finished at: 2016-11-12T18:12:26+05:30[INFO] Final Memory: 235M/1012M[INFO] ------------------------------------------------------------------------[ERROR] Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.4.0:exec (make-scripts-executable) on project hbase-archetype-builder: Command execution failed. Process exited with an error: 1 (Exit value: 1) -&gt; [Help 1][ERROR][ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.[ERROR] Re-run Maven using the -X switch to enable full debug logging.[ERROR][ERROR] For more information about the errors and possible solutions, please read the following articles:[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException[ERROR][ERROR] After correcting the problems, you can resume the build with the command[ERROR] mvn &lt;goals&gt; -rf :hbase-archetype-builder</description>
      <version>None</version>
      <fixedVersion>1.3.2,1.4.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-archetypes.hbase-archetype-builder.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="17082" opendate="2016-11-12 00:00:00" fixdate="2016-11-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ForeignExceptionUtil isn’t packaged when building shaded protocol with -Pcompile-protobuf</summary>
      <description>The source folder will be replaced from src/main/java to project.build.directory/protoc-generated-sources when building shaded protocol with -Pcompile-protobuf, but we do not copy the ForeignExceptionUtil. So the final jar lacks the ForeignExceptionUtil and it causes the test error for hbase-client and hbase-server.[ERROR] /testptch/hbase/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java:[169,36] cannot find symbol symbol: class ForeignExceptionUtil location: package org.apache.hadoop.hbase.util[ERROR] /testptch/hbase/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterRpcServices.java:[100,36] cannot find symbol symbol: class ForeignExceptionUtil location: package org.apache.hadoop.hbase.util[ERROR] /testptch/hbase/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java:[2144,17] cannot find symbol symbol: variable ForeignExceptionUtil location: class org.apache.hadoop.hbase.regionserver.HRegionServer[ERROR] /testptch/hbase/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterRpcServices.java:[938,32] cannot find symbol symbol: variable ForeignExceptionUtil location: class org.apache.hadoop.hbase.master.MasterRpcServicesThis bug blocks the patches which are against the hbase-protocol-shaded module.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-protocol-shaded.README.txt</file>
      <file type="M">hbase-protocol-shaded.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="17089" opendate="2016-11-14 00:00:00" fixdate="2016-11-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add doc on experience running with hedged reads</summary>
      <description>Add to the refguide carp84's useful experience running with hedged reads.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.protobuf.adoc</file>
      <file type="M">src.main.asciidoc..chapters.performance.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="1709" opendate="2009-7-27 00:00:00" fixdate="2009-7-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thrift getRowWithColumns doesn&amp;#39;t accept column-family only</summary>
      <description>In HBase 0.19, it was possible to give just a column-family name to getRowWithColumns and it would include all columns of that family in the result.In 0.20-r798074, this does not work anymore.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.Get.java</file>
    </fixedFiles>
  </bug>
  <bug id="17090" opendate="2016-11-14 00:00:00" fixdate="2016-12-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - fast wake if nothing else is running</summary>
      <description>We wait Nmsec to see if we can batch more procedures, but the pattern that we have allows us to wait only for what we know is running and avoid waiting for something that will never get there.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.pom.xml</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALPerformanceEvaluation.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.ProcedureStore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.NoopProcedureStore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureExecutor.java</file>
    </fixedFiles>
  </bug>
  <bug id="17114" opendate="2016-11-16 00:00:00" fixdate="2016-12-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add an option to set special retry pause when encountering CallQueueTooBigException</summary>
      <description>As titled, after HBASE-15146 we will throw CallQueueTooBigException instead of dead-wait. This is good for performance for most cases but might cause a side-effect that if too many clients connect to the busy RS, that the retry requests may come over and over again and RS never got the chance for recovering, and the issue will become especially critical when the target region is META.So here in this JIRA we propose to add a new property in name of hbase.client.pause.cqtbe to make it possible to set a special-longer pause for CallQueueTooBigException, and by default it will use the setting of hbase.client.pause</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestAsyncProcess.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCallerFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRequestFutureImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
    </fixedFiles>
  </bug>
  <bug id="17142" opendate="2016-11-21 00:00:00" fixdate="2016-12-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement multi get</summary>
      <description></description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncTableImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableBase.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncSingleRequestRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRpcRetryingCallerFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="17144" opendate="2016-11-21 00:00:00" fixdate="2016-11-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Possible offheap read ByteBuffers leak</summary>
      <description>At HBASE-15788 we reuse off heap read BBs, the CallCleanup will not called in some circumstances for example CALL_QUEUE_TOO_BIG_EXCEPTION and readParamsFailedCall.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="17149" opendate="2016-11-21 00:00:00" fixdate="2016-12-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure V2 - Fix nonce submission to avoid unnecessary calling coprocessor multiple times</summary>
      <description>instead of having all the logic in submitProcedure(), split in registerNonce() + submitProcedure().In this case we can avoid calling the coprocessor twice and having a clean submit logic knowing that there will only be one submission.</description>
      <version>1.3.0,1.4.0,1.1.7,1.2.4,2.0.0</version>
      <fixedVersion>1.3.0,1.2.5,1.1.9,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestCoprocessorWhitelistMasterObserver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestSplitTableRegionProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestProcedureAdmin.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestModifyTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestModifyColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMasterProcedureEvents.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestEnableTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestDispatchMergingRegionsProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestDisableTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestDeleteTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestCreateTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestAddColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableNamespaceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ClusterSchemaServiceImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ClusterSchema.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.TestProcedureRecovery.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.ProcedureTestingUtility.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureExecutor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestTruncateTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestTableDDLProcedureBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestRestoreSnapshotProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestModifyNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMergeTableRegionsProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestDeleteNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestDeleteColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestCreateNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestCloneSnapshotProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="17157" opendate="2016-11-22 00:00:00" fixdate="2016-11-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Increase the default mergeable threshold for mob compaction</summary>
      <description>Now the default mergeable threshold for mob compaction is 192MB, we need to increase this value.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.MobConstants.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="17160" opendate="2016-11-22 00:00:00" fixdate="2016-11-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Undo unnecessary inter-module dependency; spark to hbase-it and hbase-it to shell</summary>
      <description>Very minor untangling.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.pom.xml</file>
      <file type="M">hbase-it.pom.xml</file>
      <file type="M">hbase-shell.pom.xml</file>
      <file type="M">hbase-prefix-tree.pom.xml</file>
      <file type="M">hbase-endpoint.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="17162" opendate="2016-11-22 00:00:00" fixdate="2016-11-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Avoid unconditional call to getXXXArray() in write path</summary>
      <description>Still some calls left. Patch will address these areas.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MutableSegment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileWriterImpl.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Increment.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Delete.java</file>
    </fixedFiles>
  </bug>
  <bug id="17166" opendate="2016-11-23 00:00:00" fixdate="2016-11-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ITBLL fails on master unable to find hbase-protocol-shaded content</summary>
      <description>From an internal rig found by jmhsieh running generator step:16/11/22 16:51:17 INFO mapreduce.Job: Task Id : attempt_1479833370377_0002_m_000000_0, Status : FAILEDError: java.lang.ClassNotFoundException: org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProtos$MasterService$BlockingInterface at java.net.URLClassLoader.findClass(URLClassLoader.java:381) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at java.lang.Class.forName0(Native Method) at java.lang.Class.forName(Class.java:264) at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:225) at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:122) at org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList$Generator$GeneratorMapper.setup(IntegrationTestBigLinkedList.java:425) at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143) at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787) at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341) at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:175) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:422) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1790) at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:169)</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="17167" opendate="2016-11-23 00:00:00" fixdate="2016-11-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Pass mvcc to client when scan</summary>
      <description>For the current implementation, if we use batch or allowPartial when scan, then the row level atomic can not be guaranteed if we need to restart a scan in the middle of a record due to region move or something else.We can return the mvcc used to open scanner to client and client could use this mvcc to restart a scan to get row level atomic.</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestPartialResultsFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSink.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestTags.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Client.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ClientProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.Client.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="17169" opendate="2016-11-23 00:00:00" fixdate="2016-11-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove Cell variants with ShareableMemory</summary>
      <description>As asked by Stack in review comment of other sub tasks of the parent.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.AbstractMemStore.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.OffheapKeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.NoTagsKeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ExtendedCell.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.KeyValueCodecWithTags.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.KeyValueCodec.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="17172" opendate="2016-11-23 00:00:00" fixdate="2016-2-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Optimize mob compaction with _del files</summary>
      <description>Today, when there is a _del file in mobdir, with major mob compaction, every mob file will be recompacted, this causes lots of IO and slow down major mob compaction (may take months to finish). This needs to be improved. A few ideas are: 1) Do not compact all _del files into one, instead, compact them based on groups with startKey as the key. Then use firstKey/startKey to make each mob file to see if the _del file needs to be included for this partition.2). Based on the timerange of the _del file, compaction for files after that timerange does not need to include the _del file as these are newer files.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mob.compactions.TestPartitionedMobCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.compactions.PartitionedMobCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.compactions.PartitionedMobCompactionRequest.java</file>
    </fixedFiles>
  </bug>
  <bug id="17178" opendate="2016-11-28 00:00:00" fixdate="2016-11-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add region balance throttling</summary>
      <description>Our online cluster serves dozens of tables and different tables serve for different services. If the balancer moves too many regions in the same time, it will decrease the availability for some table or some services. So we add region balance throttling on our online serve cluster. We introduce a new config hbase.balancer.max.balancing.regions, which means the max number of regions in transition when balancing.If we config this to 1 and a table have 100 regions, then the table will have 99 regions available at any time. It helps a lot for our use case and it has been running a long timeour production cluster.But for some use case, we need the balancer run faster. If a cluster has 100 regionservers, then it add 50 new regionservers for peak requests. Then it need balancer run as soon aspossible and let the cluster reach a balance state soon. Our idea is compute max number of regions in transition by the max balancing time and the average time of region in transition.Then the balancer use the computed value to throttling.Examples for understanding.A cluster has 100 regionservers, each regionserver has 200 regions and the average time of region in transition is 1 seconds, we config the max balancing time is 10 * 60 seconds.Case 1. One regionserver crash, the cluster at most need balance 200 regions. Then 200 / (10 * 60s / 1s) &lt; 1, it means the max number of regions in transition is 1 when balancing. Then the balancer can move region one by one and the cluster will have high availability when balancing.Case 2. Add other 100 regionservers, the cluster at most need balance 10000 regions. Then 10000 / (10 * 60s / 1s) = 16.7, it means the max number of regions in transition is 17 when balancing. Then the cluster can reach a balance state within the max balancing time.Any suggestions are welcomed.Review board: https://reviews.apache.org/r/54191/</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BalancerChore.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="17181" opendate="2016-11-28 00:00:00" fixdate="2016-12-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Let HBase thrift2 support TThreadedSelectorServer</summary>
      <description>Add TThreadedSelectorServer for HBase Thrift2</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="17183" opendate="2016-11-28 00:00:00" fixdate="2016-11-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Handle ByteBufferCell while making TagRewriteCell</summary>
      <description>TagRewriteCell is the normal ExtendedCell. When it wraps a ByteBufferCell, we need a new TagRewriteCell type of type ByteBufferCell.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="17191" opendate="2016-11-29 00:00:00" fixdate="2016-12-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make use of UnsafeByteOperations#unsafeWrap(ByteBuffer buffer) in PBUtil#toCell(Cell cell)</summary>
      <description>Since we now have support for BBs in UnsafeByteOperations#unsafeWrap(ByteBuffer) . So for the non - java clients while creating the PB result we could avoid the copy to an temp array. Since we have a support to write to BB in ByteOutput having a result backed by Bytebuffer should be fine.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.protobuf.TestProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="17194" opendate="2016-11-29 00:00:00" fixdate="2016-12-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Assign the new region to the idle server after splitting</summary>
      <description>The new regions are assigned to the random servers after splitting, but there always are some idle servers which don’t be assigned any regions on the new cluster. It is a bad start of load balance, hence we should give priority to the idle servers for assignment.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestBaseLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
    </fixedFiles>
  </bug>
  <bug id="17197" opendate="2016-11-29 00:00:00" fixdate="2016-2-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hfile does not work in 2.0</summary>
      <description>I tried to use hfile in master branch, it does not print out kv pairs or meta as it is supposed to be.hsun-MBP:hbase-2.0.0-SNAPSHOT hsun$ hbase hfile file:///Users/hsun/work/local-hbase-cluster/data/data/default/t1/755b5d7a44148492b7138c79c5e4f39f/f1/53e9f9bc328f468b87831221de3a0c74 bdc6e1c4eea246a99e989e02d554cb03 bf9275ac418d4d458904d81137e82683 hsun-MBP:hbase-2.0.0-SNAPSHOT hsun$ hbase hfile file:///Users/hsun/work/local-hbase-cluster/data/data/default/t1/755b5d7a44148492b7138c79c5e4f39f/f1/bf9275ac418d4d458904d81137e82683 -m2016-11-29 12:25:22,019 WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicablehsun-MBP:hbase-2.0.0-SNAPSHOT hsun$ hbase hfile file:///Users/hsun/work/local-hbase-cluster/data/data/default/t1/755b5d7a44148492b7138c79c5e4f39f/f1/bf9275ac418d4d458904d81137e82683 -p2016-11-29 12:25:27,333 WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicableScanned kv count -&gt; 0</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter.java</file>
    </fixedFiles>
  </bug>
  <bug id="17198" opendate="2016-11-29 00:00:00" fixdate="2016-1-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>FN updates during region merge (follow up to Procedure v2 merge)</summary>
      <description>As mentioned in https://reviews.apache.org/r/53242/ (HBASE-16941), since the procedure v2 merge changes are in development, there is a follow up optimization/cleanup that can be done for favored nodes during merge. This jira will be taken up once HBASE-16119 is complete.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="17207" opendate="2016-11-30 00:00:00" fixdate="2016-12-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Arrays.asList() with too few arguments</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStateStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RackManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputSaslHelper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FilterList.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MultiAction.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.BufferedMutatorImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="17210" opendate="2016-11-30 00:00:00" fixdate="2016-2-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Set timeout on trying rowlock according to client&amp;#39;s RPC timeout</summary>
      <description>Now when we want to get a row lock, the timeout is fixed and default is 30s. But the requests from client have different RPC timeout setting. We can use the client's deadline to set timeout on tryLock.</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="17216" opendate="2016-11-30 00:00:00" fixdate="2016-12-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>A Few Fields Can Be Safely Made Static</summary>
      <description>Automated Test...</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.HFileReplicator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALEdit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutput.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.FastDiffDeltaEncoder.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
    </fixedFiles>
  </bug>
  <bug id="17224" opendate="2016-12-1 00:00:00" fixdate="2016-12-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>There are lots of spelling errors in the HBase logging and exception messages</summary>
      <description>Found a bunch of spelling errors in log messages and exception messages such as "Stoping" instead of "Stopping", "alligned" instead of "aligned".</description>
      <version>None</version>
      <fixedVersion>1.3.0,0.98.24,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ZNodeClearer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.hbck.HFileCorruptionChecker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.AuthenticationTokenSecretManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.TableAuthManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.HFileReplicator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransactionImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HeapMemoryManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.WALSplitterHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactedHFilesDischarger.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureMemberRpcs.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionPlacementMaintainer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.SplitTableRegionProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DispatchMergingRegionsProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterMobCompactionThread.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.FavoredNodeAssignmentHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentVerificationReport.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HDFSBlocksDistribution.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.BoundedByteBufferPool.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeerZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.replication.ReplicationAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="17235" opendate="2016-12-2 00:00:00" fixdate="2016-12-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improvement in creation of CIS for onheap buffer cases</summary>
      <description>if (buf.hasArray()) { cis = CodedInputStream.newInstance(buf.array(), offset, buf.limit()); } else {Currently we do this for onheap buffers incase there is no reservoir or the size is less than the minSizeforReservoir. I could see that even if reservoir is there there are requests which goes with the above way of creating CIS. This could be made efficient to avoid underlying copies by just doing thiscis = UnsafeByteOperations.unsafeWrap(buf.array(), offset, buf.limit()).newCodedInput();</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="17241" opendate="2016-12-2 00:00:00" fixdate="2016-12-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Avoid compacting already compacted mob files with _del files</summary>
      <description>Today if there is only one file in the partition, and there is no _del files, the file is skipped. With del file, the current logic is to compact the already-compacted file with _del file. Let's say there is one mob file regionA20161101**, which was compacted. On 12/1/2016, there is _del file regionB20161201_del, mob compaction kicks in, regionA20161101** is less than the threshold, and it is picked for compaction. Since there is a _del file, regionA20161101**** and regionB20161201**_del are compacted into regionA20161101_1 . After that, regionB20161201_del cannot be deleted since it is not a allFile compaction. The next mob compaction, regionA20161101_1 and regionB20161201_del will be picked up again and be compacted into regionA20161101**_2. So in this case, it will cause more unnecessary IOs.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mob.compactions.TestPartitionedMobCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.compactions.PartitionedMobCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.compactions.PartitionedMobCompactionRequest.java</file>
    </fixedFiles>
  </bug>
  <bug id="17246" opendate="2016-12-2 00:00:00" fixdate="2016-12-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestSerialReplication#testRegionMerge fails in master branch</summary>
      <description>TestSerialReplication#testRegionMerge fails intermittently in master branch.testRegionMerge(org.apache.hadoop.hbase.replication.TestSerialReplication) Time elapsed: 15.193 sec &lt;&lt;&lt; FAILURE!java.lang.AssertionError: expected:&lt;9&gt; but was:&lt;4&gt; at org.apache.hadoop.hbase.replication.TestSerialReplication.testRegionMerge(TestSerialReplication.java:305)I can reproduce the test failure locally.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MetaTableAccessor.java</file>
    </fixedFiles>
  </bug>
  <bug id="17251" opendate="2016-12-4 00:00:00" fixdate="2016-12-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a timeout parameter when locating region</summary>
      <description>Now we always use the default timeout configured for zk and meta.I think it is reasonable to always use the same timeout when accessing zk and meta as the result will be shared by lots of threads. If we could do a successful fetching then the result will be in cache so it does not make sense to set the timeout to a very small value when fetching.But I think it is also important to let the user request finish in time even if the user can only get a timeout exception. We should not block a user request longer than operation timeout.So I think we could add a timeout parameter to the region locate method, and if the location can not be fetched in time, we will just finished the returned CompletableFuture with a timeout exception, but the actual fetching operation can still go on and use its own timeout config.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncSingleRequestRpcRetryingCaller.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncRegionLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableRegionLocatorImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncSingleRequestRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRegionLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncConnectionImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="17256" opendate="2016-12-5 00:00:00" fixdate="2016-12-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Rpc handler monitoring will be removed when the task queue is full</summary>
      <description>The RPC handlers monitoring will displayed in the Web UI when the cluster has just started. As time goes on, RPC handlers disappeared .We have the RPC handlers listed as tasks and stored in CircularFifoBuffer. CircularFifoBuffer is a first in first out buffer with a fixed size that replaces its oldest element if full.When we refresh the page, completed tasks will be removed from CircularFifoBuffer.Not refresh the page for a long time, the oldest element (RPC handlers) will be replaced by new tasks.</description>
      <version>0.98.23,1.2.4,2.0.0</version>
      <fixedVersion>1.4.0,0.98.24,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.TaskMonitor.java</file>
    </fixedFiles>
  </bug>
  <bug id="17259" opendate="2016-12-5 00:00:00" fixdate="2016-2-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Missing functionality to remove space quota</summary>
      <description>I'm noticing that while I have create and update APIs for quotas, I missed the remove functionality.Need to add public API for that and some tests.</description>
      <version>None</version>
      <fixedVersion>HBASE-16961,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestQuotaAdmin.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.MasterQuotaManager.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Quota.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.Quota.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.quotas.TestQuotaSettingsFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.SpaceLimitSettings.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaTableUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaSettingsFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="17263" opendate="2016-12-6 00:00:00" fixdate="2016-5-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Netty based rpc server impl</summary>
      <description>An RPC server with Netty4 implementation, which provide better performance.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.token.TestTokenAuthentication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.TestSecureIPC.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestRpcHandlerException.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestProtoBufRpc.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.AbstractTestIPC.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.BufferChain.java</file>
    </fixedFiles>
  </bug>
  <bug id="1727" opendate="2009-7-30 00:00:00" fixdate="2009-8-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HTD and HCD versions need update</summary>
      <description>HCD is at version 7 but there's no comment as to why.There is a fixme in HTD indicating the version should be bumped to 5 after indexes have been removed. Indexes have been removed, but the version is still at 4.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="17271" opendate="2016-12-7 00:00:00" fixdate="2016-1-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase-thrift QA tests only run one test</summary>
      <description>From https://builds.apache.org/job/PreCommit-HBASE-Build/4822/artifact/patchprocess/patch-unit-hbase-thrift.txt , it is pretty clear that only one test was run - TestCallQueueEven though the patch contains modified TestThriftHBaseServiceHandler.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="17281" opendate="2016-12-9 00:00:00" fixdate="2016-2-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>FN should use datanode port from hdfs configuration</summary>
      <description>Currently we use the ServerName port for providing favored node hints. We should use the DN port from hdfs-site.xml instead to avoid warning messages in region server logs. The warnings will be from this section of HDFS code, it moves across classes.https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java#L1758 private boolean[] getPinnings(DatanodeInfo[] nodes) { if (favoredNodes == null) { return null; } else { boolean[] pinnings = new boolean[nodes.length]; HashSet&lt;String&gt; favoredSet = new HashSet&lt;&gt;(Arrays.asList(favoredNodes)); for (int i = 0; i &lt; nodes.length; i++) { pinnings[i] = favoredSet.remove(nodes[i].getXferAddrWithHostname()); LOG.debug("{} was chosen by name node (favored={}).", nodes[i].getXferAddrWithHostname(), pinnings[i]); } if (!favoredSet.isEmpty()) { // There is one or more favored nodes that were not allocated. LOG.warn("These favored nodes were specified but not chosen: " + favoredSet + " Specified favored nodes: " + Arrays.toString(favoredNodes)); } return pinnings; } }</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestTableFavoredNodes.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.favored.FavoredNodesManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="17282" opendate="2016-12-9 00:00:00" fixdate="2016-12-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reduce the redundant requests to meta table</summary>
      <description>This usually happens at startup when the meta cache is empty. There will be a lot of locating requests, but most of will have same results. Things become worse if we do batch operations with AsyncTable as we will send a locating request for each operation concurrently.We need to reduce the redundant requests to meta table.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTableNoncedRetry.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncRegionLocatorTimeout.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncRegionLocator.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncGetMultiThread.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRegionLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncConnectionImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="17286" opendate="2016-12-10 00:00:00" fixdate="2016-5-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LICENSE.txt in binary tarball contains only ASL text</summary>
      <description>Noticed this one today because I needed to make sure LICENSE was getting updated for a patch-in-progress.What I'm presently seeing after invoking mvn clean package assembly:single -DskipTests -Drat.skip -Prelease on master is that the LICENSE.txt file contains only the ASL text (which I know for certain it should contain BSD and MIT as well).I checked branch-1.2 which has lots of extra greatness, so it seems like something happened in master which broke this. Filing this now so we can try to bisect and figure out what happened.FYI, this is the one I was chatting you about busbey.</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shaded.pom.xml</file>
      <file type="M">hbase-assembly.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="17287" opendate="2016-12-10 00:00:00" fixdate="2016-3-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Master becomes a zombie if filesystem object closes</summary>
      <description>We have seen an issue whereby if the HDFS is unstable and the HBase master's HDFS client is unable to stabilize before dfs.client.failover.max.attempts then the master's filesystem object closes. This seems to result in an HBase master which will continue to run (process and znode exists) but no meaningful work can be done (e.g. assigning meta).What we saw in our HBase master logs was:2016-12-01 19:19:08,192 ERROR org.apache.hadoop.hbase.master.handler.MetaServerShutdownHandler: Caught M_META_SERVER_SHUTDOWN, count=1java.io.IOException: failed log splitting for cluster-r5n12.bloomberg.com,60200,1480632863218, will retryat org.apache.hadoop.hbase.master.handler.MetaServerShutdownHandler.process(MetaServerShutdownHandler.java:84)at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:129)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)at java.lang.Thread.run(Thread.java:745)Caused by: java.io.IOException: Filesystem closed</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.1,1.1.10,1.2.6,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterWalManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="17292" opendate="2016-12-12 00:00:00" fixdate="2016-12-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add observer notification before bulk loaded hfile is moved to region directory</summary>
      <description>Currently the postBulkLoadHFile() hook notifies the locations of bulk loaded hfiles.However, if bulk load fails after hfile is moved to region directory but before postBulkLoadHFile() hook is called, there is no way for pluggable components (replication - see HBASE-17290, backup / restore) to know which hfile(s) have been moved to region directory.Even if postBulkLoadHFile() is called in finally block, the write (to backup table or zookeeper) issued from postBulkLoadHFile() may fail, ending up with same situation.This issue adds a preCommitStoreFile() hook which notifies path of to be committed hfile before bulk loaded hfile is moved to region directory.With preCommitStoreFile() hook, write (to backup table or zookeeper) can be issued before the movement of hfile.If write fails, IOException would make bulk load fail, not leaving hfile in region directory.</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SecureBulkLoadManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.java</file>
    </fixedFiles>
  </bug>
  <bug id="17294" opendate="2016-12-12 00:00:00" fixdate="2016-12-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>External Configuration for Memory Compaction</summary>
      <description>We would like to have a single external knob to control memstore compaction.Possible memstore compaction policies are none, basic, and eager.This sub-task allows to set this property at the column family level at table creation time:create ‘&lt;tablename&gt;’, {NAME =&gt; ‘&lt;cfname&gt;’, IN_MEMORY_COMPACTION =&gt; ‘&lt;NONE|BASIC|EAGER&gt;’}or to set this at the global configuration level by setting the property in hbase-site.xml, with BASIC being the default value:&lt;property&gt; &lt;name&gt;hbase.hregion.compacting.memstore.type&lt;/name&gt; &lt;value&gt;&lt;NONE|BASIC|EAGER&gt;&lt;/value&gt;&lt;/property&gt;The values used in this property can change as memstore compaction policies evolve over time.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestIOFencing.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestAcidGuarantees.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestFlushSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRolling.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestAsyncLogRolling.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.AbstractTestWALReplay.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.AbstractTestLogRolling.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestWalAndCompactingMemStoreFlush.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRecoveredEdits.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestPerColumnFamilyFlush.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMajorCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompactingToCellArrayMapMemStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompactingMemStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestTableLockManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMasterProcedureSchedulerConcurrency.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotCloneIndependence.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMobSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestHFileArchiving.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactingMemStore.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="1730" opendate="2009-7-31 00:00:00" fixdate="2009-9-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Near-instantaneous online schema and table state updates</summary>
      <description>We should not need to take a table offline to update HCD or HTD. One option for that is putting HTDs and HCDs up into ZK, with mirror on disk catalog tables to be used only for cold init scenarios, as discussed on IRC. In this scheme, regionservers hosting regions of a table would watch permanent nodes in ZK associated with that table for schema updates and take appropriate actions out of the watcher. In effect, schema updates become another item in the ToDo list./hbase/tables/&lt;table-name&gt;/schemaMust be associated with a write locking scheme also handled with ZK primitives to avoid situations where one concurrent update clobbers another.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
      <file type="M">src.main.ruby.shell.commands.alter.rb</file>
      <file type="M">src.main.ruby.shell.rb</file>
      <file type="M">src.main.ruby.hbase.admin.rb</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.TableEventHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.TableAddFamilyHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.ClosedRegionHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HMasterInterface.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.executor.EventHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="17314" opendate="2016-12-14 00:00:00" fixdate="2016-12-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Limit total buffered size for all replication sources</summary>
      <description>If we have many peers or some servers have many recovered queues, we will hold many entries in memory which will increase the pressure of GC, even maybe OOM because we will read entries for 64MB to buffer in default for one source.</description>
      <version>None</version>
      <fixedVersion>1.5.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestGlobalThrottler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationSource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="17316" opendate="2016-12-14 00:00:00" fixdate="2016-12-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Addendum to HBASE-17294, &amp;#39;External Configuration for Memory Compaction&amp;#39;</summary>
      <description>Updating 2 tests that failed during the commit of HBASE-17294</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotFromClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="17318" opendate="2016-12-14 00:00:00" fixdate="2016-12-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Increment does not add new column if the increment amount is zero at first time writing</summary>
      <description>When the data written for the first time is 0, no new columns are added.Iterate the input columns and update existing values if they were found, otherwise add new column initialized to the increment amount.Does not add new column if the increment amount is zero at first time writting.It is necessary to add a new column at the first write to 0. If not, the result of using the phoenix is NULL.</description>
      <version>0.98.23,1.2.4,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestDurability.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestIncrementsFromClientSide.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="17320" opendate="2016-12-15 00:00:00" fixdate="2016-12-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add inclusive/exclusive support for startRow and endRow of scan</summary>
      <description>This is especially useful when doing reverse scan. HBASE-17168 maybe a more powerful solution but we need to be careful about the atomicity, and I do not think we will provide the feature to end user. But I think it is OK to provide inclusive/exclusive option to end user.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStripeStoreFileManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestRawAsyncTableScan.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.AbstractTestAsyncTableScan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StripeStoreFileManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ReversedRegionScannerImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.UserScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.RawScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.NormalUserScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.LegacyScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.CompactionScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultStoreFileManager.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Client.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ClientProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.Client.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.TimeRange.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableResultScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncSmallScanRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncScanSingleRegionRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRpcRetryingCallerFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncClientScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="17328" opendate="2016-12-16 00:00:00" fixdate="2016-12-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Properly dispose of looped replication peers</summary>
      <description>When adding a looped replication peer (clusterId == peerClusterId), the following code terminates the replication source thread, but since the source manager still holds a reference, WALs continue to get enqueued, and never get cleaned because they're stuck in the queue, leading to an unsustainable buildup. Furthermore, the replication statistics thread will continue to print statistics for the terminated source.if (clusterId.equals(peerClusterId) &amp;&amp; !replicationEndpoint.canReplicateToSameCluster()) { this.terminate("ClusterId " + clusterId + " is replicating to itself: peerClusterId " + peerClusterId + " which is not allowed by ReplicationEndpoint:" + replicationEndpoint.getClass().getName(), null, false); }</description>
      <version>1.3.0,1.4.0,0.98.23,2.0.0</version>
      <fixedVersion>1.3.0,1.2.5,0.98.24,1.1.9,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestMasterReplication.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="17333" opendate="2016-12-19 00:00:00" fixdate="2016-12-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBASE-17294 always ensures CompactingMemstore is default</summary>
      <description>Was the purpose of HBASE-17294 is to make Compacting Memstore as default? Am not sure on that. But that patch makes DefaultMemstore as a Noop. This JIRA is to discuss and revert back to default memstore only if the family is not configured for in memory flush/compaction.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactingMemStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="17335" opendate="2016-12-19 00:00:00" fixdate="2016-12-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>enable/disable replication peer requests should be routed through master</summary>
      <description>As HBASE-11392 description says, we should move replication operations to be routed through master.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.appendix.acl.matrix.adoc</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockNoopMasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.ReplicationManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MasterObserver.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.Replication.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.Master.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.replication.ReplicationAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
    </fixedFiles>
  </bug>
  <bug id="17336" opendate="2016-12-19 00:00:00" fixdate="2016-12-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>get/update replication peer config requests should be routed through master</summary>
      <description>As HBASE-11392 description says, we should move replication operations to be routed through master.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.appendix.acl.matrix.adoc</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.replication.admin.rb</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestRegionReplicaReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockNoopMasterServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.replication.TestReplicationAdmin.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ServerRegionReplicaUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.ReplicationManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MasterObserver.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.Replication.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.Master.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.replication.ReplicationAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
    </fixedFiles>
  </bug>
  <bug id="17337" opendate="2016-12-19 00:00:00" fixdate="2016-1-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>list replication peers request should be routed through master</summary>
      <description></description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.appendix.acl.matrix.adoc</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockNoopMasterServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.replication.TestReplicationAdmin.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.ReplicationManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MasterObserver.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.Replication.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.Master.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.replication.ReplicationSerDeHelper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.replication.ReplicationAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
    </fixedFiles>
  </bug>
  <bug id="17338" opendate="2016-12-19 00:00:00" fixdate="2016-3-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Treat Cell data size under global memstore heap size only when that Cell can not be copied to MSLAB</summary>
      <description>We have only data size and heap overhead being tracked globally. Off heap memstore works with off heap backed MSLAB pool. But a cell, when added to memstore, not always getting copied to MSLAB. Append/Increment ops doing an upsert, dont use MSLAB. Also based on the Cell size, we sometimes avoid MSLAB copy. But now we track these cell data size also under the global memstore data size which indicated off heap size in case of off heap memstore. For global checks for flushes (against lower/upper watermark levels), we check this size against max off heap memstore size. We do check heap overhead against global heap memstore size (Defaults to 40% of xmx) But for such cells the data size also should be accounted under the heap overhead.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestWalAndCompactingMemStoreFlush.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestPerColumnFamilyFlush.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHeapMemoryManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDefaultMemStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompactingToCellArrayMapMemStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompactingMemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Segment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerAccounting.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MutableSegment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreSnapshot.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemstoreSize.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ImmutableSegment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HeapMemoryManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultMemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompositeImmutableSegment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactionPipeline.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactingMemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.AbstractMemStore.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.SizeCachedKeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.IndividualBytesFieldCell.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ExtendedCell.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ByteBufferKeyValue.java</file>
    </fixedFiles>
  </bug>
  <bug id="17343" opendate="2016-12-20 00:00:00" fixdate="2016-5-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make Compacting Memstore default in 2.0 with BASIC as the default type</summary>
      <description>FYI anastas, eshcar and ebortnik.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactingMemStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="17345" opendate="2016-12-20 00:00:00" fixdate="2016-12-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement batch</summary>
      <description>Add the support for general batch based on the code introduced in HBASE-17142.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTableMultiGet.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncGetMultiThread.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.AbstractTestAsyncTableScan.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncTableImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableBase.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncSingleRequestRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncScanSingleRegionRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRpcRetryingCallerFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncMultiGetRpcRetryingCaller.java</file>
    </fixedFiles>
  </bug>
  <bug id="17346" opendate="2016-12-20 00:00:00" fixdate="2016-1-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add coprocessor service support</summary>
      <description>I think we need to redesign the API.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-endpoint.src.main.java.org.apache.hadoop.hbase.coprocessor.AggregateImplementation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncTableImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncTable.java</file>
      <file type="M">hbase-endpoint.src.main.java.org.apache.hadoop.hbase.client.coprocessor.AggregationClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="17349" opendate="2016-12-20 00:00:00" fixdate="2016-2-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add doc for regionserver group-based assignment</summary>
      <description>Currently, this feature has no doc. I tried to use it last night and it took reading unit tests to figure how to get it going and how to use it. I added a bit to the release notes in the parent.Marking as a critical on 2.0.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="17352" opendate="2016-12-21 00:00:00" fixdate="2016-5-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix hbase-assembly build with bash 4</summary>
      <description>hbase-assembly fails to build with bash 4.[DEBUG] Executing command line: [env, bash, -c, cat maven-shared-archive-resources/META-INF/NOTICE \ `find /Users/jg/github/hbase/hbase-assembly/target/dependency -iname NOTICE -or -iname NOTICE.txt` \][ERROR] Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.4.0:exec (concat-NOTICE-files) on project hbase-assembly: Command execution failed. Process exited with an error: 1 (Exit value: 1) -&gt; [Help 1]org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.4.0:exec (concat-NOTICE-files) on project hbase-assembly: Command execution failed.The error is caused by the trailing backslash in the bash command for concat-NOTICE-files. You can see the behavioral difference between bash 3 and 4 with the following snippet.$ # Using bash 3$ /bin/bash -c 'cat &lt;(echo foo) \' &amp;&amp; echo good || echo badfoogood$ # Using bash 4$ /usr/local/bin/bash -c 'cat &lt;(echo foo) \' &amp;&amp; echo good || echo badfoocat: \: No such file or directorybad</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.2.6,1.3.2,1.1.11,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-assembly.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="17356" opendate="2016-12-21 00:00:00" fixdate="2016-1-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add replica get support</summary>
      <description>I think we can do better for scan at least as now we will pass the mvcc to client. We can use the mvcc to determine if we can get a consistent view when reading from replicas other than primary.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.3,2.0.5</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestZKAsyncRegistry.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTableLocatePrefetch.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncSingleRequestRpcRetryingCaller.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncNonMetaRegionLocatorConcurrenyLimit.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncNonMetaRegionLocator.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncMetaRegionLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionLocations.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncTableImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionConfiguration.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableRegionLocatorImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableRegionLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncSingleRequestRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRpcRetryingCallerFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRegionLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncNonMetaRegionLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncMetaRegionLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncConnectionImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncConnectionConfiguration.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncBatchRpcRetryingCaller.java</file>
    </fixedFiles>
  </bug>
  <bug id="17396" opendate="2016-12-30 00:00:00" fixdate="2016-1-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add first async admin impl and implement balance methods</summary>
      <description></description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncSingleRequestRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRpcRetryingCallerFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncConnectionImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncConnection.java</file>
    </fixedFiles>
  </bug>
  <bug id="17408" opendate="2017-1-3 00:00:00" fixdate="2017-1-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Introduce per request limit by number of mutations</summary>
      <description>HBASE-16224 introduced hbase.client.max.perrequest.heapsize to limit the amount of data sent from client.We should consider adding per request limit through the number of mutations in a batch.In recent troubleshooting sessions, customer had to do this in their application code to avoid OOME on the server side.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionServerObserver.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestSimpleRequestController.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.SimpleRequestController.java</file>
    </fixedFiles>
  </bug>
  <bug id="17410" opendate="2017-1-4 00:00:00" fixdate="2017-1-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use isEmpty instead of size() == 0 in hbase-client</summary>
      <description>Use .isEmpty() instead of size() == 0 when possible in the hbase-client module.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.TestHTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueuesZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.MultiRowRangeFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.MultipleColumnPrefixFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.KeyOnlyFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FirstKeyOnlyFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Put.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Increment.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTableMultiplexer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallReversedScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="17416" opendate="2017-1-4 00:00:00" fixdate="2017-1-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use isEmpty instead of size() == 0 in hbase-protocol-shaded</summary>
      <description>Use .isEmpty() instead of size() == 0 when possible in the hbase-protocol-shaded module.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.util.ForeignExceptionUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="17441" opendate="2017-1-9 00:00:00" fixdate="2017-10-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>precommit test "hadoopcheck" not properly testing Hadoop 3 profile</summary>
      <description>HBASE-14061 made a change that caused building against hadoop 3 to fail, but the hadoopcheck precommit test gave the change a +1.</description>
      <version>2.0.0</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0-alpha-4,2.0.0,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  <bug id="17442" opendate="2017-1-10 00:00:00" fixdate="2017-8-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move most of the replication related classes from hbase-client to hbase-replication package</summary>
      <description>After the replication requests are routed through master, replication implementation details didn't need be exposed to client. We should move most of the replication related classes to hbase-server package.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0-alpha-3,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-replication.pom.xml</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.BaseReplicationEndpoint.java</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZNodePaths.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.TableBasedReplicationQueuesImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.TableBasedReplicationQueuesClientImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationTrackerZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationTracker.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationTableBase.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationStateZKBase.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueuesZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueuesClientZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueuesClientArguments.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueuesClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueuesArguments.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueues.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueueInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeerZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeersZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeers.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeerConfigListener.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationListener.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.replication.ReplicationAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="17471" opendate="2017-1-15 00:00:00" fixdate="2017-5-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Region Seqid will be out of order in WAL if using mvccPreAssign</summary>
      <description>mvccPreAssign was brought by HBASE-16698, which truly improved the performance of writing, especially in ASYNC_WAL scenario. But mvccPreAssign was only used in doMiniBatchMutate, not in Increment/Append path. If Increment/Append and batch put are using against the same region in parallel, then seqid of the same region may not monotonically increasing in the WAL. Since one write path acquires mvcc/seqid before append, and the other acquires in the append/sync consume thread.The out of order situation can easily reproduced by a simple UT, which was attached in the attachment. I modified the code to assert on the disorder: if(this.highestSequenceIds.containsKey(encodedRegionName)) { assert highestSequenceIds.get(encodedRegionName) &lt; sequenceid; }I'd like to say, If we allow disorder in WALs, then this is not a issue. But as far as I know, if highestSequenceIds is not properly set, some WALs may not archive to oldWALs correctly.which I haven't figure out yet is that, will disorder in WAL cause data loss when recovering from disaster? If so, then it is a big problem need to be fixed.I have fix this problem in our costom1.1.x branch, my solution is using mvccPreAssign everywhere, making it un-configurable. Since mvccPreAssign it is indeed a better way than assign seqid in the ringbuffer thread while keeping handlers waiting for it.If anyone think it is doable, then I will port it to branch-1 and master branch and upload it.</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestWALFactory.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestSecureWAL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALActionsListener.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.AbstractTestWALReplay.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.AbstractTestFSWAL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestWALLockup.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestWALObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALKey.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSWALEntry.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="17472" opendate="2017-1-16 00:00:00" fixdate="2017-2-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Correct the semantic of permission grant</summary>
      <description>Currently, HBase grant operation has following semantic:hbase(main):019:0&gt; grant 'hbase_tst', 'RW', 'ycsb'0 row(s) in 0.0960 secondshbase(main):020:0&gt; user_permission 'ycsb'User Namespace,Table,Family,Qualifier:Permission hbase_tst default,ycsb,,: [Permission:actions=READ,WRITE] 1 row(s) in 0.0550 secondshbase(main):021:0&gt; grant 'hbase_tst', 'CA', 'ycsb'0 row(s) in 0.0820 secondshbase(main):022:0&gt; user_permission 'ycsb'User Namespace,Table,Family,Qualifier:Permission hbase_tst default,ycsb,,: [Permission: actions=CREATE,ADMIN] 1 row(s) in 0.0490 seconds Later permission will replace previous granted permissions, which confused most of HBase administrator.It's seems more reasonable that HBase merge multiple granted permission.</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestTablePermissions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestNamespaceCommands.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.SecureTestUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlLists.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.AccessControl.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.TablePermission.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="17478" opendate="2017-1-17 00:00:00" fixdate="2017-2-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Avoid sending FSUtilization reports to master when quota support is not enabled</summary>
      <description>Trivial little change to make sure that the RS's do not send the filesystem utilization reports to the master when hbase.quota.enabled=false and, similarly, that the master gracefully handles these reports when the feature is not enabled.</description>
      <version>None</version>
      <fixedVersion>HBASE-16961,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.MasterQuotaManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="17480" opendate="2017-1-18 00:00:00" fixdate="2017-1-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove split region code from Region Server</summary>
      <description>HBASE-14551 moves the split region logic to the master-side. With the code in HBASE-14551, the split transaction code from region server side became un-used. There is no need to keep region_server-side split region code. We should remove them to avoid code duplication.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionWithInMemoryFlush.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransactionImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransactionFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
    </fixedFiles>
  </bug>
  <bug id="17482" opendate="2017-1-18 00:00:00" fixdate="2017-1-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>mvcc mechanism fails when using mvccPreAssign</summary>
      <description>If mvccPreAssign and ASYNC_WAL is used, then cells may have been commited to memstore before append thread can stamp seqid to them. The unit test shows everything.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide3.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="17484" opendate="2017-1-18 00:00:00" fixdate="2017-2-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add non cached version of OffheapKV for write path</summary>
      <description>After running lot of different performance tests for various scenarios and with multi threads we thought that is better to have a version of OffheapKV in write path that does not cache anything and its fixed_overhead is equal to that in KeyValue.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestOffheapKeyValue.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.io.TestTagCompressionContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.test.RedundantKVGenerator.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.OffheapKeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.RowIndexSeekerV1.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.KeyValueCodec.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="17488" opendate="2017-1-19 00:00:00" fixdate="2017-1-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>WALEdit should be lazily instantiated</summary>
      <description>Some trivial improvement. create the WALEdit on step 3 instead of step 2 count the cells from coprocessor don’t count the mutations which contain the Durability.SKIP_WAL property</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="17498" opendate="2017-1-20 00:00:00" fixdate="2017-1-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement listTables and listTableNames methods</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="17508" opendate="2017-1-22 00:00:00" fixdate="2017-2-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unify the implementation of small scan and regular scan for sync client</summary>
      <description>Implement the same logic with HBASE-17045 for sync client.</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestPartialResultsFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestMetaTableAccessorNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.MobSnapshotTestingUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController2.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestScannerWithBulkload.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMobStoreScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestLeaseRenewal.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide3.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestClientScannerRPCTimeout.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.Canary.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.SyncTable.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestClientSmallScanner.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestClientSmallReversedScanner.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MetaTableAccessor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallReversedScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncNonMetaRegionLocator.java</file>
    </fixedFiles>
  </bug>
  <bug id="17511" opendate="2017-1-23 00:00:00" fixdate="2017-2-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement enable/disable table methods</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.AsyncMetaTableAccessor.java</file>
    </fixedFiles>
  </bug>
  <bug id="17514" opendate="2017-1-23 00:00:00" fixdate="2017-4-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Warn when Thrift Server 1 is configured for proxy users but not the HTTP transport</summary>
      <description>The config hbase.thrift.support.proxyuser is ignored if the Thrift Server 1 isn't configured to use an HTTP transport with hbase.regionserver.thrift.http.We should emit a warning if our configs request proxy user support but don't specify that HTTP should be used for the transport.</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.2.6,1.3.2,1.1.11,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
    </fixedFiles>
  </bug>
  <bug id="17516" opendate="2017-1-23 00:00:00" fixdate="2017-3-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Table quota not taking precedence over namespace quota</summary>
      <description>Romil Choksi found a bug in the current patch-set where a more restrictive table quota did not take priority over a less-restrictive namespace quota.Turns out some of the logic to handle this case was incorrect.</description>
      <version>None</version>
      <fixedVersion>HBASE-16961,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestSpaceQuotas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestQuotaStatusRPCs.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestQuotaObserverChoreWithMiniCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaObserverChore.java</file>
    </fixedFiles>
  </bug>
  <bug id="17518" opendate="2017-1-24 00:00:00" fixdate="2017-4-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase Reference Guide has a syntax error</summary>
      <description>The image of "HFile Version 2 Structure" in Appendix F of HBase Reference Guide (pdf) is missing because of a wrong asciidoc syntax:image:hfilev2.png&amp;#91;HFile Version 2&amp;#93;modified as:image::hfilev2.png&amp;#91;HFile Version 2&amp;#93;it should be a double colon instead of single one</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.appendix.hfile.format.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="17520" opendate="2017-1-24 00:00:00" fixdate="2017-3-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement isTableEnabled/Disabled/Available methods</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTableAdminApi.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.AsyncMetaTableAccessor.java</file>
    </fixedFiles>
  </bug>
  <bug id="17522" opendate="2017-1-24 00:00:00" fixdate="2017-2-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RuntimeExceptions from MemoryMXBean should not take down server process</summary>
      <description>RegionServer died after MemoryMXBean threw an IllegalArgumentException while attempting to create a MemoryUsage object for the heap during construction of the server load.We shouldn't allow failure to get load information to take down the RS.</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.1,1.2.5,1.1.9,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDefaultMemStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestCacheConfig.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HeapMemoryManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.util.MemorySizeUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="1754" opendate="2009-8-8 00:00:00" fixdate="2009-8-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>use TCP keepalives</summary>
      <description>If a regionserver crashes while the client is engaged in IPC with it at a vulnerable point in the TCP FSM (ESTABLISHED, no outstanding data to send), the IPC will be stuck waiting "forever" (&gt; 12 hours, etc.). This hoses the client, especially if it is trying to look up a region in META. Worse, it is not possible to restart the regionserver if the hung client is colocated with it on the same host, because the OS will consider port 60020 bound and in use, unless the client is forcibly killed. Killing some types of applications &amp;#8211; especially long running processes which can't redo work from a checkpoint but must start over from the beginning &amp;#8211; can be very painful. Investigate if TCP keepalives can be enabled at the IPC level.</description>
      <version>None</version>
      <fixedVersion>0.20.0,0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HBaseServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HBaseClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="17562" opendate="2017-1-27 00:00:00" fixdate="2017-1-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove documentation for coprocessor execution times after HBASE-14205</summary>
      <description>Thanks, Steen Manniche for reporting. Opened up a subtask. Feel free to pick it up if you want to patch it yourself. Otherwise, I can do a quick patch.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.site.resources.images.coprocessor.stats.png</file>
      <file type="M">src.main.asciidoc..chapters.cp.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="17566" opendate="2017-1-30 00:00:00" fixdate="2017-1-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Jetty upgrade fixes</summary>
      <description>There are some issues with Jetty 9.2.6 upgrade: static contents are not available, therefore html pages do not show correctly, logs are not accessible.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.http.TestServletFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.http.TestHttpServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.http.resource.JerseyResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.http.HttpServerFunctionalTest.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.http.conf.TestConfServlet.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.locking.TestEntityLocks.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.DumpReplicationQueues.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.SslSocketConnectorSecure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.HttpServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.AdminAuthorizedServlet.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.client.Response.java</file>
    </fixedFiles>
  </bug>
  <bug id="17569" opendate="2017-1-31 00:00:00" fixdate="2017-1-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase-Procedure module need to support mvn clean test -PskipProcedureTests to skip unit test</summary>
      <description>From Reference guide, we know that To skip the tests in the hbase-server module, you would run:mvn clean test -PskipServerTestsWe can also support this command in hbase-procedure module.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-protocol.pom.xml</file>
      <file type="M">hbase-prefix-tree.pom.xml</file>
      <file type="M">hbase-metrics.pom.xml</file>
      <file type="M">hbase-metrics-api.pom.xml</file>
      <file type="M">hbase-endpoint.pom.xml</file>
      <file type="M">hbase-procedure.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1757" opendate="2009-8-10 00:00:00" fixdate="2009-8-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>REST server runs out of fds</summary>
      <description>Using the REST server at pset, we ran out of descriptors. Small issue w/ how the new HTables were being made (new one each time rather than resuse).</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.TimestampModel.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.TableModel.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.ScannerModel.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.RowModel.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.AbstractModel.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="17575" opendate="2017-2-1 00:00:00" fixdate="2017-2-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Run critical tests with each of the Inmemory Compaction Policies enabled (Towards Making BASIC the Default In-Memory Compaction Policy)</summary>
      <description>In preparation for switching the default in-memory compaction policy to BASIC, we would like to make sure that once we do the switch all tests will run (and pass!) with the new default policy.To this end, we remove the NONE configuration setting added to tests in HBASE-17294 and HBASE-17316.We verified these tests pass with all 3 memory compaction policies.For each test (1) if all 3 policies pass the test &amp;#8211; we remove the configuration from the test.(2) if some fail we add tests of all 3 configurations, e.g., by parameterized tests. When needed we update expected results.One test failure identified a small bug which is also fixed in the patch.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestIOFencing.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestAcidGuarantees.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestFlushSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestAsyncLogRolling.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.AbstractTestLogRolling.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRecoveredEdits.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestPerColumnFamilyFlush.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMajorCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMasterProcedureSchedulerConcurrency.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotCloneIndependence.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMobSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestHFileArchiving.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreSegmentsIterator.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestAcidGuarantees.java</file>
    </fixedFiles>
  </bug>
  <bug id="17578" opendate="2017-2-1 00:00:00" fixdate="2017-2-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thrift per-method metrics should still update in the case of exceptions</summary>
      <description>Currently, the InvocationHandler used to update per-method metrics in the Thrift server fails to update metrics if an exception occurs. This causes us to miss outliers. We should include exceptional cases in per-method latencies, and also look at adding specific exception rate metrics.</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift.TestThriftServer.java</file>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift2.TestThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftMetrics.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.HbaseHandlerMetricsProxy.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.thrift.MetricsThriftServerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.thrift.MetricsThriftServerSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="17581" opendate="2017-2-2 00:00:00" fixdate="2017-2-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>mvn clean test -PskipXXXTests does not work properly for some modules</summary>
      <description>mvn clean test -PskipXXXTests will skip all tests in XXX module, it works for hbase-server, when we use mvn clean test -PskipServerTests, it will skip all small and medium tests in hbase-server module. However for some module like hbase-common, this command only skip small tests, the medium tests are still executed.Need to ensure all components work in the same way</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-rsgroup.pom.xml</file>
      <file type="M">hbase-protocol.pom.xml</file>
      <file type="M">hbase-prefix-tree.pom.xml</file>
      <file type="M">hbase-metrics.pom.xml</file>
      <file type="M">hbase-metrics-api.pom.xml</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-hadoop-compat.pom.xml</file>
      <file type="M">hbase-endpoint.pom.xml</file>
      <file type="M">hbase-common.pom.xml</file>
      <file type="M">hbase-client.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="17583" opendate="2017-2-2 00:00:00" fixdate="2017-2-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add inclusive/exclusive support for startRow and endRow of scan for sync client</summary>
      <description>Implement the same feature of HBASE-17320 for sync client.</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestMetaTableAccessorNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannersFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.AbstractTestAsyncTableScan.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSimpleScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientAsyncPrefetchScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="17587" opendate="2017-2-2 00:00:00" fixdate="2017-2-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Do not Rethrow DoNotRetryIOException as UnknownScannerException</summary>
      <description>HBase commit https://github.com/apache/hbase/commit/94ade6a514e9935a8c283befb31f29cd8d3a2045 broke co-processors (such as Phoenix) throwing DoNotRetryIOExceptions when scanning a table. This change rethrows them as UnknownScannerExceptions which the HBase client will retry on. This is unintended behavior since co-processors should be able to throw DoNotRetryIOExceptions back to the client. This came up through a phoenix IT when trying to upgrade to HBase 1.3.0 https://github.com/apache/phoenix/pull/230</description>
      <version>1.3.0,2.0.0</version>
      <fixedVersion>1.4.0,1.3.1,1.2.5,1.1.9,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="17588" opendate="2017-2-2 00:00:00" fixdate="2017-2-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove unused imports brought in by HBASE-17437</summary>
      <description>During the review process of https://issues.apache.org/jira/browse/HBASE-17437, some unused imports (or unused code) was missed. This patch removes those.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestWALSplit.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALActionsListener.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRollAbort.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.AbstractTestFSWAL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestWALPlayer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestWALObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.DisabledWALProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitLogWorker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.fs.HFileSystem.java</file>
    </fixedFiles>
  </bug>
  <bug id="17595" opendate="2017-2-4 00:00:00" fixdate="2017-3-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add partial result support for small/limited scan</summary>
      <description>The partial result support is marked as a 'TODO' when implementing HBASE-17045. And when implementing HBASE-17508, we found that if we make small scan share the same logic with general scan, the scan request other than open scanner will not have the small flag so the server may return partial result to the client and cause some strange behavior. It is solved by modifying the logic at server side, but this means the 1.4.x client is not safe to contact with earlier 1.x server. So we'd better address the problem at client side. Marked as blocker as this issue should be finished before any 2.x and 1.4.x releases.</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScanResultCache.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.BatchScanResultCache.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AllowPartialScanResultCache.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestPartialResultsFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannersFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestRawAsyncTableScan.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTableScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTableScanAll.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTableScan.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.AbstractTestAsyncTableScan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ScannerContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Result.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncTableImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.CompleteScanResultCache.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncScanSingleRegionRpcRetryingCaller.java</file>
    </fixedFiles>
  </bug>
  <bug id="17596" opendate="2017-2-4 00:00:00" fixdate="2017-2-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement add/delete/modify column family methods</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="17600" opendate="2017-2-6 00:00:00" fixdate="2017-3-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement get/create/modify/delete/list namespace admin operations</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="17602" opendate="2017-2-7 00:00:00" fixdate="2017-3-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Tweak chore delay/period defaults</summary>
      <description>In testing, found that the default chore periods/delays were a little too lax. This resulted in quotas not being updated as soon as they really should have been.</description>
      <version>None</version>
      <fixedVersion>HBASE-16961,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.SpaceQuotaRefresherChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaObserverChore.java</file>
    </fixedFiles>
  </bug>
  <bug id="17627" opendate="2017-2-11 00:00:00" fixdate="2017-2-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Active workers metric for thrift</summary>
      <description>It would be good to have a metric for number of active handlers on thrift servers, which gives a good indication of business of a thrift server.</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.1,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftMetrics.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.TBoundedThreadPoolServer.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.thrift.MetricsThriftServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.thrift.MetricsThriftServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="17634" opendate="2017-2-11 00:00:00" fixdate="2017-2-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up the usage of Result.isPartial</summary>
      <description>We have marked Result.isPartial as deprecated in HBASE-17599. This issue aims to remove the isPartial usage in our code base.</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestPartialResultsFromClientSide.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.java</file>
    </fixedFiles>
  </bug>
  <bug id="17644" opendate="2017-2-14 00:00:00" fixdate="2017-2-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Always create ByteBufferCells after copying to MSLAB</summary>
      <description>We create a cell out of the Bytebuffer that is returned by MSLAB. This BB can be offheap or onheap type. If MSLAB is full we return onheap byte buffer. So the place where we create a cell by copying data to this buffer we either create KeyValue or OffheapKV based on the buffer type. So what we saw in tests is that since we have a combination of Cells the comparisons that happens when adding to memstore happens millions of times and that has an impact on the performance of write path. In read path this is not significant enougth (though we have plans to just create one type of cells every where in Server side).</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestWALReaderOnSecureWAL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.ExpAsStringVisibilityLabelServiceImpl.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALCellCodecWithCompression.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestTags.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMemStoreLAB.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMemStoreChunkPool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.protobuf.TestProtobufUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestSeekTo.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestScannerFromBucketCache.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestDependentColumnFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.SimpleRegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestOffheapKeyValue.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.io.TestTagCompressionContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.test.RedundantKVGenerator.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.TagUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.OffheapTag.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.OffheapKeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.RowIndexSeekerV1.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.KeyValueCodecWithTags.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.KeyValueCodec.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="17646" opendate="2017-2-14 00:00:00" fixdate="2017-3-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement Async getRegion method</summary>
      <description>There are some async admin APIs which depends on async getRegion method. Such as : 1. closeRegion. 2. flushRegion. 3. compactRegion. 4. mergeRegion. 5. splitRegion. and so on . So, implement async getRegion method first.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncTableImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncConnectionConfiguration.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.AsyncMetaTableAccessor.java</file>
    </fixedFiles>
  </bug>
  <bug id="17649" opendate="2017-2-14 00:00:00" fixdate="2017-2-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>REST API for scan should return 410 when table is disabled</summary>
      <description>Background:When scanning using REST API, if the table is disabled in the middle of the scan, code 410 (Gone) should be returned.Currently in 1.3 and lower releases, ScannerResultGenerator#next() doesn't handle TableNotEnabledException, leading to the exception being ignored and code 204 is returned to caller.This was first spotted by &amp;#91;~Apache9&amp;#93; when investigating HBASE-17603.Patch for HBASE-17603 contains fix for this problem.This issue fixes the bug for 1.3 and lower branches and adds test for branch-1 and master branch.</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.1,1.2.5,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.TestScannerResource.java</file>
    </fixedFiles>
  </bug>
  <bug id="17658" opendate="2017-2-17 00:00:00" fixdate="2017-2-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix bookkeeping error with max regions for a table</summary>
      <description>Currently when numMaxRegionsPerTable of a given table increases above the current maximum, the value is not properly updated. This means that the cost for Table Skew cannot get worse for a given region move during the balancer process leading to an imbalanced cluster with respect to Table Skew.</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestBaseLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
    </fixedFiles>
  </bug>
  <bug id="17667" opendate="2017-2-20 00:00:00" fixdate="2017-5-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement async flush/compact region methods</summary>
      <description>Implement following methods for async admin: 1. flush table ; 2. flush region; 3. compact table;4. compact region;5. compact region server; 6. major compact for table; 7. major compact for region; 8. major compact for CF;9. major compact for specific region and specific CF;</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncRegionAdminApi.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="17668" opendate="2017-2-20 00:00:00" fixdate="2017-4-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement async assgin/offline/move/unassign methods</summary>
      <description>Implement following methods for async admin client: 1. assign region; 2. unassign region; 3. offline region; 4. move region;</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncRegionAdminApi.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncAdminBase.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="17669" opendate="2017-2-20 00:00:00" fixdate="2017-3-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement async mergeRegion/splitRegion methods.</summary>
      <description>RT</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncRegionAdminApi.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="1767" opendate="2009-8-14 00:00:00" fixdate="2009-8-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>test zookeeper broken in trunk and 0.20 branch; broken on hudson too</summary>
      <description>Anyone want to take a look at this?</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.TestZooKeeper.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="17673" opendate="2017-2-21 00:00:00" fixdate="2017-2-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Monitored RPC Handler not shown in the WebUI</summary>
      <description>This issue has been fixed once in HBASE-14674. But, I noticed that almost all RS in our production environment still have this problem. Strange thing is that newly started servers seems do not affected. Digging for a while, then I realize the CircularFifoBuffer introduced by HBASE-10312 is the root cause. The RPC hander's monitoredTask only create once, if the server is flooded with tasks, RPC monitoredTask can be purged by CircularFifoBuffer, and then never visible in WebUI.So my solution is creating a list for RPC monitoredTask separately. It is OK to do so since the RPC handlers remain in a fixed number. It won't increase or decrease during the lifetime of the server.</description>
      <version>3.0.0-alpha-1,1.2.4,1.1.8,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.monitoring.TestTaskMonitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.TaskMonitor.java</file>
    </fixedFiles>
  </bug>
  <bug id="17677" opendate="2017-2-22 00:00:00" fixdate="2017-2-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ServerName parsing from directory name should be more robust to errors from guava&amp;#39;s HostAndPort</summary>
      <description>our internal Address facade over HostAndPort directly passes on any failures from the underlying Guava implementation. Right now when we parse a ServerName from a WAL directory we properly handle if guava gives us an IllegalArgumentException but we do not handle if it gives us a IllegalStateException. e.g. it uses the former for "I couldn't parse anything out of this string" and the latter for "I parsed a host name but didn't see a port".</description>
      <version>2.0.0</version>
      <fixedVersion>1.4.0,1.3.1,1.2.5,1.1.10,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestWALMethods.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.AbstractFSWALProvider.java</file>
    </fixedFiles>
  </bug>
  <bug id="1768" opendate="2009-8-14 00:00:00" fixdate="2009-8-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>REST server has upper limit of 5k PUT</summary>
      <description>This is getting in way of our uploading images to hbase.Below is what we see when big img to put.$ curl -v -T /tmp/y.row http://localhost:12041/api/jimk/row/x?column=misc:stack_testing:* About to connect() to localhost port 12041* Trying 127.0.0.1... connected* Connected to localhost (127.0.0.1) port 12041&gt; PUT /api/jimk/row/x?column=misc:stack_testing: HTTP/1.1&gt; User-Agent: curl/7.15.5 (x86_64-redhat-linux-gnu) libcurl/7.15.5 OpenSSL/0.9.8b zlib/1.2.3 libidn/0.6.5&gt; Host: localhost:12041&gt; Accept: */*&gt; Content-Length: 229886&gt; Expect: 100-continue&gt;&lt; HTTP/1.1 100 ContinueHTTP/1.1 500 Internal Server Error&lt; Content-Type: text/xml; charset=iso-8859-1&lt; Transfer-Encoding: chunked&lt; Server: Jetty(6.1.14)* Connection #0 to host localhost left intact* Closing connection #0&lt;status&gt;&lt;code&gt;500&lt;/code&gt;&lt;message&gt;org.apache.hadoop.hbase.rest.exception.HBaseRestException: XML document structures must start and end within the same entity.&lt;/message&gt;&lt;error&gt;true&lt;/error&gt;&lt;/status&gt;[stack@aa0-007-2 tmp]$</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.Dispatcher.java</file>
    </fixedFiles>
  </bug>
  <bug id="17698" opendate="2017-2-24 00:00:00" fixdate="2017-3-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ReplicationEndpoint choosing sinks</summary>
      <description>The only time we choose new sinks is when we have a ConnectException, but we have encountered other exceptions where there is a problem contacting a particular sink and replication gets backed up for any sources that try that sinkHBASE-17675 occurred when there was a bad keytab refresh and the source was stuck.Another issue we recently had was a bad drive controller on the sink side and replication was stuck again. Is there any reason not to choose new sinks anytime we have a RemoteException? I can understand TableNotFound we don't have to choose new sinks, but for all other cases this seems like the safest approach.</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,1.3.1,1.1.10,1.2.6,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint.java</file>
    </fixedFiles>
  </bug>
  <bug id="17699" opendate="2017-2-25 00:00:00" fixdate="2017-2-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix TestLockProcedure</summary>
      <description>TestLockProcedure is failing consistently after HBASE-17605. It's interesting that HadoopQA didn't report any test failures on that jira. Anyways, need to fix the test now.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.SimpleProcedureScheduler.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureScheduler.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureExecutor.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.java</file>
    </fixedFiles>
  </bug>
  <bug id="17712" opendate="2017-3-1 00:00:00" fixdate="2017-3-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove/Simplify the logic of RegionScannerImpl.handleFileNotFound</summary>
      <description>It is introduced in HBASE-13651 and the logic became much more complicated after HBASE-16304 due to a dead lock issue. It is really tough as sequence id is involved in and the method we called is used to serve secondary replica originally which does not handle write.In fact, in 1.x release, the problem described in HBASE-13651 is gone. Now we will write a compaction marker to WAL before deleting the compacted files. We can only consider a RS as dead after its WAL files are all closed so if the region has already been reassigned the compaction will fail as we can not write out the compaction marker.So theoretically, if we still hit FileNotFound exception, it should be a critical bug which means we may loss data. I do not think it is a good idea to just eat the exception and refresh store files. Or even if we want to do this, we can just refresh store files without dropping memstore contents. This will also simplify the logic a lot.Suggestions are welcomed.</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCorruptedRegionStoreFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MockRegionServerServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="17718" opendate="2017-3-2 00:00:00" fixdate="2017-3-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Difference between RS&amp;#39;s servername and its ephemeral node cause SSH stop working</summary>
      <description>After HBASE-9593, RS put up an ephemeral node in ZK before reporting for duty. But if the hosts config (/etc/hosts) is different between master and RS, RS's serverName can be different from the one stored the ephemeral zk node. The email metioned in HBASE-13753 (http://mail-archives.apache.org/mod_mbox/hbase-user/201505.mbox/%3CCANZDn9ueFEEuZMx=pZdmtLsdGLyZz=rrm1N6EQvLswYc1z-H=g@mail.gmail.com%3E) is exactly what happened in our production env. But what the email didn't point out is that the difference between serverName in RS and zk node can cause SSH stop to work. as we can see from the code in RegionServerTracker @Override public void nodeDeleted(String path) { if (path.startsWith(watcher.rsZNode)) { String serverName = ZKUtil.getNodeName(path); LOG.info("RegionServer ephemeral node deleted, processing expiration [" + serverName + "]"); ServerName sn = ServerName.parseServerName(serverName); if (!serverManager.isServerOnline(sn)) { LOG.warn(serverName.toString() + " is not online or isn't known to the master."+ "The latter could be caused by a DNS misconfiguration."); return; } remove(sn); this.serverManager.expireServer(sn); } }The server will not be processed by SSH/ServerCrashProcedure. The regions on this server will not been assigned again until master restart or failover.I know HBASE-9593 was to fix the issue if RS report to duty and crashed before it can put up a zk node. It is a very rare case(And controllable， just fix the bug making rs to crash). But The issue I metioned can happened more often(and uncontrollable, can't be fixed in HBase, due to DNS, hosts config, etc.) and have more severe consequence.So here I offer some solutions to discuss:1. Revert HBASE-9593 from all branches, Andrew Purtell has reverted it in branch-0.982. Abort RS if master return a different name, otherwise SSH can't work properly3. Master accepts whatever servername reported by RS and don't change it.4.correct the zk node if master return another name( idea from Ted Yu)</description>
      <version>1.2.4,1.1.8,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestServerCrashProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMasterProcedureEvents.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRSKilledWhenInitializing.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.DrainingServerTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="17736" opendate="2017-3-5 00:00:00" fixdate="2017-3-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Some options can&amp;#39;t be configured by the shell</summary>
      <description>The lost options for table are shown below. setFlushPolicyClassName setPriority setRegionMemstoreReplication setRegionSplitPolicyClassName</description>
      <version>2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.test.ruby.hbase.admin.test.rb</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug id="17737" opendate="2017-3-6 00:00:00" fixdate="2017-3-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thrift2 proxy should support scan timeRange per column family</summary>
      <description>see discussion in HBASE-14872 and HBASE-14355</description>
      <version>2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift2.TestThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-thrift.src.main.resources.org.apache.hadoop.hbase.thrift2.hbase.thrift</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftUtilities.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TScan.java</file>
    </fixedFiles>
  </bug>
  <bug id="17738" opendate="2017-3-6 00:00:00" fixdate="2017-7-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>BucketCache startup is slow</summary>
      <description>If you set bucketcache size at 64G say and then start hbase, it takes a long time. Can we do the allocations in parallel and not inline with the server startup?Related, prefetching on a bucketcache is slow. Speed it up.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0-alpha-2,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestByteBufferArray.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteBufferArray.java</file>
    </fixedFiles>
  </bug>
  <bug id="17740" opendate="2017-3-7 00:00:00" fixdate="2017-3-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Correct the semantic of batch and partial for async client</summary>
      <description></description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestCompleteResultScanResultCache.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAllowPartialScanResultCache.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Result.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AllowPartialScanResultCache.java</file>
    </fixedFiles>
  </bug>
  <bug id="17745" opendate="2017-3-7 00:00:00" fixdate="2017-3-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support short circuit connection for master services</summary>
      <description>As titled, now we have short circuit connection, but no short circuit for master services, and we propose to support it in this JIRA.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="17748" opendate="2017-3-7 00:00:00" fixdate="2017-6-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Include HBase Snapshots in Space Quotas</summary>
      <description>Umbrella issue for the inclusion of HBase Snapshots in the Space Quota feature (HBASE-16961)https://docs.google.com/document/d/1f7utThEBYRXYHvp3e5fOhQBv2K1aeuzGHGEfNNE3Clc/edit# / https://home.apache.org/~elserj/hbase/FileSystemQuotasforApacheHBase-Snapshots.pdf</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Umbrella</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestTableQuotaViolationStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestSuperUserQuotaPermissions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestSpaceQuotas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestRegionSizeUse.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestQuotaTableUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestQuotaStatusRPCs.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestQuotaObserverChoreWithMiniCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestQuotaObserverChoreRegionReports.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestNamespaceQuotaViolationStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestFileSystemUtilizationChore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.SpaceQuotaHelperForTests.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.TableSpaceQuotaSnapshotNotifier.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.TableQuotaSnapshotStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaSnapshotStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaObserverChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.NamespaceQuotaSnapshotStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.FileSystemUtilizationChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MetricsMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterQuotaSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterQuotaSource.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.SpaceQuotaSnapshot.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaTableUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="1776" opendate="2009-8-18 00:00:00" fixdate="2009-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make rowcounter enum public</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.mapreduce.RowCounter.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="17760" opendate="2017-3-8 00:00:00" fixdate="2017-3-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HDFS Balancer doc is misleading</summary>
      <description>HBASE-15332 added a doc note about how to use HDFS-6133, but the steps it adds are incorrect. The specific balancer command provided in the doc note is incorrect and not required.Since HBase uses favored nodes features internally (HBASE-7932), and HBASE-7942 extended that information to cover HDFS hinting too, the only step required in the doc note is to enable the pinning feature DN-side.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.troubleshooting.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="17777" opendate="2017-3-13 00:00:00" fixdate="2017-5-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestMemstoreLAB#testLABThreading runs too long for a small test</summary>
      <description>While working on ChunkCreator/ChunkMap found that the test in TestMSLAB#testLABThreading() runs for almost 5 mins and the whole test is under smallTest category.The reason is that we are creating 35*2MB chunks from MSLAB. We try writing data to these chunks until they are 50MB in size.And while verifying in order to check if the chunks are not overwritten/overlapped we verify the content of the buffers.So we actually keep comparing 50MB buffer n number of times. I suggest we change this in a way that at max we create chunks whose size is totally at 1MB or may be even lesser and write cells which are smaller in size. By doing this we can drastically reduce the run time of this test. May be something less than 1 min.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMemStoreLAB.java</file>
    </fixedFiles>
  </bug>
  <bug id="17785" opendate="2017-3-14 00:00:00" fixdate="2017-4-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RSGroupBasedLoadBalancer fails to assign new table regions when cloning snapshot</summary>
      <description>A novice starting out with RSGroupBasedLoadBalancer will want to enable it and, before assigning tables to groups, may want to create some test tables. Currently that does not work when creating a table by cloning a snapshot, in a surprising way. All regions of the table fail to open yet it is moved into ENABLED state. The client hangs indefinitely. 2017-03-14 19:25:49,833 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] snapshot.CloneSnapshotHandler: Clone snapshot=seed on table=test_1 completed!2017-03-14 19:25:49,871 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] hbase.MetaTableAccessor: Added 252017-03-14 19:25:49,875 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] rsgroup.RSGroupBasedLoadBalancer: Group for table test_1 is null2017-03-14 19:25:49,875 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] rsgroup.RSGroupBasedLoadBalancer: Group for table test_1 is null2017-03-14 19:25:49,875 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] rsgroup.RSGroupBasedLoadBalancer: Group for table test_1 is null2017-03-14 19:25:49,875 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] rsgroup.RSGroupBasedLoadBalancer: Group for table test_1 is null2017-03-14 19:25:49,875 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] rsgroup.RSGroupBasedLoadBalancer: Group for table test_1 is null2017-03-14 19:25:49,875 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] rsgroup.RSGroupBasedLoadBalancer: Group for table test_1 is null2017-03-14 19:25:49,875 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] rsgroup.RSGroupBasedLoadBalancer: Group for table test_1 is null2017-03-14 19:25:49,875 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] rsgroup.RSGroupBasedLoadBalancer: Group for table test_1 is null2017-03-14 19:25:49,875 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] rsgroup.RSGroupBasedLoadBalancer: Group for table test_1 is null2017-03-14 19:25:49,875 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] rsgroup.RSGroupBasedLoadBalancer: Group for table test_1 is null2017-03-14 19:25:49,875 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] rsgroup.RSGroupBasedLoadBalancer: Group for table test_1 is null2017-03-14 19:25:49,875 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] rsgroup.RSGroupBasedLoadBalancer: Group for table test_1 is null2017-03-14 19:25:49,875 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] rsgroup.RSGroupBasedLoadBalancer: Group for table test_1 is null2017-03-14 19:25:49,875 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] rsgroup.RSGroupBasedLoadBalancer: Group for table test_1 is null2017-03-14 19:25:49,875 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] rsgroup.RSGroupBasedLoadBalancer: Group for table test_1 is null2017-03-14 19:25:49,875 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] rsgroup.RSGroupBasedLoadBalancer: Group for table test_1 is null2017-03-14 19:25:49,875 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] rsgroup.RSGroupBasedLoadBalancer: Group for table test_1 is null2017-03-14 19:25:49,875 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] rsgroup.RSGroupBasedLoadBalancer: Group for table test_1 is null2017-03-14 19:25:49,875 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] rsgroup.RSGroupBasedLoadBalancer: Group for table test_1 is null2017-03-14 19:25:49,875 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] rsgroup.RSGroupBasedLoadBalancer: Group for table test_1 is null2017-03-14 19:25:49,875 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] rsgroup.RSGroupBasedLoadBalancer: Group for table test_1 is null2017-03-14 19:25:49,875 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] rsgroup.RSGroupBasedLoadBalancer: Group for table test_1 is null2017-03-14 19:25:49,875 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] rsgroup.RSGroupBasedLoadBalancer: Group for table test_1 is null2017-03-14 19:25:49,875 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] rsgroup.RSGroupBasedLoadBalancer: Group for table test_1 is null2017-03-14 19:25:49,875 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] rsgroup.RSGroupBasedLoadBalancer: Group for table test_1 is null2017-03-14 19:25:49,876 DEBUG [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] rsgroup.RSGroupBasedLoadBalancer: Group Information found to be null. Some regions might be unassigned.2017-03-14 19:25:49,878 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Failed to open/close d090e1601e01c69d1fcc032e614fb6d1 on null, set to FAILED_OPEN2017-03-14 19:25:49,878 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Transition {d090e1601e01c69d1fcc032e614fb6d1 state=OFFLINE, ts=1489519549871, server=null} to {d090e1601e01c69d1fcc032e614fb6d1 state=FAILED_OPEN, ts=1489519549878, server=null}2017-03-14 19:25:49,878 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Failed to open/close 84923d2d514e03e55ab154c92157ccb1 on null, set to FAILED_OPEN2017-03-14 19:25:49,878 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Transition {84923d2d514e03e55ab154c92157ccb1 state=OFFLINE, ts=1489519549871, server=null} to {84923d2d514e03e55ab154c92157ccb1 state=FAILED_OPEN, ts=1489519549878, server=null}2017-03-14 19:25:49,878 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Failed to open/close 963f7e4edacc84963287ded0b18df6fa on null, set to FAILED_OPEN2017-03-14 19:25:49,878 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Transition {963f7e4edacc84963287ded0b18df6fa state=OFFLINE, ts=1489519549871, server=null} to {963f7e4edacc84963287ded0b18df6fa state=FAILED_OPEN, ts=1489519549878, server=null}2017-03-14 19:25:49,878 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Failed to open/close fc7490f9b10706e7a56879861159dbcd on null, set to FAILED_OPEN2017-03-14 19:25:49,878 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Transition {fc7490f9b10706e7a56879861159dbcd state=OFFLINE, ts=1489519549871, server=null} to {fc7490f9b10706e7a56879861159dbcd state=FAILED_OPEN, ts=1489519549878, server=null}2017-03-14 19:25:49,878 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Failed to open/close 049f6fc952ab01e72f33bba1bc5dd65d on null, set to FAILED_OPEN2017-03-14 19:25:49,878 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Transition {049f6fc952ab01e72f33bba1bc5dd65d state=OFFLINE, ts=1489519549871, server=null} to {049f6fc952ab01e72f33bba1bc5dd65d state=FAILED_OPEN, ts=1489519549878, server=null}2017-03-14 19:25:49,878 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Failed to open/close 94ce90589fd4149b5f88bc8e6ef888f2 on null, set to FAILED_OPEN2017-03-14 19:25:49,878 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Transition {94ce90589fd4149b5f88bc8e6ef888f2 state=OFFLINE, ts=1489519549871, server=null} to {94ce90589fd4149b5f88bc8e6ef888f2 state=FAILED_OPEN, ts=1489519549878, server=null}2017-03-14 19:25:49,878 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Failed to open/close 0e53c04d48073b8d2f7750f0e25036de on null, set to FAILED_OPEN2017-03-14 19:25:49,878 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Transition {0e53c04d48073b8d2f7750f0e25036de state=OFFLINE, ts=1489519549871, server=null} to {0e53c04d48073b8d2f7750f0e25036de state=FAILED_OPEN, ts=1489519549878, server=null}2017-03-14 19:25:49,878 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Failed to open/close 9cea3e97118fd9d5d911cb6a713fe92c on null, set to FAILED_OPEN2017-03-14 19:25:49,878 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Transition {9cea3e97118fd9d5d911cb6a713fe92c state=OFFLINE, ts=1489519549871, server=null} to {9cea3e97118fd9d5d911cb6a713fe92c state=FAILED_OPEN, ts=1489519549878, server=null}2017-03-14 19:25:49,878 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Failed to open/close 2dcfc3c3797f63e9612c7f06cd43ef09 on null, set to FAILED_OPEN2017-03-14 19:25:49,878 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Transition {2dcfc3c3797f63e9612c7f06cd43ef09 state=OFFLINE, ts=1489519549871, server=null} to {2dcfc3c3797f63e9612c7f06cd43ef09 state=FAILED_OPEN, ts=1489519549878, server=null}2017-03-14 19:25:49,878 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Failed to open/close 08172bfac46deaa38cd1b53fe3a6da15 on null, set to FAILED_OPEN2017-03-14 19:25:49,878 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Transition {08172bfac46deaa38cd1b53fe3a6da15 state=OFFLINE, ts=1489519549871, server=null} to {08172bfac46deaa38cd1b53fe3a6da15 state=FAILED_OPEN, ts=1489519549878, server=null}2017-03-14 19:25:49,878 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Failed to open/close f1f7d7992fe87a90f83b89160e872e1c on null, set to FAILED_OPEN2017-03-14 19:25:49,878 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Transition {f1f7d7992fe87a90f83b89160e872e1c state=OFFLINE, ts=1489519549871, server=null} to {f1f7d7992fe87a90f83b89160e872e1c state=FAILED_OPEN, ts=1489519549878, server=null}2017-03-14 19:25:49,878 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Failed to open/close 5b0ffe069c7fb61532a007dcccdceeed on null, set to FAILED_OPEN2017-03-14 19:25:49,878 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Transition {5b0ffe069c7fb61532a007dcccdceeed state=OFFLINE, ts=1489519549872, server=null} to {5b0ffe069c7fb61532a007dcccdceeed state=FAILED_OPEN, ts=1489519549878, server=null}2017-03-14 19:25:49,878 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Failed to open/close f2b05bace075fd0af582b1556dfd9424 on null, set to FAILED_OPEN2017-03-14 19:25:49,878 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Transition {f2b05bace075fd0af582b1556dfd9424 state=OFFLINE, ts=1489519549872, server=null} to {f2b05bace075fd0af582b1556dfd9424 state=FAILED_OPEN, ts=1489519549878, server=null}2017-03-14 19:25:49,878 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Failed to open/close ddeae8251147c720f2bfb31f5c4f38ea on null, set to FAILED_OPEN2017-03-14 19:25:49,878 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Transition {ddeae8251147c720f2bfb31f5c4f38ea state=OFFLINE, ts=1489519549872, server=null} to {ddeae8251147c720f2bfb31f5c4f38ea state=FAILED_OPEN, ts=1489519549878, server=null}2017-03-14 19:25:49,878 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Failed to open/close 36bd37cbf02b1e774df09a713ed73f39 on null, set to FAILED_OPEN2017-03-14 19:25:49,878 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Transition {36bd37cbf02b1e774df09a713ed73f39 state=OFFLINE, ts=1489519549872, server=null} to {36bd37cbf02b1e774df09a713ed73f39 state=FAILED_OPEN, ts=1489519549878, server=null}2017-03-14 19:25:49,878 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Failed to open/close 60199e589af842ae1b468bc59225896c on null, set to FAILED_OPEN2017-03-14 19:25:49,878 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Transition {60199e589af842ae1b468bc59225896c state=OFFLINE, ts=1489519549872, server=null} to {60199e589af842ae1b468bc59225896c state=FAILED_OPEN, ts=1489519549878, server=null}2017-03-14 19:25:49,878 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Failed to open/close 78988f15ae27088228dc6b343e78bb22 on null, set to FAILED_OPEN2017-03-14 19:25:49,878 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Transition {78988f15ae27088228dc6b343e78bb22 state=OFFLINE, ts=1489519549872, server=null} to {78988f15ae27088228dc6b343e78bb22 state=FAILED_OPEN, ts=1489519549878, server=null}2017-03-14 19:25:49,878 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Failed to open/close dc3f7144432876d8c9638dddaeab9a4b on null, set to FAILED_OPEN2017-03-14 19:25:49,878 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Transition {dc3f7144432876d8c9638dddaeab9a4b state=OFFLINE, ts=1489519549873, server=null} to {dc3f7144432876d8c9638dddaeab9a4b state=FAILED_OPEN, ts=1489519549878, server=null}2017-03-14 19:25:49,878 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Failed to open/close 86042d73e77f8f4600f72f5e40402ee0 on null, set to FAILED_OPEN2017-03-14 19:25:49,878 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Transition {86042d73e77f8f4600f72f5e40402ee0 state=OFFLINE, ts=1489519549873, server=null} to {86042d73e77f8f4600f72f5e40402ee0 state=FAILED_OPEN, ts=1489519549878, server=null}2017-03-14 19:25:49,878 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Failed to open/close c5d04d3d9539f872f6ea3ba439039c92 on null, set to FAILED_OPEN2017-03-14 19:25:49,878 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Transition {c5d04d3d9539f872f6ea3ba439039c92 state=OFFLINE, ts=1489519549873, server=null} to {c5d04d3d9539f872f6ea3ba439039c92 state=FAILED_OPEN, ts=1489519549878, server=null}2017-03-14 19:25:49,878 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Failed to open/close 6cd6f1ee48a5c4c984a1669f5479bebb on null, set to FAILED_OPEN2017-03-14 19:25:49,879 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Transition {6cd6f1ee48a5c4c984a1669f5479bebb state=OFFLINE, ts=1489519549873, server=null} to {6cd6f1ee48a5c4c984a1669f5479bebb state=FAILED_OPEN, ts=1489519549879, server=null}2017-03-14 19:25:49,879 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Failed to open/close 6d93918ba17b9c9c8c6ce8dd7f80faa9 on null, set to FAILED_OPEN2017-03-14 19:25:49,879 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Transition {6d93918ba17b9c9c8c6ce8dd7f80faa9 state=OFFLINE, ts=1489519549873, server=null} to {6d93918ba17b9c9c8c6ce8dd7f80faa9 state=FAILED_OPEN, ts=1489519549879, server=null}2017-03-14 19:25:49,879 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Failed to open/close 0916b60e63a12117338729422ccce167 on null, set to FAILED_OPEN2017-03-14 19:25:49,879 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Transition {0916b60e63a12117338729422ccce167 state=OFFLINE, ts=1489519549874, server=null} to {0916b60e63a12117338729422ccce167 state=FAILED_OPEN, ts=1489519549879, server=null}2017-03-14 19:25:49,879 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Failed to open/close 986d43427be51aa346487a7ffb2fcd45 on null, set to FAILED_OPEN2017-03-14 19:25:49,879 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Transition {986d43427be51aa346487a7ffb2fcd45 state=OFFLINE, ts=1489519549874, server=null} to {986d43427be51aa346487a7ffb2fcd45 state=FAILED_OPEN, ts=1489519549879, server=null}2017-03-14 19:25:49,879 WARN [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Failed to open/close 6eb76d90c9a07fff51b1fa1d9dabfef4 on null, set to FAILED_OPEN2017-03-14 19:25:49,879 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.RegionStates: Transition {6eb76d90c9a07fff51b1fa1d9dabfef4 state=OFFLINE, ts=1489519549874, server=null} to {6eb76d90c9a07fff51b1fa1d9dabfef4 state=FAILED_OPEN, ts=1489519549879, server=null}2017-03-14 19:25:49,879 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.AssignmentManager: Bulk assigning 25 region(s) across 5 server(s), round-robin=true2017-03-14 19:25:49,880 DEBUG [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.GeneralBulkAssigner: Timeout-on-RIT=610002017-03-14 19:25:49,880 DEBUG [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.GeneralBulkAssigner: bulk assigning total 0 regions to 0 servers, took 0ms, successfully2017-03-14 19:25:49,880 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] master.AssignmentManager: Bulk assigning done2017-03-14 19:25:49,880 INFO [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] zookeeper.ZKTableStateManager: Moving table test_1 state from ENABLING to ENABLED2017-03-14 19:25:49,886 DEBUG [MASTER_TABLE_OPERATIONS-ip-172-31-5-95:8100-0] lock.ZKInterProcessLockBase: Released /hbase/table-lock/test_1/write-master:81000000000004</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-rsgroup.src.test.java.org.apache.hadoop.hbase.rsgroup.TestRSGroups.java</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupAdminEndpoint.java</file>
    </fixedFiles>
  </bug>
  <bug id="17798" opendate="2017-3-17 00:00:00" fixdate="2017-3-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RpcServer.Listener.Reader can abort due to CancelledKeyException</summary>
      <description>In our production cluster(0.98), some of the requests were unacceptable because RpcServer.Listener.Reader were aborted.getReader() will return the next reader to deal with request.The implementation of getReader() as below：RpcServer.java // The method that will return the next reader to work with // Simplistic implementation of round robin for now Reader getReader() { currentReader = (currentReader + 1) % readers.length; return readers[currentReader]; }If one of the readers abort, then it will lead to fall on the reader's request will never be dealt with.Why does RpcServer.Listener.Reader abort?We add the debug log to get it.After a while, we got the following exception:2017-03-10 08:05:13,247 ERROR [RpcServer.reader=3,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: unexpectedly error in Reader(Throwable)java.nio.channels.CancelledKeyException at sun.nio.ch.SelectionKeyImpl.ensureValid(SelectionKeyImpl.java:73) at sun.nio.ch.SelectionKeyImpl.readyOps(SelectionKeyImpl.java:87) at java.nio.channels.SelectionKey.isReadable(SelectionKey.java:289) at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.doRunLoop(RpcServer.java:592) at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.run(RpcServer.java:566) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745)So, when deal with the request in reader, we should handle CanceledKeyException.----------versions 1.x and 2.0 will log and retrun when dealing with the InterruptedException in Reader#doRunLoop after HBASE-10521. It will lead to the same problem.</description>
      <version>1.3.0,1.2.4,0.98.24,2.0.0</version>
      <fixedVersion>1.4.0,1.3.3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="17803" opendate="2017-3-18 00:00:00" fixdate="2017-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>PE always re-creates table when we specify the split policy</summary>
      <description>I find this bug when i run the tests for HBASE-17623The critical code is shown below.if ((exists &amp;&amp; opts.presplitRegions != DEFAULT_OPTS.presplitRegions) || (!isReadCmd &amp;&amp; desc != null &amp;&amp; desc.getRegionSplitPolicyClassName() != opts.splitPolicy) || (!isReadCmd &amp;&amp; desc != null &amp;&amp; desc.getRegionReplication() != opts.replicas)) {</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
    </fixedFiles>
  </bug>
  <bug id="17807" opendate="2017-3-20 00:00:00" fixdate="2017-3-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>correct the value of zookeeper.session.timeout in hbase doc</summary>
      <description>I met a regionserver gc problem, and the regionserver log show me to read the dochttp://hbase.apache.org/book.html#trouble.rs.runtime.zkexpiredIf you wish to increase the session timeout, add the following to your hbase-site.xml to increase the timeout from the default of 60 seconds to 120 seconds.&lt;property&gt; &lt;name&gt;zookeeper.session.timeout&lt;/name&gt; &lt;value&gt;1200000&lt;/value&gt;&lt;/property&gt;the value should be 120000（120s) instead of 1200000(1200s）</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.troubleshooting.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="17823" opendate="2017-3-23 00:00:00" fixdate="2017-9-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Migrate to Apache Yetus Audience Annotations</summary>
      <description>Migrate from our own audience annotation handling to apache yetus' implementation.discussion thread on dev@hbase</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0-alpha-3,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-backup.src.test.java.org.apache.hadoop.hbase.backup.TestBackupDeleteRestore.java</file>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftUtilities.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftMetrics.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftHttpServlet.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.TBoundedThreadPoolServer.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.HttpAuthenticationException.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.HThreadedSelectorServerArgs.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.HbaseHandlerMetricsProxy.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.CallQueue.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftUtilities.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-spark.src.test.scala.org.apache.hadoop.hbase.spark.HBaseDStreamFunctionsSuite.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.spark.sql.datasources.hbase.Utils.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.spark.sql.datasources.hbase.HBaseTableCatalog.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.NewHBaseRDD.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.KeyFamilyQualifier.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.JavaHBaseContext.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.HBaseRDDFunctions.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.HBaseDStreamFunctions.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.HBaseContext.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.FamilyHFileWriteOptions.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.FamiliesQualifiersValues.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.DynamicLogicExpression.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.DefaultSource.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.datasources.SerializableConfiguration.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.datasources.SchemaConverters.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.datasources.NaiveEncoder.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.datasources.JavaBytesEncoder.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.datasources.HBaseTableScanRDD.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.datasources.HBaseSparkConf.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.datasources.HBaseResources.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.datasources.Bound.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.ColumnFamilyQualifierMapKeyWrapper.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.ByteArrayWrapper.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.ByteArrayComparable.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.BulkLoadPartitioner.scala</file>
      <file type="M">hbase-spark.src.main.java.org.apache.hadoop.hbase.spark.SparkSQLPushDownFilter.java</file>
      <file type="M">hbase-spark.src.main.java.org.apache.hadoop.hbase.spark.example.hbasecontext.JavaHBaseDistributedScan.java</file>
      <file type="M">hbase-spark.src.main.java.org.apache.hadoop.hbase.spark.example.hbasecontext.JavaHBaseBulkPutExample.java</file>
      <file type="M">hbase-spark.src.main.java.org.apache.hadoop.hbase.spark.example.hbasecontext.JavaHBaseBulkLoadExample.java</file>
      <file type="M">hbase-spark.src.main.java.org.apache.hadoop.hbase.spark.example.hbasecontext.JavaHBaseBulkGetExample.java</file>
      <file type="M">hbase-spark.src.main.java.org.apache.hadoop.hbase.spark.example.hbasecontext.JavaHBaseBulkDeleteExample.java</file>
      <file type="M">hbase-shell.src.test.rsgroup.org.apache.hadoop.hbase.client.rsgroup.TestShellRSGroups.java</file>
      <file type="M">hbase-shaded.pom.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZooKeeperMainServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.WALPerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestWALSplitCompressed.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.IOTestProvider.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.FaultyFSLog.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.test.LoadTestDataGeneratorWithACL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.test.LoadTestDataGenerator.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestStealJobQueue.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestIncrementingEnvironmentEdge.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsckEncryption.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestDefaultEnvironmentEdge.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.StoppableImplementation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MockServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.LoadTestDataGeneratorWithTags.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.ConstantDelayQueue.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.tool.TestSecureLoadIncrementalHFilesSplitRecovery.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.tool.TestCanaryTool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestPartialResultsFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestNamespace.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestJMXListener.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestJMXConnectorServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestHBaseOnOtherDfsCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestMobRestoreSnapshotHelper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestMobFlushSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.SnapshotTestingUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.LoadTestDataGeneratorWithVisibilityLabels.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.LabelFilteringScanLabelGenerator.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.ExpAsStringVisibilityLabelServiceImpl.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.HBaseKerberosUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.HadoopSecurityEnabledUserProviderForTesting.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestCellACLWithMultipleVersions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestCellACLs.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationTrackerZKImpl.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationStateZKImpl.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestSourceFSConfigurationProvider.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestSequenceIdAccounting.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestMetricsWAL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestAsyncLogRolling.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRSStatusServlet.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRSKilledWhenInitializing.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRpcSchedulerFactory.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerOnlineConfigChange.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionIncrement.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestQosFunction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestParallelPut.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMultiVersionConcurrencyControlBasic.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMultiVersionConcurrencyControl.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsTableAggregate.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionReplayEvents.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestFlushRegionEntry.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestFailedAppendAndSync.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.KeyValueScanFixture.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.DelegatingKeyValueScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestQuotaObserverChore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.SpaceQuotaSnapshotNotifierForTest.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.SpaceQuotaHelperForTests.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MiniHBaseCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestSplitLogManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterQosFunction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitorInMemoryStates.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestActiveMasterManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestTableDescriptorModificationFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMasterFailoverWithProcedures.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.cleaner.TestReplicationHFileCleaner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.cleaner.TestLogsCleaner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.cleaner.TestHFileLinkCleaner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.LoadBalancerPerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.assignment.MockMasterServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.assignment.AssignmentTestingUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestRpcServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestRpcClientLeaks.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestProtobufRpcServiceImpl.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestCallRunner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestBufferChain.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.DelegatingRpcScheduler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.TestByteBufferOutputStream.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestSeekTo.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileInlineToRootChunkConversion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestChecksum.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestBlockCacheReporting.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TagUsage.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.bucket.TestFileMmapEngine.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestChangingEncoding.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.http.conf.TestConfServlet.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HFilePerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.FilterAllFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.favored.TestStartcodeAgnosticServerName.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.errorhandling.TestForeignExceptionDispatcher.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverStacking.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverBypass.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestOpenTableInCoprocessor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestNegativeMemstoreSizeWithSlowCoprocessor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorInterface.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorHost.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.codec.TestCellMessageCodec.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.codec.CodecPerformance.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSplitOrMergeStatus.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestResultSizeEstimation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestPutDeleteEtcCellIteration.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMobSnapshotCloneIndependence.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMetaCache.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestIncrementFromClientSideWithCoprocessor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestIllegalTableDescriptor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHBaseAdminNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSideWithCoprocessor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSideNoCodec.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestClientScannerRPCTimeout.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestCheckAndMutate.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTableGetMultiThreadedWithEagerCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTableGetMultiThreadedWithBasicCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTableAdminApi.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncSnapshotAdminApi.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncProcedureAdminApi.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncClusterAdminApi2.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncAdminBuilder.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.SimpleScanResultConsumer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.SimpleRawScanResultConsumer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.ColumnCountOnRowFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.example.TestZooKeeperTableArchiveClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperMainServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKSplitLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKServerTool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.SplitOrMergeTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.RegionServerTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.RecoveringRegionWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.MasterMaintenanceModeTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.LoadBalancerTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.DrainingServerTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.DeletionListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ClusterStatusTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ZKNamespaceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALPrettyPrinter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALKey.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALEdit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WAL.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.RegionGroupingProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.NamespaceGroupingStrategy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.FSHLogProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.DisabledWALProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.BoundedGroupingStrategy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.AsyncFSWALProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.AbstractFSWALProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ZKDataMigrator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.StealJobQueue.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ServerCommandLine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RowColBloomContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RowBloomContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionSplitCalculator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionMover.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ProtoUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.NettyEventLoopGroupConfig.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.MunkresAssignment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.MultiHConnection.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ModifyRegionUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ManualEnvironmentEdge.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.LeaseNotRecoveredException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.KeyRange.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.JvmVersion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.JvmPauseMonitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.JVMClusterUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.IdReadWriteLock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.IdLock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HttpServerUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.hbck.ReplicationChecker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.hbck.OfflineMetaRepair.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.hbck.HFileCorruptionChecker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsckRepair.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseConfTool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HashedBytes.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSVisitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSTableDescriptors.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSRegionScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSMapRUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSHDFSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FileStatusFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.EncryptionTest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.DirectMemoryUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ConnectionCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ConfigurationUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.CompressionTest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.CollectionBackedScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.CancelableProgressable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.BloomFilterWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.BloomFilterUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.BloomFilterFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.BloomFilterChunk.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.BloomFilterBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.BloomFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.BloomContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.AbstractFileStatusFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.LoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.Canary.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.TableDescriptors.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.SplitLogTask.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.SplitLogCounters.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotManifestV2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotManifestV1.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotManifest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.Server.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.ZKVisibilityLabelWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityScanDeleteTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityLabelServiceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityLabelService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityLabelsCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityLabelOrdinalProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityLabelFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityExpEvaluator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.SimpleScanLabelGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.ScanLabelGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.ParseException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.FeedUserAuthScanLabelGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.expression.Operator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.expression.NonLeafExpressionNode.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.expression.LeafExpressionNode.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.expression.ExpressionNode.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.ExpressionParser.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.ExpressionExpander.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.EnforcingScanLabelGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.DefinedSetFilterScanLabelGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.DefaultVisibilityLabelServiceImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.ZKSecretWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.TokenUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.TokenProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.FsDelegationToken.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.AuthenticationTokenSecretManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.AuthenticationKey.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.SecurityUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.HBaseSaslRpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.HBasePolicyProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.ZKPermissionWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.TableAuthManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.CoprocessorWhitelistMasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AuthResult.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlLists.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.WALEntryFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.WALCellFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.SystemTableWALEntryFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.ScopeWALEntryFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.ReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.WALEntryStream.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.SourceFSConfigurationProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationThrottler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceShipper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationLoad.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.Replication.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.RecoveredReplicationSourceWALReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.RecoveredReplicationSourceShipper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.RecoveredReplicationSource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.MetricsSource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.MetricsSink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.HFileReplicator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.DefaultSourceFSConfigurationProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.NamespaceTableCfWALEntryFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.master.TableCFsUpdater.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.master.ReplicationHFileCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.HBaseReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.ClusterMarkingEntryFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.ChainWALEntryFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.BaseWALEntryFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.BaseReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.RegionStateListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALEditsReplaySink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALCellCodec.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALActionsListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SyncFuture.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SequenceIdAccounting.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SecureWALCellCodec.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SecureAsyncProtobufLogWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.RingBufferTruck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.ReaderBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.MetricsWALEditsReplay.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.MetricsWAL.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSWALEntry.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.DamagedWALException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.Compressor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.CompressionContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AsyncProtobufLogWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AbstractProtobufLogWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.VersionedSegmentsList.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.TimeRangeTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.throttle.ThroughputControlUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.throttle.ThroughputController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.throttle.PressureAwareThroughputController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.throttle.PressureAwareFlushThroughputController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.throttle.PressureAwareCompactionThroughputController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.throttle.NoLimitThroughputController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.throttle.FlushThroughputControllerFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.throttle.CompactionThroughputControllerFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StripeStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StripeStoreFileManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StripeStoreEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StripeStoreConfig.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StripeMultiFileWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFlushContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StorefileRefresherChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileComparators.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreConfigInformation.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitLogWorker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.snapshot.RegionServerSnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.snapshot.FlushSnapshotSubprocedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SimpleRpcSchedulerFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ShutdownHook.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ShipperListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Shipper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ServerNonceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SequenceId.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SegmentScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SegmentFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Segment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SecureBulkLoadManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ScanType.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ScannerIdGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ScannerContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ScanInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSStatusServlet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSDumpServlet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RpcSchedulerFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RowTooBigException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RowProcessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ReversedStoreScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ReversedRegionScannerImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ReversedMobStoreScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ReversedKeyValueHeap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ReplicationSourceService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ReplicationSinkService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ReplicationService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionUnassigner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServicesForStores.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerAccounting.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionMergeRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Region.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.UserScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.StripeCompactionScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.ScanWildcardColumnTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.ScanDeleteTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.RawScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.NormalUserScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.NewVersionBehaviorTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.MinorCompactionScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.MajorCompactionScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.IncludeAllCompactionQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.ExplicitColumnTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.DropDeletesCompactionScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.DeleteTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.CompactionScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.ColumnTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.ColumnCount.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.OperationStatus.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.OnlineRegions.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.OnheapChunk.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.OffheapChunk.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.NoTagByteBufferChunkCell.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.NoOpHeapMemoryTuner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.NonReversedNonLazyKeyValueScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.NonLazyKeyValueScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.NoLimitScannerContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MutableSegment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MultiRowMutationProcessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MobStoreScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MobReferenceOnlyFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MiniBatchOperationInProgress.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregateImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsHeapMemoryManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreSnapshot.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemstoreSize.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreSegmentsIterator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreMergerSegmentsIterator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreLAB.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreCompactorSegmentsIterator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.LogRoller.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Leases.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.LeaseListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.LastSequenceId.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.KeyValueScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.KeyValueHeap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.KeyPrefixRegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.InternalScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.InternalScan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ImmutableSegment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ImmutableMemStoreLAB.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HMobStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HeapMemoryTuner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HeapMemoryManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.WALSplitterHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.RegionReplicaFlushHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.ParallelSeekHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenPriorityRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenMetaHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseMetaHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.FlushType.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.FlushRequestListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.FlushRequester.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.FlushPolicyFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.FlushPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.FlushNonSloppyStoresFirstPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.FlushLargeStoresPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.FlushAllStoresPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.FlushAllLargeStoresPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.FifoRpcSchedulerFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.FavoredNodesForRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DisabledRegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DelimitedKeyPrefixRegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultStoreFileManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultStoreEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultMemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultHeapMemoryTuner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DateTieredStoreEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DateTieredMultiFileWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CSLMImmutableSegment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompositeImmutableSegment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.StripeCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.StripeCompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.SortedCompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.RatioBasedCompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.OffPeakHours.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.FIFOCompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.DateTieredCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.DateTieredCompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CurrentHourProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.Compactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionWindowFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionWindow.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionProgress.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.AbstractMultiOutputCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactionRequestor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactionPipeline.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactingMemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactedHFilesDischarger.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactedHFilesDischargeHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ChunkCreator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Chunk.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ChangedReadersObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CellSink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CellSet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CellFlatMap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CellChunkMap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CellChunkImmutableSegment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CellArrayMap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CellArrayImmutableSegment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ByteBufferChunkCell.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.BusyRegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.BaseRowProcessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.AnnotationReadingPriorityFunction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.AbstractMultiFileWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.AbstractMemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.UserQuotaState.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.TimeBasedLimiter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.TableQuotaSnapshotStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.SpaceViolationPolicyEnforcementFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.SpaceViolationPolicyEnforcement.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.SpaceQuotaSnapshotNotifierFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.SpaceQuotaSnapshotNotifier.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.SpaceQuotaRefresherChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.SpaceLimitingException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.SnapshotQuotaObserverChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.RegionServerSpaceQuotaManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.RegionServerRpcQuotaManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.RateLimiter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaState.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaSnapshotStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaObserverChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaLimiterFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaLimiter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.policies.NoWritesViolationPolicyEnforcement.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.policies.NoWritesCompactionsViolationPolicyEnforcement.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.policies.NoInsertsViolationPolicyEnforcement.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.policies.DisableTableViolationPolicyEnforcement.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.policies.DefaultViolationPolicyEnforcement.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.policies.AbstractViolationPolicyEnforcement.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.OperationQuota.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.NoopQuotaLimiter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.NoopOperationQuota.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.NamespaceQuotaSnapshotStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.MasterSpaceQuotaObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.MasterQuotaManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.FixedIntervalRateLimiter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.FileSystemUtilizationChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.DefaultOperationQuota.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.AverageIntervalRateLimiter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.ActivePolicyEnforcement.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.ReplicationProtbufUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureMemberRpcs.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureCoordinator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.SubprocedureFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.RegionServerProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ProcedureMemberRpcs.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ProcedureMember.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ProcedureManagerHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ProcedureCoordinatorRpcs.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ProcedureCoordinator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.Procedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.MasterProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.flush.RegionServerFlushTableProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.flush.MasterFlushTableProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.flush.FlushTableSubprocedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.namespace.NamespaceTableAndRegionInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.namespace.NamespaceStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.namespace.NamespaceAuditor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.ThreadMonitoring.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.TaskMonitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.StateDumpServlet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.MonitoredTask.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.MonitoredRPCHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.MemoryBoundedLogMessageBuffer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.LogMonitoring.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.MobUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.MobStoreEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.MobFileName.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.MobFileCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.MobFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.MobConstants.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.MobCacheConfig.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.ExpiredMobFileCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.DefaultMobStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.DefaultMobStoreCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.compactions.PartitionedMobCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.compactions.PartitionedMobCompactionRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.compactions.MobCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.compactions.MobCompactionRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.CachedMobFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableNamespaceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.MasterSnapshotVerifier.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.EnabledTableSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.DisabledTableSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SnapshotSentinel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SnapshotOfRegionAssignmentFromMeta.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.ReplicationManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionPlan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionPlacementMaintainer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RackManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.TruncateTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.TableProcedureInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ServerProcedureInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ServerCrashException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.RestoreSnapshotProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ProcedureSyncWait.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ProcedurePrepareLatch.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ProcedureDescriber.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureConstants.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterDDLOperationHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.EnableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DisableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CreateNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CloneSnapshotProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.AddColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.AbstractStateMachineTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.AbstractStateMachineRegionProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.AbstractStateMachineNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.NoSuchProcedureException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.normalizer.SplitNormalizationPlan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.normalizer.SimpleRegionNormalizer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.normalizer.RegionNormalizerFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.normalizer.RegionNormalizerChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.normalizer.RegionNormalizer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.normalizer.MergeNormalizationPlan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.normalizer.EmptyNormalizationPlan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MobCompactionChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MetricsMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterWalManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterStatusServlet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterMobCompactionThread.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterMetaBootstrap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterDumpServlet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.locking.LockProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.locking.LockManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.LoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMasterCommandLine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ExpiredMobFileCleanerChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.DeadServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ClusterStatusPublisher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ClusterSchemaServiceImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ClusterSchemaService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ClusterSchemaException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ClusterSchema.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.ReplicationZKNodeCleanerChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.ReplicationZKNodeCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.ReplicationMetaCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.LogCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.HFileLinkCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.HFileCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.FileCleanerDelegate.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.BaseLogCleanerDelegate.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.BaseHFileCleanerDelegate.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.SimpleLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.ServerAndLoad.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.RegionLocationFinder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.LoadBalancerFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.ClusterStatusChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BalancerRegionLoad.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BalancerChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.Util.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.UnassignProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.SplitTableRegionProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.RegionTransitionProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.RegionStateStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.MoveRegionProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.MergeTableRegionsProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.GCRegionProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.GCMergedRegionsProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.FailedRemoteDispatchException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.AssignProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentVerificationReport.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ActiveMasterManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.LocalHBaseCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleServerRpcConnection.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleServerCall.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcServerResponder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.ServerRpcConnection.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.ServerCall.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServerInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServerFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcSchedulerContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcResponse.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcExecutor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcCallContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcCallback.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcCall.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.QosPriority.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.PriorityFunction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.NettyServerRpcConnection.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.NettyServerCall.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.NettyRpcServerResponseEncoder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.NettyRpcServerRequestDecoder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.NettyRpcServerPreambleHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.NettyRpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseRPCErrorHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.FastPathBalancedQueueRpcExecutor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.CallRunner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.BufferChain.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.BalancedQueueRpcExecutor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.WritableWithSize.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.WALLink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.util.MemorySizeUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.Reference.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.ResizableBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.NoOpDataBlockEncoder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruCachedBlockQueue.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruCachedBlock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.InvalidHFileException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.InlineBlockWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.InclusiveCombinedBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileWriterImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CorruptHFileException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CompoundBloomFilterWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CompoundBloomFilterBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CompoundBloomFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.ChecksumUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheStats.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CachedBlock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheableDeserializerIdManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheableDeserializer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.Cacheable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.UniqueIndexMap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.IOEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.FileMmapEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.FileIOEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.CacheFullException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.CachedEntryQueue.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.ByteBufferIOEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketCacheStats.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocatorException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.BlockCacheUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.BlockCachesIterator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.BlockCacheKey.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.BlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.HFileLink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.HalfStoreFileReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.FSDataInputStreamWrapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.FileLink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputSaslHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutput.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.asyncfs.AsyncFSOutputHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.asyncfs.AsyncFSOutput.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.ServerConfigurationKeys.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.package-info.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.NoCacheFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.log.LogLevel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.lib.StaticUserWebFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.lib.package-info.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.InfoServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.HttpServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.HttpConfig.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.conf.ConfServlet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.ClickjackingPreventionFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.AdminAuthorizedServlet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HDFSBlocksDistribution.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.favored.StartcodeAgnosticServerName.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.favored.FavoredNodesPromoter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.favored.FavoredNodesPlan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.favored.FavoredNodesManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.favored.FavoredNodeLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.favored.FavoredNodeAssignmentHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.executor.ExecutorService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.executor.EventHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.errorhandling.TimeoutExceptionInjector.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.errorhandling.TimeoutException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.errorhandling.ForeignExceptionSnare.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.errorhandling.ForeignExceptionListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.errorhandling.ForeignException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.WALObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.WALCoprocessorEnvironment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.SingletonCoprocessorService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionServerObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.ObserverContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MetricsCoprocessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.EndpointObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BulkLoadObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseRowProcessorEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.SplitLogWorkerCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.SplitLogManagerCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.BaseCoordinatedStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.CoordinatedStateManagerFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.CoordinatedStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.constraint.Constraints.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.constraint.ConstraintProcessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.constraint.ConstraintException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.constraint.Constraint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.constraint.BaseConstraint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.conf.PropagatingConfigurationObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.conf.ConfigurationObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.conf.ConfigurationManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.codec.MessageCodec.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.VersionInfoUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.TableSnapshotScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.locking.LockServiceClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.locking.EntityLock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HTableWrapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.coprocessor.RowProcessorClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.CoprocessorHConnection.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ClientSideRegionScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.HFileArchiver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.FailedArchiveException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.example.ZKTableArchiveClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.example.TableHFileArchiveTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.example.LongTermArchivingHFileCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.example.HFileArchiveManager.java</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-rsgroup.src.test.java.org.apache.hadoop.hbase.rsgroup.VerifyingRSGroupAdminClient.java</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.Utility.java</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupProtobufUtil.java</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupInfoManagerImpl.java</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupInfoManager.java</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupBasedLoadBalancer.java</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupAdminServer.java</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupAdminEndpoint.java</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupAdminClient.java</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupAdmin.java</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupableBalancer.java</file>
      <file type="M">hbase-rsgroup.pom.xml</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.TestNamespacesResource.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.VersionResource.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.TableScanResource.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.TableResource.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.StorageClusterVersionResource.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.StorageClusterStatusResource.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.SchemaResource.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.ScannerResultGenerator.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.ScannerResource.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.ScannerInstanceResource.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.RowSpec.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.RowResultGenerator.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.RowResource.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.RootResource.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.ResultGenerator.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.RESTServletContainer.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.RESTServlet.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.RESTServer.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.ResourceBase.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.RegionsResource.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.provider.producer.ProtobufMessageBodyProducer.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.provider.producer.PlainTextMessageBodyProducer.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.provider.JAXBContextResolver.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.provider.consumer.ProtobufMessageBodyConsumer.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.ProtobufMessageHandler.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.NamespacesResource.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.NamespacesInstanceResource.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.MultiRowResource.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.VersionModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.TableSchemaModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.TableRegionModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.TableModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.TableListModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.TableInfoModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.StorageClusterVersionModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.StorageClusterStatusModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.ScannerModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.RowModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.NamespacesModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.NamespacesInstanceModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.ColumnSchemaModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.CellSetModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.CellModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.MetricsREST.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.filter.RestCsrfPreventionFilter.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.filter.GZIPResponseWrapper.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.filter.GZIPResponseStream.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.filter.GZIPRequestWrapper.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.filter.GZIPRequestStream.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.filter.GzipFilter.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.ExistsResource.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.Constants.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.client.Response.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteAdmin.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.client.Cluster.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.client.Client.java</file>
      <file type="M">hbase-rest.pom.xml</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.TableBasedReplicationQueuesImpl.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.TableBasedReplicationQueuesClientImpl.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationTrackerZKImpl.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationTracker.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationTableBase.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationStateZKBase.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueuesZKImpl.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueuesClientZKImpl.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueuesClientArguments.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueuesClient.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueuesArguments.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueues.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueueInfo.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeerZKImpl.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeersZKImpl.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeers.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeerConfigListener.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeer.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationListener.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationFactory.java</file>
      <file type="M">hbase-replication.pom.xml</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.util.ByteStringer.java</file>
      <file type="M">hbase-protocol.pom.xml</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.util.ForeignExceptionUtil.java</file>
      <file type="M">hbase-protocol-shaded.pom.xml</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.TestProcedureToString.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.TestProcedureSuspended.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.TestProcedureReplayOrder.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.TestProcedureRecovery.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.TestProcedureNonce.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.TestProcedureExecution.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALPerformanceEvaluation.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALLoaderPerformanceEvaluation.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.util.StringUtils.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.util.DelayedUtil.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.util.ByteSlot.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.TwoPhaseProcedure.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALPrettyPrinter.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALFormatReader.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALFormat.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALFile.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.CorruptedWALProcedureStoreException.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.ProcedureStoreTracker.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.ProcedureStoreBase.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.ProcedureStore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.StateMachineProcedure.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.SimpleProcedureScheduler.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.SequentialProcedure.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.RootProcedureState.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.RemoteProcedureException.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.RemoteProcedureDispatcher.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureYieldException.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureUtil.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureSuspendedException.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureScheduler.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureInMemoryChore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureExecutor.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureException.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureEvent.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureDeque.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureAbortedException.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.Procedure.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.OnePhaseProcedure.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.LockType.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.LockedResourceType.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.LockedResource.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.LockAndQueue.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.BadProcedureException.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.java</file>
      <file type="M">hbase-procedure.pom.xml</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.util.vint.UVLongTool.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.util.vint.UVIntTool.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.util.vint.UFIntTool.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.util.byterange.impl.ByteRangeTreeSet.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.util.byterange.impl.ByteRangeHashSet.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.util.byterange.ByteRangeSet.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.scanner.ReversibleCellScanner.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.scanner.CellSearcher.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.scanner.CellScannerPosition.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeCodec.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeBlockMeta.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.tokenize.TokenizerRowSearchResult.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.tokenize.TokenizerRowSearchPosition.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.tokenize.TokenizerNode.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.tokenize.Tokenizer.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.row.RowSectionWriter.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.row.RowNodeWriter.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.PrefixTreeEncoder.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.other.LongEncoder.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.other.ColumnNodeType.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.other.CellTypeEncoder.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.EncoderPoolImpl.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.EncoderPool.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.EncoderFactory.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.column.ColumnSectionWriter.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.column.ColumnNodeWriter.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.timestamp.TimestampDecoder.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.timestamp.MvccVersionDecoder.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.row.RowNodeReader.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeCell.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArraySearcher.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayReversibleScanner.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.DecoderFactory.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.column.ColumnReader.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.column.ColumnNodeReader.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.ArraySearcherPool.java</file>
      <file type="M">hbase-prefix-tree.pom.xml</file>
      <file type="M">hbase-metrics.src.test.java.org.apache.hadoop.hbase.metrics.impl.TestTimerImpl.java</file>
      <file type="M">hbase-metrics.src.test.java.org.apache.hadoop.hbase.metrics.impl.TestGauge.java</file>
      <file type="M">hbase-metrics.src.test.java.org.apache.hadoop.hbase.metrics.impl.TestDropwizardMeter.java</file>
      <file type="M">hbase-metrics.src.test.java.org.apache.hadoop.hbase.metrics.impl.TestCounterImpl.java</file>
      <file type="M">hbase-metrics.src.main.java.org.apache.hadoop.hbase.metrics.impl.TimerImpl.java</file>
      <file type="M">hbase-metrics.src.main.java.org.apache.hadoop.hbase.metrics.impl.RefCountingMap.java</file>
      <file type="M">hbase-metrics.src.main.java.org.apache.hadoop.hbase.metrics.impl.package-info.java</file>
      <file type="M">hbase-metrics.src.main.java.org.apache.hadoop.hbase.metrics.impl.MetricRegistryImpl.java</file>
      <file type="M">hbase-metrics.src.main.java.org.apache.hadoop.hbase.metrics.impl.MetricRegistryFactoryImpl.java</file>
      <file type="M">hbase-metrics.src.main.java.org.apache.hadoop.hbase.metrics.impl.MetricRegistriesImpl.java</file>
      <file type="M">hbase-metrics.src.main.java.org.apache.hadoop.hbase.metrics.impl.HistogramImpl.java</file>
      <file type="M">hbase-metrics.src.main.java.org.apache.hadoop.hbase.metrics.impl.FastLongHistogram.java</file>
      <file type="M">hbase-metrics.src.main.java.org.apache.hadoop.hbase.metrics.impl.DropwizardMeter.java</file>
      <file type="M">hbase-metrics.src.main.java.org.apache.hadoop.hbase.metrics.impl.CounterImpl.java</file>
      <file type="M">hbase-metrics.pom.xml</file>
      <file type="M">hbase-metrics-api.src.main.java.org.apache.hadoop.hbase.metrics.Timer.java</file>
      <file type="M">hbase-metrics-api.src.main.java.org.apache.hadoop.hbase.metrics.Snapshot.java</file>
      <file type="M">hbase-metrics-api.src.main.java.org.apache.hadoop.hbase.metrics.PackageMarker.java</file>
      <file type="M">hbase-metrics-api.src.main.java.org.apache.hadoop.hbase.metrics.MetricSet.java</file>
      <file type="M">hbase-metrics-api.src.main.java.org.apache.hadoop.hbase.metrics.MetricRegistryInfo.java</file>
      <file type="M">hbase-metrics-api.src.main.java.org.apache.hadoop.hbase.metrics.MetricRegistryFactory.java</file>
      <file type="M">hbase-metrics-api.src.main.java.org.apache.hadoop.hbase.metrics.MetricRegistry.java</file>
      <file type="M">hbase-metrics-api.src.main.java.org.apache.hadoop.hbase.metrics.MetricRegistriesLoader.java</file>
      <file type="M">hbase-metrics-api.src.main.java.org.apache.hadoop.hbase.metrics.MetricRegistries.java</file>
      <file type="M">hbase-metrics-api.src.main.java.org.apache.hadoop.hbase.metrics.Metric.java</file>
      <file type="M">hbase-metrics-api.src.main.java.org.apache.hadoop.hbase.metrics.Meter.java</file>
      <file type="M">hbase-metrics-api.src.main.java.org.apache.hadoop.hbase.metrics.Histogram.java</file>
      <file type="M">hbase-metrics-api.src.main.java.org.apache.hadoop.hbase.metrics.Gauge.java</file>
      <file type="M">hbase-metrics-api.src.main.java.org.apache.hadoop.hbase.metrics.Counter.java</file>
      <file type="M">hbase-metrics-api.pom.xml</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.util.LoadTestTool.java</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.snapshot.TestMobSecureExportSnapshot.java</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.ScanPerformanceEvaluation.java</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.util.MapreduceDependencyClasspathTool.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.snapshot.ExportSnapshot.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.regionserver.CompactionTool.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapred.TableSplit.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapred.TableReduce.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapred.TableRecordReaderImpl.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapred.TableRecordReader.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapred.TableOutputFormat.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapred.TableMapReduceUtil.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapred.TableMap.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapred.TableInputFormatBase.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapred.TableInputFormat.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapred.RowCounter.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapred.MultiTableSnapshotInputFormat.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapred.IdentityTableReduce.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapred.IdentityTableMap.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapred.HRegionPartitioner.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapred.GroupingTableMap.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapred.Driver.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.WALPlayer.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.WALInputFormat.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.VisibilityExpressionResolver.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.TsvImporterTextMapper.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.TsvImporterMapper.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.TextSortReducer.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.TableSplit.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.TableReducer.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.TableRecordReader.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.TableOutputFormat.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.TableOutputCommitter.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapper.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormat.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.SimpleTotalOrderPartitioner.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.RowCounter.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.ResultSerialization.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.RegionSizeCalculator.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.PutSortReducer.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.PutCombiner.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.MutationSerialization.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.MultiTableSnapshotInputFormatImpl.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.MultiTableSnapshotInputFormat.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.MultiTableOutputFormat.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.MultiTableInputFormatBase.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.MultiTableInputFormat.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.MultiTableHFileOutputFormat.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.KeyValueSortReducer.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.KeyValueSerialization.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.ImportTsv.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.Import.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.IdentityTableReducer.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.IdentityTableMapper.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.HRegionPartitioner.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.HFileInputFormat.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.GroupingTableMapper.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.ExportUtils.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.Export.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.Driver.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.DefaultVisibilityExpressionResolver.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.CopyTable.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.CellCreator.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.CellCounter.java</file>
      <file type="M">hbase-mapreduce.pom.xml</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.StripeCompactionsPerformanceEvaluation.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.HBaseClusterManager.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.DistributedHBaseCluster.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.ClusterManager.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.RestartRandomZKNodeAction.java</file>
      <file type="M">hbase-hadoop2-compat.src.test.java.org.apache.hadoop.hbase.zookeeper.TestMetricsZooKeeperSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.util.MetricSampleQuantiles.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.util.MetricQuantile.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.MutableTimeHistogram.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.MutableSizeHistogram.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.MutableRangeHistogram.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.MutableHistogram.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.MetricsExecutorImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.DynamicMetricsRegistry.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.impl.JmxCacheBuster.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.zookeeper.MetricsZooKeeperSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.thrift.MetricsThriftServerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.thrift.MetricsThriftServerSourceFactoryImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.rest.MetricsRESTSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.replication.regionserver.MetricsReplicationSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.wal.MetricsWALSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.wal.MetricsEditsReplaySourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsTableSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsTableAggregateSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceFactoryImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionAggregateSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsHeapMemoryManagerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.metrics.MetricsInfoImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.metrics.MBeanSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.metrics.Interns.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.metrics.BaseSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsSnapshotSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterSourceFactoryImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterQuotaSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterQuotaSourceFactoryImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterProcSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterProcSourceFactoryImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterFilesystemSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsAssignmentManagerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.balancer.MetricsStochasticBalancerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.balancer.MetricsBalancerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.mapreduce.JobUtil.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceFactoryImpl.java</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-hadoop-compat.src.test.java.org.apache.hadoop.hbase.zookeeper.TestMetricsZooKeeperSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.zookeeper.MetricsZooKeeperSource.java</file>
      <file type="M">hbase-external-blockcache.src.main.java.org.apache.hadoop.hbase.io.hfile.MemcachedBlockCache.java</file>
      <file type="M">hbase-endpoint.src.test.java.org.apache.hadoop.hbase.regionserver.SecureBulkLoadEndpointClient.java</file>
      <file type="M">hbase-endpoint.src.test.java.org.apache.hadoop.hbase.coprocessor.ColumnAggregationEndpoint.java</file>
      <file type="M">hbase-endpoint.src.test.java.org.apache.hadoop.hbase.client.TestRpcControllerFactory.java</file>
      <file type="M">hbase-endpoint.src.main.java.org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint.java</file>
      <file type="M">hbase-endpoint.src.main.java.org.apache.hadoop.hbase.coprocessor.Export.java</file>
      <file type="M">hbase-endpoint.src.main.java.org.apache.hadoop.hbase.coprocessor.AggregateImplementation.java</file>
      <file type="M">hbase-endpoint.src.main.java.org.apache.hadoop.hbase.client.coprocessor.AsyncAggregationClient.java</file>
      <file type="M">hbase-endpoint.src.main.java.org.apache.hadoop.hbase.client.coprocessor.AggregationHelper.java</file>
      <file type="M">hbase-endpoint.src.main.java.org.apache.hadoop.hbase.client.coprocessor.AggregationClient.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.Waiter.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TimeOffsetEnvironmentEdge.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestVersionInfo.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestEnvironmentEdgeManager.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestByteRangeWithKVSerialization.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.RedundantKVGenerator.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.LoadTestKVGenerator.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.AbstractHBaseToolTest.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.types.TestCopyOnWriteMaps.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestCellUtil.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestCellComparator.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.HBaseCommonTestingUtility.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.codec.TestKeyValueCodecWithTags.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.codec.TestKeyValueCodec.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.codec.TestCellCodecWithTags.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.codec.TestCellCodec.java</file>
      <file type="M">hbase-common.src.saveVersion.sh</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKConfig.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.WeakObjectPool.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.VersionInfo.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.UnsafeAvailChecker.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.UnsafeAccess.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Triple.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Threads.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Strings.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.SoftObjectPool.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Sleeper.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.SimplePositionedMutableByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.SimplePositionedByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.SimpleMutableByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.SimpleByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.RowColBloomHashKey.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.RowBloomHashKey.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.RetryCounterFactory.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.RetryCounter.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ReflectionUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ReadOnlyByteRangeException.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.PrettyPrinter.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.PositionedByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.PairOfSameType.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Pair.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.OrderedBytes.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Order.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ObjectPool.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ObjectIntPair.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.NonceKey.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.MurmurHash3.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.MurmurHash.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Methods.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.MD5Hash.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.KeyLocker.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.JVM.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.JRubyFormat.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.JenkinsHash.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.IterableUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.IncrementingEnvironmentEdge.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ImmutableByteArray.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.HasThread.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.HashKey.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Hash.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ExceptionUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.EnvironmentEdgeManager.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.EnvironmentEdge.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.DynamicClassLoader.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.DrainBarrier.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.DNS.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.DefaultEnvironmentEdge.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Counter.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.CoprocessorClassLoader.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ConcatenatedLists.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.CollectionUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ClassSize.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ClassLoaderBase.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Classes.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ChecksumType.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.CellHashKey.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Bytes.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteRangeUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteBufferUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteBufferArray.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteBufferAllocator.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteArrayHashKey.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.BoundedCompletionService.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Base64.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.AvlUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.AtomicUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ArrayUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Addressing.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.AbstractPositionedByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.AbstractHBaseTool.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.AbstractByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.Union4.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.Union3.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.Union2.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.TerminatedWrapper.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.StructIterator.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.StructBuilder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.Struct.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawStringTerminated.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawStringFixedLength.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawString.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawShort.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawLong.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawInteger.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawFloat.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawDouble.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawBytesTerminated.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawBytesFixedLength.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawBytes.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawByte.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.PBType.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedString.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedNumeric.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedInt8.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedInt64.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedInt32.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedInt16.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedFloat64.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedFloat32.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedBytesBase.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedBlobVar.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedBlob.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.FixedLengthWrapper.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.DataType.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.CopyOnWriteArrayMap.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.trace.SpanReceiverHost.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.trace.HBaseHTraceConfiguration.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.TagUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.TagType.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.Tag.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.TableName.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.Stoppable.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.SizeCachedNoTagsKeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.SizeCachedKeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.SettableTimestamp.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.SettableSequenceId.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ServiceNotRunningException.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ServerName.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.security.UserProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.security.User.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.security.Superusers.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ScheduledChore.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupInfo.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ProcedureState.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.NoTagsKeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.NoTagsByteBufferKeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.nio.SingleByteBuff.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.nio.MultiByteBuff.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.nio.ByteBuff.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.net.Address.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.NamespaceDescriptor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.MetaMutationAnnotation.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValueUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValueTestUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValueBuilder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.JitterScheduledThreadPoolExecutorImpl.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.util.StreamUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.util.LRUDictionary.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.util.Dictionary.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.TimeRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.TagCompressionContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.SizedCellScanner.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.LimitInputStream.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.ImmutableBytesWritable.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileContextBuilder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.hfile.BlockType.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.HeapSize.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.hadoopbackport.ThrottledInputStream.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.RowIndexSeekerV1.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.RowIndexEncoderV1.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.RowIndexCodecV1.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.PrefixKeyDeltaEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.NoneEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.HFileBlockEncodingContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.HFileBlockDefaultEncodingContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.HFileBlockDefaultDecodingContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.HFileBlockDecodingContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.FastDiffDeltaEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.EncodingState.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.EncoderBufferTooSmallException.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.EncodedDataBlock.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.DiffKeyDeltaEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.DataBlockEncoding.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.DataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.CopyKeyDataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.CompressionState.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.AbstractDataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.KeyStoreKeyProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.KeyProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.Encryptor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.Encryption.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.DefaultCipherProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.Decryptor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.CryptoCipherProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.Context.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.CipherProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.Cipher.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.aes.CryptoAES.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.aes.CommonsCryptoAESEncryptor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.aes.CommonsCryptoAESDecryptor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.aes.CommonsCryptoAES.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.aes.AESEncryptor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.aes.AESDecryptor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.aes.AES.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.compress.ReusableStreamGzipCodec.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.compress.Compression.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.CellOutputStream.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.ByteBuffInputStream.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.ByteBufferWriterOutputStream.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.ByteBufferWriterDataOutputStream.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.ByteBufferWriter.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.ByteBufferPool.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.ByteBufferOutputStream.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.ByteBufferListOutputStream.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.ByteBufferInputStream.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.ByteArrayOutputStream.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.IndividualBytesFieldCellBuilder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.IndividualBytesFieldCell.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HBaseIOException.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HBaseInterfaceAudience.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HBaseConfiguration.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.filter.ByteArrayComparable.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ExtendedCellBuilderImpl.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ExtendedCellBuilderFactory.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ExtendedCellBuilder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ExtendedCell.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.exceptions.UnexpectedStateException.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.exceptions.TimeoutIOException.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.exceptions.IllegalArgumentIOException.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.exceptions.HBaseException.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.exceptions.DeserializationException.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CompoundConfiguration.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.KeyValueCodecWithTags.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.KeyValueCodec.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.CodecException.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.Codec.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.CellCodecWithTags.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.CellCodec.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.BaseEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.BaseDecoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ChoreService.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellScanner.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellScannable.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellComparator.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellBuilderType.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellBuilderFactory.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellBuilder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.Cell.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ByteBufferTag.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ByteBufferKeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ByteBufferKeyOnlyKeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ByteBufferCell.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.BaseConfigurable.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.backup.BackupType.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.AuthUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.AsyncConsoleAppender.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ArrayBackedTag.java</file>
      <file type="M">hbase-common.pom.xml</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.zookeeper.TestMetricsZooKeeper.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.TestInterfaceAudienceAnnotations.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.quotas.TestQuotaFilter.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.exceptions.TestClientExceptionsUtil.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestProcedureFuture.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestIncrement.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestImmutableHTableDescriptor.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestImmutableHColumnDescriptor.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestClientExponentialBackoff.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestAttributes.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperNodeTracker.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperMetricsListener.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperListener.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZNodePaths.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKLeaderManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKClusterId.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZkAclReset.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.MetricsZooKeeper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.MetaTableLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.MasterAddressTracker.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.HQuorumPeer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.EmptyWatcher.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ZooKeeperConnectionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.YouAreDeadException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.util.Writables.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.util.PoolMap.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.util.JsonMapper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.util.FileSystemVersionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.UnknownScannerException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.UnknownRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableNotFoundException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableNotEnabledException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableNotDisabledException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableInfoMissingException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableExistsException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.UnknownSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.TablePartiallyOpenException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotExistsException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotDoesNotExistException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotCreationException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.RestoreSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.HBaseSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.ExportSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.CorruptedSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.ClientSnapshotDescriptionUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ResponseConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ServerLoad.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityLabelsValidator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityControllerNotReadyException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.LabelAlreadyExistsException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.InvalidLabelException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.CellVisibility.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.Authorizations.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.token.AuthenticationTokenSelector.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.token.AuthenticationTokenIdentifier.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.SecurityInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.SaslWrapHandler.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.SaslUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.SaslUnwrapHandler.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.SaslStatus.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.SaslChallengeDecoder.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.NettyHBaseSaslRpcClientHandler.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.NettyHBaseSaslRpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.NettyHBaseRpcConnectionHeaderHandler.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.HBaseSaslRpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.EncryptionUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.CryptoAESWrapHandler.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.CryptoAESUnwrapHandler.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.AuthMethod.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.UserPermission.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.TablePermission.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.ShadedAccessControlUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.Permission.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.AccessDeniedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.AbstractHBaseSaslRpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RetryImmediatelyException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeerDescription.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeerConfig.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationLoadSource.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationLoadSink.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ReplicationPeerNotFoundException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionTooBusyException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.WrongRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FailedSyncBeforeLogCloseException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FailedLogCloseException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerStoppedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerRunningException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerAbortedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.LeaseException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.BloomType.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionLocations.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionLoad.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.ThrottlingException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.ThrottleType.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.ThrottleSettings.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.SpaceViolationPolicy.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.SpaceQuotaSnapshot.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.SpaceLimitSettings.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaType.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaTableUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaSettingsFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaSettings.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaScope.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaRetriever.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaExceededException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufMessageConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufMagic.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.PleaseHoldException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.NotServingRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.NotAllMetaRegionsOnlineException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.NamespaceNotFoundException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.NamespaceExistException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MultiActionResultTooLarge.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MetaTableAccessor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MemoryCompactionPolicy.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.master.RegionState.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MasterNotRunningException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.KeepDeletedCells.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.WrongVersionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.UnsupportedCryptoException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.UnsupportedCompressionCodecException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.UnsupportedCellCodecException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.StoppedRpcClientException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.ServerTooBusyException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.ServerRpcController.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.ServerNotRunningYetException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcControllerFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClientFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.NettyRpcConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.NettyRpcClientConfigHelper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.NettyRpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.IPCUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.HBaseRpcControllerImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.HBaseRpcController.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.FatalConnectionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.FallbackDisallowedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.FailedServers.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.FailedServerException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.DelegatingHBaseRpcController.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.DefaultNettyEventLoopConfig.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.CoprocessorRpcUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.CoprocessorRpcChannel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.ConnectionId.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.CellScannerButNoCodecException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.CellBlockBuilder.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.CallTimeoutException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.CallEvent.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.CallerDisconnectedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.CallCancelledException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.Call.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.BufferCallBeforeInitHandler.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.BlockingRpcConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.BlockingRpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.BlockingRpcCallback.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.BadAuthException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.AbstractRpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.InvalidFamilyOperationException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HRegionLocation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.WhileMatchFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ValueFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.TimestampsFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.SubstringComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.SkipFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.SingleColumnValueFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.SingleColumnValueExcludeFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.RowFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.RegexStringComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.RandomRowFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.QualifierFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.PrefixFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ParseFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ParseConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.PageFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.NullComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.MultiRowRangeFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.MultipleColumnPrefixFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.LongComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.KeyOnlyFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.InvalidRowFilterException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.IncompatibleFilterException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.InclusiveStopFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FuzzyRowFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FirstKeyValueMatchingQualifiersFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FirstKeyOnlyFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FilterWrapper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FilterList.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FilterBase.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.Filter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FamilyFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.DependentColumnFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.CompareFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ColumnRangeFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ColumnPrefixFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ColumnPaginationFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ColumnCountGetFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.BitComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.BinaryPrefixComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.BinaryComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.executor.ExecutorType.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.executor.EventType.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.UnknownProtocolException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.ScannerResetException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.RequestTooBigException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.RegionOpeningException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.RegionMovedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.RegionInRecoveryException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.PreemptiveFastFailException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.OutOfOrderScannerNextException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.MergeRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.FailedSanityCheckException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.ConnectionClosingException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.ClientExceptionsUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.DroppedSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.DoNotRetryIOException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.coprocessor.ColumnInterpreter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.coprocessor.BypassCoprocessorException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.CoprocessorEnvironment.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.Coprocessor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.CoordinatedStateException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.CompareOperator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ClusterStatus.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ClusterId.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ClockOutOfSyncException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ZooKeeperRegistry.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ZKAsyncRegistry.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.WrongRowIOException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.UnmodifyableHRegionInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.TableState.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.TableDescriptorBuilder.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.TableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.TableBuilderBase.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.TableBuilder.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Table.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.SyncCoprocessorRpcChannel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.StatisticTrackable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.SnapshotType.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.SnapshotDescription.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.SingleResponse.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.SimpleRequestController.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ShortCircuitMasterConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ServerStatisticTracker.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.security.SecurityCapability.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.SecureBulkLoadClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScanResultConsumer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScanResultCache.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCallerFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RowTooBigException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RowMutations.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RowAccess.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Row.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RetryingCallerInterceptorContext.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RetryingCallerInterceptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RetryingCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RetriesExhaustedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ResultStatsUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ResultScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ResultBoundedCompletionService.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Result.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RequestControllerFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RequestController.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.replication.TableCFs.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.replication.ReplicationSerDeHelper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.replication.ReplicationAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegistryFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Registry.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionServerCoprocessorRpcChannelImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionServerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionReplicaUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionOfflineException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionLocateType.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionLoadStats.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionCoprocessorServiceExec.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionCoprocessorRpcChannelImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionCoprocessorRpcChannel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionAdminServiceCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawScanResultConsumer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncTableImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.QuotaStatusCalls.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Query.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Put.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.PreemptiveFastFailInterceptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.PerClientRandomNonceGenerator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.PackagePrivateFieldAccessor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.OperationWithAttributes.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Operation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.NoServerForRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.NoOpRetryingInterceptorContext.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.NoOpRetryableCallerInterceptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.NonceGenerator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.NoncedRegionServerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Mutation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MultiServerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MultiResponse.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MultiAction.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MobCompactPartitionPolicy.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.metrics.ServerSideScanMetrics.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.metrics.ScanMetrics.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MetricsConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MetaCache.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MasterSwitchType.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MasterCoprocessorRpcChannelImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MasterCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.IsolationLevel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Increment.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ImmutableHTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ImmutableHColumnDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTableMultiplexer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HRegionLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Get.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.FlushRegionCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.FastFailInterceptorContext.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.FailureInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Durability.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.DoNotRetryRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Delete.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.DelayingRunner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Cursor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.LongColumnInterpreter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.DoubleColumnInterpreter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.BigDecimalColumnInterpreter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.Batch.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Consistency.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionConfiguration.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Connection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.CompleteScanResultCache.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.CompactType.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.CompactionState.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ColumnFamilyDescriptorBuilder.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ColumnFamilyDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClusterStatusListener.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClusterConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSimpleScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientServiceCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientIdGenerator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientCoprocessorRpcController.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientAsyncPrefetchScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.CancellableRegionServerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Cancellable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.BufferedMutatorParams.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.BufferedMutatorImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.BufferedMutator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.BatchScanResultCache.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.backoff.ServerStatistics.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.backoff.ExponentialClientBackoffPolicy.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.backoff.ClientBackoffPolicyFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.backoff.ClientBackoffPolicy.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Attributes.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableResultScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableRegionLocatorImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableRegionLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableBuilderBase.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableBuilder.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableBase.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncSingleRequestRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncServerRequestRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncScanSingleRegionRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRpcRetryingCallerFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRequestFutureImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRequestFuture.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRegistryFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRegistry.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRegionLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcessTask.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncNonMetaRegionLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncMetaRegionLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncMasterRequestRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncConnectionImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncConnectionConfiguration.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncBufferedMutatorImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncBufferedMutatorBuilderImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncBufferedMutatorBuilder.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncBufferedMutator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncBatchRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdminRequestRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdminBuilderBase.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdminBuilder.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Append.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AllowPartialScanResultCache.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Action.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AbstractResponse.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AbstractClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.CallQueueTooBigException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.CallDroppedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.AsyncMetaTableAccessor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.Abortable.java</file>
      <file type="M">hbase-client.pom.xml</file>
      <file type="M">hbase-build-configuration.pom.xml</file>
      <file type="M">hbase-backup.src.test.java.org.apache.hadoop.hbase.backup.TestSystemTableSnapshot.java</file>
      <file type="M">hbase-backup.src.test.java.org.apache.hadoop.hbase.backup.TestRestoreBoundaryTests.java</file>
      <file type="M">hbase-backup.src.test.java.org.apache.hadoop.hbase.backup.TestRemoteRestore.java</file>
      <file type="M">hbase-backup.src.test.java.org.apache.hadoop.hbase.backup.TestRemoteBackup.java</file>
      <file type="M">hbase-backup.src.test.java.org.apache.hadoop.hbase.backup.TestFullBackupWithFailures.java</file>
      <file type="M">hbase-backup.src.test.java.org.apache.hadoop.hbase.backup.TestFullBackupSetRestoreSet.java</file>
      <file type="M">hbase-backup.src.test.java.org.apache.hadoop.hbase.backup.TestFullBackupSet.java</file>
      <file type="M">hbase-backup.src.test.java.org.apache.hadoop.hbase.backup.TestFullBackup.java</file>
      <file type="M">hbase-backup.src.test.java.org.apache.hadoop.hbase.backup.TestBackupShowHistory.java</file>
      <file type="M">hbase-backup.src.test.java.org.apache.hadoop.hbase.backup.TestBackupRepair.java</file>
      <file type="M">hbase-backup.src.test.java.org.apache.hadoop.hbase.backup.TestBackupHFileCleaner.java</file>
      <file type="M">dev-support.checkcompatibility.py</file>
      <file type="M">hbase-annotations.pom.xml</file>
      <file type="M">hbase-annotations.src.main.java.org.apache.hadoop.hbase.classification.InterfaceAudience.java</file>
      <file type="M">hbase-annotations.src.main.java.org.apache.hadoop.hbase.classification.InterfaceStability.java</file>
      <file type="M">hbase-annotations.src.main.java.org.apache.hadoop.hbase.classification.tools.ExcludePrivateAnnotationsStandardDoclet.java</file>
      <file type="M">hbase-annotations.src.main.java.org.apache.hadoop.hbase.classification.tools.IncludePublicAnnotationsStandardDoclet.java</file>
      <file type="M">hbase-annotations.src.main.java.org.apache.hadoop.hbase.classification.tools.RootDocProcessor.java</file>
      <file type="M">hbase-annotations.src.main.java.org.apache.hadoop.hbase.classification.tools.StabilityOptions.java</file>
      <file type="M">hbase-backup.pom.xml</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.BackupAdmin.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.BackupClientFactory.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.BackupCopyJob.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.BackupDriver.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.BackupHFileCleaner.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.BackupInfo.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.BackupMergeJob.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.BackupObserver.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.BackupRequest.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.BackupRestoreConstants.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.BackupRestoreFactory.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.BackupTableInfo.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.HBackupFileSystem.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupAdminImpl.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupCommands.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupException.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupManager.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupManifest.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupSystemTable.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.impl.FullTableBackupClient.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.impl.IncrementalBackupManager.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.impl.IncrementalTableBackupClient.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.impl.RestoreTablesClient.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.impl.TableBackupClient.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.LogUtils.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.mapreduce.MapReduceBackupCopyJob.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.mapreduce.MapReduceBackupMergeJob.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.mapreduce.MapReduceHFileSplitterJob.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.mapreduce.MapReduceRestoreJob.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.master.BackupLogCleaner.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.master.LogRollMasterProcedureManager.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.regionserver.LogRollBackupSubprocedure.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.regionserver.LogRollBackupSubprocedurePool.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.regionserver.LogRollRegionServerProcedureManager.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.RestoreDriver.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.RestoreJob.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.RestoreRequest.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.util.BackupSet.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.util.BackupUtils.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.util.RestoreTool.java</file>
      <file type="M">hbase-backup.src.test.java.org.apache.hadoop.hbase.backup.TestBackupBoundaryTests.java</file>
    </fixedFiles>
  </bug>
  <bug id="17826" opendate="2017-3-23 00:00:00" fixdate="2017-8-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Backup: submit M/R job to a particular Yarn queue</summary>
      <description>We need this to be configurable. Currently, all M/R jobs are submitted to a default queue.</description>
      <version>None</version>
      <fixedVersion>2.0.0-alpha-3,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.RestoreDriver.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupCommands.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.BackupRestoreConstants.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.BackupRequest.java</file>
    </fixedFiles>
  </bug>
  <bug id="17831" opendate="2017-3-24 00:00:00" fixdate="2017-3-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support small scan in thrift2</summary>
      <description>Support small scan in thrift2</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift2.TestThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-thrift.src.main.resources.org.apache.hadoop.hbase.thrift2.hbase.thrift</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftUtilities.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TScan.java</file>
    </fixedFiles>
  </bug>
  <bug id="17835" opendate="2017-3-25 00:00:00" fixdate="2017-4-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Spelling mistakes in the Java source</summary>
      <description>I found spelling mistakes in the hbase java source files viz. recieved instead of received, and SpanReciever instead of SpanReceiver</description>
      <version>2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.WALPerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestClockSkewDetection.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureMemberRpcs.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
    </fixedFiles>
  </bug>
  <bug id="17847" opendate="2017-3-29 00:00:00" fixdate="2017-3-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>update documentation to include positions on recent Hadoop releases</summary>
      <description>per dev@hbase discussion on how to handle the most recent round of Hadoop releases, get our docs updated.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="17849" opendate="2017-3-29 00:00:00" fixdate="2017-6-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>PE tool random read is not totally random</summary>
      <description>Recently we were using the PE tool for doing some bucket cache related performance tests. One thing that we noted was that the way the random read works is not totally random.Suppose we load 200G of data using --size param and then we use --rows=500000 to do the randomRead. The assumption was among the 200G of data it could generate randomly 500000 row keys to do the reads.But it so happens that the PE tool generates random rows only on those set of row keys which falls under the first 500000 rows. This was quite evident when we tried to use HBASE-15314 in our testing. Suppose we split the bucket cache of size 200G into 2 files each 100G the randomReads with --rows=500000 always lands in the first file and not in the 2nd file. Better to make PE purely random.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestPerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
    </fixedFiles>
  </bug>
  <bug id="17855" opendate="2017-3-31 00:00:00" fixdate="2017-3-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix typo in async client implementation</summary>
      <description></description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.AbstractTestAsyncTableScan.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRegionLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncNonMetaRegionLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncMetaRegionLocator.java</file>
    </fixedFiles>
  </bug>
  <bug id="17857" opendate="2017-3-31 00:00:00" fixdate="2017-4-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove IS annotations from IA.Public classes</summary>
      <description></description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ResultScanner.java</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.spark.sql.datasources.hbase.HBaseTableCatalog.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.NewHBaseRDD.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.KeyFamilyQualifier.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.JavaHBaseContext.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.HBaseRDDFunctions.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.HBaseDStreamFunctions.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.HBaseContext.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.FamilyHFileWriteOptions.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.FamiliesQualifiersValues.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.datasources.HBaseSparkConf.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.ColumnFamilyQualifierMapKeyWrapper.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.ByteArrayWrapper.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.ByteArrayComparable.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.BulkLoadPartitioner.scala</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MiniHBaseCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.codec.CodecPerformance.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.LeaseNotRecoveredException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.EncryptionTest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ConfigurationUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.ExportSnapshot.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityLabelService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityExpEvaluator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.ScanLabelGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.TokenUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RowTooBigException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.MobConstants.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableSplit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableSnapshotInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableReduce.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableRecordReaderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableRecordReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableOutputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableMapReduceUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableMap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableInputFormatBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.RowCounter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.MultiTableSnapshotInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.IdentityTableReduce.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.IdentityTableMap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.HRegionPartitioner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.GroupingTableMap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.WALPlayer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.VisibilityExpressionResolver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TsvImporterTextMapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TsvImporterMapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TextSortReducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableSplit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableReducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableRecordReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableOutputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableOutputCommitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.SimpleTotalOrderPartitioner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.RowCounter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.ResultSerialization.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.PutSortReducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.PutCombiner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.MutationSerialization.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.MultiTableSnapshotInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.MultiTableOutputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.MultiTableInputFormatBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.MultiTableInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.MultiHFileOutputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.KeyValueSortReducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.KeyValueSerialization.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.ImportTsv.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.Import.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.IdentityTableReducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.IdentityTableMapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HRegionPartitioner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.GroupingTableMapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.Export.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.CopyTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.CellCreator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.CellCounter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.LocalHBaseCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.errorhandling.TimeoutException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.errorhandling.ForeignException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.TableSnapshotScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.locking.EntityLock.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.filter.RestCsrfPreventionFilter.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.Constants.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.client.Response.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteAdmin.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.client.Cluster.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.client.Client.java</file>
      <file type="M">hbase-endpoint.src.main.java.org.apache.hadoop.hbase.client.coprocessor.AsyncAggregationClient.java</file>
      <file type="M">hbase-endpoint.src.main.java.org.apache.hadoop.hbase.client.coprocessor.AggregationClient.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.HBaseCommonTestingUtility.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.VersionInfo.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.SimplePositionedMutableByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.SimplePositionedByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.SimpleMutableByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.SimpleByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ReadOnlyByteRangeException.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.PositionedByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.PairOfSameType.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Pair.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.OrderedBytes.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Order.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.MD5Hash.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Counter.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Bytes.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteRangeUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteBufferUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Base64.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.Union4.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.Union3.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.Union2.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.TerminatedWrapper.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.StructIterator.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.StructBuilder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.Struct.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawStringTerminated.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawStringFixedLength.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawString.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawShort.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawLong.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawInteger.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawFloat.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawDouble.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawBytesTerminated.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawBytesFixedLength.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawBytes.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawByte.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.PBType.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedString.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedNumeric.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedInt8.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedInt64.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedInt32.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedInt16.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedFloat64.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedFloat32.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedBytesBase.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedBlobVar.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedBlob.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.FixedLengthWrapper.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.DataType.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.TableName.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.Stoppable.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ServerName.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.security.User.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ScheduledChore.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupInfo.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ProcedureState.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ProcedureInfo.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.net.Address.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.NamespaceDescriptor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.TimeRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.ImmutableBytesWritable.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.DataBlockEncoding.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.KeyStoreKeyProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.KeyProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.Encryptor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.Encryption.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.DefaultCipherProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.Decryptor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.CryptoCipherProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.Context.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.CipherProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.Cipher.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.compress.Compression.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.ByteBufferOutputStream.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HBaseIOException.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HBaseInterfaceAudience.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HBaseConfiguration.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.filter.ByteArrayComparable.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ChoreService.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.Cell.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.AuthUtil.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.TestInterfaceAudienceAnnotations.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ZooKeeperConnectionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.util.JsonMapper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.util.FileSystemVersionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.UnknownScannerException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.UnknownRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableNotFoundException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableNotEnabledException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableNotDisabledException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableInfoMissingException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableExistsException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.UnknownSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.TablePartiallyOpenException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotExistsException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotDoesNotExistException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotCreationException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.RestoreSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.HBaseSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.ExportSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.CorruptedSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ServerLoad.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityControllerNotReadyException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.LabelAlreadyExistsException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.InvalidLabelException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.CellVisibility.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.Authorizations.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.Permission.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.AccessDeniedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RetryImmediatelyException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeerDescription.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeerConfig.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ReplicationPeerNotFoundException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionTooBusyException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.WrongRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FailedSyncBeforeLogCloseException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FailedLogCloseException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerStoppedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerRunningException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerAbortedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.LeaseException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.BloomType.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionLoad.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.ThrottlingException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.ThrottleType.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaType.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaSettingsFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaSettings.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaScope.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaRetriever.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaExceededException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.PleaseHoldException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.NotServingRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.NotAllMetaRegionsOnlineException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.NamespaceNotFoundException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.NamespaceExistException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MultiActionResultTooLarge.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MemoryCompactionPolicy.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MasterNotRunningException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.KeepDeletedCells.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.WrongVersionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.UnsupportedCryptoException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.UnsupportedCompressionCodecException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.UnsupportedCellCodecException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.StoppedRpcClientException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.ServerTooBusyException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.ServerNotRunningYetException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.NettyRpcClientConfigHelper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.FatalConnectionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.FallbackDisallowedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.FailedServerException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.CoprocessorRpcChannel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.CellScannerButNoCodecException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.CallTimeoutException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.CallerDisconnectedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.CallCancelledException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.BadAuthException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.InvalidFamilyOperationException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HRegionLocation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.WhileMatchFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ValueFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.TimestampsFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.SubstringComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.SkipFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.SingleColumnValueFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.SingleColumnValueExcludeFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.RowFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.RegexStringComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.RandomRowFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.QualifierFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.PrefixFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ParseFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ParseConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.PageFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.NullComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.MultiRowRangeFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.MultipleColumnPrefixFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.LongComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.KeyOnlyFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.InvalidRowFilterException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.IncompatibleFilterException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.InclusiveStopFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FuzzyRowFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FirstKeyValueMatchingQualifiersFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FirstKeyOnlyFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FilterList.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.Filter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FamilyFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.DependentColumnFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.CompareFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ColumnRangeFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ColumnPrefixFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ColumnPaginationFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ColumnCountGetFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.BitComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.BinaryPrefixComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.BinaryComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.UnknownProtocolException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.ScannerResetException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.RequestTooBigException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.RegionInRecoveryException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.PreemptiveFastFailException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.MergeRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.FailedSanityCheckException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.ConnectionClosingException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.DroppedSnapshotException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.DoNotRetryIOException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.coprocessor.BypassCoprocessorException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ClusterStatus.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ClockOutOfSyncException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.WrongRowIOException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.UnmodifyableHTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.UnmodifyableHRegionInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.TableBuilder.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Table.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.SyncCoprocessorRpcChannel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.SnapshotType.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.SnapshotDescription.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ShortCircuitMasterConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.security.SecurityCapability.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScanResultConsumer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RowTooBigException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RowMutations.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RowAccess.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Row.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RetriesExhaustedException.java</file>
      <file type="M">hbase-annotations.src.main.java.org.apache.hadoop.hbase.classification.InterfaceAudience.java</file>
      <file type="M">hbase-annotations.src.main.java.org.apache.hadoop.hbase.classification.InterfaceStability.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.CallDroppedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.CallQueueTooBigException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Append.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableBase.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableBuilder.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableRegionLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Attributes.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.backoff.ClientBackoffPolicy.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.backoff.ExponentialClientBackoffPolicy.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.BufferedMutator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.BufferedMutatorParams.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.CompactionState.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.CompactType.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Connection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Consistency.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.Batch.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Delete.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.DoNotRetryRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Durability.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Get.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTableMultiplexer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Increment.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.IsolationLevel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MasterSwitchType.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.metrics.ScanMetrics.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.metrics.ServerSideScanMetrics.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MobCompactPartitionPolicy.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Mutation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.NoServerForRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Operation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.OperationWithAttributes.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Put.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Query.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawScanResultConsumer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionLoadStats.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionOfflineException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.replication.ReplicationAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.replication.TableCFs.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RequestController.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RequestControllerFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Result.java</file>
    </fixedFiles>
  </bug>
  <bug id="17858" opendate="2017-3-31 00:00:00" fixdate="2017-4-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update refguide about the IS annotation if necessary</summary>
      <description></description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="17872" opendate="2017-4-4 00:00:00" fixdate="2017-4-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The MSLABImpl generates the invaild cells when unsafe is not availble</summary>
      <description>We will get the wrong position of buffer in multithreaded environment, so the method makes the invalid cell in MSLAB. public static int copyFromBufferToBuffer(ByteBuffer in, ByteBuffer out, int sourceOffset, int destinationOffset, int length) { if (in.hasArray() &amp;&amp; out.hasArray()) { // ... } else if (UNSAFE_AVAIL) { // ... } else { int outOldPos = out.position(); out.position(destinationOffset); ByteBuffer inDup = in.duplicate(); inDup.position(sourceOffset).limit(sourceOffset + length); out.put(inDup); out.position(outOldPos); } return destinationOffset + length; }</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestByteBufferUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteBufferUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="17873" opendate="2017-4-4 00:00:00" fixdate="2017-4-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change the IA.Public annotation to IA.Private for unstable API</summary>
      <description>As discussed in mailing list and HBASE-17857.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="17875" opendate="2017-4-4 00:00:00" fixdate="2017-4-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document why objects over 10MB are not well-suited for hbase</summary>
      <description>A new-user who has patently done their homework is unable to find in doc why objects above 10MB are not recommended for hbase. Lets add explanation that has a link from MOB on what happens when objects this size are requested form HBase.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.hbase.mob.adoc</file>
      <file type="M">src.main.asciidoc..chapters.faq.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="17877" opendate="2017-4-4 00:00:00" fixdate="2017-4-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve HBase&amp;#39;s byte[] comparator</summary>
      <description>vik.karma did some extensive tests and found that Hadoop's version is faster - dramatically faster in some cases.Patch forthcoming.</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">NOTICE.txt</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Bytes.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteBufferUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="17881" opendate="2017-4-5 00:00:00" fixdate="2017-4-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove the ByteBufferCellImpl</summary>
      <description>We should substitute ByteBufferKeyValue for ByteBufferCellImpl</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestSingleColumnValueFilter.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestCellUtil.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestCellComparator.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.filter.TestKeyOnlyFilter.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.filter.TestComparators.java</file>
    </fixedFiles>
  </bug>
  <bug id="17887" opendate="2017-4-6 00:00:00" fixdate="2017-5-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Row-level consistency is broken for read</summary>
      <description>The scanner of latest memstore may be lost if we make quick flushes. The following step may help explain this issue. put data_A (seq id = 10, active store data_A and snapshots is empty) snapshot of 1st flush (active is empty and snapshot stores data_A) put data_B (seq id = 11, active store data_B and snapshot store data_A) create user scanner (read point = 11, so It should see the data_B) commit of 1st flush clear snapshot ((hfile_A has data_A, active store data_B, and snapshot is empty) update the reader (the user scanner receives the hfile_A) snapshot of 2st flush (active is empty and snapshot store data_B) commit of 2st flush clear snapshot (hfile_A has data_A, hfile_B has data_B, active is empty, and snapshot is empty) – this is critical piece. update the reader (haven't happen) user scanner update the kv scanners (it creates scanner of hfile_A but nothing of memstore) user see the older data A – wrong result</description>
      <version>1.3.0,2.0.0</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestWideScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactingMemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ChangedReadersObserver.java</file>
    </fixedFiles>
  </bug>
  <bug id="17898" opendate="2017-4-10 00:00:00" fixdate="2017-6-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update dependencies</summary>
      <description>General issue to cover updating old, stale dependencies for hbase2 release. Lets make subissues doing each.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-thrift.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="17903" opendate="2017-4-11 00:00:00" fixdate="2017-4-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Corrected the alias for the link of HBASE-6580</summary>
      <description>Previous versions of this guide discussed `HTablePool`, which was deprecated in HBase 0.94, 0.95, and 0.96, and removed in 0.98.1, by link:https://issues.apache.org/jira/browse/HBASE-6580[HBASE-6500], or `HConnection`, which is deprecated in HBase 1.0 by `Connection`.Please use link:http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Connection.html[Connection] instead.6500 -&gt; 6580</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="17905" opendate="2017-4-11 00:00:00" fixdate="2017-4-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbase-spark] bulkload does not work when table not exist</summary>
      <description>when using HBase-Spark bulkload api, an argument of tablename is needed, the bulkload can run successfully only if table exist in HBase. If table not exist, the bulkload can not run successfully and it even do not report any errors or throw exception.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.HBaseContext.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.BulkLoadPartitioner.scala</file>
    </fixedFiles>
  </bug>
  <bug id="17915" opendate="2017-4-14 00:00:00" fixdate="2017-4-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement async replication admin methods</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncAdminBase.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.replication.ReplicationSerDeHelper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="17917" opendate="2017-4-14 00:00:00" fixdate="2017-5-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use pread by default for all user scan and switch to streaming read if needed</summary>
      <description>As said in the parent issue. We need some benchmark here first.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestCoprocessorScanPolicy.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestIOFencing.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestReversibleScanners.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMajorCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDefaultMemStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDefaultCompactSelection.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompactingMemStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestBlocksScanned.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.querymatcher.TestUserScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.querymatcher.TestCompactionScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.MockStoreFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.DelegatingKeyValueScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileBlock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SegmentScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ScanInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ReversedStoreScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.NonLazyKeyValueScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.KeyValueScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.KeyValueHeap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
    </fixedFiles>
  </bug>
  <bug id="17918" opendate="2017-4-14 00:00:00" fixdate="2017-4-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>document serial replication</summary>
      <description>It looks like HBASE-9465 addresses one of the major flaws in our existing replication (namely that order of delivery is not assured). All I see in the reference guide is a note on hbase.serial.replication.waitingMs. Instead we should cover this in the replication section, especially given that we call out the order of delivery limitation.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="17925" opendate="2017-4-14 00:00:00" fixdate="2017-4-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>mvn assembly:single fails against hadoop3-alpha2</summary>
      <description>generally to build tarballs against hadoop3 alpha2 we'd use mvn -Dhadoop.profile=3.0 -Dhadoop.three-version=3.0.0-alpha2 assembly:single -DskipTestsThis currently fails.</description>
      <version>2.0.0</version>
      <fixedVersion>1.4.0,1.1.10,1.2.6,1.3.2,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="17929" opendate="2017-4-17 00:00:00" fixdate="2017-4-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add more options for PE tool</summary>
      <description>For better evaluating scan performance.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
    </fixedFiles>
  </bug>
  <bug id="17931" opendate="2017-4-17 00:00:00" fixdate="2017-7-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Assign system tables to servers with highest version</summary>
      <description>In branch-1 and master we have some improvement and new features on scanning which is not compatible.A client of old version to a server of new version is compatible (must be a bug if not, maybe need some test?). A client of new version may not be able to read from a server of old version correctly (because of scan limit, moreResults flag, etc), which is ok for major/minor upgrade and we can tell users to upgrade server before upgrading client. But RS also use scan to read meta. If meta table is in RS of old version, all RSs of new version may have trouble while scanning meta table.So we should make sure meta table always in servers of new version. Force meta table in Master and upgrade Master first, or assign meta table in region servers with latest version?</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0-alpha-2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockNoopMasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.RegionServerTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.AssignmentManager.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.VersionInfo.java</file>
    </fixedFiles>
  </bug>
  <bug id="17937" opendate="2017-4-18 00:00:00" fixdate="2017-4-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Memstore size becomes negative in case of expensive postPut/Delete Coprocessor call</summary>
      <description>We ran into a situation where the memstore size became negative due to expensive postPut/Delete Coprocessor calls in doMiniBatchMutate. We update the memstore size in the finally block of doMiniBatchMutate, however a queued flush can be triggered during the coprocessor calls(if they are taking time eg. index updates) since we have released the locks and advanced mvcc at this point. The flush will turn the memstore size negative since the value subtracted is the actual value flushed from stores. The negative value impacts the future flushes amongst others that depend on memstore size.</description>
      <version>1.3.1,0.98.24,2.0.0</version>
      <fixedVersion>1.4.0,1.2.6,1.3.2,1.1.11,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="17938" opendate="2017-4-18 00:00:00" fixdate="2017-5-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>General fault - tolerance framework for backup/restore operations</summary>
      <description>The framework must take care of all general types of failures during backup/ restore and restore system to the original state in case of a failure.That won't solve all the possible issues but we have a separate JIRAs for them as a sub-tasks of HBASE-15277</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.impl.TableBackupClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.impl.IncrementalTableBackupClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.impl.FullTableBackupClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupSystemTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupCommands.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupAdminImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupRestoreConstants.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupDriver.java</file>
    </fixedFiles>
  </bug>
  <bug id="17942" opendate="2017-4-19 00:00:00" fixdate="2017-2-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Disable region splits and merges per table</summary>
      <description>Snapshot of a large tables usually fails when region split/merge happens during snapshot. HBASE-15128 has introduced enable/disable switch for split /merges, but only cluster - wide which is not always good in a large deployments. The new feature will improve snapshot stability ands performance for a single table.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.test.ruby.hbase.admin.test.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.create.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.alter.rb</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.SplitTableRegionProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.MergeTableRegionsProcedure.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.TableDescriptorBuilder.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.TableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
    </fixedFiles>
  </bug>
  <bug id="17950" opendate="2017-4-24 00:00:00" fixdate="2017-4-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Write the chunkId also as Int instead of long into the first byte of the chunk</summary>
      <description>I think some issue happened while updating the patch. The chunkId was converted to int every where but while writing it has been written as a long. Will push a small patch to change it.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMemstoreLABWithoutPool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMemStoreLAB.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMemStoreChunkPool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDefaultMemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.OnheapChunk.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.OffheapChunk.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Chunk.java</file>
    </fixedFiles>
  </bug>
  <bug id="17952" opendate="2017-4-24 00:00:00" fixdate="2017-4-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The new options for PE tool do not work</summary>
      <description></description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
    </fixedFiles>
  </bug>
  <bug id="17954" opendate="2017-4-24 00:00:00" fixdate="2017-6-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Switch findbugs implementation to spotbugs</summary>
      <description>The Hadoop folks got some nice finds out of switching their findbugs plugin to use the new spotbugs fork instead, let's try it out too. (ref HADOOP-14316 for details)</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0-alpha-2,1.1.12,2.0.0,1.2.7</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="17955" opendate="2017-4-24 00:00:00" fixdate="2017-4-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Commit Reviewboard comments from Vlad</summary>
      <description>Need to commit the local changes from Vlad's review on https://reviews.apache.org/r/58364/</description>
      <version>None</version>
      <fixedVersion>HBASE-16961,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerRegionSpaceUseReport.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestTableSpaceQuotaViolationNotifier.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestSpaceQuotas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestRegionServerSpaceQuotaManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestQuotaStatusRPCs.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestQuotaObserverChoreWithMiniCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestQuotaObserverChoreRegionReports.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestMasterSpaceQuotaObserver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestActivePolicyEnforcement.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.SpaceQuotaHelperForTests.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.policies.TestBulkLoadCheckingViolationPolicyEnforcement.java</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.TableQuotaSnapshotStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.SpaceViolationPolicyEnforcementFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.SpaceQuotaRefresherChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.SpaceLimitingException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.RegionServerSpaceQuotaManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaObserverChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.policies.NoWritesViolationPolicyEnforcement.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.policies.NoInsertsViolationPolicyEnforcement.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.policies.DisableTableViolationPolicyEnforcement.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.policies.BulkLoadVerifyingViolationPolicyEnforcement.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.policies.AbstractViolationPolicyEnforcement.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.NamespaceQuotaSnapshotStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.MasterSpaceQuotaObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.MasterQuotaManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.FileSystemUtilizationChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.ActivePolicyEnforcement.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MetricsMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Quota.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.RegionServerStatus.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.Quota.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.java</file>
      <file type="M">hbase-protocol-shaded.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterQuotaSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterQuotaSourceFactoryImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerQuotaSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterQuotaSource.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.SpaceViolationPolicy.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.SpaceQuotaSnapshot.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.SpaceLimitSettings.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaTableUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaSettingsFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="17956" opendate="2017-4-25 00:00:00" fixdate="2017-4-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Raw scan should ignore TTL</summary>
      <description>For now we will also test TTL to check if a cell is expired for raw scan. Since we can even return delete marker for a raw scan, I think it is also reasonable to eliminate the TTL check.</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannersFromClientSide.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="17957" opendate="2017-4-25 00:00:00" fixdate="2017-5-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Custom metrics of replicate endpoints don&amp;#39;t prepend "source." to global metrics</summary>
      <description>Custom metrics for custom replication endpoints is introduced by HBASE-16448.The name of local custom metrics follows the "source.id.metricsName" format, but the name of global custom metrics doesn't follow the "source.metricsName" format.Ex:// default metrics"source.2.shippedOps" : 1234, // peer local"source.shippedOps" : 12345, // global// custom metrics"source.1.failed.start" : 1, // peer local"failed.start" : 1, // globalWhen we consider that default metrics do so, it should be "source.metricsName" like:"source.1.failed.start" : 1,"source.failed.start" : 1,</description>
      <version>1.4.0,0.98.22,2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationEndpoint.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.replication.regionserver.MetricsReplicationGlobalSourceSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="17962" opendate="2017-4-26 00:00:00" fixdate="2017-4-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve documentation on Rest interface</summary>
      <description>The part of the documentation on the rest interface 'hides' the fact that you can retrieve the entire row in one request.It also does not clearly state that it only works for certain mime types.</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.external.apis.adoc</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.RowResource.java</file>
    </fixedFiles>
  </bug>
  <bug id="17964" opendate="2017-4-26 00:00:00" fixdate="2017-5-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ensure hbase-metrics-api is included in mapreduce job classpaths</summary>
      <description>HBASE-9774 moved metrics stuff into a couple of additional modules. currently, MR against snapshots fail because it's unable to find the metrics-api classes it needs for ClientSideRegionScanner.Error: java.io.IOException: java.lang.NoClassDefFoundError: org/apache/hadoop/hbase/metrics/Snapshotat org.apache.hadoop.hbase.regionserver.HRegion.initializeStores(HRegion.java:1027)at org.apache.hadoop.hbase.regionserver.HRegion.initializeRegionInternals(HRegion.java:883)at org.apache.hadoop.hbase.regionserver.HRegion.initialize(HRegion.java:858)at org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(HRegion.java:6694)at org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(HRegion.java:6651)at org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(HRegion.java:6622)at org.apache.hadoop.hbase.client.ClientSideRegionScanner.&lt;init&gt;(ClientSideRegionScanner.java:59)at org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$RecordReader.initialize(TableSnapshotInputFormatImpl.java:211)at org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat$TableSnapshotRegionRecordReader.initialize(TableSnapshotInputFormat.java:140)at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="17976" opendate="2017-4-28 00:00:00" fixdate="2017-5-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove stability annotation from public audience-marked classes</summary>
      <description>Looks like I grabbed HBASE-17857 in the last rebase, but missed this test failing.</description>
      <version>None</version>
      <fixedVersion>HBASE-16961,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.SpaceViolationPolicy.java</file>
    </fixedFiles>
  </bug>
  <bug id="17977" opendate="2017-4-28 00:00:00" fixdate="2017-5-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enabled Master observer to delete quotas on table deletion by default</summary>
      <description>Deleting a table's quota when we delete the table should be the common case, not the exception.Load the observer by default (when quota support is enabled), and switch the flag to disable loading it. Make sure to update the docs too.</description>
      <version>None</version>
      <fixedVersion>HBASE-16961,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestMasterSpaceQuotaObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.MasterSpaceQuotaObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="17978" opendate="2017-4-28 00:00:00" fixdate="2017-5-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Investigate hbase superuser permissions in the face of quota violation</summary>
      <description>Any hbase superuser should be able to manipulate the system, even in the face of quota violation.Add some tests to give us some confidence about what superusers can (and cannot) do, fixing any glaring permissions issues about superusers facing permission issues.</description>
      <version>None</version>
      <fixedVersion>HBASE-16961,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.SpaceQuotaHelperForTests.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="17982" opendate="2017-5-2 00:00:00" fixdate="2017-6-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Is the word "occured" should be "occurred ?</summary>
      <description>I have find some spelling may have a problem</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestJMXConnectorServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestMasterReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileBlockIndex.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestComparatorSerialization.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.DeletionListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.HFileArchiver.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.policies.PeriodicRandomActionPolicy.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.policies.DoActionsOncePolicy.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientIdGenerator.java</file>
    </fixedFiles>
  </bug>
  <bug id="17985" opendate="2017-5-2 00:00:00" fixdate="2017-5-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Inline package manage updates with package installation in Yetus Dockerfile</summary>
      <description>Context: https://lists.apache.org/thread.html/d34093557cc510bb8b1dc4b37f8a729b74577c7d4eaecdc3f1badea1@%3Cdev.hbase.apache.org%3EThe way Docker images are built for the Yetus-based PreCommit, we may accidentally use a pre-built image that has a stale package-manager cache. If the distribution updates their published packages (removing an older version, adding a new one), our (stale) client will try to pull the older version which is missing, failing.</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.2.6,1.3.2,1.1.11,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.docker.Dockerfile</file>
    </fixedFiles>
  </bug>
  <bug id="1799" opendate="2009-8-26 00:00:00" fixdate="2009-8-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>deprecate o.a.h.h.rest in favor of stargate</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.package.html</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.Dispatcher.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">conf.log4j.properties</file>
      <file type="M">conf.hbase-env.sh</file>
    </fixedFiles>
  </bug>
  <bug id="17991" opendate="2017-5-4 00:00:00" fixdate="2017-5-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add more details about compaction queue on /dump</summary>
      <description>RS dump information as followsRS Queue:===========================================================Compaction/Split Queue summary: compaction_queue=(20:0), split_queue=0, merge_queue=0Compaction/Split Queue dump: LargeCompation Queue: Request = regionName=usertable,user4180497275766179957,1491904095205.1d4085e4438752f3611f66e7b043fe44., storeName=0, fileCount=1, fileSize=1.9 G (1.9 G), priority=1, time=21697920409804647 Request = regionName=usertable,user4568009753557153251,1491904099262.95bf004e3c9b35a58c60ca5d5b11d190., storeName=0, fileCount=1, fileSize=1.9 G (1.9 G), priority=1, time=21697920413223800 SmallCompation Queue: Store = b, pri = 108 Store = b, pri = 108 Store = b, pri = 108 Store = b, pri = 108 Store = b, pri = 108 Store = b, pri = 109Compaction queue information will be displayed on page /dump.If compation has selected the file, it will print the details information of the compation, otherwise only print storename and priority(Store = b, pri = 108) which is useless for us.So, we should also print more detailed information, such as regionName, starttime etc.</description>
      <version>2.0.0</version>
      <fixedVersion>1.4.0,1.3.3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
    </fixedFiles>
  </bug>
  <bug id="17995" opendate="2017-5-4 00:00:00" fixdate="2017-6-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>improve log messages during snapshot related tests</summary>
      <description>while verifying the changes for HBASE-17964 I had to chase down a failure related to having the wrong hbase configs. Adding some additional logging detail let me see what was happening.</description>
      <version>2.0.0</version>
      <fixedVersion>1.4.0,2.0.0-alpha-2,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.SnapshotTestingUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableSnapshotInputFormat.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatTestBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="18000" opendate="2017-5-5 00:00:00" fixdate="2017-5-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make sure we always return the scanner id with ScanResponse</summary>
      <description>Some external tooling (like OpenTSDB) relies on the scanner id to tie asynchronous responses back to their requests.(see comments on HBASE-17489)</description>
      <version>1.4.0,1.3.1,2.0.0</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="18002" opendate="2017-5-5 00:00:00" fixdate="2017-7-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Investigate why bucket cache filling up in file mode in an exisiting file is slower</summary>
      <description>This issue was observed when we recently did some tests with SSD based bucket cache. Similar thing was also reported by @stack and danielpol while doing some of these bucket cache related testing.When we try to preload a bucket cache (in file mode) with a new file the bucket cache fills up quite faster and there not much 'failedBlockAdditions'. But when the same bucket cache is filled up with a preexisitng file ( that had already some entries filled up) this time it has more 'failedBlockAdditions' and the cache does not fill up faster. Investigate why this happens.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0-alpha-2,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.bucket.TestFileIOEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.FileIOEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.java</file>
    </fixedFiles>
  </bug>
  <bug id="18007" opendate="2017-5-6 00:00:00" fixdate="2017-5-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up rest module code</summary>
      <description>HBase rest model has many dead code, let's remove the dead code and clean up warnings.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.ScannerModel.java</file>
    </fixedFiles>
  </bug>
  <bug id="18015" opendate="2017-5-8 00:00:00" fixdate="2017-5-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Storage class aware block placement for procedure v2 WALs</summary>
      <description>After HBASE-14061, HBASE-15172, and HBASE-17538, we can specify storage class placement policies for store files and WAL files. However, we missed procedure v2 WALs aka "MasterProcWAL", opened and updated by the master. We should apply the same storage policy for procv2 WALs as we do for regionserver WALs, specified by the HConstants.WAL_STORAGE_POLICY configuration key, using HConstants.DEFAULT_WAL_STORAGE_POLICY as default.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="18017" opendate="2017-5-8 00:00:00" fixdate="2017-5-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reduce frequency of setStoragePolicy failure warnings</summary>
      <description>When running with storage policy specification support if the underlying HDFS doesn't support it or if it has been disabled in site configuration the resulting logging is excessive. Log at WARN level once per FileSystem instance. Otherwise, log messages at DEBUG level.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="18023" opendate="2017-5-10 00:00:00" fixdate="2017-7-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Log multi-* requests for more than threshold number of rows</summary>
      <description>Today, if a user happens to do something like a large multi-put, they can get through request throttling (e.g. it is one request) but still crash a region server with a garbage storm. We have seen regionservers hit this issue and it is silent and deadly. The RS will report nothing more than a mysterious garbage collection and exit out.Ideally, we could report a large multi-* request before starting it, in case it happens to be deadly. Knowing the client, user and how many rows are affected would be a good start to tracking down painful users.</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="18030" opendate="2017-5-11 00:00:00" fixdate="2017-6-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Per Cell TTL tags may get duplicated with increments/Append causing tags length overflow</summary>
      <description>2017-04-29 14:24:14,135 ERROR &amp;#91;B.fifo.QRpcServer.handler=49,queue=1,port=16020&amp;#93; ipc.RpcServer: Unexpected throwable object java.lang.IllegalStateException: Invalid currTagsLen -32712. Block offset: 3707853, block length: 72841, position: 0 (without header). at org.apache.hadoop.hbase.io.hfile.HFileReaderV3$ScannerV3.checkTagsLen(HFileReaderV3.java:226)I am not not using any hbase tags feature.The Increment operation from the application side is triggering this error. The same is happening when scanner is run on this table. It feels that one or more particular HFile block is corrupt (with negative tagLength).hbase(main):007:0&gt; scan 'table-name', {LIMIT=&gt;1,STARTROW=&gt;'ad:event_count:a'}Returning the resulthbase(main):008:0&gt; scan 'table-name', {LIMIT=&gt;1,STARTROW=&gt;'ad:event_count:b'}ROW COLUMN+CELL ERROR: java.io.IOException: java.lang.IllegalStateException: Invalid currTagsLen -32701. Block offset: 272031, block length: 72441, position: 32487 (without header). at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.handleException(HRegion.java:5607) at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.&lt;init&gt;(HRegion.java:5579) at org.apache.hadoop.hbase.regionserver.HRegion.instantiateRegionScanner(HRegion.java:2627) at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:2613) at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:2595) at org.apache.hadoop.hbase.regionserver.RSRpcServices.scan(RSRpcServices.java:2282) at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:32295)</description>
      <version>1.0.0,0.98.9,2.0.0</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.TagUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="18043" opendate="2017-5-12 00:00:00" fixdate="2017-5-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Institute a hard limit for individual cell size that cannot be overridden by clients</summary>
      <description>For sake of service protection we should not give absolute trust to clients regarding resource limits that can impact stability, like cell size limits. We should add a server side configuration that sets a hard limit for individual cell size that cannot be overridden by the client. We can keep the client side check, because it's expensive to reject a RPC that has already come in.</description>
      <version>2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMobStoreScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="18049" opendate="2017-5-15 00:00:00" fixdate="2017-5-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>It is not necessary to re-open the region when MOB files cannot be found</summary>
      <description>In HBASE-17712, we try to re-open the region when store files cannot be found. This is useful for store files in a region, but is not necessary when the MOB files cannot be found, because the store files in a region only contain the references to the MOB files and a re-open of a region doesn't help the lost MOB files.In this JIRA, we will directly throw DNRIOE only when the MOB files are not found in MobStoreScanner and ReversedMobStoreScanner. Other logics keep the same.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HMobStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="18051" opendate="2017-5-15 00:00:00" fixdate="2017-5-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>balance_rsgroup still run when the Load Balancer is not enabled.</summary>
      <description>When the Load Balancer is not enabled, the command "balancer" will not be executed , but the command "balance_rsgroup" can still run, which is not reasonable.So we need to fix it</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-rsgroup.src.test.java.org.apache.hadoop.hbase.rsgroup.TestRSGroupsBase.java</file>
      <file type="M">hbase-rsgroup.src.test.java.org.apache.hadoop.hbase.rsgroup.TestRSGroups.java</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupAdminServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="18052" opendate="2017-5-16 00:00:00" fixdate="2017-7-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add document for async admin</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0-alpha-2,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="18055" opendate="2017-5-16 00:00:00" fixdate="2017-5-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Releasing L2 cache HFileBlocks before shipped() when switching from pread to stream causes result corruption</summary>
      <description>In HBASE-17917 tries to switch from pread to stream read when a specific size of bytes are read. So in order to switch over, it closes the existing scanners and creates a new scanners with pread=false.When we close the exisitng scanners - if the blocks are served from offheap cache we will decrement the ref count on those blocks and if it becomes zero we make the block ready for eviction. Then there is a chance that the result could be corrupted if new blocks occupy the cache. So the expectation was that till the RPC call completes the response we will hold on to the blocks that are referred by the scan. (except the last one). So trying to switch over to stream read will break this expectation and hence TestBlockEvictionfromclient fails.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSwitchToStreamRead.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="18056" opendate="2017-5-16 00:00:00" fixdate="2017-1-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change CompactingMemStore in BASIC mode to merge multiple segments in pipeline</summary>
      <description>Under HBASE-16417 it was decided that CompactingMemStore in BASIC mode should merge multiple ImmutableSegments in CompactionPipeline. Basic+Merge actually demonstrated reduction in GC, alongside improvement in other metrics.However, the limit on the number of segments in pipeline is still set to 30. Under this JIRA it should be changed to 1, as it was tested under HBASE-16417.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreCompactor.java</file>
    </fixedFiles>
  </bug>
  <bug id="18081" opendate="2017-5-19 00:00:00" fixdate="2017-5-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The way we process connection preamble in SimpleRpcServer is broken</summary>
      <description>Though very rare, but if the preamble is not sent at once, the logic will be broken.</description>
      <version>1.4.0,1.3.1,1.2.5,1.1.10,2.0.0</version>
      <fixedVersion>1.4.0,1.2.6,1.3.2,1.1.11,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleServerRpcConnection.java</file>
    </fixedFiles>
  </bug>
  <bug id="1809" opendate="2009-9-1 00:00:00" fixdate="2009-9-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>NPE thrown in BoundedRangeFileInputStream</summary>
      <description>NPE is thrown in BoundedRangeFileInputStream.read when attempting to synchronize on 'in' (line 97).This probably means the BRFIS was created with a null FSDIS.</description>
      <version>None</version>
      <fixedVersion>0.20.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.hfile.HFile.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="18091" opendate="2017-5-22 00:00:00" fixdate="2017-5-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add API for who currently holds a lock on namespace/ table/ region and log when state is LOCK_EVENT_WAIT</summary>
      <description>Add API for who currently holds a lock on namespace/ table/ region and log message when state is LOCK_EVENT_WAIT</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.SimpleProcedureScheduler.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureScheduler.java</file>
    </fixedFiles>
  </bug>
  <bug id="18103" opendate="2017-5-24 00:00:00" fixdate="2017-8-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[AMv2] If Master gives OPEN to another, if original eventually succeeds, Master will kill it</summary>
      <description>If a RS is slow to open a Region, the Master will give the Region to another to open it (In this case, was a massive set of edits to process and a load of StoreFiles to open...). Should the original RS succeed with its open eventually, on reporting the master the successful open, the Master currently kills the RS because the region is supposed to be elsewhere.This is an easy fix.The RS does not fully open a Region until Master gives it the go so just close the region if master rejects the open....See '6.1.1 If Master gives Region to another to Open, old RS will be kill itself on reject by Master; easy fix!' in https://docs.google.com/document/d/1eVKa7FHdeoJ1-9o8yZcOTAQbv0u0bblBlCCzVSIn69g/edit#heading=h.qtfojp9774h</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.assignment.MockMasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="18104" opendate="2017-5-24 00:00:00" fixdate="2017-6-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[AMv2] Enable aggregation of RPCs (assigns/unassigns, etc.)</summary>
      <description>Machinery is in place to coalesce AMv2 RPCs (Assigns, Unassigns). It needs enabling and verification. From '6.3 We don’t do the aggregating of Assigns' of https://docs.google.com/document/d/1eVKa7FHdeoJ1-9o8yZcOTAQbv0u0bblBlCCzVSIn69g/edit#heading=h.uuwvci2r2tz4</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.RSProcedureDispatcher.java</file>
    </fixedFiles>
  </bug>
  <bug id="18105" opendate="2017-5-24 00:00:00" fixdate="2017-10-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[AMv2] Split/Merge need cleanup; currently they diverge and do not fully embrace AMv2 world</summary>
      <description>Region Split and Merge work on the new AMv2 but they work differently. This issue is about bringing them back together and fully embracing the AMv2 program.They both have issues mostly the fact that they carry around baggage no longer necessary in the new world of assignment.Here are some of the items:Split and Merge metadata modifications are done by the Master now but we have vestige of Split/Merge on RS still; e.g. when we SPLIT, we ask the Master which asks the RS, which turns around, and asks the Master to run the operation. Fun. MERGE is all done Master-side.Clean this up. Remove asking RS to run SPLIT and remove RegionMergeRequest, etc. on RS-side. Also remove PONR. We don’t Points-Of-No-Return now we are up on Pv2. Remove all calls in Interfaces; they are unused. Make RS still able to detect when split, but have it be a client of Master like anyone else.Split is Async but does not return procIdSplit is async. Doesn’t return the procId though. Merge does. Fix. Only hard part here I think is the Admin API does not allow procid return.FlagsCurrently OFFLINE is determined by looking either at the master instance of HTD (isOffline) and/or at the RegionState#state. Ditto for SPLIT. For MERGE, we rely on RegionState#state. Related is a note above on how split works &amp;#8211; there is a split flag in HTD when there should not be.TODO is move to rely on RegionState#state exclusively in Master.From Split/Merge Procedures need finishing in https://docs.google.com/document/d/1eVKa7FHdeoJ1-9o8yZcOTAQbv0u0bblBlCCzVSIn69g/edit#heading=h.4b60dc1h4m1f</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0-alpha-4,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.assignment.TestSplitTableRegionProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.assignment.TestMergeTableRegionsProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestMasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.SplitTableRegionProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MasterObserver.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.RegionServerStatus.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.MasterProcedure.proto</file>
    </fixedFiles>
  </bug>
  <bug id="18108" opendate="2017-5-25 00:00:00" fixdate="2017-10-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure WALs are archived but not cleaned; fix</summary>
      <description>The Procedure WAL files used to be deleted when done. HBASE-14614 keeps them around in case issue but what is missing is a GC for no-longer-needed WAL files. This one is pretty important.From WALProcedureStore Cleaner TODO in https://docs.google.com/document/d/1eVKa7FHdeoJ1-9o8yZcOTAQbv0u0bblBlCCzVSIn69g/edit#heading=h.r2pc835nb7vi</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.cleaner.TestLogsCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.LogCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.CleanerChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.BaseFileCleanerDelegate.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="18109" opendate="2017-5-25 00:00:00" fixdate="2017-6-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Assign system tables first (priority)</summary>
      <description>Need this for stuff like the RSGroup table, etc. Assign these ahead of user-space regions.From 'Handle sys table assignment first (e.g. acl, namespace, rsgroup); currently only hbase:meta is first.' of https://docs.google.com/document/d/1eVKa7FHdeoJ1-9o8yZcOTAQbv0u0bblBlCCzVSIn69g/edit#heading=h.oefcyphs0v0x</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.AssignmentManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.TableDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="18113" opendate="2017-5-25 00:00:00" fixdate="2017-5-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Handle old client without include_stop_row flag when startRow equals endRow</summary>
      <description>Now we have include_start_row/include_stop_row flag in new version. Before it, startRow is include and stopRow is exclude, but when startRow=endRow there is a special logic that we consider it as a get and we should return the value of this row to client.In the new client, if user set start=end we will change include_stop_row to true for behavior compatibility. We should also do a special logic if old client access new server for compatibility at server.</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
    </fixedFiles>
  </bug>
  <bug id="18114" opendate="2017-5-25 00:00:00" fixdate="2017-5-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update the config of TestAsync*AdminApi to make test stable</summary>
      <description>2017-05-25 17:56:34,967 INFO [RpcServer.default.FPBQ.Fifo.handler=3,queue=0,port=50801] master.HMaster$11(2297): Client=hao//127.0.0.1 disable testModifyColumnFamily2017-05-25 17:56:37,974 INFO [RpcClient-timer-pool1-t1] client.AsyncHBaseAdmin$TableProcedureBiConsumer(2219): Operation: DISABLE, Table Name: default:testModifyColumnFamily failed with Failed after attempts=3, exceptions: Thu May 25 17:56:35 CST 2017, , java.io.IOException: Call to localhost/127.0.0.1:50801 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call id=294, waitTime=1008, rpcTimeout=1000Thu May 25 17:56:37 CST 2017, , java.io.IOException: Call to localhost/127.0.0.1:50801 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call id=295, waitTime=1299, rpcTimeout=1000Thu May 25 17:56:37 CST 2017, , java.io.IOException: Call to localhost/127.0.0.1:50801 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call id=296, waitTime=668, rpcTimeout=660017-05-25 17:56:38,936 DEBUG [RpcServer.default.FPBQ.Fifo.handler=3,queue=0,port=50801] procedure2.ProcedureExecutor(788): Stored procId=15, owner=hao, state=RUNNABLE:DISABLE_TABLE_PREPARE, DisableTableProcedure table=testModifyColumnFamilyFor this disable table procedure, master return the procedure id when it submit the procedure to ProcedureExecutor. And the above procedure take 4 seconds to submit. So the disable table call failed because the rpc timeout is 1 seconds and the retry number is 3.For admin operation, I thought we don't need change the default timeout config in unit test. And the retry is not need, too. (Or we can set a retry &gt; 1 to test nonce thing). Meanwhile, the default timeout is 60 seconds. So the test type may need change to LargeTests.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTableAdminApi.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncSnapshotAdminApi.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncReplicationAdminApi.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncRegionAdminApi.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncProcedureAdminApi.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncNamespaceAdminApi.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncAdminBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="18118" opendate="2017-5-26 00:00:00" fixdate="2017-5-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Default storage policy if not configured cannot be "NONE"</summary>
      <description>HBase can't use 'NONE' as default storage policy if not configured because HDFS supports no such policy. This policy name was probably available in a precommit or early version of the HDFS side support for heterogeneous storage. Now the best default is 'HOT'.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="1812" opendate="2009-9-2 00:00:00" fixdate="2009-9-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document fact that Scanners do not respect row locks</summary>
      <description>See discussion in hbase-1806. Agreement that Scanners are loosey-goosey. Need to doc. that this is how they work in Scanner javadoc.</description>
      <version>None</version>
      <fixedVersion>0.20.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.client.package-info.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="18122" opendate="2017-5-26 00:00:00" fixdate="2017-5-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scanner id should include ServerName of region server</summary>
      <description>Now the scanner id is a long number from 1 to max in a region server. Each new scanner will have a scanner id.If a client has a scanner whose id is x, when the RS restart and the scanner id is also incremented to x or a little larger, there will be a scanner id collision.So the scanner id should now be same during each time the RS restart. We can add the start timestamp as the highest several bits in scanner id uint64.And because HBASE-18121 is not easy to fix and there are many clients with old version. We can also encode server host:port into the scanner id.So we can use ServerName.</description>
      <version>1.4.0,1.3.1,1.1.10,1.2.6,2.0.0</version>
      <fixedVersion>1.4.0,1.3.2,1.1.11,2.0.0,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRpcRetryingCallerFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="18129" opendate="2017-5-27 00:00:00" fixdate="2017-5-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>truncate_preserve fails when the truncate method doesn&amp;#39;t exists on the master</summary>
      <description>Recently, I runs a rolling upgrade from HBase 0.98.x to HBase 1.2.5. During the master hasn't been upgraded yet, I truncate a table by the command truncate_preserve of 1.2.5, but failed.hbase(main):001:0&gt; truncate_preserve 'cf_logs'Truncating 'cf_logs' table (it may take a while): - Disabling table... - Truncating table... - Dropping table... - Creating table with region boundaries...ERROR: no method 'createTable' for arguments (org.apache.hadoop.hbase.HTableDescriptor,org.jruby.java.proxies.ArrayJavaProxy) on Java::OrgApacheHadoopHbaseClient::HBaseAdminAfter checking code and commit history, I found it's HBASE-12833 which causes this bug.so we should fix it.</description>
      <version>1.2.5,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.test.ruby.hbase.admin.test.rb</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug id="18145" opendate="2017-6-1 00:00:00" fixdate="2017-6-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The flush may cause the corrupt data for reading</summary>
      <description>After HBASE-17887, the store scanner closes the memstore scanner in updating the inner scanners. The chunk which stores the current data may be reclaimed. So if the chunk is rewrited before we send the data to client, the client will receive the corrupt data.This issue also breaks the TestAcid*.</description>
      <version>2.0.0</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="18147" opendate="2017-6-1 00:00:00" fixdate="2017-7-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>nightly job to check health of active branches</summary>
      <description>We should set up a job that runs Apache Yetus Test Patch's nightly mode. Essentially, it produces a report that considers how the branch measures up against the things we check in our precommit checks.</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0-alpha-2,1.1.12,2.0.0,1.2.7</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.docker.Dockerfile</file>
    </fixedFiles>
  </bug>
  <bug id="18149" opendate="2017-6-2 00:00:00" fixdate="2017-6-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The setting rules for table-scope attributes and family-scope attributes should keep consistent</summary>
      <description>I use the following command to create a table.hbase(main):030:0&gt; create 't3',{NAME =&gt; 'f2', BLOCKCACHE =&gt; false}, {COMPACTION_ENABLED =&gt; false}An argument ignored (unknown or overridden): COMPACTION_ENABLED0 row(s) in 1.1390 secondshbase(main):031:0&gt; describe 't3'Table t3 is ENABLEDt3 COLUMN FAMILIES DESCRIPTION {NAME =&gt; 'f2', BLOOMFILTER =&gt; 'ROW', VERSIONS =&gt; '1', IN_MEMORY =&gt; 'false', KEEP_DELETED_CELLS =&gt; 'FALSE', DATA_BLOCK_ENCODING =&gt; 'NONE', TTL =&gt; 'FOREVER', COMPRESSION =&gt; 'NONE', MIN_VERSIONS =&gt; '0', BLOCKCACHE =&gt; 'false', BLOCKSIZE =&gt; '65536', REPLICATION_SCOPE =&gt; '0'}1 row(s) in 0.0720 secondsBLOCKCACHE was in effect but COMPACTION_ENABLED didn't take effect.After checking code, I found that if the table-scope attributes value is false, you need to enclose 'false' in single quotation marks while family-scope is not required.so we should keep the consistent logic for table-scope and family-scope.the command alter also have the same problem.</description>
      <version>1.2.5,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.test.ruby.hbase.admin.test.rb</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug id="18209" opendate="2017-6-12 00:00:00" fixdate="2017-6-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Include httpclient / httpcore jars in build artifacts</summary>
      <description>We need httpclient &amp; httpcore jars to be present when rootdir is placed on s3(a).Attempts to move to the fully shaded amazon-SDK JAR caused problems of its own. (according to steve_l)Here are the versions we should use:&lt;commons.httpclient.version&gt;4.5.2&lt;/commons.httpclient.version&gt;&lt;commons.httpcore.version&gt;4.4.4&lt;/commons.httpcore.version&gt;Currently they are declared test dependency.This JIRA is to move to compile time dependency so that the corresponding jars are bundled in lib directory.</description>
      <version>None</version>
      <fixedVersion>2.0.0-alpha-2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-assembly.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="18216" opendate="2017-6-14 00:00:00" fixdate="2017-3-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[AMv2] Workaround for HBASE-18152, corrupt procedure WAL</summary>
      <description>Let me commit workaround for the issue up in HBASE-18152, corruption in the master wal procedure files. Testing on cluster shows it helps.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALFormatReader.java</file>
    </fixedFiles>
  </bug>
  <bug id="1822" opendate="2009-9-10 00:00:00" fixdate="2009-9-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove the deprecated APIs</summary>
      <description>Remove all the deprecated stuff in client and mapred.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.mapreduce.Driver.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.util.TestMigration.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.util.TestMergeTool.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.util.SoftSortedMapTest.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TimestampTestBase.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.thrift.TestThriftServer.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestZooKeeper.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestTable.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestSerialization.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestRegionRebalancing.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestMasterAdmin.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestKeyValue.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestHStoreKey.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestCompare.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestClassMigration.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestStoreFile.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestScanWildcardColumnTracker.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestScanner.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestMemStore.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestLruHashMap.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestKeyValueHeap.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestHLog.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.OOMERegionServer.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.DisabledTestRegionServerExit.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.MultiRegionTable.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.MiniZooKeeperCluster.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.master.OOMEHMaster.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.mapred.TestTableMapReduce.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.mapred.TestTableIndex.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.mapreduce.TestTimeRangeMapRed.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.mapreduce.TestTableMapReduce.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.mapreduce.TestTableIndex.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.io.TestHeapSize.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.io.TestHbaseObjectWritable.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.HBaseTestCase.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.client.TestOldAPITimestamp.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.client.TestOldAPIHTable.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.client.TestOldAPIGetRowVersions.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.client.TestHTable.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.client.TestHBaseAdmin.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.client.TestForceSplit.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.client.TestClient.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.client.TestBatchUpdate.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.AbstractMergeTestBase.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.Writables.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.SoftSortedMap.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.Migrate.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.ThriftUtilities.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.TimestampModel.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.TimestampController.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.TableModel.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.TableController.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.Status.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.serializer.SimpleXMLSerializer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.serializer.RestSerializerFactory.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.serializer.JSONSerializer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.serializer.ISerializable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.serializer.IRestSerializer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.serializer.AbstractRestSerializer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.ScannerModel.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.ScannerController.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.RowModel.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.RowController.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.RESTConstants.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.parser.XMLRestParser.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.parser.JsonRestParser.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.parser.IHBaseRestParser.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.parser.HBaseRestParserFactory.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.package.html</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.filter.WhileMatchRowFilterFactory.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.filter.StopRowFilterFactory.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.filter.RowFilterSetFactory.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.filter.RegExpRowFilterFactory.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.filter.PageRowFilterFactory.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.filter.InclusiveStopRowFilterFactory.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.filter.FilterFactoryConstants.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.filter.FilterFactory.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.filter.ColumnValueFilterFactory.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.exception.HBaseRestException.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.Dispatcher.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.descriptors.TimestampsDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.descriptors.ScannerIdentifier.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.descriptors.ScannerDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.descriptors.RowUpdateDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.descriptors.RestCell.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.DatabaseModel.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.DatabaseController.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.AbstractModel.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.AbstractController.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.ScanQueryMatcher.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.MemStore.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.package-info.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.regionserver.HStoreFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.onelab.filter.RetouchedBloomFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.onelab.filter.RemoveScheme.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.onelab.filter.Key.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.onelab.filter.HashFunction.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.onelab.filter.Filter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.onelab.filter.DynamicBloomFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.onelab.filter.CountingBloomFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.onelab.filter.BloomFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.io.Reference.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.io.HBaseMapFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.io.HalfMapFileReader.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.io.BloomFilterMapFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.HStoreKey.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.HStoreFileToStoreFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.RegionManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ProcessServerShutdown.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ProcessRegionStatusChange.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ModifyTableMeta.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.MetaRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ChangeTableState.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableSplit.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableReduce.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableOutputFormat.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableMapReduceUtil.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableMap.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableInputFormatBase.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableInputFormat.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.RowCounter.Counters.properties</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.RowCounter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.package-info.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.LuceneDocumentWrapper.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.IndexTableReduce.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.IndexOutputFormat.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.IndexConfiguration.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.IdentityTableReduce.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.IdentityTableMap.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.HRegionPartitioner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.GroupingTableMap.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.Driver.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.BuildTableIndex.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapreduce.RowCounter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapreduce.IndexTableReducer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapreduce.GroupingTableMapper.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.contrib.stargate.src.java.org.apache.hadoop.hbase.stargate.model.CellModel.java</file>
      <file type="M">src.contrib.stargate.src.java.org.apache.hadoop.hbase.stargate.RESTServlet.java</file>
      <file type="M">src.contrib.stargate.src.java.org.apache.hadoop.hbase.stargate.RowResource.java</file>
      <file type="M">src.contrib.stargate.src.java.org.apache.hadoop.hbase.stargate.RowResultGenerator.java</file>
      <file type="M">src.contrib.stargate.src.java.org.apache.hadoop.hbase.stargate.ScannerInstanceResource.java</file>
      <file type="M">src.contrib.stargate.src.java.org.apache.hadoop.hbase.stargate.ScannerResultGenerator.java</file>
      <file type="M">src.contrib.stargate.src.test.org.apache.hadoop.hbase.stargate.TestRowResource.java</file>
      <file type="M">src.contrib.stargate.src.test.org.apache.hadoop.hbase.stargate.TestScannerResource.java</file>
      <file type="M">src.contrib.stargate.src.test.org.apache.hadoop.hbase.stargate.TestTableResource.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.client.tableindexed.IndexedTable.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.client.tableindexed.IndexedTableAdmin.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.client.transactional.HBaseBackedTransactionLogger.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.client.transactional.TransactionalTable.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.regionserver.tableindexed.IndexedRegion.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.regionserver.tableindexed.IndexMaintenanceUtils.java</file>
      <file type="M">src.contrib.transactional.src.test.org.apache.hadoop.hbase.client.tableindexed.TestIndexedTable.java</file>
      <file type="M">src.contrib.transactional.src.test.org.apache.hadoop.hbase.client.transactional.StressTestTransactions.java</file>
      <file type="M">src.contrib.transactional.src.test.org.apache.hadoop.hbase.client.transactional.TestTransactions.java</file>
      <file type="M">src.contrib.transactional.src.test.org.apache.hadoop.hbase.regionserver.transactional.TestTHLogRecovery.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.Delete.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.Get.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.Put.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.Result.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.Scanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ClusterStatus.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.ColumnValueFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.InclusiveStopRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.PageRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.PrefixRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.RegExpRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.RowFilterInterface.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.RowFilterSet.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.StopRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.ValueFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.WhileMatchRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HStoreKey.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.BatchOperation.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.BatchUpdate.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.Cell.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.CodeToClassAndBack.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.HbaseObjectWritable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.RowResult.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HBaseServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapreduce.BuildTableIndex.java</file>
    </fixedFiles>
  </bug>
  <bug id="18220" opendate="2017-6-15 00:00:00" fixdate="2017-6-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compaction scanners need not reopen storefile scanners while trying to switch over from pread to stream</summary>
      <description>We try switch over to stream scanner if we have read more than a certain number of bytes. In case of compaction we already have stream based scanners only and but on calling shipped() we try to again close and reopen the scanners which is unwanted. Apache9</description>
      <version>3.0.0-alpha-1,2.0.0-alpha-1,2.0.0</version>
      <fixedVersion>2.0.0-alpha-2,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="18224" opendate="2017-6-15 00:00:00" fixdate="2017-8-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade jetty</summary>
      <description>Jetty can be updated to 9.4.6 and thrift can be updated to 0.10.0. I tried to update them in HBASE-17898 but some unit tests failed, so created a sub-task for them.</description>
      <version>None</version>
      <fixedVersion>2.0.0-alpha-3,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift.TestThriftHttpServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.http.TestSSLHttpServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.http.TestSpnegoHttpServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.http.TestHttpServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.favored.FavoredNodeLoadBalancer.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="18226" opendate="2017-6-16 00:00:00" fixdate="2017-6-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Disable reverse DNS lookup at HMaster and use the hostname provided by RegionServer</summary>
      <description>Description updated:In some unusual network environment, forward DNS lookup is supported while reverse DNS lookup may not work properly.This JIRA is to address that HMaster uses the hostname passed from RS instead of doing reverse DNS lookup to tells RS which hostname to use during reportForDuty() . This has already been implemented by HBASE-12954 by adding "useThisHostnameInstead" field in RegionServerStatusProtos.Currently "useThisHostnameInstead" is optional and RS by default only passes port, server start code and server current time info to HMaster during RS reportForDuty(). In order to use this field, users currently need to specify "hbase.regionserver.hostname" on every regionserver node's hbase-site.xml. This causes some trouble in1. some deployments managed by some management tools like Ambari, which maintains the same copy of hbase-site.xml across all the nodes.2. HBASE-12954 is targeting multihomed hosts, which users want to manually set the hostname value for each node. In the other cases (not multihomed), I just want RS to use the hostname return by the node and set it in useThisHostnameInstead and pass to HMaster during reportForDuty().I would like to introduce a setting that if the setting is set to true, "useThisHostnameInstead" will be set to the hostname RS gets from the node. Then HMaster will skip reverse DNS lookup because it sees "useThisHostnameInstead" field is set in the request."hbase.regionserver.hostname.reported.to.master", is it a good name?--------------------Regarding the hostname returned by the RS node, I read the source code again (including hadoop-common dns.java). By default RS gets hostname by calling InetAddress.getLocalHost().getCanonicalHostName(). If users specify "hbase.regionserver.dns.interface" or "hbase.regionserver.dns.nameserver" or some underlying system configuration changes (eg. modifying /etc/nsswitch.conf), it may first read from DNS or other sources instead of first checking /etc/hosts file.</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0-alpha-2,2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerHostname.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="18232" opendate="2017-6-18 00:00:00" fixdate="2017-12-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add variable size chunks to the MSLAB</summary>
      <description>Add possibility to create a variable size chunks of memory, so any cell (of any size) can reside on a chunk.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompactingToCellFlatMapMemStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompactingMemStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCellFlatSet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreLAB.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ImmutableMemStoreLAB.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ChunkCreator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Chunk.java</file>
    </fixedFiles>
  </bug>
  <bug id="18269" opendate="2017-6-26 00:00:00" fixdate="2017-6-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Jython docs out of date</summary>
      <description>The documentation describing how to launch Jython + HBase is out of date. - https://hbase.apache.org/book.html#jythonFirst, we would set the classpath differently:HBASE_CLASSPATH=/home/hbase/jython.jar bin/hbase org.python.util.jythonThen, the actual code example is out of date too:&gt;&gt;&gt; desc = HTableDescriptor(tablename)&gt;&gt;&gt; desc.addFamily(HColumnDescriptor("content:"))Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; at org.apache.hadoop.hbase.HColumnDescriptor.isLegalFamilyName(HColumnDescriptor.java:566) at org.apache.hadoop.hbase.HColumnDescriptor.&lt;init&gt;(HColumnDescriptor.java:470) at org.apache.hadoop.hbase.HColumnDescriptor.&lt;init&gt;(HColumnDescriptor.java:425) at org.apache.hadoop.hbase.HColumnDescriptor.&lt;init&gt;(HColumnDescriptor.java:390) at org.apache.hadoop.hbase.HColumnDescriptor.&lt;init&gt;(HColumnDescriptor.java:338) at org.apache.hadoop.hbase.HColumnDescriptor.&lt;init&gt;(HColumnDescriptor.java:327) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:526) at org.python.core.PyReflectedConstructor.constructProxy(PyReflectedConstructor.java:211)We should make sure that the examples we claim are runnable actually are.</description>
      <version>1.3.1,1.2.6,1.5.0,1.4.2,2.0.0</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.external.apis.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="18290" opendate="2017-6-28 00:00:00" fixdate="2017-6-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix TestAddColumnFamilyProcedure and TestDeleteTableProcedure</summary>
      <description>These two tests don't pass. Turns out the cause was interesting.We added a workaround for case where procedure WAL could have procs out of order.HBASE-18216 &amp;#91;AMv2&amp;#93; Workaround for HBASE-18152, corrupt procedure WALIf we find a procedure that is not 'increasing' &amp;#8211; of a later timestamp or procid &amp;#8211; then we'd skip the application of the 'old' proc. The workaround was until we figure in what scenarios we can write procedures out of order (seems to be rare and high-concurrency... TBD).These two tests trip FAILs and ROLLBACKs (double delete of table or disable of an already disabled table). They are good tests. But procedures that get marked FAIL or ROLLEDBACK will have procids that are less than current. Makes it so we skipped adding the ROLLBACK and so finishing up the procedure.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALFormatReader.java</file>
    </fixedFiles>
  </bug>
  <bug id="18448" opendate="2017-7-25 00:00:00" fixdate="2017-8-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>EndPoint example for refreshing HFiles for stores</summary>
      <description>In the case where multiple HBase clusters are sharing a common rootDir, even after flushing the data fromone cluster doesn't mean that other clusters (replicas) will automatically pick the new HFile. Through this patch,we are exposing the refresh HFiles API which when issued from a replica will update the in-memory file handle listwith the newly added file.This allows replicas to be consistent with the data written through the primary cluster.</description>
      <version>1.3.1,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0-alpha-3,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-examples.src.test.java.org.apache.hadoop.hbase.coprocessor.example.TestRefreshHFilesEndpoint.java</file>
      <file type="M">hbase-examples.src.main.protobuf.RefreshHFiles.proto</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.coprocessor.example.RefreshHFilesEndpoint.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.client.example.RefreshHFilesClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
    </fixedFiles>
  </bug>
  <bug id="18560" opendate="2017-8-10 00:00:00" fixdate="2017-8-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Test master.assignment.TestAssignmentManager hangs on master and its in flaky list</summary>
      <description>Test master.assignment.TestAssignmentManager hangs on master and showing up in flaky list</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockNoopMasterServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="18588" opendate="2017-8-13 00:00:00" fixdate="2017-8-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Verify we&amp;#39;re using netty .so epolling on linux post HBASE-18271</summary>
      <description>This is a task to verify that indeed we are using .so native epoll on linux. This task is probably unnecessary since we'd fail on the linux build box if this was not in place but verify that our relocation is indeed finding the native code. Assigned myself.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-protocol-shaded.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="18609" opendate="2017-8-16 00:00:00" fixdate="2017-9-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Apply ClusterStatus#getClusterStatus(EnumSet&lt;Option&gt;) in code base</summary>
      <description>HBASE-15511 enable us to get the cluster status by scope, and after refactoring in HBASE-18621. We should apply it in code base so as to prevent the useless information.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestMiniClusterLoadSequential.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsckReplicas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.BaseTestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestRegionLoad.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationStatus.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestMasterReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerReadRequestMetrics.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterOperationsForRegionReplicas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestFavoredStochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestFavoredStochasticBalancerPickers.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMetaWithReplicas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncClusterAdminApi.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionMover.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsckRepair.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.Canary.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionPlacementMaintainer.java</file>
      <file type="M">hbase-rsgroup.src.test.java.org.apache.hadoop.hbase.rsgroup.TestRSGroupsBase.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.StorageClusterVersionResource.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.StorageClusterStatusResource.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.mapreduce.IntegrationTestBulkLoad.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.MoveRegionsOfTableAction.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="18656" opendate="2017-8-22 00:00:00" fixdate="2017-8-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Address issues found by error-prone in hbase-common</summary>
      <description>We should address the new compilation errors found by running with -PerrorProne.Can convert this to a top-level task and add subtasks for modules if desired (in which case, link it back to parent issue HBASE-12187, please)</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0-alpha-3,2.0.0,1.2.7</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestDrainBarrier.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestConcatenatedLists.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestChoreService.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ConcatenatedLists.java</file>
    </fixedFiles>
  </bug>
  <bug id="18667" opendate="2017-8-23 00:00:00" fixdate="2017-10-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Disable error-prone for hbase-protocol-shaded</summary>
      <description>This is all generated code that we shouldn't be running extra analysis on because it adds a lot of noise to the build, and also takes a very long time (15 minutes on my machine). Let's make it fast and simple.Even when we run with error-prone enabled for the rest of the build, it should not apply here.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-protocol.pom.xml</file>
      <file type="M">hbase-protocol-shaded.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="18791" opendate="2017-9-11 00:00:00" fixdate="2017-9-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBASE_HOME/lib does not contain hbase-mapreduce-${project.version}-tests.jar</summary>
      <description>hbase peError: Could not find or load main class org.apache.hadoop.hbase.PerformanceEvaluationhbase lttError: Could not find or load main class org.apache.hadoop.hbase.util.LoadTestToolThose class are in hbase-mapreduce-test.jar</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0-alpha-3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-assembly.src.main.assembly.components.xml</file>
    </fixedFiles>
  </bug>
  <bug id="18792" opendate="2017-9-12 00:00:00" fixdate="2017-4-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase-2 needs to defend against hbck operations</summary>
      <description>hbck needs updating to run against hbase2. Meantime, if an hbck from hbase1 is run against hbck2, it may do damage. hbase2 should defend itself against hbck1 ops.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.VersionInfo.java</file>
    </fixedFiles>
  </bug>
  <bug id="18875" opendate="2017-9-25 00:00:00" fixdate="2017-9-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thrift server supports read-only mode</summary>
      <description>Provide option for thrift server to support read-only mode.To start the thrift server, use the -ro option or set hbase.thrift.readonly to true.false: Both read and write request are permitted.(all methods)true : Only the read request is permitted. (only get/scan method)</description>
      <version>3.0.0-alpha-1,1.5.0,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0-alpha-4,2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftHBaseServiceHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="18876" opendate="2017-9-25 00:00:00" fixdate="2017-9-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Backup create command fails to take queue parameter as option</summary>
      <description>Backup help shows we can set queue using -q parameter.-q &lt;arg&gt; Yarn queue name to run backup restore command onBut when we give ./hbase backup create full hdfs://localhost:8020/test/ -t test1 -q hbaseIt throws following error "Error when parsing command-line arguments: Unrecognized option: -q"</description>
      <version>None</version>
      <fixedVersion>2.0.0-alpha-4,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.BackupDriver.java</file>
    </fixedFiles>
  </bug>
  <bug id="18878" opendate="2017-9-26 00:00:00" fixdate="2017-10-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use Optional&lt;T&gt; return types when T can be null</summary>
      <description>I've already done lots of Nullable to Optional change when purging the interfaces for CP. This is a big one so open a separated issue for it.</description>
      <version>None</version>
      <fixedVersion>2.0.0-alpha-4,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestWithDisabledAuthorization.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestNamespaceCommands.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController3.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestProtobufRpcServiceImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.TokenProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SecureBulkLoadManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.RegionServerRpcQuotaManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.ServerCall.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcCallContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.CallRunner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.ObserverContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.VersionInfoUtil.java</file>
      <file type="M">hbase-endpoint.src.test.java.org.apache.hadoop.hbase.coprocessor.ProtobufCoprocessorService.java</file>
      <file type="M">hbase-endpoint.src.main.java.org.apache.hadoop.hbase.coprocessor.Export.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Classes.java</file>
    </fixedFiles>
  </bug>
  <bug id="18988" opendate="2017-10-11 00:00:00" fixdate="2017-12-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add release managers to reference guide</summary>
      <description>Reference guide lists release managers only up to version 1.3. We should have a complete list there.http://hbase.apache.org/book.html#_release_managers</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="18989" opendate="2017-10-12 00:00:00" fixdate="2017-10-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Polish the compaction related CP hooks</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0-alpha-4,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MockRegionServerServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Region.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionLifeCycleTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionObserver.java</file>
    </fixedFiles>
  </bug>
  <bug id="1899" opendate="2009-10-9 00:00:00" fixdate="2009-10-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use scanner caching in shell count</summary>
      <description>Since the shell count now uses the FirstKeyOnlyFilter, it's safe to combine it with scanner caching for huge count speedups.</description>
      <version>None</version>
      <fixedVersion>0.20.2,0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.HBase.rb</file>
    </fixedFiles>
  </bug>
  <bug id="19000" opendate="2017-10-12 00:00:00" fixdate="2017-12-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Group multiple block cache clear requests per server</summary>
      <description>During the review of HBASE-18624, I brought up the following:There would be multiple regions on the same server whose block cache is to be cleared.Multiple block cache clear requests should be grouped per server to reduce the number of RPC calls.</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.HBase.proto</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.CacheEvictionStatsBuilder.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.CacheEvictionStats.java</file>
    </fixedFiles>
  </bug>
  <bug id="19002" opendate="2017-10-13 00:00:00" fixdate="2017-11-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Introduce more examples to show how to intercept normal region operations</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.coprocessor.example.ExampleRegionObserverWithMetrics.java</file>
    </fixedFiles>
  </bug>
  <bug id="19141" opendate="2017-10-31 00:00:00" fixdate="2017-11-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[compat 1-2] getClusterStatus always return empty ClusterStatus</summary>
      <description>We are able to limit the scope to get part of ClusterStatus in 2.0. However the request sent by 1.x client has no specific scope info to retrieve any information from ClusterStatus.</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestClientClusterStatus.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="19227" opendate="2017-11-9 00:00:00" fixdate="2017-11-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Nightly jobs should archive JVM dumpstream files</summary>
      <description>came up on dev@ discussion about some of our current nightly test failures. when surefire fails to launch a test JVM instance, the details go into a file that we currently don't archive:&amp;#91;ERROR&amp;#93; Please refer to dump files (if any exist) &amp;#91;date&amp;#93;-jvmRun&amp;#91;N&amp;#93;.dump, &amp;#91;date&amp;#93;.dumpstream and &amp;#91;date&amp;#93;-jvmRun&amp;#91;N&amp;#93;.dumpstream.Add them to the default archive pattern.</description>
      <version>None</version>
      <fixedVersion>1.0.4,1.1.13,2.0.0,1.2.7</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  <bug id="19228" opendate="2017-11-9 00:00:00" fixdate="2017-11-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>nightly job should gather machine stats.</summary>
      <description>leverage the script added in HBASE-19189 to get machine stats when running nightly</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0-beta-1,1.1.13,2.0.0,1.2.7</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
      <file type="M">dev-support.gather.machine.environment.sh</file>
    </fixedFiles>
  </bug>
  <bug id="19229" opendate="2017-11-9 00:00:00" fixdate="2017-11-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Nightly script to check source artifact should not do a destructive git operation without opt-in</summary>
      <description>right now we have a "git please destroy all this stuff" command in the check of the source artifact. we shouldn't do this unless the person invoking the script has indicated that's okay (e..g through a cli flag).</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0-beta-1,1.1.13,2.0.0,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
      <file type="M">dev-support.hbase.nightly.source-artifact.sh</file>
    </fixedFiles>
  </bug>
  <bug id="19290" opendate="2017-11-17 00:00:00" fixdate="2017-12-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reduce zk request when doing split log</summary>
      <description>We observe once the cluster has 1000+ nodes and when hundreds of nodes abort and doing split log, the split is very very slow, and we find the regionserver and master wait on the zookeeper response, so we need to reduce zookeeper request and pressure for big cluster.(1) Reduce request to rsZNode, every time calculateAvailableSplitters will get rsZNode's children from zookeeper, when cluster is huge, this is heavy. This patch reduce the request. (2) When the regionserver has max split tasks running, it may still trying to grab task and issue zookeeper request, we should sleep and wait until we can grab tasks again.</description>
      <version>3.0.0-alpha-1,1.5.0,2.0.0</version>
      <fixedVersion>1.5.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination.java</file>
    </fixedFiles>
  </bug>
  <bug id="19389" opendate="2017-11-30 00:00:00" fixdate="2017-3-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Limit concurrency of put with dense (hundreds) columns to prevent write handler exhausted</summary>
      <description>In a large cluster, with a large number of clients, we found the RS's handlers are all busy sometimes. And after investigation we found the root cause is about CSLM, such as compare function heavy load. We reviewed the related WALs, and found that there were many columns (more than 1000 columns) were writing at that time.</description>
      <version>2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.throttle.TestStoreHotnessProtector.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.throttle.StoreHotnessProtector.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.TestHeapSize.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="19390" opendate="2017-11-30 00:00:00" fixdate="2017-12-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Revert to older version of Jetty 9.3</summary>
      <description>As discussed in HBASE-19256 we will have to temporarily revert to Jetty 9.3 due existing issues with 9.4 and Hadoop3. Once HBASE-19256 is resolved we can revert to 9.4.</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="19437" opendate="2017-12-6 00:00:00" fixdate="2017-3-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Batch operation can&amp;#39;t handle the null result for Append/Increment</summary>
      <description>But the Table#append and #increment can handle the null result...that is an inconsistent behavior for user.I have noticed two scenarios that server will return null result to user. postAppend/postIncrement return null mutation.isReturnResults() is false and preIncrementAfterRowLock/preAppendAfterRowLock doesn't return nullWe should wrap the null to empty result on server side. CP user should throw Exception rather than return null if they intend to say something is broken.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="19448" opendate="2017-12-7 00:00:00" fixdate="2017-12-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace StringBuffer with StringBuilder for hbase-server</summary>
      <description>Replace the thread-safe StringBuffer class with the un-synchronized StringBuilder class for better performance.</description>
      <version>3.0.0-alpha-1,2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.SecureTestUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDefaultMemStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mob.MobTestUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterOperationsForRegionReplicas.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.AbstractMemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServerFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.favored.FavoredNodeAssignmentHelper.java</file>
    </fixedFiles>
  </bug>
  <bug id="19505" opendate="2017-12-13 00:00:00" fixdate="2017-12-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Disable ByteBufferPool by default at HM</summary>
      <description>The main usage of the pool is while accepting bigger sized requests ie. Mutation requests. HM do not have any regions by default. So we can make this pool OFF in HM side. Still add a config to turn this ON.</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestNettyIPC.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestBlockingIPC.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServerInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServerFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.NettyRpcServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="19521" opendate="2017-12-15 00:00:00" fixdate="2017-12-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase mob compaction need to check hfile version</summary>
      <description>When HBase master configuration is not set hfile.format.version to 3, and user already run compact mob, this operation will cause compactor write V2 ref hfile, the result is that user can not scan the correct cell value since the mob cell ref tags are not written. So it is necessary to check the hfile version before to run mob compaction.</description>
      <version>3.0.0-alpha-1,2.0.0</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="19524" opendate="2017-12-15 00:00:00" fixdate="2017-12-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Master side changes for moving peer modification from zk watcher to procedure</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.replication.DummyModifyPeerProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockNoopMasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.ReplicationManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.RefreshPeerProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.RefreshPeerCallable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.ModifyPeerProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ProcedurePrepareLatch.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.RegionTransitionProcedure.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeersZKImpl.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.Replication.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.RegionServerStatus.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.MasterProcedure.proto</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.RemoteProcedureDispatcher.java</file>
    </fixedFiles>
  </bug>
  <bug id="19525" opendate="2017-12-15 00:00:00" fixdate="2017-12-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RS side changes for moving peer modification from zk watcher to procedure</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationTrackerZKImpl.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.replication.TestDummyModifyPeerProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.replication.DummyModifyPeerProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.Replication.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.RefreshPeerCallable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.BaseReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ReplicationSourceService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.RSProcedureHandler.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationTrackerZKImpl.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeerZKImpl.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeersZKImpl.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeer.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationListener.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="19526" opendate="2017-12-15 00:00:00" fixdate="2017-12-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update hadoop version to 3.0 GA</summary>
      <description>We're still building against hadoop 3.0-beta1, while GA is recently released. We should update, hopefully no surprises.</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-resource-bundle.src.main.resources.supplemental-models.xml</file>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  <bug id="19528" opendate="2017-12-15 00:00:00" fixdate="2017-2-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Major Compaction Tool</summary>
      <description>The basic overview of how this tool works is:Parameters: Table Stores ClusterConcurrency TimestampSo you input a table, desired concurrency and the list of stores you wish to major compact. The tool first checks the filesystem to see which stores need compaction based on the timestamp you provide (default is current time). It takes that list of stores that require compaction and executes those requests concurrently with at most N distinct RegionServers compacting at a given time. Each thread waits for the compaction to complete before moving to the next queue. If a region split, merge or move happens this tool ensures those regions get major compacted as well. This helps us in two ways, we can limit how much I/O bandwidth we are using for major compaction cluster wide and we are guaranteed after the tool completes that all requested compactions complete regardless of moves, merges and splits.</description>
      <version>None</version>
      <fixedVersion>1.5.0,2.0.0-beta-2,2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.compaction.MajorCompactorTest.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.compaction.MajorCompactionRequestTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="19530" opendate="2017-12-15 00:00:00" fixdate="2017-12-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>New regions should always be added with state CLOSED</summary>
      <description>We shouldn't add regions with state null. In case of failures and recovery, it's not possible to determine what did it mean and things become uncertain.All operations should add regions in a well defined state.For now, we'll set the default to CLOSED, since whatever ops are adding new regions, they would anyways be enabling them explicitly if needed.fyi: stack</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MetaTableAccessor.java</file>
    </fixedFiles>
  </bug>
  <bug id="19536" opendate="2017-12-17 00:00:00" fixdate="2017-12-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Client side changes for moving peer modification from zk watcher to procedure</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
    </fixedFiles>
  </bug>
  <bug id="19537" opendate="2017-12-17 00:00:00" fixdate="2017-12-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove unnecessary semicolons in hbase-backup</summary>
      <description>Currently hbase-backup has some places with unnecessary semicolons, which should be removed.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-backup.src.test.java.org.apache.hadoop.hbase.backup.TestIncrementalBackupMergeWithFailures.java</file>
      <file type="M">hbase-backup.src.test.java.org.apache.hadoop.hbase.backup.TestBackupDeleteRestore.java</file>
      <file type="M">hbase-backup.src.test.java.org.apache.hadoop.hbase.backup.TestBackupBase.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.util.RestoreTool.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.RestoreDriver.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.mapreduce.MapReduceBackupMergeJob.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.mapreduce.MapReduceBackupCopyJob.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.impl.TableBackupClient.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.impl.RestoreTablesClient.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.impl.IncrementalTableBackupClient.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.impl.IncrementalBackupManager.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.impl.FullTableBackupClient.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupSystemTable.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupManifest.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupCommands.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupAdminImpl.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.BackupInfo.java</file>
    </fixedFiles>
  </bug>
  <bug id="19538" opendate="2017-12-17 00:00:00" fixdate="2017-12-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove unnecessary semicolons in hbase-client</summary>
      <description>Currently hbase-client has some places with unnecessary semicolons, which should be removed.</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestAsyncProcess.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.ThrottlingException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.SpaceViolationPolicy.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MetaTableAccessor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ClusterStatus.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.SnapshotType.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.security.SecurityCapability.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.CompactionState.java</file>
    </fixedFiles>
  </bug>
  <bug id="19539" opendate="2017-12-17 00:00:00" fixdate="2017-12-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove unnecessary semicolons in hbase-common</summary>
      <description>Currently hbase-common has some places with unnecessary semicolons, which should be removed.</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestClassFinder.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestCellUtil.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.io.crypto.KeyProviderForTesting.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.ClassTestFinder.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.ClassFinder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ProcedureState.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.TagCompressionContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.aes.CommonsCryptoAESDecryptor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.Codec.java</file>
    </fixedFiles>
  </bug>
  <bug id="19564" opendate="2017-12-20 00:00:00" fixdate="2017-12-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure id is missing in the response of peer related operations</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.ModifyPeerProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="19996" opendate="2018-2-14 00:00:00" fixdate="2018-2-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Some nonce procs might not be cleaned up (follow up HBASE-19756)</summary>
      <description>Follow up to HBASE-19756 which dealt with NPEs during proc cleanup. Unfortunately, the patch for branch-1 might not remove some valid procs too. The branch-2 patch doesn't have this problem. This fixes the branch-1 bug and also adds another test to branch-2. Thanks to toffer for flagging this internally.</description>
      <version>None</version>
      <fixedVersion>1.3.2,2.0.0-beta-2,1.4.2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.procedure.TestFailedProcCleanup.java</file>
    </fixedFiles>
  </bug>
  <bug id="19999" opendate="2018-2-14 00:00:00" fixdate="2018-3-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove the SYNC_REPLICATION_ENABLED flag</summary>
      <description>It is a bit strange since we can not guard all the sync replication related code with it. We'd better change its name and only use it within the WAL construction.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestSyncReplicationWALProvider.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestSyncReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.master.TestRecoverStandbyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.SyncReplicationWALProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="2" opendate="2008-2-1 00:00:00" fixdate="2008-2-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hlog numbers should wrap around when they reach 999</summary>
      <description>Question about log numbers -&gt; Closing current log writer hdfs://10.0.0.1:9000/gfs_storage/hadoop-root/hbase/log_10.0.0.3_1201900440436_60020/hlog.dat.024What happens when the log get to hlog.dat.999</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.TestHLog.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HLog.java</file>
      <file type="M">conf.hbase-env.sh</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="20000" opendate="2018-2-14 00:00:00" fixdate="2018-2-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove the quantum logic in FairQueue, always put high priority queue in front</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-2,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMasterProcedureSchedulerConcurrency.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMasterProcedureScheduler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureSchedulerPerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureEnv.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.AvlUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="20163" opendate="2018-3-9 00:00:00" fixdate="2018-4-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Forbid major compaction when standby cluster replay the remote wals</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MockRegionServerServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="20164" opendate="2018-3-9 00:00:00" fixdate="2018-3-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>failed hadoopcheck should add footer link</summary>
      <description>thought for sure this already had an issue, busbey, but I can't find it.</description>
      <version>None</version>
      <fixedVersion>1.3.2,1.4.3,2.0.0,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  <bug id="20165" opendate="2018-3-9 00:00:00" fixdate="2018-3-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Shell command to make a normal peer to be a serial replication peer</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.test.ruby.hbase.replication.admin.test.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.list.peers.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.rb</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.replication.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug id="2017" opendate="2009-11-30 00:00:00" fixdate="2009-11-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Set configurable max value size check to 10MB</summary>
      <description>Make the user think about whether storing larger values than 10MB is a good idea.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="20182" opendate="2018-3-13 00:00:00" fixdate="2018-4-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Can not locate region after split and merge</summary>
      <description>When implementing serial replication feature in HBASE-20046, I found that when splitting a region, we will not remove the parent region, instead we will mark it offline.And when locating a region, we will only scan one row so if we locate to the offlined region then we are dead.This will not happen for splitting, since one of the new daughter regions have the same start row with the parent region, and the timestamp is greater so when doing reverse scan we will always hit the daughter first.But if we also consider merge then bad things happen. Consider we have two regions A and B, we split B to C and D, and then merge A and C to E, then ideally the regions should be E and D, but actually the regions in meta will be E, B and D, and they all have different start rows. If you use a row within the range of old region C, then we will always locate to B and throw exception.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncNonMetaRegionLocatorConcurrenyLimit.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionInfoBuilder.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncNonMetaRegionLocator.java</file>
    </fixedFiles>
  </bug>
  <bug id="20189" opendate="2018-3-13 00:00:00" fixdate="2018-3-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Typo in Required Java Version error message while building HBase.</summary>
      <description>Change 'requirs' to 'requires'. See below:$ mvn clean install -DskipTests...[WARNING] Rule 2: org.apache.maven.plugins.enforcer.RequireJavaVersion failed with message:Java is out of date.  HBase requirs at least version 1.8 of the JDK to properly build from source.  You appear to be using an older version. You can use either "mvn -version" or  "mvn enforcer:display-info" to verify what version is active.  See the reference guide on building for more information: http://hbase.apache.org/book.html#build</description>
      <version>None</version>
      <fixedVersion>1.3.2,1.4.3,2.0.0,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="2019" opendate="2009-12-1 00:00:00" fixdate="2009-12-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[EC2] Prompt for and remember credentials if not configured</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.contrib.ec2.bin.image.create-hbase-image-remote</file>
      <file type="M">src.contrib.ec2.bin.hbase-ec2-env.sh</file>
      <file type="M">src.contrib.ec2.bin.create-hbase-image</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="20190" opendate="2018-3-14 00:00:00" fixdate="2018-3-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix default for MIGRATE_TABLE_STATE_FROM_ZK_KEY</summary>
      <description>All works but the flag name will confuse: name is MIGRATE_TABLE_STATE_FROM_ZK_KEY but you'd set it to true to NOT migrate from zk. Found by tedyu in the parent issue.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableStateManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="20204" opendate="2018-3-14 00:00:00" fixdate="2018-5-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add locking to RefreshFileConnections in BucketCache</summary>
      <description>This is a follow-up to HBASE-20141 where anoop.hbase suggested adding locking for refreshing channels.I have also seen this become an issue when a RS has to abort and it locks on trying to flush out the remaining data to the cache (since cache on write was turned on).</description>
      <version>1.4.3,2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0,1.4.5</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.bucket.TestFileIOEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.FileIOEngine.java</file>
    </fixedFiles>
  </bug>
  <bug id="20207" opendate="2018-3-15 00:00:00" fixdate="2018-5-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update doc on the steps to revert RegionServer groups feature</summary>
      <description>Reverting the rsgroup feature from a hbase cluster involves additional steps on top of removing the changes to hbase-site.xml. Documenting it will help cluster admins to be aware of them when rsgroup feature is being enabled.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="20210" opendate="2018-3-15 00:00:00" fixdate="2018-3-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Note in refguide that RSGroups API is private, not for public consumption; shell is only access</summary>
      <description>Came up yesterday in an internal conversation. Mike Drob noticed that the CPEP for RSGroups is marked audience Private which sort of makes sense given this an evolving feature. The refguide though makes it sound as though you can drive RSGroups from shell or API. Let me shutdown the talk of API being public.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="20253" opendate="2018-3-22 00:00:00" fixdate="2018-4-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Error message is missing for restore_snapshot</summary>
      <description>When the table is not disabled and restore_snapshot executed the error message is useless, only displays the table name.hbase(main):007:0&gt; restore_snapshot 'tsnap'ERROR: tRestore a specified snapshot.The restore will replace the content of the original table,bringing back the content to the snapshot state.The table must be disabled.Examples:  hbase&gt; restore_snapshot 'snapshotName'Following command will restore all acl from snapshot table into the table.  hbase&gt; restore_snapshot 'snapshotName', {RESTORE_ACL=&gt;true}Took 0.1044 seconds</description>
      <version>2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.test.ruby.hbase.admin.test.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.rb</file>
    </fixedFiles>
  </bug>
  <bug id="20256" opendate="2018-3-22 00:00:00" fixdate="2018-4-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document commands that do not work with 1.2 shell</summary>
      <description>Some commands do not work from 1.2 shell when running against 2.0 server. Add a section to the reference guide mentioning the incompatibilities.Some of these are collected in this document: https://docs.google.com/document/d/1l2ad5G_GUk0WQ02xKeKO6mTbpdyZjU1NGuPPI42Wbf4/edit</description>
      <version>2.0.0</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="20264" opendate="2018-3-23 00:00:00" fixdate="2018-3-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update Java prerequisite section with LTS rec and status of current GA JDKs</summary>
      <description>Per the thread [DISCUSS] strategy on Java versions Add Java 9 and Java 10 to the support matrix as NT Add a NOTE to Java prereqs about "use a LTS version"For now, leave out talk about planning for timelines on LTS additions or dropping older JDK support. Once we get over the initial hurdle of prepping for Java 11 we'll hopefully have enough info to know how realistic the things talked about in the thread are and we can include a writeup.</description>
      <version>1.5.0,2.0.0</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="20273" opendate="2018-3-24 00:00:00" fixdate="2018-3-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[DOC] include call out of additional changed config defaults in 2.0 upgrade</summary>
      <description>Copied from feedback on HBASE-19158 from mdrob:Default settings/configuration properties changed/renamed:HBASE-19919HBASE-19148HBASE-18307HBASE-17314HBASE-15784HBASE-15027HBASE-14906HBASE-14521More detail later from mdrob:would like to see notes that:hbase.master.cleaner.interval changed from 1 min to 10 minMasterProcedureConstants.MASTER_PROCEDURE_THREADS defaults to CPU/4 instead of CPUhbase.rpc.server.nativetransport renamed to hbase.netty.nativetransporthbase.netty.rpc.server.worker.count renamed to base.netty.worker.counthbase.hfile.compactions.discharger.interval renamed to hbase.hfile.compaction.discharger.intervalhbase.hregion.percolumnfamilyflush.size.lower.bound removed at site level, but can still be applied at table levelhbase.client.reties.number now counts the total number of retries, not the total number of tries</description>
      <version>2.0.0</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mob.compactions.TestMobCompactor.java</file>
    </fixedFiles>
  </bug>
  <bug id="20275" opendate="2018-3-24 00:00:00" fixdate="2018-4-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[DOC] clarify impact to hfile command from HBASE-17197</summary>
      <description>Feedback on HBASE-19158 from mdrobTools:HBASE-17197It's not clear to me from the patch on HBASE-17197 if this was actually a change that needs to be called out. So tasks:1) Figure out if the hfile command args from HBase 1.y still works2) Update the title of HBASE-17197 to match what the change in the jira ended up being3) If hfile changed in an incompatible way, add it to the upgrade section and make sure the refguide section "hfile_tool" is up to date.</description>
      <version>2.0.0</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="20285" opendate="2018-3-26 00:00:00" fixdate="2018-3-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Delete all last pushed sequence ids when removing a peer or removing the serial flag for a peer</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestSerialReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestAddToSerialReplicationPeer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.SerialReplicationTestBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.UpdatePeerConfigProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.ReplicationPeerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.RemovePeerProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.EnablePeerProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.DisablePeerProcedure.java</file>
      <file type="M">hbase-replication.src.test.java.org.apache.hadoop.hbase.replication.TestZKReplicationQueueStorage.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ZKReplicationQueueStorage.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueueStorage.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.MasterProcedure.proto</file>
    </fixedFiles>
  </bug>
  <bug id="20288" opendate="2018-3-26 00:00:00" fixdate="2018-3-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[DOC] upgrade section needs to call out DLR</summary>
      <description>copied out of HBASE-13428. I think from stack Make sure Distributed Log Replay is not enabled on your hbase1 cluster; it was problematic in hbase1 and does not work at all in hbase2.</description>
      <version>2.0.0</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="20289" opendate="2018-3-26 00:00:00" fixdate="2018-5-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Comparator for NormalizationPlan breaks comparator&amp;#39;s convention</summary>
      <description>Comparator must meet the condition: sign(comparator(plan1, plan2)) = - sign(comparator(plan2, plan1)).Current implementation breaks above condition.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.5</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.normalizer.TestSimpleRegionNormalizer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.normalizer.SimpleRegionNormalizer.java</file>
    </fixedFiles>
  </bug>
  <bug id="20328" opendate="2018-4-2 00:00:00" fixdate="2018-4-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix local backup master start command in documentation</summary>
      <description>In "2.3. Pseudo-Distributed Local Install" section of documentation, a command for starting backup masters lacks "start" argument.$ ./bin/local-master-backup.sh 2 3 5should$ ./bin/local-master-backup.sh start 2 3 5</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.getting.started.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="20329" opendate="2018-4-2 00:00:00" fixdate="2018-4-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add note for operators to refguide on AsyncFSWAL</summary>
      <description>Need a few notes in refguide on this new facility.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="20332" opendate="2018-4-3 00:00:00" fixdate="2018-6-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>shaded mapreduce module shouldn&amp;#39;t include hadoop</summary>
      <description>AFAICT, we should just entirely skip including hadoop in our shaded mapreduce module1) Folks expect to run yarn / mr apps via hadoop jar / yarn jar2) those commands include all the needed Hadoop jars in your classpath by default (both client side and in the containers)3) If you try to use "user classpath first" for your job as a workaround (e.g. for some library your application needs that hadoop provides) then our inclusion of some but not all hadoop classes then causes everything to fall over because of mixing rewritten and non-rewritten hadoop classes4) if you don't use "user classpath first" then all of our non-relocated-but-still-shaded hadoop classes are ignored anyways so we're just wasting space</description>
      <version>2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-thrift.pom.xml</file>
      <file type="M">hbase-testing-util.pom.xml</file>
      <file type="M">hbase-shell.pom.xml</file>
      <file type="M">hbase-shaded.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-mapreduce.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-check-invariants.src.test.resources.ensure-jars-have-correct-contents.sh</file>
      <file type="M">hbase-shaded.hbase-shaded-check-invariants.pom.xml</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-rsgroup.pom.xml</file>
      <file type="M">hbase-rest.pom.xml</file>
      <file type="M">hbase-replication.pom.xml</file>
      <file type="M">hbase-mapreduce.pom.xml</file>
      <file type="M">hbase-it.pom.xml</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-external-blockcache.pom.xml</file>
      <file type="M">hbase-examples.pom.xml</file>
      <file type="M">hbase-endpoint.pom.xml</file>
      <file type="M">hbase-common.pom.xml</file>
      <file type="M">hbase-client.pom.xml</file>
      <file type="M">hbase-checkstyle.src.main.resources.hbase.checkstyle.xml</file>
      <file type="M">hbase-checkstyle.src.main.resources.hbase.checkstyle-suppressions.xml</file>
      <file type="M">hbase-backup.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="20333" opendate="2018-4-3 00:00:00" fixdate="2018-6-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>break up shaded client into one with no Hadoop and one that&amp;#39;s standalone</summary>
      <description>there are contexts where we want to stay out of our downstream users way wrt dependencies, but they need more Hadoop classes than we provide. i.e. any downstream client that wants to use both HBase and HDFS in their application, or any non-MR YARN application.Now that Hadoop also has shaded client artifacts for Hadoop 3, we're also providing less incremental benefit by including our own rewritten Hadoop classes to avoid downstream needing to pull in all of Hadoop's transitive dependencies.right now those users need to ensure that any jars from the Hadoop project are loaded in the classpath prior to our shaded client jar. This is brittle and prone to weird debugging trouble.instead, we should have two artifacts: one that just lists Hadoop as a prerequisite and one that still includes the rewritten-but-not-relocated Hadoop classes.We can then use docs to emphasize when each of these is appropriate to use.</description>
      <version>2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shaded.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-mapreduce.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-client.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-check-invariants.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="20334" opendate="2018-4-3 00:00:00" fixdate="2018-6-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>add a test that expressly uses both our shaded client and the one from hadoop 3</summary>
      <description>Since we're making a shaded client that bleed out of our namespace and into Hadoop's, we should ensure that we can show our clients coexisting. Even if it's just an IT that successfully talks to both us and HDFS via our respective shaded clients, that'd be a big help in keeping us proactive.</description>
      <version>2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
      <file type="M">dev-support.hbase.nightly.source-artifact.sh</file>
    </fixedFiles>
  </bug>
  <bug id="20335" opendate="2018-4-3 00:00:00" fixdate="2018-4-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>nightly jobs no longer contain machine information</summary>
      <description>something is up with nightly jobs. they no longer have the machine information from HBASE-19228.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0,1.3.3,1.4.4,2.0.1,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.hbase.nightly.yetus.sh</file>
      <file type="M">dev-support.Jenkinsfile</file>
      <file type="M">dev-support.gather.machine.environment.sh</file>
    </fixedFiles>
  </bug>
  <bug id="20343" opendate="2018-4-4 00:00:00" fixdate="2018-4-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[DOC] fix log directory paths</summary>
      <description>The documentation refers to the log directories as .logs, splitlog, etc. These references should be changed to WALs, splitWAL, etc.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.troubleshooting.adoc</file>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
      <file type="M">src.main.asciidoc..chapters.hbase-default.adoc</file>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="20344" opendate="2018-4-4 00:00:00" fixdate="2018-4-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix asciidoc warnings</summary>
      <description>IntelliJ shows some warnings for asciidoc files.1. Markdown Style Heading:&amp;#35;## Required properties 2. Asciidoc Old Style Heading:Creating a New Table with Compression On a ColumnFamily ==== &amp;#45;---hbase&gt; create 'test2', { NAME =&gt; 'cf2', COMPRESSION =&gt; 'SNAPPY' } &amp;#45;--- ====3. Warning during buildasciidoctor: WARNING: _chapters/troubleshooting.adoc: line 105: invalid style for listing block: NOTE</description>
      <version>2.0.0</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.shell.adoc</file>
      <file type="M">src.main.asciidoc..chapters.security.adoc</file>
      <file type="M">src.main.asciidoc..chapters.schema.design.adoc</file>
      <file type="M">src.main.asciidoc..chapters.performance.adoc</file>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
      <file type="M">src.main.asciidoc..chapters.hbase.mob.adoc</file>
      <file type="M">src.main.asciidoc..chapters.getting.started.adoc</file>
      <file type="M">src.main.asciidoc..chapters.compression.adoc</file>
      <file type="M">src.main.asciidoc..chapters.backup.restore.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="20346" opendate="2018-4-4 00:00:00" fixdate="2018-4-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[DOC] document change to shell tests</summary>
      <description>HBASE-19903 changed how the shell tests are organized and executed, but it missed updating the section on the ref guide that talks about the shell tests.bring it up to date so that folks don't miss a bunch of the tests or add new ones in the wrong place.</description>
      <version>2.0.0-beta-2,2.0.0</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="20349" opendate="2018-4-4 00:00:00" fixdate="2018-4-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[DOC] upgrade guide should call out removal of prefix-tree data block encoding</summary>
      <description>See HBASE-19179. Needs to be in the upgrade section. Right now there's just an offhand mention in Appendix E about the removal.Since we can no longer read data encoded with prefix tree, we should include instructions on rewriting data.Also ensure we don't have spurious references to it. (the help from ltt that's in the ref guide still lists it, for example).</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
      <file type="M">src.main.asciidoc..chapters.troubleshooting.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="20355" opendate="2018-4-5 00:00:00" fixdate="2018-4-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>upgrade section incorrectly attempts to link to sections</summary>
      <description>just figured out that I've been linking to things incorrectly.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="20368" opendate="2018-4-9 00:00:00" fixdate="2018-7-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix RIT stuck when a rsgroup has no online servers but AM&amp;#39;s pendingAssginQueue is cleared</summary>
      <description>This error can be reproduced by shutting down all servers in a rsgroups and starting them soon afterwards. The regions on this rsgroup will be reassigned, but there is no available servers of this rsgroup.They will be added to AM's pendingAssginQueue, which AM will clear regardless of the result of assigning in this case.</description>
      <version>2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.0.6,2.2.1,2.1.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MiniHBaseCluster.java</file>
      <file type="M">hbase-rsgroup.src.test.java.org.apache.hadoop.hbase.rsgroup.TestRSGroupsKillRS.java</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupBasedLoadBalancer.java</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupAdminServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="20369" opendate="2018-4-9 00:00:00" fixdate="2018-6-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document incompatibilities between HBase 1.x and HBase 2.0</summary>
      <description>Hi, I compiled a  draft document for the HBase incompatibilities from the raw source content that was available in HBase Beta 1 site. Can someone please review and provide a feedback or share your comments on this document?Appreciate your support and time. Best Regards, Triguna</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc.book.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="20370" opendate="2018-4-9 00:00:00" fixdate="2018-4-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Also remove the wal file in remote cluster when we finish replicating a file</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.ReplicationSourceDummy.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.SyncReplicationWALProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceShipper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="20371" opendate="2018-4-9 00:00:00" fixdate="2018-4-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>website landing page should draw attention to CFP</summary>
      <description>I missed that the CFP for HBaseCon NA West 2018 is still open because I didn't click the link to the conf page. The "News" section should mention that CFP is open until it is not.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.index.xml</file>
    </fixedFiles>
  </bug>
  <bug id="20377" opendate="2018-4-10 00:00:00" fixdate="2018-4-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Deal with table in enabling and disabling state when modifying serial replication peer</summary>
      <description>There could be race between reopening regions and enabling table, and also between disabling table and write last pushed sequence id for disabled table. Maybe we need to wait for the table state to become enabled or disabled.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestAddToSerialReplicationPeer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.ModifyPeerProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DisableTableProcedure.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.TableState.java</file>
    </fixedFiles>
  </bug>
  <bug id="20384" opendate="2018-4-10 00:00:00" fixdate="2018-4-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[AMv2] Logging format improvements; use encoded name rather than full region name marking transitions</summary>
      <description>We use encoded name near everywhere. Makes logging regular-looking at least and eases tracing. In a few places we still do full region name. Let me fix (ran into it trying to debug...)</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionPlan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.RegionStateStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="20387" opendate="2018-4-11 00:00:00" fixdate="2018-8-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>flaky infrastructure should work for all branches</summary>
      <description>We need a flaky list per-branch, since what does/does not work reliably on master isn't really relevant to our older maintenance release lines.We should just make the invocation a step in the current per-branch nightly jobs, prior to when we need the list in the stages that run unit tests. We can publish it in the nightly job as well so that precommit can still get it. (and can fetch it per-branch if needed)</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.3.3,2.2.0,1.2.7,2.1.1,2.0.2,1.4.7</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.report-flakies.py</file>
      <file type="M">dev-support.Jenkinsfile</file>
      <file type="M">dev-support.hbase.nightly.yetus.sh</file>
      <file type="M">dev-support.flaky-dashboard-template.html</file>
      <file type="M">dev-support.findHangingTests.py</file>
      <file type="M">dev-support.Dockerfile</file>
    </fixedFiles>
  </bug>
  <bug id="20388" opendate="2018-4-11 00:00:00" fixdate="2018-4-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>nightly tests running on a feature branch should only comment on that feature branch&amp;#39;s jira</summary>
      <description>It would help improve our signal-to-noise ratio from nightly tests if feature branch runs stopped commenting on all the jiras that got covered by a rebase / merge.should be straight forward to have the commenting bit check the current branch against our feature branch naming convention.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  <bug id="20389" opendate="2018-4-11 00:00:00" fixdate="2018-4-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move website building flags into a profile</summary>
      <description>we have some "magic" in our website building right now. The script that's used bout our automated website build + publish mechanism manually sets a bunch of stuff on the maven command line.It'd be better to reflect those settings in a maven profile, so that folks are less likely to be surprised e.g. when trying to debug a failure in the site goal happens.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0,2.0.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-spark.pom.xml</file>
      <file type="M">dev-support.jenkins-scripts.generate-hbase-website.sh</file>
    </fixedFiles>
  </bug>
  <bug id="20391" opendate="2018-4-11 00:00:00" fixdate="2018-4-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>close out stale or finished PRs on github</summary>
      <description>Time to do another round of closing PRs via empty commit. #51 - &gt; 1 month since notification #52 - &gt; 1 month since notification #61 - HBASE-18928 has already closed #62 - HBASE-18929 has already closed #64 -HBASE-18901 has already closed #67 - HBASE-19386 has already closed #68 - HBASE-19387 has already closed</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="20393" opendate="2018-4-12 00:00:00" fixdate="2018-6-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Operational documents for synchronous replication.</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
      <file type="M">src.main.asciidoc.book.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="20396" opendate="2018-4-12 00:00:00" fixdate="2018-7-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove redundant MBean from thrift JMX</summary>
      <description>HBase has two types of thrift server. When any type of thrift server is started, the MBean of the two thrift servers will be registered which is redundant.For example, when starting thrift2, we only need to register MBean "Hadoop:service=HBase,name=Thrift,sub=ThriftTwo" of thrift2 in JMX, there's no need to register MBean "Hadoop:service=HBase,name=Thrift,sub=ThriftOne" of thrift. Vice versa</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.thrift.MetricsThriftServerSourceFactoryImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="20397" opendate="2018-4-12 00:00:00" fixdate="2018-4-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make it more explicit that monkey.properties is found on CLASSPATH</summary>
      <description>Underline in the refguide that IT tests look for monkey properties on CLASSPATH. I missed this and it caused me a bit of confusion.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="2040" opendate="2009-12-11 00:00:00" fixdate="2009-12-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fixes to group commit</summary>
      <description>Two (somewhat) major things.First when the LogSyncer thread is created it's expecting optionalFlushInterval but we pass logflushentries. What it means is that it will run every 100ms by default.Also when the optional flush is running (meaning that no entries came in for that interval) and that logflushentries&gt;1 then it won't do the hflush because we don't enforce it.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="20401" opendate="2018-4-12 00:00:00" fixdate="2018-3-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make `MAX_WAIT` and `waitIfNotFinished` in CleanerContext configurable</summary>
      <description>When backporting HBASE-18309 in HBASE-20352, the deleteFiles calls CleanerContext.java#getResult with a waitIfNotFinished timeout to wait for notification (notify) from the fs.delete file thread. there might be two situation need to tune the MAX_WAIT in CleanerContext or waitIfNotFinished when LogClearner call getResult. fs.delete never complete (strange but possible), then we need to wait for a max of 60 seconds. here, 60 seconds might be too long getResult is waiting in the period of 500 milliseconds, but the fs.delete has completed and setFromClear is set but yet notify(). one might want to tune this 500 milliseconds to 200 or less .</description>
      <version>3.0.0-alpha-1,1.5.0,2.0.0-beta-1,1.4.4,2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,1.3.3,1.4.6,2.2.0,2.1.1,2.0.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.cleaner.TestLogsCleaner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.cleaner.TestHFileCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.LogCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.HFileCleaner.java</file>
    </fixedFiles>
  </bug>
  <bug id="20406" opendate="2018-4-13 00:00:00" fixdate="2018-4-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase Thrift HTTP - Shouldn&amp;#39;t handle TRACE/OPTIONS methods</summary>
      <description>HBASE-10473 introduced a utility HttpServerUtil.constrainHttpMethods to prevent Jetty from answering on TRACE and OPTIONS methods. This should be added to Thrift in HTTP mode as well.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0,1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift.TestThriftHttpServer.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">hbase-http.src.test.java.org.apache.hadoop.hbase.http.TestHttpServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="2041" opendate="2009-12-12 00:00:00" fixdate="2009-2-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change WAL default configuration values</summary>
      <description>My last email on the thread "Should we change the default value of hbase.regionserver.flushlogentries for 0.21?"Ok to make sure I get this right: we enable deferred log flush by default we set flushlogentries=1Also since 10 seconds is kind of a huge window I propose that: we set optionalLogFlush=1000which is the MySQL default. We also have to update the wiki (there'salready an entry on deferred log flush) by adding the configuration offlushlogentries.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
    </fixedFiles>
  </bug>
  <bug id="20410" opendate="2018-4-13 00:00:00" fixdate="2018-4-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>upgrade protoc compiler to 3.5.1-1</summary>
      <description>See HBASE-20356After doing the cleanup there, I was informed that there's a 3.5.1-1 version of the compiler binaries that work on rhel6, so let's just go to that. Wish I knew about it beforehand.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
      <file type="M">hbase-protocol-shaded.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="20438" opendate="2018-4-17 00:00:00" fixdate="2018-4-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add an HBase antipattern check for reintroducing commons-logging</summary>
      <description>We moved to slf4j in HBASE-10092, but looking at our source tree we've had some regression back to commons-logging:$ git grep -E "org.apache.commons.logging.Log(Factory|;)"hbase-server/src/main/java/org/apache/hadoop/hbase/master/zksyncer/ClientZKSyncer.java:import org.apache.commons.logging.Log;hbase-server/src/main/java/org/apache/hadoop/hbase/master/zksyncer/ClientZKSyncer.java:import org.apache.commons.logging.LogFactory;hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/FileArchiverNotifierImpl.java:import org.apache.commons.logging.Log;hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/FileArchiverNotifierImpl.java:import org.apache.commons.logging.LogFactory;hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/RegionSizeReportingChore.java:import org.apache.commons.logging.Log;hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/RegionSizeReportingChore.java:import org.apache.commons.logging.LogFactory;hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/RegionSizeStoreImpl.java:import org.apache.commons.logging.Log;hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/RegionSizeStoreImpl.java:import org.apache.commons.logging.LogFactory;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/throttle/StoreHotnessProtector.java:import org.apache.commons.logging.Log;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/throttle/StoreHotnessProtector.java:import org.apache.commons.logging.LogFactory;hbase-server/src/test/java/org/apache/hadoop/hbase/TestClusterPortAssignment.java:import org.apache.commons.logging.Log;hbase-server/src/test/java/org/apache/hadoop/hbase/TestClusterPortAssignment.java:import org.apache.commons.logging.LogFactory;hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFlushFromClient.java:import org.apache.commons.logging.Log;hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFlushFromClient.java:import org.apache.commons.logging.LogFactory;hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSeparateClientZKCluster.java:import org.apache.commons.logging.Log;hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSeparateClientZKCluster.java:import org.apache.commons.logging.LogFactory;hbase-server/src/test/java/org/apache/hadoop/hbase/procedure/TestFailedProcCleanup.java:import org.apache.commons.logging.Log;hbase-server/src/test/java/org/apache/hadoop/hbase/procedure/TestFailedProcCleanup.java:import org.apache.commons.logging.LogFactory;hbase-server/src/test/java/org/apache/hadoop/hbase/wal/TestDisabledWAL.java:import org.apache.commons.logging.Log;hbase-server/src/test/java/org/apache/hadoop/hbase/wal/TestDisabledWAL.java:import org.apache.commons.logging.LogFactory;We should do the same kind of check that we do to avoid e.g. the Hadoop annotations</description>
      <version>3.0.0-alpha-1,2.1.0,2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  <bug id="20447" opendate="2018-4-18 00:00:00" fixdate="2018-5-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Only fail cacheBlock if block collisions aren&amp;#39;t related to next block metadata</summary>
      <description>This is the issue I was originally having here: http://mail-archives.apache.org/mod_mbox/hbase-dev/201802.mbox/%3CCAN+qs_Pav=md_Aoj4Xji+KCNETubg2XOu2nTxV1g6m8-5VN-GA@mail.gmail.com%3E When we pread, we don't force the read to read all of the next block header.However, when we get into a race condition where two opener threads try tocache the same block and one thread read all of the next block header and the other one didn't, it will fail the open process. This is especially importantin a splitting case where it will potentially fail the split process.Instead, in the caches, we should only fail if the required blocks are different. </description>
      <version>1.4.3,2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0,1.4.5</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestLruBlockCache.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileBlock.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestCachedBlockQueue.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestCacheConfig.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.CacheTestUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.bucket.TestBucketCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.Cacheable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.BlockCacheUtil.java</file>
      <file type="M">hbase-external-blockcache.src.main.java.org.apache.hadoop.hbase.io.hfile.MemcachedBlockCache.java</file>
    </fixedFiles>
  </bug>
  <bug id="20494" opendate="2018-4-26 00:00:00" fixdate="2018-5-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade com.yammer.metrics dependency</summary>
      <description>The current com.yammer.metrics version is quite outdated. Please consider upgrading to the latest io.dropwizard.metrics</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.0.6,2.1.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="20500" opendate="2018-4-27 00:00:00" fixdate="2018-5-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[rsgroup] should keep at least one server in default group</summary>
      <description>we move all the servers from default groupthe default group will has  no servers,then we create a  new table ,it will failed case of the default group has no serverseorr info is :EROOR: ConstraintException:Target RSGroup must have at lease on server we should keep at least one server in 'default' RSGroup </description>
      <version>2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0,1.4.5</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-rsgroup.src.test.java.org.apache.hadoop.hbase.rsgroup.TestRSGroupsBase.java</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupAdminServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="20501" opendate="2018-4-27 00:00:00" fixdate="2018-5-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change the Hadoop minimum version to 2.7.1</summary>
      <description>See discussion thread on dev@ "&amp;#91;DISCUSS&amp;#93; Branching for HBase 1.5 and Hadoop minimum version update (to 2.7)"Consensus This is a needed change due to the practicalities of having Hadoop as a dependency Let's move up the minimum supported version of Hadoop to 2.7.1. Update documentation (support matrix, compatibility discussion) to call this out. Be sure to call out this change in the release notes. Take the opportunity to remind users about our callout "Replace the Hadoop Bundled With HBase!" recommending users upgrade their Hadoop if &lt; 2.7.1.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0,1.5.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  <bug id="20502" opendate="2018-4-27 00:00:00" fixdate="2018-7-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document HBase incompatible with Yarn 2.9.0 and 3.0.x due to YARN-7190</summary>
      <description>We need to call out hadoop-yarn 2.9.0 and the entire 3.0.x line as explicitly unsupported due to needing YARN-7190 fixed in versions that have ATS available.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="20507" opendate="2018-4-29 00:00:00" fixdate="2018-5-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Do not need to call recoverLease on the broken file when we fail to create a wal writer</summary>
      <description>I tried locally with a UT, if we overwrite a file which is currently being written, the old file will be completed and then deleted. If you call close on the previous file, a no lease exception will be thrown which means that the file has already been completed.So we do not need to close a file if it will be overwritten immediately, since recoverLease may take a very long time...</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0,2.0.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputHelper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.asyncfs.TestOverwriteFileUnderConstruction.java</file>
    </fixedFiles>
  </bug>
  <bug id="20512" opendate="2018-5-1 00:00:00" fixdate="2018-8-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>document change to running tests on secure clusters</summary>
      <description>We should document the change to authentication handling in HBASE-16231 in the upgrade section of the reference guide.It's surprising to folks that have existing automated testing that's been working on our prior stable release lines. We should give a warning to those updating. The release note is probably suitable for a first pass.</description>
      <version>1.3.0,2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,2.0.2</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="20516" opendate="2018-5-1 00:00:00" fixdate="2018-1-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Offheap read-path needs more detail</summary>
      <description>Needs notes on what an operator should look for to see that all is on and what to monitor in a running cluster.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.offheap.read.write.adoc</file>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="20523" opendate="2018-5-3 00:00:00" fixdate="2018-5-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>PE tool should support configuring client side buffering sizes</summary>
      <description>The client side buffering size impacts the write load and the write performance. Hence for testing purpose it is better we allow client side buffering to be configurable in PE. Already YCSB has such facility.</description>
      <version>2.0.0</version>
      <fixedVersion>2.1.0,2.0.1,1.4.5,1.2.7</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.TestPerformanceEvaluation.java</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
    </fixedFiles>
  </bug>
  <bug id="20547" opendate="2018-5-9 00:00:00" fixdate="2018-5-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Restore from backup will fail if done from a different file system</summary>
      <description>In recent tests, restore from s3a:// to local hdfs:// fails with "not supported file system". This is due to a bug in a code that creates instance of a file system being restored from.Credits: tedyu@apache.org, Gaurav Sharma</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.util.BackupUtils.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.impl.IncrementalTableBackupClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="20581" opendate="2018-5-14 00:00:00" fixdate="2018-5-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase book documentation wrong for REST operations on schema endpoints</summary>
      <description>On https://hbase.apache.org/book.html#_using_rest_endpointsThe documentation states that to update a table schema (the configuration for a column family), the PUT HTTP verb will update the current configuration with the "fragment" of configuration provided, while the POST HTTP verb will replace the current configuration with whatever is provided.In reality, the opposite is true: POST updates the configuration, PUT replaces. The old javadoc for the o.a.h.h.rest package got it right, but the entry on the HBase book transposed this.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.external.apis.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="20582" opendate="2018-5-14 00:00:00" fixdate="2018-5-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bump up JRuby version because of some reported vulnerabilities</summary>
      <description>There are some vulnerabilities reported with two of the libraries used in HBase.Jruby(version:9.1.10.0):CVE-2009-5147CVE-2013-4363CVE-2014-4975CVE-2014-8080CVE-2014-8090CVE-2015-3900CVE-2015-7551CVE-2015-9096CVE-2017-0899CVE-2017-0900CVE-2017-0901CVE-2017-0902CVE-2017-0903CVE-2017-10784CVE-2017-14064CVE-2017-9224CVE-2017-9225CVE-2017-9226CVE-2017-9227CVE-2017-9228Tool somehow able to relate the vulnerability of Ruby with JRuby(Java implementation). (Jackson will be handled in a different issue.)Not all of them directly affects HBase but elserj suggested that it is better to be on the updated version to avoid issues during an audit in security sensitive organization. </description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="20587" opendate="2018-5-15 00:00:00" fixdate="2018-2-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace Jackson with shaded thirdparty gson</summary>
      <description>HBASE-20582 got me looking at how we use Jackson. It appears that we moved some JSON code from hbase-server into hbase-common via HBASE-19053. But, there seems to be no good reason why this code should live there and not in hbase-http instead. Keeping Jackson off the user's classpath is a nice goal.FYI appy, mdrob</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestJSONMetricUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALPrettyPrinter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheStats.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.BlockCacheUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.AgeSnapshot.java</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-rest.pom.xml</file>
      <file type="M">hbase-metrics.src.main.java.org.apache.hadoop.hbase.metrics.impl.FastLongHistogram.java</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.TestPerformanceEvaluation.java</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
      <file type="M">hbase-mapreduce.pom.xml</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.RESTApiClusterManager.java</file>
      <file type="M">hbase-it.pom.xml</file>
      <file type="M">hbase-http.src.main.java.org.apache.hadoop.hbase.http.jmx.JMXJsonServlet.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.JSONMetricUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.JSONBean.java</file>
      <file type="M">hbase-common.pom.xml</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestOperation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.util.JsonMapper.java</file>
      <file type="M">hbase-client.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="20588" opendate="2018-5-15 00:00:00" fixdate="2018-5-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Space quota change after quota violation doesn&amp;#39;t seem to take in effect</summary>
      <description>Steps followed  Through hbase shellset_quota TYPE =&gt; SPACE, TABLE =&gt; 'TestTable', LIMIT =&gt; '2M', POLICY =&gt; NO_INSERTS Run PE until the quota is reachedhbase org.apache.hadoop.hbase.PerformanceEvaluation --nomapred --rows=20000000 sequentialWrite 1 Through HBase shellset_quota TYPE =&gt; SPACE, TABLE =&gt; 'TestTable', LIMIT =&gt; NONE- Through HBase shell verify the effective Quotas&gt; list_quotasOWNER                                               QUOTAS                                                                                                                                               0 row(s)Took 0.0365 seconds Wait for some time (at least 5 mins) and try to add data to the table&gt; put 'TestTable','r1','info0:0','v1'ERROR: org.apache.hadoop.hbase.quotas.SpaceLimitingException: NO_INSERTS Puts are disallowed due to a space quota.at org.apache.hadoop.hbase.quotas.policies.NoInsertsViolationPolicyEnforcement.check(NoInsertsViolationPolicyEnforcement.java:47)To resolve the issue, RSes need to be restarted which points to in memory data not getting reset. </description>
      <version>3.0.0-alpha-1,2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0,2.0.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestSpaceQuotas.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.SpaceQuotaRefresherChore.java</file>
    </fixedFiles>
  </bug>
  <bug id="20589" opendate="2018-5-16 00:00:00" fixdate="2018-5-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Don&amp;#39;t need to assign meta to a new RS when standby master become active</summary>
      <description>I found this problem when I write ut for HBASE-20569. Now the master  finishActiveMasterInitialization introduce a new RecoverMetaProcedure(HBASE-18261) and it has a sub procedure AssignProcedure. AssignProcedure will skip assign a region when regions state is OPEN and server is online. But for the new regiog state node is created with state OFFLINE. So it will assign the meta to a new RS. And kill the old RS when old RS report to master. This will make the master initialization cost a long time. I will attatch a ut to show this. FYI stack</description>
      <version>None</version>
      <fixedVersion>2.0.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestServerName.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ServerName.java</file>
    </fixedFiles>
  </bug>
  <bug id="20601" opendate="2018-5-18 00:00:00" fixdate="2018-5-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add multiPut support and other miscellaneous to PE</summary>
      <description>Add some useful stuff and some refinement to PE tool1. Add multiPut supportThough we have BufferedMutator, sometimes we need to benchmark batch put in a certain number.Set --multiPut=number to enable batchput(meanwhile, --autoflush need be set to false)2. Add Connection Number supportBefore, there is only on parameter to control the connection used by threads. oneCon=true means all threads use one connection, false means each thread has it own connection.When thread number is high and oneCon=false, we noticed high context switch frequency in the machine which PE run on, disturbing the benchmark results(each connection has its own netty worker threads, 2*CPU IIRC). So, added a new parameter connCount to PE. set --connCount=2 means all threads will share 2 connections.3. Add avg RT and avg TPS/QPS statstic for all threadsUseful when we want to meansure the total throughtput of the cluster4. Delete some redundant codeNow RandomWriteTest is inherited from SequentialWrite.</description>
      <version>2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.TestPerformanceEvaluation.java</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
    </fixedFiles>
  </bug>
  <bug id="20602" opendate="2018-5-18 00:00:00" fixdate="2018-6-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase.master.quota.observer.ignore property seems to be not taking effect</summary>
      <description>From doc setting hbase.master.quota.observer.ignore property to true will retain the space quota even after table is deleted. But doesn't seem to be the case i.e. whether the property is not defined which sets the value to false or set the property to true in site.xml, the quota gets removed when the corresponding table is dropped. Will verify whether it works in 1.x. Did a grep on the master source, did get a hit on the property in code.Steps to reproduce Add this property and restart hbase    &lt;property&gt;        &lt;name&gt;hbase.master.quota.observer.ignore&lt;/name&gt;        &lt;value&gt;true&lt;/value&gt;    &lt;/property&gt; Through hbase shell hbase(main):003:0&gt; set_quota TYPE =&gt; SPACE, TABLE =&gt; 't1', LIMIT =&gt; '1G', POLICY =&gt; NO_INSERTSTook 0.0317 seconds hbase(main):005:0&gt; create 't1','cf1'Created table t1Took 0.7904 seconds hbase(main):006:0&gt; list_quotasOWNER QUOTASTABLE =&gt; t1 TYPE =&gt; SPACE, TABLE =&gt; t1, LIMIT =&gt; 1073741824, VIOLATION_POLICY =&gt; NO_INSERTS1 row(s) hbase(main):007:0&gt; disable 't1'Took 0.4909 secondshbase(main):008:0&gt; list_quotasOWNER QUOTASTABLE =&gt; t1 TYPE =&gt; SPACE, TABLE =&gt; t1, LIMIT =&gt; 1073741824, VIOLATION_POLICY =&gt; NO_INSERTS1 row(s)Took 0.0420 seconds hbase(main):009:0&gt; drop 't1'Took 0.1407 seconds hbase(main):010:0&gt; list_quotasOWNER QUOTAS0 row(s)Took 0.0307 seconds</description>
      <version>2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0,2.0.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="20617" opendate="2018-5-22 00:00:00" fixdate="2018-7-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade/remove jetty-jsp</summary>
      <description>jetty-jsp removed after jetty-9.2.x version. We use the 9.2 version. Research so far brings out that apache-jsp might be of interest to us in jetty-9.4.x version(as JettyJspServlet.class is in apache-jsp). Yet to figure out about jetty-9.3.x.Filing to track this along.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-thrift.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-mapreduce.pom.xml</file>
      <file type="M">hbase-resource-bundle.src.main.resources.supplemental-models.xml</file>
    </fixedFiles>
  </bug>
  <bug id="20626" opendate="2018-5-23 00:00:00" fixdate="2018-10-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change the value of "Requests Per Second" on WEBUI</summary>
      <description>Now we use "totalRequestCount"(RSRpcServices#requestCount) to calculate requests per second. After HBASE-18469, "totalRequestCount" count only once for multi request.(Includes requests that are not serviced by regions.) When we have a large number of read and write requests, the value of "Requests Per Second" is very small which does not reflect the load of the cluster.Maybe it is more reasonable to use "totalRowActionRequestCount" to calculate RPS?</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,1.6.0,2.2.2,2.1.8</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="20659" opendate="2018-5-30 00:00:00" fixdate="2018-5-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement a reopen table regions procedure</summary>
      <description>For serial replication peer, and sync replication peer on branch HBASE-19064, sometimes we need to reopen the regions for a table to make sure that we have some wal edits which have not been replicated yet, or let the region switch a wal implementation. But for peer related procedures, we do not hold the table lock so if there are region split or merge than we may fail to reopen all the regions and cause problems.So I think we need to introduce a table procedure which is used to reopen all the regions for a table, and like other table procedures, such as ModifyTableProcedure, it will hold the exclusive lock on a table so we will not miss the new regions.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.ModifyPeerProcedure.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.MasterProcedure.proto</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.StateMachineProcedure.java</file>
    </fixedFiles>
  </bug>
  <bug id="20664" opendate="2018-5-31 00:00:00" fixdate="2018-6-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Variable shared across multiple threads</summary>
      <description>Some static analysis found a variable which was used across multiple threads without any synchronization that would allow race conditions.The variable does not need to be a member of the class, instead just made a local variable.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0,1.3.3,2.0.1,1.4.5,1.2.6.1,1.3.2.1,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftHttpServlet.java</file>
    </fixedFiles>
  </bug>
  <bug id="20666" opendate="2018-5-31 00:00:00" fixdate="2018-8-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unsuccessful table creation leaves entry in hbase:rsgroup table</summary>
      <description>If a table creation fails in a cluster enabled with rsgroup feature, the table is still listed as part of default rsgroup.To recreate the scenario: Create a namespace (NS) with number of region limit Create table in the NS which satisfies the region limit by pre-splitting Create a new table in the NS which will fail list_rsgroup will show the table being part of default rsgroup and data can be found in hbase:rsgroup tableWould be good to revert the entry when the table creation fails or a script to clean up the metadata.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.java</file>
      <file type="M">hbase-rsgroup.src.test.java.org.apache.hadoop.hbase.rsgroup.TestRSGroups.java</file>
    </fixedFiles>
  </bug>
  <bug id="20672" opendate="2018-6-1 00:00:00" fixdate="2018-7-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>New metrics ReadRequestRate and WriteRequestRate</summary>
      <description>Hbase currently provides counter read/write requests (ReadRequestCount, WriteRequestCount). That said it is not easy to use counter that reset only after a restart of the service, we would like to expose 2 new metrics in HBase to provide ReadRequestRate and WriteRequestRate at region server level.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.3.3,2.2.0,1.4.10</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperStub.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="20688" opendate="2018-6-6 00:00:00" fixdate="2018-9-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Refguide has "HBase Backup" section and a chapter named "Backup and Restore"; neither refers to the other</summary>
      <description>The two backup sections are not connected or related. It'd be confusing to the user. Needs addressing.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="20691" opendate="2018-6-6 00:00:00" fixdate="2018-7-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Storage policy should allow deferring to HDFS</summary>
      <description>In HBase 1.1 - 1.4 we can defer storage policy decisions to HDFS by using "NONE" as the storage policy in hbase configs.As described on this dev@hbase thread "WAL storage policies and interactions with Hadoop admin tools." we no longer have that option in 2.0.0 and 1.5.0 (as the branch is now). Additionally, we can't set the policy to HOT in the event that HDFS has changed the policy for a parent directory of our WALs.We should put back that ability. Presuming this is done by re-adopting the "NONE" placeholder variable, we need to ensure that value doesn't get passed to HDFS APIs. Since it isn't a valid storage policy attempting to use it will cause a bunch of logging churn (which will be a regression of the problem HBASE-18118 sought to fix).</description>
      <version>2.0.0</version>
      <fixedVersion>2.1.0,1.5.0,2.0.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestFSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.CommonFSUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="20695" opendate="2018-6-6 00:00:00" fixdate="2018-6-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement table level RegionServer replication metrics</summary>
      <description>Region server metrics now are mainly global metrics. It would be nice to have table level metrics such as table level source.AgeOfLastShippedOp to indicate operators which table's replication is lagging behind. </description>
      <version>None</version>
      <fixedVersion>2.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceShipper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.MetricsSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="20700" opendate="2018-6-7 00:00:00" fixdate="2018-6-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move meta region when server crash can cause the procedure to be stuck</summary>
      <description>As said in HBASE-20682.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0,2.0.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestServerCrashProcedureStuck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureTestingUtility.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.TableProcedureInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ServerProcedureInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.SchemaLocking.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.RecoverMetaProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.PeerProcedureInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterMetaBootstrap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.UnassignProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.RegionTransitionProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.AssignmentManager.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.LockedResourceType.java</file>
    </fixedFiles>
  </bug>
  <bug id="20702" opendate="2018-6-7 00:00:00" fixdate="2018-6-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Processing crash, skip ONLINE&amp;#39;ing empty rows</summary>
      <description>This patch comes from the parent issue. Parent issue identifies us ONLINE'ing a region though it has nothing in the row (in parent issue scenario, region info family was deleted in a merge region parent). We shouldn't do this.Committing patch from parent here in this subtask since the parent issue is still under investigation.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.RegionStateStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="20704" opendate="2018-6-7 00:00:00" fixdate="2018-9-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Sometimes some compacted storefiles are not archived on region close</summary>
      <description>During region close compacted files which have not yet been archived by the discharger are archived as part of the region closing process. It is important that these files are wholly archived to insure data consistency. ie a storefile containing delete tombstones can be archived while older storefiles containing cells that were supposed to be deleted are left unarchived thereby undeleting those cells. On region close a compacted storefile is skipped from archiving if it has read references (ie open scanners). This behavior is correct for when the discharger chore runs but on region close consistency is of course more important so we should add a special case to ignore any references on the storefile and go ahead and archive it. Attached patch contains a unit test that reproduces the problem and the proposed fix.</description>
      <version>3.0.0-alpha-1,1.3.0,1.4.0,1.5.0,2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,1.3.3,2.2.0,1.4.8,2.1.1,2.0.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="20705" opendate="2018-6-7 00:00:00" fixdate="2018-8-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Having RPC Quota on a table prevents Space quota to be recreated/removed</summary>
      <description>Property hbase.quota.remove.on.table.delete is set to true by default Create a table and set RPC and Space quotahbase(main):022:0&gt; create 't2','cf1'Created table t2Took 0.7420 seconds=&gt; Hbase::Table - t2hbase(main):023:0&gt; set_quota TYPE =&gt; SPACE, TABLE =&gt; 't2', LIMIT =&gt; '1G', POLICY =&gt; NO_WRITESTook 0.0105 secondshbase(main):024:0&gt; set_quota TYPE =&gt; THROTTLE, TABLE =&gt; 't2', LIMIT =&gt; '10M/sec'Took 0.0186 secondshbase(main):025:0&gt; list_quotasTABLE =&gt; t2 TYPE =&gt; THROTTLE, THROTTLE_TYPE =&gt; REQUEST_SIZE, LIMIT =&gt; 10M/sec, SCOPE =&gt; MACHINETABLE =&gt; t2 TYPE =&gt; SPACE, TABLE =&gt; t2, LIMIT =&gt; 1073741824, VIOLATION_POLICY =&gt; NO_WRITES Drop the table and the Space quota is set to REMOVE =&gt; truehbase(main):026:0&gt; disable 't2'Took 0.4363 secondshbase(main):027:0&gt; drop 't2'Took 0.2344 secondshbase(main):028:0&gt; list_quotasTABLE =&gt; t2 TYPE =&gt; SPACE, TABLE =&gt; t2, REMOVE =&gt; trueUSER =&gt; u1 TYPE =&gt; THROTTLE, THROTTLE_TYPE =&gt; REQUEST_SIZE, LIMIT =&gt; 10M/sec, SCOPE =&gt; MACHINE Recreate the table and set Space quota back. The Space quota on the table is still set to REMOVE =&gt; truehbase(main):029:0&gt; create 't2','cf1'Created table t2Took 0.7348 seconds=&gt; Hbase::Table - t2hbase(main):031:0&gt; set_quota TYPE =&gt; SPACE, TABLE =&gt; 't2', LIMIT =&gt; '1G', POLICY =&gt; NO_WRITESTook 0.0088 secondshbase(main):032:0&gt; list_quotasOWNER QUOTASTABLE =&gt; t2 TYPE =&gt; THROTTLE, THROTTLE_TYPE =&gt; REQUEST_SIZE, LIMIT =&gt; 10M/sec, SCOPE =&gt; MACHINETABLE =&gt; t2 TYPE =&gt; SPACE, TABLE =&gt; t2, REMOVE =&gt; true Remove RPC quota and drop the table, the Space Quota is not removedhbase(main):033:0&gt; set_quota TYPE =&gt; THROTTLE, TABLE =&gt; 't2', LIMIT =&gt; NONETook 0.0193 secondshbase(main):036:0&gt; disable 't2'Took 0.4305 secondshbase(main):037:0&gt; drop 't2'Took 0.2353 secondshbase(main):038:0&gt; list_quotasOWNER QUOTASTABLE =&gt; t2                               TYPE =&gt; SPACE, TABLE =&gt; t2, REMOVE =&gt; true Deleting the quota entry from hbase:quota seems to be the option to reset it.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1,2.0.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestMasterQuotasObserver.java</file>
    </fixedFiles>
  </bug>
  <bug id="20724" opendate="2018-6-13 00:00:00" fixdate="2018-2-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Sometimes some compacted storefiles are still opened after region failover</summary>
      <description>It is important that compacted storefiles of a given compaction execution are wholly opened or archived to insure data consistency. ie a storefile containing delete tombstones can be archived while older storefiles containing cells that were supposed to be deleted are left unarchived thereby undeleting those cells.When a server fails compaction markers (in the wal edit) are used to determine which storefiles are compacted and should be excluded during region open (during failover). But the WALs containing compaction markers can be prematurely archived even though there are still compacted storefiles for that particular compaction event that hasn't been archived yet. Thus losing compaction information that needs to be replayed in the event of an RS crash. This is because hlog archiving logic only keeps track of flushed storefiles and not compacted ones.https://issues.apache.org/jira/browse/HBASE-20704?focusedCommentId=16507680&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16507680</description>
      <version>3.0.0-alpha-1,1.3.0,1.4.0,1.5.0,2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSwitchToStreamRead.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCleanupCompactedFileOnRegionClose.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.compactions.TestCompactor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestSpaceQuotasWithSnapshots.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestSnapshotQuotaObserverChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.StripeCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.DateTieredCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.AbstractMultiFileWriter.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.HFile.proto</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="20739" opendate="2018-6-15 00:00:00" fixdate="2018-6-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add priority for SCP</summary>
      <description>As said in the design doc of HBASE-20708.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ServerQueue.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.SchemaLocking.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.FairQueue.java</file>
    </fixedFiles>
  </bug>
  <bug id="20741" opendate="2018-6-15 00:00:00" fixdate="2018-9-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Split of a region with replicas creates all daughter regions and its replica in same server</summary>
      <description>Generally it is better that the parent region when split creates the daughter region in the same target server. But for replicas also we do the same and all the replica regions are created in the same target server. We should ideally be doing a round robin and only the primary daughter region should be opened in the intended target server (where the parent was previously opened).huaxiang FYI.</description>
      <version>3.0.0-alpha-1,2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.assignment.TestRegionReplicaSplit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.SplitTableRegionProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.MergeTableRegionsProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.AssignmentManagerUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="20742" opendate="2018-6-15 00:00:00" fixdate="2018-6-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Always create WAL directory for region server</summary>
      <description>After HBASE-20708, when master restart, we will scan the wal directory to find out the live servers. In most cases this is OK, as when we create a HRegion instance at RS side, we will create a WAL for it, and the directory which contains the server name will be there, even if user always use SKIP_WAL.But there could still be problem as the directory is created in the implementation of WAL, not in the initialization of region server, so if user uses DisabledWALProvider then we will be in trouble.So let's fix it.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="20745" opendate="2018-6-16 00:00:00" fixdate="2018-6-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Log when master proc wal rolls</summary>
      <description>Emit when we roll master proc WAL so can see when they happen. Want to correlate instances of corruption w/ events on Master. Currently hard to do on a server where log-level is INFO (default for many deploys).Also, we log STUCK regions every 5 seconds. If a bundle of regions get stuck, we can log so frequently, we roll away where the problem happened so lose the chance to debug. Let me fix that too....Need both debugging instances of parent issue.</description>
      <version>None</version>
      <fixedVersion>2.0.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.AssignmentManager.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureExecutor.java</file>
    </fixedFiles>
  </bug>
  <bug id="20749" opendate="2018-6-18 00:00:00" fixdate="2018-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade our use of checkstyle to 8.6+</summary>
      <description>We should upgrade our checkstyle version to 8.6 or later so we can use the "match violation message to this regex" feature for suppression. That will allow us to make sure we don't regress on HTrace v3 vs v4 APIs (came up in HBASE-20332).We're currently blocked on upgrading to 8.3+ by checkstyle #5279, a regression that flags our use of both the "separate import groups" and "put static imports over here" configs as an error.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-checkstyle.src.main.resources.hbase.checkstyle-suppressions.xml</file>
    </fixedFiles>
  </bug>
  <bug id="20759" opendate="2018-6-20 00:00:00" fixdate="2018-6-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Please use HTTPS for KEYS</summary>
      <description>Please use HTTPS for the link to KEYS on download page(s)</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.downloads.xml</file>
    </fixedFiles>
  </bug>
  <bug id="2076" opendate="2009-12-29 00:00:00" fixdate="2009-12-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Many javadoc warnings</summary>
      <description>We are about to release 0.20.3, it would be nice to get pretty and fix javadoc warnings.</description>
      <version>None</version>
      <fixedVersion>0.20.3,0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.InternalScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapreduce.package-info.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapreduce.MultiTableOutputFormat.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="20792" opendate="2018-6-26 00:00:00" fixdate="2018-7-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>info:servername and info:sn inconsistent for OPEN region</summary>
      <description>Next problem we've run into after HBASE-20752 and HBASE-20708After a rolling restart of a cluster, we'll see situations where a collection of regions will simply not be assigned out to the RS. I was able to reproduce this my mimic the restart patterns our tests do internally (ignore whether this is the best way to restart nodes for now ). The general pattern is this:for rs in regionservers: stop(server, rs, RS)for master in masters: stop(server, master, MASTER)sleep(15)for master in masters: start(server, master, MASTER)for rs in regionservers: start(server, rs, RS)Looking at meta, we can see why the Master is ignoring some regions: test column=table:state, timestamp=1529871718998, value=\x08\x00 test,,1529871718122.0297f680df6dc0166a44f9536346268e. column=info:regioninfo, timestamp=1529967103390, value={ENCODED =&gt; 0297f680df6dc0166a44f9536346268e, NAME =&gt; 'test,,1529871718122.0297f680df6dc0166a44f9536346268e.', STARTKEY =&gt; '', ENDKEY =&gt; ''} test,,1529871718122.0297f680df6dc0166a44f9536346268e. column=info:seqnumDuringOpen, timestamp=1529967103390, value=\x00\x00\x00\x00\x00\x00\x00* test,,1529871718122.0297f680df6dc0166a44f9536346268e. column=info:server, timestamp=1529967103390, value=ctr-e138-1518143905142-378097-02-000012.hwx.site:16020 test,,1529871718122.0297f680df6dc0166a44f9536346268e. column=info:serverstartcode, timestamp=1529967103390, value=1529966776248 test,,1529871718122.0297f680df6dc0166a44f9536346268e. column=info:sn, timestamp=1529967096482, value=ctr-e138-1518143905142-378097-02-000006.hwx.site,16020,1529966755170 test,,1529871718122.0297f680df6dc0166a44f9536346268e. column=info:state, timestamp=1529967103390, value=OPENThe region is marked as OPEN. The master doesn't know any better. However, the interesting bit is that info:server and info:sn are inconsistent (which, according to the javadoc should not be possible for an OPEN region).{{}}This doesn't happen every time, but I caught it yesterday on the 2nd or 3rd attempt, so I'm hopeful it's not a bear to repro.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.RegionStateStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.RegionStates.java</file>
    </fixedFiles>
  </bug>
  <bug id="20794" opendate="2018-6-26 00:00:00" fixdate="2018-8-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CreateTable operation does not log its landing at the master nor the initiator at INFO level</summary>
      <description>We don't log at INFO level the arrival on the Master of a create table request. Need to log for basic audit purposes the initiator and the pid created to run the create table.Review other macro ops to make sure they log at INFO level.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0,2.2.0,2.0.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="20798" opendate="2018-6-27 00:00:00" fixdate="2018-6-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Duplicate thread names of StoreFileOpenerThread and StoreFileCloserThread</summary>
      <description>jstack "StoreFileOpenerThread-info-1" #8994 daemon prio=5 os_prio=0 tid=0x00007fad7a46b000 nid=0x624a waiting on condition [0x00007fad7f7ef000] "StoreFileOpenerThread-info-1" #8993 daemon prio=5 os_prio=0 tid=0x00007fad71064000 nid=0x6249 waiting on condition [0x00007fad7fff7000]Duplicated thread names exists in jstack sometimes, because StoreFileOpenerThreads are created per region and have same names. Suggest adding region name to corresponding thread name in order to distinguish StoreFileOpenerThreads, which are created per region. This could be helpful for troubleShooting.</description>
      <version>3.0.0-alpha-1,2.0.0</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="20817" opendate="2018-6-29 00:00:00" fixdate="2018-7-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Infinite loop when executing ReopenTableRegionsProcedure</summary>
      <description>As discussed in HBASE-20792, it seems that a region's openSeqNum could remain the same after a sucessful reopen, which causes the RTRP loop infinitely.</description>
      <version>2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0,2.0.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin1.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.MoveRegionProcedure.java</file>
    </fixedFiles>
  </bug>
  <bug id="2083" opendate="2009-12-31 00:00:00" fixdate="2009-12-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[EC2] HDFS DataNode no longer required on master</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.3,0.90.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.contrib.ec2.bin.hbase-ec2-init-remote.sh</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.contrib.ec2.bin.hbase-ec2-env.sh</file>
    </fixedFiles>
  </bug>
  <bug id="20830" opendate="2018-7-2 00:00:00" fixdate="2018-7-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document that region replica does not work well with AMv2</summary>
      <description>As we can see lots of TODOs for region replica feature in the AssignmentManager' code. And also, now we rely on the openSeqNum to determine whether a region has been successfully reopened, but the openSeqNum for a non-default replica region seems unstable...It is too late for the 2.1.0 release so let's just add a note in ref guide to say that region replica does not work well with AMv2 first, and then start to make it stable in follow on minor or major release lines.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="20833" opendate="2018-7-2 00:00:00" fixdate="2018-7-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Modify pre-upgrade coprocessor validator to support table level coprocessors</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0,2.0.2</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.tool.coprocessor.CoprocessorValidatorTest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.PreUpgradeValidator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.coprocessor.CoprocessorViolation.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.coprocessor.CoprocessorValidator.java</file>
    </fixedFiles>
  </bug>
  <bug id="20873" opendate="2018-7-11 00:00:00" fixdate="2018-7-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update doc for Endpoint-based Export</summary>
      <description>The current documentation on the usage is a little vague. I'd like to take a stab at expanding it, based on my experience.</description>
      <version>2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1,2.0.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="2090" opendate="2010-1-4 00:00:00" fixdate="2010-1-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>findbugs issues</summary>
      <description>Findbugs issues/ fixes for a subset of them.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.wal.TestHLog.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestWideScanner.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestStoreScanner.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestStoreReconstruction.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.generated.Hbase.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.KeyValueHeap.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="20901" opendate="2018-7-17 00:00:00" fixdate="2018-7-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reducing region replica has no effect</summary>
      <description>While reducing the region replica, server name(sn) and state column of the replica are not getting deleted, resulting in assignment manager to think that these regions are CLOSED and assign them again.</description>
      <version>2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestMetaTableAccessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.EnableTableProcedure.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MetaTableAccessor.java</file>
    </fixedFiles>
  </bug>
  <bug id="20909" opendate="2018-7-19 00:00:00" fixdate="2018-7-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add 2.1.0 to the download page</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.downloads.xml</file>
    </fixedFiles>
  </bug>
  <bug id="20915" opendate="2018-7-20 00:00:00" fixdate="2018-7-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove the commit column on our download page</summary>
      <description>As required by the ASF moderator.However first please fix the download page so it does not link to the Gitrepo.Please drop the commit id and the link; they are not appropriate for adownload page.Only approved releases should be linked from the download page.Whilst the commit itself may have been included in the VOTE email as partof the approval process, it is not a formal release artefact. And links torepos give access to code that has not been approved.Information on commit ids and git repos etc should appear on pages intendedfor the HBase developer community only.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.downloads.xml</file>
    </fixedFiles>
  </bug>
  <bug id="20943" opendate="2018-7-25 00:00:00" fixdate="2018-1-25 01:00:00" resolution="Unresolved">
    <buginformation>
      <summary>Add offline/online region count into metrics</summary>
      <description>We intensively use metrics to monitor the health of our HBase production cluster. We have seen some regions of a table stuck and cannot be brought online due to AWS issue which cause some log file corrupted. It will be good if we can catch this early. Although WebUI has this information, it is not useful for automated monitoring. By adding this metric, we can easily monitor them with our monitoring system. </description>
      <version>2.0.0,1.2.6.1</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterMetricsWrapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterWrapperImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="21001" opendate="2018-8-3 00:00:00" fixdate="2018-9-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ReplicationObserver fails to load in HBase 2.0.0</summary>
      <description>ReplicationObserver was added in HBASE-17290 to prevent "Potential loss of data for replication of bulk loaded hfiles".I tried to enable bulk loading replication feature (hbase.replication.bulkload.enabled=true and configure hbase.replication.cluster.id) on a HBase 2.0.0 cluster, but the RegionServer started with the following error:2018-08-02 18:20:36,365 INFO org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost: System coprocessor loading is enabled2018-08-02 18:20:36,365 INFO org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost: Table coprocessor loading is enabled2018-08-02 18:20:36,365 ERROR org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost: org.apache.hadoop.hbase.replication.regionserver.ReplicationObserver is not of typeRegionServerCoprocessor. Check the configuration of hbase.coprocessor.regionserver.classes2018-08-02 18:20:36,366 ERROR org.apache.hadoop.hbase.coprocessor.CoprocessorHost: Cannot load coprocessor ReplicationObserverIt looks like this was broken by HBASE-17732 to me, but I could be wrong.</description>
      <version>2.0.0-alpha-4,2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1,2.0.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="21026" opendate="2018-8-8 00:00:00" fixdate="2018-8-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix Backup/Restore command usage bug in book</summary>
      <description></description>
      <version>2.0.0</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.backup.restore.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="21132" opendate="2018-8-30 00:00:00" fixdate="2018-9-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>return wrong result in rest multiget</summary>
      <description>There are two ways to specify columns in multi-gets feature。1、Specify columns in PathParam as described in HBASE-15870. Examples: GET /t1/multiget/cf1:c1,cf2?row=r12、Specify columns in QueryParam. Examples: GET /t1/multiget?row=r1/cf1:c1,cf2&amp;row=r2/cf2 However, when we specify columns in QueryParam, the result is wrong , the rowkey contains the columns.</description>
      <version>3.0.0-alpha-1,2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.2.0,2.1.1,2.0.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.TestMultiRowResource.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.MultiRowResource.java</file>
    </fixedFiles>
  </bug>
  <bug id="21179" opendate="2018-9-10 00:00:00" fixdate="2018-9-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix the number of actions in responseTooSlow log</summary>
      <description>responseTooSlow2018-09-10 16:13:53,022 WARN &amp;#91;B.DefaultRpcServer.handler=209,queue=29,port=60020&amp;#93; ipc.RpcServer: (responseTooSlow): {"processingtimems":321262,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"127.0.0.1:56149","param":"region= tsdb,\\x00\\x00.[\\x89\\x1F\\xB0\\x00\\x00\\x01\\x00\\x01Y\\x00\\x00\\x02\\x00\\x00x04,1536133210446.7c752de470bd5558a001117b123a5db5., for 1 actions and 1st row key=\\x00\\x00.[\\x96x16p","starttimems":1536566911759,"queuetimems":0,"class":"HRegionServer","responsesize":2,"method":"Multi"}The responseTooSlow log is printed when the processing time of a request exceeds the specified threshold. The number of actions and the contents of the first rowkey in the request will be included in the log.However, the number of actions is inaccurate, and it is actually the number of regions that the request needs to visit.Just like the logs above, users may be mistaken for using 321262ms to process an action, which is incredible, so we need to fix it.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.3.3,1.2.8,2.2.0,1.4.8,2.1.1,2.0.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="21206" opendate="2018-9-18 00:00:00" fixdate="2018-9-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scan with batch size may return incomplete cells</summary>
      <description>See the attached UT. the table has 5 columns and each column has at least one cell in it, but when we scan the table with batchSize=3, we only got 3 cells returned , the other 2 cells got lost ...It's a critial bug and should be fixed..</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,1.4.8,2.1.1,2.0.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide3.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="21244" opendate="2018-9-27 00:00:00" fixdate="2018-9-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Skip persistence when retrying for assignment related procedures</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ReopenTableRegionsProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.TransitRegionStateProcedure.java</file>
    </fixedFiles>
  </bug>
  <bug id="21245" opendate="2018-9-27 00:00:00" fixdate="2018-9-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add exponential backoff when retrying for sync replication related procedures</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.TransitPeerSyncReplicationStateProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.SyncReplicationReplayWALProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.ModifyPeerProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.AbstractPeerProcedure.java</file>
    </fixedFiles>
  </bug>
  <bug id="21299" opendate="2018-10-12 00:00:00" fixdate="2018-10-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>List counts of actual region states in master UI tables section</summary>
      <description>It the tables panel, we list Open Regions, Offline Regions, Failed Regions, Split Region, and Other. This is not very useful. It is from a time before region states were edited down. Better to list OPEN, CLOSED, OPENING, CLOSING...</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="21338" opendate="2018-10-18 00:00:00" fixdate="2018-10-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[balancer] If balancer is an ill-fit for cluster size, it gives little indication</summary>
      <description>See parent issue. Running balancer on a cluster where the max steps was way inadequate, the balancer gave little to no indication that it was ill-configured. In fact, it only logged its starting and then that there was nothing to do though the cluster was obviously out-of-whack.Ideally the balancer would complain when say the maxSteps limit is a small fraction of what the cluster's calculated max steps are, or it would notice that the balancer is making little progress on an imbalanced cluster and shout. Can we set balancer configs w/o having to restart Master?</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1,2.0.3</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.java</file>
    </fixedFiles>
  </bug>
  <bug id="2138" opendate="2010-1-16 00:00:00" fixdate="2010-1-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>unknown metrics type</summary>
      <description>Since the recent metric commits I see this on the master and RS at boot:2010-01-16 11:24:59,730 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=RegionServer, sessionId=regionserver/10.10.1.49:600202010-01-16 11:24:59,732 ERROR org.apache.hadoop.metrics.MetricsUtil: unknown metrics type: org.apache.hadoop.hbase.metrics.MetricsRate2010-01-16 11:24:59,732 ERROR org.apache.hadoop.hbase.metrics: unknown metrics instance: org.apache.hadoop.metrics.util.MetricsTimeVaryingRate2010-01-16 11:24:59,732 ERROR org.apache.hadoop.hbase.metrics: unknown metrics instance: org.apache.hadoop.metrics.util.MetricsTimeVaryingRate2010-01-16 11:24:59,732 ERROR org.apache.hadoop.hbase.metrics: unknown metrics instance: org.apache.hadoop.metrics.util.MetricsTimeVaryingRate2010-01-16 11:24:59,732 ERROR org.apache.hadoop.hbase.metrics: unknown metrics instance: org.apache.hadoop.metrics.util.MetricsTimeVaryingRateWe need to clean that for 0.20.3</description>
      <version>None</version>
      <fixedVersion>0.20.3,0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.metrics.RegionServerMetrics.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.metrics.MetricsMBeanBase.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="21404" opendate="2018-10-29 00:00:00" fixdate="2018-7-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Master/RS navbar active state does not work</summary>
      <description>In master/rs web UI, the current active tab is not updated when user switches to any tab other than "Home" tab.For example: even though say if we are on "tabledetailed.jsp", the navbar does not update the active state of that tab. See master_before.png</description>
      <version>3.0.0-alpha-1,2.0.0</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.regionserver.footer.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.footer.jsp</file>
    </fixedFiles>
  </bug>
  <bug id="21405" opendate="2018-10-30 00:00:00" fixdate="2018-6-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[DOC] Add Details about Output of "status &amp;#39;replication&amp;#39;"</summary>
      <description>Add more information about the meaning of each metric on to http://hbase.apache.org/book.html#_monitoring_replication_status.SOURCE: PeerID AgeOfLastShippedOp SizeOfLogQueue TimeStampsOfLastShippedOp Replication LagSINK AgeOfLastAppliedOp TimeStampsOfLastAppliedOp</description>
      <version>3.0.0-alpha-1,1.4.0,2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="21411" opendate="2018-10-30 00:00:00" fixdate="2018-11-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Need to document the snapshot metric data that is shown in HBase Master Web UI</summary>
      <description>We need to add documentation into the Reference Guide for the work that was done in HBASE-15415.</description>
      <version>1.3.0,2.0.0</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="21475" opendate="2018-11-13 00:00:00" fixdate="2018-1-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Put mutation (having TTL set) added via co-processor is retrieved even after TTL expires</summary>
      <description>Steps to reproduce Create a region co-processor and override preBatchMutate such that it creates a put corresponding to a user put having same timestamp and TTL as the user put. Create a table and add a row having TTL set to 3000 ms. Wait for &gt; 3000 ms. Scan the table.Expected Result No rows should be retrieved in step 4Actual Result User row is not retreived, while put created via co-processor is still retrieved.Analysis/Issue Unlike user mutations, the mutations added by coprocessor do not have tags corresponding to TTL, hence they are retrieved in scan even after TTL expires.</description>
      <version>3.0.0-alpha-1,2.0.0,2.1.1</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,1.4.10,2.1.3,2.0.5,1.3.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverForAddingMutationsFromCoprocessors.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="21502" opendate="2018-11-20 00:00:00" fixdate="2018-4-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update SyncTable section on RefGuide once HBASE-20586 is committed</summary>
      <description>SyncTable refguide section currently mentions limitation to run it on different kerberos realm. HBASE-20586 is ongoing to resolve this problem. This jira is to make sure RefGuide is updated accordingly once HBASE-20586 is resolved.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="21545" opendate="2018-12-4 00:00:00" fixdate="2018-12-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>NEW_VERSION_BEHAVIOR breaks Get/Scan with specified columns</summary>
      <description>Setting NEW_VERSION_BEHAVIOR =&gt; 'true' on a column family causes only one column to be returned when columns are specified in Scan or Get query. The result is always one first column by sorted order. I've attached a code snipped to reproduce the issue that can be converted into a test.I've also validated with hbase shell and gohbase client, so it's gotta be server side issue.</description>
      <version>2.0.0,2.1.1</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.2,2.0.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.querymatcher.TestNewVersionBehaviorTracker.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.NewVersionBehaviorTracker.java</file>
    </fixedFiles>
  </bug>
  <bug id="21659" opendate="2018-12-29 00:00:00" fixdate="2018-1-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Avoid to load duplicate coprocessors in system config and table descriptor</summary>
      <description>When there are same coprocessor in system coprocessor config and table descriptor. It will load the coprocessor twice and the coprocessor method may run twice, too. It should avoid to load duplicate coprocessors.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorHost.java</file>
    </fixedFiles>
  </bug>
  <bug id="21697" opendate="2019-1-8 00:00:00" fixdate="2019-1-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add 2.1.2 to the download page</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.1.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.downloads.xml</file>
    </fixedFiles>
  </bug>
  <bug id="21705" opendate="2019-1-11 00:00:00" fixdate="2019-1-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Should treat meta table specially for some methods in AsyncAdmin</summary>
      <description>For example, tableExists, isTableEnabled, isTableDisabled...For now, we will go to the meta table directly but obviously, meta table does not contain the record for itself...</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.3,2.0.5</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTableAdminApi3.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.AsyncMetaTableAccessor.java</file>
    </fixedFiles>
  </bug>
  <bug id="21976" opendate="2019-3-1 00:00:00" fixdate="2019-3-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Deal with RetryImmediatelyException for batching request</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.4</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncBatchRpcRetryingCaller.java</file>
    </fixedFiles>
  </bug>
  <bug id="21977" opendate="2019-3-1 00:00:00" fixdate="2019-3-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Skip replay WAL and update seqid when open regions restored from snapshot</summary>
      <description>TableSnapshotScanner restore a snapshot and then open the restored regions. When open these regions, we can skip replay WAL and update seqid.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestRestoreSnapshotHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ClientSideRegionScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="21978" opendate="2019-3-2 00:00:00" fixdate="2019-3-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Should close AsyncRegistry if we fail to get cluster id when creating AsyncConnection</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.4</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="22072" opendate="2019-3-20 00:00:00" fixdate="2019-5-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>High read/write intensive regions may cause long crash recovery</summary>
      <description>Compaction of high read loaded region may leave compacted files undeleted because of existing scan references:INFO org.apache.hadoop.hbase.regionserver.HStore - Can't archive compacted file hdfs://hdfs-ha/hbase... because of either isCompactedAway=true or file has reference, isReferencedInReads=true, refCount=1, skipping for nowIf region is either high write loaded this happens quite often and region may have few storefiles and tons of undeleted compacted hdfs files.Region keeps all that files (in my case thousands) untill graceful region closing procedure, which ignores existing references and drop obsolete files. It works fine unless consuming some extra hdfs space, but only in case of normal region closing. If region server crashes than new region server, responsible for that overfiling region, reads hdfs folder and try to deal with all undeleted files, producing tons of storefiles, compaction tasks and consuming abnormal amount of memory, wich may lead to OutOfMemory Exception and further region servers crash. This stops writing to region because number of storefiles reach hbase.hstore.blockingStoreFiles limit, forces high GC duty and may take hours to compact all files into working set of files.Workaround is a periodically check hdfs folders files count and force region assign for ones with too many files.It could be nice if regionserver had a setting similar to hbase.hstore.blockingStoreFiles and invoke attempt to drop undeleted compacted files if number of files reaches this setting.</description>
      <version>2.0.0</version>
      <fixedVersion>2.2.0,2.3.0,2.0.6,2.1.5</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="22077" opendate="2019-3-21 00:00:00" fixdate="2019-3-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expose sleep time as a command line argument of IntergationTestBackupRestore</summary>
      <description>Extend command line arguments of IntergationTestBackupRestore with a sleep time of chaos monkey options to be able to setup policy of region server restarts more granularly.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestBackupRestore.java</file>
    </fixedFiles>
  </bug>
  <bug id="2208" opendate="2010-2-10 00:00:00" fixdate="2010-6-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TableServers # processBatchOfRows - converts from List to [ ] - Expensive copy</summary>
      <description>With autoFlush to false and a large write buffer on HTable, when we write bulk puts - TableServer # processBatchOfRows , convert the input (List) to an [ ] , before sending down the wire. With a write buffer as large as 20 MB , that becomes an expensive copy when we do - list.toArray(new T[ ] ). May be - should we change the wire protocol to support List as well , and then revisit this to prevent the bulk copy ?Batch b = new Batch(this) { @Override int doCall(final List&lt;Row&gt; currentList, final byte [] row, final byte [] tableName) throws IOException, RuntimeException { *final Put [] puts = currentList.toArray(PUT_ARRAY_TYPE);* return getRegionServerWithRetries(new ServerCallable&lt;Integer&gt;(this.c, tableName, row) { public Integer call() throws IOException { return server.put(location.getRegionInfo().getRegionName(), puts); } }); }</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HRegionInterface.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="22152" opendate="2019-4-3 00:00:00" fixdate="2019-4-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create a jenkins file for yetus to processing GitHub PR</summary>
      <description>I think we can just copy the jenkinsfile from the hadoop project.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,1.4.10,1.3.4,2.3.0,2.0.6,1.2.12,2.1.5</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile.GitHub</file>
    </fixedFiles>
  </bug>
  <bug id="22155" opendate="2019-4-3 00:00:00" fixdate="2019-4-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move 2.2.0 on to hbase-thirdparty-2.2.0</summary>
      <description>hbase-thirdparty-2.2.0 was just released. The 2.2.0 RM (zghaobac) gave his blessing in parent issue that 2.2.0 should use thirdparty 2.2.0.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="22160" opendate="2019-4-3 00:00:00" fixdate="2019-6-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add sorting functionality in regionserver web UI for user regions</summary>
      <description>Should be good to have the same sort of sorting functionality, like hmaster via HBASE-21207, in regionserver web UI for the list of regions too.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.1,2.1.6</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="22250" opendate="2019-4-16 00:00:00" fixdate="2019-4-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The same constants used in many places should be placed in constant classes</summary>
      <description>I think we should put these configurations in the HConstants class to avoid the trouble of modifying a lot of places when we modify them later.public static final String MASTER_KRB_PRINCIPAL = "hbase.master.kerberos.principal";public static final String MASTER_KRB_KEYTAB_FILE = "hbase.master.keytab.file";public static final String REGIONSERVER_KRB_PRINCIPAL = "hbase.regionserver.kerberos.principal";public static final String REGIONSERVER_KRB_KEYTAB_FILE = "hbase.regionserver.keytab.file";</description>
      <version>1.2.0,2.0.0,2.1.1,2.1.4</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.HBaseKerberosUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestZKAndFSPermissions.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.SecurityInfo.java</file>
    </fixedFiles>
  </bug>
  <bug id="22280" opendate="2019-4-21 00:00:00" fixdate="2019-12-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Separate read/write handler for priority request(especially for meta).</summary>
      <description>Client may give too many read pressure on meta, so blocking master write meta for region open.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.3</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.assignment.TestReportOnlineRegionsRace.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor.java</file>
    </fixedFiles>
  </bug>
  <bug id="22281" opendate="2019-4-21 00:00:00" fixdate="2019-4-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix failed shell UTs</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.table.rb</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.hbase.rb</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug id="22379" opendate="2019-5-8 00:00:00" fixdate="2019-5-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix Markdown for "Voting on Release Candidates" in book</summary>
      <description>The Markdown in the section "Voting on Release Candidates" of the HBase book seems to be broken. It looks like that there should be a quote, which isn't displayed correctly. Same is true for the formatting of the Maven RAT command.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,1.4.10,2.3.0,2.0.6,2.1.5,1.3.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="22456" opendate="2019-5-22 00:00:00" fixdate="2019-5-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Polish TestSplitTransitionOnCluster</summary>
      <description>Remove the compaction state check in TestSplitTransitionOnCluster.testMasterRestartAtRegionSplitPendingCatalogJanitor, as region.compact is a synchronous call, we will only return when the compaction is finished. And not sure why we do not wait for the split to finish in this test, before getting the daughter regions...</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
    </fixedFiles>
  </bug>
  <bug id="22513" opendate="2019-5-31 00:00:00" fixdate="2019-6-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Admin#getQuota does not work correctly if exceedThrottleQuota is set</summary>
      <description>Admin#getQuota get nothing if exceedThrottleQuota is set, because exceedThrottleQuota is a special row key in quota table and can not be parsed to a QuotaSettings.The shell command results are as follows:hbase(main):018:0&gt; list_quotasOWNER QUOTAS0 row(s)Took 0.0342 secondshbase(main):019:0&gt; scan 'hbase:quota'ROW COLUMN+CELLexceedThrottleQuota column=q:s, timestamp=1559199136449, value=\x00n.ang column=q:s, timestamp=1559122413584, value=PBUF\x12\x08*\x06\x08\x04\x10" \x02n.ns1 column=q:s, timestamp=1559203286943, value=PBUF\x12\x10\x1A\x06\x08\x04\x10\x05 \x02*\x06\x08\x04\x10\x05 \x02\x1A\x0A\x08\x80\x80\x80\x80\x80\xC0\x0C\x10\x03</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestQuotaAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaRetriever.java</file>
    </fixedFiles>
  </bug>
  <bug id="22710" opendate="2019-7-18 00:00:00" fixdate="2019-4-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Wrong result in one case of scan that use raw and versions and filter together</summary>
      <description>create 'testScanRaw',{NAME =&gt; 'f', VERSIONS =&gt; 1} put 'testScanRaw','r1','f:q','1'put 'testScanRaw','r1','f:q','2'put 'testScanRaw','r1','f:q','3' hbase(main):005:0&gt; scan 'testScanRaw',{RAW =&gt; true, STARTROW =&gt; 'r1', STOPROW=&gt;'r1',VERSIONS=&gt;2}ROW COLUMN+CELLr1 column=f:q, timestamp=1563430154757, value=3r1 column=f:q, timestamp=1563430153120, value=2 hbase(main):006:0&gt; scan 'testScanRaw',{RAW =&gt; true, STARTROW =&gt; 'r1', STOPROW=&gt;'r1',VERSIONS=&gt;2,FILTER =&gt; "(QualifierFilter (=, 'binary:q'))"}ROW COLUMN+CELLr1 column=f:q, timestamp=1563430154757, value=3 BTW,the result is right in hbase1.2.</description>
      <version>2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.5</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.ScanQueryMatcher.java</file>
    </fixedFiles>
  </bug>
  <bug id="22935" opendate="2019-8-27 00:00:00" fixdate="2019-8-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TaskMonitor warns MonitoredRPCHandler task may be stuck when it recently started</summary>
      <description>After setting hbase.taskmonitor.rpc.warn.time to 180000, the logs show WARN messages such as these2019-08-08 21:50:02,601 WARN [read for TaskMonitor] monitoring.TaskMonitor - Task may be stuck: RpcServer.FifoWFPBQ.default.handler=4,queue=4,port=60020: status=Servicing call from &lt;ip&gt;:55164: Scan, state=RUNNING, startTime=1563305858103, completionTime=-1, queuetimems=1565301002599, starttimems=1565301002599, clientaddress=&lt;ip&gt;, remoteport=55164, packetlength=370, rpcMethod=ScanNotice that the first starttimems is far in the past. The second starttimems and the queuetimems are much closer to the log timestamp than 180 seconds. I think this is because the warnTime is initialized to the time that MonitoredTaskImpl is created, but never updated until we write a warn message to the log.</description>
      <version>3.0.0-alpha-1,1.4.0,1.5.0,1.3.3,2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,2.2.1,1.3.6,1.4.11,2.1.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.monitoring.TestTaskMonitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="23172" opendate="2019-10-14 00:00:00" fixdate="2019-10-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase Canary region success count metrics reflect column family successes, not region successes</summary>
      <description>HBase Canary reads once per column family per region. The current "region success count" should actually be "column family success count," which means we need another metric that actually reflects region success count. Additionally, the region read and write latencies only store the latencies of the last column family of the region read. Instead of a map of regions to a single latency value and success value, we should map each region to a list of such values.</description>
      <version>3.0.0-alpha-1,1.3.0,1.4.0,1.5.0,2.0.0,2.1.5,2.2.1</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,1.6.0,2.1.8,2.2.3</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.tool.TestCanaryTool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.CanaryTool.java</file>
    </fixedFiles>
  </bug>
  <bug id="23222" opendate="2019-10-28 00:00:00" fixdate="2019-10-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Better logging and mitigation for MOB compaction failures</summary>
      <description>Some logging and mitigation options for MOB dataloss issues described in HBASE-22075.</description>
      <version>2.1.0,2.0.0,2.2.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.1.8,2.2.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.resources.log4j.properties</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.cleaner.TestHFileCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.MobUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.compactions.PartitionedMobCompactor.java</file>
    </fixedFiles>
  </bug>
  <bug id="2324" opendate="2010-3-14 00:00:00" fixdate="2010-3-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Refactoring of TableRecordReader (mapred / mapreduce) for reuse outside the scope of InputSplit / RecordReader</summary>
      <description>For the storing of tf-idf in hbase ( lucene-hbase project) we need to scan the keys across the table and retrieve columnar values. Quite an amount of logic can be reused from TableRecordReader for the purpose. Refactored TableRecordReader ( from being a protected inner class to a public class outside ) Created an impl class , that does the actual work, without the dependency on hadop.mapreduce.* packages ( RecordReader) while retaining the implementation that can be reused across libraries.Do the same thing for .mapred. and .mapreduce. packages. Let me know the thoughts on the same.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapred.TableInputFormatBase.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2533" opendate="2010-5-11 00:00:00" fixdate="2010-5-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[EC2] ec2-describe-instances returning account number instead of bucket name</summary>
      <description>ec2-describe-instances is returning account number instead of bucket name now that our bucket names are apparently too long. Update launch scripts.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">contrib.ec2.bin.launch-hbase-zookeeper</file>
      <file type="M">contrib.ec2.bin.launch-hbase-slaves</file>
      <file type="M">contrib.ec2.bin.launch-hbase-master</file>
      <file type="M">contrib.ec2.bin.hbase-ec2-init-remote.sh</file>
      <file type="M">contrib.ec2.bin.hbase-ec2-env.sh</file>
      <file type="M">contrib.ec2.bin.create-hbase-image</file>
    </fixedFiles>
  </bug>
  <bug id="2577" opendate="2010-5-19 00:00:00" fixdate="2010-5-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove &amp;#39;core&amp;#39; maven module; move core up a level</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.filter.Filter.java</file>
      <file type="M">bin.hirb.rb</file>
      <file type="M">core.pom.xml</file>
      <file type="M">src.assembly.bin.xml</file>
      <file type="M">pom.xml</file>
      <file type="M">core.src.test.ruby.test.helper.rb</file>
      <file type="M">core.src.test.ruby.tests.runner.rb</file>
      <file type="M">core.src.test.ruby.shell.shell.test.rb</file>
      <file type="M">core.src.test.ruby.shell.formatter.test.rb</file>
      <file type="M">core.src.test.ruby.shell.commands.test.rb</file>
      <file type="M">core.src.test.ruby.hbase.table.test.rb</file>
      <file type="M">core.src.test.ruby.hbase.hbase.test.rb</file>
      <file type="M">core.src.test.ruby.hbase.admin.test.rb</file>
      <file type="M">core.src.test.resources.org.apache.hadoop.hbase.PerformanceEvaluation.Counter.properties</file>
      <file type="M">core.src.test.resources.mapred-queues.xml</file>
      <file type="M">core.src.test.resources.log4j.properties</file>
      <file type="M">core.src.test.resources.hbase-site.xml</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.zookeeper.TestHQuorumPeer.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.util.TestRootPath.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.util.TestMergeTool.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.util.TestKeying.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.util.TestBytes.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.util.TestByteBloomFilter.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.util.TestBase64.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.util.SoftValueSortedMapTest.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.util.DisabledTestMetaUtils.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.TimestampTestBase.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.thrift.TestThriftServer.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.TestZooKeeper.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.TestSerialization.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.TestScanMultipleVersions.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.TestRegionRebalancing.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.TestMultiParallelPut.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.TestMergeTable.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.TestMergeMeta.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.TestKeyValue.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.TestInfoServers.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.TestHMsg.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.TestFullLogReconstruction.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.TestEmptyMetaInfo.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.TestCompare.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.rest.TestVersionResource.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.rest.TestTableResource.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.rest.TestStatusResource.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.rest.TestSchemaResource.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.rest.TestScannersWithFilters.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.rest.TestScannerResource.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.rest.TestRowResource.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.rest.PerformanceEvaluation.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.rest.model.TestVersionModel.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.rest.model.TestTableSchemaModel.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.rest.model.TestTableRegionModel.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.rest.model.TestTableListModel.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.rest.model.TestTableInfoModel.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.rest.model.TestStorageClusterVersionModel.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.rest.model.TestStorageClusterStatusModel.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.rest.model.TestScannerModel.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.rest.model.TestRowModel.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.rest.model.TestColumnSchemaModel.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.rest.model.TestCellSetModel.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.rest.model.TestCellModel.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.rest.HBaseRESTClusterTestBase.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.rest.client.TestRemoteTable.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.rest.client.TestRemoteAdmin.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRolling.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogActionsListener.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLog.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.TestWildcardColumnTracker.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.TestWideScanner.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreScanner.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreReconstruction.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreFile.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.TestStore.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.TestScanWildcardColumnTracker.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.TestScanner.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.TestScanDeleteTracker.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.TestReadWriteConsistencyControl.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.TestQueryMatcher.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.TestMinorCompactingStoreScanner.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.TestMemStore.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.TestKeyValueSkipListSet.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.TestKeyValueScanFixture.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.TestKeyValueHeap.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionInfo.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.TestGetDeleteTracker.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.TestGetClosestAtOrBefore.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.TestExplicitColumnTracker.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.TestDeleteCompare.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.OOMERegionServer.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.KeyValueScanFixture.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.DisabledTestRegionServerExit.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluationCommons.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.MultiRegionTable.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.MiniHBaseCluster.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.metrics.TestMetricsMBeanBase.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.master.TestServerManager.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.master.TestRegionServerOperationQueue.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.master.TestRegionManager.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.master.TestOldLogsCleaner.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.master.TestMinimumServerCount.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.master.TestMasterWithDisabling.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.master.TestMasterTransitions.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.master.OOMEHMaster.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.mapred.TestTableMapReduce.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTimeRangeMapRed.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableMapReduce.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.mapreduce.TestSimpleTotalOrderPartitioner.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.MapFilePerformanceEvaluation.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.KeyValueTestUtil.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.io.TestImmutableBytesWritable.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.io.TestHeapSize.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.io.TestHbaseObjectWritable.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.io.hfile.TestSeekTo.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.io.hfile.TestLruBlockCache.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileSeek.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFilePerformance.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFile.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.io.hfile.TestCachedBlockQueue.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.io.hfile.RandomSeek.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.io.hfile.RandomDistribution.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.io.hfile.NanoTimer.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.io.hfile.KVGenerator.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.io.hfile.KeySampler.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.HFilePerformanceEvaluation.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.HBaseTestCase.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.HBaseClusterTestCase.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.filter.TestSingleColumnValueFilter.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.filter.TestSingleColumnValueExcludeFilter.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.filter.TestPrefixFilter.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.filter.TestPageFilter.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.filter.TestInclusiveStopFilter.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.filter.TestFilterList.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.filter.TestFilter.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.filter.TestDependentColumnFilter.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.filter.TestColumnPaginationFilter.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.EmptyWatcher.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.client.TestTimestamp.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.client.TestShell.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.client.TestScannerTimeout.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.client.TestHTablePool.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.client.TestGetRowVersions.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.AbstractMergeTestBase.java</file>
      <file type="M">core.src.saveVersion.sh</file>
      <file type="M">core.src.main.ruby.shell.formatter.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.zk.dump.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.zk.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.version.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.truncate.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.status.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.split.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.shutdown.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.scan.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.put.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.major.compact.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.list.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.incr.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.get.counter.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.get.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.flush.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.exists.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.enable.region.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.enable.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.drop.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.disable.region.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.disable.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.describe.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.deleteall.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.delete.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.create.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.count.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.compact.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.close.region.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.alter.rb</file>
      <file type="M">core.src.main.ruby.shell.commands.rb</file>
      <file type="M">core.src.main.ruby.shell.rb</file>
      <file type="M">core.src.main.ruby.irb.hirb.rb</file>
      <file type="M">core.src.main.ruby.hbase.table.rb</file>
      <file type="M">core.src.main.ruby.hbase.hbase.rb</file>
      <file type="M">core.src.main.ruby.hbase.admin.rb</file>
      <file type="M">core.src.main.ruby.hbase.rb</file>
      <file type="M">core.src.main.resources.webapps.static.images.treeview-default.gif</file>
      <file type="M">core.src.main.resources.webapps.static.images.treeview-default-line.gif</file>
      <file type="M">core.src.main.resources.webapps.static.images.plus.gif</file>
      <file type="M">core.src.main.resources.webapps.static.images.minus.gif</file>
      <file type="M">core.src.main.resources.webapps.static.hbase.logo.med.gif</file>
      <file type="M">core.src.main.resources.webapps.static.hbase.css</file>
      <file type="M">core.src.main.resources.webapps.rest.WEB-INF.web.xml</file>
      <file type="M">core.src.main.resources.webapps.rest.META-INF.MANIFEST.MF</file>
      <file type="M">core.src.main.resources.webapps.regionserver.regionserver.jsp</file>
      <file type="M">core.src.main.resources.webapps.regionserver.index.html</file>
      <file type="M">core.src.main.resources.webapps.master.zk.jsp</file>
      <file type="M">core.src.main.resources.webapps.master.table.jsp</file>
      <file type="M">core.src.main.resources.webapps.master.master.jsp</file>
      <file type="M">core.src.main.resources.webapps.master.index.html</file>
      <file type="M">core.src.main.resources.org.apache.hadoop.hbase.thrift.Hbase.thrift</file>
      <file type="M">core.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.VersionMessage.proto</file>
      <file type="M">core.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.TableSchemaMessage.proto</file>
      <file type="M">core.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.TableListMessage.proto</file>
      <file type="M">core.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.TableInfoMessage.proto</file>
      <file type="M">core.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.StorageClusterStatusMessage.proto</file>
      <file type="M">core.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.ScannerMessage.proto</file>
      <file type="M">core.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.ColumnSchemaMessage.proto</file>
      <file type="M">core.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.CellSetMessage.proto</file>
      <file type="M">core.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.CellMessage.proto</file>
      <file type="M">core.src.main.resources.org.apache.hadoop.hbase.mapred.RowCounter.Counters.properties</file>
      <file type="M">core.src.main.resources.org.apache.hadoop.hbase.mapreduce.RowCounter.Counters.properties</file>
      <file type="M">core.src.main.resources.hbase-default.xml</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKServerTool.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.zookeeper.HQuorumPeer.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.WritableComparator.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.VersionAnnotation.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.ValueOverMaxLengthException.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.Writables.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.VersionInfo.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.Threads.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.Strings.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.SoftValueSortedMap.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.SoftValueMap.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.SoftValue.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.Sleeper.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.Pair.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.MurmurHash.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.MetaUtils.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.Merge.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.Keying.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.JvmVersion.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.JVMClusterUtil.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.JenkinsHash.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.InfoServer.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.Hash.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.FileSystemVersionException.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.DynamicByteBloomFilter.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.CompressionTest.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.ClassSize.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.Bytes.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.ByteBloomFilter.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.BloomFilter.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.util.Base64.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.UnknownScannerException.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.UnknownRowLockException.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.thrift.ThriftUtilities.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.thrift.generated.TRowResult.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.thrift.generated.TRegionInfo.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.thrift.generated.TCell.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.thrift.generated.Mutation.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.thrift.generated.IOError.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.thrift.generated.IllegalArgument.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.thrift.generated.Hbase.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.thrift.generated.ColumnDescriptor.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.thrift.generated.BatchMutation.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.thrift.generated.AlreadyExists.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.TableNotFoundException.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.TableNotDisabledException.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.TableExistsException.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.VersionResource.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.TableResource.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.StorageClusterVersionResource.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.StorageClusterStatusResource.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.SchemaResource.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.ScannerResultGenerator.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.ScannerResource.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.ScannerInstanceResource.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.RowSpec.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.RowResultGenerator.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.RowResource.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.RootResource.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.ResultGenerator.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.RESTServlet.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.ResourceConfig.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.ResourceBase.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.RegionsResource.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.provider.producer.ProtobufMessageBodyProducer.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.provider.producer.PlainTextMessageBodyProducer.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.provider.JAXBContextResolver.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.provider.consumer.ProtobufMessageBodyConsumer.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.VersionMessage.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.TableSchemaMessage.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.TableListMessage.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.TableInfoMessage.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.ScannerMessage.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.ColumnSchemaMessage.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.CellSetMessage.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.CellMessage.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.ProtobufMessageHandler.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.model.VersionModel.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.model.TableSchemaModel.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.model.TableRegionModel.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.model.TableModel.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.model.TableListModel.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.model.TableInfoModel.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.model.StorageClusterVersionModel.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.model.StorageClusterStatusModel.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.model.ScannerModel.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.model.RowModel.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.model.ColumnSchemaModel.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.model.CellSetModel.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.model.CellModel.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.metrics.RESTStatistics.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.metrics.RESTMetrics.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.Main.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.ExistsResource.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.Constants.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.client.Response.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteAdmin.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.client.Cluster.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.rest.client.Client.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.RemoteExceptionHandler.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.WrongRegionException.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALEdit.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.wal.LogRollListener.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.wal.LogActionsListener.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogKey.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FailedLogCloseException.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFlusher.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileGetScan.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.ScanWildcardColumnTracker.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.ScanQueryMatcher.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.ScanDeleteTracker.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerRunningException.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.ReadWriteConsistencyControl.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.QueryMatcher.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.MinorCompactingStoreScanner.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.metrics.RegionServerStatistics.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.metrics.RegionServerMetrics.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.MemStore.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.LruHashMap.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.LogRoller.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.KeyValueSkipListSet.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.KeyValueScanner.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.KeyValueHeap.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.InternalScanner.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.GetDeleteTracker.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.GetClosestRowBeforeTracker.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.FlushRequester.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.ExplicitColumnTracker.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.DeleteTracker.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.DeleteCompare.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.DebugPrint.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.ColumnTracker.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.ColumnCount.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.ChangedReadersObserver.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.RegionException.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.NotServingRegionException.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.MiniZooKeeperCluster.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.metrics.MetricsRate.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.metrics.MetricsMBeanBase.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.metrics.file.TimeStampingFileContext.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.ZKMasterAddressWatcher.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.TimeToLiveLogCleaner.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.TableOperation.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.TableDelete.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.RootScanner.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.RetryableMetaOperation.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.RegionServerOperationQueue.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.RegionServerOperationListener.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.RegionServerOperation.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.RegionManager.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.ProcessServerShutdown.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.ProcessRegionStatusChange.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.ProcessRegionOpen.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.ProcessRegionClose.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.OldLogsCleaner.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.NotAllMetaRegionsOnlineException.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.ModifyTableMeta.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.ModifyColumn.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.metrics.MasterStatistics.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.metrics.MasterMetrics.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.MetaScanner.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.MetaRegion.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.LogCleanerDelegate.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.InvalidColumnNameException.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.DeleteColumn.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.ColumnOperation.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.ChangeTableState.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.BaseScanner.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.AddColumn.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.MasterNotRunningException.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapred.TableSplit.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapred.TableReduce.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapred.TableRecordReaderImpl.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapred.TableRecordReader.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapred.TableOutputFormat.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapred.TableMapReduceUtil.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapred.TableMap.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapred.TableInputFormatBase.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapred.TableInputFormat.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapred.RowCounter.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapred.package-info.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapred.IdentityTableReduce.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapred.IdentityTableMap.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapred.HRegionPartitioner.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapred.GroupingTableMap.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapred.Driver.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.TableSplit.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.TableReducer.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.TableRecordReader.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.TableOutputFormat.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.TableOutputCommitter.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapper.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormat.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.SimpleTotalOrderPartitioner.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.RowCounter.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.package-info.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.MultiTableOutputFormat.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.KeyValueSortReducer.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.Import.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.IdentityTableReducer.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.IdentityTableMapper.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.HRegionPartitioner.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.HFileOutputFormat.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.GroupingTableMapper.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.Export.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.Driver.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.CopyTable.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.LocalHBaseCluster.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.Leases.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.LeaseListener.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.LeaseException.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.ipc.HRegionInterface.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.ipc.HMasterRegionInterface.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.ipc.HMasterInterface.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.ipc.HBaseServer.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.ipc.HBaseRPCStatistics.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.ipc.HBaseRPCProtocolVersion.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.ipc.HBaseRpcMetrics.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.ipc.HBaseRPCErrorHandler.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.ipc.HBaseRPC.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.ipc.HBaseClient.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.io.TimeRange.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.io.Reference.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.io.ImmutableBytesWritable.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.io.hfile.SimpleBlockCache.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileScanner.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.io.hfile.HFile.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.io.hfile.Compression.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.io.hfile.CachedBlockQueue.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.io.hfile.CachedBlock.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.io.hfile.BoundedRangeFileInputStream.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.io.hfile.BlockCache.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.io.HeapSize.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.io.HbaseObjectWritable.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.io.HbaseMapWritable.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.io.HalfStoreFileReader.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.io.CodeToClassAndBack.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.HServerLoad.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.HServerInfo.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.HServerAddress.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.HRegionLocation.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.HMsg.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.HMerge.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.HBaseConfTool.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.HBaseConfiguration.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.filter.WritableByteArrayComparable.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.filter.WhileMatchFilter.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.filter.ValueFilter.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.filter.SubstringComparator.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.filter.SkipFilter.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.filter.SingleColumnValueFilter.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.filter.SingleColumnValueExcludeFilter.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.filter.RowFilter.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.filter.RegexStringComparator.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.filter.QualifierFilter.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.filter.PrefixFilter.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.filter.PageFilter.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.filter.package-info.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.filter.InvalidRowFilterException.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.filter.IncompatibleFilterException.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.filter.InclusiveStopFilter.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.filter.FirstKeyOnlyFilter.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.filter.FilterList.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.filter.FilterBase.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">core.src.main.javadoc.org.apache.hadoop.hbase.io.hfile.package.html</file>
      <file type="M">core.src.main.javadoc.org.apache.hadoop.hbase.ipc.package.html</file>
      <file type="M">core.src.main.javadoc.org.apache.hadoop.hbase.thrift.doc-files.Hbase.html</file>
      <file type="M">core.src.main.javadoc.org.apache.hadoop.hbase.thrift.doc-files.index.html</file>
      <file type="M">core.src.main.javadoc.org.apache.hadoop.hbase.thrift.doc-files.style.css</file>
      <file type="M">core.src.main.javadoc.org.apache.hadoop.hbase.thrift.package.html</file>
      <file type="M">core.src.main.javadoc.overview.html</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.Chore.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.Delete.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.Get.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.HConnection.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.HTableFactory.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.HTableInterface.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.HTableInterfaceFactory.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.HTablePool.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.MetaScanner.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.MultiPut.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.MultiPutResponse.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.NoServerForRegionException.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.package-info.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.Put.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.RegionOfflineException.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.Result.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.ResultScanner.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.RetriesExhaustedException.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.Row.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.RowLock.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.ScannerTimeoutException.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.ServerCallable.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.ServerConnection.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.ServerConnectionManager.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.UnmodifyableHColumnDescriptor.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.UnmodifyableHRegionInfo.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.client.UnmodifyableHTableDescriptor.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.ClusterStatus.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.ColumnNameParseException.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.DoNotRetryIOException.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.DroppedSnapshotException.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.filter.BinaryComparator.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.filter.BinaryPrefixComparator.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.filter.ColumnCountGetFilter.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.filter.ColumnPaginationFilter.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.filter.CompareFilter.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.filter.DependentColumnFilter.java</file>
    </fixedFiles>
  </bug>
  <bug id="2578" opendate="2010-5-20 00:00:00" fixdate="2010-6-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add ability for tests to override server-side timestamp setting (currentTimeMillis)</summary>
      <description>Many of our tests use client APIs which do not set explicit stamps. This creates weird timing issues with tests running on different systems because sometimes a set of operations happens in the same millisecond and other times they do not.We should have a way for a test to specify it's own way of generating the timestamps (for example, could always increment by 1 ensuring forward progression in time).</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">pom.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="3727" opendate="2011-4-2 00:00:00" fixdate="2011-7-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>MultiHFileOutputFormat</summary>
      <description>Like MultiTableOutputFormat, but outputting HFiles. Key is tablename as an IBW. Creates sub-writers (code cut and pasted from HFileOutputFormat) on demand that produce HFiles in per-table subdirectories of the configured output path. Does not currently support partitioning for existing tables / incremental update.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.java</file>
    </fixedFiles>
  </bug>
  <bug id="4114" opendate="2011-7-18 00:00:00" fixdate="2011-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Metrics for HFile HDFS block locality</summary>
      <description>Normally, when we put hbase and HDFS in the same cluster ( e.g., region server runs on the datenode ), we have a reasonably good data locality, as explained by Lars. Also Work has been done by Jonathan to address the startup situation.There are scenarios where regions can be on a different machine from the machines that hold the underlying HFile blocks, at least for some period of time. This will have performance impact on whole table scan operation and map reduce job during that time.1. After load balancer moves the region and before compaction (thus generate HFile on the new region server ) on that region, HDFS block can be remote.2. When a new machine is added, or removed, Hbase's region assignment policy is different from HDFS's block reassignment policy.3. Even if there is no much hbase activity, HDFS can load balance HFile blocks as other non-hbase applications push other data to HDFS.Lots has been or will be done in load balancer, as summarized by Ted. I am curious if HFile HDFS block locality should be used as another factor here.I have done some experiments on how HDFS block locality can impact map reduce latency. First we need to define a metrics to measure HFile data locality.Metrics defintion:For a given table, or a region server, or a region, we can define the following. The higher the value, the more local HFile is from region server's point of view.HFile locality index = ( Total number of HDFS blocks that can be retrieved locally by the region server ) / ( Total number of HDFS blocks for all HFiles )Test Results:This is to show how HFile locality can impact the latency. It is based on a table with 1M rows, 36KB per row; regions are distributed in balance. The map job is RowCounter.HFile Locality Index Map job latency ( in sec )28% 15736% 15047% 14261% 13373% 12289% 10399% 95So the first suggestion is to expose HFile locality index as a new region server metrics. It will be ideal if we can somehow measure HFile locality index on a per map job level.Regarding if/when we should include that as another factor for load balancer, that will be a different work item. It is unclear how load balancer can take various factors into account to come up with the best load balancer strategy.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.util.TestFSUtils.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.metrics.RegionServerMetrics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.LoadBalancer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4362" opendate="2011-9-9 00:00:00" fixdate="2011-9-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>SITE: Center logo</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.site.vm</file>
      <file type="M">src.site.resources.css.site.css</file>
    </fixedFiles>
  </bug>
  <bug id="4625" opendate="2011-10-19 00:00:00" fixdate="2011-11-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Convert @deprecated HBaseTestCase tests JUnit4 style tests</summary>
      <description>This will class has 47 references so separating out into a separate subtask.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestMergeTool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestWideScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreFileInfo.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestScanWildcardColumnTracker.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestScanDeleteTracker.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestQueryMatcher.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestKeyValueHeap.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestGetClosestAtOrBefore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestBlocksScanned.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestBlocksRead.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestSeekTo.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFile.java</file>
    </fixedFiles>
  </bug>
  <bug id="4626" opendate="2011-10-19 00:00:00" fixdate="2011-10-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Filters unnecessarily copy byte arrays...</summary>
      <description>Just looked at SingleCol and ValueFilter... And on every column compared they create a copy of the column and/or value portion of the KV.</description>
      <version>None</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.WritableByteArrayComparable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.SubstringComparator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.SingleColumnValueFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.RegexStringComparator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.NullComparator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.CompareFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.BitComparator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.BinaryPrefixComparator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.BinaryComparator.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6206" opendate="2012-6-14 00:00:00" fixdate="2012-6-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Large tests fail with jdk1.7</summary>
      <description>Failed tests: testSimplePutDelete(org.apache.hadoop.hbase.replication.TestMasterReplication): Waited too much time for put replication testCyclicReplication(org.apache.hadoop.hbase.replication.TestMasterReplication): Waited too much time for put replication testMultiSlaveReplication(org.apache.hadoop.hbase.replication.TestMultiSlaveReplication): Waited too much time for put replication testDeleteTypes(org.apache.hadoop.hbase.replication.TestReplication): Waited too much time for put replication testSimplePutDelete(org.apache.hadoop.hbase.replication.TestReplication): Waited too much time for put replication testSmallBatch(org.apache.hadoop.hbase.replication.TestReplication): Waited too much time for normal batch replication testStartStop(org.apache.hadoop.hbase.replication.TestReplication): Waited too much time for put replication testDisableEnable(org.apache.hadoop.hbase.replication.TestReplication): Waited too much time for put replication testDisableInactivePeer(org.apache.hadoop.hbase.replication.TestReplication): Waited too much time for put replication testAddAndRemoveClusters(org.apache.hadoop.hbase.replication.TestReplication): Waited too much time for put replication loadTesting(org.apache.hadoop.hbase.replication.TestReplication): Waited too much time for normal batch replication, 0 instead of 1000 testVerifyRepJob(org.apache.hadoop.hbase.replication.TestReplication): Waited too much time for normal batch replication testRSSplitEphemeralsDisappearButDaughtersAreOnlinedAfterShutdownHandling(org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster)Tests in error: testNull(org.apache.hadoop.hbase.client.TestFromClientSide) testPut(org.apache.hadoop.hbase.client.TestFromClientSide) testSplit(org.apache.hadoop.hbase.regionserver.wal.TestHLog): 3 exceptions [org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException: No lease on /user/jxiang/hbase/TestHLog/08fec3b92db148f74a1599c3db6fb1ee/recovered.edits/0000000000000000004.temp File is not open for writing. Holder DFSClient_388157531 does not have any open files.(..)Tests run: 333, Failures: 4, Errors: 3, Skipped: 7</description>
      <version>None</version>
      <fixedVersion>0.94.4,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Get.java</file>
    </fixedFiles>
  </bug>
  <bug id="6207" opendate="2012-6-14 00:00:00" fixdate="2012-6-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add jitter to client retry timer</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="6454" opendate="2012-7-25 00:00:00" fixdate="2012-8-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Write PB definitions for filters</summary>
      <description>See HBASE-5447.Conversion to protobuf requires writing protobuf definitions.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.protobuf.hbase.proto</file>
      <file type="M">hbase-server.src.main.protobuf.Client.proto</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ClientProtos.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="7332" opendate="2012-12-11 00:00:00" fixdate="2012-2-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[webui] HMaster webui should display the number of regions a table has.</summary>
      <description>Pre-0.96/trunk hbase displayed the number of regions per table in the table listing. Would be good to have this back.</description>
      <version>1.1.0,2.0.0</version>
      <fixedVersion>1.1.0,0.98.11,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="7612" opendate="2013-1-17 00:00:00" fixdate="2013-9-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[JDK8] Replace use of high-scale-lib counters with intrinsic facilities</summary>
      <description>JEP155 introduces a few new classes (DoubleAccumulator, DoubleAdder, LongAccumulator, LongAdder) that "internally employ contention-reduction techniques that provide huge throughput improvements as compared to Atomic variables". There are applications of these where we are currently using Cliff Click's high-scale-lib and for metrics.See http://openjdk.java.net/jeps/155</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestBlocksRead.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestForceCacheImportantBlocks.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestFilterListOrOperatorWithBlkCnt.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheStats.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketCacheStats.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.MutableHistogram.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.MutableFastCounter.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.MetricsExecutorImpl.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.FastLongHistogram.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Counter.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.trace.SpanReceiverHost.java</file>
    </fixedFiles>
  </bug>
  <bug id="7767" opendate="2013-2-5 00:00:00" fixdate="2013-9-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Get rid of ZKTable, and table enable/disable state in ZK</summary>
      <description>As discussed table state in zookeeper for enable/disable state breaks our zookeeper contract. It is also very intrusive, used from the client side, master and region servers. We should get rid of it.</description>
      <version>2.0.0</version>
      <fixedVersion>2.0.0,1.7.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKTableStateManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKTableStateManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestMergeTool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestFSTableDescriptors.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestHColumnDescriptorDefaultVersions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.SnapshotTestingUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestTableLockManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterRestartAfterDisablingTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.handler.TestTableDescriptorModification.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionAdapter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Registry.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ZooKeeperRegistry.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKTableStateClientSideReader.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestClientNoCluster.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MasterProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.HBase.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Master.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.ZooKeeper.proto</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.CoprocessorHConnection.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.CoordinatedStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.BaseCoordinatedStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.CreateTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DeleteTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DisableTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.EnableTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ModifyTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableAddFamilyHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableDeleteFamilyHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableEventHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableModifyFamilyHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TruncateTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableNamespaceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.migration.NamespaceUpgrade.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactionTool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALCellCodec.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotManifest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.TableDescriptors.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.TableStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSTableDescriptors.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HMerge.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.Merge.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ZKDataMigrator.java</file>
    </fixedFiles>
  </bug>
  <bug id="7972" opendate="2013-3-1 00:00:00" fixdate="2013-9-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a configuration for the TCP backlog in the Thrift server</summary>
      <description>Once THRIFT-1868 goes in, we can start letting our users configure the TCP backlog.</description>
      <version>1.3.0,2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="9465" opendate="2013-9-9 00:00:00" fixdate="2013-4-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Push entries to peer clusters serially</summary>
      <description>When region-move or RS failure occurs in master cluster, the hlog entries that are not pushed before region-move or RS-failure will be pushed by original RS(for region move) or another RS which takes over the remained hlog of dead RS(for RS failure), and the new entries for the same region(s) will be pushed by the RS which now serves the region(s), but they push the hlog entries of a same region concurrently without coordination.This treatment can possibly lead to data inconsistency between master and peer clusters:1. there are put and then delete written to master cluster2. due to region-move / RS-failure, they are pushed by different replication-source threads to peer cluster3. if delete is pushed to peer cluster before put, and flush and major-compact occurs in peer cluster before put is pushed to peer cluster, the delete is collected and the put remains in peer clusterIn this scenario, the put remains in peer cluster, but in master cluster the put is masked by the delete, hence data inconsistency between master and peer clusters</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestMetaTableAccessor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WAL.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSTableDescriptors.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.Replication.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSWALEntry.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStateStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.WAL.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.WALProtos.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MetaTableAccessor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.replication.ReplicationAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
    </fixedFiles>
  </bug>
  <bug id="9467" opendate="2013-9-9 00:00:00" fixdate="2013-9-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>write can be totally blocked temporarily by a write-heavy region</summary>
      <description>Write to a region can be blocked temporarily if the memstore of that region reaches the threshold(hbase.hregion.memstore.block.multiplier * hbase.hregion.flush.size) until the memstore of that region is flushed.For a write-heavy region, if its write requests saturates all the handler threads of that RS when write blocking for that region occurs, requests of other regions/tables to that RS also can't be served due to no available handler threads...until the pending writes of that write-heavy region are served after the flush is done. Hence during this time period, from the RS perspective it can't serve any request from any table/region just due to a single write-heavy region.This sounds not very reasonable, right? Maybe write requests from a region can only be served by a sub-set of the handler threads, and then write blocking of any single region can't lead to the scenario mentioned above?Comment?</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="9468" opendate="2013-9-9 00:00:00" fixdate="2013-9-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Previous active master can still serves RPC request when it is trying recovering expired zk session</summary>
      <description>When the active master's zk session expires, it'll try to recover zk session, but without turn off its RpcServer. What if a previous backup master has already become the now active master, and some client tries to send request to this expired master by using the cached master info? Any problem here?</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.94.12,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.configuration.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="947" opendate="2008-10-21 00:00:00" fixdate="2008-11-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[Optimization] Major compaction should remove deletes as well as the deleted cell</summary>
      <description>Currently major compactions retains both deletes and the deleted cell. It should remove both.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>
