<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="10132" opendate="2013-12-11 00:00:00" fixdate="2013-12-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>sun.security.pkcs11.wrapper.PKCS11Exception: CKR_ARGUMENTS_BAD</summary>
      <description>Looks like RedHat broke OpenJDK 7 crypto: https://bugzilla.redhat.com/show_bug.cgi?id=1031145 I came across this today when setting up a Jenkins slave for OpenJDK 7. Looks like 1.7.0u25 is affected but 1.7.0u45 is not - a more recent RH package build I suspect. The issue manifests as exceptions caused ultimately by:Caused by: sun.security.pkcs11.wrapper.PKCS11Exception: CKR_ARGUMENTS_BAD at sun.security.pkcs11.wrapper.PKCS11.C_DecryptUpdate(Native Method) at sun.security.pkcs11.P11Cipher.implDoFinal(P11Cipher.java:795)The RH bug report for this problem includes a workaround that fixed the problem for me. Informational issue only, will attach a patch for the manual shortly.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.troubleshooting.xml</file>
    </fixedFiles>
  </bug>
  <bug id="10226" opendate="2013-12-23 00:00:00" fixdate="2013-12-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[AccessController] Namespace grants not always checked</summary>
      <description>Namespace grants for a user are supposed to supercede table level permissions, a middle tier between table grants and global grants. We are not always checking.</description>
      <version>0.98.0,0.96.2,0.99.0</version>
      <fixedVersion>0.98.0,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestZKPermissionsWatcher.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.TableAuthManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="10729" opendate="2014-3-12 00:00:00" fixdate="2014-3-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable table doesn&amp;#39;t balance out replicas evenly if the replicas were unassigned earlier</summary>
      <description>Enable table doesn't assign out replicas keeping availability in mind, if the replicas were unassigned before the table was disabled. For example, when a snapshot is restored and then the table is enabled, the replicas are unevenly assigned. The reason for this is that the the enable table invokes randomAssign that assigns one region at a time. Since the master doesn't have any information about the unassigned replicas, the calls to randomAssign can't do any availability checks.</description>
      <version>None</version>
      <fixedVersion>0.99.0,hbase-10070</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.EnableTableHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="10922" opendate="2014-4-7 00:00:00" fixdate="2014-6-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Log splitting status should always be closed</summary>
      <description>With distributed log replay enabled by default, I ran into an issue that log splitting hasn't completed after 13 hours. It seems to hang somewhere.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
    </fixedFiles>
  </bug>
  <bug id="10923" opendate="2014-4-7 00:00:00" fixdate="2014-6-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Control where to put meta region</summary>
      <description>There is a concern on placing meta regions on the master, as in the comments of HBASE-10569. I was thinking we should have a configuration for a load balancer to decide where to put it. Adjusting this configuration we can control whether to put the meta on master, or other region server.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestBaseLoadBalancer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.BalancerTestBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
    </fixedFiles>
  </bug>
  <bug id="10948" opendate="2014-4-9 00:00:00" fixdate="2014-4-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix hbase table file &amp;#39;x&amp;#39; mode</summary>
      <description>The hbase table files currently all have 'x' mode in there:$hadoop fs -ls -R /hbase/data/default/TestTable/drwxr-xr-x - hbase biadmin 0 2014-04-08 20:53 /hbase/data/default/TestTable/.tabledesc-rw-r--r-- 1 hbase biadmin 313 2014-04-08 20:53 /hbase/data/default/TestTable/.tabledesc/.tableinfo.0000000001drwxr-xr-x - hbase biadmin 0 2014-04-08 20:53 /hbase/data/default/TestTable/724c8c3075da516b450ce4826327ce64-rwxr-xr-x 1 hbase biadmin 68 2014-04-08 20:53 /hbase/data/default/TestTable/724c8c3075da516b450ce4826327ce64/.regioninfodrwxr-xr-x - hbase biadmin 0 2014-04-08 21:54 /hbase/data/default/TestTable/724c8c3075da516b450ce4826327ce64/info-rwxr-xr-x 1 hbase biadmin 272958577 2014-04-08 20:53 /hbase/data/default/TestTable/724c8c3075da516b450ce4826327ce64/info/7138e61cbcd24538b64726db13dab48e-rwxr-xr-x 1 hbase biadmin 108603714 2014-04-08 20:53 /hbase/data/default/TestTable/724c8c3075da516b450ce4826327ce64/info/9ce233fcdfde49679797d13f28e26129drwxr-xr-x - hbase biadmin 0 2014-04-08 20:53 /hbase/data/default/TestTable/b5350c581363f786e49ff6f32e71f564-rwxr-xr-x 1 hbase biadmin 68 2014-04-08 20:53 /hbase/data/default/TestTable/b5350c581363f786e49ff6f32e71f564/.regioninfodrwxr-xr-x - hbase biadmin 0 2014-04-08 21:54 /hbase/data/default/TestTable/b5350c581363f786e49ff6f32e71f564/info-rwxr-xr-x 1 hbase biadmin 33800049 2014-04-08 21:54 /hbase/data/default/TestTable/b5350c581363f786e49ff6f32e71f564/info/576190de431341b9a02280654e3deb58-rwxr-xr-x 1 hbase biadmin 108650474 2014-04-08 20:53 /hbase/data/default/TestTable/b5350c581363f786e49ff6f32e71f564/info/7c54098fb62a4ef29aab0f5658b25260If the user does not specify 'hbase.data.umask', we use the fs default:FsPermission.getDefault()Instead we should use FsPermission.getFileDefault().</description>
      <version>0.96.2,0.98.1</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestFSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="10958" opendate="2014-4-10 00:00:00" fixdate="2014-4-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[dataloss] Bulk loading with seqids can prevent some log entries from being replayed</summary>
      <description>We found an issue with bulk loads causing data loss when assigning sequence ids (HBASE-6630) that is triggered when replaying recovered edits. We're nicknaming this issue Blindspot.The problem is that the sequence id given to a bulk loaded file is higher than those of the edits in the region's memstore. When replaying recovered edits, the rule to skip some of them is that they have to be lower than the highest sequence id. In other words, the edits that have a sequence id lower than the highest one in the store files should have also been flushed. This is not the case with bulk loaded files since we now have an HFile with a sequence id higher than unflushed edits.The log recovery code takes this into account by simply skipping the bulk loaded files, but this "bulk loaded status" is lost on compaction. The edits in the logs that have a sequence id lower than the bulk loaded file that got compacted are put in a blind spot and are skipped during replay.Here's the easiest way to recreate this issue: Create an empty table Put one row in it (let's say it gets seqid 1) Bulk load one file (it gets seqid 2). I used ImporTsv and set hbase.mapreduce.bulkload.assign.sequenceNumbers. Bulk load a second file the same way (it gets seqid 3). Major compact the table (the new file has seqid 3 and isn't considered bulk loaded). Kill the region server that holds the table's region. Scan the table once the region is made available again. The first row, at seqid 1, will be missing since the HFile with seqid 3 makes us believe that everything that came before it was flushed.</description>
      <version>0.96.2,0.98.1,0.94.18</version>
      <fixedVersion>0.99.0,0.98.2,0.96.3,0.94.20</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="11038" opendate="2014-4-19 00:00:00" fixdate="2014-4-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Filtered scans can bypass metrics collection</summary>
      <description>In RegionScannerImpl#nextRaw, after a batch of results are retrieved, delegates to the filter regarding continuation of the scan. If filterAllRemaining returns true, the method exits immediately, without calling MetricsRegion#updateNextScan.</description>
      <version>0.96.2,0.98.1,0.99.0</version>
      <fixedVersion>0.99.0,0.98.2,0.96.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="1105" opendate="2009-1-1 00:00:00" fixdate="2009-1-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove duplicated code in HCM, add javadoc to RegionState, etc.</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.master.RegionManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.HBase.rb</file>
    </fixedFiles>
  </bug>
  <bug id="11096" opendate="2014-4-29 00:00:00" fixdate="2014-5-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>stop method of Master and RegionServer coprocessor is not invoked</summary>
      <description>the stop method of coprocessor specified by "hbase.coprocessor.master.classes" and "hbase.coprocessor.regionserver.classes" is not invoked.If coprocessor allocates OS resources, it could cause master/regionserver resource leak or hang during exit.</description>
      <version>0.96.2,0.98.1,0.94.19</version>
      <fixedVersion>0.99.0,0.98.3,0.94.21</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorHost.java</file>
    </fixedFiles>
  </bug>
  <bug id="11136" opendate="2014-5-8 00:00:00" fixdate="2014-9-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add permission check to roll WAL writer</summary>
      <description>Currently HBase provides HBaseAdmin.rollHLogWriter() and shell command to roll WAL on a region server. But no permission check is done on this operation in a secure cluster.We need to add permission check to prevent un-authorized user from running this operation.</description>
      <version>0.96.2,0.98.2</version>
      <fixedVersion>0.99.0,0.98.7</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionServerObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseRegionServerObserver.java</file>
    </fixedFiles>
  </bug>
  <bug id="11171" opendate="2014-5-14 00:00:00" fixdate="2014-5-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>More doc improvements on block cache options</summary>
      <description>I have more doc improvement (no code changes for sure this time). Follow on from HBASE-11098.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.book.xml</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.DirectMemoryUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.slab.SlabCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.DoubleBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteBufferArray.java</file>
      <file type="M">conf.hbase-env.sh</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.package-info.java</file>
    </fixedFiles>
  </bug>
  <bug id="11280" opendate="2014-6-2 00:00:00" fixdate="2014-6-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document distributed log replay and distributed log splitting</summary>
      <description>Enable 'distributed log replay' by default. Depends on hfilev3 being enabled.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11487" opendate="2014-7-9 00:00:00" fixdate="2014-7-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ScanResponse carries non-zero cellblock for CloseScanRequest (ScanRequest with close_scanner = true)</summary>
      <description>After upgrading hbase from 0.94 to 0.96, we've found that our asynchbase client keep throwing errors during normal scan. It turns out these errors are due to Scanner.close call in asynchbase. Since asynchbase assumes the ScanResponse of CloseScannerRequest should never carry any cellblocks, it will throw an exception if there is a violation.In the asynchbase client (1.5.0), it constructs a CloseScannerRequest in the following way, ScanRequest.newBuilder() .setScannerId(scanner_id) .setCloseScanner(true) .build();Note, it does not set numOfRows, which kind of make sense. Why a close scanner request cares about number of rows to scan ?However, after narrowing down the CloseScannerRequest code path, it seems the issue is on regionserver side. In RsRpcServices.scan, we always init numOfRows to scan to 1 and we do this even for ScanRequest with close_scanner = true. This causes response for CloseScannerRequest will carry a cellBlock (if scan stops before the end row and this could happen in many normal scenarios)There are two fixes, either we always set numOfRows in asynchbase client side when constructing a CloseScannerRequest or we fix the default value in the server side.From a hbase client side point of view, it seems make less sense that server will send you a cellBlock for your close scanner request, unless the request explicitly asks for. We've made the change in our server code and the asynchbase client errors goes away. In addition to this issue, I want to know if we have any specifications for our hbase rpc. Like if close_scanner = true in ScanRequest and numOfRows is not set, ScanResponse guarantees that there is no cellBlock in the response. Since we moved to protobuf and many fields are optional for compatibility consideration, it might be helpful to have such specification which helps people to develop code that depends on hbase rpc.</description>
      <version>0.96.2,0.99.0,2.0.0</version>
      <fixedVersion>0.99.0,0.98.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="11629" opendate="2014-7-31 00:00:00" fixdate="2014-8-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Operational concerns for Replication should call out ZooKeeper</summary>
      <description>Our design invariants state that ZooKeeper data is safe to delete. However, replication only stores its data in zookeeper. This can lead to operators accidentally disabling their replication set up while attempting to recover from an unrelated issue by clearing the zk state.We should update the operational concerns section on replication to call out that the /hbase/replication tree should not be deleted. We should probably also add a warning to the set up steps.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
      <file type="M">src.main.docbkx.developer.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11726" opendate="2014-8-12 00:00:00" fixdate="2014-8-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Master should fail-safe if starting with a pre 0.96 layout</summary>
      <description>We recently saw this: If user inadvertently starts the HBase Master after deploying new HBase binaries (any version that supports namespaces), the HMaster will start the migration to PBs the the hbase.version file per HBASE-5453 and that will write a new version file PB-serialized but with the old version number. Further restarts of the master will fail because the hbase version file has been migrated to PBs and there will be version mismatch. The right approach should be to fail safe the master if we find an old hbase.version file in order to force user to run upgrade tool.</description>
      <version>0.96.2,0.99.0,0.98.5,2.0.0</version>
      <fixedVersion>0.99.0,0.98.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="11727" opendate="2014-8-12 00:00:00" fixdate="2014-8-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Assignment wait time error in case of ServerNotRunningYetException</summary>
      <description>maxWaitTime = this.server.getConfiguration(). getLong("hbase.regionserver.rpc.startup.waittime", 60000);It should add the current time.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="11892" opendate="2014-9-4 00:00:00" fixdate="2014-9-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>configs contain stale entries</summary>
      <description>Configuration details that need to be cleaned up the documentation around configuring cleaner plugins have stale class names for customizing behavior. hbase.master.logcleaner.plugins has LogCleanerDelegate and I think the correct class is BaseLogCleanerDelegate. hbase.master.hfilecleaner.plugin has HFileCleanerDelegate instead of BaseHFileCleanerDelegate. hbase.rpc.server.engine doesn't appear anywhere other than hdfs-default.xml and the classes it references were removed by HBASE-8214</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="12516" opendate="2014-11-18 00:00:00" fixdate="2014-11-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up master so QA Bot is in known good state</summary>
      <description>QA Bot is flagging new patches for errors they didn't introduce. clean it up.</description>
      <version>None</version>
      <fixedVersion>0.99.2</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableOutputFormat.java</file>
    </fixedFiles>
  </bug>
  <bug id="13466" opendate="2015-4-14 00:00:00" fixdate="2015-4-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document deprecations in 1.x - Part 1</summary>
      <description>This documents deprecations for the following issues: HBASE-6038 HBASE-1502 HBASE-5453 HBASE-5357 HBASE-9870 HBASE-10870 HBASE-12363 HBASE-9508</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableSplit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ClusterStatus.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTableInterface.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
    </fixedFiles>
  </bug>
</bugrepository>
