<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="1009" opendate="2008-11-19 00:00:00" fixdate="2008-11-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Master stuck in loop wanting to assign but regions are closing</summary>
      <description>From streamy logs.2008-11-19 10:36:58,933 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,�,1225411057556 because it is already closing.2008-11-19 10:37:01,315 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 138, Num Servers: 9, Avg Load: 16.02008-11-19 10:37:01,935 DEBUG org.apache.hadoop.hbase.master.RegionManager: Server XX.XX.XX.212:60020 is overloaded. Server load: 21 avg: 16.0, slop: 0.12008-11-19 10:37:01,935 DEBUG org.apache.hadoop.hbase.master.RegionManager: Choosing to reassign 5 regions. mostLoadedRegions has 10 regions in it.2008-11-19 10:37:01,935 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streams,'6,1226967394935 because it is already closing.2008-11-19 10:37:01,935 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,'�,1226078595896 because it is already closing.2008-11-19 10:37:01,935 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,���,1225472287315 because it is already closing.2008-11-19 10:37:01,935 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,X$�,1225411877996 because it is already closing.2008-11-19 10:37:01,935 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,�},1225411050812 because it is already closing.2008-11-19 10:37:01,935 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region api,,1222913694225 because it is already closing.2008-11-19 10:37:01,935 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,0��,1226459423496 because it is already closing.2008-11-19 10:37:01,935 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region items,R�,1223906859795 because it is already closing.2008-11-19 10:37:01,935 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region authentication,,1222913700431 because it is already closing.2008-11-19 10:37:01,935 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,�,1225411057556 because it is already closing.2008-11-19 10:37:04,939 DEBUG org.apache.hadoop.hbase.master.RegionManager: Server XX.XX.XX.212:60020 is overloaded. Server load: 21 avg: 16.0, slop: 0.12008-11-19 10:37:04,939 DEBUG org.apache.hadoop.hbase.master.RegionManager: Choosing to reassign 5 regions. mostLoadedRegions has 10 regions in it.2008-11-19 10:37:04,939 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streams,'6,1226967394935 because it is already closing.2008-11-19 10:37:04,939 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,'�,1226078595896 because it is already closing.2008-11-19 10:37:04,939 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,���,1225472287315 because it is already closing.2008-11-19 10:37:04,939 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,X$�,1225411877996 because it is already closing.2008-11-19 10:37:04,939 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,�},1225411050812 because it is already closing.2008-11-19 10:37:04,939 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region api,,1222913694225 because it is already closing.2008-11-19 10:37:04,939 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,0��,1226459423496 because it is already closing.2008-11-19 10:37:04,939 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region items,R�,1223906859795 because it is already closing.2008-11-19 10:37:04,939 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region authentication,,1222913700431 because it is already closing.2008-11-19 10:37:04,939 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,�,1225411057556 because it is already closing.2008-11-19 10:37:07,941 DEBUG org.apache.hadoop.hbase.master.RegionManager: Server XX.XX.XX.212:60020 is overloaded. Server load: 21 avg: 16.0, slop: 0.12008-11-19 10:37:07,941 DEBUG org.apache.hadoop.hbase.master.RegionManager: Choosing to reassign 5 regions. mostLoadedRegions has 10 regions in it.2008-11-19 10:37:07,941 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streams,'6,1226967394935 because it is already closing.2008-11-19 10:37:07,941 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,'�,1226078595896 because it is already closing.2008-11-19 10:37:07,942 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,���,1225472287315 because it is already closing.2008-11-19 10:37:07,942 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,X$�,1225411877996 because it is already closing.2008-11-19 10:37:07,942 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,�},1225411050812 because it is already closing.2008-11-19 10:37:07,942 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region api,,1222913694225 because it is already closing.2008-11-19 10:37:07,942 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,0��,1226459423496 because it is already closing.2008-11-19 10:37:07,942 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region items,R�,1223906859795 because it is already closing.2008-11-19 10:37:07,942 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region authentication,,1222913700431 because it is already closing.2008-11-19 10:37:07,942 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,�,1225411057556 because it is already closing.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12279" opendate="2014-10-16 00:00:00" fixdate="2014-11-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Generated thrift files were generated with the wrong parameters</summary>
      <description>It turns out that the java code generated from the thrift files have been generated with the wrong settings.Instead of the documented (thrift, thrift2) thrift -strict --gen java:hashcode the current files seem to be generated instead withthrift -strict --gen java</description>
      <version>0.94.0,0.98.0,0.99.0</version>
      <fixedVersion>0.98.8,0.94.26,0.99.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TScan.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TRowResult.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TRegionInfo.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TIncrement.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TColumn.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TCell.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.TAppend.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.Mutation.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.IOError.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.IllegalArgument.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.Hbase.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.ColumnDescriptor.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.BatchMutation.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.generated.AlreadyExists.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TTimeRange.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TScan.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TRowMutations.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TResult.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TPut.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TMutation.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIOError.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIncrement.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIllegalArgument.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.THBaseService.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TGet.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TDelete.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumnValue.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumnIncrement.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumn.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TCellVisibility.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TAuthorization.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TAppend.java</file>
    </fixedFiles>
  </bug>
  <bug id="1323" opendate="2009-4-12 00:00:00" fixdate="2009-5-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase-1234 broke TestThriftServer; fix and reenable</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.thrift.DisabledTestThriftServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.ThriftUtilities.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="15415" opendate="2016-3-7 00:00:00" fixdate="2016-5-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve Master WebUI snapshot information</summary>
      <description>On the Master WebUI, we currently show lots of information about the space used by individual snapshots.We should also give a total space used.</description>
      <version>0.94.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotInfo.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="18049" opendate="2017-5-15 00:00:00" fixdate="2017-5-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>It is not necessary to re-open the region when MOB files cannot be found</summary>
      <description>In HBASE-17712, we try to re-open the region when store files cannot be found. This is useful for store files in a region, but is not necessary when the MOB files cannot be found, because the store files in a region only contain the references to the MOB files and a re-open of a region doesn't help the lost MOB files.In this JIRA, we will directly throw DNRIOE only when the MOB files are not found in MobStoreScanner and ReversedMobStoreScanner. Other logics keep the same.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HMobStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="2819" opendate="2010-7-7 00:00:00" fixdate="2010-11-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbck should have the ability to repair basic problems</summary>
      <description>Right now, the hbck utility can detect issues with region deployment but can't fix them.It should be able to handle basic things like closing one side of a double assignment, re-adding something to META, etc.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.MiniHBaseCluster.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HRegionInterface.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HBaseRPCProtocolVersion.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.MetaScanner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HBaseFsck.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.catalog.MetaReader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4240" opendate="2011-8-22 00:00:00" fixdate="2011-8-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow Loadbalancer to be pluggable.</summary>
      <description>Everyone seems to want something different from a load balancer. People want low latency, simplicity, and total control. It seems like at some point the load balancer can't be all things to all people. Something akin to what hadoop JT's pluggable scheduler seems like it will enable all solutions without making the code much more complex.</description>
      <version>0.94.0</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestLoadBalancer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.LoadBalancer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4322" opendate="2011-9-1 00:00:00" fixdate="2011-9-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbck] Update checkIntegrity/checkRegionChain to present more accurate region split problem summary</summary>
      <description>This is a mostly semantics preserving upgrade to hbck that uses the RegionSplitCalculator from HBASE-4321 that provides more in depth information about region split problems in meta when running hbck.</description>
      <version>0.90.4,0.94.0</version>
      <fixedVersion>0.90.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="4365" opendate="2011-9-9 00:00:00" fixdate="2011-2-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a decent heuristic for region size</summary>
      <description>A few of us were brainstorming this morning about what the default region size should be. There were a few general points made: in some ways it's better to be too-large than too-small, since you can always split a table further, but you can't merge regions currently with HFile v2 and multithreaded compactions there are fewer reasons to avoid very-large regions (10GB+) for small tables you may want a small region size just so you can distribute load better across a cluster for big tables, multi-GB is probably best</description>
      <version>0.92.1,0.94.0</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionSplitPolicy.java</file>
      <file type="M">src.main.resources.hbase-default.xml</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.RegionSplitPolicy.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.KeyPrefixRegionSplitPolicy.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="4375" opendate="2011-9-12 00:00:00" fixdate="2011-9-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbck] Add region coverage visualization to hbck</summary>
      <description>After HBASE-4322 and HBASE-4321, we now have an accurate region splits / coverage map for properly identifying holes, overlaps, backwards regions and other kinds of problems in the .META. table. hbck should display this information so that someone can fix this.A simple version for a table with regions &amp;#91;,A&amp;#93;, &amp;#91;A,B&amp;#93;, &amp;#91;A,C&amp;#93;, &amp;#91;C,&amp;#93; and would dump out something like this (showing an overlap in &amp;#91;A,B&amp;#93;): &amp;#91;&amp;#39;table,,..&amp;#39;, &amp;#39;table,A,..&amp;#39;&amp;#93;A: &amp;#91;&amp;#39;table,A,..&amp;#39;, &amp;#39;B&amp;#39;&amp;#93; &amp;#91;&amp;#39;table,A,..&amp;#39;, &amp;#39;C&amp;#39;&amp;#93;B: &amp;#91;&amp;#39;table,A,..&amp;#39;, &amp;#39;C&amp;#39;&amp;#93; C: &amp;#91;&amp;#39;table,C&amp;#39;, &amp;#39;&amp;#39;&amp;#93;null:My first thought is '-details' should this dump the full region map including all good and bad regions. Without -details, any errors should dump info with some context &amp;#8211; dump one region before problems, problem regions, and then one post problem region.Alternately we could add a new option or options to dump the region split map.What is the preferred way to toggle display of this information in hbck?</description>
      <version>0.90.5,0.94.0</version>
      <fixedVersion>0.90.5</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4379" opendate="2011-9-13 00:00:00" fixdate="2011-7-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbck] Does not complain about tables with no end region [Z,]</summary>
      <description>hbck does not detect or have an error condition when the last region of a table is missing (end key != '').</description>
      <version>0.90.5,0.92.0,0.94.0,0.95.2</version>
      <fixedVersion>0.92.2,0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.hbck.TableIntegrityErrorHandlerImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.hbck.TableIntegrityErrorHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="4451" opendate="2011-9-21 00:00:00" fixdate="2011-1-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve zk node naming (/hbase/shutdown)</summary>
      <description>Right now the node /hbase/shutdown is used to indicate cluster status (cluster up, cluster down).However, upon a chat with Lars George today, we feel that having a name /hbase/shutdown is possibly bad. The /hbase/shutdown zknode contains a date when the cluster was started. Now that is difficult to understand and digest, given that a person may connect to zk and try to look at what it is about (they may think it 'shutdown' at that date.).I feel a better name may simply be: /hbase/running. Thoughts?</description>
      <version>0.94.0</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.ZooKeeper.proto</file>
    </fixedFiles>
  </bug>
  <bug id="4454" opendate="2011-9-21 00:00:00" fixdate="2011-9-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add failsafe plugin to build and rename integration tests</summary>
      <description>Add the maven-failsafe-plugin to the build process so we can run integration tests with "mvn verify". This will also involve a renaming of integration tests to conform to a new integration test regex.This is a stopgap measure while we until break them out into their own module.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.developer.xml</file>
      <file type="M">pom.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4509" opendate="2011-9-29 00:00:00" fixdate="2011-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbck] Improve region map output</summary>
      <description>HBASE-4375 added a region coverage visualization to hbck in details mode. When users have binary row keys the output is difficult to parse (awk/sed) or pull into programs (numeric, excel) capable of handling tsv formatted data.This patch improves output by using Bytes.toStringBinary (which escapes binary) instead of Bytes.toString when printing keys, suggests some repair actions, and collects "problem group" that groups regions that are overlapping.</description>
      <version>0.90.5,0.92.0,0.94.0</version>
      <fixedVersion>0.90.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4510" opendate="2011-9-29 00:00:00" fixdate="2011-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Check and workaround usage of internal HDFS APIs in HBase</summary>
      <description>HBase isn't seemingly compiling anymore on 0.23 after the HDFS-1620 naming refactorings were carried out.Two solutions: We use new classnames. This breaks HBase's backward compatibility with older Hadoop releases (is that a concern with future releases?) HBase gets its own sets of constants as the upstream one is not marked for public usage. This needs a little more maintenance on HBases' side.</description>
      <version>0.94.0</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.FSHDFSUtils.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4583" opendate="2011-10-12 00:00:00" fixdate="2011-11-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Integrate RWCC with Append and Increment operations</summary>
      <description>Currently Increment and Append operations do not work with RWCC and hence a client could see the results of multiple such operation mixed in the same Get/Scan.The semantics might be a bit more interesting here as upsert adds and removes to and from the memstore.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestAtomicOperation.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="4588" opendate="2011-10-13 00:00:00" fixdate="2011-10-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The floating point arithmetic to validate memory allocation configurations need to be done as integers</summary>
      <description>The floating point arithmetic to validate memory allocation configurations need to be done as integers.On our cluster, we had block cache = 0.6 and memstore = 0.2. It was saying this was &gt; 0.8 when it is actually equal.Minor bug but annoying nonetheless.</description>
      <version>0.92.0,0.94.0</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HBaseConfiguration.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4605" opendate="2011-10-17 00:00:00" fixdate="2011-12-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Constraints</summary>
      <description>From Jesse's comment on dev:What I would like to propose is a simple interface that people can use to implement a 'constraint' (matching the classic database definition). This would help ease of adoption by helping HBase more easily check that box, help minimize code duplication across organizations, and lead to easier adoption.Essentially, people would implement a 'Constraint' interface for checking keys before they are put into a table. Puts that are valid get written to the table, but if not people can will throw an exception that gets propagated back to the client explaining why the put was invalid.Constraints would be set on a per-table basis and the user would be expected to ensure the jars containing the constraint are present on the machines serving that table.Yes, people could roll their own mechanism for doing this via coprocessors each time, but this would make it easier to do so, so you only have to implement a very minimal interface and not worry about the specifics.</description>
      <version>0.94.0</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">src.docbkx.book.xml</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.constraint.WorksConstraint.java.orig</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.constraint.TestConstraints.java.orig</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.constraint.TestConstraint.java.orig</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.constraint.RuntimeFailConstraint.java.orig</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.constraint.CheckConfigurationConstraint.java.orig</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.constraint.AllPassConstraint.java.orig</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.constraint.AllFailConstraint.java.orig</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.constraint.package-info.java.orig</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.constraint.Constraints.java.orig</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.constraint.ConstraintProcessor.java.orig</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.constraint.ConstraintException.java.orig</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.constraint.Constraint.java.orig</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.constraint.BaseConstraint.java.orig</file>
    </fixedFiles>
  </bug>
  <bug id="4606" opendate="2011-10-17 00:00:00" fixdate="2011-10-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove spam in HCM and fix a list.size == 0</summary>
      <description>As discussed on the ML, HCM in 0.92 is being spammy with "expecting X results" which is a debug leftover. Also right next to it I see a list.size == 0, which should be converted into isEmpty.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4629" opendate="2011-10-19 00:00:00" fixdate="2011-10-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>enable automated patch testing for hbase</summary>
      <description>enable jenkins automated patch testing for hbase project</description>
      <version>None</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4642" opendate="2011-10-20 00:00:00" fixdate="2011-10-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add Apache License Header</summary>
      <description>executing mvn apache-rat:check fails with &amp;#91;ERROR&amp;#93; Failed to execute goal org.apache.rat:apache-rat-plugin:0.6:check (default-cli) on project hbase: Too many unapproved licenses: 84 -&gt; &amp;#91;Help 1&amp;#93;org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.rat:apache-rat-plugin:0.6:check (default-cli) on project hbase: Too many unapproved licenses: 84there are about 70 + files which are missing the Apache License Headers and rest of them should be added to the exclude list.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.set.meta.memstore.size.rb</file>
      <file type="M">bin.set.meta.block.caching.rb</file>
      <file type="M">bin.local-regionservers.sh</file>
      <file type="M">bin.local-master-backup.sh</file>
    </fixedFiles>
  </bug>
  <bug id="4669" opendate="2011-10-25 00:00:00" fixdate="2011-10-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add an option of using round-robin assignment for enabling table</summary>
      <description>Under some scenarios, we use the function of disable/enable HTable. But currently, enable HTable uses the random-assignment. We hope all the regions show a better distribution, no matter how many regions and how many regionservers.So I suggest to add an option of using round-robin assignment on enable-table.</description>
      <version>0.90.4,0.94.0</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.EnableTableHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.BulkReOpen.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.BulkAssigner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4670" opendate="2011-10-25 00:00:00" fixdate="2011-10-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix javadoc warnings</summary>
      <description>We have hundreds of javadoc warnings emitted on every build.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.metrics.RegionServerDynamicMetrics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperNodeTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.RegionServerTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.Objects.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.CompoundBloomFilterBase.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.Bytes.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.ByteBloomFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.BloomFilterFactory.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.BloomFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.TableDescriptors.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ServerName.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogKey.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.SplitLogWorker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.catalog.CatalogTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.catalog.MetaMigrationRemovingHTD.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.catalog.MetaReader.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.Append.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.coprocessor.AggregationClient.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.coprocessor.LongColumnInterpreter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnection.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HTableInterface.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HTablePool.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.Mutation.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.coprocessor.AggregateProtocol.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.coprocessor.ColumnInterpreter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.coprocessor.MasterObserver.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.coprocessor.package-info.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.executor.RegionTransitionData.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.BitComparator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.ParseFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.RowFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HServerAddress.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HServerInfo.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.HalfStoreFileReader.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.AbstractHFileReader.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.BlockCache.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFile.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderV1.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderV2.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.InlineBlockWriter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.slab.SlabCache.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.Delayable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HBaseServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.hadoopbackport.InputSampler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.LoadBalancer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.LoadBalancerFactory.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.monitoring.MonitoredTask.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.monitoring.ThreadMonitoring.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.KeyValueScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="4679" opendate="2011-10-26 00:00:00" fixdate="2011-10-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thrift null mutation error</summary>
      <description>When using null as a value for a mutation, HBasse thrift client failed and threw an error. We should instad check for a null byte buffer.</description>
      <version>0.92.0,0.94.0</version>
      <fixedVersion>0.92.0,0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.thrift.TestThriftServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4683" opendate="2011-10-26 00:00:00" fixdate="2011-12-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Always cache index and bloom blocks</summary>
      <description>This would add a new boolean config option: hfile.block.cache.datablocksDefault would be true.Setting this to false allows HBase in a mode where only index blocks are cached, which is useful for analytical scenarios where a useful working set of the data cannot be expected to fit into the (aggregate) cache.This is the equivalent of setting cacheBlocks to false on all scans (including scans on behalf of gets).I would like to get a general feeling about what folks think about this.The change itself would be simple.Update (Mikhail): we probably don't need a new conf option. Instead, we will make index blocks cached by default.</description>
      <version>None</version>
      <fixedVersion>0.92.0,0.94.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestSeekOptimizations.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestScanWithBloomError.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestMultiColumnScanner.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.metrics.TestSchemaConfigured.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.CreateRandomStoreFile.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.metrics.SchemaMetrics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.metrics.SchemaConfigured.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFileWriterV2.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderV2.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderV1.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.AbstractHFileWriter.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4698" opendate="2011-10-28 00:00:00" fixdate="2011-12-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Let the HFile Pretty Printer print all the key values for a specific row.</summary>
      <description>When using HFile Pretty Printer to debug HBase issues, it would very nice to allow the Pretty Printer to seek to a specific row, and only print all the key values for this row.</description>
      <version>None</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
    </fixedFiles>
  </bug>
  <bug id="4699" opendate="2011-10-28 00:00:00" fixdate="2011-10-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cleanup the UIs</summary>
      <description>UIs have had a bunch of stuff dumped into them of late. Its all good stuff its just not sitting nicely in the web page. Fix.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.resources.hbase-webapps.static.hbase.css</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HServerLoad.java</file>
      <file type="M">src.main.jamon.org.apache.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">src.main.jamon.org.apache.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">src.main.jamon.org.apache.hbase.tmpl.common.TaskMonitorTmpl.jamon</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="47" opendate="2007-11-17 00:00:00" fixdate="2007-5-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>option to set TTL for columns in hbase</summary>
      <description>I would like to see the option to have a TTL on the columns in hbase this feature could be helpfully in removing stale data from large datasets with out havening to do a full scan of the dataset and then issuing deletes.Example Say I am crawling pages and only refreshing pages based on a set score and some pages doe not get updated over X days the old version of the page gets removed from the data set. Say I am striping out links form html and storing them say a link is removed from a page then I would need to issue a delete statement to remove that links form the data set with a ttl the link data would remove its self if not updated in x secs. These are just examples based on crawling like nutch but I can foresee many apps using this option. This is a feature in bigtables thats is handled when bigtable does garbage-collection.</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.TestToString.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestBloomFilters.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestTimestamp.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.HBaseTestCase.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.ThriftUtilities.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.Hbase.thrift</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.generated.ColumnDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Memcache.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.hql.SchemaModificationCommand.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.hql.HQLParser.jj</file>
      <file type="M">src.java.org.apache.hadoop.hbase.hql.HelpCommand.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.hql.generated.HQLParserTokenManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.hql.generated.HQLParserConstants.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.hql.generated.HQLParser.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.hql.AlterCommand.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4725" opendate="2011-11-2 00:00:00" fixdate="2011-11-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>NPE in AM#updateTimers</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4734" opendate="2011-11-2 00:00:00" fixdate="2011-11-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[bulk load] Warn if bulk load directory contained no files</summary>
      <description>Bulk load exits if no files are found in the specified directory. This can happen if a directory has been bulk loaded already (bulk load renames/moves files). It would be good to provide some sort of warning when this happens.</description>
      <version>0.90.5,0.92.0,0.94.0</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4744" opendate="2011-11-3 00:00:00" fixdate="2011-8-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove @Ignore for testLogRollAfterSplitStart</summary>
      <description>We fixed a data loss bug in HBASE-2312 by adding non-recursive creates to HDFS. Although a number of HDFS versions have this fix, the official HDFS 0.20.205 branch currently doesn't, so we needed to mark the test as ignored. Please revisit before the RC of 0.94, which should have 0.20.205.1 or later &amp; the necessary HDFS patches.</description>
      <version>0.94.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRollAbort.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLogSplit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
    </fixedFiles>
  </bug>
  <bug id="4745" opendate="2011-11-3 00:00:00" fixdate="2011-11-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LRU Statistics thread should be daemon</summary>
      <description>Here was from 'HBase 0.92/Hadoop 0.22 test results' discussion on dev@hbase"LRU Statistics #0" prio=10 tid=0x00007f4edc7dd800 nid=0x211a waitingon condition [0x00007f4e631e2000] java.lang.Thread.State: TIMED_WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00007f4e88acc968&gt; (ajava.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:198) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2025) at java.util.concurrent.DelayQueue.take(DelayQueue.java:164) at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:583) at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:576) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:947) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:907) at java.lang.Thread.run(Thread.java:619)We should make this thread daemon thread.</description>
      <version>None</version>
      <fixedVersion>0.92.0,0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4746" opendate="2011-11-4 00:00:00" fixdate="2011-11-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use a random ZK client port in unit tests so we can run them in parallel</summary>
      <description>The hard-coded ZK client port has long been a problem for running HBase test suite in parallel. The mini ZK cluster should run on a random free port, and that port should be passed to all parts of the unit tests that need to talk to the mini cluster. In fact, randomizing the port exposes a lot of places in the code where a new configuration is instantiated, and as a result the client tries to talk to the default ZK client port and times out.The initial fix is for 0.89-fb, where it already allows to run unit tests in parallel in 10 minutes. A fix for the trunk will follow.</description>
      <version>None</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.zookeeper.TestZooKeeperMainServerArg.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.zookeeper.TestHQuorumPeer.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.util.TestRegionSplitter.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.util.TestMergeTool.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.thrift2.TestThriftHBaseServiceHandler.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.TestZooKeeper.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.TestHBaseTestingUtility.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.replication.TestReplication.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.replication.TestMultiSlaveReplication.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.replication.TestMasterReplication.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithRemove.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithAbort.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKConfig.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.RegionSplitter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.FSTableDescriptors.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.thrift2.ThriftHBaseServiceHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMasterCommandLine.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.TableOutputFormat.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorHost.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4747" opendate="2011-11-4 00:00:00" fixdate="2011-11-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade maven surefire plugin to 2.10</summary>
      <description>Quite often, we see the following when running unit tests:Running org.apache.hadoop.hbase.master.TestMasterFailoverException in thread "ThreadedStreamConsumer" java.lang.OutOfMemoryError: Java heap space at java.util.Arrays.copyOf(Arrays.java:2882) at java.lang.AbstractStringBuilder.expandCapacity(AbstractStringBuilder.java:100) at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:390) at java.lang.StringBuffer.append(StringBuffer.java:224) at org.apache.maven.surefire.report.TestSetRunListener.getAsString(TestSetRunListener.java:201) at org.apache.maven.surefire.report.TestSetRunListener.testError(TestSetRunListener.java:139) at org.apache.maven.plugin.surefire.booterclient.output.ForkClient.consumeLine(ForkClient.java:112) at org.apache.maven.plugin.surefire.booterclient.output.ThreadedStreamConsumer$Pumper.run(ThreadedStreamConsumer.java:67) at java.lang.Thread.run(Thread.java:680)This was due to https://jira.codehaus.org/browse/SUREFIRE-754 which has been fixed in surefire 2.10We should upgrade to version 2.10</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="4759" opendate="2011-11-8 00:00:00" fixdate="2011-11-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Migrate from JUnit 4.8.2 to JUnit 4.10</summary>
      <description>Rationale: better to stay up to date we're going to start Categories, there are bug fixes around this in the last releases</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4761" opendate="2011-11-8 00:00:00" fixdate="2011-11-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add Developer Debug Options to HBase Config</summary>
      <description>Add in optional HBase configuration options that core developers will commonly use: an option to enable JDWP debugging &amp; an option to use a separate logfile for GC information. (Part of the effort to move 89-fb features over to trunk)</description>
      <version>0.94.0</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.hbase-env.sh</file>
      <file type="M">bin.stop-hbase.sh</file>
      <file type="M">bin.hbase-daemon.sh</file>
    </fixedFiles>
  </bug>
  <bug id="4785" opendate="2011-11-15 00:00:00" fixdate="2011-11-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve recovery time of HBase client when a region server dies.</summary>
      <description>When a region server dies, the HBase client waits until the RPC timesout before learning that it needs to check META to find the new location of the region. And it incurs this timeout cost for every region being served by the dead region server. Remove this overhead by clearing the entries in cache that have the dead region server as their values.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.SoftValueSortedMap.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="4801" opendate="2011-11-16 00:00:00" fixdate="2011-11-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>alter_status shell prints sensible message at completion</summary>
      <description>The alter_status command used to print 0/0 once an alter operation had completed and its progress was no longer available. Now it instad indicates that all regions were updated.</description>
      <version>0.94.0</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.ruby.hbase.admin.rb</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4802" opendate="2011-11-16 00:00:00" fixdate="2011-9-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Disable show table metrics in bulk loader</summary>
      <description>During bulk load, the Configuration object may be set to null. This caused an NPE in per-CF metrics because it consults the Configuration to determine whether to show the Table name. Need to add simple change to allow the conf to be null &amp; not specify table name in that instance.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.metrics.SchemaMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.metrics.SchemaConfigured.java</file>
    </fixedFiles>
  </bug>
  <bug id="4820" opendate="2011-11-18 00:00:00" fixdate="2011-11-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Distributed log splitting coding enhancement to make it easier to understand, no semantics change</summary>
      <description>In reviewing distributed log splitting feature, we found some cosmetic issues. They make the code hard to understand.It will be great to fix them. For this issue, there should be no semantic change.</description>
      <version>0.92.0,0.94.0</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestSplitLogManager.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.SplitLogWorker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="4829" opendate="2011-11-19 00:00:00" fixdate="2011-11-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix javadoc warnings in 0.92 branch</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKLeaderManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.security.User.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormat.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.RequestContext.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.Result.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.catalog.CatalogTracker.java</file>
    </fixedFiles>
  </bug>
  <bug id="4847" opendate="2011-11-22 00:00:00" fixdate="2011-12-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Activate single jvm for small tests on jenkins</summary>
      <description>This will not revolutionate performances alone. We will win between 1 to 4 minutes.But we win as well: it's a step for parallelizing the tests new tests are less expensive as they do not create a new jvm: it's a continuous win it will allow to push it on dev env while having the same env on dev &amp; on build, and 3 minutes are 10% of small + medium tests execution time.I will do a few "submit patch" to see if it works well before asking for the real commit.</description>
      <version>0.94.0</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.util.TestIncrementingEnvironmentEdge.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.util.TestFSTableDescriptors.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreScanner.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestStore.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransaction.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestSeekOptimizations.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestScanWithBloomError.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestResettingCounters.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestMultiColumnScanner.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestKeepDeletes.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestColumnSeeking.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.ipc.TestDelayedRpc.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.HBaseTestCase.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.filter.TestMultipleColumnPrefixFilter.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.filter.TestFilter.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.filter.TestDependentColumnFilter.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.filter.TestColumnPrefixFilter.java</file>
      <file type="M">pom.xml</file>
      <file type="M">dev-support.hbasetests.sh</file>
    </fixedFiles>
  </bug>
  <bug id="4851" opendate="2011-11-22 00:00:00" fixdate="2011-11-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hadoop maven dependency needs to be an optional one</summary>
      <description>Given that HBase 0.92/0.94 is likely to be used with at least 3 different versions of Hadoop (0.20, 0.22 and 0.23) it seems appropriate to make hadoop maven dependencies into optional ones (IOW, the build of HBase will see NO changes in behavior, but any component that has HBase as a dependency will be in control of what version of Hadoop gets used).</description>
      <version>0.92.0,0.92.1,0.94.0</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="4859" opendate="2011-11-23 00:00:00" fixdate="2011-12-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Correctly PreWarm HBCK ThreadPool</summary>
      <description>See description at HBASE-3553. We had a patch ready for this in HBASE-3620 but never applied it publicly. Testing showed massive speedup in HBCK, especially when RegionServers were down or had long response times.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="4861" opendate="2011-11-24 00:00:00" fixdate="2011-11-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix some misspells and extraneous characters in logs; set some to TRACE</summary>
      <description>Some small clean up in logs.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.BloomFilterFactory.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.SplitRegionHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderV2.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.catalog.MetaEditor.java</file>
    </fixedFiles>
  </bug>
  <bug id="4881" opendate="2011-11-28 00:00:00" fixdate="2011-12-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unhealthy region is on service caused by rollback of region splitting</summary>
      <description>If region splitting is failed in the state of JournalEntry.CLOSED_PARENT_REGIONIt will be rollback as the following steps:1.case CLOSED_PARENT_REGION: this.parent.initialize(); break;2.case CREATE_SPLIT_DIR: this.parent.writestate.writesEnabled = true; cleanupSplitDir(fs, this.splitdir); break;3.case SET_SPLITTING_IN_ZK: if (server != null &amp;&amp; server.getZooKeeper() != null) { cleanZK(server, this.parent.getRegionInfo()); } break;If this.parent.initialize() throws IOException in step 1,If check filesystem is ok. it will do nothing.However, the parent region is on service now.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
    </fixedFiles>
  </bug>
  <bug id="4886" opendate="2011-11-28 00:00:00" fixdate="2011-11-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>truncate fails in HBase shell</summary>
      <description>Seeing this in trunk:hbase(main):001:0&gt; truncate 'table'Truncating 'table' table (it may take a while):ERROR: wrong number of arguments (1 for 3)Here is some help for this command: Disables, drops and recreates the specified table.... caused by the removal of the HTable(String) constructor.</description>
      <version>0.94.0</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug id="4927" opendate="2011-12-1 00:00:00" fixdate="2011-12-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CatalogJanior:SplitParentFirstComparator doesn&amp;#39;t sort as expected, for the last region when the endkey is empty</summary>
      <description>When reviewing HBASE-4238 backporting, Jon found this issue.What happens if the split points are (empty end key is the last key, empty start key is the first key)Parent [A,)L daughter [A,B), R daughter [B,)When sorted, we gets to end key comparision which results in this incorrector order:[A,B), [A,), [B,) we wanted:[A,), [A,B), [B,)</description>
      <version>0.92.0,0.94.0</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionInfo.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
    </fixedFiles>
  </bug>
  <bug id="4944" opendate="2011-12-4 00:00:00" fixdate="2011-12-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Optionally verify bulk loaded HFiles</summary>
      <description>We rely on users to produce properly formatted HFiles for bulk import. Attached patch adds an optional code path, toggled by a configuration property, that verifies the HFile under consideration for import is properly sorted. The default maintains the current behavior, which does not scan the file for correctness.Patch is against trunk but can apply against all active branches.</description>
      <version>0.90.5,0.92.0,0.94.0</version>
      <fixedVersion>0.90.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
    </fixedFiles>
  </bug>
  <bug id="4955" opendate="2011-12-5 00:00:00" fixdate="2011-8-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use the official versions of surefire &amp; junit</summary>
      <description>We currently use private versions for Surefire &amp; JUnit since HBASE-4763.This JIRA traks what we need to move to official versions.Surefire 2.11 is just out, but, after some tests, it does not contain all what we need.JUnit. Could be for JUnit 4.11. Issue to monitor:https://github.com/KentBeck/junit/issues/359: fixed in our version, no feedback for an integration on trunkSurefire: Could be for Surefire 2.12. Issues to monitor are:329 (category support): fixed, we use the official implementation from the trunk786 (@Category with forkMode=always): fixed, we use the official implementation from the trunk791 (incorrect elapsed time on test failure): fixed, we use the official implementation from the trunk793 (incorrect time in the XML report): Not fixed (reopen) on trunk, fixed on our version.760 (does not take into account the test method): fixed in trunk, not fixed in our version798 (print immediately the test class name): not fixed in trunk, not fixed in our version799 (Allow test parallelization when forkMode=always): not fixed in trunk, not fixed in our version800 (redirectTestOutputToFile not taken into account): not yet fix on trunk, fixed on our version800 &amp; 793 are the more important to monitor, it's the only ones that are fixed in our version but not on trunk.</description>
      <version>0.94.0,0.98.0,0.96.0,0.99.0</version>
      <fixedVersion>0.99.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.http.TestServletFilter.java</file>
    </fixedFiles>
  </bug>
  <bug id="4956" opendate="2011-12-5 00:00:00" fixdate="2011-7-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Control direct memory buffer consumption by HBaseClient</summary>
      <description>As Jonathan explained here https://groups.google.com/group/asynchbase/browse_thread/thread/c45bc7ba788b2357?pli=1 , standard hbase client inadvertently consumes large amount of direct memory.We should consider using netty for NIO-related tasks.</description>
      <version>None</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Result.java</file>
    </fixedFiles>
  </bug>
  <bug id="4974" opendate="2011-12-7 00:00:00" fixdate="2011-12-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove some resources leaks on the tests</summary>
      <description>Cf. title and HBASE-4965</description>
      <version>0.94.0</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.rest.TestScannersWithFilters.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="4976" opendate="2011-12-7 00:00:00" fixdate="2011-12-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add compaction/flush queue size metrics mistakenly removed by HFile v2</summary>
      <description>Upping priority, and putting it against 0.92 since J-D fingered it as blocker. Which metrics in particular are missing? Hard to patch?</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="4993" opendate="2011-12-9 00:00:00" fixdate="2011-12-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Performance regression in minicluster creation</summary>
      <description>Side effect of 4610: the mini cluster needs 4,5 seconds to start</description>
      <version>0.94.0</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.resources.hbase-site.xml</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="5015" opendate="2011-12-13 00:00:00" fixdate="2011-12-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove some leaks in tests due to lack of HTable.close()</summary>
      <description></description>
      <version>0.94.0</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.TestZooKeeper.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.TestRegionRebalancing.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.TestMultiVersions.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.TestInfoServers.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.TestHBaseTestingUtility.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.TestGlobalMemStoreSize.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.TestFullLogReconstruction.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.ResourceChecker.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestEndToEndSplitTransaction.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestZKBasedOpenCloseRegion.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestRollingRestart.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestMasterTransitions.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestMasterRestartAfterDisablingTable.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestMaster.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.filter.TestColumnRangeFilter.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithRemove.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithAbort.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverBypass.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.coprocessor.TestMasterObserver.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorEndpoint.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.coprocessor.TestAggregateProtocol.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestTimestampsFilter.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestScannerTimeout.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestMultipleTimestamps.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestMultiParallel.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestMetaScanner.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestMetaMigrationRemovingHTD.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestInstantSchemaChangeSplit.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestInstantSchemaChangeFailover.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestInstantSchemaChange.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestHTableUtil.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.catalog.TestMetaReaderEditor.java</file>
    </fixedFiles>
  </bug>
  <bug id="5030" opendate="2011-12-14 00:00:00" fixdate="2011-1-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Some tests do not close the HFile.Reader they use, leaving some file descriptors open</summary>
      <description></description>
      <version>0.94.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.TestHalfStoreFileReader.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.hfile.TestSeekTo.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.hfile.TestReseekTo.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFilePerformance.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileBlockIndex.java</file>
    </fixedFiles>
  </bug>
  <bug id="5033" opendate="2011-12-14 00:00:00" fixdate="2011-1-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Opening/Closing store in parallel to reduce region open/close time</summary>
      <description>Region servers are opening/closing each store and each store file for every store in sequential fashion, which may cause inefficiency to open/close regions. So this diff is to open/close each store in parallel in order to reduce region open/close time. Also it would help to reduce the cluster restart time.1) Opening each store in parallel2) Loading each store file for every store in parallel3) Closing each store in parallel4) Closing each store file for every store in parallel.</description>
      <version>None</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.Threads.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="5038" opendate="2011-12-15 00:00:00" fixdate="2011-12-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Some tests leak connections</summary>
      <description></description>
      <version>0.94.0</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreFileBlockCacheSummary.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.TestHalfStoreFileReader.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.filter.TestColumnRangeFilter.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.RegionSplitter.java</file>
    </fixedFiles>
  </bug>
  <bug id="5055" opendate="2011-12-16 00:00:00" fixdate="2011-12-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Build against hadoop 0.22 broken</summary>
      <description>I got the following when compiling TRUNK against hadoop 0.22:[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.0.2:compile (default-compile) on project hbase: Compilation failure: Compilation failure:[ERROR] /Users/zhihyu/trunk-hbase/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogReader.java:[37,39] cannot find symbol[ERROR] symbol : class DFSInputStream[ERROR] location: class org.apache.hadoop.hdfs.DFSClient[ERROR] [ERROR] /Users/zhihyu/trunk-hbase/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogReader.java:[109,37] cannot find symbol[ERROR] symbol : class DFSInputStream[ERROR] location: class org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader.WALReader.WALReaderFSDataInputStream</description>
      <version>0.92.0,0.94.0</version>
      <fixedVersion>0.92.0,0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestStore.java</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="5064" opendate="2011-12-18 00:00:00" fixdate="2011-1-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>utilize surefire tests parallelization</summary>
      <description>To be tried multiple times on hadoop-qa before committing.</description>
      <version>0.94.0</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.resources.hbase-site.xml</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.mapreduce.TestTimeRangeMapRed.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">pom.xml</file>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  <bug id="5081" opendate="2011-12-21 00:00:00" fixdate="2011-1-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Distributed log splitting deleteNode races against splitLog retry</summary>
      <description>Recently, during 0.92 rc testing, we found distributed log splitting hangs there forever. Please see attached screen shot.I looked into it and here is what happened I think:1. One rs died, the servershutdownhandler found it out and started the distributed log splitting;2. All three tasks failed, so the three tasks were deleted, asynchronously;3. Servershutdownhandler retried the log splitting;4. During the retrial, it created these three tasks again, and put them in a hashmap (tasks);5. The asynchronously deletion in step 2 finally happened for one task, in the callback, it removed onetask in the hashmap;6. One of the newly submitted tasks' zookeeper watcher found out that task is unassigned, and it is notin the hashmap, so it created a new orphan task.7. All three tasks failed, but that task created in step 6 is an orphan so the batch.err counter was one short,so the log splitting hangs there and keeps waiting for the last task to finish which is never going to happen.So I think the problem is step 2. The fix is to make deletion sync, instead of async, so that the retry will havea clean start.Async deleteNode will mess up with split log retrial. In extreme situation, if async deleteNode doesn't happensoon enough, some node created during the retrial could be deleted.deleteNode should be sync.</description>
      <version>0.92.0,0.94.0</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKSplitLog.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestSplitLogManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5115" opendate="2012-1-3 00:00:00" fixdate="2012-8-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change HBase "color" from purple to "International Orange (Engineering)"</summary>
      <description>See http://en.wikipedia.org/wiki/International_orange See the bit about the color of the golden gate bridge.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.resources.images.hbase.small.gif</file>
      <file type="M">src.site.resources.images.hbase.logo.med.gif</file>
      <file type="M">src.site.resources.images.hbase.logo.png</file>
      <file type="M">src.site.resources.images.favicon.ico</file>
      <file type="M">src.main.resources.hbase-webapps.static.hbase.logo.png</file>
    </fixedFiles>
  </bug>
  <bug id="5150" opendate="2012-1-9 00:00:00" fixdate="2012-1-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Failure in a thread may not fail a test, clean up log splitting test</summary>
      <description>This is to clean up some tests for HBASE-5081. The Assert.fail method in a separate thread will terminate the thread, but may not fail the test.We can use callable, so that we can get the error in getting the result. Some documentation to explain the test will be helpful too.</description>
      <version>0.94.0</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestSplitLogManager.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="5152" opendate="2012-1-9 00:00:00" fixdate="2012-1-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Region is on service before completing initialization when doing rollback of split, it will affect read correctness</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.92.0,0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5195" opendate="2012-1-13 00:00:00" fixdate="2012-2-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[Coprocessors] preGet hook does not allow overriding or wrapping filter on incoming Get</summary>
      <description>Without the ability to wrap the internal Scan on the Get, we can't override (or protect, in the case of access control) Gets as we can Scans. The result is inconsistent behavior.</description>
      <version>0.92.0,0.94.0</version>
      <fixedVersion>0.92.1,0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="5196" opendate="2012-1-13 00:00:00" fixdate="2012-1-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Failure in region split after PONR could cause region hole</summary>
      <description>If region split fails after PONR, it relies on the master ServerShutdown handler to fix it. However, if the master doesn't get a chance to fix it. There will be a hole in the region chain.</description>
      <version>0.92.0,0.94.0</version>
      <fixedVersion>0.90.6,0.92.0,0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.SplitRequest.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5206" opendate="2012-1-16 00:00:00" fixdate="2012-3-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Port HBASE-5155 to 0.92, 0.94, and TRUNK</summary>
      <description>This JIRA ports HBASE-5155 (ServerShutDownHandler And Disable/Delete should not happen parallely leading to recreation of regions that were deleted) to 0.92 and TRUNK</description>
      <version>0.92.2,0.94.0,0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.TestDrainingServer.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKTable.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestMasterRestartAfterDisablingTable.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestMaster.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKTable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.DeleteTableHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="5213" opendate="2012-1-17 00:00:00" fixdate="2012-4-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>"hbase master stop" does not bring down backup masters</summary>
      <description>Typing "hbase master stop" produces the following message:"stop Start cluster shutdown; Master signals RegionServer shutdown"It seems like backup masters should be considered part of the cluster, but they are not brought down by "hbase master stop"."stop-hbase.sh" does correctly bring down the backup masters.The same behavior is observed when a client app makes use of the client API HBaseAdmin.shutdown() http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HBaseAdmin.html#shutdown() &amp;#8211; this isn't too surprising since I think "hbase master stop" just calls this API.It seems like HBASE-1448 address this; perhaps there was a regression?</description>
      <version>0.90.5,0.92.0,0.94.0,0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestActiveMasterManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.ActiveMasterManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="5228" opendate="2012-1-18 00:00:00" fixdate="2012-1-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[REST] Rip out "transform" feature</summary>
      <description>The 'transform' feature, where REST can be instructed, via a table attribute, to apply a transformation (e.g. base64 encoding or decoding) to a (sub)set of column values before serving them up to a client or storing them into HBase, was added some time ago at the request of Jack Levin. I have since come to regret it, it was not a well thought out feature: This is really an application concern. It adds significant overhead to request processing: Periodically a HBaseAdmin is used to retrieve the table descriptor, in order to scan through table attributes for transformation directives.I think it is best to rip it out, its a real problem area, and REST should be no more concerned about data formats than the Java API. I doubt anyone uses this, not even Jack. Will need to follow up with him to confirm.</description>
      <version>0.90.5,0.92.0,0.94.0</version>
      <fixedVersion>0.90.6,0.92.1,0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.rest.TestTransform.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.transform.Transform.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.transform.NullTransform.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.transform.Base64.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.TableResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.RowResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.MultiRowResource.java</file>
    </fixedFiles>
  </bug>
  <bug id="5278" opendate="2012-1-25 00:00:00" fixdate="2012-1-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase shell script refers to removed "migrate" functionality</summary>
      <description>$ hbase migrateException in thread "main" java.lang.NoClassDefFoundError: org/apache/hadoop/hbase/util/MigrateCaused by: java.lang.ClassNotFoundException: org.apache.hadoop.hbase.util.Migrateat java.net.URLClassLoader$1.run(URLClassLoader.java:202)at java.security.AccessController.doPrivileged(Native Method)at java.net.URLClassLoader.findClass(URLClassLoader.java:190)at java.lang.ClassLoader.loadClass(ClassLoader.java:306)at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)at java.lang.ClassLoader.loadClass(ClassLoader.java:247)Could not find the main class: org.apache.hadoop.hbase.util.Migrate. Program will exit.The 'hbase' shell script has docs referring to a 'migrate' command which no longer exists.</description>
      <version>0.90.5,0.92.0,0.94.0</version>
      <fixedVersion>0.92.1,0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug id="5291" opendate="2012-1-27 00:00:00" fixdate="2012-6-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add Kerberos HTTP SPNEGO authentication support to HBase web consoles</summary>
      <description>Like HADOOP-7119, the same motivations:Hadoop RPC already supports Kerberos authentication. As does the HBase secure RPC engine.Kerberos enables single sign-on.Popular browsers (Firefox and Internet Explorer) have support for Kerberos HTTP SPNEGO.Adding support for Kerberos HTTP SPNEGO to &amp;#91;HBase&amp;#93; web consoles would provide a unified authentication mechanism and single sign-on for web UI and RPC.Also like HADOOP-7119, the same solution:A servlet filter is configured in front of all Hadoop web consoles for authentication.This filter verifies if the incoming request is already authenticated by the presence of a signed HTTP cookie. If the cookie is present, its signature is valid and its value didn't expire; then the request continues its way to the page invoked by the request. If the cookie is not present, it is invalid or it expired; then the request is delegated to an authenticator handler. The authenticator handler then is responsible for requesting/validating the user-agent for the user credentials. This may require one or more additional interactions between the authenticator handler and the user-agent (which will be multiple HTTP requests). Once the authenticator handler verifies the credentials and generates an authentication token, a signed cookie is returned to the user-agent for all subsequent invocations.The authenticator handler is pluggable and 2 implementations are provided out of the box: pseudo/simple and kerberos.1. The pseudo/simple authenticator handler is equivalent to the Hadoop pseudo/simple authentication. It trusts the value of the user.name query string parameter. The pseudo/simple authenticator handler supports an anonymous mode which accepts any request without requiring the user.name query string parameter to create the token. This is the default behavior, preserving the behavior of the HBase web consoles before this patch.2. The kerberos authenticator handler implements the Kerberos HTTP SPNEGO implementation. This authenticator handler will generate a token only if a successful Kerberos HTTP SPNEGO interaction is performed between the user-agent and the authenticator. Browsers like Firefox and Internet Explorer support Kerberos HTTP SPNEGO.We can build on the support added to Hadoop via HADOOP-7119. Should just be a matter of wiring up the filter to our infoservers in a similar manner. And from https://issues.apache.org/jira/browse/HBASE-5050?focusedCommentId=13171086&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13171086Hadoop 0.23 onwards has a hadoop-auth artifact that provides SPNEGO/Kerberos authentication for webapps via a filter. You should consider using it. You don't have to move Hbase to 0.23 for that, just consume the hadoop-auth artifact, which has no dependencies on the rest of Hadoop 0.23 artifacts.</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.security.adoc</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.InfoServer.java</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.http.HttpServerFunctionalTest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.HttpServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="5318" opendate="2012-2-2 00:00:00" fixdate="2012-2-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support Eclipse Indigo</summary>
      <description>The current 'standard' release of Eclipse (indigo) comes with m2eclipse installed. However, as of m2e v1.0, "interesting lifecycle phases" are now handled via a 'connector'. However, several of the plugins we use don't support connectors. This means that eclipse bails out and won't build the project or view it as 'working' even though it builds just fine from the the command line.Since Eclipse is one of the major java IDEs and that Indigo has been around for a while, we should make it easy to for new devs to pick up the code and for older devs to upgrade painlessly. The original build should not be modified in any significant way.</description>
      <version>0.94.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="5325" opendate="2012-2-2 00:00:00" fixdate="2012-2-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expose basic information about the master-status through jmx beans</summary>
      <description>Similar to the Namenode and Jobtracker, it would be good if the hbase master could expose some information through mbeans.</description>
      <version>None</version>
      <fixedVersion>0.92.1,0.94.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="5358" opendate="2012-2-8 00:00:00" fixdate="2012-2-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBaseObjectWritable should be able to serialize/deserialize generic arrays</summary>
      <description>HBaseObjectWritable can encode Writable[]'s but, but cannot encode A[] where A extends Writable. This becomes an issue for example when adding a coprocessor method which takes A[] (see HBASE-5352).</description>
      <version>0.94.0</version>
      <fixedVersion>0.92.1,0.94.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.TestHbaseObjectWritable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.HbaseObjectWritable.java</file>
    </fixedFiles>
  </bug>
  <bug id="5360" opendate="2012-2-9 00:00:00" fixdate="2012-6-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[uberhbck] Add options for how to handle offline split parents.</summary>
      <description>In a recent case, we attempted to repair a cluster that suffered from HBASE-4238 that had about 6-7 generations of "leftover" split data. The hbck repair options in an development version of HBASE-5128 treat HDFS as ground truth but didn't check SPLIT and OFFLINE flags only found in meta. The net effect was that it essentially attempted to merge many regions back into its eldest geneneration's parent's range. More safe guards to prevent "mega-merges" are being added on HBASE-5128.This issue would automate the handling of the "mega-merge" avoiding cases such as "lingering grandparents". The strategy here would be to add more checks against .META., and perform part of the catalog janitor's responsibilities for lingering grandparents. This would potentially include options to sideline regions, deleting grandparent regions, min size for sidelining, and mechanisms for cleaning .META.. Note: There already exists an mechanism to reload these regions &amp;#8211; the bulk loaded mechanisms in LoadIncrementalHFiles can be used to re-add grandparents (automatically splitting them if necessary) to HBase.</description>
      <version>0.90.7,0.92.1,0.94.0</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="5364" opendate="2012-2-9 00:00:00" fixdate="2012-2-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix source files missing licenses in 0.92 and trunk</summary>
      <description>running 'mvn rat:check' shows that a few files have snuck in that do not have proper apache licenses. Ideally we should fix these before we cut another release/release candidate.This is a blocker for 0.94, and probably should be for the other branches as well.</description>
      <version>0.92.0,0.94.0</version>
      <fixedVersion>0.90.6,0.92.1,0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.TestHTableDescriptor.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.mapreduce.TestImportExport.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.constraint.RuntimeFailConstraint.java</file>
      <file type="M">src.packages.deb.conf-pseudo.control.control</file>
      <file type="M">src.main.python.hbase.merge.conf.py</file>
      <file type="M">dev-support.findHangingTest.sh</file>
      <file type="M">bin.hbase-jruby</file>
    </fixedFiles>
  </bug>
  <bug id="5372" opendate="2012-2-9 00:00:00" fixdate="2012-6-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Table mutation operations should check table level rights, not global rights</summary>
      <description>drop/modify/disable/enable etc table operations should not check for global CREATE/ADMIN rights, but table CREATE/ADMIN rights. Since we check for global permissions first for table permissions, configuring table access using global permissions will continue to work.</description>
      <version>0.94.0,0.94.1,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug id="5385" opendate="2012-2-11 00:00:00" fixdate="2012-5-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Delete table/column should delete stored permissions on -acl- table</summary>
      <description>Deleting the table or a column does not cascade to the stored permissions at the acl table. We should also remove those permissions, otherwise, it can be a security leak, where freshly created tables contain permissions from previous same-named tables. We might also want to ensure, upon table creation, that no entries are already stored at the acl table.</description>
      <version>0.94.0</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.security.access.AccessControlLists.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug id="5433" opendate="2012-2-19 00:00:00" fixdate="2012-3-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[REST] Add metrics to keep track of success/failure count</summary>
      <description>In a production environment, the visibility of successful REST request(s) are not getting exposed to metric system as we have only one metric (requests) today.Proposing to add more metrics such as successful_get_count, failed_get_count, successful_put_count, failed_put_countThe current implementation increases the request count at the beginning of the method implementation and it is very hard to monitor requests (unless turn on debug, find the row_key and validate it in get/scan using hbase shell), it will be very useful to ops to keep an eye as requests from cross data-centers are trying to write data to one cluster using REST gateway through load balancer (and there is no visibility of which REST-server/RS failed to write data) Response update(final CellSetModel model, final boolean replace) { // for requests servlet.getMetrics().incrementRequests(1); .. .. table.put(puts); table.flushCommits(); ResponseBuilder response = Response.ok(); // for successful_get_count servlet.getMetrics().incrementSuccessfulGetRequests(1); return response.build(); } catch (IOException e) { // for failed_get_count servlet.getMetrics().incrementFailedGetRequests(1); throw new WebApplicationException(e, Response.Status.SERVICE_UNAVAILABLE); } finally { } }</description>
      <version>0.94.0</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.VersionResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.StorageClusterVersionResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.StorageClusterStatusResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.SchemaResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.ScannerResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.ScannerInstanceResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.RowResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.RootResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.RegionsResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.MultiRowResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.metrics.RESTMetrics.java</file>
    </fixedFiles>
  </bug>
  <bug id="5434" opendate="2012-2-19 00:00:00" fixdate="2012-3-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[REST] Include more metrics in cluster status request</summary>
      <description>/status/cluster shows onlystores=2storefiless=0storefileSizeMB=0memstoreSizeMB=0storefileIndexSizeMB=0for a region but master web-ui showsstores=1,storefiles=0,storefileUncompressedSizeMB=0storefileSizeMB=0memstoreSizeMB=0storefileIndexSizeMB=0readRequestsCount=0writeRequestsCount=0rootIndexSizeKB=0totalStaticIndexSizeKB=0totalStaticBloomSizeKB=0totalCompactingKVs=0currentCompactedKVs=0compactionProgressPct=NaNIn a write-heavy REST gateway based production environment, ops team needs to verify whether write counters are getting incremented per region (they do run /status/cluster on each REST server), we can get the same values from rpc.metrics.put_num_ops and hbase.regionserver.writeRequestsCount but some home-grown tools needs to parse the output of /status/cluster and updates the dashboard.</description>
      <version>0.94.0</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.rest.model.TestStorageClusterStatusModel.java</file>
      <file type="M">src.main.resources.org.apache.hadoop.hbase.rest.XMLSchema.xsd</file>
      <file type="M">src.main.resources.org.apache.hadoop.hbase.rest.protobuf.StorageClusterStatusMessage.proto</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.StorageClusterStatusResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.model.StorageClusterStatusModel.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HServerLoad.java</file>
    </fixedFiles>
  </bug>
  <bug id="5439" opendate="2012-2-22 00:00:00" fixdate="2012-2-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix some performance findbugs issues</summary>
      <description>Given 0.94 is the "performance" release, I took a look at some performance findbugs.This patch should fixeall of the following types of findbugs (except one case in generated code):Bug type DM_NUMBER_CTORBug type DM_STRING_CTORBug type DM_BOOLEAN_CTOR(these are simple constructor issues where Type.valueOf is more efficientFixes one of:Bug type SIC_INNER_SHOULD_BE_STATIC (Inner class should be static)</description>
      <version>0.94.0</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.MasterSchemaChangeTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.DefaultLoadBalancer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.ImportTsv.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.slab.SlabCache.java</file>
    </fixedFiles>
  </bug>
  <bug id="5451" opendate="2012-2-22 00:00:00" fixdate="2012-4-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Switch RPC call envelope/headers to PBs</summary>
      <description></description>
      <version>0.94.0</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.security.User.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HBaseServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HBaseClient.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.DataOutputOutputStream.java</file>
    </fixedFiles>
  </bug>
  <bug id="5454" opendate="2012-2-22 00:00:00" fixdate="2012-3-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Refuse operations from Admin before master is initialized</summary>
      <description>In our testing environment,When master is initializing, we found conflict problems between master#assignAllUserRegions and EnableTable event, causing assigning region throw exception so that master abort itself.We think we'd better refuse operations from Admin, such as CreateTable, EnableTable,etc, It could reduce error.</description>
      <version>None</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.PleaseHoldException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="5460" opendate="2012-2-23 00:00:00" fixdate="2012-2-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add protobuf as M/R dependency jar</summary>
      <description>Getting this from M/R jobs (Export for example):Error: java.lang.ClassNotFoundException: com.google.protobuf.Message at java.net.URLClassLoader$1.run(URLClassLoader.java:217) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:205) at java.lang.ClassLoader.loadClass(ClassLoader.java:321) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:294) at java.lang.ClassLoader.loadClass(ClassLoader.java:266) at org.apache.hadoop.hbase.io.HbaseObjectWritable.&lt;clinit&gt;(HbaseObjectWritable.java:262)</description>
      <version>None</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="5536" opendate="2012-3-7 00:00:00" fixdate="2012-9-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make it clear that hbase 0.96 requires hadoop 1.0.0 at least; we will no longer work on older versions</summary>
      <description>Looks like there is pretty much consensus that depending on 1.0.0 in 0.96 should be fine? See http://search-hadoop.com/m/dSbVW14EsUb2/discuss+0.96&amp;subj=RE+DISCUSS+Have+hbase+require+at+least+hadoop+1+0+0+in+hbase+0+96+0+</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.configuration.xml</file>
    </fixedFiles>
  </bug>
  <bug id="5538" opendate="2012-3-8 00:00:00" fixdate="2012-3-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>A metric to measure the size of the response queue in the hbase rpc server</summary>
      <description>The HbaseServer queues responses to client (if the client is slow). Expose a metric that records the size of the response queue.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HBaseServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HBaseRpcMetrics.java</file>
    </fixedFiles>
  </bug>
  <bug id="5574" opendate="2012-3-13 00:00:00" fixdate="2012-3-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>DEFAULT_MAX_FILE_SIZE defaults to a negative value</summary>
      <description>HBASE-4365 changed the value of DEFAULT_MAX_FILE_SIZE from 256MB to 10G. Here is the line of code:public static final long DEFAULT_MAX_FILE_SIZE = 10 * 1024 * 1024 * 1024;The problem is that java evaluates the constant as an int which wraps and gets assigned to a long. I verified this with a test. The quick fix is to change the end to 1024L;</description>
      <version>0.94.0</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="5577" opendate="2012-3-14 00:00:00" fixdate="2012-4-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>improve &amp;#39;patch submission&amp;#39; section in HBase book</summary>
      <description>Improve patch section in the book http://hbase.apache.org/book/submitting.patches.html</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.developer.xml</file>
    </fixedFiles>
  </bug>
  <bug id="5589" opendate="2012-3-15 00:00:00" fixdate="2012-3-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add of the offline call to the Master Interface</summary>
      <description>Hbck from HBASE-5128 requires an offline method on the master to properly cleanup state during certain assignment repair operations. This will this method will be added to recent and older versions of HBase.</description>
      <version>0.90.6,0.92.0,0.94.0,0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HMasterInterface.java</file>
    </fixedFiles>
  </bug>
  <bug id="559" opendate="2008-4-3 00:00:00" fixdate="2008-4-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>MR example job to count table rows</summary>
      <description>The Lars' import is a little messy; he's not sure how many records were imported. Running a select takes a couple of hours. He happens to have an idle MR cluster standing by. An example MR job that just did a count of records would be generally useful. Could even output row keys so you'd have a list of what made it in. Later, if this tool becomes popular with derivatives and similiars, we can bundle a jar of MR jobs to run against your tables that can answer common queries and that are amenable to subclassing/modification.</description>
      <version>None</version>
      <fixedVersion>0.1.2,0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.package-info.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="5591" opendate="2012-3-16 00:00:00" fixdate="2012-10-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ThiftServerRunner.HBaseHandler.toBytes() is identical to Bytes.getBytes()</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionThriftServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="5596" opendate="2012-3-16 00:00:00" fixdate="2012-3-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Few minor bugs from HBASE-5209</summary>
      <description>A few leftover bugs from HBASE-5209. Comments are documented here:https://reviews.apache.org/r/3892/</description>
      <version>0.92.1,0.94.0</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ServerName.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.ActiveMasterManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ClusterStatus.java</file>
    </fixedFiles>
  </bug>
  <bug id="5604" opendate="2012-3-20 00:00:00" fixdate="2012-4-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>M/R tool to replay WAL files</summary>
      <description>Just an idea I had. Might be useful for restore of a backup using the HLogs.This could an M/R (with a mapper per HLog file).The tool would get a timerange and a (set of) table(s). We'd pick the right HLogs based on time before the M/R job is started and then have a mapper per HLog file.The mapper would then go through the HLog, filter all WALEdits that didn't fit into the time range or are not any of the tables and then uses HFileOutputFormat to generate HFiles.Would need to indicate the splits we want, probably from a live table.</description>
      <version>None</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.mapreduce.TestWALPlayer.java</file>
      <file type="M">src.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  <bug id="5631" opendate="2012-3-24 00:00:00" fixdate="2012-9-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbck should handle case where .tableinfo file is missing.</summary>
      <description>0.92+ branches have a .tableinfo file which could be missing from hdfs. hbck should be able to detect and repair this properly.</description>
      <version>0.92.2,0.94.0,0.95.2</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.HbckTestingUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="5633" opendate="2012-3-24 00:00:00" fixdate="2012-3-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>NPE reading ZK config in HBase</summary>
      <description>If zoo.cfg contains server.* ("server.0=server0:2888:3888\n") and cluster.distributed property (in hbase-site.xml) is empty we get an NPE in parseZooCfg().The easy way to reproduce the bug is running org.apache.hbase.zookeeper.TestHQuorumPeer with hbase-site.xml containing:&lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;&lt;/value&gt;&lt;/property&gt;</description>
      <version>None</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKConfig.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="5688" opendate="2012-3-30 00:00:00" fixdate="2012-4-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Convert zk root-region-server znode content to pb</summary>
      <description>Move the root-region-server znode content from the versioned bytes that ServerName.getVersionedBytes outputs to instead be pb.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestMasterNoCluster.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.catalog.TestCatalogTrackerOnCluster.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.catalog.TestCatalogTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.RootRegionTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.catalog.RootLocationEditor.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos.java</file>
    </fixedFiles>
  </bug>
  <bug id="5704" opendate="2012-4-3 00:00:00" fixdate="2012-4-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBASE-4398 mistakenly rolled back on trunk</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.HRegionPartitioner.java</file>
    </fixedFiles>
  </bug>
  <bug id="5707" opendate="2012-4-3 00:00:00" fixdate="2012-4-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move clusterid and clusterup (shutdown) znodes over to pb</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.protobuf.ZooKeeper.proto</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.RootRegionTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ClusterStatusTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ClusterId.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="5709" opendate="2012-4-3 00:00:00" fixdate="2012-4-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move active master and backup master znodes to use pbs</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestRSStatusServlet.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestMasterAddressManager.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestActiveMasterManager.java</file>
      <file type="M">src.main.protobuf.ZooKeeper.proto</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.RootRegionTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.ActiveMasterManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.MasterAddressTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="5712" opendate="2012-4-4 00:00:00" fixdate="2012-4-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Parallelize load of .regioninfo files in diagnostic/repair portion of hbck.</summary>
      <description>On heavily loaded hdfs's some dfs nodes may not respond quickly and backs off for 60s before attempting to read data from another datanode. Portions of the information gathered from hdfs (.regioninfo files) are loaded serially. With HBase with clusters with 100's, or 1000's, or 10000's regions encountering these 60s delay blocks progress and can be very painful. There is already some parallelization of portions of the hdfs information load operations and the goal here is move the reading of .regioninfos into the parallelized sections..</description>
      <version>0.90.7,0.92.2,0.94.0,0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="5714" opendate="2012-4-4 00:00:00" fixdate="2012-8-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add write permissions check before any hbck run that modifies hdfs.</summary>
      <description>We encoutered a situation where hbck was run by an under-privileged user that was unable to write/modify/merge regions due to hdfs perms. Unfortunately, this user was alerted of this after several minutes of read-only operations. hbck should fail early by having a write perm check and providing actionable advice to the hbase admin.Maybe something like: "Current user yy does not have write perms to &lt;hbase home&gt;. Please run hbck as hdfs user xxx"</description>
      <version>0.90.6,0.92.2,0.94.0,0.95.2</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="5715" opendate="2012-4-4 00:00:00" fixdate="2012-4-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Revert &amp;#39;Instant schema alter&amp;#39; for now, HBASE-4213</summary>
      <description>See this discussion: http://search-hadoop.com/m/NxCQh1KlSxR1/Pull+instant+schema+updating+out%253F&amp;subj=Pull+instant+schema+updating+out+Pull out hbase-4213 for now. Can add it back later.</description>
      <version>None</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.util.MockRegionServerServices.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestInstantSchemaChangeSplit.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestInstantSchemaChangeFailover.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestInstantSchemaChange.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.InstantSchemaChangeTestBase.java</file>
      <file type="M">src.main.resources.hbase-default.xml</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.SchemaChangeTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.MasterSchemaChangeTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.OnlineRegions.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.TableModifyFamilyHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.TableEventHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.TableDeleteFamilyHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.TableAddFamilyHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.ModifyTableHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.DeleteTableHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.LocalHBaseCluster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HMasterInterface.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.executor.EventHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="5717" opendate="2012-4-4 00:00:00" fixdate="2012-4-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scanner metrics are only reported if you get to the end of a scanner</summary>
      <description>When you turn on Scanner Metrics, the metrics are currently only made available if you run over all records available in the scanner. If you stop iterating before the end, the values are never flushed into the metrics object (in the Scan attribute).Will supply a patch with fix and test.</description>
      <version>None</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="5719" opendate="2012-4-4 00:00:00" fixdate="2012-4-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enhance hbck to sideline overlapped mega regions</summary>
      <description>If there are too many regions in one overlapped group (by default, more than 10), hbck currently doesn't merge them since it takes time.In this case, we can sideline some regions in the group and break the overlapping to fix the inconsistency. Later on, sidelined regions can be bulk loaded manually.</description>
      <version>0.94.0,0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.util.TestRegionSplitCalculator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.RegionSplitCalculator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="5721" opendate="2012-4-5 00:00:00" fixdate="2012-4-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update bundled hadoop to be 1.0.2 (it was just released)</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="5734" opendate="2012-4-5 00:00:00" fixdate="2012-4-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change hbck sideline root</summary>
      <description>Currently hbck sideline root is the root which can run into permission issue. We can change it to /hbck</description>
      <version>0.94.0,0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="5737" opendate="2012-4-6 00:00:00" fixdate="2012-4-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Minor Improvements related to balancer.</summary>
      <description>Currently in Am.getAssignmentByTable() we use a result map which is currenly a hashmap. It could be better if we have a treeMap. Even in MetaReader.fullScan we have the treeMap only so that we have the naming order maintained. I felt this change could be very useful in cases where we are extending the DefaultLoadBalancer.</description>
      <version>None</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="5748" opendate="2012-4-9 00:00:00" fixdate="2012-4-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable lib directory in jar file for coprocessor</summary>
      <description>Hadoop MapReduce job can use external libraries in 'lib' directory in the job.jar file.It is useful that jar files for coprocessor can use external libraries in the same way.</description>
      <version>0.92.1,0.94.0</version>
      <fixedVersion>0.92.2,0.94.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.coprocessor.TestClassLoading.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorHost.java</file>
    </fixedFiles>
  </bug>
  <bug id="5772" opendate="2012-4-12 00:00:00" fixdate="2012-4-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unable to open the few links in http://hbase.apache.org/</summary>
      <description>Few links in http://hbase.apache.org/ is not working. For example, Ref Guide (multi-page) will actually link to http://hbase.apache.org/book/book.html and if I try to open this, Page not found error is coming.If I add /book in the url, like http://hbase.apache.org/book/book/book.html, it is taking me to the Apache HBase Reference Guide I think the folder structure has been changed.</description>
      <version>0.94.0</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.resources.css.site.css</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="5782" opendate="2012-4-13 00:00:00" fixdate="2012-4-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Edits can be appended out of seqid order since HBASE-4487</summary>
      <description>Create a table with 1000 splits, after the region assignemnt, kill the regionserver wich contains META table.Here few regions are missing after the log splitting and region assigment. HBCK report shows multiple region holes are got created.Same scenario was verified mulitple times in 0.92.1, no issues.</description>
      <version>0.94.0</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLog.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
    </fixedFiles>
  </bug>
  <bug id="5784" opendate="2012-4-13 00:00:00" fixdate="2012-4-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable mvn deploy of website</summary>
      <description>Up to this, deploy of website has been build local and then copy up to apache and put it into place under /www/hbase.apache.org. Change it so can have maven deploy the site. The good thing about having the latter do it is that its regular; permissions will always be the same so Doug and I won't be fighting each other when we stick stuff up there. Also, its a one step process rather than multiple.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.old.news.xml</file>
      <file type="M">src.site.xdoc.index.xml</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="5787" opendate="2012-4-13 00:00:00" fixdate="2012-4-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Table owner can&amp;#39;t disable/delete his/her own table</summary>
      <description>An user with CREATE privileges can create a table, but can not disable it, because disable operation require ADMIN privileges. Also if a table is already disabled, anyone can remove it.public void preDeleteTable(ObserverContext&lt;MasterCoprocessorEnvironment&gt; c, byte[] tableName) throws IOException { requirePermission(Permission.Action.CREATE);}public void preDisableTable(ObserverContext&lt;MasterCoprocessorEnvironment&gt; c, byte[] tableName) throws IOException { /* TODO: Allow for users with global CREATE permission and the table owner */ requirePermission(Permission.Action.ADMIN);}</description>
      <version>0.92.1,0.94.0,0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">security.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">security.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug id="5800" opendate="2012-4-16 00:00:00" fixdate="2012-4-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Birds of a feather link on web page doesn&amp;#39;t work.</summary>
      <description>just missing the http://</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.index.xml</file>
    </fixedFiles>
  </bug>
  <bug id="5840" opendate="2012-4-20 00:00:00" fixdate="2012-5-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Open Region FAILED_OPEN doesn&amp;#39;t clear the TaskMonitor Status, keeps showing the old status</summary>
      <description>TaskMonitor Status will not be cleared in case Regions FAILED_OPEN. This will keeps showing old status.This will miss leads the user.</description>
      <version>0.94.0</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="5862" opendate="2012-4-23 00:00:00" fixdate="2012-4-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>After Region Close remove the Operation Metrics.</summary>
      <description>If a region is closed then Hadoop metrics shouldn't still be reporting about that region.</description>
      <version>None</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerMetrics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.metrics.RegionServerDynamicMetrics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.metrics.RegionMetricsStorage.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.metrics.OperationMetrics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="5882" opendate="2012-4-26 00:00:00" fixdate="2012-5-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Prcoess RIT on master restart can try assigning the region if the region is found on a dead server instead of waiting for Timeout Monitor</summary>
      <description>Currently on master restart if it tries to do processRIT, any region if found on dead server tries to avoid the nwe assignment so that timeout monitor can take care.This case is more prominent if the node is found in RS_ZK_REGION_OPENING state. I think we can handle this by triggering a new assignment with a new plan.</description>
      <version>0.90.6,0.92.1,0.94.0</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="5885" opendate="2012-4-26 00:00:00" fixdate="2012-4-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Invalid HFile block magic on Local file System</summary>
      <description>ERROR: java.lang.RuntimeException: org.apache.hadoop.hbase.client.RetriesExhaustedException: Failed after attempts=7, exceptions:Thu Apr 26 11:19:18 PDT 2012, org.apache.hadoop.hbase.client.ScannerCallable@190a621a, java.io.IOException: java.io.IOException: Could not iterate StoreFileScanner[HFileScanner for reader reader=file:/tmp/hbase-eclark/hbase/TestTable/e2d1c846363c75262cbfd85ea278b342/info/bae2681d63734066957b58fe791a0268, compression=none, cacheConf=CacheConfig:enabled &amp;#91;cacheDataOnRead=true&amp;#93; &amp;#91;cacheDataOnWrite=false&amp;#93; &amp;#91;cacheIndexesOnWrite=false&amp;#93; &amp;#91;cacheBloomsOnWrite=false&amp;#93; &amp;#91;cacheEvictOnClose=false&amp;#93; &amp;#91;cacheCompressed=false&amp;#93;, firstKey=0000000001/info:data/1335463981520/Put, lastKey=0002588100/info:data/1335463902296/Put, avgKeyLen=30, avgValueLen=1000, entries=1215085, length=1264354417, cur=0000000248/info:data/1335463994457/Put/vlen=1000/ts=0] at org.apache.hadoop.hbase.regionserver.StoreFileScanner.next(StoreFileScanner.java:135) at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:95) at org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:368) at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:127) at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.nextInternal(HRegion.java:3323) at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.next(HRegion.java:3279) at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.next(HRegion.java:3296) at org.apache.hadoop.hbase.regionserver.HRegionServer.next(HRegionServer.java:2393) at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.apache.hadoop.hbase.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:364) at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1376)Caused by: java.io.IOException: Invalid HFile block magic: \xEC\xD5\x9D\xB4\xC2bfo at org.apache.hadoop.hbase.io.hfile.BlockType.parse(BlockType.java:153) at org.apache.hadoop.hbase.io.hfile.BlockType.read(BlockType.java:164) at org.apache.hadoop.hbase.io.hfile.HFileBlock.&lt;init&gt;(HFileBlock.java:254) at org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderV2.readBlockDataInternal(HFileBlock.java:1779) at org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderV2.readBlockData(HFileBlock.java:1637) at org.apache.hadoop.hbase.io.hfile.HFileReaderV2.readBlock(HFileReaderV2.java:327) at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.readNextDataBlock(HFileReaderV2.java:555) at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.next(HFileReaderV2.java:651) at org.apache.hadoop.hbase.regionserver.StoreFileScanner.next(StoreFileScanner.java:130) ... 12 moreThu Apr 26 11:19:19 PDT 2012, org.apache.hadoop.hbase.client.ScannerCallable@190a621a, java.io.IOException: java.io.IOException: java.lang.IllegalArgumentException at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:1132) at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:1121) at org.apache.hadoop.hbase.regionserver.HRegionServer.next(HRegionServer.java:2420) at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.apache.hadoop.hbase.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:364) at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1376)Caused by: java.lang.IllegalArgumentException at java.nio.Buffer.position(Buffer.java:216) at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.next(HFileReaderV2.java:630) at org.apache.hadoop.hbase.regionserver.StoreFileScanner.next(StoreFileScanner.java:130) at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:95) at org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:406) at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:127) at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.nextInternal(HRegion.java:3323) at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.next(HRegion.java:3279) at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.next(HRegion.java:3296) at org.apache.hadoop.hbase.regionserver.HRegionServer.next(HRegionServer.java:2393) ... 5 moreOn latest 0.94 branch I spun up a new standalone hbase. Then I started a performance evaluation run hbase/bin/hbase org.apache.hadoop.hbase.PerformanceEvaluation --nomapred randomWrite 10after that completed I tried a scan of TestTable. The scan got the above error.</description>
      <version>0.94.0,0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.hfile.TestChecksum.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.fs.HFileSystem.java</file>
    </fixedFiles>
  </bug>
  <bug id="5886" opendate="2012-4-26 00:00:00" fixdate="2012-5-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add new metric for possible data loss due to puts without WAL</summary>
      <description>Add a metrics to keep track of puts without WAL and possible data loss size.</description>
      <version>None</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.metrics.RegionServerMetrics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="5892" opendate="2012-4-27 00:00:00" fixdate="2012-6-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbck] Refactor parallel WorkItem* to Futures.</summary>
      <description>This would convert WorkItem* logic (with low level notifies, and rough exception handling) into a more canonical Futures pattern.Currently there are two instances of this pattern (for loading hdfs dirs, for contacting regionservers for assignments, and soon &amp;#8211; for loading hdfs .regioninfo files).</description>
      <version>0.90.6,0.92.1,0.94.0</version>
      <fixedVersion>0.92.2,0.94.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="5893" opendate="2012-4-27 00:00:00" fixdate="2012-4-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow spaces in coprocessor conf (aka trim() className)</summary>
      <description>This is annoying especially for coprocessors where you've long class name.but maybe is a bug of Configuration.getStrings() that doesn't trim each string.When you've comma separated values like in the coprocessors case, you've to pack together your values without spaces ("v1,v2,v3,...") otherwise the coprocessor is not loaded because the class name with spaces is not found.&lt;property&gt; &lt;name&gt;hbase.coprocessor.master.classes&lt;/name&gt; &lt;value&gt; org.apache.hadoop.hbase.security.token.TokenProvider, org.apache.hadoop.hbase.security.access.AccessController &lt;/value&gt;&lt;/property&gt;</description>
      <version>0.92.1,0.94.0,0.95.2</version>
      <fixedVersion>0.92.2,0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorHost.java</file>
    </fixedFiles>
  </bug>
  <bug id="5916" opendate="2012-5-2 00:00:00" fixdate="2012-5-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RS restart just before master intialization we make the cluster non operative</summary>
      <description>Consider a case where my master is getting restarted. RS that was alive when the master restart started, gets restarted before the master initializes the ServerShutDownHandler.serverShutdownHandlerEnabled = true;In this case when the RS tries to register with the master, the master will try to expire the server but the server cannot be expired as still the serverShutdownHandler is not enabled.This case may happen when i have only one RS gets restarted or all the RS gets restarted at the same time.(before assignRootandMeta).LOG.info(message); if (existingServer.getStartcode() &lt; serverName.getStartcode()) { LOG.info("Triggering server recovery; existingServer " + existingServer + " looks stale, new server:" + serverName); expireServer(existingServer); }If another RS is brought up then the cluster comes back to normalcy.May be a very corner case.</description>
      <version>0.92.1,0.94.0</version>
      <fixedVersion>0.92.2,0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRSKilledWhenMasterInitializing.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="5955" opendate="2012-5-8 00:00:00" fixdate="2012-7-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Guava 11 drops MapEvictionListener and Hadoop 2.0.0-alpha requires it</summary>
      <description>Hadoop 2.0.0-alpha depends on Guava 11.0.2. Updating HBase dependencies to match produces the following compilation errors:[ERROR] SingleSizeCache.java:[41,32] cannot find symbol[ERROR] symbol : class MapEvictionListener[ERROR] location: package com.google.common.collect[ERROR] [ERROR] SingleSizeCache.java:[94,4] cannot find symbol[ERROR] symbol : class MapEvictionListener[ERROR] location: class org.apache.hadoop.hbase.io.hfile.slab.SingleSizeCache[ERROR] [ERROR] SingleSizeCache.java:[94,69] cannot find symbol[ERROR] symbol : class MapEvictionListener[ERROR] location: class org.apache.hadoop.hbase.io.hfile.slab.SingleSizeCache</description>
      <version>0.94.0</version>
      <fixedVersion>0.94.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
    </fixedFiles>
  </bug>
  <bug id="5965" opendate="2012-5-8 00:00:00" fixdate="2012-8-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move replication znodes to pb</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.main.protobuf.ZooKeeper.proto</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.ReplicationZookeeper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.Replication.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.replication.ReplicationAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="5966" opendate="2012-5-9 00:00:00" fixdate="2012-7-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>MapReduce based tests broken on Hadoop 2.0.0-alpha</summary>
      <description>Some fairly recent change in Hadoop 2.0.0-alpha has broken our MapReduce test rigging. Below is a representative error, can be easily reproduced with:mvn -PlocalTests -Psecurity \ -Dhadoop.profile=23 -Dhadoop.version=2.0.0-SNAPSHOT \ clean test \ -Dtest=org.apache.hadoop.hbase.mapreduce.TestTableMapReduceAnd the result:------------------------------------------------------- T E S T S-------------------------------------------------------Running org.apache.hadoop.hbase.mapreduce.TestTableMapReduceTests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 54.292 sec &lt;&lt;&lt; FAILURE!-------------------------------------------------------------------------------Test set: org.apache.hadoop.hbase.mapreduce.TestTableMapReduce-------------------------------------------------------------------------------Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 54.292 sec &lt;&lt;&lt; FAILURE!testMultiRegionTable(org.apache.hadoop.hbase.mapreduce.TestTableMapReduce) Time elapsed: 21.935 sec &lt;&lt;&lt; ERROR!java.lang.reflect.UndeclaredThrowableException at org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl.unwrapAndThrowException(YarnRemoteExceptionPBImpl.java:135) at org.apache.hadoop.yarn.api.impl.pb.client.ClientRMProtocolPBClientImpl.getNewApplication(ClientRMProtocolPBClientImpl.java:134) at org.apache.hadoop.mapred.ResourceMgrDelegate.getNewJobID(ResourceMgrDelegate.java:183) at org.apache.hadoop.mapred.YARNRunner.getNewJobID(YARNRunner.java:216) at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:339) at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1226) at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1223) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:416) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1232) at org.apache.hadoop.mapreduce.Job.submit(Job.java:1223) at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1244) at org.apache.hadoop.hbase.mapreduce.TestTableMapReduce.runTestOnTable(TestTableMapReduce.java:151) at org.apache.hadoop.hbase.mapreduce.TestTableMapReduce.testMultiRegionTable(TestTableMapReduce.java:129) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:616) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20) at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:47) at org.junit.rules.RunRules.evaluate(RunRules.java:18) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222) at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28) at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30) at org.junit.runners.ParentRunner.run(ParentRunner.java:300) at org.apache.maven.surefire.junit4.JUnit4TestSet.execute(JUnit4TestSet.java:53) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:123) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:104) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:616) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:164) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:110) at org.apache.maven.surefire.booter.SurefireStarter.invokeProvider(SurefireStarter.java:175) at org.apache.maven.surefire.booter.SurefireStarter.runSuitesInProcessWhenForked(SurefireStarter.java:81) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:68)Caused by: com.google.protobuf.ServiceException: java.net.ConnectException: Call From acer.localdomain/192.168.122.1 to 0.0.0.0:8032 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:188) at $Proxy89.getNewApplication(Unknown Source) at org.apache.hadoop.yarn.api.impl.pb.client.ClientRMProtocolPBClientImpl.getNewApplication(ClientRMProtocolPBClientImpl.java:132) ... 45 moreCaused by: java.net.ConnectException: Call From acer.localdomain/192.168.122.1 to 0.0.0.0:8032 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:725) at org.apache.hadoop.ipc.Client.call(Client.java:1160) at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:185) ... 47 moreCaused by: java.net.ConnectException: Connection refused at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:592) at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206) at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:522) at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:487) at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:469) at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:563) at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:212) at org.apache.hadoop.ipc.Client.getConnection(Client.java:1266) at org.apache.hadoop.ipc.Client.call(Client.java:1136) ... 48 more</description>
      <version>0.94.0,0.95.2</version>
      <fixedVersion>0.94.1,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
    </fixedFiles>
  </bug>
  <bug id="5974" opendate="2012-5-9 00:00:00" fixdate="2012-10-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scanner retry behavior with RPC timeout on next() seems incorrect</summary>
      <description>I'm seeing the following behavior: set RPC timeout to a short value call next() for some batch of rows, big enough so the client times out before the result is returned the HConnectionManager stuff will retry the next() call to the same server. At this point, one of two things can happen: 1) the previous next() call will still be processing, in which case you get a LeaseException, because it was removed from the map during the processing, or 2) the next() call will succeed but skip the prior batch of rows.</description>
      <version>0.90.7,0.92.1,0.94.0,0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.protobuf.Client.proto</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.JVMClusterUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ClientProtos.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="6004" opendate="2012-5-15 00:00:00" fixdate="2012-5-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Adding more logging to help debugging MR job</summary>
      <description>MR job sometime fails because scanner expired. In this case, it will be helpful to know the last successful row, the ip of the region sever, and so on.</description>
      <version>0.94.0,0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapred.TableRecordReaderImpl.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
    </fixedFiles>
  </bug>
  <bug id="6005" opendate="2012-5-15 00:00:00" fixdate="2012-5-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Broken Links on Homepages</summary>
      <description>I ran w3c's link checker on the homepage and there a few broken links.I'll start getting a patch to fix the links that were broken.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.old.news.xml</file>
      <file type="M">src.site.xdoc.cygwin.xml</file>
      <file type="M">src.main.javadoc.overview.html</file>
      <file type="M">src.docbkx.preface.xml</file>
      <file type="M">src.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6007" opendate="2012-5-15 00:00:00" fixdate="2012-5-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make getTableRegions return an empty list if the table does not exist</summary>
      <description>Making the getTableRegions Thrift API method handle TableNotFoundException and return an empty list in that case. Without this the behavior is dependent on whether an HTable object is present in the thread-local cache in case a table was deleted.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
    </fixedFiles>
  </bug>
  <bug id="6029" opendate="2012-5-17 00:00:00" fixdate="2012-5-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBCK doesn&amp;#39;t recover Balance switch if exception occurs in onlineHbck()</summary>
      <description></description>
      <version>0.94.0</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="603" opendate="2008-4-29 00:00:00" fixdate="2008-4-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>When an exception bubbles out of getRegionServerWithRetries, wrap the exception with a RetriesExhaustedException</summary>
      <description>There's always a lot of confusion about what NotServingRegionExceptions and WrongRegionExceptions mean when they come out of the client side. To help alleviate this, I propose that we create a new exception type called RetriesExhaustedException that wraps the actual thrown exception and presents it clearly as a retry issue. This will be very helpful, I think. Perhaps the exception can even take a list of the exceptions that led up to this point.</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6046" opendate="2012-5-18 00:00:00" fixdate="2012-6-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Master retry on ZK session expiry causes inconsistent region assignments.</summary>
      <description>1&gt; ZK Session timeout in the hmaster leads to bulk assignment though all the RSs are online.2&gt; While doing bulk assignment, if the master again goes down &amp; restart(or backup comes up) all the node created in the ZK will now be tried to reassign to the new RSs. This is leading to double assignment.we had 2800 regions, among this 1900 region got double assignment, taking the region count to 4700.</description>
      <version>0.92.1,0.94.0</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestZooKeeper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="6052" opendate="2012-5-18 00:00:00" fixdate="2012-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Convert .META. and -ROOT- content to pb</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.OfflineMetaRebuildTestCore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestSerialization.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestGetClosestAtOrBefore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestEndToEndSplitTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.migration.TestMigrationFrom090To092.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestZKBasedOpenCloseRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterTransitions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.Mocking.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMetaMigrationRemovingHTD.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.catalog.TestMetaReaderEditorNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.catalog.TestCatalogTracker.java</file>
      <file type="M">hbase-server.src.main.ruby.hbase.table.rb</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.Writables.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.MetaUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.Merge.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HMerge.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsckRepair.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.migration.HRegionInfo090x.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Result.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.MetaScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.catalog.MetaReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.catalog.MetaMigrationRemovingHTD.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.catalog.MetaEditor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-server.src.test.data.hbase-4388-root.dir.tgz</file>
    </fixedFiles>
  </bug>
  <bug id="6055" opendate="2012-5-18 00:00:00" fixdate="2012-2-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Offline Snapshots in HBase 0.96</summary>
      <description>Continuation of HBASE-50 for the current trunk. Since the implementation has drastically changed, opening as a new ticket.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.CheckedArchivingHFileCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.FileCleanerDelegate.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.CleanerChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.BaseLogCleanerDelegate.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.example.LongTermArchivingHFileCleaner.java</file>
    </fixedFiles>
  </bug>
  <bug id="6056" opendate="2012-5-19 00:00:00" fixdate="2012-5-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Restore hbase-default version check</summary>
      <description>Was removed by mistake.</description>
      <version>None</version>
      <fixedVersion>0.94.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HBaseConfiguration.java</file>
    </fixedFiles>
  </bug>
  <bug id="6061" opendate="2012-5-21 00:00:00" fixdate="2012-5-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix ACL "Admin" Table inconsistent permission check</summary>
      <description>the requirePermission() check for "admin" operation on a table is currently inconsistent.Table Owner with CREATE rights (that means, the owner has created that table) can enable/disable and delete the table but needs ADMIN rights to add/remove/modify a column.</description>
      <version>0.92.1,0.94.0,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug id="6062" opendate="2012-5-21 00:00:00" fixdate="2012-5-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>preCheckAndPut/Delete() checks for READ when also a WRITE is performed</summary>
      <description>preCheckAndPut() and preCheckAndDelete() checks for READ when they also want to WRITE... for me checking for WRITE permission is the right thing... what do you say about that? keep READ, replace with WRITE?</description>
      <version>0.92.1,0.94.0,0.95.2</version>
      <fixedVersion>0.92.2,0.94.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug id="6070" opendate="2012-5-23 00:00:00" fixdate="2012-5-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>AM.nodeDeleted and SSH races creating problems for regions under SPLIT</summary>
      <description>We tried to address the problems in Master restart and RS restart while SPLIT region is in progress as part of HBASE-5806.While doing some more we found still there is one race condition.-&gt; Split has just started and the znode is in RS_SPLIT state.-&gt; RS goes down.-&gt; First call back for SSH comes.-&gt; As part of the fix for HBASE-5806 SSH knows that some region is in RIT.-&gt; But now nodeDeleted event comes for the SPLIt node and there we try to delete the RIT.-&gt; After this we try to see in the SSH whether any node is in RIT. As we dont find the region in RIT the region is never assigned.When we fixed HBASE-5806 step 6 happened first and then step 5 happened. So we missed it. Now we found that. Will come up with a patch shortly.</description>
      <version>0.92.1,0.94.0</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.Mocking.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="6089" opendate="2012-5-24 00:00:00" fixdate="2012-5-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>SSH and AM.joinCluster causes Concurrent Modification exception.</summary>
      <description>AM.regions map is parallely accessed in SSH and Master initialization leading to ConcurrentModificationException.</description>
      <version>0.92.1,0.94.0</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="609" opendate="2008-4-30 00:00:00" fixdate="2008-5-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Master doesn&amp;#39;t see regionserver edits because of clock skew</summary>
      <description>The streamy folks had a cluster where regionserver was 2 minutes in advance of the master. On split, regionserver would update .META. with split info but scanners opened on the master wouldn't see the edits because they were being opened using current time.</description>
      <version>None</version>
      <fixedVersion>0.1.2,0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.master.TableOperation.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ProcessServerShutdown.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.BaseScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6120" opendate="2012-5-28 00:00:00" fixdate="2012-5-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Few logging improvements around enabling tables</summary>
      <description>Few log statements between Enable/Disable/Create table handler event classes have a typo with word "Attempting" (its misspelled "Attemping"). Even upon an enable operation's failure, the tailing message is a mere INFO with a state of 'false'. This isn't as visible as I'd like it to be when diagnosing logs for issues. I've put it in a proper if-else for this case.</description>
      <version>0.94.0</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.EnableTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DisableTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.CreateTableHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="6157" opendate="2012-6-4 00:00:00" fixdate="2012-6-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Revoke of Global permission is not taking effect without restart.</summary>
      <description>Revoke of Global permission is not taking effect without restart.Revoke is updating the acl table but it's not updating the USER_CACHE.</description>
      <version>0.94.0</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.TableAuthManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="6158" opendate="2012-6-4 00:00:00" fixdate="2012-6-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Data loss if the words &amp;#39;merges&amp;#39; or &amp;#39;splits&amp;#39; are used as Column Family name</summary>
      <description>If a table is creates with either 'merges' or 'splits' as one of the Column Family name it can never be flushed to the disk even though the table creation (and data population) succeeds.The reason for this is that these two are used as temporary directory names inside the region folder or merge and splits respectively and hence conflicts with the directories created for CF with same name.A simple fix would be to uses ".merges' and ".splits" as the working folder (patch attached). This will also be consistent with other work folder names. An alternate fix would be to declare these words (and other similar) as reserve words and throw exception when they are used. However, I do find the alternate approach as unnecessarily restrictive.</description>
      <version>0.94.0</version>
      <fixedVersion>0.92.2,0.94.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="6160" opendate="2012-6-4 00:00:00" fixdate="2012-6-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>META entries from daughters can be deleted before parent entries</summary>
      <description>HBASE-5986 fixed and issue, where the client sees the META entry for the parent, but not the children. However, after the fix, we have seen the following issue in tests: Region A is split to -&gt; B, CRegion B is split to -&gt; D, EAfter some time, META entry for B is deleted since it is not needed anymore, but META entry for Region A stays in META (C still refers it). In this case, the client throws RegionOfflineException for B.</description>
      <version>0.92.2,0.94.0,0.95.2</version>
      <fixedVersion>0.92.2,0.94.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
    </fixedFiles>
  </bug>
  <bug id="6170" opendate="2012-6-6 00:00:00" fixdate="2012-7-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Timeouts for row lock and scan should be separate</summary>
      <description>Apparently the timeout used for row locking and for scanning is global. It would be better to have two separate timeouts.(opening the issue to make Lars George happy)</description>
      <version>0.94.0</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorInterface.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannerTimeout.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Leases.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="6173" opendate="2012-6-6 00:00:00" fixdate="2012-6-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbck check specified tables only</summary>
      <description>Currently hbck can fix specified tables so that we can fix one table each time.However, it doesn't check the health of the specified tables only. It stillcheck the health of the whole system.If tables are specified, we can check the health of these tables only.</description>
      <version>None</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.HbckTestingUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="6188" opendate="2012-6-7 00:00:00" fixdate="2012-6-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove the concept of table owner</summary>
      <description>The table owner concept was a design simplification in the initial drop.First, the design changes under review means only a user with GLOBAL CREATE permission can create a table, which will probably be an administrator.Then, granting implicit permissions may lead to oversights and it adds unnecessary conditionals to our code. So instead the administrator with GLOBAL CREATE permission should make the appropriate grants at table create time.</description>
      <version>0.94.0,0.94.1,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlLists.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="62" opendate="2007-11-13 00:00:00" fixdate="2007-7-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbase] Allow user add arbitrary key/value pairs to table and column descriptors</summary>
      <description>Folks have asked if they can tag columns and tables with markings of their own designation. Examples include 'type' and 'descriptiion'.</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.util.TestMetaUtils.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.util.TestMigrate.java</file>
      <file type="M">src.testdata.HADOOP-2478-testdata.zip</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestTable.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.client.TestHTable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.Migrate.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.ThriftUtilities.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.TableHandler.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HAbstractScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HMasterInterface.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.UnmodifyableHTableDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.MetaScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.BloomFilterDescriptor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6200" opendate="2012-6-11 00:00:00" fixdate="2012-6-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>KeyComparator.compareWithoutRow can be wrong when families have the same prefix</summary>
      <description>As reported by Desert Rose on IRC and on the ML, Result has a weird behavior when some families share the same prefix. He posted a link to his code to show how it fails, http://pastebin.com/7TBA1XGhBasically KeyComparator.compareWithoutRow doesn't differentiate families and qualifiers so "f:a" is said to be bigger than "f1:", which is false. Then what happens is that the KVs are returned in the right order from the RS but then doing Result.binarySearch it uses KeyComparator.compareWithoutRow which has a different sorting so the end result is undetermined.I added some debug and I can see that the data is returned in the right order but Arrays.binarySearch returned the wrong KV, which is then verified agains the passed family and qualifier which fails so null is returned.I don't know how frequent it is for users to have families with the same prefix, but those that do have that and that use those families at the same time will have big correctness issues. This is why I mark this as a blocker.</description>
      <version>0.90.6,0.92.1,0.94.0</version>
      <fixedVersion>0.92.2,0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestKeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
    </fixedFiles>
  </bug>
  <bug id="621" opendate="2008-5-9 00:00:00" fixdate="2008-5-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make MAX_VERSIONS work like TTL: In scans and gets, check MAX_VERSIONs setting and return that many only rather than wait on compaction</summary>
      <description>HBASE-47 added specification of TTL on cells. The implementation checks cell timestamp against configured TTL before returning results scanning or getting. You can also set the maximum versions of a cell to keep. The maximum versions is not checked scanning or getting, only when we compact (We'll drop cells that are beyond the maximum version at compaction time). This issue is about adding check for maximum versions to gets and scans so that if you ask for all versions but have configured the store to only keep 3 versions, though 4 may have been inserted, you'll currently get 4 returned (if compactions have not had a chance to run).</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Memcache.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6211" opendate="2012-6-14 00:00:00" fixdate="2012-6-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Put latencies in jmx</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.metrics.TestMetricsMBeanBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.metrics.MetricsMBeanBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.metrics.histogram.MetricsHistogram.java</file>
    </fixedFiles>
  </bug>
  <bug id="6238" opendate="2012-6-19 00:00:00" fixdate="2012-6-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Grant on META not taking effect</summary>
      <description>User is not able to perform authorized operations on Meta.</description>
      <version>0.94.0,0.94.1,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlLists.java</file>
    </fixedFiles>
  </bug>
  <bug id="625" opendate="2008-5-13 00:00:00" fixdate="2008-10-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Metrics support for cluster load history: emissions and graphs</summary>
      <description>hbase should write loadings on a period in a format that is amenable to tools like ganglia (rrd). Master can dump cluster loadings and averages. Regionservers would report their own loadings. Should exploit the work up in hadoop for doing this kinda thing (GangliaContext) where it makes sense. Extra browning points if user can optionally enable display of graphs in the hbase UI (JRobin).</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.webapps.regionserver.regionserver.jsp</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.RegionManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HServerLoad.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6252" opendate="2012-6-21 00:00:00" fixdate="2012-6-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TABLE ADMIN should be allowed to relocate regions</summary>
      <description></description>
      <version>0.94.0,0.94.1,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug id="6265" opendate="2012-6-25 00:00:00" fixdate="2012-7-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Calling getTimestamp() on a KV in cp.prePut() causes KV not to be flushed</summary>
      <description>There is an issue when you call getTimestamp() on any KV handed into a Coprocessor's prePut(). It initializes the internal "timestampCache" variable. When you then pass it to the normal processing, the region server sets the time to the server time in case you have left it unset from the client side (updateLatestStamp() call). The TimeRangeTracker then calls getTimestamp() later on to see if it has to include the KV, but instead of getting the proper time it sees the cached timestamp from the prePut() call.</description>
      <version>0.92.0,0.94.0,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestKeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
    </fixedFiles>
  </bug>
  <bug id="6281" opendate="2012-6-27 00:00:00" fixdate="2012-7-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Assignment need not be called for disabling table regions during clean cluster start up.</summary>
      <description>Currently during clean cluster start up if there are tables in DISABLING state, we do bulk assignment through assignAllUserRegions() and after region is OPENED in RS, master checks if the table is in DISBALING/DISABLED state (in Am.regionOnline) and again calls unassign. This roundtrip can be avoided even before calling assignment.This JIRA is to address the above scenario.</description>
      <version>0.92.1,0.94.0</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="6285" opendate="2012-6-27 00:00:00" fixdate="2012-7-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase master should log INFO message when it attempts to assign a region</summary>
      <description>With the default logging level (INFO), it is very difficult to diagnose a large HBase cluster that is having problems assigning regions because the HBase master logs a DEBUG message when it instructs a region-server to assign a region.You actually have to crawl EVERY HBase region-server log to find out which node received the request for a particular region. Further, lets say the HBase master sends the request and something goes wrong, we might not even get a message in the region-server log.</description>
      <version>0.94.0</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="6286" opendate="2012-6-27 00:00:00" fixdate="2012-9-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade maven-compiler-plugin to 2.5.1</summary>
      <description>time mvn -PlocalTests clean install -DskipTests With 2.5.1:user1m35.634s1m31.178s1m31.366ssys0m06.540s0m05.376s0m05.488sWith 2.0.2 (current):user2m01.168s1m54.027s1m57.799ssys0m05.896s0m05.912s0m06.032s</description>
      <version>None</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.upgrading.xml</file>
      <file type="M">src.main.docbkx.developer.xml</file>
      <file type="M">src.main.docbkx.configuration.xml</file>
      <file type="M">src.main.docbkx.community.xml</file>
      <file type="M">src.main.docbkx.case.studies.xml</file>
      <file type="M">src.main.docbkx.book.xml</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-assembly.src.xslt.configuration.to.docbook.section.xsl</file>
      <file type="M">hbase-assembly.src.site.xdoc.sponsors.xml</file>
      <file type="M">hbase-assembly.src.site.xdoc.resources.xml</file>
      <file type="M">hbase-assembly.src.site.xdoc.replication.xml</file>
      <file type="M">hbase-assembly.src.site.xdoc.pseudo-distributed.xml</file>
      <file type="M">hbase-assembly.src.site.xdoc.old.news.xml</file>
      <file type="M">hbase-assembly.src.site.xdoc.metrics.xml</file>
      <file type="M">hbase-assembly.src.site.xdoc.index.xml</file>
      <file type="M">hbase-assembly.src.site.xdoc.cygwin.xml</file>
      <file type="M">hbase-assembly.src.site.xdoc.bulk-loads.xml</file>
      <file type="M">hbase-assembly.src.site.xdoc.acid-semantics.xml</file>
      <file type="M">hbase-assembly.src.site.site.xml</file>
      <file type="M">hbase-assembly.src.site.site.vm</file>
      <file type="M">hbase-assembly.src.site.resources.images.hbase.logo.svg</file>
      <file type="M">hbase-assembly.src.site.resources.images.hbase.logo.png</file>
      <file type="M">hbase-assembly.src.site.resources.images.big.h.logo.svg</file>
      <file type="M">hbase-assembly.src.site.resources.doap.Hbase.rdf</file>
      <file type="M">hbase-assembly.src.site.resources.css.site.css</file>
      <file type="M">hbase-assembly.src.site.resources.css.freebsd.docbook.css</file>
      <file type="M">hbase-assembly.src.docbkx.zookeeper.xml</file>
      <file type="M">hbase-assembly.src.docbkx.upgrading.xml</file>
      <file type="M">hbase-assembly.src.docbkx.troubleshooting.xml</file>
      <file type="M">hbase-assembly.src.docbkx.shell.xml</file>
      <file type="M">hbase-assembly.src.docbkx.security.xml</file>
      <file type="M">hbase-assembly.src.docbkx.schema.design.xml</file>
      <file type="M">hbase-assembly.src.docbkx.rpc.xml</file>
      <file type="M">hbase-assembly.src.docbkx.preface.xml</file>
      <file type="M">hbase-assembly.src.docbkx.performance.xml</file>
      <file type="M">hbase-assembly.src.docbkx.ops.mgt.xml</file>
      <file type="M">hbase-assembly.src.docbkx.getting.started.xml</file>
      <file type="M">hbase-assembly.src.docbkx.external.apis.xml</file>
      <file type="M">hbase-assembly.src.docbkx.developer.xml</file>
      <file type="M">hbase-assembly.src.docbkx.customization.xsl</file>
      <file type="M">hbase-assembly.src.docbkx.configuration.xml</file>
      <file type="M">hbase-assembly.src.docbkx.community.xml</file>
      <file type="M">hbase-assembly.src.docbkx.case.studies.xml</file>
      <file type="M">hbase-assembly.src.docbkx.book.xml</file>
      <file type="M">hbase-assembly.src.assembly.src.xml</file>
      <file type="M">hbase-assembly.src.assembly.hadoop-two-compat.xml</file>
      <file type="M">hbase-assembly.src.assembly.hadoop-one-compat.xml</file>
      <file type="M">hbase-assembly.src.assembly.components.xml</file>
      <file type="M">hbase-assembly.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6292" opendate="2012-6-29 00:00:00" fixdate="2012-6-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compact can skip the security access control</summary>
      <description>When client sends compact command to rs, the rs just create a CompactionRequest, and then put it into the thread pool to process the CompactionRequest. And when the region do the compact, it uses the rs's ugi to process the compact, so the compact can successfully done.Example:user "mapred" do not have permission "Admin",hbase(main):001:0&gt; user_permission 'Security'User Table,Family,Qualifier:Permission mapred Security,f1,c1: [Permission: actions=READ,WRITE] hbase(main):004:0&gt; put 'Security', 'r6', 'f1:c1', 'v9'0 row(s) in 0.0590 secondshbase(main):005:0&gt; put 'Security', 'r6', 'f1:c1', 'v10'0 row(s) in 0.0040 secondshbase(main):006:0&gt; compact 'Security'0 row(s) in 0.0260 secondsMaybe we can add permission check in the preCompactSelection() ?</description>
      <version>0.94.0,0.94.1,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactionRequestor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.java</file>
    </fixedFiles>
  </bug>
  <bug id="630" opendate="2008-5-20 00:00:00" fixdate="2008-5-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Default hbase.rootdir is garbage</summary>
      <description>Always writes to '/tmp/hbase-'.</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6303" opendate="2012-7-2 00:00:00" fixdate="2012-7-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HCD.setCompressionType should use Enum support for storing compression types as strings</summary>
      <description>Let's not require an update to HCD every time the HFile compression enum is changed.</description>
      <version>0.94.0,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="6308" opendate="2012-7-2 00:00:00" fixdate="2012-8-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Coprocessors should be loaded in a custom ClassLoader to prevent dependency conflicts with HBase</summary>
      <description>Currently each coprocessor is loaded with a URLClassLoader that puts the coprocessor's jar at the beginning of the classpath. The URLClassLoader always tries to load classes from the parent ClassLoader first and only attempts to load from its own configured URLs if the class was not found by the parent. This class loading behavior can be problematic for coprocessors that have common dependencies with HBase but whose versions are incompatible. For example, I have a coprocessor that depends on a different version of Avro than the version used by HBase. The current class loading behavior results in NoSuchMethodErrors in my coprocessor because some Avro classes have already been loaded by HBase, and the ClassLoader for my coprocessor picks up HBase's loaded classes first.My proposed solution to this problem is to use a custom ClassLoader when instantiating coprocessor instances. This custom ClassLoader would always attempt to load classes from the coprocessor's jar first and would only delegate to the parent ClassLoader if the class were not found in the coprocessor jar. However, certain classes would need to be exempt from this behavior. As an example, if the Copcoessor interface were loaded by both the region server's ClassLoader and the coprocessor's custom ClassLoader, then the region server would get a ClassCastException when attempting to cast the coprocessor instance to the Coprocessor interface. This problem can be avoided by defining a set of class name prefixes that would be exempt from loading by the custom ClassLoader. When loading a class, if the class starts with any of these prefixes (e.g. "org.apache.hadoop"), then the ClassLoader would delegate immediately to the parent ClassLoader.I've already implemented a patch to provide this functionality which I'll attach shortly.</description>
      <version>0.92.1,0.94.0</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestClassLoading.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorHost.java</file>
    </fixedFiles>
  </bug>
  <bug id="6312" opendate="2012-7-3 00:00:00" fixdate="2012-7-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make BlockCache eviction thresholds configurable</summary>
      <description>Some of our customers found that tuning the BlockCache eviction thresholds made test results different in their test environment. However, those thresholds are not configurable in the current implementation. The only way to change those values is to re-compile the HBase source code. We wonder if it is possible to make them configurable.</description>
      <version>0.94.0</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestLruBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.DoubleBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
    </fixedFiles>
  </bug>
  <bug id="6313" opendate="2012-7-3 00:00:00" fixdate="2012-7-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Client hangs because the client is not notified</summary>
      <description>If the call first remove from the calls, when some exception happened in reading from the DataInputStream, the call will not be notified, cause the client hangs.</description>
      <version>0.92.1,0.94.0</version>
      <fixedVersion>0.92.2,0.94.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="6314" opendate="2012-7-3 00:00:00" fixdate="2012-7-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fast fail behavior for unauthenticated user</summary>
      <description>In case of unauthenticated users in secure hbase, hbase shell does a connection retry at two levels:a) HConnection: It retries hbase.client.retries.number times in the getMaster()b) HBaseAdmin: it again retries hbase.client.retries.number times in its ctrSo, hbase shell retries square number of times of the configured setting. We can make it failfast (no retries) in case the user is not authenticated (no valid kerberos credentials).</description>
      <version>0.92.0,0.94.0,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="6327" opendate="2012-7-4 00:00:00" fixdate="2012-9-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HLog can be null when create table</summary>
      <description>As HBASE-4010 discussed, the HLog can be null.We have meet createTable failed because the no use hlog.When createHReagion, the HLog.LogSyncer is run sync(), in under layer it call the DFSClient.DFSOutputStream.sync(). Then the hlog.closeAndDelete() was called，firstly the HLog.close() will interrupt the LogSyncer, and interrupt DFSClient.DFSOutputStream.sync().The DFSClient.DFSOutputStream will store the exception and throw it when we called DFSClient.close(). The HLog.close() call the writer.close()/DFSClient.close() after interrupt the LogSyncer. And there is no catch exception for the close().So the Master throw exception to the client. There is no need to throw this exception, further， the hlog is no use.Our cluster is 0.90, the logs is attached, after "closing hlog writer", there is no log for the createTable().The trunk and 0.92, 0.94, we used just one hlog, and if the exception happends, the client will got createTable failed, but indeed ,we expect all the regions for the table can also be assigned.I will give the patch for this later.</description>
      <version>None</version>
      <fixedVersion>0.94.4,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.CreateTableHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="6336" opendate="2012-7-6 00:00:00" fixdate="2012-7-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Split point should not be equal to start row or end row</summary>
      <description>Should we allow split point equal with region's start row or end row?// if the midkey is the same as the first and last keys, then we cannot // (ever) split this region. if (this.comparator.compareRows(mk, firstKey) == 0 &amp;&amp; this.comparator.compareRows(mk, lastKey) == 0) { if (LOG.isDebugEnabled()) { LOG.debug("cannot split because midkey is the same as first or " + "last row"); }Here, I think it is a mistake.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
    </fixedFiles>
  </bug>
  <bug id="6350" opendate="2012-7-7 00:00:00" fixdate="2012-7-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Some logging improvements for RegionServer bulk loading</summary>
      <description>The current logging in the bulk loading RPC call to a RegionServer lacks some info in certain cases. For instance, I recently noticed that it is possible that IOException may be caused during bulk load file transfer (copy) off of another FS and that during the same time the client already times the socket out and thereby does not receive a thrown Exception back remotely (HBase prints a ClosedChannelException for the IPC when it attempts to send the real message, and hence the real cause is lost).Improvements around this kind of issue, wherein we could first log the IOException at the RS before sending, and a few other wording improvements are present in my patch.</description>
      <version>0.94.0</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="636" opendate="2008-5-22 00:00:00" fixdate="2008-10-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>java6 as a requirement</summary>
      <description>Make java6 a requirement running hbase. Our hand will proably be forced by hadoop making java6 a requirement (0.19?).</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
      <file type="M">src.java.overview.html</file>
    </fixedFiles>
  </bug>
  <bug id="6378" opendate="2012-7-12 00:00:00" fixdate="2012-8-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>the javadoc of setEnabledTable maybe not describe accurately</summary>
      <description>/** Sets the ENABLED state in the cache and deletes the zookeeper node. Fails silently if the node is not in enabled in zookeeper @param tableName @throws KeeperException */ public void setEnabledTable(final String tableName) throws KeeperException { setTableState(tableName, TableState.ENABLED); }When setEnabledTable occours ,It will update the cache and the zookeeper node,rather than to delete the zk node.</description>
      <version>0.94.0</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="638" opendate="2008-5-22 00:00:00" fixdate="2008-5-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Purge \r from src</summary>
      <description>Bunch of our src has carriage-returns. Remove them.</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.filter.TestWhileMatchRowFilter.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.filter.TestStopRowFilter.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.filter.TestRowFilterSet.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.filter.TestRegExpRowFilter.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.filter.TestPageRowFilter.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.filter.TestInclusiveStopRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStoreScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableOutputFormat.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.WhileMatchRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.StopRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.RowFilterSet.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.RowFilterInterface.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.RegExpRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.PageRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.InclusiveStopRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6380" opendate="2012-7-12 00:00:00" fixdate="2012-7-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>bulkload should update the store.storeSize</summary>
      <description>After bulkloading some HFiles into the Table, we found the force-split didn't work because of the MidKey == NULL. Only if we re-booted the HBase service, the force-split can work normally.</description>
      <version>0.94.0,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
    </fixedFiles>
  </bug>
  <bug id="6392" opendate="2012-7-13 00:00:00" fixdate="2012-7-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>UnknownRegionException blocks hbck from sideline big overlap regions</summary>
      <description>Before sidelining a big overlap region, hbck tries to close it and offline it at first. However, sometimes, it throws NotServingRegion or UnknownRegionException.It could be because the region is not open/assigned at all, or some other issue.We should figure out why and fix it.By the way, it's better to print out in the log the command line to bulk load back sidelined regions, if any.</description>
      <version>None</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="6397" opendate="2012-7-16 00:00:00" fixdate="2012-7-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbck] print out bulk load commands for sidelined regions if necessary</summary>
      <description>It's better to print out in the log the command line to bulk load back sidelined regions, if any.Separate it out from HBASE-6392 since it is a different issue.</description>
      <version>None</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="6405" opendate="2012-7-17 00:00:00" fixdate="2012-7-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create Hadoop compatibilty modules and Metrics2 implementation of replication metrics</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.assembly.all.xml</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationStatistics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSinkMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSink.java</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-hadoop1-compat.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6419" opendate="2012-7-18 00:00:00" fixdate="2012-9-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>PersistentMetricsTimeVaryingRate gets used for non-time-based metrics (part2 of HBASE-6220)</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.metrics.RegionServerMetrics.java</file>
    </fixedFiles>
  </bug>
  <bug id="6423" opendate="2012-7-18 00:00:00" fixdate="2012-12-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Writes should not block reads on blocking updates to memstores</summary>
      <description>We have a big data use case where we turn off WAL and have a ton of reads and writes. We found that:1. flushing a memstore takes a while (GZIP compression)2. incoming writes cause the new memstore to grow in an unbounded fashion3. this triggers blocking memstore updates4. in turn, this causes all the RPC handler threads to block on writes to that memstore5. we are not able to read during this time as RPC handlers are blockedAt a higher level, we should not hold up the RPC threads while blocking updates, and we should build in some sort of rate control.</description>
      <version>None</version>
      <fixedVersion>0.94.4,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="6460" opendate="2012-7-26 00:00:00" fixdate="2012-8-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbck "-repairHoles" usage inconsistent with "-fixHdfsOrphans"</summary>
      <description>According to the hbck's help info, shortcut - "-repairHoles" will enable "-fixHdfsOrphans" as below. -repairHoles Shortcut for -fixAssignments -fixMeta -fixHdfsHoles -fixHdfsOrphansHowever, in the implementation, the function "fsck.setFixHdfsOrphans(false);" is called in "-repairHoles". This is not consistent with the usage information.</description>
      <version>0.94.0,0.95.2</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="648" opendate="2008-5-28 00:00:00" fixdate="2008-5-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>If mapfile index is empty, run repair</summary>
      <description>Our cluster lost data. Made for some interesting scenarios in hbase. One such was empty index files (Would get an EOFException when we tried to scan or open region). HBASE-646 added checking of data, info, and index files. Tried to run repair of indexes but was doing it wrong place and wasn't first removing the broken index so it'd fail.</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStoreFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6501" opendate="2012-8-2 00:00:00" fixdate="2012-9-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Integrate with unit-testing tools of hadoop&amp;#39;s metrics2 framework</summary>
      <description>Hadoop's metrics2 framework provides handy tools to write unit-tests for metrics sources. E.g. MetricsAsserts class. We want to use that too in HBase unit-tests.Integration seems straightforward, wowever when integrating this piece we faced maven bug: http://jira.codehaus.org/browse/MRRESOURCES-53. Hence we decided to extract this into separate issue (originally was done in one of the patches of HBASE-6411).</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.metrics.MasterStatistics.java</file>
      <file type="M">hbase-hadoop2-compat.src.test.java.org.apache.hadoop.hbase.test.MetricsAssertHelperImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.metrics.MasterMetricsSourceImpl.java</file>
      <file type="M">hbase-hadoop1-compat.src.test.java.org.apache.hadoop.hbase.test.MetricsAssertHelperImpl.java</file>
      <file type="M">hbase-hadoop1-compat.src.main.java.org.apache.hadoop.hbase.master.metrics.MasterMetricsSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.test.java.org.apache.hadoop.hbase.test.MetricsAssertHelper.java</file>
    </fixedFiles>
  </bug>
  <bug id="6505" opendate="2012-8-2 00:00:00" fixdate="2012-8-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow shared RegionObserver state</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorHost.java</file>
    </fixedFiles>
  </bug>
  <bug id="6514" opendate="2012-8-6 00:00:00" fixdate="2012-8-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>unknown metrics type: org.apache.hadoop.hbase.metrics.histogram.MetricsHistogram</summary>
      <description>When trying to run a unit test that just starts up and shutdown the server the following errors occur in System.out01:10:59,874 ERROR MetricsUtil:116 - unknown metrics type: org.apache.hadoop.hbase.metrics.histogram.MetricsHistogram01:10:59,874 ERROR MetricsUtil:116 - unknown metrics type: org.apache.hadoop.hbase.metrics.histogram.MetricsHistogram01:10:59,875 ERROR MetricsUtil:116 - unknown metrics type: org.apache.hadoop.hbase.metrics.histogram.MetricsHistogram01:10:59,875 ERROR MetricsUtil:116 - unknown metrics type: org.apache.hadoop.hbase.metrics.histogram.MetricsHistogram</description>
      <version>0.92.2,0.94.0</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.metrics.MetricsMBeanBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="6524" opendate="2012-8-7 00:00:00" fixdate="2012-8-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hooks for hbase tracing</summary>
      <description>Includes the hooks that use htrace library to add dapper-like tracing to hbase.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.book.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.trace.TestHTraceHooks.java</file>
      <file type="M">hbase-server.src.main.protobuf.Tracing.proto</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.trace.SpanReceiverHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.trace.HBaseLocalFileSpanReceiver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.generated.Tracing.java</file>
      <file type="M">hbase-server.src.main.protobuf.RPC.proto</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.generated.RPCProtos.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.generated.FilterProtos.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.EnableTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DisableTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.executor.EventHandler.java</file>
      <file type="M">hbase-server.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6649" opendate="2012-8-24 00:00:00" fixdate="2012-9-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[0.92 UNIT TESTS] TestReplication.queueFailover occasionally fails [Part-1]</summary>
      <description>Have seen it twice in the recent past: http://bit.ly/MPCykB &amp; http://bit.ly/O79Dq7 .. Looking briefly at the logs hints at a pattern - in both the failed test instances, there was an RS crash while the test was running.</description>
      <version>None</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="665" opendate="2008-6-4 00:00:00" fixdate="2008-6-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>server side scanner doesn&amp;#39;t honor stop row</summary>
      <description>I have a large table. If I create a scanner with a stop row near the beginning of the table, the last hasNext call hangs for a while. If I do the same with the stop row near the end of the table, the last hasNext call is pretty quick.I suspect that the server side scanner isn't terminating early, and is actually scanning through the whole table returning nothing.</description>
      <version>None</version>
      <fixedVersion>0.1.3,0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="670" opendate="2008-6-6 00:00:00" fixdate="2008-6-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Historian deadlocks if regionserver is at global memory boundary and is hosting .META.</summary>
      <description>The global memory unit test was deadlocking because historian was trying to update .META. with flush info &amp;#8211; only the single regionserver was the one hosting the .META. and the regionserver global lock was in place while memory is full</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Flusher.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.RegionHistorian.java</file>
    </fixedFiles>
  </bug>
  <bug id="671" opendate="2008-6-6 00:00:00" fixdate="2008-6-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>New UI page displaying all regions in a table should be sorted</summary>
      <description>Sort the regions displayed in the new regions-in-a-table page</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="6716" opendate="2012-9-4 00:00:00" fixdate="2012-9-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hadoopqa is hosed</summary>
      <description>See this thread on list: http://search-hadoop.com/m/PtDLC19vEd62/%2522Looks+like+HadoopQA+is+hosed%2522&amp;subj=Looks+like+HadoopQA+is+hosed+Lots of the hadoopqa builds are failing complaining about missing dir.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  <bug id="6769" opendate="2012-9-13 00:00:00" fixdate="2012-9-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HRS.multi eats NoSuchColumnFamilyException since HBASE-5021</summary>
      <description>I think this is a pretty major usability regression, since HBASE-5021 this is what you get in the client when using a wrong family:2012-09-11 09:45:29,634 WARN org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException: Failed 1 action: DoNotRetryIOException: 1 time, servers with issues: sfor3s44:10304, at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.processBatchCallback(HConnectionManager.java:1601) at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.processBatch(HConnectionManager.java:1377) at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:916) at org.apache.hadoop.hbase.client.HTable.doPut(HTable.java:772) at org.apache.hadoop.hbase.client.HTable.put(HTable.java:747)Then you have to log on the server to understand what failed.Since everything is now a multi call, even single puts in the shell fail like this.This is present since 0.94.0Assigning to Elliott because he asked.</description>
      <version>0.94.0,0.94.1</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="6798" opendate="2012-9-17 00:00:00" fixdate="2012-9-17 01:00:00" resolution="Duplicate">
    <buginformation>
      <summary>HDFS always read checksum form meta file</summary>
      <description>I use hbase0.941 and hadoop-0.20.2-cdh3u5 version.The HBase support checksums in HBase block cache in HBASE-5074 jira.The HBase support checksums for decrease the iops of HDFS, so that HDFSdont't need to read the checksum from meta file of block file.But in hadoop-0.20.2-cdh3u5 version, BlockSender still read the metadata file even if the hbase.regionserver.checksum.verify property is ture.</description>
      <version>0.94.0,0.94.1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.performance.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6806" opendate="2012-9-18 00:00:00" fixdate="2012-9-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBASE-4658 breaks backward compatibility / example scripts</summary>
      <description>HBASE-4658 introduces the new 'attributes' argument as a non optional parameter. This is not backward compatible and also breaks the code in the example section. Resolution: Mark as 'optional'</description>
      <version>0.94.0</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">examples.thrift.Makefile</file>
      <file type="M">examples.thrift.DemoClient.rb</file>
      <file type="M">examples.thrift.DemoClient.py</file>
      <file type="M">examples.thrift.DemoClient.pl</file>
      <file type="M">examples.thrift.DemoClient.php</file>
      <file type="M">examples.thrift.DemoClient.java</file>
      <file type="M">examples.thrift.DemoClient.cpp</file>
    </fixedFiles>
  </bug>
  <bug id="6809" opendate="2012-9-18 00:00:00" fixdate="2012-9-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Deprecate Old metrics classes.</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.metrics.PersistentMetricsTimeVaryingRate.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.metrics.MetricsString.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.metrics.MetricsRate.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.metrics.MetricsMBeanBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.metrics.histogram.MetricsHistogram.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.metrics.HBaseInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.metrics.file.TimeStampingFileContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.metrics.ExactCounterMetric.java</file>
    </fixedFiles>
  </bug>
  <bug id="6868" opendate="2012-9-22 00:00:00" fixdate="2012-9-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Skip checksum is broke; are we double-checksumming by default?</summary>
      <description>The HFile contains checksums for decrease the iops, so when Hbase read HFile , that dont't need to read the checksum from meta file of HDFS. But HLog file of Hbase don't contain the checksum, so when HBase read the HLog, that must read checksum from meta file of HDFS. We could add setSkipChecksum per file to hdfs or we could write checksums into WAL if this skip checksum facility is enabled</description>
      <version>0.94.0,0.94.1</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.fs.HFileSystem.java</file>
    </fixedFiles>
  </bug>
  <bug id="6869" opendate="2012-9-23 00:00:00" fixdate="2012-9-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update our hadoop-2 to 2.0.1-alpha</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6889" opendate="2012-9-26 00:00:00" fixdate="2012-10-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Ignore source control files with apache-rat</summary>
      <description>Running 'mvn apache-rat:check' locally causes a failure because it finds the source control files, making it hard to check that you didn't include a file without a source header.</description>
      <version>None</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7045" opendate="2012-10-24 00:00:00" fixdate="2012-10-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add some comments to MVCC code</summary>
      <description>I've been digging through the MVCC/transaction code and adding some comments to help me (or others) understand quicker the next time through</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MultiVersionConsistencyControl.java</file>
    </fixedFiles>
  </bug>
  <bug id="7077" opendate="2012-10-31 00:00:00" fixdate="2012-10-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Test for: CheckAndPut should properly read MVCC</summary>
      <description>checkAndPut should integrate with MVCC, similar to how HBASE-4583 fixed appends and increments.Also need a test, here's one we could use (originally proposed in HBASE-7051):The current value of some cell is 10.I issue two concurrent requests:A) a check and put where check value = 10, put value = 11B) a put where put value = 50The only result at the end of these operations that seems reasonable to me is the value of the cell being 50. If A occurred first (ACID wise), then our values go 10-&gt;11-&gt;50. If B occurred first, then our values go 10-&gt;50 (and the checkAndPut fails)</description>
      <version>None</version>
      <fixedVersion>0.94.3,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHBase7051.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="7153" opendate="2012-11-13 00:00:00" fixdate="2012-3-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>print gc option in hbase-env.sh affects hbase zkcli</summary>
      <description>I un-commented the -verbose:gc option in hbase-env.sh, which print out the gc info.but when I use hbase zkcli to check zk, it can not connect to the server.the problem is zkcli uses "hbase org.apache.hadoop.hbase.zookeeper.ZooKeeperMainServerArg" to get the server_arg in the script hbase. when gc verbose option is open, the output of ZooKeeperMainServerArg is with gc info, which masses up with server_arg. and this is the reason stop zkcli working.I think the easiest way to fix this is to trim the gc info out of server_arg in the hbase script.</description>
      <version>0.94.0</version>
      <fixedVersion>0.98.0,0.94.6,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug id="7158" opendate="2012-11-13 00:00:00" fixdate="2012-12-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow CopyTable to identify the source cluster (for replication scenarios)</summary>
      <description>When I worked on HBASE-2195 I added a mechanism for an edit to identify its source cluster, so that replication would not bounce it back to the source.See: this.clusterId = zkHelper.getUUIDForCluster(zkHelper.getZookeeperWatcher()); in ReplicationSource, and put.setClusterId(entry.getKey().getClusterId()); in ReplicationSink.In master-master replication scenarios, it would very useful if CopyTable would identify the source cluster (by tagging each Put/Delete with the source clusterId before applying it).</description>
      <version>None</version>
      <fixedVersion>0.94.4,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.Import.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Mutation.java</file>
    </fixedFiles>
  </bug>
  <bug id="7159" opendate="2012-11-14 00:00:00" fixdate="2012-11-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade zookeeper dependency to 3.4.5</summary>
      <description>zookeeper 3.4.5 works with Oracle JDK 1.7We should upgrade to zookeeper 3.4.5 in trunk</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7244" opendate="2012-11-30 00:00:00" fixdate="2012-5-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Provide a command or argument to startup, that formats znodes if provided</summary>
      <description>Many a times I've had to, and have seen instructions being thrown, to stop cluster, clear out ZK and restart.While this is only a quick (and painful to master) fix, it is certainly nifty to some smaller cluster users but the process is far too long, roughly:1. Stop HBase2. Start zkCli.sh and connect to the right quorum3. Find and ensure the HBase parent znode from the configs (/hbase only by default)4. Run an "rmr /hbase" in the zkCli.sh shell, or manually delete each znode if on a lower version of ZK.5. Quit zkCli.sh and start HBase againPerhaps it may be useful, if the start-hbase.sh itself accepted a formatZK parameter. Such that, when you do a start-hbase.sh -formatZK, it does steps 2-4 automatically for you.For safety, we could make the formatter code ensure that no HBase instance is actually active, and skip the format process if it is. Similar to a HDFS NameNode's format, which would disallow if the name directories are locked.Would this be a useful addition for administrators? Bigtop too can provide a service subcommand that could do this.</description>
      <version>0.94.0</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug id="7526" opendate="2013-1-9 00:00:00" fixdate="2013-1-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>create table does not log the table name in audit log</summary>
      <description>If I issue a create table command - create 'test', 'f1'Then from the audit log, there is no way to identify what table was createdrequest: createTable; context: (user=th30z, scope=GLOBAL, family=, action=CREATE)</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug id="7546" opendate="2013-1-11 00:00:00" fixdate="2013-3-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Obtain a table read lock on region split operations</summary>
      <description>As discussed in the parent issue HBASE-7305, we should be coordinating between splits and table operations to ensure that they don't happen at the same time. In this issue we will acquire shared read locks for region splits.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MockRegionServerServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestTableLockManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableLockManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="7827" opendate="2013-2-12 00:00:00" fixdate="2013-3-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve the speed of Hbase Thirft Batch mutation for deletes</summary>
      <description>A batch mutate operation does both puts and deletes. Batch mutate for put uses table.put(puts) however batch mutate for delete loops over all deletes and calls table.delete for every single cell. This causes delete performance to degrade.</description>
      <version>0.94.0</version>
      <fixedVersion>0.98.0,0.94.6,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
    </fixedFiles>
  </bug>
  <bug id="792" opendate="2008-8-1 00:00:00" fixdate="2008-12-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Rewrite getClosestAtOrJustBefore; doesn&amp;#39;t scale as currently written</summary>
      <description>As currently written, as a table gets bigger, the number of rows .META. needs to keep count of grows.As written, our getClosestAtOrJustBefore, goes through every storefile and in each picks up any row that could be a possible candidate for closest before. It doesn't just get the closest from the storefile, but all keys that are closest before. Its not selective because how can it tell at the store file level which of the candidates will survive deletes that are sitting in later store files or up in memcache.So, if a store file has keys 0-10 and we ask to get the row that is closest or just before 7, it returns rows 0-7.. and so on per store file.Can bet big and slow weeding key wanted.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="8334" opendate="2013-4-12 00:00:00" fixdate="2013-4-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable essential column family support by default</summary>
      <description>Essential column family support has gone through several iterations of refinement.We should enable this feature by default.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="8427" opendate="2013-4-24 00:00:00" fixdate="2013-4-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Apache Rat is incorrectly excluding test source files</summary>
      <description>HBASE-5524 added &amp;#42;&amp;#42;/test/&amp;#42;&amp;#42; as a rat exclude. This unfortunately excludes directories like hbase-it/src/test/* from the rat checks and has allowed a few unit tests to get in without proper licenses. Tightening it to only the directory HBASE-5524 was concerned about (and fixing files with non-compliant licenses)</description>
      <version>0.92.1,0.94.0</version>
      <fixedVersion>0.98.0,0.94.7,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8939" opendate="2013-7-12 00:00:00" fixdate="2013-10-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hanging unit tests</summary>
      <description>We have hanging tests. Here's a few from this morning's review:durruti:0.95 stack$ ./dev-support/findHangingTest.sh https://builds.apache.org/job/hbase-0.95-on-hadoop2/176/consoleText % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 3300k 0 3300k 0 0 508k 0 --:--:-- 0:00:06 --:--:-- 621kHanging test: Running org.apache.hadoop.hbase.TestIOFencingHanging test: Running org.apache.hadoop.hbase.regionserver.wal.TestLogRollingAnd...durruti:0.95 stack$ ./dev-support/findHangingTest.sh http://54.241.6.143/job/HBase-TRUNK-Hadoop-2/396/consoleText % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 779k 0 779k 0 0 538k 0 --:--:-- 0:00:01 --:--:-- 559kHanging test: Running org.apache.hadoop.hbase.TestIOFencingHanging test: Running org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithAbortHanging test: Running org.apache.hadoop.hbase.client.TestFromClientSide3and....durruti:0.95 stack$ ./dev-support/findHangingTest.sh http://54.241.6.143/job/HBase-0.95/607/consoleText % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 445k 0 445k 0 0 490k 0 --:--:-- --:--:-- --:--:-- 522kHanging test: Running org.apache.hadoop.hbase.replication.TestReplicationDisableInactivePeerHanging test: Running org.apache.hadoop.hbase.master.TestAssignmentManagerHanging test: Running org.apache.hadoop.hbase.util.TestHBaseFsckHanging test: Running org.apache.hadoop.hbase.regionserver.TestStoreFileBlockCacheSummaryHanging test: Running org.apache.hadoop.hbase.IntegrationTestDataIngestSlowDeterministicand...durruti:0.95 stack$ ./dev-support/findHangingTest.sh http://54.241.6.143/job/HBase-0.95-Hadoop-2/607/consoleText % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 781k 0 781k 0 0 240k 0 --:--:-- 0:00:03 --:--:-- 244kHanging test: Running org.apache.hadoop.hbase.coprocessor.TestCoprocessorEndpointHanging test: Running org.apache.hadoop.hbase.client.TestFromClientSideHanging test: Running org.apache.hadoop.hbase.TestIOFencingHanging test: Running org.apache.hadoop.hbase.master.TestMasterFailoverBalancerPersistenceHanging test: Running org.apache.hadoop.hbase.master.TestDistributedLogSplitting</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRollAbort.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
    </fixedFiles>
  </bug>
  <bug id="8941" opendate="2013-7-12 00:00:00" fixdate="2013-8-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestAccessController.testGlobalPermissionList failed with IndexOutOfBoundsException</summary>
      <description>https://builds.apache.org/job/HBase-TRUNK/4246/testReport/junit/org.apache.hadoop.hbase.security.access/TestAccessController/testGlobalPermissionList/java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 at java.util.ArrayList.RangeCheck(ArrayList.java:547) at java.util.ArrayList.get(ArrayList.java:322) at org.apache.hadoop.hbase.security.access.TestAccessController.setUp(TestAccessController.java:188)</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.Canary.java</file>
    </fixedFiles>
  </bug>
</bugrepository>
