<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="10062" opendate="2013-12-2 00:00:00" fixdate="2013-12-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reconsider storing plaintext length in the encrypted block header</summary>
      <description>After HBASE-7544, if an HFile belongs to an encrypted family, it is encrypted on a per block basis. The encrypted blocks include the following header: // +--------------------------+ // | vint plaintext length | // +--------------------------+ // | vint iv length | // +--------------------------+ // | iv data ... | // +--------------------------+ // | encrypted block data ... | // +--------------------------+The reason for storing the plaintext length is so we can create an decryption stream over the encrypted block data and, no matter the internal details of the crypto algorithm (whether it adds padding, etc.) after reading the expected plaintext bytes we know the reader is finished. However my colleague Jerry Chen pointed out today this construction mandates the block be processed exactly that way. Storing and using the encrypted data length instead could provide more implementation flexibility down the road.</description>
      <version>None</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileEncryption.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.HFileBlockDefaultEncodingContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.HFileBlockDefaultDecodingContext.java</file>
    </fixedFiles>
  </bug>
  <bug id="9277" opendate="2013-8-20 00:00:00" fixdate="2013-8-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>REST should use listTableNames to list tables</summary>
      <description></description>
      <version>0.98.0,0.95.2,0.94.12,0.96.0</version>
      <fixedVersion>0.98.0,0.94.12,0.96.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RootResource.java</file>
    </fixedFiles>
  </bug>
  <bug id="9301" opendate="2013-8-22 00:00:00" fixdate="2013-9-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Default hbase.dynamic.jars.dir to hbase.rootdir/jars</summary>
      <description>A reasonable default for hbase.dynamic.jars.dir would be hbase.rootdir/jars so that folks aren't forced to edit their hbase-sites.xml to take advantage of the new, cool feature to load coprocessor/custom filter jars out of HDFS.</description>
      <version>0.98.0,0.95.2,0.94.12,0.96.0</version>
      <fixedVersion>0.98.0,0.94.12,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.migration.NamespaceUpgrade.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="9667" opendate="2013-9-26 00:00:00" fixdate="2013-10-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>NullOutputStream removed from Guava 15</summary>
      <description>com.google.common.io.NullOutputStream was dropped in Guava 15.0 in favor of com.google.common.io.ByteStreams.nullOutputStream() which prevents projects on this artifact from upgrading from Guava 14 to Guava 15.ERROR 2013-09-26 17:46:12,229 [hbase.master.MasterFileSystem] bootstraporg.apache.hadoop.hbase.DroppedSnapshotException: region: -ROOT-,,0 at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1608) at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1482) at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1011) at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:959) at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:930) at org.apache.hadoop.hbase.master.MasterFileSystem.bootstrap(MasterFileSystem.java:447) at org.apache.hadoop.hbase.master.MasterFileSystem.checkRootDir(MasterFileSystem.java:387) at org.apache.hadoop.hbase.master.MasterFileSystem.createInitialFileSystemLayout(MasterFileSystem.java:134) at org.apache.hadoop.hbase.master.MasterFileSystem.&lt;init&gt;(MasterFileSystem.java:119) at org.apache.hadoop.hbase.master.HMaster.finishInitialization(HMaster.java:536) at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:395) at java.lang.Thread.run(Thread.java:680)Caused by: java.lang.NoClassDefFoundError: com/google/common/io/NullOutputStream at org.apache.hadoop.hbase.io.hfile.HFileWriterV2.close(HFileWriterV2.java:374) at org.apache.hadoop.hbase.regionserver.StoreFile$Writer.close(StoreFile.java:1283) at org.apache.hadoop.hbase.regionserver.Store.internalFlushCache(Store.java:836) at org.apache.hadoop.hbase.regionserver.Store.flushCache(Store.java:747) at org.apache.hadoop.hbase.regionserver.Store$StoreFlusherImpl.flushCache(Store.java:2229) at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1583) ... 11 moreCaused by: java.lang.ClassNotFoundException: com.google.common.io.NullOutputStream at java.net.URLClassLoader$1.run(URLClassLoader.java:202) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:190) at java.lang.ClassLoader.loadClass(ClassLoader.java:306) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301) at java.lang.ClassLoader.loadClass(ClassLoader.java:247) ... 17 more</description>
      <version>0.98.0,0.94.12,0.96.1</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.metrics.ExactCounterMetric.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.EncodedDataBlock.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Result.java</file>
    </fixedFiles>
  </bug>
  <bug id="9753" opendate="2013-10-12 00:00:00" fixdate="2013-10-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Excessive readpoint checks in MemstoreScanner</summary>
      <description>Brought up by vrodionov on the mailing list. See also HBASE-9751.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.94.13,0.96.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="9755" opendate="2013-10-14 00:00:00" fixdate="2013-10-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cannot run classes in hbase-server tests jar from command line</summary>
      <description>cached_classpath.txt no longer contains references to hbase-server-version-tests.jar. This prevents to run classes under hbase-server/src/test from bin/hbase script.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-assembly.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9757" opendate="2013-10-14 00:00:00" fixdate="2013-11-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reenable fast region move in SlowDeterministicMonkey</summary>
      <description>HBASE-9338 slows down the region move CM a little so that ITBLL is green for 0.96.0 RC. We should revert the change and make sure the test is still green.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.factories.SlowDeterministicMonkeyFactory.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.ChangeEncodingAction.java</file>
    </fixedFiles>
  </bug>
  <bug id="9758" opendate="2013-10-14 00:00:00" fixdate="2013-10-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Log missing rows and their regions if ITBLL fails</summary>
      <description>Currently, when ITBLL fails, the log only shows how many rows are missing. We have to go to the MR log to find the rows. The row key is some binary string that is hard to map to a region. It will be helpful to log the missing rows in the ITBLL log and the corresponding regions that hold these rows.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
    </fixedFiles>
  </bug>
  <bug id="976" opendate="2008-10-31 00:00:00" fixdate="2008-10-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HADOOP 0.19.0 RC0 is broke; replace with HEAD of branch-0.19</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">lib.hadoop-0.19.0-RC0-test.jar</file>
      <file type="M">lib.hadoop-0.19.0-RC0-core.jar</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9784" opendate="2013-10-16 00:00:00" fixdate="2013-10-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Switch to Hadoop-2.2</summary>
      <description>Hadoop 2.2.0 is released yesterday. We should default to the GA version instead of 2.1.0-beta. I imagine we also want to do this for 0.96 as well as trunk.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9831" opendate="2013-10-24 00:00:00" fixdate="2013-11-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>&amp;#39;hbasefsck.numthreads&amp;#39; property isn&amp;#39;t passed to hbck via cmdline -D option</summary>
      <description>We use generic option way to pass 'hbasefsck.numthreads' property to 'hbase hbck', but it does not accept our new setting valuehbase hbck -D hbasefsck.numthreads=5We can still find there are threads over than 5 we already set via generic opttion[2013-10-24 09:25:02,561][pool-2-thread-6][DEBUG][org.apache.hadoop.security.UserGroupInformation]: PrivilegedAction as:hbase/spn-d-hdn1.sjdc@ISPN.TRENDMICRO.COM (auth:KERBEROS) from:sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) (UserGroupInformation.java:1430)[2013-10-24 09:25:02,562][pool-2-thread-10][DEBUG][org.apache.hadoop.security.UserGroupInformation]: PrivilegedAction as:hbase/spn-d-hdn1.sjdc@ISPN.TRENDMICRO.COM (auth:KERBEROS) from:sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) (UserGroupInformation.java:1430)[2013-10-24 09:25:02,565][pool-2-thread-13][DEBUG][org.apache.hadoop.security.UserGroupInformation]: PrivilegedAction as:hbase/spn-d-hdn1.sjdc@ISPN.TRENDMICRO.COM (auth:KERBEROS) from:sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) (UserGroupInformation.java:1430)[2013-10-24 09:25:02,566][pool-2-thread-11][DEBUG][org.apache.hadoop.security.UserGroupInformation]: PrivilegedAction as:hbase/spn-d-hdn1.sjdc@ISPN.TRENDMICRO.COM (auth:KERBEROS) from:sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) (UserGroupInformation.java:1430)[2013-10-24 09:25:02,567][pool-2-thread-9][DEBUG][org.apache.hadoop.security.UserGroupInformation]: PrivilegedAction as:hbase/spn-d-hdn1.sjdc@ISPN.TRENDMICRO.COM (auth:KERBEROS) from:sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) (UserGroupInformation.java:1430)[2013-10-24 09:25:02,568][pool-2-thread-12][DEBUG][org.apache.hadoop.security.UserGroupInformation]: PrivilegedAction as:hbase/spn-d-hdn1.sjdc@ISPN.TRENDMICRO.COM (auth:KERBEROS) from:sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) (UserGroupInformation.java:1430)[2013-10-24 09:25:02,570][pool-2-thread-7][DEBUG][org.apache.hadoop.security.UserGroupInformation]: PrivilegedAction as:hbase/spn-d-hdn1.sjdc@ISPN.TRENDMICRO.COM (auth:KERBEROS) from:sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) (UserGroupInformation.java:1430)[2013-10-24 09:25:02,571][pool-2-thread-14][DEBUG][org.apache.hadoop.security.UserGroupInformation]: PrivilegedAction as:hbase/spn-d-hdn1.sjdc@ISPN.TRENDMICRO.COM (auth:KERBEROS) from:sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) (UserGroupInformation.java:1430)</description>
      <version>0.94.12</version>
      <fixedVersion>0.98.0,0.96.1,0.94.14</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
</bugrepository>
