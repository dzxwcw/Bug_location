<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="12697" opendate="2014-12-16 00:00:00" fixdate="2014-12-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Don&amp;#39;t use RegionLocationFinder if localityCost == 0</summary>
      <description>Clusters with lots of reference files will be un-able to balance since the RegionLocationFinder tries to open every reference file.</description>
      <version>0.98.9</version>
      <fixedVersion>1.0.0,0.98.10,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.java</file>
    </fixedFiles>
  </bug>
  <bug id="12747" opendate="2014-12-22 00:00:00" fixdate="2014-2-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>IntegrationTestMTTR will OOME if launched with mvn verify</summary>
      <description>IntegrationTestMTRR will OOME if launched like:cd hbase-itmvn verify -Dit.test=IntegrationTestMTTRLinux environment, 7u67.Looks like we should bump the heap on the failsafe argline in the POM. 2014-12-22 11:24:07,725 ERROR [B.DefaultRpcServer.handler=2,queue=0,port=55672] ipc.RpcServer(2067): Unexpected throwable object java.lang.OutOfMemoryError: Java heap space at org.apache.hadoop.hbase.regionserver.MemStoreLAB$Chunk.init(MemStoreLAB.java:246) at org.apache.hadoop.hbase.regionserver.MemStoreLAB.getOrMakeChunk(MemStoreLAB.java:196) at org.apache.hadoop.hbase.regionserver.MemStoreLAB.allocateBytes(MemStoreLAB.java:114) at org.apache.hadoop.hbase.regionserver.MemStore.maybeCloneWithAllocator(MemStore.java:274) at org.apache.hadoop.hbase.regionserver.MemStore.add(MemStore.java:229) at org.apache.hadoop.hbase.regionserver.HStore.add(HStore.java:576) at org.apache.hadoop.hbase.regionserver.HRegion.applyFamilyMapToMemstore(HRegion.java:3084) at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutation(HRegion.java:2517) at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2284) at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2239) at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2243) at org.apache.hadoop.hbase.regionserver.HRegionServer.doBatchOp(HRegionServer.java:4482) at org.apache.hadoop.hbase.regionserver.HRegionServer.doNonAtomicRegionMutation(HRegionServer.java:3665) at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3554)Another minor issue: After taking the OOME, the test executor will linger indefinitely as a zombie.</description>
      <version>0.98.9</version>
      <fixedVersion>1.0.0,1.1.0,0.98.11</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-it.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="12776" opendate="2014-12-29 00:00:00" fixdate="2014-12-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>SpliTransaction: Log number of files to be split</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.0.0,0.98.10,1.1.0,0.94.27</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
    </fixedFiles>
  </bug>
  <bug id="12777" opendate="2014-12-30 00:00:00" fixdate="2014-1-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Multi-page book has broken links that work in the single-page version</summary>
      <description>Noticed this today in a few places. As an example, on this page of the multi-page book, all the links are broken (because their href attribute is rendered as empty). Meanwhile, the links are present and functional in the single-page book. Do you happen to know why this is happening, misty? I'd be happy to help you investigate, but I imagine you already know what's going on at a glance.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.configuration.xml</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="12779" opendate="2014-12-30 00:00:00" fixdate="2014-1-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>SplitTransaction: Add metrics</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.0.0,0.98.10,1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperStub.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="12793" opendate="2014-12-31 00:00:00" fixdate="2014-1-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbck] closeRegionSilentlyAndWait() should log cause of IOException and retry until hbase.hbck.close.timeout expires</summary>
      <description>This is subtask on HBASE-12131 in order to handle gracefully network partitions.</description>
      <version>1.0.0,0.98.9</version>
      <fixedVersion>1.0.0,0.98.10,1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsckRepair.java</file>
    </fixedFiles>
  </bug>
  <bug id="12804" opendate="2015-1-5 00:00:00" fixdate="2015-1-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ImportTsv fails to delete partition files created by it</summary>
      <description>fs.deleteOnExit(partitionsPath); writePartitions(job.getConfiguration(), partitionsPath, splitPoints);In the above code deleteOnExit will return without adding file in the deleteOnExit set as the file is not created till then.</description>
      <version>0.98.9</version>
      <fixedVersion>1.0.0,0.98.10,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.java</file>
    </fixedFiles>
  </bug>
  <bug id="12812" opendate="2015-1-6 00:00:00" fixdate="2015-8-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update Netty dependency to latest release</summary>
      <description>Netty version was 4.0.23.Release of august 15th. Lets update to 4.0.25 which contains some performance improvements and bug fixes.http://netty.io/news/2014/10/29/4-0-24-Final.htmlhttp://netty.io/news/2014/12/31/4-0-25-Final.html</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="12817" opendate="2015-1-7 00:00:00" fixdate="2015-1-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Data missing while scanning using PREFIX_TREE data block encoding</summary>
      <description>write a testcase like this @Test public void test() throws IOException { for (int i = 0; i &lt; 100; i++) { region.put(new Put(Bytes.toBytes("obj" + (2900 + i))).add(fam, qual1, Bytes.toBytes(i))); } region.put(new Put(Bytes.toBytes("obj299")).add(fam, qual1, Bytes.toBytes("whatever"))); region.put(new Put(Bytes.toBytes("obj29")).add(fam, qual1, Bytes.toBytes("whatever"))); region.put(new Put(Bytes.toBytes("obj2")).add(fam, qual1, Bytes.toBytes("whatever"))); region.put(new Put(Bytes.toBytes("obj3")).add(fam, qual1, Bytes.toBytes("whatever"))); region.flushcache(true); Scan scan = new Scan(Bytes.toBytes("obj29995")); RegionScanner scanner = region.getScanner(scan); List&lt;Cell&gt; cells = new ArrayList&lt;Cell&gt;(); assertFalse(scanner.next(cells)); assertArrayEquals(Bytes.toBytes("obj3"), Result.create(cells).getRow()); }use obj29995 to scan should return obj3, but obj2990 is returned.Seems a bug introduced by the fix of HBASE-11728.</description>
      <version>0.98.9</version>
      <fixedVersion>1.0.0,0.98.10,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestPrefixTree.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayReversibleScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="12887" opendate="2015-1-20 00:00:00" fixdate="2015-1-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cleanup many checkstyle errors in o.a.h.h.client</summary>
      <description>The volume of checkstyle bugs makes it difficult to find what my patch introduces. Clean some of them up.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HTableWrapper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.UnmodifyableHTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ServerStatisticTracker.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Result.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegistryFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Mutation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MultiServerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MultiAction.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MetaScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MetaCache.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTableMultiplexer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnectable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.FailureInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClusterStatusListener.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClusterConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallReversedScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientIdGenerator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
      <file type="M">hbase-annotations.src.main.java.org.apache.hadoop.hbase.classification.tools.StabilityOptions.java</file>
      <file type="M">hbase-annotations.src.main.java.org.apache.hadoop.hbase.classification.tools.RootDocProcessor.java</file>
      <file type="M">hbase-annotations.src.main.java.org.apache.hadoop.hbase.classification.tools.IncludePublicAnnotationsStandardDoclet.java</file>
      <file type="M">hbase-annotations.src.main.java.org.apache.hadoop.hbase.classification.tools.ExcludePrivateAnnotationsStandardDoclet.java</file>
      <file type="M">hbase-annotations.src.main.java.org.apache.hadoop.hbase.classification.InterfaceAudience.java</file>
    </fixedFiles>
  </bug>
  <bug id="12915" opendate="2015-1-26 00:00:00" fixdate="2015-1-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Disallow small scan with batching</summary>
      <description>If user sets batching in Scan object, ClientSmallScanner may return unexpected result because data from same row may appear in multiple Result objects but ClientSmallScanner considers different Results to correspond to different rows.Small scan with batching should be disallowed.</description>
      <version>None</version>
      <fixedVersion>1.0.0,0.98.10,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="13497" opendate="2015-4-20 00:00:00" fixdate="2015-5-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove MVCC stamps from HFile when that is safe</summary>
      <description>See discussion in HBASE-13389.The optimization was initially put in with HBASE-8166, HBASE-12600 undoes it, this will partially restores it.Instead of checking the MVCC readpoints against the oldest current scanner, we check that all are 0, if so, we do not need to write them.</description>
      <version>None</version>
      <fixedVersion>1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.StripeCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor.java</file>
    </fixedFiles>
  </bug>
  <bug id="13498" opendate="2015-4-20 00:00:00" fixdate="2015-4-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add more docs and a basic check for storage policy handling</summary>
      <description>some minor clean up: make sure our javadocs contain enough info for someone unfamiliar with HDFS storage policies to get started. add a basic test that verifies things happily continue on non-supported versions, or with non-supported policies clarify some log messages</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestFSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="18030" opendate="2017-5-11 00:00:00" fixdate="2017-6-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Per Cell TTL tags may get duplicated with increments/Append causing tags length overflow</summary>
      <description>2017-04-29 14:24:14,135 ERROR &amp;#91;B.fifo.QRpcServer.handler=49,queue=1,port=16020&amp;#93; ipc.RpcServer: Unexpected throwable object java.lang.IllegalStateException: Invalid currTagsLen -32712. Block offset: 3707853, block length: 72841, position: 0 (without header). at org.apache.hadoop.hbase.io.hfile.HFileReaderV3$ScannerV3.checkTagsLen(HFileReaderV3.java:226)I am not not using any hbase tags feature.The Increment operation from the application side is triggering this error. The same is happening when scanner is run on this table. It feels that one or more particular HFile block is corrupt (with negative tagLength).hbase(main):007:0&gt; scan 'table-name', {LIMIT=&gt;1,STARTROW=&gt;'ad:event_count:a'}Returning the resulthbase(main):008:0&gt; scan 'table-name', {LIMIT=&gt;1,STARTROW=&gt;'ad:event_count:b'}ROW COLUMN+CELL ERROR: java.io.IOException: java.lang.IllegalStateException: Invalid currTagsLen -32701. Block offset: 272031, block length: 72441, position: 32487 (without header). at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.handleException(HRegion.java:5607) at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.&lt;init&gt;(HRegion.java:5579) at org.apache.hadoop.hbase.regionserver.HRegion.instantiateRegionScanner(HRegion.java:2627) at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:2613) at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:2595) at org.apache.hadoop.hbase.regionserver.RSRpcServices.scan(RSRpcServices.java:2282) at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:32295)</description>
      <version>1.0.0,0.98.9,2.0.0</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.TagUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="8725" opendate="2013-6-10 00:00:00" fixdate="2013-3-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add total time RPC call metrics</summary>
      <description>Right now we have: queueCallTime exposes the ammount of time that a call is in the queue processCallTime exposes how long a call was processing We don't have a stat for total time. It's pretty easy to think that the two metrics might not track together so getting a total time could be useful.</description>
      <version>0.98.9</version>
      <fixedVersion>1.1.0,0.98.13,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestRpcMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServer.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSource.java</file>
    </fixedFiles>
  </bug>
</bugrepository>
