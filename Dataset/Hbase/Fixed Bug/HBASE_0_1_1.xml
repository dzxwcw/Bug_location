<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="478" opendate="2008-2-29 00:00:00" fixdate="2008-5-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>offlining of table does not run reliably</summary>
      <description>I have a table of 4 regions made w/ PE. I cannot reliably offline it. I'm using 'disable TestTable' and have traced it to ensure its not a problem in hql. What I see is that one region will get the offlined mark or maybe two.. but never all.Jim in IRC suggested that if we did the .TABLE. catalog table, offlining the entry there might be more reliable than trying to offline all regions in a table.</description>
      <version>0.1.1,0.1.2,0.2.0</version>
      <fixedVersion>0.1.2,0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.TestHBaseCluster.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Memcache.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.TableOperation.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.TableDelete.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.RetryableMetaOperation.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.RegionManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ProcessServerShutdown.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ProcessRegionClose.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ModifyColumn.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ChangeTableState.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.BaseScanner.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5430" opendate="2012-2-18 00:00:00" fixdate="2012-3-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix licenses in 0.92.1 -- RAT plugin won&amp;#39;t pass</summary>
      <description>Use the -Drelease profile to see we are missing 30 or so license. Fix.</description>
      <version>None</version>
      <fixedVersion>0.92.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="548" opendate="2008-3-27 00:00:00" fixdate="2008-4-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Tool to online single region</summary>
      <description>A sequence of events put a region offline in the middle of an online table. I was unable to get the region backon by running 'enable table'. Here is a little bit of code that I ran to bring the region back online and get the table running again. This issue is about adding it to hbase tools (A new package named 'tools'?). public static void main(String[] args) throws IOException { HBaseConfiguration c = new HBaseConfiguration(); c.set("hbase.master", args[0]); HTable t = new HTable(c, new Text(".META.")); Text row = new Text(args[1]); byte [] cell = t.get(row, new Text("info:regioninfo")); HRegionInfo info = Writables.getHRegionInfo(cell); LOG.info(info); long id = t.startUpdate(row); info.setOffline(false); t.put(id, COL_REGIONINFO, Writables.getBytes(info)); t.delete(id, COL_SERVER); t.delete(id, COL_STARTCODE); t.commit(id); }</description>
      <version>0.1.0,0.1.1,0.2.0</version>
      <fixedVersion>0.1.1,0.2.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.util.MetaUtils.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="569" opendate="2008-4-8 00:00:00" fixdate="2008-5-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>DemoClient.php</summary>
      <description>Adding DemoClient.php implementation</description>
      <version>0.1.0,0.1.1,0.1.2,0.2.0</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.examples.thrift.README.txt</file>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="573" opendate="2008-4-11 00:00:00" fixdate="2008-4-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase does not read hadoop-*.xml for dfs configuration after moving out hadoop/contrib</summary>
      <description>When HBase was in hadoop/contrib, the hbase script set both HADOOP_CONF_DIRand HBASE_CONF_DIR to CLASSPATH, so that dfs's configuration can be loadedcorrectly. However, when moved out hadoop/contrib, it only sets HBASE_CONF_DIR.I can think of several possible solutions:1) set HADOOP_CONF_DIR in hbase-env.sh, then add HADOOP_CONF_DIR to CLASSPATH as before2) Instruct user to create links for hadoop-*.xml if they want to customize some dfs settings.3) If only a small set of dfs confs are related to dfs's client, maybe they can be set via hbase-site.xml, then hbase sets these for us when create a FileSystem obj.Please see the thread "# of dfs replications when using hbase" on hbase-user@.</description>
      <version>0.1.0,0.1.1,0.1.2,0.2.0</version>
      <fixedVersion>0.1.2,0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.overview.html</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.IdentityTableMap.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.GroupingTableMap.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="574" opendate="2008-4-11 00:00:00" fixdate="2008-4-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase does not load hadoop native libs</summary>
      <description>After moving out from hadoop/contrib, the standalone release does not include hadoop native libs in hbase/lib/native while it still includes hadoop-core.jar. I think they should be included as well to improve speed for compression and decompression.</description>
      <version>0.1.0,0.1.1,0.1.2,0.2.0</version>
      <fixedVersion>0.1.2,0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug id="590" opendate="2008-4-17 00:00:00" fixdate="2008-4-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase migration tool does not get correct FileSystem or root directory if configuration is not correct.</summary>
      <description>The HBase migration tool does not validate hbase.rootdir as a valid URI that contains a scheme (e.g., file:// or hdfs://) and fails to find the root directory and the file system if hbase.rootdir is not a URI.</description>
      <version>0.1.1</version>
      <fixedVersion>0.1.2,0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.util.Migrate.java</file>
    </fixedFiles>
  </bug>
  <bug id="6082" opendate="2012-5-23 00:00:00" fixdate="2012-5-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[refGuide] adding HBck docs in RefGuide appendix</summary>
      <description>Jon pointed me to a PDF that he had put together and attached in HBASE-5634. I ported the attachment to the refGuide in the Appendix.Also, added link in Ops_Mgt.xml Tools chapter to point to the appendix.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.ops.mgt.xml</file>
      <file type="M">src.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6083" opendate="2012-5-24 00:00:00" fixdate="2012-5-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Modify old filter tests to use Junit4/no longer use HBaseTestCase</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestSingleColumnValueFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestSingleColumnValueExcludeFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestRandomRowFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestPrefixFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestPageFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestInclusiveStopFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestFilterList.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestDependentColumnFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestColumnPaginationFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestBitComparator.java</file>
    </fixedFiles>
  </bug>
  <bug id="6084" opendate="2012-5-24 00:00:00" fixdate="2012-5-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Server Load does not display correctly on the ui</summary>
      <description>The ui uses the toString method and toString does not implement it any more.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ServerLoad.java</file>
    </fixedFiles>
  </bug>
  <bug id="613" opendate="2008-5-2 00:00:00" fixdate="2008-6-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Timestamp-anchored scanning fails to find all records</summary>
      <description>If I add 3 versions of a cell and then scan across the first set of added cells using a timestamp that should only get values from the first upload, a bunch are missing (I added 100k on each of the three uploads). I thought it the fact that we set the number of cells found back to 1 in HStore when we move off current row/column but that doesn't seem to be it. I also tried upping the MAX_VERSIONs on my table and that seemed to have no effect. Need to look closer.Build a unit test because replicating on cluster takes too much time.</description>
      <version>0.1.0,0.1.1,0.1.2</version>
      <fixedVersion>0.1.3,0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.util.TestMergeTool.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestRegionRebalancing.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.MultiRegionTable.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.HBaseTestCase.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.AbstractMergeTestBase.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Memcache.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HAbstractScanner.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>
