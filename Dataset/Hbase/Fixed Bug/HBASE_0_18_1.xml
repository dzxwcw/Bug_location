<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="10392" opendate="2014-1-21 00:00:00" fixdate="2014-2-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Correct references to hbase.regionserver.global.memstore.upperLimit</summary>
      <description>As part of the awesome new HBASE-5349, a couple references to hbase.regionserver.global.memstore.upperLimit was missed. Clean those up to use the new hbase.regionserver.global.memstore.size instead.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.performance.xml</file>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HBaseConfiguration.java</file>
    </fixedFiles>
  </bug>
  <bug id="10600" opendate="2014-2-24 00:00:00" fixdate="2014-2-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HTable#batch() should perform validation on empty Put</summary>
      <description>Raised by java8964 in this thread:http://osdir.com/ml/general/2014-02/msg44384.htmlWhen an empty Put is passed in the List to HTable#batch(), there is no validation performed whereas IllegalArgumentException would have been thrown if this empty Put in the simple Put API call.Validation on empty Put should be carried out in HTable#batch().</description>
      <version>None</version>
      <fixedVersion>0.98.1,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide3.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
    </fixedFiles>
  </bug>
  <bug id="10601" opendate="2014-2-24 00:00:00" fixdate="2014-3-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade hadoop dependency to 2.3.0 release</summary>
      <description>Apache Hadoop 2.3.0 has been released.This issue is to upgrade hadoop dependency to 2.3.0</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="10604" opendate="2014-2-25 00:00:00" fixdate="2014-2-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix parseArgs javadoc</summary>
      <description>Javadoc for parseArgs is a cut&amp;past of previous method and need to be fixed. /* * Adds a region's meta information from the passed &lt;code&gt;meta&lt;/code&gt; * region. * * @param metainfo hbase:meta HRegionInfo to be updated * @param region HRegion to add to &lt;code&gt;meta&lt;/code&gt; * * @throws IOException */ private int parseArgs(String[] args) throws IOException { GenericOptionsParser parser = new GenericOptionsParser(getConf(), args); String[] remainingArgs = parser.getRemainingArgs(); if (remainingArgs.length != 3) { usage(); return -1; } tableName = TableName.valueOf(remainingArgs[0]); region1 = Bytes.toBytesBinary(remainingArgs[1]); region2 = Bytes.toBytesBinary(remainingArgs[2]); int status = 0; if (notInTable(tableName, region1) || notInTable(tableName, region2)) { status = -1; } else if (Bytes.equals(region1, region2)) { LOG.error("Can't merge a region with itself"); status = -1; } return status; }</description>
      <version>None</version>
      <fixedVersion>0.96.2,0.98.1,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.Merge.java</file>
    </fixedFiles>
  </bug>
  <bug id="11032" opendate="2014-4-18 00:00:00" fixdate="2014-4-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace deprecated methods in FileSystem with their replacements</summary>
      <description>FileStatus#isDir() is deprecated.FileStatus#isDirectory() should be called instead.Here is the list of deprecated methods in FileSystem :public String getName()public static FileSystem getNamed(String name, Configuration conf) public FSDataOutputStream createNonRecursive(Path f, boolean overwrite, int bufferSize, short replication, long blockSize, Progressable progress) throws IOException { public FSDataOutputStream createNonRecursive(Path f, FsPermission permission, boolean overwrite, int bufferSize, short replication, long blockSize, Progressable progress) throws IOException { public short getReplication(Path src) throws IOException { public boolean delete(Path f) throws IOException { public long getLength(Path f) throws IOException { public long getBlockSize(Path f) throws IOException { public long getDefaultBlockSize() {public short getDefaultReplication()Except for createNonRecursive() which doesn't have non-deprecated equivalent in DistributedFileSystem, deprecated methods are replaced with their non-deprecated counterparts.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestFSVisitor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.HFileArchiveTestingUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestExportSnapshot.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.SnapshotTestingUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.PerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRolling.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.HFileReadWriteTest.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.migration.TestUpgradeTo96.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.handler.TestTableDeleteFamilyHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.TestFileLink.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestHFileArchiving.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.example.TestZooKeeperTableArchiveClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSRegionScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.ExportSnapshot.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactionTool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.CleanerChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HLogInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.example.LongTermArchivingHFileCleaner.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.DynamicClassLoader.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.CoprocessorClassLoader.java</file>
    </fixedFiles>
  </bug>
  <bug id="1142" opendate="2009-1-20 00:00:00" fixdate="2009-2-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cleanup thrift server; remove Text and profuse DEBUG messaging</summary>
      <description>Ambiguous issue name.. sorry.The thrift server has loads of getText(..) calls. Which is a local function that checks for utf8 compliance, we don't need them anywhere, because we don't use Text anymore.There is probably other things we missed last time we updated the api, that we should also clean up while we're at it. Open to suggestions.</description>
      <version>0.18.0,0.18.1,0.19.0,0.19.1</version>
      <fixedVersion>0.19.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.ThriftUtilities.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1230" opendate="2009-3-2 00:00:00" fixdate="2009-3-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document installation of HBase on Windows</summary>
      <description>Provide documentation on how to run HBase on Windows.</description>
      <version>0.18.1,0.19.0,0.19.1,0.20.0</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.overview.html</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="900" opendate="2008-9-24 00:00:00" fixdate="2008-12-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Regionserver memory leak causing OOME during relatively modest bulk importing</summary>
      <description>I have recreated this issue several times and it appears to have been introduced in 0.2.During an import to a single table, memory usage of individual region servers grows w/o bounds and when set to the default 1GB it will eventually die with OOME. This has happened to me as well as Daniel Ploeg on the mailing list. In my case, I have 10 RS nodes and OOME happens w/ 1GB heap at only about 30-35 regions per RS. In previous versions, I have imported to several hundred regions per RS with default heap size.I am able to get past this by increasing the max heap to 2GB. However, the appearance of this in newer versions leads me to believe there is now some kind of memory leak happening in the region servers during import.</description>
      <version>0.18.1,0.19.0</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.ipc.HBaseClient.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HBaseRPCProtocolVersion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HbaseRPC.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.SoftValueSortedMap.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.SoftValueMap.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.ReferenceQueueUtil.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.HBaseMapFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.BlockFSInputStream.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.Bytes.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Memcache.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.BatchUpdate.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.BatchOperation.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HStoreKey.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="9090" opendate="2013-7-30 00:00:00" fixdate="2013-7-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>cleanup snapshot tests setup/teardown code</summary>
      <description>There's a lot of duplicated code around createTable() and loadTable() and other some stuff are done slightly different in each test (e.g. the snapshot deletion in the teardown)</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2,0.94.11</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestRestoreFlushSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestFlushSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestExportSnapshot.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.SnapshotTestingUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.cleaner.TestSnapshotFromMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotCloneIndependence.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestRestoreSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestCloneSnapshotFromClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="938" opendate="2008-10-20 00:00:00" fixdate="2008-11-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>major compaction period is not checked periodically</summary>
      <description>The major compaction period, hbase.hregion.majorcompaction, is not checked periodically. Currently, we only request major compaction when the region is open or split at which point we check whether the major compaction period is due.</description>
      <version>0.18.0,0.18.1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.util.Threads.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.MemcacheFlusher.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStoreFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">conf.hbase-env.sh</file>
    </fixedFiles>
  </bug>
  <bug id="9380" opendate="2013-8-29 00:00:00" fixdate="2013-8-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>StoreFile.Reader is not being closed on memstore flush</summary>
      <description>We are not closing the StoreFile.Reader upon memstore flush.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="994" opendate="2008-11-11 00:00:00" fixdate="2008-11-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>IPC interfaces with different versions can cause problems</summary>
      <description>This morning we ran into a situation in which some 0.2.x region servers started up and joined a 0.18.1 cluster. This 'sort of' worked in that the hrs could communicate with the master, but clients could not communicate with the 0.2 region servers because the api version changed (the master wouldn't have liked it if it had deployed root or meta there).Suggestion is that we have a single api version that gets bumped when any of the interfaces changes.</description>
      <version>0.2.1,0.18.0,0.18.1,0.19.0</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.TransactionalRegionInterface.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HRegionInterface.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HMasterRegionInterface.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HMasterInterface.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>
