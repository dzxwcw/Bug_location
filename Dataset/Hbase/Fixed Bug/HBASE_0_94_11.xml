<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="10669" opendate="2014-3-4 00:00:00" fixdate="2014-3-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbck tool] Usage is wrong for hbck tool for -sidelineCorruptHfiles option</summary>
      <description>Usage is wrong for hbck tool for -sidelineCorruptHfiles option: it is like:-sidelineCorruptHfiles Quarantine corrupted HFiles. implies -checkCorruptHfileshere in "sidelineCorruptHfiles" and "checkCorruptHfiles" small 'f' is used but actually in code it is like else if (cmd.equals("-checkCorruptHFiles")) { checkCorruptHFiles = true; } else if (cmd.equals("-sidelineCorruptHFiles")) { sidelineCorruptHFiles = true; }so if we use sidelineCorruptHfiles option for hbck then it will give error Unrecognized option:-sidelineCorruptHfiles</description>
      <version>0.94.11,0.96.0</version>
      <fixedVersion>0.96.2,0.98.1,0.99.0,0.94.18</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="10671" opendate="2014-3-4 00:00:00" fixdate="2014-11-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add missing InterfaceAudience annotations for classes in hbase-common and hbase-client modules</summary>
      <description>In this jira, we'll add missing InterfaceAudience annotations to classes in the client visible modules (hbase-client and hbase-common).Parent jira is for deciding on whether some of the classes should be private or public.</description>
      <version>None</version>
      <fixedVersion>0.99.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.ImmutableBytesWritable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.ChecksumUtil.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.util.ByteStringer.java</file>
      <file type="M">hbase-protocol.pom.xml</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.ClassFinder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.SimpleByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ReadOnlyByteRangeException.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.PrettyPrinter.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.MurmurHash3.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ExceptionUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ConcatenatedLists.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ChecksumType.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ChecksumFactory.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.BoundedCompletionService.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Base64.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.AbstractPositionedByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.AbstractByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.PBType.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.trace.SpanReceiverHost.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.trace.HBaseHTraceConfiguration.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.security.UserProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.NamespaceDescriptor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.MetaMutationAnnotation.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.LimitInputStream.java</file>
      <file type="M">hbase-annotations.src.main.java.org.apache.hadoop.hbase.classification.tools.ExcludePrivateAnnotationsStandardDoclet.java</file>
      <file type="M">hbase-annotations.src.main.java.org.apache.hadoop.hbase.classification.tools.IncludePublicAnnotationsStandardDoclet.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.Batch.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.DelegatingRetryingCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.FailureInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTableInterface.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTableMultiplexer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionAdminServiceCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RetriesExhaustedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RowTooBigException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCallerFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.ConnectionClosingException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.FailedSanityCheckException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.LockTimeoutException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.PreemptiveFastFailException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.UnknownProtocolException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.LongComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.RegexStringComparator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.DelegatingPayloadCarryingRpcController.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.IPCUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcControllerFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.ServerRpcController.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.TimeLimitedRpcController.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.KeepDeletedCells.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.InvalidQuotaSettingsException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaExceededException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.ThrottlingException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeersZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueueInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueuesClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueuesClientZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueuesZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationStateZKBase.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationTrackerZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.Permission.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.TablePermission.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.UserPermission.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.HBaseSaslRpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.token.AuthenticationTokenIdentifier.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityControllerNotReadyException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.ExportSnapshotException.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.BaseConfigurable.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.crypto.Encryption.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.hadoopbackport.ThrottledInputStream.java</file>
    </fixedFiles>
  </bug>
  <bug id="10672" opendate="2014-3-4 00:00:00" fixdate="2014-3-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Table snapshot should handle tables whose REGION_REPLICATION is greater than one</summary>
      <description>If a table has more than one region replica, then snapshot utility - take-snapshot, clone-snapshot etc crashes.</description>
      <version>None</version>
      <fixedVersion>0.99.0,hbase-10070</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.SnapshotTestingUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestRestoreSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestCloneSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ModifyRegionUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.snapshot.RegionServerSnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.MasterSnapshotVerifier.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.DisabledTableSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.CreateTableHandler.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionReplicaUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="10786" opendate="2014-3-18 00:00:00" fixdate="2014-3-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>If snapshot verification fails with &amp;#39;Regions moved&amp;#39;, the message should contain the name of region causing the failure</summary>
      <description>I was trying to find cause for test failure in https://builds.apache.org/job/PreCommit-HBASE-Build/9036//testReport/org.apache.hadoop.hbase.snapshot/TestSecureExportSnapshot/testExportRetry/ :org.apache.hadoop.hbase.snapshot.HBaseSnapshotException: org.apache.hadoop.hbase.snapshot.HBaseSnapshotException: Snapshot { ss=emptySnaptb0-1395177346656 table=testtb-1395177346656 type=FLUSH } had an error. Procedure emptySnaptb0-1395177346656 { waiting=[] done=[] } at org.apache.hadoop.hbase.master.snapshot.SnapshotManager.isSnapshotDone(SnapshotManager.java:342) at org.apache.hadoop.hbase.master.HMaster.isSnapshotDone(HMaster.java:3007) at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$2.callBlockingMethod(MasterProtos.java:40494) at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2020) at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:98) at org.apache.hadoop.hbase.ipc.FifoRpcScheduler$1.run(FifoRpcScheduler.java:73) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441) at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303) at java.util.concurrent.FutureTask.run(FutureTask.java:138) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:662)Caused by: org.apache.hadoop.hbase.snapshot.CorruptedSnapshotException via Failed taking snapshot { ss=emptySnaptb0-1395177346656 table=testtb-1395177346656 type=FLUSH } due to exception:Regions moved during the snapshot '{ ss=emptySnaptb0-1395177346656 table=testtb-1395177346656 type=FLUSH }'. expected=9 snapshotted=8:org.apache.hadoop.hbase.snapshot.CorruptedSnapshotException: Regions moved during the snapshot '{ ss=emptySnaptb0-1395177346656 table=testtb-1395177346656 type=FLUSH }'. expected=9 snapshotted=8 at org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher.rethrowException(ForeignExceptionDispatcher.java:83) at org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler.rethrowExceptionIfFailed(TakeSnapshotHandler.java:320) at org.apache.hadoop.hbase.master.snapshot.SnapshotManager.isSnapshotDone(SnapshotManager.java:332) ... 11 moreHowever, it is not clear which region caused the verification to fail.I searched for log from balancer but found none.The exception message should include region name which caused the verification to fail.</description>
      <version>None</version>
      <fixedVersion>0.98.1,0.99.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.MasterSnapshotVerifier.java</file>
    </fixedFiles>
  </bug>
  <bug id="12270" opendate="2014-10-15 00:00:00" fixdate="2014-1-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>A bug in the bucket cache, with cache blocks on write enabled</summary>
      <description>In my experiments, I have writers streaming their output to HBase. The reader powers a web page and does this scatter/gather, where it reads 1000 keys written last and passes them the the front end. With this workload, I get the exception below at the region server. Again, I am using HBAse (0.98.6.1). Any help is appreciated.2014-10-10 15:06:44,173 ERROR &amp;#91;B.DefaultRpcServer.handler=62,queue=2,port=60020&amp;#93; ipc.RpcServer: Unexpected throwable object java.lang.IllegalArgumentException at java.nio.Buffer.position(Buffer.java:236) at org.apache.hadoop.hbase.util.ByteBufferUtils.skip(ByteBufferUtils.java:434) at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.readKeyValueLen(HFileReaderV2.java:849) at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.next(HFileReaderV2.java:760) at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekAtOrAfter(StoreFileScanner.java:248) at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seek(StoreFileScanner.java:152) at org.apache.hadoop.hbase.regionserver.StoreScanner.seekScanners(StoreScanner.java:317) at org.apache.hadoop.hbase.regionserver.StoreScanner.&lt;init&gt;(StoreScanner.java:176) at org.apache.hadoop.hbase.regionserver.HStore.getScanner(HStore.java:1780) at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.&lt;init&gt;(HRegion.java:3758) at org.apache.hadoop.hbase.regionserver.HRegion.instantiateRegionScanner(HRegion.java:1950) at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1936) at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1913) at org.apache.hadoop.hbase.regionserver.HRegionServer.scan(HRegionServer.java:3157) at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:29587) at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2027) at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:108) at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:114) at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:94) at java.lang.Thread.run(Thread.java:744)</description>
      <version>0.94.11,0.98.6.1</version>
      <fixedVersion>1.0.0,0.98.10,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestCacheOnWrite.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
    </fixedFiles>
  </bug>
  <bug id="12922" opendate="2015-1-26 00:00:00" fixdate="2015-1-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Post-asciidoc conversion fix-ups part 2</summary>
      <description>I did read through large parts of the documentation and fixed what I found. Some of it is AsciiDoc stuff, some is contents, some is grammar, some typos fixed etc.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
      <file type="M">src.main.asciidoc..chapters.troubleshooting.adoc</file>
      <file type="M">src.main.asciidoc..chapters.thrift.filter.language.adoc</file>
      <file type="M">src.main.asciidoc..chapters.shell.adoc</file>
      <file type="M">src.main.asciidoc..chapters.security.adoc</file>
      <file type="M">src.main.asciidoc..chapters.schema.design.adoc</file>
      <file type="M">src.main.asciidoc..chapters.preface.adoc</file>
      <file type="M">src.main.asciidoc..chapters.performance.adoc</file>
      <file type="M">src.main.asciidoc..chapters.orca.adoc</file>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
      <file type="M">src.main.asciidoc..chapters.mapreduce.adoc</file>
      <file type="M">src.main.asciidoc..chapters.hbase.apis.adoc</file>
      <file type="M">src.main.asciidoc..chapters.getting.started.adoc</file>
      <file type="M">src.main.asciidoc..chapters.external.apis.adoc</file>
      <file type="M">src.main.asciidoc..chapters.datamodel.adoc</file>
      <file type="M">src.main.asciidoc..chapters.cp.adoc</file>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
      <file type="M">src.main.asciidoc..chapters.case.studies.adoc</file>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="12925" opendate="2015-1-26 00:00:00" fixdate="2015-1-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use acl cache for doing access control checks in prepare and clean phases of Bulkloading.</summary>
      <description>Currently, prepareBulkLoad and cleanupBulkLoad are using "hasSomeAccess", which performs scan on ACL table, instead of using TableAuthManager. Also, the method "hasSomeAccess" has a logical error, as it doesn't filter the acl scan results by the current active user. More specifically for (UserPermission userPerm: perms) { for (Action userAction: userPerm.getActions()) { if (userAction.equals(action)) { return AuthResult.allow(method, "Access allowed", requestUser, action, tableName, null, null); } } } The if clause ideally should be having something like userPerm.getUser.equals(requestUser). This issue will help us in getting rid of this problematic implementation.</description>
      <version>None</version>
      <fixedVersion>1.0.0,0.98.10</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug id="9049" opendate="2013-7-26 00:00:00" fixdate="2013-7-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Generalize ServerCallable creation to support custom callables</summary>
      <description>Currently, sever callables are instantiated via direct calls. Instead, we can use a single factory and that allows more specialized callable implementations, for instance, using a circuit-breaker pattern (or the Hystrix implementation!) to minimize attempts to contact the server.</description>
      <version>0.98.0,0.95.2,0.94.11</version>
      <fixedVersion>0.98.0,0.95.2,0.94.11</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionServerBulkLoad.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALEditsReplaySink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestAsyncProcess.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RegionCoprocessorRpcChannel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
    </fixedFiles>
  </bug>
  <bug id="9232" opendate="2013-8-15 00:00:00" fixdate="2013-8-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix javadoc warning and a few findbugs items.</summary>
      <description>Findbugs and javadoc are complaining in hadoopqa builds. Try and fix.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.TablePermission.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCaller.java</file>
    </fixedFiles>
  </bug>
  <bug id="9279" opendate="2013-8-20 00:00:00" fixdate="2013-8-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thrift should use listTableNames to list tables</summary>
      <description></description>
      <version>0.98.0,0.95.2,0.94.11,0.96.0</version>
      <fixedVersion>0.98.0,0.94.12,0.96.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
    </fixedFiles>
  </bug>
  <bug id="9343" opendate="2013-8-26 00:00:00" fixdate="2013-1-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement stateless scanner for Stargate</summary>
      <description>The current scanner implementation for scanner stores state and hence not very suitable for REST server failure scenarios. The current JIRA proposes to implement a stateless scanner. In the first version of the patch, a new resource class "ScanResource" has been added and all the scan parameters will be specified as query params. The following are the scan parametersstartrow - The start row for the scan.endrow - The end row for the scan.columns - The columns to scan. starttime, endtime - To only retrieve columns within a specific range of version timestamps,both start and end time must be specified.maxversions - To limit the number of versions of each column to be returned.batchsize - To limit the maximum number of values returned for each call to next().limit - The number of rows to return in the scan operation. More on start row, end row and limit parameters.1. If start row, end row and limit not specified, then the whole table will be scanned.2. If start row and limit (say N) is specified, then the scan operation will return N rows from the start row specified.3. If only limit parameter is specified, then the scan operation will return N rows from the start of the table.4. If limit and end row are specified, then the scan operation will return N rows from start of table till the end row. If the end row is reached before N rows ( say M and M &lt; N ), then M rows will be returned to the user.5. If start row, end row and limit (say N ) are specified and N &lt; number of rows between start row and end row, then N rows from start rowwill be returned to the user. If N &gt; (number of rows between start row and end row (say M), then M number of rows will be returned to theuser.</description>
      <version>0.94.11</version>
      <fixedVersion>0.98.0,0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestScannerResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestGetAndPutResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.TableResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.MetricsREST.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.Constants.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.Response.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.Client.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.rest.MetricsRESTSourceImpl.java</file>
      <file type="M">hbase-hadoop1-compat.src.main.java.org.apache.hadoop.hbase.rest.MetricsRESTSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.rest.MetricsRESTSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="9345" opendate="2013-8-26 00:00:00" fixdate="2013-6-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add support for specifying filters in scan</summary>
      <description>In the implementation of stateless scanner from HBase-9343, the support for specifying filters is missing. This JIRA aims to implement support for filter specification.</description>
      <version>0.94.11</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestTableScan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.TableResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RESTServlet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.Constants.java</file>
    </fixedFiles>
  </bug>
  <bug id="9347" opendate="2013-8-27 00:00:00" fixdate="2013-9-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support for enabling servlet filters for REST service</summary>
      <description>Currently there is no support for specifying filters for filtering client requests. It will be useful if filters can be configured through hbase configuration.</description>
      <version>0.94.11</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestGzipFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.HBaseRESTTestingUtility.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RESTServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.Constants.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9364" opendate="2013-8-28 00:00:00" fixdate="2013-9-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Get request with multiple columns returns partial results</summary>
      <description>When a GET request is issue for a table row with multiple columns and columns have empty qualifier like f1: , results for empty qualifiers is being ignored.</description>
      <version>0.94.11</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestRowResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.client.TestRemoteTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RowSpec.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RowResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="9375" opendate="2013-8-29 00:00:00" fixdate="2013-9-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[REST] Querying row data gives all the available versions of a column</summary>
      <description>In the hbase shell, when a user tries to get a value related to a column, hbase returns only the latest value. But using the REST API returns HColumnDescriptor.DEFAULT_VERSIONS versions by default. The behavior should be consistent with the hbase shell.</description>
      <version>0.94.11</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestRowResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RowSpec.java</file>
    </fixedFiles>
  </bug>
  <bug id="9428" opendate="2013-9-4 00:00:00" fixdate="2013-9-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Regex filters are at least an order of magnitude slower since 0.94.3</summary>
      <description>I found this issue after debugging a performance problem on an OpenTSDB cluster, it was basically unusable after an upgrade from 0.94.2 to 0.94.6. It was caused by HBASE-7279 (ping lhofhansl).The easiest way to see it is to run a simple 1 client PE:$ ./bin/hbase org.apache.hadoop.hbase.PerformanceEvaluation sequentialWrite 1Then in the shell do a filter scan (flush the table first and make sure if fits in your blockcache if you want stable numbers).Pre HBASE-7279:hbase(main):028:0&gt; scan 'TestTable', {FILTER =&gt; "(RowFilter (=, 'regexstring:0000055872') )"}ROW COLUMN+CELL 0000055872 column=info:data, timestamp=1378248850191, value=(blanked) 1 row(s) in 1.2780 secondsPost HBASE-7279hbase(main):037:0* scan 'TestTable', {FILTER =&gt; "(RowFilter (=, 'regexstring:0000055872') )"}ROW COLUMN+CELL 0000055872 column=info:data, timestamp=1378248850191, value=(blanked) 1 row(s) in 24.2940 secondsI tried a bunch of 0.94, up to 0.94.11, and the tip of 0.96. They are all slow like this.It seems that since that jira went in we do a lot more row matching, and running the regex gets super expensive.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.94.12,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.RegexStringComparator.java</file>
    </fixedFiles>
  </bug>
  <bug id="9431" opendate="2013-9-4 00:00:00" fixdate="2013-12-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Set &amp;#39;hbase.bulkload.retries.number&amp;#39; to 10 as HBASE-8450 claims</summary>
      <description>HBASE-8450 claimes 'hbase.bulkload.retries.number' is set to 10 when its still 0 (jeffreyz noticed). Fix.</description>
      <version>None</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9487" opendate="2013-9-10 00:00:00" fixdate="2013-9-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>create_namespace with property value throws error</summary>
      <description>Creating a namespace with properties fails from shell: hbase(main):002:0&gt; create_namespace 'ns1',{'PROERTY_NAME'=&gt;'PROPERTY_VALUE'}ERROR: undefined method `addProperty' for #&lt;Java::OrgApacheHadoopHbase::NamespaceDescriptor::Builder:0x71b98cbb&gt;Here is some help for this command:Create namespace; pass namespace name,and optionally a dictionary of namespace configuration.Examples:hbase&gt; create_namespace 'ns1'hbase&gt; create_namespace 'ns1', {'PROERTY_NAME'=&gt;'PROPERTY_VALUE'}</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug id="9489" opendate="2013-9-10 00:00:00" fixdate="2013-12-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add cp hooks in online merge before and after setting PONR</summary>
      <description>As we need to merge index region along with user region we need the hooks before and after setting PONR in region merge transtion.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionMergeTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionMergeTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionServerObserver.java</file>
    </fixedFiles>
  </bug>
  <bug id="949" opendate="2008-10-22 00:00:00" fixdate="2008-10-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add an HBase Manual</summary>
      <description>HBase needs a Manual. Manual can be checked in under docs and evolve as hbase does (Hopefully we get to a state where new feature can't be closed unless manual has been updated to include mention and howto). Let this issue be about adding under docs an outline with some basic getting started info. Thereafter, we can open individual issues to add "chapters" or topics.Made it a blocker on 0.20.0.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docs.src.documentation.content.xdocs.site.xml</file>
      <file type="M">docs.skin.images.rc-t-r-5-1header-2tab-unselected-3tab-unselected.png</file>
      <file type="M">docs.skin.images.rc-t-r-5-1header-2tab-selected-3tab-selected.png</file>
      <file type="M">docs.skin.images.rc-t-r-5-1header-2searchbox-3searchbox.png</file>
      <file type="M">docs.skin.images.rc-t-r-15-1body-2menu-3menu.png</file>
      <file type="M">docs.skin.images.rc-t-l-5-1header-2tab-unselected-3tab-unselected.png</file>
      <file type="M">docs.skin.images.rc-t-l-5-1header-2tab-selected-3tab-selected.png</file>
      <file type="M">docs.skin.images.rc-t-l-5-1header-2searchbox-3searchbox.png</file>
      <file type="M">docs.skin.images.rc-b-r-5-1header-2tab-selected-3tab-selected.png</file>
      <file type="M">docs.skin.images.rc-b-r-15-1body-2menu-3menu.png</file>
      <file type="M">docs.skin.images.rc-b-l-15-1body-2menu-3menu.png</file>
      <file type="M">docs.linkmap.pdf</file>
      <file type="M">docs.linkmap.html</file>
      <file type="M">docs.index.html</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9505" opendate="2013-9-11 00:00:00" fixdate="2013-9-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable replication by default</summary>
      <description>Wondering if we can enable replication by default, going to attach a patch that does it and get a QA run.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestMultiSlaveReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestMasterReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSink.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.cleaner.TestLogsCleaner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.replication.TestReplicationAdmin.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.Replication.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.replication.ReplicationAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="9577" opendate="2013-9-18 00:00:00" fixdate="2013-9-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Log process environment variable on HBase service startup</summary>
      <description>HBase services already logs information related to JVM properties and command line arguments used to start the services which have been immensely helpful to investigate issues.One thing that they do not log is the environment variables and an unintended variable in the environment could lead to a scenario not reproducible anywhere else including its original location if the service is restarted differently.We should log environment variables (excluding those which may contains credentials) on service startup with option to disable this logging.</description>
      <version>0.95.2,0.94.11</version>
      <fixedVersion>0.96.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ServerCommandLine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMasterCommandLine.java</file>
    </fixedFiles>
  </bug>
  <bug id="9607" opendate="2013-9-21 00:00:00" fixdate="2013-9-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Data loss after snapshot restore into cloned table</summary>
      <description>Take snapshot s1 of table t1 which has some dataDrop t1Clone snapshot s1 to t1Disable t1Restore s1 to t1Enable t1At this moment, scan 't1' returns nothing.</description>
      <version>0.94.11,0.96.0</version>
      <fixedVersion>0.96.0,0.94.13</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestRestoreSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper.java</file>
    </fixedFiles>
  </bug>
  <bug id="9745" opendate="2013-10-11 00:00:00" fixdate="2013-10-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Append HBASE_CLASSPATH to end of Java classpath and use another env var for prefix</summary>
      <description>HBASE-9097 changed the behavior to prefix HBASE_CLASSPATH to end of Java classpath instead of appending it. This break existing behavior (read more on HBASE-9097).We should revert to existing behavior and provide another way to prefix certain jars to the classpath.</description>
      <version>0.98.0,0.95.2,0.94.11</version>
      <fixedVersion>0.98.0,0.94.13,0.96.1,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
</bugrepository>
