<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="16824" opendate="2016-10-13 00:00:00" fixdate="2016-10-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Writer.flush() can be called on already closed streams in WAL roll</summary>
      <description>In https://issues.apache.org/jira/browse/HBASE-12074, we hit an error if an async thread calls flush on a WAL record already closed as the WAL is being rotated. This JIRA investigates if setting the new WAL record path as the first operation during WAL rotation will fix the issue.</description>
      <version>None</version>
      <fixedVersion>1.3.0,1.2.4,1.1.8,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRollingNoCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
    </fixedFiles>
  </bug>
  <bug id="1683" opendate="2009-7-22 00:00:00" fixdate="2009-7-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>OOME on master splitting logs; stuck, won&amp;#39;t go down</summary>
      <description>This is holding it up."HMaster" prio=10 tid=0x000000004048c000 nid=0x6ab0 in Object.wait() [0x0000000040d6c000..0x0000000040d6cd00] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) at java.lang.Thread.join(Unknown Source) - locked &lt;0x00007fc6d28be720&gt; (a org.apache.hadoop.hbase.master.RootScanner) at java.lang.Thread.join(Unknown Source) at org.apache.hadoop.hbase.master.RegionManager.stop(RegionManager.java:611) at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:405)Was splitting 11 logs.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HLog.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="17542" opendate="2017-1-26 00:00:00" fixdate="2017-4-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move backup system table into separate namespace</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupSystemTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupRestoreConstants.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupHFileCleaner.java</file>
    </fixedFiles>
  </bug>
  <bug id="17546" opendate="2017-1-26 00:00:00" fixdate="2017-6-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Incorrect syntax at HBase-Spark Module Examples</summary>
      <description>Corrected : Syntax errors at HBase-Spark moduleDescription: Syntax errors has been correct at HBase-Spark module examples. Spark Transformation : somewhere show() and somewhere show only, corrected to show().</description>
      <version>1.1.8</version>
      <fixedVersion>3.0.0-alpha-1,connector-1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.example.datasources.HBaseSource.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.example.datasources.DataType.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.example.datasources.AvroSource.scala</file>
    </fixedFiles>
  </bug>
  <bug id="17549" opendate="2017-1-26 00:00:00" fixdate="2017-1-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase-Spark Module : Incorrect log at println and unwanted comment code</summary>
      <description>HBase-Spark module : Corrected wrong class names referred at println statements. Rephrased Comments to appropriate lines. Unused extra comments removed.</description>
      <version>1.1.8</version>
      <fixedVersion>3.0.0-alpha-1,connector-1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.example.rdd.HBaseMapPartitionExample.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.example.rdd.HBaseForeachPartitionExample.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.example.rdd.HBaseBulkPutExample.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.example.rdd.HBaseBulkGetExample.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.example.rdd.HBaseBulkDeleteExample.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.example.hbasecontext.HBaseStreamingBulkPutExample.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.example.hbasecontext.HBaseDistributedScanExample.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.example.hbasecontext.HBaseBulkPutTimestampExample.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.example.hbasecontext.HBaseBulkPutExampleFromFile.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.example.hbasecontext.HBaseBulkPutExample.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.example.hbasecontext.HBaseBulkGetExample.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.example.hbasecontext.HBaseBulkDeleteExample.scala</file>
    </fixedFiles>
  </bug>
  <bug id="17611" opendate="2017-2-8 00:00:00" fixdate="2017-2-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thrift 2 per-call latency metrics are capped at ~ 2 seconds</summary>
      <description>Thrift 2 latency metrics are measured in nanoseconds. However, the duration used for per-method latencies is cast to an int, meaning the values are capped at 2.147 seconds. Let's use a long instead.</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift2.TestThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftHBaseServiceHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="17614" opendate="2017-2-9 00:00:00" fixdate="2017-8-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move Backup/Restore into separate module</summary>
      <description>Move all the backup code into separate hbase-backup module.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestBackupDeleteWithFailures.java</file>
      <file type="M">hbase-backup..DS.Store</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestSystemTableSnapshot.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestRestoreBoundaryTests.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestRepairAfterFailedDelete.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestRemoteRestore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestRemoteBackup.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestIncrementalBackupWithFailures.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestIncrementalBackupWithBulkLoad.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestIncrementalBackupMergeWithFailures.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestIncrementalBackupDeleteTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestIncrementalBackup.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestFullRestore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestFullBackupWithFailures.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestFullBackupSetRestoreSet.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestFullBackupSet.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestFullBackup.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestBackupSystemTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestBackupStatusProgress.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestBackupShowHistory.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestBackupRepair.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestBackupMultipleDeletes.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestBackupHFileCleaner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestBackupDescribe.java</file>
      <file type="M">hbase-assembly.pom.xml</file>
      <file type="M">hbase-assembly.src.main.assembly.hadoop-two-compat.xml</file>
      <file type="M">hbase-assembly.src.main.assembly.src.xml</file>
      <file type="M">hbase-it.pom.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupAdmin.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupClientFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupCopyJob.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupDriver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupHFileCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupMergeJob.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupRestoreConstants.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupRestoreFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupTableInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.HBackupFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupAdminImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupCommands.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupManifest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.impl.BackupSystemTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.impl.FullTableBackupClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.impl.IncrementalBackupManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.impl.IncrementalTableBackupClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.impl.RestoreTablesClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.impl.TableBackupClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.LogUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.mapreduce.MapReduceBackupCopyJob.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.mapreduce.MapReduceBackupMergeJob.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.mapreduce.MapReduceHFileSplitterJob.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.mapreduce.MapReduceRestoreJob.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.master.BackupLogCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.master.LogRollMasterProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.regionserver.LogRollBackupSubprocedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.regionserver.LogRollBackupSubprocedurePool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.regionserver.LogRollRegionServerProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.RestoreDriver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.RestoreJob.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.RestoreRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.util.BackupSet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.util.BackupUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.util.RestoreTool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.master.TestBackupLogCleaner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestBackupBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestBackupBoundaryTests.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestBackupCommandLineTool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestBackupDelete.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestBackupDeleteRestore.java</file>
    </fixedFiles>
  </bug>
  <bug id="17673" opendate="2017-2-21 00:00:00" fixdate="2017-2-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Monitored RPC Handler not shown in the WebUI</summary>
      <description>This issue has been fixed once in HBASE-14674. But, I noticed that almost all RS in our production environment still have this problem. Strange thing is that newly started servers seems do not affected. Digging for a while, then I realize the CircularFifoBuffer introduced by HBASE-10312 is the root cause. The RPC hander's monitoredTask only create once, if the server is flooded with tasks, RPC monitoredTask can be purged by CircularFifoBuffer, and then never visible in WebUI.So my solution is creating a list for RPC monitoredTask separately. It is OK to do so since the RPC handlers remain in a fixed number. It won't increase or decrease during the lifetime of the server.</description>
      <version>3.0.0-alpha-1,1.2.4,1.1.8,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.monitoring.TestTaskMonitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.TaskMonitor.java</file>
    </fixedFiles>
  </bug>
  <bug id="17705" opendate="2017-2-28 00:00:00" fixdate="2017-7-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure execution must fail fast if procedure is not registered</summary>
      <description>The issue was discovered during backup testing and described here:https://issues.apache.org/jira/browse/HBASE-14123?focusedCommentId=15886712&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15886712If procedure is not registered, client will be retrying until max attempts reached. The Master should throw DoNotRetryIOException and client RPC should handle this.</description>
      <version>None</version>
      <fixedVersion>2.0.0-alpha-2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="17718" opendate="2017-3-2 00:00:00" fixdate="2017-3-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Difference between RS&amp;#39;s servername and its ephemeral node cause SSH stop working</summary>
      <description>After HBASE-9593, RS put up an ephemeral node in ZK before reporting for duty. But if the hosts config (/etc/hosts) is different between master and RS, RS's serverName can be different from the one stored the ephemeral zk node. The email metioned in HBASE-13753 (http://mail-archives.apache.org/mod_mbox/hbase-user/201505.mbox/%3CCANZDn9ueFEEuZMx=pZdmtLsdGLyZz=rrm1N6EQvLswYc1z-H=g@mail.gmail.com%3E) is exactly what happened in our production env. But what the email didn't point out is that the difference between serverName in RS and zk node can cause SSH stop to work. as we can see from the code in RegionServerTracker @Override public void nodeDeleted(String path) { if (path.startsWith(watcher.rsZNode)) { String serverName = ZKUtil.getNodeName(path); LOG.info("RegionServer ephemeral node deleted, processing expiration [" + serverName + "]"); ServerName sn = ServerName.parseServerName(serverName); if (!serverManager.isServerOnline(sn)) { LOG.warn(serverName.toString() + " is not online or isn't known to the master."+ "The latter could be caused by a DNS misconfiguration."); return; } remove(sn); this.serverManager.expireServer(sn); } }The server will not be processed by SSH/ServerCrashProcedure. The regions on this server will not been assigned again until master restart or failover.I know HBASE-9593 was to fix the issue if RS report to duty and crashed before it can put up a zk node. It is a very rare case(And controllable， just fix the bug making rs to crash). But The issue I metioned can happened more often(and uncontrollable, can't be fixed in HBase, due to DNS, hosts config, etc.) and have more severe consequence.So here I offer some solutions to discuss:1. Revert HBASE-9593 from all branches, Andrew Purtell has reverted it in branch-0.982. Abort RS if master return a different name, otherwise SSH can't work properly3. Master accepts whatever servername reported by RS and don't change it.4.correct the zk node if master return another name( idea from Ted Yu)</description>
      <version>1.2.4,1.1.8,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestServerCrashProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMasterProcedureEvents.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRSKilledWhenInitializing.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.DrainingServerTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="17853" opendate="2017-3-30 00:00:00" fixdate="2017-9-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Link to "Why does HBase care about /etc/hosts?" does not work</summary>
      <description>when we go to the webpage in the link, https://hbase.apache.org/book.html#quickstart, there is a text as below."Prior to HBase 0.94.x, HBase expected the loopback IP address to be 127.0.0.1. Ubuntu and some other distributions default to 127.0.1.1 and this will cause problems for you. See Why does HBase care about /etc/hosts? for detail".The web link provided for the text "Why does HBase care about /etc/hosts?" does not work.</description>
      <version>1.1.8</version>
      <fixedVersion>2.0.0-alpha-3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.getting.started.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="19355" opendate="2017-11-28 00:00:00" fixdate="2017-11-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Missing dependency on hbase-zookeeper module causes CopyTable to fail</summary>
      <description>Romil reported seeing the following error when running CopyTable:2017-11-27 23:14:38,003 INFO [main] mapreduce.Job: Task Id : attempt_1511805117287_0023_m_000000_1, Status : FAILEDError: java.lang.ClassNotFoundException: org.apache.hadoop.hbase.zookeeper.ZKWatcher at java.net.URLClassLoader.findClass(URLClassLoader.java:381) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at org.apache.hadoop.hbase.mapreduce.Import$Importer.setup(Import.java:614) at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143) at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:794) at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342) at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:422) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1962) at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)This was due to missing dependency on hbase-zookeeper module.Once dependency is added through ZKWatcher.class, the CopyTable job can succeed.</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
      <file type="M">hbase-mapreduce.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="19357" opendate="2017-11-28 00:00:00" fixdate="2017-12-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bucket cache no longer L2 for LRU cache</summary>
      <description>When Bucket cache is used, by default we dont configure it as an L2 cache alone. The default setting is combined mode ON where the data blocks to Bucket cache and index/bloom blocks go to LRU cache. But there is a way to turn this off and make LRU as L1 and Bucket cache as a victim handler for L1. It will be just L2. After the off heap read path optimization Bucket cache is no longer slower compared to L1. We have test results on data sizes from 12 GB. The Alibaba use case was also with 12 GB and they have observed a ~30% QPS improve over the LRU cache.This issue is to remove the option for combined mode = false. So when Bucket cache is in use, data blocks will go to it only and LRU will get only index /meta/bloom blocks. Bucket cache will no longer be configured as a victim handler for LRU.Note : WHen external cache is in use, there only the L1 L2 thing comes. LRU will be L1 and external cache act as its L2. That make full sense.</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHeapMemoryManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestLruBlockCache.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestCacheOnWrite.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestCacheConfig.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.bucket.TestBucketCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSTableDescriptors.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HeapMemoryManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.util.MemorySizeUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.InclusiveCombinedBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.BlockCache.java</file>
      <file type="M">hbase-external-blockcache.src.main.java.org.apache.hadoop.hbase.io.hfile.MemcachedBlockCache.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestImmutableHColumnDescriptor.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestColumnFamilyDescriptorBuilder.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.TableDescriptorBuilder.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ColumnFamilyDescriptorBuilder.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ColumnFamilyDescriptor.java</file>
    </fixedFiles>
  </bug>
</bugrepository>
