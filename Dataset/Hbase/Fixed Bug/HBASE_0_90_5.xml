<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="3170" opendate="2010-10-29 00:00:00" fixdate="2010-1-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RegionServer confused about empty row keys</summary>
      <description>I'm no longer sure about the expected behavior when using an empty row key (e.g. a 0-byte long byte array). I assumed that this was a legitimate row key, just like having an empty column qualifier is allowed. But it seems that the RegionServer considers the empty row key to be whatever the first row key is.Version: 0.89.20100830, r0da2890b242584a8a5648d83532742ca7243346b, Sat Sep 18 15:30:09 PDT 2010hbase(main):001:0&gt; scan 'tsdb-uid', {LIMIT =&gt; 1}ROW COLUMN+CELL \x00 column=id:metrics, timestamp=1288375187699, value=foo \x00 column=id:tagk, timestamp=1287522021046, value=bar \x00 column=id:tagv, timestamp=1288111387685, value=qux 1 row(s) in 0.4610 secondshbase(main):002:0&gt; get 'tsdb-uid', ''COLUMN CELL id:metrics timestamp=1288375187699, value=foo id:tagk timestamp=1287522021046, value=bar id:tagv timestamp=1288111387685, value=qux 3 row(s) in 0.0910 secondshbase(main):003:0&gt; get 'tsdb-uid', "\000"COLUMN CELL id:metrics timestamp=1288375187699, value=foo id:tagk timestamp=1287522021046, value=bar id:tagv timestamp=1288111387685, value=qux 3 row(s) in 0.0550 secondsThis isn't a parsing problem with the command-line of the shell. I can reproduce this behavior both with plain Java code and with my asynchbase client.Since I don't actually have a row with an empty row key, I expected that the first get would return nothing.</description>
      <version>0.89.20100621,0.89.20100924,0.90.0,0.90.1,0.90.2,0.90.3,0.90.4,0.90.5,0.90.6,0.92.0,0.92.1</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide3.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
    </fixedFiles>
  </bug>
  <bug id="3443" opendate="2011-1-13 00:00:00" fixdate="2011-4-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ICV optimization to look in memstore first and then store files (HBASE-3082) does not work when deletes are in the mix</summary>
      <description>For incrementColumnValue() HBASE-3082 adds an optimization to check memstores first, and only if not present in the memstore then check the store files. In the presence of deletes, the above optimization is not reliable.If the column is marked as deleted in the memstore, one should not look further into the store files. But currently, the code does so.Sample test code outline:admin.createTable(desc)table = HTable.new(conf, tableName)table.incrementColumnValue(Bytes.toBytes("row"), cf1name, Bytes.toBytes("column"), 5);admin.flush(tableName)sleep(2)del = Delete.new(Bytes.toBytes("row"))table.delete(del)table.incrementColumnValue(Bytes.toBytes("row"), cf1name, Bytes.toBytes("column"), 5);get = Get.new(Bytes.toBytes("row"))keyValues = table.get(get).raw()keyValues.each do |keyValue| puts "Expect 5; Got Value=#{Bytes.toLong(keyValue.getValue())}";endThe above prints:Expect 5; Got Value=10</description>
      <version>0.90.0,0.90.1,0.90.2,0.90.3,0.90.4,0.90.5,0.90.6,0.92.0,0.92.1</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="3444" opendate="2011-1-14 00:00:00" fixdate="2011-10-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Test to prove Bytes.toBytesBinary and Bytes.toStringBinary() is reversible</summary>
      <description>Bytes.toStringBinary() doesn't escape \.Otherwise the transformation isn't reversiblebyte[] a = {'\', 'x' , '0', '0'}Bytes.toBytesBinary(Bytes.toStringBinary(a)) won't be equal to a</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestBytes.java</file>
    </fixedFiles>
  </bug>
  <bug id="4269" opendate="2011-8-29 00:00:00" fixdate="2011-8-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add tests and restore semantics to TableInputFormat/TableRecordReader</summary>
      <description>HBASE-4196 Modified the semantics of failures in TableImportFormat/TableRecordReader, and had no tests cases. This patch restores semantics to rethrow when a DoNotRetryIOException is triggered and adds test cases.</description>
      <version>0.90.5,0.92.0</version>
      <fixedVersion>0.90.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapred.TableRecordReaderImpl.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4375" opendate="2011-9-12 00:00:00" fixdate="2011-9-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbck] Add region coverage visualization to hbck</summary>
      <description>After HBASE-4322 and HBASE-4321, we now have an accurate region splits / coverage map for properly identifying holes, overlaps, backwards regions and other kinds of problems in the .META. table. hbck should display this information so that someone can fix this.A simple version for a table with regions &amp;#91;,A&amp;#93;, &amp;#91;A,B&amp;#93;, &amp;#91;A,C&amp;#93;, &amp;#91;C,&amp;#93; and would dump out something like this (showing an overlap in &amp;#91;A,B&amp;#93;): &amp;#91;&amp;#39;table,,..&amp;#39;, &amp;#39;table,A,..&amp;#39;&amp;#93;A: &amp;#91;&amp;#39;table,A,..&amp;#39;, &amp;#39;B&amp;#39;&amp;#93; &amp;#91;&amp;#39;table,A,..&amp;#39;, &amp;#39;C&amp;#39;&amp;#93;B: &amp;#91;&amp;#39;table,A,..&amp;#39;, &amp;#39;C&amp;#39;&amp;#93; C: &amp;#91;&amp;#39;table,C&amp;#39;, &amp;#39;&amp;#39;&amp;#93;null:My first thought is '-details' should this dump the full region map including all good and bad regions. Without -details, any errors should dump info with some context &amp;#8211; dump one region before problems, problem regions, and then one post problem region.Alternately we could add a new option or options to dump the region split map.What is the preferred way to toggle display of this information in hbck?</description>
      <version>0.90.5,0.94.0</version>
      <fixedVersion>0.90.5</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4379" opendate="2011-9-13 00:00:00" fixdate="2011-7-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbck] Does not complain about tables with no end region [Z,]</summary>
      <description>hbck does not detect or have an error condition when the last region of a table is missing (end key != '').</description>
      <version>0.90.5,0.92.0,0.94.0,0.95.2</version>
      <fixedVersion>0.92.2,0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.hbck.TableIntegrityErrorHandlerImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.hbck.TableIntegrityErrorHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="4403" opendate="2011-9-14 00:00:00" fixdate="2011-3-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Adopt interface stability/audience classifications from Hadoop</summary>
      <description>As HBase gets more widely used, we need to be more explicit about which APIs are stable and not expected to break between versions, which APIs are still evolving, etc. We also have many public classes that are really internal to the RS or Master and not meant to be used by users. Hadoop has adopted a classification scheme for audience (public, private, or limited-private) as well as stability (stable, evolving, unstable). I think we should copy these annotations to HBase and start to classify our public classes.</description>
      <version>0.90.5,0.92.0</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.Row.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.MiniHBaseCluster.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperNodeTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperListener.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKTable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKSplitLog.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKServerTool.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKLeaderManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKConfig.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKAssign.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.SchemaChangeTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.RootRegionTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.RegionServerTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.MetaNodeTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.MasterSchemaChangeTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.HQuorumPeer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.DrainingServerTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ClusterStatusTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ClusterId.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ZooKeeperConnectionException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.YouAreDeadException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.VersionAnnotation.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.Writables.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.VersionInfo.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.Threads.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.Strings.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.SortedCopyOnWriteSet.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.SoftValueSortedMap.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.Sleeper.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.ServerCommandLine.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.RetryCounterFactory.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.RetryCounter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.RegionSplitter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.RegionSplitCalculator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.ProtoUtil.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.PoolMap.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.PairOfSameType.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.Pair.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.Objects.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.MurmurHash.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.Methods.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.MetaUtils.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.Merge.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.MD5Hash.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.ManualEnvironmentEdge.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.KeyRange.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.Keying.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.JvmVersion.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.JVMClusterUtil.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.JenkinsHash.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.InfoServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.IncrementingEnvironmentEdge.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.IdLock.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HMerge.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.hbck.OfflineMetaRepair.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HBaseFsckRepair.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HBaseConfTool.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HasThread.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HashedBytes.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.Hash.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.FSTableDescriptors.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.FSMapRUtils.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.FSHDFSUtils.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.FileSystemVersionException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.EnvironmentEdgeManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.EnvironmentEdge.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.DirectMemoryUtils.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.DefaultEnvironmentEdge.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.CompressionTest.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.CompoundBloomFilterWriter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.CompoundBloomFilterBase.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.CompoundBloomFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.CollectionBackedScanner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.ClassSize.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.Classes.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.CancelableProgressable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.Bytes.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.ByteBufferUtils.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.ByteBufferOutputStream.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.ByteBloomFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.BloomFilterWriter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.BloomFilterFactory.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.BloomFilterBase.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.BloomFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.Base64.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.Addressing.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.AbstractHBaseTool.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.UnknownScannerException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.UnknownRowLockException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.UnknownRegionException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.thrift.ThriftUtilities.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.thrift.ThriftMetrics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.thrift.TBoundedThreadPoolServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.thrift.HThreadedSelectorServerArgs.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.thrift.HbaseHandlerMetricsProxy.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.thrift.CallQueue.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.thrift2.ThriftUtilities.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.thrift2.ThriftHBaseServiceHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.TableNotFoundException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.TableNotEnabledException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.TableNotDisabledException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.TableExistsException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.TableDescriptors.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.Stoppable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ServerName.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.Server.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.security.User.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.security.TokenInfo.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.security.KerberosInfo.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.VersionResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.TableResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.StorageClusterVersionResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.StorageClusterStatusResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.SchemaResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.ScannerResultGenerator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.ScannerResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.ScannerInstanceResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.RowSpec.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.RowResultGenerator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.RowResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.RootResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.ResultGenerator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.RESTServlet.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.ResourceConfig.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.ResourceBase.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.RegionsResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.provider.producer.ProtobufMessageBodyProducer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.provider.producer.PlainTextMessageBodyProducer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.provider.JAXBContextResolver.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.provider.consumer.ProtobufMessageBodyConsumer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.ProtobufMessageHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.MultiRowResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.model.VersionModel.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.model.TableSchemaModel.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.model.TableRegionModel.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.model.TableModel.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.model.TableListModel.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.model.TableInfoModel.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.model.StorageClusterVersionModel.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.model.StorageClusterStatusModel.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.model.ScannerModel.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.model.RowModel.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.model.ColumnSchemaModel.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.model.CellSetModel.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.model.CellModel.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.metrics.RESTStatistics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.metrics.RESTMetrics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.Main.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.filter.GZIPResponseWrapper.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.filter.GZIPResponseStream.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.filter.GZIPRequestWrapper.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.filter.GZIPRequestStream.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.filter.GzipFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.ExistsResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.Constants.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.client.Response.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.client.RemoteAdmin.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.client.Cluster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.client.Client.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.replication.ReplicationZookeeper.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationStatistics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceMetrics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceInterface.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSinkMetrics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSink.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.replication.regionserver.Replication.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.RemoteExceptionHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.WrongRegionException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALEdit.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALCoprocessorHost.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALActionsListener.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.OrphanHLogAfterSplitException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogPrettyPrinter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogKey.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.FailedLogCloseException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.TimeRangeTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.StoreFlusher.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.SplitRequest.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.SplitLogWorker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.ShutdownHook.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.ScanWildcardColumnTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.ScanQueryMatcher.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.ScanDeleteTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.RSStatusServlet.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.RSDumpServlet.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.ReplicationSourceService.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.ReplicationSinkService.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.ReplicationService.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.RegionSplitPolicy.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerStoppedException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerServices.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerRunningException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerAccounting.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.RegionScanner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.RegionOpeningState.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.OperationStatus.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.OnlineRegions.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.NonLazyKeyValueScanner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.MultiVersionConsistencyControl.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.metrics.SchemaMetrics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.metrics.SchemaConfigured.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.metrics.RegionServerStatistics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.metrics.RegionServerMetrics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.metrics.RegionServerDynamicStatistics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.metrics.RegionServerDynamicMetrics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreLAB.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.MemStore.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.LruHashMap.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.LogRoller.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.Leases.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.LeaseListener.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.LeaseException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.KeyValueSkipListSet.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.KeyValueScanner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.KeyValueHeap.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.KeyPrefixRegionSplitPolicy.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.InternalScanner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.InternalScan.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionThriftServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenRootHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenMetaHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseRootHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseMetaHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.GetClosestRowBeforeTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.FlushRequester.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.ExplicitColumnTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.DeleteTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.DebugPrint.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactSelection.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionProgress.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.CompactionRequestor.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.ColumnTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.ColumnCount.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.ChangedReadersObserver.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.RegionException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.PleaseHoldException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.NotServingRegionException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.NotAllMetaRegionsOnlineException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.monitoring.ThreadMonitoring.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.monitoring.TaskMonitor.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.monitoring.StateDumpServlet.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.monitoring.MonitoredTask.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.monitoring.MonitoredRPCHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.monitoring.MemoryBoundedLogMessageBuffer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.monitoring.LogMonitoring.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.migration.HRegionInfo090x.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.metrics.PersistentMetricsTimeVaryingRate.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.metrics.MetricsString.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.metrics.MetricsRate.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.metrics.MetricsMBeanBase.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.metrics.HBaseInfo.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.metrics.file.TimeStampingFileContext.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.UnAssignCallable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.TimeToLiveLogCleaner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.ServerAndLoad.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.RegionPlan.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.metrics.MasterStatistics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.metrics.MasterMetrics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.MasterStatusServlet.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.MasterDumpServlet.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.MasterCoprocessorHost.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.LogCleanerDelegate.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.LogCleaner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.LoadBalancerFactory.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.LoadBalancer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMasterCommandLine.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.TotesHRegionInfo.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.TableModifyFamilyHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.TableEventHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.TableDeleteFamilyHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.TableAddFamilyHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.SplitRegionHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.OpenedRegionHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.ModifyTableHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.MetaServerShutdownHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.EnableTableHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.DisableTableHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.DeleteTableHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.CreateTableHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.ClosedRegionHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.DefaultLoadBalancer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.DeadServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.BulkReOpen.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.BulkAssigner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignCallable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.ActiveMasterManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.MasterNotRunningException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.MasterAddressTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.TsvImporterMapper.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.TableSplit.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.TableReducer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.TableRecordReader.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.TableOutputFormat.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.TableOutputCommitter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapper.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormat.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.SimpleTotalOrderPartitioner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.RowCounter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.PutSortReducer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.MultiTableOutputFormat.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.KeyValueSortReducer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.ImportTsv.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.Import.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.IdentityTableReducer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.IdentityTableMapper.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.HRegionPartitioner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.HFileOutputFormat.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.GroupingTableMapper.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.Export.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.Driver.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.CopyTable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.CellCounter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.LocalHBaseCluster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.WritableRpcEngine.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.VersionedProtocol.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.Status.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.ServerNotRunningYetException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.RpcEngine.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.ResponseFlag.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.RequestContext.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.ProtocolSignature.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.Invocation.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HRegionInterface.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HMasterRegionInterface.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HMasterInterface.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HBaseServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HBaseRPCStatistics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HBaseRpcMetrics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HBaseRPCErrorHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HBaseRPC.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HBaseClient.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.ExecRPCInvoker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.Delayable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.CoprocessorProtocol.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.ConnectionHeader.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.WritableWithSize.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.TimeRange.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.Reference.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.ImmutableBytesWritable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.slab.SlabItemActionWatcher.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.slab.SlabCache.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.slab.Slab.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.slab.SingleSizeCache.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.SimpleBlockCache.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.ReusableStreamGzipCodec.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.NoOpDataBlockEncoder.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.InvalidHFileException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.InlineBlockWriter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFileWriterV2.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFileWriterV1.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFileScanner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderV2.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderV1.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoderImpl.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoder.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFile.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.DoubleBlockCache.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.Compression.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.CacheStats.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.CachedBlockQueue.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.CachedBlock.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.CacheableDeserializer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.Cacheable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.BoundedRangeFileInputStream.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.BlockType.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.BlockCacheKey.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.BlockCacheColumnFamilySummary.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.BlockCache.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.AbstractHFileWriter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.AbstractHFileReader.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.HeapSize.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.HbaseObjectWritable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.HbaseMapWritable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.HalfStoreFileReader.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.encoding.PrefixKeyDeltaEncoder.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.encoding.FastDiffDeltaEncoder.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.encoding.EncoderBufferTooSmallException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.encoding.EncodedDataBlock.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.encoding.DiffKeyDeltaEncoder.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.encoding.DataBlockEncoding.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.encoding.DataBlockEncoder.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.encoding.CopyKeyDataBlockEncoder.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.encoding.CompressionState.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.DoubleOutputStream.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.DataOutputOutputStream.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.CodeToClassAndBack.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.InvalidFamilyOperationException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HServerLoad.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HRegionLocation.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HDFSBlocksDistribution.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HBaseConfiguration.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.WritableByteArrayComparable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.WhileMatchFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.ValueFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.TimestampsFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.SubstringComparator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.SkipFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.SingleColumnValueFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.SingleColumnValueExcludeFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.RowFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.RegexStringComparator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.RandomRowFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.QualifierFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.PrefixFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.ParseFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.ParseConstants.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.PageFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.NullComparator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.MultipleColumnPrefixFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.KeyOnlyFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.InvalidRowFilterException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.IncompatibleFilterException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.InclusiveStopFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.FirstKeyOnlyFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.FilterList.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.FilterBase.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.Filter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.FamilyFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.DependentColumnFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.CompareFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.ColumnRangeFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.ColumnPrefixFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.ColumnPaginationFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.ColumnCountGetFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.BitComparator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.BinaryPrefixComparator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.BinaryComparator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.executor.RegionTransitionData.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.executor.ExecutorService.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.executor.EventHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.EmptyWatcher.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.DroppedSnapshotException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.DoNotRetryIOException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.coprocessor.WALObserver.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.coprocessor.WALCoprocessorEnvironment.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.coprocessor.RegionObserver.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.coprocessor.ObserverContext.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.coprocessor.MultiRowMutationProtocol.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.coprocessor.MasterObserver.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorHost.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.coprocessor.ColumnInterpreter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.coprocessor.BaseEndpointCoprocessor.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.coprocessor.AggregateProtocol.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.coprocessor.AggregateImplementation.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.CoprocessorEnvironment.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.Coprocessor.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.constraint.Constraints.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.constraint.ConstraintProcessor.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.constraint.ConstraintException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.constraint.Constraint.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.constraint.BaseConstraint.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ClusterStatus.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ClockOutOfSyncException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.UnmodifyableHTableDescriptor.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.UnmodifyableHRegionInfo.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.UnmodifyableHColumnDescriptor.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.ServerCallable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.ScannerTimeoutException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.RowMutations.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.RowLock.java</file>
      <file type="M">src.docbkx.developer.xml</file>
      <file type="M">bin.region.mover.rb</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.Abortable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.avro.AvroServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.avro.AvroUtil.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.catalog.CatalogTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.catalog.MetaEditor.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.catalog.MetaMigrationRemovingHTD.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.catalog.MetaReader.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.catalog.RootLocationEditor.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.Chore.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.AbstractClientScanner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.Action.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.Append.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.Attributes.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.coprocessor.AggregationClient.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.coprocessor.Batch.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.coprocessor.Exec.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.coprocessor.ExecResult.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.coprocessor.LongColumnInterpreter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.Delete.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.Get.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnection.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HTableFactory.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HTableInterface.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HTableInterfaceFactory.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HTablePool.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HTableUtil.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.Increment.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.IsolationLevel.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.MetaScanner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.metrics.ScanMetrics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.MultiAction.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.MultiPut.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.MultiResponse.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.Mutation.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.NoServerForRegionException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.Operation.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.OperationWithAttributes.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.Put.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.RegionOfflineException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.Result.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.ResultScanner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.RetriesExhaustedException.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException.java</file>
    </fixedFiles>
  </bug>
  <bug id="4509" opendate="2011-9-29 00:00:00" fixdate="2011-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbck] Improve region map output</summary>
      <description>HBASE-4375 added a region coverage visualization to hbck in details mode. When users have binary row keys the output is difficult to parse (awk/sed) or pull into programs (numeric, excel) capable of handling tsv formatted data.This patch improves output by using Bytes.toStringBinary (which escapes binary) instead of Bytes.toString when printing keys, suggests some repair actions, and collects "problem group" that groups regions that are overlapping.</description>
      <version>0.90.5,0.92.0,0.94.0</version>
      <fixedVersion>0.90.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4734" opendate="2011-11-2 00:00:00" fixdate="2011-11-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[bulk load] Warn if bulk load directory contained no files</summary>
      <description>Bulk load exits if no files are found in the specified directory. This can happen if a directory has been bulk loaded already (bulk load renames/moves files). It would be good to provide some sort of warning when this happens.</description>
      <version>0.90.5,0.92.0,0.94.0</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4944" opendate="2011-12-4 00:00:00" fixdate="2011-12-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Optionally verify bulk loaded HFiles</summary>
      <description>We rely on users to produce properly formatted HFiles for bulk import. Attached patch adds an optional code path, toggled by a configuration property, that verifies the HFile under consideration for import is properly sorted. The default maintains the current behavior, which does not scan the file for correctness.Patch is against trunk but can apply against all active branches.</description>
      <version>0.90.5,0.92.0,0.94.0</version>
      <fixedVersion>0.90.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
    </fixedFiles>
  </bug>
  <bug id="5186" opendate="2012-1-12 00:00:00" fixdate="2012-2-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add metrics to ThriftServer</summary>
      <description>It will be useful to have some metrics (queue length, waiting time, processing time ...) similar to Hadoop RPC server. This allows us to monitor system health also provide a tool to diagnose the problem where thrift calls are slow.</description>
      <version>None</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.thrift.TestThriftServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.thrift.TBoundedThreadPoolServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionThriftServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="5189" opendate="2012-1-13 00:00:00" fixdate="2012-8-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add metrics to keep track of region-splits in RS</summary>
      <description>For write-heavy workload with region-size 1 GB, region-split is considerably high. We do normally grep the NN log (grep "mkdir*.split" NN.log | sort | uniq -c) to get the count.I would like to have a counter incremented each time region-split execution succeeds and this counter exposed via the metrics stuff in HBase. regionSplitSuccessCount regionSplitFailureCount (will help us to correlate the timestamp range in RS logs across all RS)</description>
      <version>0.90.5,0.92.0</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.metrics.RegionServerMetrics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.SplitRequest.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.metrics.RegionServerMetrics.java</file>
    </fixedFiles>
  </bug>
  <bug id="5190" opendate="2012-1-13 00:00:00" fixdate="2012-3-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Limit the IPC queue size based on calls&amp;#39; payload size</summary>
      <description>Currently we limit the number of calls in the IPC queue only on their count. It used to be really high and was dropped down recently to num_handlers * 10 (so 100 by default) because it was easy to OOME yourself when huge calls were being queued. It's still possible to hit this problem if you use really big values and/or a lot of handlers, so the idea is that we should take into account the payload size. I can see 3 solutions: Do the accounting outside of the queue itself for all calls coming in and out and when a call doesn't fit, throw a retryable exception. Same accounting but instead block the call when it comes in until space is made available. Add a new parameter for the maximum size (in bytes) of a Call and then set the size the IPC queue (in terms of the number of items) so that it could only contain as many items as some predefined maximum size (in bytes) for the whole queue.</description>
      <version>0.90.5</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HBaseServer.java</file>
      <file type="M">security.src.main.java.org.apache.hadoop.hbase.ipc.SecureServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="5199" opendate="2012-1-13 00:00:00" fixdate="2012-2-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Delete out of TTL store files before compaction selection</summary>
      <description>Currently, HBase deletes the out of TTL store files after compaction. We can change the sequence to delete the out of TTL store files before selecting store files for compactions. In this way, HBase can keep deleting the old invalid store files without compaction, and also prevent from unnecessary compactions since the out of TTL store files will be deleted before the compaction selection.</description>
      <version>None</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestStore.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactSelection.java</file>
    </fixedFiles>
  </bug>
  <bug id="5213" opendate="2012-1-17 00:00:00" fixdate="2012-4-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>"hbase master stop" does not bring down backup masters</summary>
      <description>Typing "hbase master stop" produces the following message:"stop Start cluster shutdown; Master signals RegionServer shutdown"It seems like backup masters should be considered part of the cluster, but they are not brought down by "hbase master stop"."stop-hbase.sh" does correctly bring down the backup masters.The same behavior is observed when a client app makes use of the client API HBaseAdmin.shutdown() http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HBaseAdmin.html#shutdown() &amp;#8211; this isn't too surprising since I think "hbase master stop" just calls this API.It seems like HBASE-1448 address this; perhaps there was a regression?</description>
      <version>0.90.5,0.92.0,0.94.0,0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestActiveMasterManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.ActiveMasterManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="5228" opendate="2012-1-18 00:00:00" fixdate="2012-1-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[REST] Rip out "transform" feature</summary>
      <description>The 'transform' feature, where REST can be instructed, via a table attribute, to apply a transformation (e.g. base64 encoding or decoding) to a (sub)set of column values before serving them up to a client or storing them into HBase, was added some time ago at the request of Jack Levin. I have since come to regret it, it was not a well thought out feature: This is really an application concern. It adds significant overhead to request processing: Periodically a HBaseAdmin is used to retrieve the table descriptor, in order to scan through table attributes for transformation directives.I think it is best to rip it out, its a real problem area, and REST should be no more concerned about data formats than the Java API. I doubt anyone uses this, not even Jack. Will need to follow up with him to confirm.</description>
      <version>0.90.5,0.92.0,0.94.0</version>
      <fixedVersion>0.90.6,0.92.1,0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.rest.TestTransform.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.transform.Transform.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.transform.NullTransform.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.transform.Base64.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.TableResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.RowResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.MultiRowResource.java</file>
    </fixedFiles>
  </bug>
  <bug id="5237" opendate="2012-1-20 00:00:00" fixdate="2012-1-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Addendum for HBASE-5160 and HBASE-4397</summary>
      <description>As part of HBASE-4397 there is one more scenario where the patch has to be applied.RegionPlan plan = getRegionPlan(state, forceNewPlan); if (plan == null) { debugLog(state.getRegion(), "Unable to determine a plan to assign " + state); return; // Should get reassigned later when RIT times out. }I think in this scenario also this.timeoutMonitor.setAllRegionServersOffline(true);this should be done.</description>
      <version>0.90.5</version>
      <fixedVersion>0.90.6,0.92.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5243" opendate="2012-1-21 00:00:00" fixdate="2012-1-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LogSyncerThread not getting shutdown waiting for the interrupted flag</summary>
      <description>In the LogSyncer run() we keep looping till this.isInterrupted flag is set.But in some cases the DFSclient is consuming the Interrupted exception. Sowe are running into infinite loop in some shutdown cases.I would suggest that as we are the ones who tries to close down theLogSyncerThread we can introduce a variable likeClose or shutdown and based on the state of this flag along withisInterrupted() we can make the thread stop.</description>
      <version>0.90.5</version>
      <fixedVersion>0.90.6,0.92.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5256" opendate="2012-1-23 00:00:00" fixdate="2012-4-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use WritableUtils.readVInt() in RegionLoad.readFields()</summary>
      <description>Currently in.readInt() is used in RegionLoad.readFields()More metrics would be added to RegionLoad in the future, we should utilize WritableUtils.readVInt() to reduce the amount of data exchanged between Master and region servers.</description>
      <version>None</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HServerLoad.java</file>
    </fixedFiles>
  </bug>
  <bug id="5259" opendate="2012-1-23 00:00:00" fixdate="2012-1-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Normalize the RegionLocation in TableInputFormat by the reverse DNS lookup.</summary>
      <description>Assuming the HBase and MapReduce running in the same cluster, the TableInputFormat is to override the split function which divides all the regions from one particular table into a series of mapper tasks. So each mapper task can process a region or one part of a region. Ideally, the mapper task should run on the same machine on which the region server hosts the corresponding region. That's the motivation that the TableInputFormat sets the RegionLocation so that the MapReduce framework can respect the node locality. The code simply set the host name of the region server as the HRegionLocation. However, the host name of the region server may have different format with the host name of the task tracker (Mapper task). The task tracker always gets its hostname by the reverse DNS lookup. And the DNS service may return different host name format. For example, the host name of the region server is correctly set as a.b.c.d while the reverse DNS lookup may return a.b.c.d. (With an additional doc in the end).So the solution is to set the RegionLocation by the reverse DNS lookup as well. No matter what host name format the DNS system is using, the TableInputFormat has the responsibility to keep the consistent host name format with the MapReduce framework.</description>
      <version>None</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="5278" opendate="2012-1-25 00:00:00" fixdate="2012-1-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase shell script refers to removed "migrate" functionality</summary>
      <description>$ hbase migrateException in thread "main" java.lang.NoClassDefFoundError: org/apache/hadoop/hbase/util/MigrateCaused by: java.lang.ClassNotFoundException: org.apache.hadoop.hbase.util.Migrateat java.net.URLClassLoader$1.run(URLClassLoader.java:202)at java.security.AccessController.doPrivileged(Native Method)at java.net.URLClassLoader.findClass(URLClassLoader.java:190)at java.lang.ClassLoader.loadClass(ClassLoader.java:306)at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)at java.lang.ClassLoader.loadClass(ClassLoader.java:247)Could not find the main class: org.apache.hadoop.hbase.util.Migrate. Program will exit.The 'hbase' shell script has docs referring to a 'migrate' command which no longer exists.</description>
      <version>0.90.5,0.92.0,0.94.0</version>
      <fixedVersion>0.92.1,0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug id="5328" opendate="2012-2-3 00:00:00" fixdate="2012-3-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Small changes to Master to make it more testable</summary>
      <description>Here are some small changes in Master that make it more testable. Included tests stand up a Master and then fake it into thinking that three regionservers are registering making master assign root and meta, etc.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestMasterNoCluster.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.catalog.TestCatalogTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.RootRegionTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.catalog.CatalogTracker.java</file>
    </fixedFiles>
  </bug>
  <bug id="5393" opendate="2012-2-13 00:00:00" fixdate="2012-2-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Consider splitting after flushing</summary>
      <description>Spawning this from HBASE-2375, I saw that it was much more efficient compaction-wise to check if we can split right after flushing. Much like the ideas that Jon spelled out in the description of that jira, the window is smaller because you don't have to compact and then split right away to only compact again when the daughters open.Another thing it improves is while we're normally waiting for the compaction to happen, data that's still coming in will make us go way past the MAX_FILESIZE to a point where for the first region I was seeing a store size 3-4x bigger before it was able to split.I targeted this for 0.94, but I'd like to get this into 0.92.1 or .2 too.</description>
      <version>0.90.5</version>
      <fixedVersion>0.92.1,0.94.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
    </fixedFiles>
  </bug>
  <bug id="5464" opendate="2012-2-23 00:00:00" fixdate="2012-2-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Log warning message when thrift calls throw exceptions</summary>
      <description>Currently there is no logging message when client calls throw exceptions. It will be easier to debug if we have them.</description>
      <version>None</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionThriftServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="5466" opendate="2012-2-23 00:00:00" fixdate="2012-2-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Opening a table also opens the metatable and never closes it.</summary>
      <description>Having upgraded to CDH3U3 version of hbase we found we had a zookeeper connection leak, tracking it down we found that closing the connection will only close the zookeeper connection if all calls to get the connection have been closed, there is incCount and decCount in the HConnection class,When a table is opened it makes a call to the metascanner class which opens a connection to the meta table, this table never gets closed.This caused the count in the HConnection class to never return to zero meaning that the zookeeper connection will not close when we close all the tables or callingHConnectionManager.deleteConnection(config, true);</description>
      <version>0.90.5,0.92.0</version>
      <fixedVersion>0.90.7,0.92.1,0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.MetaScanner.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5586" opendate="2012-3-15 00:00:00" fixdate="2012-3-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[replication] NPE in ReplicationSource when creating a stream to an inexistent cluster</summary>
      <description>This is from 0.92.1-ish:2012-03-15 09:52:16,589 ERRORorg.apache.hadoop.hbase.replication.regionserver.ReplicationSource:Unexpected exception in ReplicationSource, currentPath=nulljava.lang.NullPointerException at org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.chooseSinks(ReplicationSource.java:223) at org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.connectToPeers(ReplicationSource.java:442) at org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.run(ReplicationSource.java:246)I wanted to add a replication stream to a cluster that wasn't existing yet so that the logs would be buffered until then. This should just be treated as if there was no region servers.</description>
      <version>0.90.5</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.replication.ReplicationZookeeper.java</file>
    </fixedFiles>
  </bug>
</bugrepository>
