<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="10729" opendate="2014-3-12 00:00:00" fixdate="2014-3-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable table doesn&amp;#39;t balance out replicas evenly if the replicas were unassigned earlier</summary>
      <description>Enable table doesn't assign out replicas keeping availability in mind, if the replicas were unassigned before the table was disabled. For example, when a snapshot is restored and then the table is enabled, the replicas are unevenly assigned. The reason for this is that the the enable table invokes randomAssign that assigns one region at a time. Since the master doesn't have any information about the unassigned replicas, the calls to randomAssign can't do any availability checks.</description>
      <version>None</version>
      <fixedVersion>0.99.0,hbase-10070</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.EnableTableHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="11052" opendate="2014-4-23 00:00:00" fixdate="2014-6-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Sending random data crashes thrift service</summary>
      <description>Upstream thrift library has a know issue (THRIFT-601) causing the thrift server to crash with an Out-of-Memory Error when bogus requests are sent.This reproduces when a very large request size is sent in the request header, making the thrift server to allocate a large memory segment leading to OOM.LoadBalancer health checks are the first "candidate" for bogus requestsThrift developers admit this is a known issue with TBinaryProtocol and their recommandation is to use TCompactProtocol/TFramedTransport but this requires all thrift clients to be updated (might not be feasible atm)So we need a fix similar to CASSANDRA-475.</description>
      <version>0.98.1,1.0.0,0.94.18</version>
      <fixedVersion>0.99.0,0.94.21,0.98.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11195" opendate="2014-5-16 00:00:00" fixdate="2014-1-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Potentially improve block locality during major compaction for old regions</summary>
      <description>This might be a specific use case. But we have some regions which are no longer written to (due to the key). Those regions have 1 store file and they are very old, they haven't been written to in a while. We still use these regions to read from so locality would be nice. I propose putting a configuration option: something likehbase.hstore.min.locality.to.skip.major.compact &amp;#91;between 0 and 1&amp;#93;such that you can decide whether or not to skip major compaction for an old region with a single store file.I'll attach a patch, let me know what you guys think.</description>
      <version>1.0.0,0.94.26,0.98.10,2.0.0</version>
      <fixedVersion>1.0.0,0.98.10,0.94.27</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.RatioBasedCompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration.java</file>
    </fixedFiles>
  </bug>
  <bug id="11196" opendate="2014-5-16 00:00:00" fixdate="2014-5-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update description of -ROOT- in ref guide</summary>
      <description>Since the resolution of HBASE-3171, &amp;#45;ROOT- is no longer used to store the location(s) of .META. . Unfortunately, not all of our documentation has been updated to reflect this change in architecture.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11448" opendate="2014-7-1 00:00:00" fixdate="2014-7-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix javadoc warnings</summary>
      <description>Master has a couple of new javadoc warnings because of the hbase-10070. We should fix them.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RackManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedScannerCallable.java</file>
    </fixedFiles>
  </bug>
  <bug id="1145" opendate="2009-1-21 00:00:00" fixdate="2009-3-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Ensure that there is only 1 Master with Zookeeper (part of HA Master)</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.master.OOMEHMaster.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.MasterNotRunningException.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.LocalHBaseCluster.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">conf.zoo.cfg</file>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">bin.hbase</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.Hbase.thrift</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.generated.Hbase.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11458" opendate="2014-7-2 00:00:00" fixdate="2014-7-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>NPEs if RegionServer cannot initialize</summary>
      <description>If master aborts, or RS aborts before initialization is complete, we run into a lot of NPE's in region server abort / stop code path.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="11459" opendate="2014-7-2 00:00:00" fixdate="2014-7-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add more doc on compression codecs, how to hook up native lib, lz4, etc.</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1146" opendate="2009-1-21 00:00:00" fixdate="2009-1-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace the HRS leases with Zookeeper</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.TestHBaseCluster.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestLogRolling.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.filter.TestRowFilterAfterWrite.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.RegionManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11564" opendate="2014-7-22 00:00:00" fixdate="2014-7-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve cancellation management in the rpc layer</summary>
      <description>The current client code depends on interrupting the thread for canceling a request. It's actually possible to rely on a callback in protobuf.The patch includes as well various performance improvements in replica management. On a version before HBASE-11492 the perf was ~35% better. I will redo the test with the last version.</description>
      <version>1.0.0,2.0.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestIPC.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.Subprocedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.BufferChain.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestRegionReplicaPerf.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ExceptionUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.TimeLimitedRpcController.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCaller.java</file>
    </fixedFiles>
  </bug>
  <bug id="11585" opendate="2014-7-24 00:00:00" fixdate="2014-8-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>PE: Allows warm-up</summary>
      <description>When we measure the latency, warm-up helps to get repeatable and useful measures.</description>
      <version>1.0.0,2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
    </fixedFiles>
  </bug>
  <bug id="11610" opendate="2014-7-29 00:00:00" fixdate="2014-8-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enhance remote meta updates</summary>
      <description>Currently, if the meta region is on a regionserver instead of the master, meta update is synchronized on one HTable instance. We should be able to do better.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.6</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStateStore.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCallerFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="11611" opendate="2014-7-29 00:00:00" fixdate="2014-8-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up ZK-based region assignment</summary>
      <description>We can clean up the ZK-based region assignment code and use the ZK-less one in the master branch, to make the code easier to understand and maintain.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildOverlap.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildHole.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestZooKeeper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestMetaTableAccessor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestIOFencing.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestDrainingServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestZKLessSplitOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestZKLessMergeOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerNoMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionReplicas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionMergeTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestEndToEndSplitTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.handler.TestOpenRegionHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.handler.TestCloseRegionHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.migration.TestUpgradeTo96.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.migration.TestNamespaceUpgrade.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestZKLessAMOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestZKBasedOpenCloseRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRollingRestart.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRestartCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestOpenedRegionHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterRestartAfterDisablingTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.master.RegionState.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionTransition.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKAssign.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.ZooKeeper.proto</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.BaseCoordinatedStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.CloseRegionCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.OpenRegionCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.RegionMergeCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.SplitTransactionCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZkCloseRegionCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZkOpenRegionCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZkRegionMergeCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZKSplitTransactionCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignCallable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ClosedRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.OpenedRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.OfflineCallback.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStateStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.migration.UpgradeTo96.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseMetaHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenMetaHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionMergeTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ConfigUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsckRepair.java</file>
      <file type="M">hbase-server.src.test.data.TestNamespaceUpgrade.tgz</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestReplicasClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannersFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestChangingEncoding.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.Mocking.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
    </fixedFiles>
  </bug>
  <bug id="11650" opendate="2014-8-1 00:00:00" fixdate="2014-8-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Write hbase.id to a temporary location and move into place</summary>
      <description>We should write hbase.id to a temporary location and move it into place. Will avoid potential race issues between create and write.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="11689" opendate="2014-8-6 00:00:00" fixdate="2014-8-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Track meta in transition</summary>
      <description>With ZK-less region assignment, user regions in transition are tracked in meta. We need a way to track meta in transition too.</description>
      <version>1.0.0,2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestMetaTableLocator.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStateStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.MetaServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.ZooKeeper.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.MetaTableLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ServerName.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.master.RegionState.java</file>
    </fixedFiles>
  </bug>
  <bug id="11719" opendate="2014-8-11 00:00:00" fixdate="2014-8-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove some unused paths in AsyncClient</summary>
      <description>sershe you're ok with these changes?</description>
      <version>1.0.0,2.0.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
    </fixedFiles>
  </bug>
  <bug id="11757" opendate="2014-8-15 00:00:00" fixdate="2014-8-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Provide a common base abstract class for both RegionObserver and MasterObserver</summary>
      <description>Some security coprocessors extend both RegionObserver and MasterObserver, unfortunately only one of the two can use the available base abstract class implementations. Provide a common base abstract class for both the RegionObserver and MasterObserver interfaces. Update current coprocessors that extend both interfaces to use the new common base abstract class.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.6</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug id="11835" opendate="2014-8-27 00:00:00" fixdate="2014-10-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Wrong managenement of non expected calls in the client</summary>
      <description>If a call is purged or canceled we try to skip the reply from the server, but we read the wrong number of bytes so we corrupt the tcp channel. It's hidden as it triggers retry and so on, but it's bad for performances obviously.It happens with cell blocks.ram_krish_86, saint.ack@gmail.com, you know this part better than me, do you agree with the analysis and the patch?The changes in rpcServer are not fully related: as the client close the connections in such situation, I observed both ClosedChannelException and CancelledKeyException.</description>
      <version>1.0.0,0.98.6,2.0.0</version>
      <fixedVersion>0.99.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="11998" opendate="2014-9-16 00:00:00" fixdate="2014-10-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document a workflow for cherry-picking a fix to a different branch</summary>
      <description>We are not all git experts and it will be helpful to have a workflow documented, understanding that there are about a million ways to do everything in git.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.developer.xml</file>
    </fixedFiles>
  </bug>
  <bug id="12102" opendate="2014-9-26 00:00:00" fixdate="2014-2-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Duplicate keys in HBase.RegionServer metrics JSON</summary>
      <description>The JSON returned by /jmx on the RegionServer contains duplicate 'tag.Context' keys for various HBase.RegionServer metrics. Regions:{ "name" : "Hadoop:service=HBase,name=RegionServer,sub=Regions", "modelerType" : "RegionServer,sub=Regions", "tag.Context" : "regionserver", "tag.Context" : "regionserver", "tag.Hostname" : "some.host.name", ...}Server:"name" : "Hadoop:service=HBase,name=RegionServer,sub=Server", "modelerType" : "RegionServer,sub=Server", "tag.Context" : "regionserver", "tag.zookeeperQuorum" : "some.zookeeper.quorum.peers", "tag.serverName" : "some.server.name", "tag.clusterId" : "88c186ea-2308-4713-8b5f-5a3e829cbb10", "tag.Context" : "regionserver", ...}IPC:{ "name" : "Hadoop:service=HBase,name=IPC,sub=IPC", "modelerType" : "IPC,sub=IPC", "tag.Context" : "ipc", "tag.Context" : "ipc", "tag.Hostname" : "some.host.name", ...}This can cause issues with some JSON parsers. We should avoid emitting duplicate keys if it is under our control.</description>
      <version>1.0.0,0.98.10,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.11,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionAggregateSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="12147" opendate="2014-10-1 00:00:00" fixdate="2014-10-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Porting Online Config Change from 89-fb</summary>
      <description>This jira is to track the forward port of HBASE-8805 and HBASE-8544 implemented by gaurav.menghani in 89-fb. This improves operational efficiency in managing clusters that are serving production traffic.</description>
      <version>1.0.0</version>
      <fixedVersion>0.99.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MetaScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="12151" opendate="2014-10-2 00:00:00" fixdate="2014-10-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make dev scripts executable</summary>
      <description>Is there any reason not to make dev-support/*.sh executable? It would make it possible to sym-link to them from a directory in the executable path for easier execution of the definitive scripts.</description>
      <version>None</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.publish.hbase.website.sh</file>
      <file type="M">dev-support.jenkinsEnv.sh</file>
      <file type="M">dev-support.jdiffHBasePublicAPI.common.sh</file>
      <file type="M">dev-support.hbase.docker.sh</file>
    </fixedFiles>
  </bug>
  <bug id="12181" opendate="2014-10-6 00:00:00" fixdate="2014-10-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Some tests create a table and try to use it before regions get assigned</summary>
      <description>I inadvertently did some unit test stress testing this weekend by running mvn test -P runAllTests on a machine that also had other processes going on. The overall sluggishness led to a number of failed tests that were caused by a table being created using HBaseAdmin#createTable, which only blocks for meta to get updated and not for the region to actually get assigned a RegionServer. Quick fix is to use HBaseTestingUtility#createTable whenever possible.</description>
      <version>1.0.0,0.98.6.1,2.0.0</version>
      <fixedVersion>0.98.8,0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
    </fixedFiles>
  </bug>
  <bug id="12197" opendate="2014-10-7 00:00:00" fixdate="2014-10-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move REST</summary>
      <description>Lets move Rest to it's own module like thrift. That should allow us to remove some dependencies from the class path when running MR tests.</description>
      <version>None</version>
      <fixedVersion>0.98.8,0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RESTServer.java</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-thrift.pom.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestVersionResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestTableScan.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestTableResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestStatusResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestSchemaResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestScannersWithLabels.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestScannersWithFilters.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestScannerResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestResourceFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestMultiRowResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestGZIPResponseWrapper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestGzipFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestGetAndPutResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestDeleteRow.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.RowResourceBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.PerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestVersionModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestTableSchemaModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestTableRegionModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestTableListModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestTableInfoModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestStorageClusterVersionModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestStorageClusterStatusModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestScannerModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestRowModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestModelBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestColumnSchemaModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestCellSetModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestCellModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.HBaseRESTTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.DummyFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.client.TestRemoteTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.client.TestRemoteHTableRetries.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.client.TestRemoteAdminRetries.java</file>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.rest.XMLSchema.xsd</file>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.VersionMessage.proto</file>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.TableSchemaMessage.proto</file>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.TableListMessage.proto</file>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.TableInfoMessage.proto</file>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.StorageClusterStatusMessage.proto</file>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.ScannerMessage.proto</file>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.ColumnSchemaMessage.proto</file>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.CellSetMessage.proto</file>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.CellMessage.proto</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.rest.rest.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.rest.index.html</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.VersionResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.TableScanResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.TableResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.StorageClusterVersionResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.StorageClusterStatusResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.SchemaResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerResultGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerInstanceResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RowSpec.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RowResultGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RowResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RootResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ResultGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RESTServletContainer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RESTServlet.java</file>
      <file type="M">hbase-assembly.pom.xml</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.Client.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.Cluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteAdmin.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.Response.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.Constants.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ExistsResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.filter.AuthFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.filter.GzipFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.filter.GZIPRequestStream.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.filter.GZIPRequestWrapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.filter.GZIPResponseStream.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.filter.GZIPResponseWrapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.MetricsREST.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.CellModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.CellSetModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.ColumnSchemaModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.RowModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.ScannerModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.StorageClusterStatusModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.StorageClusterVersionModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.TableInfoModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.TableListModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.TableModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.TableRegionModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.TableSchemaModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.VersionModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.MultiRowResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.package.html</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ProtobufMessageHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ProtobufStreamingUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.CellMessage.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.CellSetMessage.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.ColumnSchemaMessage.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.ScannerMessage.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.TableInfoMessage.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.TableListMessage.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.TableSchemaMessage.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.VersionMessage.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.provider.consumer.ProtobufMessageBodyConsumer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.provider.JacksonProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.provider.JAXBContextResolver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.provider.producer.PlainTextMessageBodyProducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.provider.producer.ProtobufMessageBodyProducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RegionsResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ResourceBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ResourceConfig.java</file>
    </fixedFiles>
  </bug>
  <bug id="12198" opendate="2014-10-7 00:00:00" fixdate="2014-10-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix the bug of not updating location cache</summary>
      <description>Fix the bug of not updating location cache.Add a testcase for it.</description>
      <version>1.0.0,0.98.7,2.0.0</version>
      <fixedVersion>0.98.8,0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTableMultiplexer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
    </fixedFiles>
  </bug>
  <bug id="12200" opendate="2014-10-8 00:00:00" fixdate="2014-10-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>When an RPC server handler thread dies, throw exception</summary>
      <description>When a Rpc server handler thread dies, throws exception so as to find out what issues caused the handler to exit.It relates to HBASE-12028.</description>
      <version>None</version>
      <fixedVersion>0.98.8,0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcExecutor.java</file>
    </fixedFiles>
  </bug>
  <bug id="12278" opendate="2014-10-16 00:00:00" fixdate="2014-10-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Race condition in TestSecureLoadIncrementalHFilesSplitRecovery</summary>
      <description>I sometimes get #testGroupOrSplitWhenRegionHoleExistsInMeta to error out on me because of a TableNotFoundException. Fix is pretty simple and will involve a little bit of test refactoring to get rid of some duplicate behavior that's done better in HBaseTestingUtility anyway.</description>
      <version>1.0.0</version>
      <fixedVersion>0.98.8,0.99.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFilesSplitRecovery.java</file>
    </fixedFiles>
  </bug>
  <bug id="12285" opendate="2014-10-17 00:00:00" fixdate="2014-11-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Builds are failing, possibly because of SUREFIRE-1091</summary>
      <description>Our branch-1 builds on builds.apache.org have been failing in recent days after we switched over to an official version of Surefire a few days back (HBASE-4955). The version we're using, 2.17, is hit by a bug (SUREFIRE-1091) that results in an IOException, which looks like what we're seeing on Jenkins.</description>
      <version>1.0.0</version>
      <fixedVersion>0.99.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.resources.log4j.properties</file>
    </fixedFiles>
  </bug>
  <bug id="12288" opendate="2014-10-19 00:00:00" fixdate="2014-10-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support DirectByteBuffer usage in DataBlock Encoding area</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.99.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteBufferUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.PrefixKeyDeltaEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.FastDiffDeltaEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.DiffKeyDeltaEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.CopyKeyDataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
    </fixedFiles>
  </bug>
  <bug id="12448" opendate="2014-11-7 00:00:00" fixdate="2014-11-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix rate reporting in compaction progress DEBUG logging</summary>
      <description>HBASE-11702 introduced rate reporting at DEBUG level for long running compactions but failed to align bytesWritten with the reporting interval.</description>
      <version>None</version>
      <fixedVersion>0.98.8,0.99.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.Compactor.java</file>
    </fixedFiles>
  </bug>
  <bug id="12496" opendate="2014-11-17 00:00:00" fixdate="2014-11-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>A blockedRequestsCount metric</summary>
      <description>blockedRequestsCount counts for requests blocked because mem size is greater than blockingMemStoreSize.</description>
      <version>1.0.0,0.98.7,2.0.0</version>
      <fixedVersion>0.98.9,0.99.2</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperStub.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="12519" opendate="2014-11-18 00:00:00" fixdate="2014-11-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove tabs used as whitespace</summary>
      <description>We have a number of files with tabs for whitespace. Our style guide and our checkstyle settings don't allow them, so clean them up.Doing this in a dedicate patch should make dealing with the churn easier, since ignoring whitespace changes will make the patch appear empty.To get a list of files:grep -rl -e "\t" */src/ | grep java$</description>
      <version>1.0.0</version>
      <fixedVersion>0.99.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.RegionServerTracker.java</file>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift2.TestHTablePool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MultiThreadedUpdater.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MultiThreadedReader.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.LoadTestTool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationSmallTests.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestTags.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMajorCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestClockSkewDetection.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFilePerformance.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestParseFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestDependentColumnFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestBigDecimalColumnInterpreter.java</file>
      <file type="M">hbase-annotations.src.main.java.org.apache.hadoop.hbase.classification.tools.ExcludePrivateAnnotationsStandardDoclet.java</file>
      <file type="M">hbase-annotations.src.main.java.org.apache.hadoop.hbase.classification.tools.RootDocProcessor.java</file>
      <file type="M">hbase-annotations.src.main.java.org.apache.hadoop.hbase.classification.tools.StabilityOptions.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.AggregationClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.UnmodifyableHTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.DependentColumnFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.TimeRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.CollectionUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.JenkinsHash.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestHBaseConfiguration.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedListWithVisibility.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArraySearcher.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.column.ColumnSectionWriter.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.other.LongEncoder.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.tokenize.Tokenizer.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.tokenize.TokenizerNode.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.encode.tokenize.TokenizerRowSearchPosition.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeBlockMeta.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.util.vint.UFIntTool.java</file>
      <file type="M">hbase-prefix-tree.src.test.java.org.apache.hadoop.hbase.codec.prefixtree.row.data.TestRowDataComplexQualifiers.java</file>
      <file type="M">hbase-prefix-tree.src.test.java.org.apache.hadoop.hbase.codec.prefixtree.row.data.TestRowDataDeeper.java</file>
      <file type="M">hbase-prefix-tree.src.test.java.org.apache.hadoop.hbase.codec.prefixtree.row.data.TestRowDataDifferentTimestamps.java</file>
      <file type="M">hbase-prefix-tree.src.test.java.org.apache.hadoop.hbase.codec.prefixtree.row.data.TestRowDataExerciseFInts.java</file>
      <file type="M">hbase-prefix-tree.src.test.java.org.apache.hadoop.hbase.codec.prefixtree.row.data.TestRowDataNub.java</file>
      <file type="M">hbase-prefix-tree.src.test.java.org.apache.hadoop.hbase.codec.prefixtree.row.data.TestRowDataQualifierByteOrdering.java</file>
      <file type="M">hbase-prefix-tree.src.test.java.org.apache.hadoop.hbase.codec.prefixtree.row.data.TestRowDataSearcherRowMiss.java</file>
      <file type="M">hbase-prefix-tree.src.test.java.org.apache.hadoop.hbase.codec.prefixtree.row.data.TestRowDataSingleQualifier.java</file>
      <file type="M">hbase-prefix-tree.src.test.java.org.apache.hadoop.hbase.codec.prefixtree.row.data.TestRowDataTrivial.java</file>
      <file type="M">hbase-prefix-tree.src.test.java.org.apache.hadoop.hbase.codec.prefixtree.row.data.TestRowDataUrls.java</file>
      <file type="M">hbase-prefix-tree.src.test.java.org.apache.hadoop.hbase.codec.prefixtree.row.data.TestRowDataUrlsExample.java</file>
      <file type="M">hbase-prefix-tree.src.test.java.org.apache.hadoop.hbase.codec.prefixtree.row.TestPrefixTreeSearcher.java</file>
      <file type="M">hbase-prefix-tree.src.test.java.org.apache.hadoop.hbase.codec.prefixtree.row.TestRowEncoder.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.StorageClusterVersionModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.TableListModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.TableModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.VersionModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.provider.JAXBContextResolver.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.provider.producer.PlainTextMessageBodyProducer.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.provider.producer.ProtobufMessageBodyProducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseRPCErrorHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.CleanerChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionPlacementMaintainer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SnapshotOfRegionAssignmentFromMeta.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.WALSplitterHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitLogWorker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="12603" opendate="2014-11-30 00:00:00" fixdate="2014-12-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove javadoc warnings introduced due to removal of unused imports</summary>
      <description>After removal of unused imports in HBASE-12526 , a lot of javadoc warnings were introduced because some of the classes referred to were no longer imported.</description>
      <version>1.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKSplitLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ClusterStatusTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HFileArchiveUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.BloomFilterFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitLogWorker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MiniBatchOperationInProgress.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.RegionServerProcedureManagerHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.MasterProcedureManagerHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.MasterProcedureManager.java</file>
      <file type="M">hbase-annotations.src.main.java.org.apache.hadoop.hbase.classification.InterfaceStability.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.coprocessor.ColumnInterpreter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.QualifierFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.RowFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.SingleColumnValueFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.CoprocessorRpcChannel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.ServerRpcController.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.util.PoolMap.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.Codec.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.CellOutputStream.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.DataType.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawBytesFixedLength.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawBytesTerminated.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawStringFixedLength.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawStringTerminated.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.AbstractPositionedByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ConcurrentIndex.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.PositionedByteRange.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.coprocessor.example.ZooKeeperScanPolicyObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.example.LongTermArchivingHFileCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.TableSnapshotScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.constraint.ConstraintException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.SplitLogManagerCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.SplitLogWorkerCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HLogInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.IdentityTableReducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.RowCounter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableInputFormatBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableRecordReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableRecordReaderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.FavoredNodeLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.SimpleLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.LogReplayHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TotesHRegionInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.MasterSnapshotVerifier.java</file>
    </fixedFiles>
  </bug>
  <bug id="12606" opendate="2014-12-1 00:00:00" fixdate="2014-12-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Sanity check encryption configuration before opening WAL or onlining regions</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.0.0,0.98.9</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestIngestWithEncryption.java</file>
    </fixedFiles>
  </bug>
  <bug id="12663" opendate="2014-12-9 00:00:00" fixdate="2014-12-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>unify getTableDescriptors() and listTableDescriptorsByNamespace()</summary>
      <description>currently we have getTableDescriptors()/listTableNames()and listTableDescriptorsByNamespace()/listTableNamesByNamespace()which are just filtering by namespace.The first two are already able to filter tables by regex,and there is also an ACL check which shows only the table the user have access to,while the namespace version just return a list without any ACLs check.to me there is no point to keep the *ByNamespace() version on the server side, since the "base" version must be able to do the filtering bynamespace and the ACLs check must be the same for both anyway.or at least we can just call the base version with the ns filtering.</description>
      <version>1.0.0,2.0.0</version>
      <fixedVersion>1.0.0,0.98.19</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestNamespaceCommands.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestMasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Master.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MasterProtos.java</file>
    </fixedFiles>
  </bug>
  <bug id="12674" opendate="2014-12-11 00:00:00" fixdate="2014-12-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add permission check to getNamespaceDescriptor()</summary>
      <description>Add permission check to getNamespaceDescriptor()</description>
      <version>1.0.0,2.0.0</version>
      <fixedVersion>1.0.0,0.98.19</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestNamespaceCommands.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestMasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.java</file>
    </fixedFiles>
  </bug>
  <bug id="12675" opendate="2014-12-11 00:00:00" fixdate="2014-12-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use interface methods in shell scripts</summary>
      <description>There are places in the shell script code that use methods from HTable or HConnection or etc. This patch will fix at least some of them.</description>
      <version>None</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.table.rb</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.security.rb</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug id="12708" opendate="2014-12-18 00:00:00" fixdate="2014-1-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document newly introduced params for using Thrift-over-HTTPS.</summary>
      <description>Per the description.</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.security.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="12709" opendate="2014-12-18 00:00:00" fixdate="2014-12-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[mvn] Add unit test excludes command line flag to the build.</summary>
      <description>I've added a simple way to specify unit test classes to skip when executing unit test runs. I've added a -D variable called test.exclude.pattern that you can using like this:mvn test -Dtest.exclude.pattern=**/TestFoo.java,**/TestBar.javato exclude the unit tests form TestFoo and TestBar in this run. By default there is nothing excluded.</description>
      <version>1.0.0,0.98.10,2.0.0</version>
      <fixedVersion>1.0.0,hbase-11339,0.98.10,1.1.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1271" opendate="2009-3-20 00:00:00" fixdate="2009-4-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow multiple tests to run on one machine</summary>
      <description>Currently, if we try to run two tests on one machine (e.g. in two checkouts) the second one will fail because its servers won't be able to bind to ports. We should use random ports in our servers in the tests to fix this.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.MiniZooKeeperCluster.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.MiniHBaseCluster.java</file>
      <file type="M">src.test.hbase-site.xml</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HServerInfo.java</file>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12711" opendate="2014-12-18 00:00:00" fixdate="2014-12-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix new findbugs warnings in hbase-thrift module</summary>
      <description>From https://builds.apache.org/job/PreCommit-HBASE-Build/12121/artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html , there were 5 findbugs warnings introduced.This issue fixes the new warnings.</description>
      <version>None</version>
      <fixedVersion>1.0.0,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftHttpServlet.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="1272" opendate="2009-3-20 00:00:00" fixdate="2009-5-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unreadable log messages -- "... to the only server localhost_1237525439599_56094" &lt;- You&amp;#39;d have to be perverse to recognize that as a hostname, startcode, and port number.</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.HServerInfo.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1276" opendate="2009-3-20 00:00:00" fixdate="2009-10-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[testing] Upgrade to JUnit 4.x and use @BeforeClass annotations to optimize tests</summary>
      <description>If we upgrade to JUnit 4.x we can get access to @BeforeClass annotations... that allows us to start up DFS &amp; Hbase only once per test class. This should improve the speed of our unit tests substantially.We will also need an ability to reset the hbase state between tests however. Drop all tables for example.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">lib.junit-3.8.1.jar</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12768" opendate="2014-12-29 00:00:00" fixdate="2014-1-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support enable cache_data_on_write in Shell while creating table</summary>
      <description>A simple approach to support cache_data_on_write while creating table in shell.</description>
      <version>1.0.0,0.94.27,2.0.0</version>
      <fixedVersion>1.0.0,0.98.10,1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug id="12773" opendate="2014-12-29 00:00:00" fixdate="2014-1-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add warning message when user is trying to bulkload a large HFile.</summary>
      <description>As per the description.</description>
      <version>None</version>
      <fixedVersion>1.0.0,0.98.10</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
    </fixedFiles>
  </bug>
  <bug id="12774" opendate="2014-12-29 00:00:00" fixdate="2014-1-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix the inconsistent permission checks for bulkloading.</summary>
      <description>Three checks(prePrepareBulkLoad, preCleanupBulkLoad, preBulkLoadHFile) are being done while performing secure bulk load, and it looks the former two checks for 'W', while the later checks for 'C'. After having offline chat with jdcryans, looks like the inconsistency among checks were unintended. So, we can address this multiple ways. All checks should be for 'W' All checks should be for 'C' All checks should be for both 'W' and 'C'Posting the initial patch going by the first option. Open to discussion.</description>
      <version>None</version>
      <fixedVersion>1.0.0,0.98.10,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug id="12785" opendate="2014-12-30 00:00:00" fixdate="2014-1-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use FutureTask to timeout the attempt to get the lock for hbck</summary>
      <description>In reviewing HBASE-12607, Sean pointed out:It would be nice if we used a FutureTask to timeout the attempt to get the lock rather than wait the whole period and then fail.This issue is to address Sean's review comment.</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="12793" opendate="2014-12-31 00:00:00" fixdate="2014-1-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbck] closeRegionSilentlyAndWait() should log cause of IOException and retry until hbase.hbck.close.timeout expires</summary>
      <description>This is subtask on HBASE-12131 in order to handle gracefully network partitions.</description>
      <version>1.0.0,0.98.9</version>
      <fixedVersion>1.0.0,0.98.10,1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsckRepair.java</file>
    </fixedFiles>
  </bug>
  <bug id="12802" opendate="2015-1-4 00:00:00" fixdate="2015-1-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove unnecessary Table.flushCommits()</summary>
      <description>It looks like there are a lot of places where flushCommits() are called on tables that do not have autoFlush turned on. That might be a legacy concern from pre-autoFlush days. HBASE-12728 will likely result in removing the flushCommits() method from Table. The patch for this issue should remove all unnecessary calls to flushCommit() to prepare for the full fix.flushCommits() are only necessary after a setAutoFlushTo(false) is called. Here's the relevant code from HTable.java:HTable.java @Override public void put(final Put put) throws InterruptedIOException, RetriesExhaustedWithDetailsException { doPut(put); if (autoFlush) { flushCommits(); } } /** * {@inheritDoc} */ @Override public void put(final List&lt;Put&gt; puts) throws InterruptedIOException, RetriesExhaustedWithDetailsException { for (Put put : puts) { doPut(put); } if (autoFlush) { flushCommits(); } }Puts have implicit flushCommits() calls when autoFlush is true. Deletes are not affected by autoFlush() and are not directly impacted by flushCommits() since deletes are not added to the writeAysncBuffer.</description>
      <version>1.0.0,2.0.0</version>
      <fixedVersion>1.0.0,1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestWALFiltering.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.OfflineMetaRebuildTestCore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithDeletes.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabels.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationSmallTests.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerMetrics.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestEndToEndSplitTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompactionState.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTimeRangeMapRed.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestImportExport.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestPrefixTree.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestChangingEncoding.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverScannerOpenHook.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestOpenTableInCoprocessor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotCloneIndependence.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide3.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFastFail.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.TestScannersWithLabels.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.TestScannerResource.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.mttr.IntegrationTestMTTR.java</file>
    </fixedFiles>
  </bug>
  <bug id="12831" opendate="2015-1-9 00:00:00" fixdate="2015-1-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Changing the set of vis labels a user has access to doesn&amp;#39;t generate an audit log event</summary>
      <description>Right now, the AccessController makes sure that (when users care about audit events) we generate an audit log event for any access change, like granting or removing a permission from a user.When the set of labels a user has access to is altered, it gets handled by the VisibilityLabelService and we don't log anything to the audit log.</description>
      <version>1.0.0,0.98.6,2.0.0</version>
      <fixedVersion>1.0.0,0.98.10,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityController.java</file>
      <file type="M">conf.log4j.properties</file>
    </fixedFiles>
  </bug>
  <bug id="12899" opendate="2015-1-21 00:00:00" fixdate="2015-1-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase should prefix htrace configuration keys with "hbase.htrace" rather than just "hbase."</summary>
      <description>In Hadoop, we pass all configuration keys starting with "hadoop.htrace" to htrace. So "hadoop.htrace.sampler.fraction" gets passed to HTrace as sampler.fraction, and so forth.For consistency, it seems like HBase should prefix htrace configuration keys with "hbase.htrace" rather than just "hbase."</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0,1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.trace.HBaseHTraceConfiguration.java</file>
    </fixedFiles>
  </bug>
  <bug id="12944" opendate="2015-1-29 00:00:00" fixdate="2015-2-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support patches to branches in precommit jenkins build</summary>
      <description>We have a quite a few active branches now, which makes backporting a full time job. I was thinking about whether we can get hadoopqa to test the patches specific to branches with the code from that branch. I think we can grab the branch name from the patch file name and check out that branch prior to running the tests. I have a patch, but not sure whether it will work. Let me experiment a bit. If hadoopqa gets broken, it is probably this issue.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.properties</file>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  <bug id="12956" opendate="2015-2-3 00:00:00" fixdate="2015-2-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Binding to 0.0.0.0 is broken after HBASE-10569</summary>
      <description>After the Region Server and Master code was merged, we lost the functionality to bind to 0.0.0.0 via hbase.regionserver.ipc.address and znodes now get created with the wildcard address which means that RSs and the master cannot connect to each other. Thanks to dimaspivak for reporting the issue.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestHBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="12976" opendate="2015-2-5 00:00:00" fixdate="2015-2-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Set default value for hbase.client.scanner.max.result.size</summary>
      <description>Setting scanner caching is somewhat of a black art. It's hard to estimate ahead of time how large the result set will be.I propose we hbase.client.scanner.max.result.size to 2mb. That is good compromise between performance and buffer usage on typical networks (avoiding OOMs when the caching was chosen too high).To an HTable client this is completely transparent.</description>
      <version>None</version>
      <fixedVersion>1.0.0,1.1.0,0.98.11</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="12978" opendate="2015-2-5 00:00:00" fixdate="2015-2-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Region goes permanently offline (WAS: hbase:meta has a row missing hregioninfo and it causes my long-running job to fail)</summary>
      <description>Testing 1.0.0 trying long-running tests.A row in hbase:meta was missing its HRI entry. It caused the job to fail. Around the time of the first task failure, there are balances of the hbase:meta region and it was on a server that crashed. I tried to look at what happened around time of our writing hbase:meta and I ran into another issue; 20 logs of 256MBs filled with WrongRegionException written over a minute or two. The actual update of hbase:meta was not in the logs, it'd been rotated off.</description>
      <version>None</version>
      <fixedVersion>1.0.0,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileWriterV2.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestCellComparator.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellComparator.java</file>
    </fixedFiles>
  </bug>
  <bug id="13006" opendate="2015-2-10 00:00:00" fixdate="2015-3-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document visibility label support for groups</summary>
      <description>This is to document the changes added from HBASE-12745.</description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.security.adoc</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.set.auths.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.get.auths.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.clear.auths.rb</file>
    </fixedFiles>
  </bug>
  <bug id="13028" opendate="2015-2-12 00:00:00" fixdate="2015-2-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cleanup mapreduce API changes</summary>
      <description>The API changes made in HBASE-12798 need to be cleaned up so their common use makes more sense. initialize should take some kind of configuration object that can be used in setting up a Connection (e.g. JobConf) initialize should be called at the start of getSplits and getRecordReader rather than across the class when a member is needed the same changes should be present in the mapred package since it is not longer deprecated examples should rely on idiomatic MapReduce (specifically they should not be relying on JobConfigurable to get a JobConf instance)</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapred.TestTableInputFormat.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableInputFormatBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormat.java</file>
    </fixedFiles>
  </bug>
  <bug id="13054" opendate="2015-2-17 00:00:00" fixdate="2015-2-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Provide more tracing information for locking/latching events.</summary>
      <description>Currently not much tracing information available for locking and latching events like row level locking during do mini batch mutations, region level locking during flush, close and so on. It will be better to add the trace information for such events so that it will be useful for finding time spent on locking and waiting time on locks while analyzing performance issues in queries using trace information.</description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,0.98.11,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultMemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderV2.java</file>
    </fixedFiles>
  </bug>
  <bug id="13062" opendate="2015-2-18 00:00:00" fixdate="2015-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add documentation coverage for configuring dns server with thrift and rest gateways</summary>
      <description>Currently, the documentation doesn't cover about configuring DNS with thrift or rest gateways, though code base does provide provision for doing so. The following parameters are being used for accomplishing the same.For REST: hbase.rest.dns.interface hbase.rest.dns.nameserverFor Thrift: hbase.thrift.dns.interface hbase.thrift.dns.nameserver</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.security.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="13063" opendate="2015-2-18 00:00:00" fixdate="2015-3-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow to turn off memstore replication for region replicas</summary>
      <description>HBASE-11568 allows to use replication to send wal edits from the primary to the replicas.sometimes the memstore replication is not required, so it will be nice have a flag to disable it.the result will be more or less the same to what we have in phase-1, but with the row-level consistency provided by the "flush" edit transfered via replication to refresh the hfiles.create 't1', 'f', {REGION_REPLICATION =&gt; 2, REGION_MEMSTORE_REPLICATION =&gt; false}</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestRegionReplicaReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.ReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALEdit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ServerRegionReplicaUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionReplicaUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="13065" opendate="2015-2-18 00:00:00" fixdate="2015-2-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Increasing -Xmx when running TestDistributedLogSplitting</summary>
      <description>Found this in PreCommit Build reportshttps://builds.apache.org/job/PreCommit-HBASE-Build/12885/artifact/hbase-server/target/surefire-reports/org.apache.hadoop.hbase.master.TestDistributedLogSplitting-output.txt2015-02-18 03:45:42,141 WARN [RS:4;asf901:41265] util.Sleeper(97): We slept 59018ms instead of 1000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired2015-02-18 03:45:26,750 WARN [JvmPauseMonitor] util.JvmPauseMonitor$Monitor(167): Detected pause in JVM or host machine (eg GC): pause of approximately 39767msGC pool 'PS MarkSweep' had collection(s): count=65 time=47720msMaybe we should increase the max heap size since this test starts 6 regionservers.</description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,0.98.11,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="13074" opendate="2015-2-19 00:00:00" fixdate="2015-5-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cleaned up usage of hbase.master.lease.thread.wakefrequency</summary>
      <description>While checking for configs to tweak, I ran into hbase.master.lease.thread.wakefrequency, but it has been deprecated. There are however still references of it in a few tests classes so just cleaning it up..</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.test.resources.hbase-site.xml</file>
      <file type="M">hbase-spark.src.test.resources.hbase-site.xml</file>
      <file type="M">hbase-server.src.test.resources.hbase-site2.xml</file>
      <file type="M">hbase-server.src.test.resources.hbase-site.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorInterface.java</file>
      <file type="M">hbase-rest.src.test.resources.hbase-site.xml</file>
    </fixedFiles>
  </bug>
  <bug id="13081" opendate="2015-2-20 00:00:00" fixdate="2015-2-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Branch precommit builds are not updating to branch head before patch application</summary>
      <description>See for example https://builds.apache.org/job/PreCommit-HBASE-Build/12922//consolegit checkout 0.98Previous HEAD position was 03d8918... HBASE-13069 Thrift Http Server returns an error code of 500 instead of 401 when authentication fails (Srikanth Srungarapu)Switched to branch '0.98'Your branch is behind 'origin/0.98' by 48 commits, and can be fast-forwarded. (use "git pull" to update your local branch)git statusOn branch 0.98Your branch is behind 'origin/0.98' by 48 commits, and can be fast-forwarded. (use "git pull" to update your local branch)Untracked files: (use "git add &lt;file&gt;..." to include in what will be committed) patchprocess/nothing added to commit but untracked files present (use "git add" to track)Because the local tree is 48 commits behind the head of the 0.98 branch, the contributor's patch based on the head of 0.98 branch cannot cleanly apply.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  <bug id="13085" opendate="2015-2-23 00:00:00" fixdate="2015-2-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Security issue in the implementation of Rest gataway &amp;#39;doAs&amp;#39; proxy user support</summary>
      <description>When 'hbase.rest.support.proxyuser' is turned on, HBase Rest gateway support 'doAs' proxy user from the Rest client.The current implementation checks to see if the 'rest server user' is authorized to impersonate the 'doAs' user (the user in the 'doAs' Rest query string).if (doAsUserFromQuery != null) { Configuration conf = servlet.getConfiguration(); if (!servlet.supportsProxyuser()) { throw new ServletException("Support for proxyuser is not configured"); } UserGroupInformation ugi = servlet.getRealUser(); // create and attempt to authorize a proxy user (the client is attempting // to do proxy user) ugi = UserGroupInformation.createProxyUser(doAsUserFromQuery, ugi); // validate the proxy user authorization try { ProxyUsers.authorize(ugi, request.getRemoteAddr(), conf); } catch(AuthorizationException e) { throw new ServletException(e.getMessage()); } servlet.setEffectiveUser(doAsUserFromQuery); } The current implementation allows anyone from the rest client side to impersonate another user by 'doAs'. For example, potentially, 'user1' can 'doAs=admin'The correct implementation should check to see if the rest client user is authorized to do impersonation.</description>
      <version>1.0.0,0.98.10,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.11,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.RESTServletContainer.java</file>
    </fixedFiles>
  </bug>
  <bug id="13086" opendate="2015-2-23 00:00:00" fixdate="2015-2-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Show ZK root node on Master WebUI</summary>
      <description>Currently we show a well-formed ZK quorum on the master webUI but not the root node. Root node can be changed based on deployment, so we should list it here explicitly. This information is helpful for folks playing around with phoenix.</description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,0.98.11,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
    </fixedFiles>
  </bug>
  <bug id="13095" opendate="2015-2-25 00:00:00" fixdate="2015-3-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document how to retrieve replication stats from HBase Shell</summary>
      <description></description>
      <version>1.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="13103" opendate="2015-2-25 00:00:00" fixdate="2015-6-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[ergonomics] add region size balancing as a feature of master</summary>
      <description>Often enough, folks miss-judge split points or otherwise end up with a suboptimal number of regions. We should have an automated, reliable way to "reshape" or "balance" a table's region boundaries. This would be for tables that contain existing data. This might look like:Admin#reshapeTable(TableName, int numSplits);or from the shell:&gt; reshape TABLE, numSplitsBetter still would be to have a maintenance process, similar to the existing Balancer that runs AssignmentManager on an interval, to run the above "reshape" operation on an interval. That way, the cluster will automatically self-correct toward a desirable state.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="13111" opendate="2015-2-26 00:00:00" fixdate="2015-2-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>truncate_preserve command is failing with undefined method error</summary>
      <description>hbase(main):001:0&gt; truncate_preserve 't1'Truncating 't1' table (it may take a while):ERROR: undefined method `getTable' for nil:NilClassHere is some help for this command: Disables, drops and recreates the specified table while still maintaing the previous region boundaries.</description>
      <version>1.0.0,1.1.0,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.11,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug id="13123" opendate="2015-2-27 00:00:00" fixdate="2015-3-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Minor bug in ROW bloom filter</summary>
      <description>While checking the code for Bloom filter found that while checking if a key passes the ROW bloom check we try to create a bloom key. The bloom key should be constructed only with the row part of the key. But try to form the bloom key including the meta data part of the key.</description>
      <version>1.0.0,1.1.0,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.11,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
    </fixedFiles>
  </bug>
  <bug id="13149" opendate="2015-3-3 00:00:00" fixdate="2015-4-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase MR is broken on Hadoop 2.5+ Yarn</summary>
      <description>Running the server MR tools is not working on Yarn version 2.5+.Running org.apache.hadoop.hbase.mapreduce.Export:Exception in thread "main" java.lang.NoSuchMethodError: org.codehaus.jackson.map.ObjectMapper.setSerializationInclusion(Lorg/codehaus/jackson/map/annotate/JsonSerialize$Inclusion;)Lorg/codehaus/jackson/map/ObjectMapper; at org.apache.hadoop.yarn.webapp.YarnJacksonJaxbJsonProvider.configObjectMapper(YarnJacksonJaxbJsonProvider.java:59) at org.apache.hadoop.yarn.util.timeline.TimelineUtils.&lt;clinit&gt;(TimelineUtils.java:47) at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.serviceInit(YarnClientImpl.java:166) at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163) at org.apache.hadoop.mapred.ResourceMgrDelegate.serviceInit(ResourceMgrDelegate.java:102) at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163) at org.apache.hadoop.mapred.ResourceMgrDelegate.&lt;init&gt;(ResourceMgrDelegate.java:96) at org.apache.hadoop.mapred.YARNRunner.&lt;init&gt;(YARNRunner.java:112) at org.apache.hadoop.mapred.YarnClientProtocolProvider.create(YarnClientProtocolProvider.java:34) at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:95) at org.apache.hadoop.mapreduce.Cluster.&lt;init&gt;(Cluster.java:82) at org.apache.hadoop.mapreduce.Cluster.&lt;init&gt;(Cluster.java:75) at org.apache.hadoop.mapreduce.Job$9.run(Job.java:1266) at org.apache.hadoop.mapreduce.Job$9.run(Job.java:1262) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628) at org.apache.hadoop.mapreduce.Job.connect(Job.java:1261) at org.apache.hadoop.mapreduce.Job.submit(Job.java:1290) at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1314) at org.apache.hadoop.hbase.mapreduce.Export.main(Export.java:189)The problem seems to be the jackson jar version. HADOOP-10104 updated jackson version to 1.9.13. YARN-2092 reported a problem as well.HBase is using jackson 1.8.8. This version of the jar in the classpath seem to cause the problem.Should we upgrade to jackson 1.9.13?</description>
      <version>1.0.0,0.98.10.1,2.0.0</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="13174" opendate="2015-3-8 00:00:00" fixdate="2015-3-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Apply HBASE-11804 to Windows scripts</summary>
      <description>HBASE-11804 was only applied to the Linux scripts. Do the same for Windows. Need a +1 here from the Windows supporters, since this patch is a one liner but I need to know if it is OK to do on Windows. I'd say yes, but better ask first. cc enis</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.1,1.1.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase.cmd</file>
    </fixedFiles>
  </bug>
  <bug id="13221" opendate="2015-3-12 00:00:00" fixdate="2015-9-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HDFS Transparent Encryption breaks WAL writing in Hadoop 2.6.0</summary>
      <description>We need to detect when HDFS Transparent Encryption (Hadoop 2.6.0+) is enabled and fall back to more synchronization in the WAL to prevent catastrophic failure under load.See HADOOP-11708 for more details.</description>
      <version>0.98.0,1.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="13226" opendate="2015-3-13 00:00:00" fixdate="2015-3-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document enable_table_replication and disable_table_replication shell commands</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="13227" opendate="2015-3-13 00:00:00" fixdate="2015-3-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LoadIncrementalHFile should skip non-files inside a possible family-dir</summary>
      <description>if we have random files/dirs inside the bulkload family dir, we should try to skip them.</description>
      <version>1.0.0,1.1.0,0.98.11,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
    </fixedFiles>
  </bug>
  <bug id="13228" opendate="2015-3-13 00:00:00" fixdate="2015-3-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create procedure v2 branch and add it to QA branch list</summary>
      <description>to develop Procedure V2 quickly, we are going to commit stuff to an hbase-12439 branch.In theory we can have QA running if the patch name is HBASE-xyz-hbase-12439.patch</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.properties</file>
    </fixedFiles>
  </bug>
  <bug id="1323" opendate="2009-4-12 00:00:00" fixdate="2009-5-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase-1234 broke TestThriftServer; fix and reenable</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.thrift.DisabledTestThriftServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.ThriftUtilities.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13265" opendate="2015-3-17 00:00:00" fixdate="2015-3-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make thrift2 usable from c++</summary>
      <description>Currently the c++ code generated from our thrift2 idl doesn't compile. Mostly this is a naming issue for parameters.</description>
      <version>1.0.0,1.1.0,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.resources.org.apache.hadoop.hbase.thrift2.hbase.thrift</file>
    </fixedFiles>
  </bug>
  <bug id="13286" opendate="2015-3-19 00:00:00" fixdate="2015-3-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Minimum timeout for a rpc call could be 1 ms instead of 2 seconds</summary>
      <description>There is a check in the client to be sure that we don't use a timeout of zero (i.e. infinite). This includes setting the minimal time out for a rpc timeout to 2 seconds. However, it makes sense for some calls (typically gets going to the cache) to have much lower timeouts. So it's better to do the check vs. zero but with a minimal timeout of 1. I fixed a typo &amp; a wrong comment in this patch as well. I don't understand this code: // t could be a RemoteException so go around again. translateException(t); // We don't use the result?but may be it's good.</description>
      <version>1.0.0,0.98.12</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="13289" opendate="2015-3-19 00:00:00" fixdate="2015-4-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>typo in splitSuccessCount metric</summary>
      <description>Our split metrics have a misspelled Count and it shows up in our jmx metrics "splitSuccessCounnt" : 0,</description>
      <version>1.0.0,0.98.10,1.1.0,0.98.11,0.98.12,0.98.10.1,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="13294" opendate="2015-3-20 00:00:00" fixdate="2015-3-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix the critical ancient loopholes in security testing infrastructure.</summary>
      <description>Unfortunately, the "verifyDenied" method doesn't fail when action parameter returns null. The relevant code snippettry { Object obj = user.runAs(action); if (requireException) { fail("Expected exception was not thrown for user '" + user.getShortName() + "'"); } if (obj != null &amp;&amp; obj instanceof List&lt;?&gt;) { List&lt;?&gt; results = (List&lt;?&gt;) obj; if (results != null &amp;&amp; !results.isEmpty()) { fail("Unexpected results for user '" + user.getShortName() + "'"); } } }As you can see, when obj is null, it returns silently. Fixing this issue has uncovered another major bug. While constructing actions, we're using TEST_UTIL.getConnection(), which replaces the "doAs" user with the user who initiated the connection. I really am grateful to mbertozzi without whom debugging this would have been a nightmare. Now, fixing these two issues have uncovered more issues in our tests . The main one is we're allowing the table owner to truncate table in code. But, in test, we're not allowing him. We should either remove the code that allows owner or document that the table owner can truncate table.The other minor issues include granting permissions to namespace, but checking whether user was able to access tables inside other namespace. That's it, folks!</description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestScanEarlyTermination.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestNamespaceCommands.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestCellACLWithMultipleVersions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestCellACLs.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController2.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.SecureTestUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="13296" opendate="2015-3-20 00:00:00" fixdate="2015-4-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix the deletion of acl notify nodes for namespace.</summary>
      <description>Though we're clearing the permissions of namespaces in AccessControlLists, we're not taking care of clearing acl znodes related to namespace. Looking at the code, we're taking care of this case with tables.</description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController2.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.SecureTestUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.ZKPermissionWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug id="13307" opendate="2015-3-21 00:00:00" fixdate="2015-4-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Making methods under ScannerV2#next inlineable, faster</summary>
      <description>See parent issue for patch and evidence.I was looking at graphs of our scan and found that methods were 'too big' to be inlined (looking at jvm compilation and inlining output flags &amp;#8211; see parent for list). Changing method size helped some. Let me commit the resultant patch.</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestTags.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Bytes.java</file>
    </fixedFiles>
  </bug>
  <bug id="13326" opendate="2015-3-24 00:00:00" fixdate="2015-3-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Disabled table can&amp;#39;t be enabled after HBase is restarted</summary>
      <description>The folks at Intel discovered a pretty nasty bug in 1.0 and 1.1 (but not master). Steps to reproduce:1. Create a table, any table.2. Disable the table.3. Restart HBase.4. Try enabling the table.The table won't become enabled and the master web UI will indicate a never-ending region in transition. Also worth noting is that mbertozzi dug in and noted that this isn't happening in the master branch.</description>
      <version>1.0.0,1.1.0,0.98.12</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  <bug id="13332" opendate="2015-3-24 00:00:00" fixdate="2015-3-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix the usage of doAs/runAs in Visibility Controller tests.</summary>
      <description>The "doAs" bug is also affecting VC related tests too.</description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityWithCheckAuths.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLablesWithGroups.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithSLGStack.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithDeletes.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithDefaultVisLabelService.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithACL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabels.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelReplicationWithExpAsString.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestEnforcingScanLabelGenerator.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestDefaultScanLabelGeneratorStack.java</file>
    </fixedFiles>
  </bug>
  <bug id="13334" opendate="2015-3-25 00:00:00" fixdate="2015-4-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>FindBugs should create precise report for new bugs introduced</summary>
      <description>Currently findbugs build process reports only number of bugs introduced. And there is no report on what acutally was introduced.Lets improve that: we can use computeBugHistory to generate precise report on new bugs (and optionally missed bugs).Report should be available in html format.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.properties</file>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  <bug id="13362" opendate="2015-3-29 00:00:00" fixdate="2015-4-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Set max result size from client only (like scanner caching).</summary>
      <description>With the recent problems we've been seeing client/server result size mismatch, I was thinking: Why was this not a problem with scanner caching?There are two reasons: number of rows is easy to calculate (and we did it correctly) caching is only controlled from the client, never set on the server aloneWe did fix both #1 and #2 in HBASE-13262.Still, I'd like to discuss the following: default the client sent max result size to 2mb remove any server only result sizing continue to use hbase.client.scanner.max.result.size but enforce it via the client only (as the name implies anyway).Comments? Concerns?</description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="13369" opendate="2015-3-31 00:00:00" fixdate="2015-3-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expose scanNext stats to region server level</summary>
      <description>Regions have a scanNext_num_ops stat but there is no such stat at the regionserver level. The num_ops metrics at the RS level (exposed through JMX) are as follows: "SyncTime_num_ops" : 54, "AppendSize_num_ops" : 56, "AppendTime_num_ops" : 56, "Append_num_ops" : 0, "Delete_num_ops" : 0, "Mutate_num_ops" : 0, "Get_num_ops" : 0, "Replay_num_ops" : 0, "Increment_num_ops" : 0, "QueueCallTime_num_ops" : 53, "ProcessCallTime_num_ops" : 53,We need a scanNext_num_ops, along with 95th percentile stat, at the RS level.</description>
      <version>None</version>
      <fixedVersion>1.1.0,0.98.13,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServer.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerMetrics.java</file>
    </fixedFiles>
  </bug>
  <bug id="13374" opendate="2015-4-1 00:00:00" fixdate="2015-4-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Small scanners (with particular configurations) do not return all rows</summary>
      <description>I recently ran into a couple data loss issues with small scans. Similar to HBASE-13262, these issues only appear when scans are configured in such a way that the max result size limit is reached before the caching limit is reached. As far as I can tell, this issue affects branches 0.98+I should note that after investigation it looks like the root cause of these issues is not the same as HBASE-13262. Rather, these issue are caused by errors in the small scanner logic (I will explain in more depth below). Furthermore, I do know that the solution from HBASE-13262 has not made its way into small scanners (it is being addressed in HBASE-13335). As a result I made sure to test these issues with the patch from HBASE-13335 applied and I saw that they were still present.The following two issues have been observed (both lead to data loss):1. When a small scan is configured with a caching value of Integer.MAX_VALUE, and a maxResultSize limit that is reached before the region is exhausted, integer overflow will occur. This eventually leads to a preemptive skip of the regions.2. When a small scan is configured with a maxResultSize that is smaller than the size of a single row, the small scanner will jump between regions preemptively. This issue seems to be because small scanners assume that, unless a region is exhausted, at least 2 rows will be returned from the server. This assumption isn't clearly state in the small scanners but is implied through the use of skipRowOfFirstResult.Again, I would like to stress that the root cause of these issues is NOT related to the cause of HBASE-13262. These issues occur because of inappropriate assumption made in the small scanner logic. The inappropriate assumptions are:1. Integer overflow will not occur when incrementing caching2. At least 2 rows will be returned from the server unless the region has been exhaustedI am attaching a patch that contains tests to display these issues. If these issues should be split into separate JIRAs please let me know.</description>
      <version>1.0.0,1.1.0,0.98.13,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannersFromClientSide.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallReversedScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="13375" opendate="2015-4-1 00:00:00" fixdate="2015-5-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Provide HBase superuser higher priority over other users in the RPC handling</summary>
      <description>HBASE-13351 annotates Master RPCs so that RegionServer RPCs are treated with a higher priority compared to user RPCs (and they are handled by a separate set of handlers, etc.). It may be good to stretch this to users too - hbase superuser (configured via hbase.superuser) gets higher priority over other users in the RPC handling. That way the superuser can always perform administrative operations on the cluster even if all the normal priority handlers are occupied (for example, we had a situation where all the master's handlers were tied up with many simultaneous createTable RPC calls from multiple users and the master wasn't able to perform any operations initiated by the admin). (Discussed this some with enis and elserj).Does this make sense to others?</description>
      <version>None</version>
      <fixedVersion>1.2.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestQosFunction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestPriorityRpc.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterPriorityRpc.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.AnnotationReadingPriorityFunction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.PriorityFunction.java</file>
    </fixedFiles>
  </bug>
  <bug id="13376" opendate="2015-4-1 00:00:00" fixdate="2015-2-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improvements to Stochastic load balancer</summary>
      <description>There are two things this jira tries to address:1. The locality picker in the stochastic balancer does not pick regions with least locality as candidates for swap/move. So when any user configures locality cost in the configs, the balancer does not always seems to move regions with bad locality. 2. When a cluster has equal number of loaded regions, it always picks the first one. It should pick a random region on one of the equally loaded servers. This improves a chance of finding a good candidate, when load picker is invoked several times.</description>
      <version>1.0.0,0.98.12</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestStochasticLoadBalancer2.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestStochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.BalancerTestBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.RegionLocationFinder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
    </fixedFiles>
  </bug>
  <bug id="1338" opendate="2009-4-22 00:00:00" fixdate="2009-4-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBASE-1234 lost use of compaction.dir; we were compacting into live store subdirectory</summary>
      <description>Found up on Ryan's cluster.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.BaseScanner.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13393" opendate="2015-4-3 00:00:00" fixdate="2015-5-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Optimize memstore flushing to avoid writing tag information to hfiles when no tags are present.</summary>
      <description>We used to specify 'no tags' by choosing to write files that were version 2. After parent goes in, make it so can ask a v3 file not to write tags.</description>
      <version>None</version>
      <fixedVersion>1.2.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabels.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreSnapshot.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultMemStore.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestKeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValueUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.KeyValueCodecWithTags.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.KeyValueCodec.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
    </fixedFiles>
  </bug>
  <bug id="13412" opendate="2015-4-6 00:00:00" fixdate="2015-4-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Region split decisions should have jitter</summary>
      <description>Whenever a region splits it causes lots of IO (compactions are queued for a while). Because of this it's important to make sure that well distributed tables don't have all of their regions split at exactly the same time.This is basically the same as our compaction jitter.</description>
      <version>1.0.0,2.0.0</version>
      <fixedVersion>1.1.0,0.98.13,2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy.java</file>
    </fixedFiles>
  </bug>
  <bug id="13413" opendate="2015-4-6 00:00:00" fixdate="2015-4-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create an integration test for Replication</summary>
      <description>We want to have an end-to-end test for replication. it can write data into one cluster (with replication setup) and then read data from the other. The test should be capable of running for a long time and be reliant even under chaos monkey testing.</description>
      <version>1.0.0,2.0.0</version>
      <fixedVersion>1.1.0,0.98.13,2.0.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="1345" opendate="2009-4-24 00:00:00" fixdate="2009-5-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove distributed mode from MiniZooKeeper</summary>
      <description>MiniZooKeeper currently has a standalone and a distributed mode. For HBase testing we only need (and only use) the standalone mode. We should remove all of the distributed logic.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.TestZooKeeper.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.MiniZooKeeperCluster.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.HBaseClusterTestCase.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13453" opendate="2015-4-10 00:00:00" fixdate="2015-4-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Master should not bind to region server ports</summary>
      <description>In 1.0, master by default binds to the region server ports (rpc and info). We have done it so thinking that in the long term, master and meta co-location will be default, and we can merge the master and region server as a single daemon. Over at HBASE-11165, if the conclusion end up being that meta will not be colocated at all, then master hosting a region server will just become an implementation detail. saint.ack@gmail.com says that we might never allow master to host regions. Now, we are stuck in a state where we have made master bind to RS ports in 1.0, which might create some confusion (and frustration) for small cluster users who traditionally used to host a master and a region server on the same node.I think we should undo this in 1.1 and use the previous master ports (16000) and not bind to 16030, so that the user does not need to do anything to bring up a RS on the same host. At least users going from 0.98 -&gt; 1.1 will not take a hit. Users going from 1.0 -&gt; 1.1 will see changed default ports.</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="13477" opendate="2015-4-15 00:00:00" fixdate="2015-4-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create metrics on failed requests</summary>
      <description>Add a metric on how many requests failed/errored out.</description>
      <version>1.0.0,2.0.0</version>
      <fixedVersion>1.1.0,0.98.13,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestRpcMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServer.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceFactoryImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="13478" opendate="2015-4-15 00:00:00" fixdate="2015-11-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document the change of default master ports being used .</summary>
      <description>In 1.0.x, master by default binds to the region server ports. But in 1.1 and 2.0 branches, we have undone this changes and brought back the usage of old master ports to make the migration from 0.98 -&gt; 1.1 hassle free. Please see the parent jira for more background.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="13481" opendate="2015-4-15 00:00:00" fixdate="2015-4-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Master should respect master (old) DNS/bind related configurations</summary>
      <description>This is a continuation of parent HBASE-13453. We should continue respecting the following parameters that 1.0.0 does not: hbase.master.dns.interfacehbase.master.dns.nameserverhbase.master.ipc.addressCredit goes to jerryhe for pointing that out.</description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.RatioBasedCompactionPolicy.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerHostname.java</file>
    </fixedFiles>
  </bug>
  <bug id="13527" opendate="2015-4-22 00:00:00" fixdate="2015-4-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The default value for hbase.client.scanner.max.result.size is never actually set on Scans</summary>
      <description>Now that max result size is driven from the client side like caching (HBASE-13362), we also need to set Scan.maxResultSize to the default value of hbase.client.scanner.max.result.size which is never performed. I think this has gone unnoticed because the server used to read the configuration hbase.client.scanner.max.result.size for itself, but now we expect the serialized Scan sent from the client side to contain this information. Realistically this should have been set on the Scans even before HBASE-13362, it's surprising that it's not as the scanner code seems to indicate otherwise.Ultimately, the end result is that, by default, scan RPC's are limited by hbase.server.scanner.max.result.size (note this is the new server side config not the client side config) which has a default value of 100 MB. The scan RPC's should instead be limited by hbase.client.scanner.max.result.size which has a default value of 2 MB.The reason why this issue occurs is because, by default, a new Scan() initializes Scan.maxResultSize to -1. This initial value of -1 will never be changed unless Scan#setMaxResultSize() is called. In the event that this value is not changed, the Scan that is serialized and sent to the server will also have Scan.maxResultSize = -1. Then, when the server is deciding what size limit should be enforced, it sees that Scan.maxResultSize = -1 so it uses the most relaxed size restriction possible, which is hbase.server.scanner.max.result.size (default value 100 MB).</description>
      <version>1.0.0,1.1.0,0.98.12,1.2.0,2.0.0</version>
      <fixedVersion>1.1.0,0.98.12,1.0.2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannersFromClientSide.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.TableConfiguration.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="13561" opendate="2015-4-25 00:00:00" fixdate="2015-7-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ITBLL.Verify doesn&amp;#39;t actually evaluate counters after job completes</summary>
      <description>Was digging through ITBLL and noticed this oddity:The Verify Tool doesn't actually call Verify#verify(long) like the Loop Tool does. Granted, it doesn't know the total number of KVs that were written given the current arguments, it's not even checking to see if there things like UNDEFINED records found.It seems to me that Verify should really be doing some checking on the counters like Loop does and not just leaving it up to the visual inspection of whomever launched the task.Am I missing something?</description>
      <version>1.0.0,1.1.0,0.98.12,2.0.0</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
    </fixedFiles>
  </bug>
  <bug id="13563" opendate="2015-4-25 00:00:00" fixdate="2015-4-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add missing table owner to AC tests.</summary>
      <description>As per the description.</description>
      <version>None</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
    </fixedFiles>
  </bug>
  <bug id="13577" opendate="2015-4-27 00:00:00" fixdate="2015-4-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Documentation is pointing to wrong port for Master Web UI</summary>
      <description>At the bottom of section 2.4 in the Hbase Documentation, there is a section about Browsing the web UI that makes several references to port 16610. http://hbase.apache.org/book.html#quickstart_fully_distributed&lt;DOCUMENTATION&gt;"In HBase newer than 0.98.x, the HTTP ports used by the HBase Web UI changed from 60010 for the Master and 60030 for each RegionServer to 16610 for the Master and 16030 for the RegionServer.If everything is set up correctly, you should be able to connect to the UI for the Master http://node-a.example.com:16610/ or the secondary master at http://node-b.example.com:16610/ for the secondary master, using a web browser. If you can connect via localhost but not from another host, check your firewall rules. You can see the web UI for each of the RegionServers at port 16630 of their IP addresses, or by clicking their links in the web UI for the Master."&lt;/DOCUMENTATION&gt;This is the wrong port; it should instead be 16010. The correct port is listed in Section 6: http://hbase.apache.org/book.html#confirmThis might seem like a pretty minor issue, but it took me a couple hours to figure out.</description>
      <version>1.0.0</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.getting.started.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="13579" opendate="2015-4-28 00:00:00" fixdate="2015-5-28 01:00:00" resolution="Pending Closed">
    <buginformation>
      <summary>Avoid isCellTTLExpired() for NO-TAG cases</summary>
      <description>As observed in this JIRA's performance test, we are always calling the isCellTTLExpired() for every cell and internally it is parsing the keyLength, valueLength() to get the tagsLength after which we decide whether Cell level TTL is present are not.This JIRA aims to avoid this check if all the readers of the storescanner knows that there are no tags to read. Note that, for the memstore scanner we will do that in another JIRA, which I suppose Stack had already raised to avoid tag length while flushing (for the NO-TAG) case.</description>
      <version>1.0.0,1.0.1</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="13582" opendate="2015-4-28 00:00:00" fixdate="2015-5-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update docs for HTrace</summary>
      <description>the ref guide currently points to HTrace at its old location. update it to point at the ASF project. Should also verify that the usage example is still correct.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.tracing.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="13599" opendate="2015-4-30 00:00:00" fixdate="2015-5-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The Example Provided in Section 69: Examples of the Documentation Does Not Compile</summary>
      <description>I'm trying to build and run the example java code I found in the HBase Documentation, and I'm running into several issues.1. I don't have the code/library used in the following import:import static com.example.hbase.Constants.*;I don't believe it is included in any of the HBase libraries or documentation.2. All of the methods in createOrOverwrite() that use table.getName() should instead be using table.getTableName()3. The interface org.apache.hadoop.hbase.client.Admin is abstract, and can't be instantiated with a Configuration. Constructing an org.apache.hadoop.hbase.client.HBaseAdmin would allow the code to compile, but that constructor is deprecated.4. I have no references to the field "TABLE_NAME" or "CF_DEFAULT". I'm assuming they are Strings in com.example.hbase.Constants. Perhaps those variables should simply be copied into the the Example?Link to the documentation section:http://hbase.apache.org/book.html#_examples&lt;code&gt;package com.example.hbase.admin;import java.io.IOException;import org.apache.hadoop.hbase.HBaseConfiguration;import org.apache.hadoop.hbase.HColumnDescriptor;import org.apache.hadoop.hbase.HTableDescriptor;import org.apache.hadoop.hbase.TableName;import org.apache.hadoop.hbase.client.Admin;import org.apache.hadoop.hbase.io.compress.Compression.Algorithm;import org.apache.hadoop.conf.Configuration;import static com.example.hbase.Constants.*;public class CreateSchema { public static void createOrOverwrite(Admin admin, HTableDescriptor table) throws IOException { if (admin.tableExists(table.getName())) { admin.disableTable(table.getName()); admin.deleteTable(table.getName()); } admin.createTable(table); } public static void createSchemaTables (Configuration config) { try { final Admin admin = new Admin(config); HTableDescriptor table = new HTableDescriptor(TableName.valueOf(TABLE_NAME)); table.addFamily(new HColumnDescriptor(CF_DEFAULT).setCompressionType(Algorithm.SNAPPY)); System.out.print("Creating table. "); createOrOverwrite(admin, table); System.out.println(" Done."); admin.close(); } catch (Exception e) { e.printStackTrace(); System.exit(-1); } }}&lt;/code&gt;</description>
      <version>1.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.hbase.apis.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="13601" opendate="2015-4-30 00:00:00" fixdate="2015-5-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Connection leak during log splitting</summary>
      <description>Ran into an issue where Region server died with the following exception2015-04-29 17:10:11,856 WARN [nector@0.0.0.0:60030] mortbay.log - EXCEPTIONjava.io.IOException: Too many open files at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method) at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:241) at org.mortbay.jetty.nio.SelectChannelConnector$1.acceptChannel(SelectChannelConnector.java:75) at org.mortbay.io.nio.SelectorManager$SelectSet.doSelect(SelectorManager.java:686) at org.mortbay.io.nio.SelectorManager.doSelect(SelectorManager.java:192) at org.mortbay.jetty.nio.SelectChannelConnector.accept(SelectChannelConnector.java:124) at org.mortbay.jetty.AbstractConnector$Acceptor.run(AbstractConnector.java:708) at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)Realized that all the tcp sockets on the system were used out due to the regionserver trying to split the log and failing multiple times and leaving a connection open -java.io.IOException: Got error for OP_READ_BLOCK, self=/10..99.3:50695, remote=/10.232.99.36:50010, for file /hbase/WALs/host1,60020,1425930917890-splitting/host1%2C60020%2C1425930917890.1429358890944, for pool BP-181199659-10.232.99.2-1411124363096 block 1074497051_756497 at org.apache.hadoop.hdfs.RemoteBlockReader2.checkSuccess(RemoteBlockReader2.java:432) at org.apache.hadoop.hdfs.RemoteBlockReader2.newBlockReader(RemoteBlockReader2.java:397) at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:786) at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:665) at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:325) at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:567) at org.apache.hadoop.hdfs.DFSInputStream.seekToNewSource(DFSInputStream.java:1446) at org.apache.hadoop.hdfs.DFSInputStream.readBuffer(DFSInputStream.java:769) at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:799) at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:840) at java.io.DataInputStream.read(DataInputStream.java:100) at org.apache.hadoop.hbase.regionserver.wal.HLogFactory.createReader(HLogFactory.java:124) at org.apache.hadoop.hbase.regionserver.wal.HLogFactory.createReader(HLogFactory.java:91) at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.getReader(HLogSplitter.java:660) at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.getReader(HLogSplitter.java:569) at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.splitLogFile(HLogSplitter.java:282) at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.splitLogFile(HLogSplitter.java:225) at org.apache.hadoop.hbase.regionserver.SplitLogWorker$1.exec(SplitLogWorker.java:143) at org.apache.hadoop.hbase.regionserver.handler.HLogSplitterHandler.process(HLogSplitterHandler.java:82) at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745)</description>
      <version>1.0.0,0.98.10</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="13604" opendate="2015-4-30 00:00:00" fixdate="2015-5-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>bin/hbase mapredcp does not include yammer-metrics jar</summary>
      <description>Noticed this while testing hive integration with HBase snapshots. The yammer metrics jar is needed for working with snapshots, but we don't include it in the bin/hbase mapredcp output. That means the necessary classes are not on Hive's classpath by default.</description>
      <version>None</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="13622" opendate="2015-5-5 00:00:00" fixdate="2015-11-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>document upgrade rollback</summary>
      <description>I have some docs on doing a rollback of an hbase upgrade that are currently vendor specific. polish them up, make them suitable for HBase generally, and add them to the ref guide.</description>
      <version>0.98.0,1.0.0,1.1.0</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="13635" opendate="2015-5-6 00:00:00" fixdate="2015-5-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Regions stuck in transition because master is incorrectly assumed dead</summary>
      <description>On master I see:15/05/05 20:56:38 INFO master.HMaster: balance hri=hbase:meta,,1.1588230740, src=hbase1375.prn2.facebook.com,16020,1430858968368, dest=hbase1377.prn2.facebook.com,16020,143088426455415/05/05 20:56:38 INFO master.RegionStates: Transition {1588230740 state=OPEN, ts=1430876450098, server=hbase1375.prn2.facebook.com,16020,1430858968368} to {1588230740 state=PENDING_CLOSE, ts=1430884598277, server=hbase1375.prn2.facebook.com,16020,1430858968368}Tue May 05 21:01:54 PDT 2015, null, java.net.SocketTimeoutException: callTimeout=60000, callDuration=60724: row '' on table 'hbase:meta' at region=hbase:meta,,1.1588230740, hostname=hbase1375.prn2.facebook.com,16020,1430858968368, seqNum=0Caused by: java.net.SocketTimeoutException: callTimeout=60000, callDuration=60724: row '' on table 'hbase:meta' at region=hbase:meta,,1.1588230740, hostname=hbase1375.prn2.facebook.com,16020,1430858968368, seqNum=0On the regionserver I see the following log spew:15/05/06 09:30:11 INFO regionserver.HRegionServer: Failed to report region transition, will retryorg.apache.hadoop.hbase.ipc.FailedServerException: This server is in the failed servers list: hbasectrl054.prn2.facebook.com/10.104.157.28:16020 at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.setupIOstreams(RpcClientImpl.java:694) at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.writeRequest(RpcClientImpl.java:880) at or^Cg.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.tracedWriteRequest(RpcClientImpl.java:849) at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1173) at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:216) at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:300) at org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionServerStatusService$BlockingStub.reportRegionStateTransition(RegionServerStatusProtos.java:8325) at org.apache.hadoop.hbase.regionserver.HRegionServer.reportRegionStateTransition(HRegionServer.java:1863) at org.apache.hadoop.hbase.regionserver.HRegionServer.reportRegionStateTransition(HRegionServer.java:1837) at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:157) at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745)</description>
      <version>1.0.0</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestQosFunction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.AnnotationReadingPriorityFunction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor.java</file>
    </fixedFiles>
  </bug>
  <bug id="13639" opendate="2015-5-7 00:00:00" fixdate="2015-7-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>SyncTable - rsync for HBase tables</summary>
      <description>Given HBase tables in remote clusters with similar but not identical data, efficiently update a target table such that the data in question is identical to a source table. Efficiency in this context means using far less network traffic than would be required to ship all the data from one cluster to the other. Takes inspiration from rsync.Design doc: https://docs.google.com/document/d/1-2c9kJEWNrXf5V4q_wBcoIXfdchN7Pxvxv1IO6PW0-U/</description>
      <version>None</version>
      <fixedVersion>0.98.14,1.2.0,2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestBytes.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Bytes.java</file>
    </fixedFiles>
  </bug>
  <bug id="1364" opendate="2009-5-1 00:00:00" fixdate="2009-4-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[performance] Distributed splitting of regionserver commit logs</summary>
      <description>HBASE-1008 has some improvements to our log splitting on regionserver crash; but it needs to run even faster.(Below is from HBASE-1008)In bigtable paper, the split is distributed. If we're going to have 1000 logs, we need to distribute or at least multithread the splitting.1. As is, regions starting up expect to find one reconstruction log only. Need to make it so pick up a bunch of edit logs and it should be fine that logs are elsewhere in hdfs in an output directory written by all split participants whether multithreaded or a mapreduce-like distributed process (Lets write our distributed sort first as a MR so we learn whats involved; distributed sort, as much as possible should use MR framework pieces). On startup, regions go to this directory and pick up the files written by split participants deleting and clearing the dir when all have been read in. Making it so can take multiple logs for input, can also make the split process more robust rather than current tenuous process which loses all edits if it doesn't make it to the end without error.2. Each column family rereads the reconstruction log to find its edits. Need to fix that. Split can sort the edits by column family so store only reads its edits.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLogSplit.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13656" opendate="2015-5-10 00:00:00" fixdate="2015-5-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Rename getDeadServers to getDeadServersSize in Admin</summary>
      <description>The name is inconsistent with the other methods (e.g. getServersSize &amp; getBackupMastersSize.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ClusterStatus.java</file>
    </fixedFiles>
  </bug>
  <bug id="13716" opendate="2015-5-19 00:00:00" fixdate="2015-5-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Stop using Hadoop&amp;#39;s FSConstants</summary>
      <description>the FSConstants class was removed in HDFS-8135 (currently slated for Hadoop 2.8.0). I'm trying to have it reverted in branch-2, but we should migrate off of it sooner rather htan later.</description>
      <version>1.0.0,1.1.0</version>
      <fixedVersion>1.2.0,2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestWALFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="13821" opendate="2015-6-1 00:00:00" fixdate="2015-6-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>WARN if hbase.bucketcache.percentage.in.combinedcache is set</summary>
      <description>HBASE-11520 improved configuration of bucket cache to no longer require hbase.bucketcache.percentage.in.combinedcache. This was done rather aggressively, with this previously mandatory configuration being ignored. This can result in RS crashes for unsuspecting users. We should add a WARN when hbase.bucketcache.percentage.in.combinedcache is set to make debugging the crash more straight forward.</description>
      <version>1.0.0,1.1.0,1.2.0,2.0.0</version>
      <fixedVersion>1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
    </fixedFiles>
  </bug>
  <bug id="13863" opendate="2015-6-8 00:00:00" fixdate="2015-6-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Multi-wal feature breaks reported number and size of HLogs</summary>
      <description>When multi-wal is enabled the number and size of retained HLogs is always reported as zero.We should fix this so that the numbers are the sum of all retained logs.</description>
      <version>1.0.0,1.1.0</version>
      <fixedVersion>1.0.2,1.2.0,1.1.2,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.DefaultWALProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.BoundedRegionGroupingProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="13907" opendate="2015-6-16 00:00:00" fixdate="2015-12-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document how to deploy a coprocessor</summary>
      <description>Capture this information:&gt; Where are the dependencies located for these classes? Is there a path on HDFS or local disk that dependencies need to be placed so that each RegionServer has access to them?It is suggested to bundle them as a single jar so that RS can load the whole jar and resolve dependencies. If you are not able to do that, you need place the dependencies in regionservers class path so that they are loaded during RS startup. Do either of these options work for you? Btw, you can load the coprocessors/filters into path specified by hbase.dynamic.jars.dir &amp;#91;1&amp;#93;, so that they are loaded dynamically by regionservers when the class is accessed (or you can place them in the RS class path too, so that they are loaded during RS JVM startup).&gt; How would one deploy these using an automated system? (puppet/chef/ansible/etc)You can probably use these tools to automate shipping the jars to above locations?&gt; Tests our developers have done suggest that simply disabling a coprocessor, replacing the jar with a different version, and enabling the coprocessor again does not load the newest version. With that in mind how does one know which version is currently deployed and enabled without resorting to parsing `hbase shell` output or restarting hbase?Actually this is a design issue with current classloader. You can't reload a class in a JVM unless you delete all the current references to it. Since the current JVM (classloader) has reference to it, you can't overwrite it unless you kill the JVM, which is equivalent to restarting it. So you still have the older class loaded in place. For this to work, classloader design should be changed. If it works for you, you can rename the coprocessor class name and the new version of jar and RS loads it properly.&gt; Where does logging go, and how does one access it? Does logging need to be configured in a certain way?Can you please specify which logging you are referring to?&gt; Where is a good location to place configuration files?Same as above, are these hbase configs or something else? If hbase configs, are these gateway configs/server side?</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.cp.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="13918" opendate="2015-6-16 00:00:00" fixdate="2015-6-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix hbase:namespace description in webUI</summary>
      <description>This inconsistency bothers me.hbase:meta The hbase:meta table holds references to all User Table regionshbase:namespace The .NAMESPACE. table holds information about namespaces.Should it be the .NAMESPACE. table? or should it be hbase:namespace</description>
      <version>1.0.0</version>
      <fixedVersion>0.98.14,1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="13933" opendate="2015-6-18 00:00:00" fixdate="2015-6-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>DBE&amp;#39;s seekBefore with tags corrupts the tag&amp;#39;s offset information thus leading to incorrect results</summary>
      <description>The problem occurs with moveToPrevious() case and incase of tags we copy the previous pointer's tag info to the current because already decoded the tags.Will check once again before I post other details. I have a test case to reproduce the problem. Found this while working with MultibyteBuffers and verified if this is present in trunk - it is in all branches where we have tags compression (I suppose) will verify</description>
      <version>1.0.0,1.0.1,1.1.0,0.98.13,1.0.1.1,1.1.0.1,2.0.0</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.1,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestSeekTo.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
    </fixedFiles>
  </bug>
  <bug id="13938" opendate="2015-6-19 00:00:00" fixdate="2015-6-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Deletes done during the region merge transaction may get eclipsed</summary>
      <description>Was looking at an issue from our internal testing. It seems the Deletes of the region rows from the meta done during the merge transaction could be eclipsed by the Put of a region row that might have happened moments before.The master logs this for the merge:2015-06-18 13:13:46,018 INFO [AM.ZK.Worker-pool2-t12] master.AssignmentManager: Handled MERGED event; merged=IntegrationTestIngest,a666665c,1434633226681.0927319db6bf5e128e3bec2a420819aa., region_a=IntegrationTestIngest,a666665c,1434631353820.8b911862d7705ac808b8d132d0154c16., region_b=IntegrationTestIngest,acccccc2,1434631353820.1bdaf759862f45d133ef77fdbda21aec., on ddas-2-5.openstacklocal,16020,1434632778438One of the regions that got merged got Opened a few seconds back:2015-06-18 13:13:46,591 INFO [RS_OPEN_REGION-ddas-2-5:16020-1] regionserver.HRegion: Onlined 1bdaf759862f45d133ef77fdbda21aec; next sequenceid=182988The above would have done a Put in the meta.Looking at the raw scan of the meta, for the new merged region, the creation timestamp is 1434633226101: IntegrationTestIngest,a666665c,1434633226681.0927319db6bf5e128e3bec2a420819aa. column=info:regioninfo, timestamp=1434633226101, value={ENCODED =&gt; 0927319db6bf5e128e3bec2a420819aa, NAME =&gt; 'IntegrationTestIngest,a666665c,1434633226681.0927319db6bf5e128e3bec2a420819aa.', STARTKEY =&gt; 'a666665c', ENDKEY =&gt; 'b3333328'}Looking at the raw scan of the meta, the timestamp for the region open of the already merged region is 1434633226600. This is a little after the merge transaction's timestamp.IntegrationTestIngest,acccccc2,1434631353820.1bdaf759862f45d133ef77fdbda21aec. column=info:seqnumDuringOpen, timestamp=1434633226600, value=\x00\x00\x00\x00\x00\x02\xCA\xCC IntegrationTestIngest,acccccc2,1434631353820.1bdaf759862f45d133ef77fdbda21aec. column=info:server, timestamp=1434633226600, value=ddas-2-5.openstacklocal:16020 IntegrationTestIngest,acccccc2,1434631353820.1bdaf759862f45d133ef77fdbda21aec. column=info:serverstartcode, timestamp=1434633226600, value=1434632778438We need to fix it so that the merge region transaction also takes the master's timestamp. Similar to HBASE-13875.When this happens, clients start to see a row in the meta with an empty HRegionInfo (this is because the Put done during the region open only updates the location information but not the HRI, and the HRI deleted during the merge transaction "remains deleted").</description>
      <version>None</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.1,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestMetaTableAccessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionMergeTransactionImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionMergeRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStateStore.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Admin.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.AdminProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MetaTableAccessor.java</file>
    </fixedFiles>
  </bug>
  <bug id="14027" opendate="2015-7-6 00:00:00" fixdate="2015-7-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up netty dependencies</summary>
      <description>We have multiple copies of Netty (3?) getting shipped around. clean some up.</description>
      <version>1.0.0</version>
      <fixedVersion>1.2.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-it.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="14030" opendate="2015-7-7 00:00:00" fixdate="2015-5-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase Backup/Restore Phase 1</summary>
      <description>This is the umbrella ticket for Backup/Restore Phase 1. See HBASE-7912 design doc for the phase description.</description>
      <version>None</version>
      <fixedVersion>HBASE-7912</fixedVersion>
      <type>Umbrella</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestRemoteBackup.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.procedure.SimpleRSProcedureManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestRestoreBoundaryTests.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestRemoteRestore.java</file>
      <file type="M">bin.hbase</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupCommands.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupCopyService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupManifest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupRestoreConstants.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupRestoreServiceFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupStatus.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupSystemTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupSystemTableHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.HBackupFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.IncrementalBackupManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.IncrementalRestoreService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.mapreduce.MapReduceBackupCopyService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.mapreduce.MapReduceRestoreService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.master.BackupLogCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.master.LogRollMasterProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.regionserver.LogRollBackupSubprocedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.regionserver.LogRollBackupSubprocedurePool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.regionserver.LogRollRegionServerProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.RestoreClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.RestoreUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.BaseCoordinatedStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.WALPlayer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.flush.RegionServerFlushTableProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.RegionServerProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.RegionServerProcedureManagerHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureCoordinatorRpcs.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureMemberRpcs.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.snapshot.RegionServerSnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotCopy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.DefaultWALProvider.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestBackupBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestBackupBoundaryTests.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestBackupLogCleaner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestBackupSystemTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestFullBackup.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestFullRestore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestIncrementalBackup.java</file>
    </fixedFiles>
  </bug>
  <bug id="1404" opendate="2009-5-11 00:00:00" fixdate="2009-5-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>minor edit of regionserver logging messages</summary>
      <description>Some minor edits of regionserver logging; coalesce a few so less emissions.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.MemcacheFlusher.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HLog.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="14193" opendate="2015-8-7 00:00:00" fixdate="2015-9-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove support for direct upgrade from pre-0.96 versions</summary>
      <description>As discussed on the mailing list this will remove all support for upgrades from pre-0.96 versions.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSTableDescriptorMigrationToSubdir.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">bin.hbase.cmd</file>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug id="14260" opendate="2015-8-19 00:00:00" fixdate="2015-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>don&amp;#39;t build javadocs for hbase-protocol module</summary>
      <description>I'm not sure I have all the affected versions, but it seems that something is amiss in making our javadocs: mvn -Papache-release -Prelease -DskipTests clean package... SNIP ...[INFO] ------------------------------------------------------------------------[INFO] Reactor Summary:[INFO] [INFO] Apache HBase ....................................... SUCCESS [ 11.149 s][INFO] Apache HBase - Checkstyle .......................... SUCCESS [ 1.249 s][INFO] Apache HBase - Resource Bundle ..................... SUCCESS [ 0.539 s][INFO] Apache HBase - Annotations ......................... SUCCESS [ 4.438 s][INFO] Apache HBase - Protocol ............................ SUCCESS [10:15 min][INFO] Apache HBase - Common .............................. SUCCESS [ 48.465 s][INFO] Apache HBase - Procedure ........................... SUCCESS [ 14.375 s][INFO] Apache HBase - Client .............................. SUCCESS [ 45.187 s][INFO] Apache HBase - Hadoop Compatibility ................ SUCCESS [ 6.998 s][INFO] Apache HBase - Hadoop Two Compatibility ............ SUCCESS [ 14.891 s][INFO] Apache HBase - Prefix Tree ......................... SUCCESS [ 14.214 s][INFO] Apache HBase - Server .............................. SUCCESS [02:01 min][INFO] Apache HBase - Testing Util ........................ SUCCESS [ 12.779 s][INFO] Apache HBase - Thrift .............................. SUCCESS [01:15 min][INFO] Apache HBase - Shell ............................... SUCCESS [ 6.649 s][INFO] Apache HBase - Integration Tests ................... SUCCESS [ 6.429 s][INFO] Apache HBase - Examples ............................ SUCCESS [ 13.200 s][INFO] Apache HBase - Rest ................................ SUCCESS [ 27.831 s][INFO] Apache HBase - Assembly ............................ SUCCESS [ 19.400 s][INFO] Apache HBase - Shaded .............................. SUCCESS [ 0.419 s][INFO] Apache HBase - Shaded - Client ..................... SUCCESS [ 23.707 s][INFO] Apache HBase - Shaded - Server ..................... SUCCESS [ 43.654 s][INFO] Apache HBase - Spark ............................... SUCCESS [02:22 min][INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 21:13 min[INFO] Finished at: 2015-08-19T15:48:00-05:00[INFO] Final Memory: 181M/1513M[INFO] ------------------------------------------------------------------------</description>
      <version>0.98.0,1.0.0,1.1.0,1.2.0,2.0.0</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.2,1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-protocol.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="14261" opendate="2015-8-19 00:00:00" fixdate="2015-9-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enhance Chaos Monkey framework by adding zookeeper and datanode fault injections.</summary>
      <description>One of the shortcomings of existing ChaosMonkey framework is lack of fault injections for hbase dependencies like zookeeper, hdfs etc. This patch attempts to solve this problem partially by adding datanode and zk node fault injections.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,0.98.15,1.0.3,1.1.3,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MiniHBaseCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseCluster.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.RESTApiClusterManager.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.HBaseClusterManager.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.DistributedHBaseCluster.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.ClusterManager.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.factories.MonkeyFactory.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.RestartActionBaseAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.Action.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKServerTool.java</file>
    </fixedFiles>
  </bug>
  <bug id="14271" opendate="2015-8-20 00:00:00" fixdate="2015-10-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve Nexus staging instructions</summary>
      <description>Refine the Nexus staging instructions a bit. (A promise I made a long time ago.)</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="14283" opendate="2015-8-21 00:00:00" fixdate="2015-10-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reverse scan doesn’t work with HFile inline index/bloom blocks</summary>
      <description>Reverse scans do not work if an HFile contains inline bloom blocks or leaf level index blocks. The reason is because the seekBefore() call calculates the previous data block’s size by assuming data blocks are contiguous which is not the case in HFile V2 and beyond.Attached is a first cut patch (targeting bcef28eefaf192b0ad48c8011f98b8e944340da5 on trunk) which includes:(1) a unit test which exposes the bug and demonstrates failures for both inline bloom blocks and inline index blocks(2) a proposed fix for inline index blocks that does not require a new HFile version change, but is only performant for 1 and 2-level indexes and not 3+. 3+ requires an HFile format update for optimal performance. This patch does not fix the bloom filter blocks bug. But the fix should be similar to the case of inline index blocks. The reason I haven’t made the change yet is I want to confirm that you guys would be fine with me revising the HFile.Reader interface.Specifically, these 2 functions (getGeneralBloomFilterMetadata and getDeleteBloomFilterMetadata) need to return the BloomFilter. Right now the HFileReader class doesn’t have a reference to the bloom filters (and hence their indices) and only constructs the IO streams and hence has no way to know where the bloom blocks are in the HFile. It seems that the HFile.Reader bloom method comments state that they “know nothing about how that metadata is structured” but I do not know if that is a requirement of the abstraction (why?) or just an incidental current property. We would like to do 3 things with community approval:(1) Update the HFile.Reader interface and implementation to contain and return BloomFilters directly rather than unstructured IO streams(2) Merge the fixes for index blocks and bloom blocks into open source(3) Create a new Jira ticket for open source HBase to add a ‘prevBlockSize’ field in the block header in the next HFile version, so that seekBefore() calls can not only be correct but performant in all cases.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,1.0.3,1.1.3,0.98.16,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="14534" opendate="2015-10-1 00:00:00" fixdate="2015-12-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bump yammer/coda/dropwizard metrics dependency version</summary>
      <description>After HBASE-12911 lands, let's update our dependency to the latest incarnation of this library. I guess they're now calling it Dropwizard Metrics.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-shell.pom.xml</file>
      <file type="M">hbase-shaded.pom.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.WALPerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestPerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestClientPushback.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.YammerHistogramUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheStats.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.BlockCacheUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.AgeSnapshot.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmpl.jamon</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-resource-bundle.src.main.resources.supplemental-models.xml</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestRegionReplicaPerf.java</file>
      <file type="M">hbase-it.pom.xml</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.lib.MutableHistogram.java</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestMetricsConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MetricsConnection.java</file>
      <file type="M">hbase-client.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1458" opendate="2009-5-29 00:00:00" fixdate="2009-5-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>64 commit logs as upper bound is too many -- make it half</summary>
      <description>Running an upload, 64 commit logs as upper bound before we force flushes to clear the oldest edit is too much. I can see an upload running in my little cluster and even after running for an hour we still have not hit the 64 logs max. The more logs we have, the longer recovery on crash. We should halve the number I'd say.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HLog.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="14624" opendate="2015-10-15 00:00:00" fixdate="2015-10-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>BucketCache.freeBlock is too expensive</summary>
      <description>Moving regions is unacceptably slow when using bucket cache, as it takes too long to free all the blocks.</description>
      <version>1.0.0</version>
      <fixedVersion>1.2.0,1.3.0,1.0.3,1.1.3,0.98.16,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator.java</file>
    </fixedFiles>
  </bug>
  <bug id="14761" opendate="2015-11-4 00:00:00" fixdate="2015-11-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Deletes with and without visibility expression do not delete the matching mutation</summary>
      <description>This is from the user list as reported by Anoop Sharma running into an issue related to visibility expressions and delete.Example run from hbase shell is listed below.Will appreciate any help on this issue.thanks.In the example below, user running queries has ‘MANAGER’ authorization.*First example:* add a column with visib expr ‘MANAGER’ delete it by passing in visibility of ‘MANAGER’ This works and scan doesn’t return anything.*Second example:* add a column with visib expr ‘MANAGER’ delete it by not passing in any visibility. This doesn’t delete the column. Scan doesn’t return the row but RAW scan shows the column marked as deleteColumn. Now if delete is done again with visibility of ‘MANAGER’, it still doesn’t delete it and scan returns the original column.*Example 1:*hbase(main):096:0&gt; create 'HBT1', 'cf'hbase(main):098:0* *put 'HBT1', 'John', 'cf:a', 'CA',{VISIBILITY=&gt;'MANAGER'}*hbase(main):099:0&gt; *scan 'HBT1'*ROWCOLUMN+CELL John column=cf:a, timestamp=1446154722055,value=CA1 row(s) in 0.0030 secondshbase(main):100:0&gt; *delete 'HBT1', 'John', 'cf:a', {VISIBILITY=&gt;'MANAGER'}*0 row(s) in 0.0030 secondshbase(main):101:0&gt; *scan 'HBT1'*ROWCOLUMN+CELL0 row(s) in 0.0030 seconds*Example 2:*hbase(main):010:0* *put 'HBT1', 'John', 'cf:a', 'CA',{VISIBILITY=&gt;'MANAGER'}*0 row(s) in 0.0040 secondshbase(main):011:0&gt; *scan 'HBT1'*ROWCOLUMN+CELL John column=cf:a, timestamp=1446155346473,value=CA1 row(s) in 0.0060 secondshbase(main):012:0&gt; *delete 'HBT1', 'John', 'cf:a'*0 row(s) in 0.0090 secondshbase(main):013:0&gt; *scan 'HBT1'*ROWCOLUMN+CELL John column=cf:a, timestamp=1446155346473,value=CA1 row(s) in 0.0050 secondshbase(main):014:0&gt; *scan 'HBT1', {RAW =&gt; true}*ROWCOLUMN+CELL John column=cf:a, timestamp=1446155346519,type=DeleteColumn1 row(s) in 0.0060 secondshbase(main):015:0&gt; *delete 'HBT1', 'John', 'cf:a', {VISIBILITY=&gt;'MANAGER'}*0 row(s) in 0.0030 secondshbase(main):016:0&gt; *scan 'HBT1'*ROWCOLUMN+CELL John column=cf:a, timestamp=1446155346473,value=CA1 row(s) in 0.0040 secondshbase(main):017:0&gt; *scan 'HBT1', {RAW =&gt; true}*ROWCOLUMN+CELL John column=cf:a, timestamp=1446155346601,type=DeleteColumn1 row(s) in 0.0060 seconds</description>
      <version>1.0.0,1.0.1,1.1.0,1.0.2,1.1.2,0.98.15</version>
      <fixedVersion>1.2.0,1.3.0,1.0.3,1.1.3,0.98.17,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithDeletes.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityScanDeleteTracker.java</file>
    </fixedFiles>
  </bug>
  <bug id="14788" opendate="2015-11-9 00:00:00" fixdate="2015-11-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Splitting a region does not support the hbase.rs.evictblocksonclose config when closing source region</summary>
      <description>i have a table with bucket cache turned on and hbase.rs.evictblocksonclose set to false. I split a region and watched that the closing of the source region did not complete until the bucketcache was flushed for that region.</description>
      <version>1.0.0</version>
      <fixedVersion>1.2.0,1.3.0,0.98.17,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionFileSystem.java</file>
    </fixedFiles>
  </bug>
  <bug id="15036" opendate="2015-12-23 00:00:00" fixdate="2015-1-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update HBase Spark documentation to include bulk load with thin records</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.spark.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="15158" opendate="2016-1-22 00:00:00" fixdate="2016-2-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change order in which we do write pipeline operations; do all under row locks!</summary>
      <description>Change how we do our write pipeline. I want to do all write pipeline ops under row lock so I lean on this fact fixing performance regression in check-and-set type operations like increment, append, and checkAnd* (see sibling issue HBASE-15082).To be specific, we write like this now:# take rowlock# start mvcc# append to WAL# add to memstore# let go of rowlock# sync WAL# in case of error: rollback memstoreInstead, write like this:# take rowlock# start mvcc# append to WAL# sync WAL# add to memstore# let go of rowlock... no need to do rollback.The old ordering was put in place because it got better performance in a time when WAL was different and before row locks were read/write (HBASE-12751).Testing in branch-1 shows that a reordering and skipping mvcc waits gets us back to the performance we had before we unified mvcc and sequenceid (HBASE-8763). Tests in HBASE-15046 show that at the macro level using our usual perf tools, reordering pipeline seems to cause no slowdown (see HBASE-15046). A rough compare of increments with reordered write pipeline seems to have us getting back a bunch of our performance (see tail of https://issues.apache.org/jira/browse/HBASE-15082?focusedCommentId=15111703&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15111703 and subsequent comment).</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALKey.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogKey.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsckOneRS.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestCoprocessorScanPolicy.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.NoOpScanPolicyObserver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverScannerOpenHook.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSWALEntry.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RowProcessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Region.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.KeyValueScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultMemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.CellCounter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.coprocessor.example.ZooKeeperScanPolicyObserver.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.TagUtil.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
    </fixedFiles>
  </bug>
  <bug id="15811" opendate="2016-5-10 00:00:00" fixdate="2016-5-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Batch Get after batch Put does not fetch all Cells</summary>
      <description>A big batch put followed by a batch get does not always return all Cells put. See attached test program by Robert Farr that reproduces the issue. It seems to be an issue to do with a cluster of more than one machine. Running against a single machine does not have the problem (though the single machine may have many regions). Robert was unable to make his program fail with a single machine only.I reproduced what Robert was seeing running his program. I was also unable to make a single machine fail. In a batch of 1000 puts, I see one to three Gets fail. I noticed too that if I wait a second after a fail and then re-get, the Get succeeds.</description>
      <version>1.0.0,1.3.0,1.2.1,0.98.19</version>
      <fixedVersion>1.3.0,1.2.2,1.1.6,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestAsyncProcess.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
    </fixedFiles>
  </bug>
  <bug id="15925" opendate="2016-5-31 00:00:00" fixdate="2016-7-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>compat-module maven variable not evaluated</summary>
      <description>Looks like we've regressed on HBASE-8488. Have a look at the dependency artifacts list on http://mvnrepository.com/artifact/org.apache.hbase/hbase-testing-util/1.2.1. Notice the direct dependency's artifactId is ${compat.module}.</description>
      <version>1.0.0,1.1.0,1.2.0,1.2.1,1.0.3,1.1.5</version>
      <fixedVersion>1.3.0,1.2.2,1.1.6,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="15941" opendate="2016-6-2 00:00:00" fixdate="2016-3-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBCK repair should not unsplit healthy splitted region</summary>
      <description>Currently HBCK design in branch-1 has a flaw when repair option (the -fixHdfsOverlaps option specifically) is specified: it would wrongly merge split region (by looking at HDFS, it thinks that there exists overlapped regions - parent region and daughter regions covers the same key range, of course). See HBASE-15940 for details. This JIRA tracks the improvement not-to-merge split region in HBCK repair.</description>
      <version>1.0.0</version>
      <fixedVersion>1.4.0,1.3.1,1.2.6,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsckTwoRS.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsckReplicas.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.hbck.TableIntegrityErrorHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsckRepair.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="15984" opendate="2016-6-7 00:00:00" fixdate="2016-10-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Given failure to parse a given WAL that was closed cleanly, replay the WAL.</summary>
      <description>subtask for a general work around for "underlying reader failed / is in a bad state" just for the case where a WAL 1) was closed cleanly and 2) we can tell that our current offset ought not be the end of parseable entries.</description>
      <version>None</version>
      <fixedVersion>1.3.0,1.1.7,0.98.23,1.2.4,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationWALReaderManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.MetricsSource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.replication.regionserver.MetricsReplicationSourceSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.replication.regionserver.MetricsReplicationGlobalSourceSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.replication.regionserver.MetricsReplicationSourceSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="15985" opendate="2016-6-7 00:00:00" fixdate="2016-7-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>clarify promises about edits from replication in ref guide</summary>
      <description>we should make clear in a call out that replication only provides at-least-once delivery and doesn't guarantee ordering so that e.g. folks using increments aren't surprised.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="15989" opendate="2016-6-8 00:00:00" fixdate="2016-6-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove hbase.online.schema.update.enable</summary>
      <description>Pre discussion on HBASE-15981, the configuration hbase.online.schema.update.enable is an artifact of a bygone era. Lets rip it out.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.hbase-default.adoc</file>
      <file type="M">hbase-shell.src.test.rsgroup.org.apache.hadoop.hbase.client.rsgroup.TestShellRSGroups.java</file>
      <file type="M">hbase-shell.src.test.java.org.apache.hadoop.hbase.client.AbstractTestShell.java</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.alter.rb</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestRestoreFlushSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithDefaultVisLabelService.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelReplicationWithExpAsString.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestEncryptionKeyRotation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestTableLockManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestChangingEncoding.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestRestoreSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide3.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestCloneSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin2.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin1.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterDDLOperationHelper.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.replication.ReplicationAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="16495" opendate="2016-8-24 00:00:00" fixdate="2016-8-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>When accessed via Thrift, all column families have timeToLive equal to -1</summary>
      <description>When accessed via Thrift, all column families have timeToLive equal to -1. This happens because converter function colDescFromHbase forgets to copy timeToLive from HColumnDescriptor. One line change fixes that.</description>
      <version>None</version>
      <fixedVersion>1.4.0,0.98.22,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftUtilities.java</file>
    </fixedFiles>
  </bug>
  <bug id="16650" opendate="2016-9-18 00:00:00" fixdate="2016-9-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Wrong usage of BlockCache eviction stat for heap memory tuning</summary>
      <description>1. We use the stat evictedBlocksCount - A block can get evicted because of eviction thread due to lack of space or because of removal of an HFile itself (After a compaction). We should not consider the latter in the tune decision at all. These are actually invalidation of blocks. Should the stat counter itself not use this count of evicted blocks? I think yes. This will give wrong message to users that there are lot of real eviction happening.2. In case L1+ L2 combined block cache, what we use is the sum of evictions from both. But we will be tuning L1 size alone. Eviction count from L2 should not affect the tuning of L1</description>
      <version>1.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestScannerFromBucketCache.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestLazyDataBlockDecompression.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestForceCacheImportantBlocks.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestCacheConfig.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestBlockCacheReporting.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HeapMemoryManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="16708" opendate="2016-9-26 00:00:00" fixdate="2016-11-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expose endpoint Coprocessor name in "responseTooSlow" log messages</summary>
      <description>Operational diagnostics of a Phoenix install would be easier if we included which endpoint coprocessor was being called in this responseTooSlow WARN message.</description>
      <version>1.0.0</version>
      <fixedVersion>1.4.0,0.98.24,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="1671" opendate="2009-7-18 00:00:00" fixdate="2009-7-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBASE-1609 broke scanners riding across splits</summary>
      <description>On split, we close region and close out scanner leases. Scanners coming in get USEs instead of NSREs. Fix. Broke by hbase-1609.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.client.TestForceSplit.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HLog.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.hfile.HFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.DoNotRetryIOException.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.MetaScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.client.transactional.TransactionScannerCallable.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.client.transactional.TransactionalTable.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.regionserver.transactional.THLog.java</file>
    </fixedFiles>
  </bug>
  <bug id="17281" opendate="2016-12-9 00:00:00" fixdate="2016-2-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>FN should use datanode port from hdfs configuration</summary>
      <description>Currently we use the ServerName port for providing favored node hints. We should use the DN port from hdfs-site.xml instead to avoid warning messages in region server logs. The warnings will be from this section of HDFS code, it moves across classes.https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java#L1758 private boolean[] getPinnings(DatanodeInfo[] nodes) { if (favoredNodes == null) { return null; } else { boolean[] pinnings = new boolean[nodes.length]; HashSet&lt;String&gt; favoredSet = new HashSet&lt;&gt;(Arrays.asList(favoredNodes)); for (int i = 0; i &lt; nodes.length; i++) { pinnings[i] = favoredSet.remove(nodes[i].getXferAddrWithHostname()); LOG.debug("{} was chosen by name node (favored={}).", nodes[i].getXferAddrWithHostname(), pinnings[i]); } if (!favoredSet.isEmpty()) { // There is one or more favored nodes that were not allocated. LOG.warn("These favored nodes were specified but not chosen: " + favoredSet + " Specified favored nodes: " + Arrays.toString(favoredNodes)); } return pinnings; } }</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestTableFavoredNodes.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.favored.FavoredNodesManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="17297" opendate="2016-12-12 00:00:00" fixdate="2016-12-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Single Filter in parenthesis cannot be parsed correctly</summary>
      <description>hbase(main):010:0* put 'testtable', 'row1', 'cf1:a', 'ab'0 row(s) in 0.1800 secondshbase(main):011:0&gt; scan 'testtable'ROW COLUMN+CELL row1 column=cf1:a, timestamp=1481538756308, value=abhbase(main):012:0&gt; scan 'testtable', FILTER=&gt;"(ValueFilter(=,'binary:ab'))"ROW COLUMN+CELL row1 column=cf1:a, timestamp=1481538756308, value=abhbase(main):013:0* scan 'testtable', FILTER=&gt;"(ValueFilter(=,'binary:x') AND ValueFilter(=,'binary:y')) OR ValueFilter(=,'binary:ab')"ROW COLUMN+CELL row1 column=cf1:a, timestamp=1481538756308, value=abhbase(main):014:0&gt; scan 'testtable', FILTER=&gt;"(ValueFilter(=,'binary:x') AND (ValueFilter(=,'binary:y'))) OR ValueFilter(=,'binary:ab')"ROW COLUMN+CELL0 row(s) in 0.0100 secondsIn the last scan, we should got a row.The inner cause is that the last filter is parsed incorrectly.</description>
      <version>None</version>
      <fixedVersion>1.4.0,0.98.24,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestParseFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ParseFilter.java</file>
    </fixedFiles>
  </bug>
  <bug id="17447" opendate="2017-1-11 00:00:00" fixdate="2017-3-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Automatically delete quota when table is deleted</summary>
      <description>If a table has a space quota defined on it, we can delete that quota when the table is deleted.</description>
      <version>None</version>
      <fixedVersion>HBASE-16961,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="17562" opendate="2017-1-27 00:00:00" fixdate="2017-1-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove documentation for coprocessor execution times after HBASE-14205</summary>
      <description>Thanks, Steen Manniche for reporting. Opened up a subtask. Feel free to pick it up if you want to patch it yourself. Otherwise, I can do a quick patch.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.site.resources.images.coprocessor.stats.png</file>
      <file type="M">src.main.asciidoc..chapters.cp.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="18030" opendate="2017-5-11 00:00:00" fixdate="2017-6-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Per Cell TTL tags may get duplicated with increments/Append causing tags length overflow</summary>
      <description>2017-04-29 14:24:14,135 ERROR &amp;#91;B.fifo.QRpcServer.handler=49,queue=1,port=16020&amp;#93; ipc.RpcServer: Unexpected throwable object java.lang.IllegalStateException: Invalid currTagsLen -32712. Block offset: 3707853, block length: 72841, position: 0 (without header). at org.apache.hadoop.hbase.io.hfile.HFileReaderV3$ScannerV3.checkTagsLen(HFileReaderV3.java:226)I am not not using any hbase tags feature.The Increment operation from the application side is triggering this error. The same is happening when scanner is run on this table. It feels that one or more particular HFile block is corrupt (with negative tagLength).hbase(main):007:0&gt; scan 'table-name', {LIMIT=&gt;1,STARTROW=&gt;'ad:event_count:a'}Returning the resulthbase(main):008:0&gt; scan 'table-name', {LIMIT=&gt;1,STARTROW=&gt;'ad:event_count:b'}ROW COLUMN+CELL ERROR: java.io.IOException: java.lang.IllegalStateException: Invalid currTagsLen -32701. Block offset: 272031, block length: 72441, position: 32487 (without header). at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.handleException(HRegion.java:5607) at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.&lt;init&gt;(HRegion.java:5579) at org.apache.hadoop.hbase.regionserver.HRegion.instantiateRegionScanner(HRegion.java:2627) at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:2613) at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:2595) at org.apache.hadoop.hbase.regionserver.RSRpcServices.scan(RSRpcServices.java:2282) at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:32295)</description>
      <version>1.0.0,0.98.9,2.0.0</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.TagUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="18049" opendate="2017-5-15 00:00:00" fixdate="2017-5-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>It is not necessary to re-open the region when MOB files cannot be found</summary>
      <description>In HBASE-17712, we try to re-open the region when store files cannot be found. This is useful for store files in a region, but is not necessary when the MOB files cannot be found, because the store files in a region only contain the references to the MOB files and a re-open of a region doesn't help the lost MOB files.In this JIRA, we will directly throw DNRIOE only when the MOB files are not found in MobStoreScanner and ReversedMobStoreScanner. Other logics keep the same.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HMobStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="18988" opendate="2017-10-11 00:00:00" fixdate="2017-12-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add release managers to reference guide</summary>
      <description>Reference guide lists release managers only up to version 1.3. We should have a complete list there.http://hbase.apache.org/book.html#_release_managers</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="18989" opendate="2017-10-12 00:00:00" fixdate="2017-10-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Polish the compaction related CP hooks</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0-alpha-4,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MockRegionServerServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Region.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionLifeCycleTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionObserver.java</file>
    </fixedFiles>
  </bug>
  <bug id="1899" opendate="2009-10-9 00:00:00" fixdate="2009-10-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use scanner caching in shell count</summary>
      <description>Since the shell count now uses the FirstKeyOnlyFilter, it's safe to combine it with scanner caching for huge count speedups.</description>
      <version>None</version>
      <fixedVersion>0.20.2,0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.HBase.rb</file>
    </fixedFiles>
  </bug>
  <bug id="19000" opendate="2017-10-12 00:00:00" fixdate="2017-12-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Group multiple block cache clear requests per server</summary>
      <description>During the review of HBASE-18624, I brought up the following:There would be multiple regions on the same server whose block cache is to be cleared.Multiple block cache clear requests should be grouped per server to reduce the number of RPC calls.</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.HBase.proto</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.CacheEvictionStatsBuilder.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.CacheEvictionStats.java</file>
    </fixedFiles>
  </bug>
  <bug id="19002" opendate="2017-10-13 00:00:00" fixdate="2017-11-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Introduce more examples to show how to intercept normal region operations</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.coprocessor.example.ExampleRegionObserverWithMetrics.java</file>
    </fixedFiles>
  </bug>
  <bug id="2233" opendate="2010-2-17 00:00:00" fixdate="2010-6-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support both Hadoop 0.20, 0.21, and 0.22</summary>
      <description>Since Hadoop 0.21 isn't going to be well supported and that a lot of users may wish to stick on 0.20, the next HBase major release should support both 0.20 and 0.21. HDFS-265 support will be swapped for HDFS-200 if running on HDFS 0.20. A cluster without that patchset shouldn't be supported.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.util.TestFSUtils.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.replication.TestReplication.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLogSplit.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.InfoServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.HFileOutputFormat.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.hadoopbackport.InputSampler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.ConnectionHeader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="22357" opendate="2019-5-3 00:00:00" fixdate="2019-6-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix remaining Checkstyle issues in hbase-replication</summary>
      <description>There are three Checkstyle issues remaining in the hbase-replication module, which should be fixed.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.6</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ZKReplicationQueueStorage.java</file>
    </fixedFiles>
  </bug>
  <bug id="24231" opendate="2020-4-22 00:00:00" fixdate="2020-6-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add hadoop 3.2.x in our support matrix</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
    </fixedFiles>
  </bug>
</bugrepository>
