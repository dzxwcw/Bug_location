<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="10252" opendate="2013-12-29 00:00:00" fixdate="2013-12-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Don&amp;#39;t write back to WAL/memstore when Increment amount is zero (mostly for query rather than update intention)</summary>
      <description>When user calls Increment by providing amount=0, we don't write the original value to WAL or memstore : adding 0 yields a 'new' value just with the same value as the original one.1. user provides 0 amount for query rather than for update, this fix is ok; this intention is the most possible case;2. user provides 0 amount for an update, this fix is also ok : no need to touch back-end value if that value isn't changed;3. either case we both return correct value, and keep subsequent query results correct : if the 0 amount Increment is the first update, the query is the same for retrieving a 0 value or retrieving nothing;</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestDurability.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="11048" opendate="2014-4-21 00:00:00" fixdate="2014-5-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support setting custom priority per client RPC</summary>
      <description>Servers have the ability to handle custom rpc priority levels, but currently we are only using it to differentiate META/ROOT updates from replication and other 'priority' updates (as specified by annotation tags per RS method). However, some clients need the ability to create custom handlers (e.g. PHOENIX-938) which can really only be cleanly tied together to requests by the request priority. The disconnect is in that there is no way for the client to overwrite the priority per table - the PayloadCarryingRpcController will always just set priority per ROOT/META and otherwise just use the generic priority.</description>
      <version>0.99.0,0.98.2</version>
      <fixedVersion>0.99.0,0.98.3</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.HConnectionTestingUtility.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALEditsReplaySink.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestAsyncProcess.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MultiServerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallReversedScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
    </fixedFiles>
  </bug>
  <bug id="11118" opendate="2014-5-6 00:00:00" fixdate="2014-7-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>non environment variable solution for "IllegalAccessError: class com.google.protobuf.ZeroCopyLiteralByteString cannot access its superclass com.google.protobuf.LiteralByteString"</summary>
      <description>I am running into the problem described in https://issues.apache.org/jira/browse/HBASE-10304, while trying to use a newer version within cascading.hbase (https://github.com/cascading/cascading.hbase).One of the features of cascading.hbase is that you can use it from lingual (http://www.cascading.org/projects/lingual/), our SQL layer for hadoop. lingual has a notion of providers, which are fat jars that we pull down dynamically at runtime. Those jars give users the ability to talk to any system or format from SQL. They are added to the classpath programmatically before we submit jobs to a hadoop cluster.Since lingual does not know upfront , which providers are going to be used in a given run, the HADOOP_CLASSPATH trick proposed in the JIRA above is really clunky and breaks the ease of use we had before. No other provider requires this right now.It would be great to have a programmatical way to fix this, when using fat jars.</description>
      <version>0.98.2</version>
      <fixedVersion>0.99.0,0.98.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestPriorityRpc.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotManifestV2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotManifestV1.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSink.java</file>
      <file type="M">src.main.docbkx.troubleshooting.xml</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.BigDecimalColumnInterpreter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.SecureBulkLoadClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ClusterStatus.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ByteArrayComparable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ColumnPaginationFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ColumnPrefixFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.ColumnRangeFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.DependentColumnFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FirstKeyValueMatchingQualifiersFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FuzzyRowFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.InclusiveStopFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.MultipleColumnPrefixFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.PrefixFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.SingleColumnValueFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.MasterCoprocessorRpcChannel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RegionCoprocessorRpcChannel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionTransition.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.EncryptionUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestClientNoCluster.java</file>
      <file type="M">hbase-protocol.pom.xml</file>
      <file type="M">hbase-protocol.src.main.java.com.google.protobuf.HBaseZeroCopyByteString.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.codec.MessageCodec.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.Reference.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.ReplicationProtbufUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogKey.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.CellModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.CellSetModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.ScannerModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.StorageClusterStatusModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.TableInfoModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestBatchCoprocessorEndpoint.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorEndpoint.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRowProcessorEndpoint.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.protobuf.TestProtobufUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="11119" opendate="2014-5-6 00:00:00" fixdate="2014-5-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update ExportSnapShot to optionally not use a tmp file on external file system</summary>
      <description>There are FileSystem like S3 where renaming is extremely expensive. This patch will add a parameter that says something likeuse.tmp.folderIt will be defaulted to true. So default behavior is the same. If false is set them the files will land in the final destination with no need for a rename.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.96.3,0.94.20,0.98.3</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestExportSnapshot.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.ExportSnapshot.java</file>
    </fixedFiles>
  </bug>
  <bug id="1112" opendate="2009-1-9 00:00:00" fixdate="2009-4-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>we will lose data if the table name happens to be the logs&amp;#39; dir name</summary>
      <description>If the tablename happens to equal with the logs' dir name of a certain regionserver, the table will store table's data into the same dir in HDFS shared with the regionserver's log dir. If the specified region server fails, the dir may be removed after the logs are replayed. And here, we lose the data.I suggest that a special char like '_' could be added before the logdir's name, just as what root region and meta region have done. So we can prevent the user table's data from being stored in a log dir. for example, 'log_10.132.15.1_1231465024534_60020' will be changed to '_log_10.132.15.1_1231465024534_60020'.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HLog.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11123" opendate="2014-5-6 00:00:00" fixdate="2014-5-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade instructions from 0.94 to 0.98</summary>
      <description>I cloned this from the 0.96 upgrade docs task. It was suggested that we need upgrade instructions from 0.94 to 0.98. I will need source material to even prioritize this. Assuming this is Minor.</description>
      <version>0.98.2</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.upgrading.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11136" opendate="2014-5-8 00:00:00" fixdate="2014-9-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add permission check to roll WAL writer</summary>
      <description>Currently HBase provides HBaseAdmin.rollHLogWriter() and shell command to roll WAL on a region server. But no permission check is done on this operation in a secure cluster.We need to add permission check to prevent un-authorized user from running this operation.</description>
      <version>0.96.2,0.98.2</version>
      <fixedVersion>0.99.0,0.98.7</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionServerObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseRegionServerObserver.java</file>
    </fixedFiles>
  </bug>
  <bug id="11143" opendate="2014-5-9 00:00:00" fixdate="2014-5-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve replication metrics</summary>
      <description>We are trying to report on replication lag and find that there is no good single metric to do that.ageOfLastShippedOp is close, but unfortunately it is increased even when there is nothing to ship on a particular RegionServer.I would like discuss a few options here:Add a new metric: replicationQueueTime (or something) with the above meaning. I.e. if we have something to ship we set the age of that last shipped edit, if we fail we increment that last time (just like we do now). But if there is nothing to replicate we set it to current time (and hence that metric is reported to close to 0).Alternatively we could change the meaning of ageOfLastShippedOp to mean to do that. That might lead to surprises, but the current behavior is clearly weird when there is nothing to replicate.Comments? jdcryans, stack.If approach sounds good, I'll make a patch for all branches.Edit: Also adds a new shippedKBs metric to track the amount of data that is shipped via replication.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.94.20,0.98.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.MetricsSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="11154" opendate="2014-5-13 00:00:00" fixdate="2014-5-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document how to use Reverse Scan API</summary>
      <description></description>
      <version>0.98.2</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.schema.design.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11155" opendate="2014-5-13 00:00:00" fixdate="2014-5-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix Validation Errors in Ref Guide</summary>
      <description>Before I do serious documentation work, I have to fix all of the validation errors that are somehow not causing the Ref Guide to break the builds. I will attach one patch per file &amp;#8211; that's the easiest way I know how to do it. I will try not to make any content changes, only validation changes.</description>
      <version>0.98.2</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.zookeeper.xml</file>
      <file type="M">src.main.docbkx.upgrading.xml</file>
      <file type="M">src.main.docbkx.troubleshooting.xml</file>
      <file type="M">src.main.docbkx.security.xml</file>
      <file type="M">src.main.docbkx.schema.design.xml</file>
      <file type="M">src.main.docbkx.performance.xml</file>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
      <file type="M">src.main.docbkx.getting.started.xml</file>
      <file type="M">src.main.docbkx.external.apis.xml</file>
      <file type="M">src.main.docbkx.developer.xml</file>
      <file type="M">src.main.docbkx.configuration.xml</file>
      <file type="M">src.main.docbkx.case.studies.xml</file>
      <file type="M">src.main.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11162" opendate="2014-5-13 00:00:00" fixdate="2014-6-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RegionServer webui uses the default master info port irrespective of the user configuration.</summary>
      <description>Under the regionserver ui software attributes section, the value for attribute HBase Master is always using the default port (60010), even if the user configured master info port to a different value.</description>
      <version>0.98.2</version>
      <fixedVersion>0.99.0,0.98.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="11164" opendate="2014-5-14 00:00:00" fixdate="2014-10-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document and test rolling updates from 0.98 -&gt; 1.0</summary>
      <description>I think 1.0 should be rolling upgradable from 0.98 unless we break it intentionally for a specific reason. Unless there is such an issue, lets document that 1.0 and 0.98 should be rolling upgrade compatible. We should also test this before the 0.99 release.</description>
      <version>None</version>
      <fixedVersion>0.99.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.upgrading.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11178" opendate="2014-5-14 00:00:00" fixdate="2014-9-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove deprecation annotations from mapred namespace</summary>
      <description>I guess mapred API is here to stay. We should remove these annotations and clean it up.</description>
      <version>None</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableSplit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableReduce.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableRecordReaderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableRecordReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableOutputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableMapReduceUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableMap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableInputFormatBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.RowCounter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.package-info.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.IdentityTableReduce.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.IdentityTableMap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.HRegionPartitioner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.GroupingTableMap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.Driver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.package-info.java</file>
    </fixedFiles>
  </bug>
  <bug id="11190" opendate="2014-5-15 00:00:00" fixdate="2014-5-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix easy typos in documentation</summary>
      <description></description>
      <version>0.98.2</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.upgrading.xml</file>
      <file type="M">src.main.docbkx.troubleshooting.xml</file>
      <file type="M">src.main.docbkx.shell.xml</file>
      <file type="M">src.main.docbkx.schema.design.xml</file>
      <file type="M">src.main.docbkx.performance.xml</file>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
      <file type="M">src.main.docbkx.external.apis.xml</file>
      <file type="M">src.main.docbkx.developer.xml</file>
      <file type="M">src.main.docbkx.configuration.xml</file>
      <file type="M">src.main.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11201" opendate="2014-5-19 00:00:00" fixdate="2014-5-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable global procedure members to return values to procedure master</summary>
      <description>Currently in the global procedure framework, the procedure coordinator can send data (procedure argument) to the members when starting procedure.But we don't support getting data returned from the procedure members back to the master.Similar to RPC and normal procedure/function calls, in many cases, this is a useful capability.The infrastructure is in place. We just need to plug in the holes and make it happen.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.procedure.TestZKProcedureControllers.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.procedure.TestProcedureMember.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.procedure.TestProcedureCoordinator.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.procedure.TestProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.procedure.SimpleRSProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.snapshot.FlushSnapshotSubprocedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureMemberRpcs.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.Subprocedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ProcedureMemberRpcs.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ProcedureCoordinator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.Procedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.flush.FlushTableSubprocedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureCoordinatorRpcs.java</file>
    </fixedFiles>
  </bug>
  <bug id="11209" opendate="2014-5-20 00:00:00" fixdate="2014-5-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Increase the default value for hbase.hregion.memstore.block.multipler from 2 to 4</summary>
      <description>On a YCSB test, I saw a 33% performance increase, both on the max latency and on the throughput. I'm convinced enough that this value is better that I think it makes sense to change it on 0.98 as well.More fundamentally, but outside of the scope of this patch, I think this parameter should be changed to something at the region server level: today, we have: global memstore check: if we're other 40%, we flush the biggest memstore local: no more than 2 (proposed: 4) memstore size per region.But if we have enough memory and a spike on a region, there is no reason for not taking the write.</description>
      <version>0.99.0,0.98.2</version>
      <fixedVersion>0.99.0,0.98.3</fixedVersion>
      <type>Brainstorming</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11214" opendate="2014-5-20 00:00:00" fixdate="2014-5-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fixes for scans on a replicated table</summary>
      <description>During testing with the IT in HBASE-10818, found an issue to do with how "close" of scanners was handled.</description>
      <version>None</version>
      <fixedVersion>0.99.0,hbase-10070</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestReplicasClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MetaScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallReversedScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="11226" opendate="2014-5-21 00:00:00" fixdate="2014-5-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document and increase the default value for hbase.hstore.flusher.count</summary>
      <description>HBASE-6466 add the possibility to have multiple threads for the flusher.The default value is 1, but this should be incremented to 2 reasons: I've observed that the flush of a region can be delayed because another is in progress. During a write load, this leads to an increased latency because the memstore size increases and then block the client if, by accident, a flusher hits a slow or bad datanode, all the flush will have to wait until the timeouts expires. With 2 or more flushers and some luck the other regions will be flushed by the second thread.Lastly this setting is important enough to be documented in the standard hbase site imho.I think it's important enough to go in the .98 branch as wellThere will be an impact: as the flush won't be queued (or less queued) we may have more compactions...</description>
      <version>0.99.0,0.98.2</version>
      <fixedVersion>0.99.0,0.98.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11238" opendate="2014-5-23 00:00:00" fixdate="2014-6-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add info about SlabCache and BucketCache to Ref Guide</summary>
      <description>Upstream issues: HBASE-11171 and HBASE-11098. Could back port some of what is in these issues, the package-info.java class for instance.</description>
      <version>0.98.2</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.performance.xml</file>
      <file type="M">src.main.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1124" opendate="2009-1-13 00:00:00" fixdate="2009-1-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Balancer kicks in way too early</summary>
      <description>Balancer kicks in before all regions are assigned out. Causes confusion. Master won't accept OPENs from "overloaded" HRS. Master is slow to respond to UI and HRS during. Master sometimes takes too long to respond to a HRS heartbeat and so the HRS will reinit. This causes more confusion.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.RegionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11240" opendate="2014-5-23 00:00:00" fixdate="2014-7-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Print hdfs pipeline when hlog&amp;#39;s sync is slow</summary>
      <description>Sometimes the slow sync of hlog writer is because there is an abnormal datanode in the pipeline. So it will be helpful to print the pipeline of slow sync to diagnose those problems.The ultimate solution is to join the trace of HBase and HDFS.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
    </fixedFiles>
  </bug>
  <bug id="11311" opendate="2014-6-9 00:00:00" fixdate="2014-6-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Secure Bulk Load does not execute chmod 777 on the files</summary>
      <description>With HBASE-10902 we lost the setPermission() on the hfiles that we are moving, resulting in a Permission denied when we try to remove the filePermission denied: user=hbase, access=WRITE, inode="/hbase/.../3de9fdb2a99e4ef9937b4622317d10e0_SeqId_2_":testuser:hadoop:-rwxr-xr-x for(Pair&lt;byte[], String&gt; el: familyPaths) {- Path p = new Path(el.getSecond());- LOG.trace("Setting permission for: " + p);- fs.setPermission(p, PERM_ALL_ACCESS);</description>
      <version>0.99.0,0.98.2</version>
      <fixedVersion>0.99.0,0.98.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint.java</file>
    </fixedFiles>
  </bug>
  <bug id="11329" opendate="2014-6-11 00:00:00" fixdate="2014-6-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Minor fixup of new blockcache tab number formatting</summary>
      <description>Counts are showing as MB/KB. Let me fix.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.FileIOEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.ByteBufferIOEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="11331" opendate="2014-6-11 00:00:00" fixdate="2014-9-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[blockcache] lazy block decompression</summary>
      <description>Maintaining data in its compressed form in the block cache will greatly increase our effective blockcache size and should show a meaning improvement in cache hit rates in well designed applications. The idea here is to lazily decompress/decrypt blocks when they're consumed, rather than as soon as they're pulled off of disk.This is related to but less invasive than HBASE-8894.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.7</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileWriterV3.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileWriterV2.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileEncryption.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileBlockCompatibility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileBlock.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestForceCacheImportantBlocks.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestChecksum.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestCacheOnWrite.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestCacheConfig.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileWriterV2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderV2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl.jamon</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileContext.java</file>
    </fixedFiles>
  </bug>
  <bug id="11332" opendate="2014-6-11 00:00:00" fixdate="2014-6-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix for metas location cache from HBASE-10785</summary>
      <description>In HBASE-10785, we removed the invalidation of the cached location from patch v2 to v3. This results in a case where if there is a cached location for meta, it is not invalidated. Since we do a second check from cache for the location after acquiring the lock, this results in metas location to be wrongly cached forever resulting in clients blocking indefinitely.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="11397" opendate="2014-6-22 00:00:00" fixdate="2014-6-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>When merging expired stripes, we need to create an empty file to preserve metadata.</summary>
      <description>Stripe Compaction is a good feature in 0.96 and 0.98. But when I used it in a heavy-write non-uniform row keys scenario(e.g. time dimension in a key), I came across some problems. I made my stripes split at the size of 2G(hbase.store.stripe.sizeToSplit=2G), and soon there were tens of them. It was true that only the last stripe receiving the new keys kept compacting - old data didn't compact as much, or at all. However, the old stripes were still there when they all expired. I checked the source code and found that when compacting expired stripes, the StoreScanner may return no KVs so that SizeMultiWriter.append() is never called. That's to say, NO NEW FILE WILL BE CREATED. My solution is to create an empty file to preserve metadata at the end of the SizeMultiWriter.commitWritersInternal().</description>
      <version>0.98.2</version>
      <fixedVersion>0.99.0,0.98.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.compactions.TestStripeCompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StripeMultiFileWriter.java</file>
    </fixedFiles>
  </bug>
  <bug id="11399" opendate="2014-6-23 00:00:00" fixdate="2014-7-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve Quickstart chapter and move Pseudo-distributed and distributed to it</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.getting.started.xml</file>
      <file type="M">src.main.docbkx.configuration.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1144" opendate="2009-1-21 00:00:00" fixdate="2009-1-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Store the ROOT region location in Zookeeper</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.log4j.properties</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestEmptyMetaInfo.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.HBaseClusterTestCase.java</file>
      <file type="M">src.test.log4j.properties</file>
      <file type="M">src.java.overview.html</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.RegionManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HMasterRegionInterface.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HMasterInterface.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HBaseRPCProtocolVersion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">conf.hbase-default.xml</file>
    </fixedFiles>
  </bug>
</bugrepository>
