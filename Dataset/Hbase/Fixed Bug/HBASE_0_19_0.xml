<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="1043" opendate="2008-12-3 00:00:00" fixdate="2008-12-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Removing @Override attributes where they are no longer needed.</summary>
      <description>There seem to be some left-over @Override attributes from when classes were extending and overriding methods prior to interface refactoring.</description>
      <version>0.19.0</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.HRegionPartitioner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.SubstringComparator.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.RegexStringComparator.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1142" opendate="2009-1-20 00:00:00" fixdate="2009-2-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cleanup thrift server; remove Text and profuse DEBUG messaging</summary>
      <description>Ambiguous issue name.. sorry.The thrift server has loads of getText(..) calls. Which is a local function that checks for utf8 compliance, we don't need them anywhere, because we don't use Text anymore.There is probably other things we missed last time we updated the api, that we should also clean up while we're at it. Open to suggestions.</description>
      <version>0.18.0,0.18.1,0.19.0,0.19.1</version>
      <fixedVersion>0.19.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.ThriftUtilities.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11540" opendate="2014-7-18 00:00:00" fixdate="2014-7-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document HBASE-11474</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.thrift.filter.language.xml</file>
      <file type="M">src.main.docbkx.security.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11560" opendate="2014-7-22 00:00:00" fixdate="2014-7-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase.regionserver.global.memstore.size is documented twice</summary>
      <description>On the documentation at http://hbase.apache.org/book/config.files.html we describe twice hbase.regionserver.global.memstore.size.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11640" opendate="2014-8-1 00:00:00" fixdate="2014-8-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add syntax highlighting support to HBase Ref Guide programlistings</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">src.main.docbkx.zookeeper.xml</file>
      <file type="M">src.main.docbkx.upgrading.xml</file>
      <file type="M">src.main.docbkx.troubleshooting.xml</file>
      <file type="M">src.main.docbkx.tracing.xml</file>
      <file type="M">src.main.docbkx.thrift.filter.language.xml</file>
      <file type="M">src.main.docbkx.security.xml</file>
      <file type="M">src.main.docbkx.schema.design.xml</file>
      <file type="M">src.main.docbkx.preface.xml</file>
      <file type="M">src.main.docbkx.performance.xml</file>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
      <file type="M">src.main.docbkx.hbase.apis.xml</file>
      <file type="M">src.main.docbkx.getting.started.xml</file>
      <file type="M">src.main.docbkx.developer.xml</file>
      <file type="M">src.main.docbkx.customization.xsl</file>
      <file type="M">src.main.docbkx.cp.xml</file>
      <file type="M">src.main.docbkx.configuration.xml</file>
      <file type="M">src.main.docbkx.case.studies.xml</file>
      <file type="M">src.main.docbkx.book.xml</file>
      <file type="M">src.main.docbkx.appendix.contributing.to.documentation.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11643" opendate="2014-8-1 00:00:00" fixdate="2014-9-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Read and write MOB in HBase</summary>
      <description>The read/write MOB in HBase are implemented in this JIRA. Normally, the Cells are saved in the MemStore, and flushed to the HFiles when necessary. For MOB, the Cells are saved in the MemStore as well, but they're flushed to elsewhere out of HBase in the format of HFiles.</description>
      <version>None</version>
      <fixedVersion>hbase-11339,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultStoreEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DeleteTableHandler.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.TagType.java</file>
    </fixedFiles>
  </bug>
  <bug id="1176" opendate="2009-2-2 00:00:00" fixdate="2009-4-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Javadocs in HBA should be clear about which functions are asynchronous and which are synchronous</summary>
      <description>Since we don't name all of our functions as sync/async, we should at least be explicit in javadoc about the behavior of each.</description>
      <version>0.19.0</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11760" opendate="2014-8-15 00:00:00" fixdate="2014-9-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Tighten up region state transition</summary>
      <description>When a regionserver reports to master a region transition, we should check the current region state to be exactly what we expect.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerNoMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.master.RegionState.java</file>
    </fixedFiles>
  </bug>
  <bug id="11761" opendate="2014-8-15 00:00:00" fixdate="2014-9-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a FAQ item for updating a maven-managed application from 0.94 -&gt; 0.96+</summary>
      <description>In 0.96 we changed artifact structure, so that clients need to rely on an artifact specific to some module (hopefully hbase-client) instead of a single fat jar.We should add a FAQ item that points people towards hbase-client, to ease those updating downstream applications from 0.94 to 0.98+.Showing an example pom entry for e.g. org.apache.hbase:hbase:0.94.22 and one for e.g. org.apache.hbase:hbase-client:0.98.5 should be sufficient.</description>
      <version>None</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11770" opendate="2014-8-18 00:00:00" fixdate="2014-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestBlockCacheReporting.testBucketCache is not stable</summary>
      <description>Depending on the machine and OS TestBlockCacheReporting.testBucketCache may fail with NPE:java.lang.NullPointerException at org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.getBlock(BucketCache.java:417) at org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.getBlock(CombinedBlockCache.java:80) at org.apache.hadoop.hbase.io.hfile.TestBlockCacheReporting.addDataAndHits(TestBlockCacheReporting.java:67) at org.apache.hadoop.hbase.io.hfile.TestBlockCacheReporting.testBucketCache(TestBlockCacheReporting.java:86)</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestCacheConfig.java</file>
    </fixedFiles>
  </bug>
  <bug id="1185" opendate="2009-2-5 00:00:00" fixdate="2009-3-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>wrong request/sec in the gui reporting wrong</summary>
      <description>I am seeing lower number of request in the masters gui then I have seen in 0.18.0 while scanning.I thank part of it is we moved to report per sec request not per 3 secs so the request should be 1/3 of the old numbers I was getting.hbase.client.scanner.caching is not the reason the request are under reported.I set hbase.client.scanner.caching = 1 and still get about 2K request a sec in the guibut when the job is done I take records / job time and get 36,324/ records /sec. Sothere must be some caching out side of the hbase.client.scanner.caching making therequest per sec lower then it should be. I know it running faster then reported just thoughtit might give some new users the wrong impression that request/sec = read/write /sec.</description>
      <version>0.19.0</version>
      <fixedVersion>0.19.1,0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1191" opendate="2009-2-8 00:00:00" fixdate="2009-2-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ZooKeeper ensureParentExists calls fail on absolute path</summary>
      <description>If user specifies absolute path for one of the files in ZooKeeper, the following will not do what it's supposed to:if (!ensureZNodeExists(parentZNode)) { ...Because the user specified path is not a child of parentZNode, all operations on it will fail.</description>
      <version>0.19.0</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.TestZooKeeper.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper.java</file>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11910" opendate="2014-9-8 00:00:00" fixdate="2014-2-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document Premptive Call Me Maybe HBase findings in the online manual</summary>
      <description>Document the Premptive Call Me Maybe HBase findings in the online manual.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.performance.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="11912" opendate="2014-9-8 00:00:00" fixdate="2014-10-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Catch some bad practices at compile time with error-prone</summary>
      <description>Google's error-prone (https://code.google.com/p/error-prone/) wraps javac with some additional static analysis that will generate additional warnings or errors at compile time if certain bug patterns (https://code.google.com/p/error-prone/wiki/BugPatterns) are detected. What's nice about this approach, as opposed to findbugs, is the compile time detection and erroring out prevent the detected problems from getting into the codebase up front.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.HbckTestingUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.hbck.OfflineMetaRepair.java</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.HTablePool.java</file>
      <file type="M">hbase-thrift.pom.xml</file>
      <file type="M">hbase-shell.pom.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestMergeTool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableSnapshotInputFormat.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.TestHeapSize.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestSeekTo.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestScannerSelectionUsingTTL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestCase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestMasterCoprocessorExceptionWithAbort.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HTableWrapper.java</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-prefix-tree.src.test.java.org.apache.hadoop.hbase.codec.prefixtree.row.TestRowData.java</file>
      <file type="M">hbase-prefix-tree.src.test.java.org.apache.hadoop.hbase.codec.prefixtree.row.TestPrefixTreeSearcher.java</file>
      <file type="M">hbase-prefix-tree.src.test.java.org.apache.hadoop.hbase.codec.keyvalue.TestKeyValueTool.java</file>
      <file type="M">hbase-prefix-tree.pom.xml</file>
      <file type="M">hbase-it.pom.xml</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-hadoop-compat.pom.xml</file>
      <file type="M">hbase-examples.pom.xml</file>
      <file type="M">hbase-common.pom.xml</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ClusterStatus.java</file>
      <file type="M">hbase-client.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1202" opendate="2009-2-17 00:00:00" fixdate="2009-4-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>getRow does not always work when specifying number of versions</summary>
      <description>When a cell that exists is updated, getRow specifying number of versions does not work.What is returned is the original value at that timestamp, instead of the updated value.Note that this only applies when more than one version is specified. getRow with (implied) timestamp = latest does work.</description>
      <version>0.19.0,0.19.1,0.20.0</version>
      <fixedVersion>0.19.2,0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.io.Cell.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1206" opendate="2009-2-20 00:00:00" fixdate="2009-6-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scanner spins when there are concurrent inserts to column family</summary>
      <description>I had a MR job that would launch multiple scanners on a region that made updates to the same column family as they were scanning on (but not the same column). As a result, there were lots of processes that had to grep through all of the irrelevent inserts many times as flushes occurred.However, if I put the column that I was outputting to in the list of columns to scan for, everything worked quickly.The code that's causing this is:01:13 &lt; BenM&gt; keys&amp;#91;i&amp;#93; = new HStoreKey(HConstants.EMPTY_BYTE_ARRAY, this.store.getHRegionInfo());01:13 &lt; BenM&gt; if (firstRow != null &amp;&amp; firstRow.length != 0) {01:13 &lt; BenM&gt; if (findFirstRow(i, firstRow)) {01:13 &lt; BenM&gt; continue;01:13 &lt; BenM&gt; }01:13 &lt; BenM&gt; }01:13 &lt; BenM&gt; while (getNext) {01:13 &lt; BenM&gt; if (columnMatch) {01:13 &lt; BenM&gt; break;01:13 &lt; BenM&gt; }01:13 &lt; BenM&gt; }columnMatch() on the stuff that just got flushed out never returns true. This caused lots of problems to build up.The fix for this is:(10:58:30 PM) BenM: IMHO, this is a somewhat easier issue to fix(10:58:38 PM) BenM: i think it could be done in a way that cleans up the code(10:58:50 PM) BenM: right now, the code just scans through each of the map files(10:59:02 PM) BenM: without regard to the relative key positions(10:59:12 PM) BenM: i think it could use a priority queue so that it only works on the relevent files(11:01:22 PM) St^Ack_: BenM: please expand, I don't follow exactly(11:01:50 PM) BenM: lets say we have two map files(11:02:09 PM) BenM: one with 1/foo:bar 2/foo:bar 3/foo:bar(11:02:17 PM) BenM: (row/family:col)(11:02:31 PM) BenM: and the other with 1000/blah:blah 1001/blah:blah(11:02:39 PM) BenM: the curent logic is(11:02:44 PM) BenM: for each map file:(11:02:56 PM) BenM: find the first potential row in this file(11:03:08 PM) BenM: look at min(all potential rows)(11:03:34 PM) BenM: the algorith should be:(11:03:43 PM) BenM: q = new PriorityQueue()(11:04:05 PM) BenM: for each map file: insert the HStoreKey of the first key in the file(11:04:17 PM) BenM: while(k = q.pop()) {(11:04:37 PM) BenM: if (k is intersting) break;(11:04:37 PM) BenM: advance k(11:04:37 PM) BenM: q.push(k)(11:04:38 PM) BenM: }</description>
      <version>0.19.0</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12062" opendate="2014-9-23 00:00:00" fixdate="2014-9-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix usage of Collections.toArray</summary>
      <description>Need to give the correctly sized array when possible.</description>
      <version>None</version>
      <fixedVersion>0.98.7,0.99.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift.TestThriftServerCmdLine.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.LoadTestTool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.TestUser.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.compactions.TestStripeCompactionPolicy.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestInvocationRecordFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotMetadata.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.MunkresAssignment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.CollectionBackedScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.expression.NonLeafExpressionNode.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RowSpec.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.ChainWALEntryFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StripeStoreFileManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.metrics.MetricsMBeanBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.FileLink.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.RollingBatchRestartRsAction.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.mapreduce.IndexBuilder.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestConcatenatedLists.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestKeyValue.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ServerLoad.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.visibility.Authorizations.java</file>
    </fixedFiles>
  </bug>
  <bug id="1230" opendate="2009-3-2 00:00:00" fixdate="2009-3-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document installation of HBase on Windows</summary>
      <description>Provide documentation on how to run HBase on Windows.</description>
      <version>0.18.1,0.19.0,0.19.1,0.20.0</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.overview.html</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1233" opendate="2009-3-3 00:00:00" fixdate="2009-3-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Transactional fixes: Overly conservative scan read-set, potential CME</summary>
      <description>This patch fixes two issues with the OCC transactions: Overly conservative read-set. Previously a scanner was claiming read set on the whole region. This patch gets the read set from the start and end keys that a scanner was opened with (the start key comes from the arg to open, the end key comes from a WhileMatch(StopRow()) filter if present. A potential ConcurrentModificationException.</description>
      <version>0.19.0</version>
      <fixedVersion>0.19.1,0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.transactional.TransactionState.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.RowFilterSet.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.transactional.package.html</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1238" opendate="2009-3-4 00:00:00" fixdate="2009-3-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Under upload, region servers are unable to compact when loaded with hundreds of regions</summary>
      <description>We have a situation where each region server is loaded with 100+ regions, most of them in the same table. During a long upload of webpages, each memcache gets filled near equally fast so that the global memcache limit is usually triggered before the max memcache size. Since that emergency flush does not trigger compactions, the number of store files just keeps growing until it fails on all kinds of errors.We need a better story for this as this is a "normal" situation.</description>
      <version>0.19.0</version>
      <fixedVersion>0.19.1,0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.MemcacheFlusher.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12511" opendate="2014-11-18 00:00:00" fixdate="2014-12-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>namespace permissions - add support from table creation privilege in a namespace &amp;#39;C&amp;#39;</summary>
      <description>As discussed in namespace permission Jira. A user granted a 'C' on a namespace enables a user to create tables within the namespace. 'C' on a namespace does not enable a user to create/drop the namespace.</description>
      <version>None</version>
      <fixedVersion>1.0.0,1.1.0,0.98.19</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestNamespaceCommands.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug id="12526" opendate="2014-11-18 00:00:00" fixdate="2014-11-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove unused imports</summary>
      <description>Even if we relax the import checker to include javadocs in HBASE-12523, we still get ~250 remaining. Find and fix. Try to avoid reorganizing.</description>
      <version>None</version>
      <fixedVersion>0.99.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKSplitLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.RegionServerTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ClusterStatusTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.DisabledWALProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.DefaultWALProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ZKDataMigrator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.SortedCopyOnWriteSet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ShutdownHookManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ModifyRegionUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.MetaUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.Merge.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HFileArchiveUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.hbck.OfflineMetaRepair.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSTableDescriptors.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSTableDescriptorMigrationToSubdir.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSRegionScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.CompressionTest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.BloomFilterFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.SplitLogTask.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.ExportSnapshot.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.AuthenticationTokenSecretManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.HbaseObjectWritableFor96Migration.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.Replication.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.MetricsWALEditsReplay.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogPrettyPrinter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitLogWorker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.snapshot.RegionServerSnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ServerNonceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MultiRowMutationProcessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MiniBatchOperationInProgress.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.StripeCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.TimeBasedLimiter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.RegionServerQuotaManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaLimiterFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.OperationQuota.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.NoopOperationQuota.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.DefaultOperationQuota.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureCoordinatorRpcs.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.RegionServerProcedureManagerHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ProcedureMemberRpcs.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.MasterProcedureManagerHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.MasterProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.flush.FlushTableSubprocedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.MasterSnapshotVerifier.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterStatusServlet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TruncateTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TotesHRegionInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableModifyFamilyHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableEventHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableAddFamilyHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.LogReplayHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DeleteTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ClusterStatusPublisher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.SimpleLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.FavoredNodeLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BalancerChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableRecordReaderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableRecordReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableInputFormatBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.RowCounter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableOutputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.MultiTableInputFormatBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.IdentityTableReducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HLogInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.CellCounter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.BalancedQueueRpcExecutor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileScanner.java</file>
      <file type="M">hbase-annotations.src.main.java.org.apache.hadoop.hbase.classification.InterfaceStability.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClusterStatusListener.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.NoServerForRegionException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.replication.ReplicationAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.coprocessor.ColumnInterpreter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.QualifierFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.RowFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.SingleColumnValueFilter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.CoprocessorRpcChannel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.ServerRpcController.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeers.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.util.PoolMap.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.Codec.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.CellOutputStream.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.DataType.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawBytesFixedLength.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawBytesTerminated.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawStringFixedLength.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawStringTerminated.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.AbstractPositionedByteRange.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteBufferUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ConcurrentIndex.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.OrderedBytes.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.PositionedByteRange.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.coprocessor.example.ZooKeeperScanPolicyObserver.java</file>
      <file type="M">hbase-prefix-tree.src.main.java.org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeCodec.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.example.HFileArchiveManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.example.LongTermArchivingHFileCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ClientSideRegionScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.CoprocessorHConnection.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.TableSnapshotScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.constraint.Constraint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.constraint.ConstraintException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.SplitLogManagerCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.SplitLogWorkerCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.errorhandling.ForeignExceptionSnare.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
    </fixedFiles>
  </bug>
  <bug id="12528" opendate="2014-11-18 00:00:00" fixdate="2014-12-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document the newly introduced params for providing principal and keytabs.</summary>
      <description>As per the description.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  <bug id="12550" opendate="2014-11-20 00:00:00" fixdate="2014-11-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Check all storefiles are referenced before splitting</summary>
      <description>Make double extra sure all storefiles are referenced before</description>
      <version>None</version>
      <fixedVersion>0.98.9,0.99.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="12552" opendate="2014-11-21 00:00:00" fixdate="2014-11-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>listSnapshots should list only owned snapshots for non-super user</summary>
      <description>Currently list_snapshots lists all the snapshots available for a non-super user which may not be correct, this should be applicable only for a user with admin rights. So I feel for a non-super user it should lists only the snapshots owned by it if any.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestMasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.java</file>
    </fixedFiles>
  </bug>
  <bug id="12561" opendate="2014-11-22 00:00:00" fixdate="2014-2-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replicas of regions can be cached from different instances of the table in MetaCache</summary>
      <description>In testing, we have observed that if a client caches some regions with replicas in MetaCache, and then the table is recreated, the cache does not get invalidated. Upon caching more entries from a new instance of the table we can have entries for replicas from different instances of a table (remember that metacache is row based)On async wal replay (HBASE-11568), we have an elaborate mechanism to track region replica locations and skip replaying wal entries if the current region replica is not the same region replica from the original wal edit. This prevents replaying entries of older tables with the same name to the region replicas as well as replaying older entries from split (or merged) regions from old parent to new daughters.Trace level logging in my test setup showed that we were skipping some entries because of a case, where we would have region locations (of the same range) cached from different instances of the table (meaning some replicas are from already deleted table vs some entries from new table). This was causing superfluous skipping entries.The fix can be when we are merging entries for the same range, we simply check the other entries and delete those that do not match the new region id.</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.TestRegionLocations.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionLocations.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionReplicaUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="12562" opendate="2014-11-22 00:00:00" fixdate="2014-3-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Handling memory pressure for secondary region replicas</summary>
      <description>This issue will track the implementation of how to handle the memory pressure for secondary region replicas. Since the replicas cannot flush by themselves, the region server might get blocked or cause extensive flushing for its primary regions. The design doc attached at HBASE-11183 contains two possible solutions that we can pursue. The first one is to not allow secondary region replicas to not flush by themselves, but instead of needed allow them to refresh their store files on demand (which possibly allows them to drop their memstore snapshots or memstores). The second approach is to allow the secondaries to flush to a temporary space. Both have pros and cons, but for simplicity and to not cause extra write amplification, we have implemented the first approach. More details can be found in the design doc, but we can also discuss other options here.</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionReplayEvents.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ServerRegionReplicaUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.FileLink.java</file>
    </fixedFiles>
  </bug>
  <bug id="1258" opendate="2009-3-12 00:00:00" fixdate="2009-3-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ganglia metrics for &amp;#39;requests&amp;#39; is confusing</summary>
      <description>the 'requests' metric is incremented for every request, but it is reset and published every interval. Which means the number is actually 'requests per interval' which is a config value in hbase. HBase should export 'requests/second' instead.</description>
      <version>0.19.0</version>
      <fixedVersion>0.19.1,0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.metrics.RegionServerMetrics.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="12590" opendate="2014-11-27 00:00:00" fixdate="2014-12-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>A solution for data skew in HBase-Mapreduce Job</summary>
      <description>1, MotivationIn production environment, data skew is a very common case. A HBase table may contains a lot of small regions and several large regions. Small regions waste a lot of computing resources. If we use a job to scan a table with 3000 small regions, we need a job with 3000 mappers. Large regions always block the job. If in a 100-region table, one region is far large then the other 99 regions. When we run a job with the table as input, 99 mappers will be completed very quickly, and then we need to wait for the last mapper for a long time.2, ConfigurationAdd three new configuration hbase.mapreduce.input.autobalance = true means enabling the “auto balance” in HBase-MapReduce jobs. The default value is false. hbase.mapreduce.input.autobalance.maxskewratio= 3 (default is 3). If a region size is larger than 3x average region size, treat the region as “proportionately too large”.hbase.table.row.textkey = true means the row key is text. False means binary row key. It is used to find the mid row key in large region. The default value is true. If (region size &gt;= average size*ratio) : cut the region into two MR input splitsIf (average size &lt;= region size &lt; average size*ratio) : one region as one MR input splitIf (sum of several continuous regions size &lt; average size): combine these regions into one MR input split.Example:In attachmentWelcome to the Review Board.https://reviews.apache.org/r/28494/diff/#</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScanBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan1.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="1262" opendate="2009-3-14 00:00:00" fixdate="2009-3-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Eclipse warnings, including performance related things like synthetic accessors.</summary>
      <description>We get this warning all over in many pieces of the code.</description>
      <version>0.19.0</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.IdentityTableMap.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.util.TestMergeTool.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TimestampTestBase.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestRegionRebalancing.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestMergeMeta.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestInfoServers.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestHStoreKey.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestHBaseCluster.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestClassMigration.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.transactional.DisabledTestHLogRecovery.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestSplit.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestScanner.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestHMemcache.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestGet2.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestGet.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestBloomFilters.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.MiniZooKeeperCluster.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.mapred.TestTableMapReduce.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.mapred.TestTableIndex.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.MapFilePerformanceEvaluation.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.io.TestHbaseObjectWritable.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.io.hfile.TestHFileSeek.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.io.hfile.KeySampler.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.HFilePerformanceEvaluation.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.HBaseTestCase.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.HBaseClusterTestCase.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.filter.TestStopRowFilter.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.filter.TestRowFilterSet.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.filter.TestRowFilterOnMultipleFamilies.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.filter.TestRowFilterAfterWrite.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.filter.TestRegExpRowFilter.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.filter.TestPrefixRowFilter.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.filter.TestPageRowFilter.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.filter.TestInclusiveStopRowFilter.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.DFSAbort.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.client.transactional.StressTestTransactions.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.client.TestTimestamp.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.client.TestForceSplit.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.client.TestBatchUpdate.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.AbstractMergeTestBase.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.Pair.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.MetaUtils.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.Merge.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.Bytes.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.TimestampModel.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.TimestampController.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.TableModel.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.TableController.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.serializer.AbstractRestSerializer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.ScannerModel.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.RowController.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.RESTConstants.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.parser.XMLRestParser.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.parser.JsonRestParser.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.parser.IHBaseRestParser.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.filter.RowFilterSetFactory.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.filter.FilterFactoryConstants.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.Dispatcher.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.descriptors.RestCell.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.DatabaseController.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.AbstractModel.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.AbstractController.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.transactional.TransactionState.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.metrics.RegionServerMetrics.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.MemcacheFlusher.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Memcache.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HLogKey.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HLogEdit.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HLog.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.metrics.MetricsRate.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.TableOperation.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.TableDelete.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.RetryableMetaOperation.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.RegionManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ProcessServerShutdown.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ProcessRegionOpen.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ModifyTableMeta.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.metrics.MasterMetrics.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.MetaRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ColumnOperation.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.BaseScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableOutputFormat.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableInputFormatBase.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.RowCounter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.IndexOutputFormat.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.IdentityTableReduce.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.hadoop.hbase.Chore.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.MetaScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.ServerCallable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.tableindexed.IndexedTable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.tableindexed.IndexedTableAdmin.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.tableindexed.IndexSpecification.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.transactional.TransactionState.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.UnmodifyableHColumnDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.UnmodifyableHTableDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.InclusiveStopRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.PrefixRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.StopRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HMerge.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HMsg.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HRegionLocation.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HServerAddress.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HServerInfo.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HServerLoad.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HStoreKey.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.BatchOperation.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.BatchUpdate.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.BlockFSInputStream.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.BloomFilterMapFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.Cell.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.DataOutputBuffer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.HalfHFileReader.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.HbaseMapWritable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.HbaseObjectWritable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.hfile.BlockCache.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.hfile.HFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.hfile.HFileScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.ImmutableBytesWritable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.MapFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.Reference.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.RowResult.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.SequenceFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HBaseClient.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HBaseRPC.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HBaseRpcMetrics.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HBaseServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.Leases.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.GroupingTableMap.java</file>
    </fixedFiles>
  </bug>
  <bug id="12620" opendate="2014-12-3 00:00:00" fixdate="2014-1-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add HBASE-11639 related items to Ref Guide</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.security.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="12920" opendate="2015-1-26 00:00:00" fixdate="2015-2-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hadoopqa should compile with different hadoop versions</summary>
      <description>From time to time, we break compilation with hadoop-2.4 or other earlier versions, and only realize that at the time of a release candidate. We should fix hadoopqa to do the compilation for us. What I have locally is something like this: HADOOP2_VERSIONS="2.2.0 2.3.0 2.4.0 2.5.0 2.6.0"function buildWithHadoop2 { for HADOOP2_VERSION in $HADOOP2_VERSIONS ; do echo "" echo "##### BUILDING $ARTIFACT WITH HADOOP 2 VERSION $HADOOP2_VERSION #####" echo "" echo mvn clean install -DskipTests -Dhadoop-two.version=$HADOOP2_VERSION mvn clean install -DskipTests -Dhadoop-two.version=$HADOOP2_VERSION done}</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.properties</file>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  <bug id="12980" opendate="2015-2-6 00:00:00" fixdate="2015-2-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Delete of a table may not clean all rows from hbase:meta</summary>
      <description>One such case is if we miswrite the info:regioninfo column and it comes up empty, this row will remain in the table. We have a set of 'finally' cleanup tasks on table delete. Let me add one that for sure purges any rows to do with the deleted table.</description>
      <version>None</version>
      <fixedVersion>1.0.0,1.1.0,0.98.11</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.handler.TestEnableTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DeleteTableHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="13546" opendate="2015-4-23 00:00:00" fixdate="2015-4-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>NPE on region server status page if all masters are down</summary>
      <description>while trying to debug a cluster with all masters down, I noticed going to the region server status page failed with NPE.</description>
      <version>None</version>
      <fixedVersion>1.1.0,0.98.13,1.0.2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMasterAddressTracker.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.MasterAddressTracker.java</file>
    </fixedFiles>
  </bug>
  <bug id="1355" opendate="2009-4-28 00:00:00" fixdate="2009-4-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[performance] Cache family maxversions; we were calculating on each access</summary>
      <description>Profiling I see we are calculating max versions each time: String value = getValue(HConstants.VERSIONS); this.cachedMaxVersions = (value != null)? Integer.valueOf(value).intValue(): DEFAULT_VERSIONS;Caching it should improve things. Seeing that its 10% of memory when writing and about 10% of CPU. Reading its 10% of CPU according to profiler.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HBaseRPC.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="782" opendate="2008-7-28 00:00:00" fixdate="2008-12-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The DELETE key in the hbase shell deletes the wrong character</summary>
      <description>Within the hbase shell, if you type "monkey", then place the cursor on the letter 'k' and hit the key 'DELETE' several times it will do this:monkeymokeymkeykeykeykey...</description>
      <version>0.19.0</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.hirb.rb</file>
    </fixedFiles>
  </bug>
  <bug id="8030" opendate="2013-3-7 00:00:00" fixdate="2013-3-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>znode path of online region servers is hard coded in rolling_restart.sh</summary>
      <description>znode path of online region servers($zparent/rs) is hard coded. We need to use configured value of zookeeper.znode.rs as child path. # gracefully restart all online regionservers online_regionservers=`$bin/hbase zkcli ls $zparent/rs 2&gt;&amp;1 | tail -1 | sed "s/\[//" | sed "s/\]//"`</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.94.7,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.rolling-restart.sh</file>
    </fixedFiles>
  </bug>
  <bug id="8031" opendate="2013-3-7 00:00:00" fixdate="2013-3-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Adopt goraci as an Integration test</summary>
      <description>As you might know, I am a big fan of the goraci test that Keith Turner has developed, which in turn is inspired by the Accumulo test called Continuous Ingest. As much as I hate to say it, having to rely on gora and and external github library makes using this lib cumbersome. And lately we had to use this for testing against secure clusters and with Hadoop2, which gora does not support for now. So, I am proposing we add this test as an IT in the HBase code base so that all HBase devs can benefit from it.The original source code can be found here: https://github.com/keith-turner/goraci https://github.com/enis/goraci/From the javadoc:Apache Accumulo [0] has a simple test suite that verifies that data is not * lost at scale. This test suite is called continuous ingest. This test runs * many ingest clients that continually create linked lists containing 25 * million nodes. At some point the clients are stopped and a map reduce job is * run to ensure no linked list has a hole. A hole indicates data was lost.·· * * The nodes in the linked list are random. This causes each linked list to * spread across the table. Therefore if one part of a table loses data, then it * will be detected by references in another part of the table. *Below is rough sketch of how data is written. For specific details look at * the Generator code. * * 1 Write out 1 million nodes· 2 Flush the client· 3 Write out 1 million that * reference previous million· 4 If this is the 25th set of 1 million nodes, * then update 1st set of million to point to last· 5 goto 1 * * The key is that nodes only reference flushed nodes. Therefore a node should * never reference a missing node, even if the ingest client is killed at any * point in time. * * Some ASCII art time: * [ . . . ] represents one batch of random longs of length WIDTH * * _________________________ * | ______ | * | | || * __+_________________+_____ || * v v v ||| * first = [ . . . . . . . . . . . ] ||| * ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ||| * | | | | | | | | | | | ||| * prev = [ . . . . . . . . . . . ] ||| * ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ||| * | | | | | | | | | | | ||| * current = [ . . . . . . . . . . . ] ||| * ||| * ... ||| * ||| * last = [ . . . . . . . . . . . ] ||| * | | | | | | | | | | |-----||| * | |--------|| * |___________________________|</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.94.6,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8034" opendate="2013-3-8 00:00:00" fixdate="2013-3-8 01:00:00" resolution="Won&amp;#39;t Fix">
    <buginformation>
      <summary>record on-disk data size for store file and make it available during writing</summary>
      <description>To better estimate the size of data in the file, and to be able to split files intelligently during any multi-file compactor like stripe or level.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.AbstractHFileWriter.java</file>
    </fixedFiles>
  </bug>
  <bug id="8035" opendate="2013-3-8 00:00:00" fixdate="2013-9-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add site target check to precommit tests</summary>
      <description>We should check that the Maven 'site' target passes as part of precommit testing. See HBASE-8022.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  <bug id="8826" opendate="2013-6-28 00:00:00" fixdate="2013-7-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Ensure HBASE-8695 is covered in Thrift 2</summary>
      <description>HBASE-8695 is about using the config file, make sure Thrift 2 is doing the same.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2,0.94.10</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="883" opendate="2008-9-12 00:00:00" fixdate="2008-11-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Secondary Indexes</summary>
      <description>I'm working on a secondary index impl. The basic idea is to maintain a separate table per index.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.UnmodifyableHTableDescriptor.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.test.org.apache.hadoop.hbase.client.tableindexed.TestIndexedTable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.tableindexed.package.html</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.tableindexed.IndexSpecification.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.tableindexed.IndexNotFoundException.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.tableindexed.IndexedTableAdmin.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HStoreKey.java</file>
    </fixedFiles>
  </bug>
  <bug id="8832" opendate="2013-6-28 00:00:00" fixdate="2013-7-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Ensure HBASE-4658 is supported by Thrift 2</summary>
      <description>HBASE-4658 adds support for "attributes" for certain operations. Make sure Thrift 2 supports them where ever available in the native API.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2,0.94.10</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.thrift2.TestThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.thrift2.hbase.thrift</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftUtilities.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TScan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TPut.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIncrement.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.THBaseService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TGet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TDelete.java</file>
    </fixedFiles>
  </bug>
  <bug id="8921" opendate="2013-7-10 00:00:00" fixdate="2013-7-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[thrift2] Add GenericOptionsParser to Thrift 2 server</summary>
      <description>Add GenericOptionsParser to be able to hand in configuration changes from the command line.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2,0.94.10</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="900" opendate="2008-9-24 00:00:00" fixdate="2008-12-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Regionserver memory leak causing OOME during relatively modest bulk importing</summary>
      <description>I have recreated this issue several times and it appears to have been introduced in 0.2.During an import to a single table, memory usage of individual region servers grows w/o bounds and when set to the default 1GB it will eventually die with OOME. This has happened to me as well as Daniel Ploeg on the mailing list. In my case, I have 10 RS nodes and OOME happens w/ 1GB heap at only about 30-35 regions per RS. In previous versions, I have imported to several hundred regions per RS with default heap size.I am able to get past this by increasing the max heap to 2GB. However, the appearance of this in newer versions leads me to believe there is now some kind of memory leak happening in the region servers during import.</description>
      <version>0.18.1,0.19.0</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.ipc.HBaseClient.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HBaseRPCProtocolVersion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HbaseRPC.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.SoftValueSortedMap.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.SoftValueMap.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.ReferenceQueueUtil.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.HBaseMapFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.BlockFSInputStream.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.Bytes.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Memcache.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.BatchUpdate.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.BatchOperation.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HStoreKey.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="9520" opendate="2013-9-12 00:00:00" fixdate="2013-9-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>shortcut split asap while requested splitPoint equals with region&amp;#39;s startKey</summary>
      <description>we can shortcut this corener case from client side at all, w/o any traffic within RS.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="9541" opendate="2013-9-16 00:00:00" fixdate="2013-9-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>icv fails w/ npe if client does not support cellblocks</summary>
      <description>Benoît found an npe migrating asynchbase to 0.96 exercising icv:2013-09-14 23:27:17,305 WARN [RpcServer.handler=10,port=60934]ipc.RpcServer: RpcServer.handler=10,port=60934: caught:java.lang.NullPointerException at org.apache.hadoop.hbase.ipc.RpcServer.channelWrite(RpcServer.java:2346) at org.apache.hadoop.hbase.ipc.RpcServer$Responder.processResponse(RpcServer.java:985) at org.apache.hadoop.hbase.ipc.RpcServer$Responder.doRespond(RpcServer.java:1062) at org.apache.hadoop.hbase.ipc.RpcServer$Call.sendResponseIfReady(RpcServer.java:478) at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1875)This is stalling progress on asynchbase migration.</description>
      <version>None</version>
      <fixedVersion>0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="9547" opendate="2013-9-16 00:00:00" fixdate="2013-9-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Surefire steals focus on mac osx</summary>
      <description>When I run builds on mac osx, the focus is stolen as we go through tests; surefire is launching a little app named variously: "forkedbooter" is one, "mapred.Child" another. The little app goes away when the test is done but meantime it robs the focus making desktop unusable.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.resources.mapred-site.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestNamespace.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterNoCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableNamespaceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9560" opendate="2013-9-17 00:00:00" fixdate="2013-9-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>bin/hbase clean --cleanAll should not skip data cleaning if in local mode</summary>
      <description>I don't see a reason why we are skipping cleaning in local mode:Eniss-MacBook-Pro:hbase-0.96$ bin/hbase clean --cleanAllSkipping hbase data clearing in standalone mode.I use this often for standalone mode.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase-cleanup.sh</file>
    </fixedFiles>
  </bug>
  <bug id="959" opendate="2008-10-25 00:00:00" fixdate="2008-10-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Be able to get multiple RowResult at one time from client side</summary>
      <description>Now from the region server side, we can get multiple rows at one time now. It's mostly used to cache the results in the client side. But we still can only get one row by row at one time. I think it's better to let users also be able to get multiple rows if they want.</description>
      <version>0.19.0</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9792" opendate="2013-10-17 00:00:00" fixdate="2013-11-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Region states should update last assignments when a region is opened.</summary>
      <description>Currently, we update a region's last assignment region server when the region is online. We should do this sooner, when the region is moved to OPEN state. CM could kill this region server before we delete the znode and online the region.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="9793" opendate="2013-10-17 00:00:00" fixdate="2013-10-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Offline a region before it&amp;#39;s closed could cause double assignment</summary>
      <description>The fix for HBASE-9773 could cause double assignment, as jeffreyz pointed out. Let's fix it in a separate jira instead of an addendum since there are different opinions on how to fix it.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="984" opendate="2008-11-7 00:00:00" fixdate="2008-11-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix javadoc warnings</summary>
      <description>There are a number of javadoc warnings: @see pointing to the wrong place, etc. These need to be fixed before 0.19 is released.</description>
      <version>0.19.0</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.util.InfoServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.HalfMapFileReader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="994" opendate="2008-11-11 00:00:00" fixdate="2008-11-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>IPC interfaces with different versions can cause problems</summary>
      <description>This morning we ran into a situation in which some 0.2.x region servers started up and joined a 0.18.1 cluster. This 'sort of' worked in that the hrs could communicate with the master, but clients could not communicate with the 0.2 region servers because the api version changed (the master wouldn't have liked it if it had deployed root or meta there).Suggestion is that we have a single api version that gets bumped when any of the interfaces changes.</description>
      <version>0.2.1,0.18.0,0.18.1,0.19.0</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.TransactionalRegionInterface.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HRegionInterface.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HMasterRegionInterface.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HMasterInterface.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>
