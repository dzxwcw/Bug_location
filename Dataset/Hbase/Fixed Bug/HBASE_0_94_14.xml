<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="10048" opendate="2013-11-27 00:00:00" fixdate="2013-12-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add hlog number metric in regionserver</summary>
      <description>Add hlog number metric in regionserver. We can use this metric to alert about memstore flush because of too many hlogs.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.1,0.94.15,0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRolling.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLog.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.HLogUtilsForTests.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsRegionServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperStub.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl.jamon</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop1-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="10087" opendate="2013-12-5 00:00:00" fixdate="2013-1-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Store should be locked during a memstore snapshot</summary>
      <description>regression from HBASE-9963, found while looking at HBASE-10079.</description>
      <version>0.98.0,0.96.1,0.94.14</version>
      <fixedVersion>0.98.0,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="1009" opendate="2008-11-19 00:00:00" fixdate="2008-11-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Master stuck in loop wanting to assign but regions are closing</summary>
      <description>From streamy logs.2008-11-19 10:36:58,933 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,�,1225411057556 because it is already closing.2008-11-19 10:37:01,315 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 138, Num Servers: 9, Avg Load: 16.02008-11-19 10:37:01,935 DEBUG org.apache.hadoop.hbase.master.RegionManager: Server XX.XX.XX.212:60020 is overloaded. Server load: 21 avg: 16.0, slop: 0.12008-11-19 10:37:01,935 DEBUG org.apache.hadoop.hbase.master.RegionManager: Choosing to reassign 5 regions. mostLoadedRegions has 10 regions in it.2008-11-19 10:37:01,935 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streams,'6,1226967394935 because it is already closing.2008-11-19 10:37:01,935 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,'�,1226078595896 because it is already closing.2008-11-19 10:37:01,935 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,���,1225472287315 because it is already closing.2008-11-19 10:37:01,935 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,X$�,1225411877996 because it is already closing.2008-11-19 10:37:01,935 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,�},1225411050812 because it is already closing.2008-11-19 10:37:01,935 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region api,,1222913694225 because it is already closing.2008-11-19 10:37:01,935 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,0��,1226459423496 because it is already closing.2008-11-19 10:37:01,935 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region items,R�,1223906859795 because it is already closing.2008-11-19 10:37:01,935 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region authentication,,1222913700431 because it is already closing.2008-11-19 10:37:01,935 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,�,1225411057556 because it is already closing.2008-11-19 10:37:04,939 DEBUG org.apache.hadoop.hbase.master.RegionManager: Server XX.XX.XX.212:60020 is overloaded. Server load: 21 avg: 16.0, slop: 0.12008-11-19 10:37:04,939 DEBUG org.apache.hadoop.hbase.master.RegionManager: Choosing to reassign 5 regions. mostLoadedRegions has 10 regions in it.2008-11-19 10:37:04,939 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streams,'6,1226967394935 because it is already closing.2008-11-19 10:37:04,939 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,'�,1226078595896 because it is already closing.2008-11-19 10:37:04,939 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,���,1225472287315 because it is already closing.2008-11-19 10:37:04,939 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,X$�,1225411877996 because it is already closing.2008-11-19 10:37:04,939 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,�},1225411050812 because it is already closing.2008-11-19 10:37:04,939 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region api,,1222913694225 because it is already closing.2008-11-19 10:37:04,939 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,0��,1226459423496 because it is already closing.2008-11-19 10:37:04,939 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region items,R�,1223906859795 because it is already closing.2008-11-19 10:37:04,939 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region authentication,,1222913700431 because it is already closing.2008-11-19 10:37:04,939 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,�,1225411057556 because it is already closing.2008-11-19 10:37:07,941 DEBUG org.apache.hadoop.hbase.master.RegionManager: Server XX.XX.XX.212:60020 is overloaded. Server load: 21 avg: 16.0, slop: 0.12008-11-19 10:37:07,941 DEBUG org.apache.hadoop.hbase.master.RegionManager: Choosing to reassign 5 regions. mostLoadedRegions has 10 regions in it.2008-11-19 10:37:07,941 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streams,'6,1226967394935 because it is already closing.2008-11-19 10:37:07,941 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,'�,1226078595896 because it is already closing.2008-11-19 10:37:07,942 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,���,1225472287315 because it is already closing.2008-11-19 10:37:07,942 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,X$�,1225411877996 because it is already closing.2008-11-19 10:37:07,942 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,�},1225411050812 because it is already closing.2008-11-19 10:37:07,942 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region api,,1222913694225 because it is already closing.2008-11-19 10:37:07,942 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,0��,1226459423496 because it is already closing.2008-11-19 10:37:07,942 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region items,R�,1223906859795 because it is already closing.2008-11-19 10:37:07,942 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region authentication,,1222913700431 because it is already closing.2008-11-19 10:37:07,942 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region streamitems,�,1225411057556 because it is already closing.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10111" opendate="2013-12-9 00:00:00" fixdate="2013-12-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Verify that a snapshot is not corrupted before restoring it</summary>
      <description>To avoid assigning/opening regions with missing files, verify that the snapshot is not corrupted before restoring/cloning it.In 96 a corrupted file in a region is "not a problem" since the assignment will give up after awhile.In 94 having a corrupted file in a region means looping forever, on "enable", until manual intervention. (Easy way to test this is create a table, disable it, add a corrupted reference file and enable the table to start looping: you can use echo "foo" &gt; aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa.aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa)</description>
      <version>0.98.0,0.96.0,0.94.14</version>
      <fixedVersion>0.98.0,0.96.1,0.94.15</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.SnapshotTestingUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestRestoreSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="1013" opendate="2008-11-21 00:00:00" fixdate="2008-11-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add debugging around commit log cleanup</summary>
      <description>Yesterday, streamy replayed 1000 logs. This seems too many for any one regionserver to be carrying. Its hard to tell if the 1000 logs were legit though because our logging isn't detailed enough. This issue is about adding detail around log cleaning so we can see how many logs are to be cleaned and which region the last edit belongs to.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.LogRoller.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HLog.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10132" opendate="2013-12-11 00:00:00" fixdate="2013-12-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>sun.security.pkcs11.wrapper.PKCS11Exception: CKR_ARGUMENTS_BAD</summary>
      <description>Looks like RedHat broke OpenJDK 7 crypto: https://bugzilla.redhat.com/show_bug.cgi?id=1031145 I came across this today when setting up a Jenkins slave for OpenJDK 7. Looks like 1.7.0u25 is affected but 1.7.0u45 is not - a more recent RH package build I suspect. The issue manifests as exceptions caused ultimately by:Caused by: sun.security.pkcs11.wrapper.PKCS11Exception: CKR_ARGUMENTS_BAD at sun.security.pkcs11.wrapper.PKCS11.C_DecryptUpdate(Native Method) at sun.security.pkcs11.P11Cipher.implDoFinal(P11Cipher.java:795)The RH bug report for this problem includes a workaround that fixed the problem for me. Informational issue only, will attach a patch for the manual shortly.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.troubleshooting.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1020" opendate="2008-11-22 00:00:00" fixdate="2008-11-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Regionserver OOME handler should dump vital stats</summary>
      <description>On OOME the regionserver should dump into the log some vital stats: Number of regions Number of store files Estimated item count and size of memcache(s) Estimated item count and size of store file indexesAssumes the reserve can be released upon OOME to allow the additional actions.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10202" opendate="2013-12-18 00:00:00" fixdate="2013-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Documentation is lacking information about rolling-restart.sh script.</summary>
      <description>Current documentation is talking about graceful_stop.sh and how to do a rolling restart but is not talking about the rolling-restart.sh script. We need to document that.</description>
      <version>0.98.0,0.94.14,0.99.0,0.96.1.1</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1021" opendate="2008-11-23 00:00:00" fixdate="2008-11-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase metrics FileContext not working</summary>
      <description>Figure why it ain't writing to file though it does to ganglia.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.hadoop-metrics.properties</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10213" opendate="2013-12-20 00:00:00" fixdate="2013-1-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add read log size per second metrics for replication source</summary>
      <description>The current metrics of replication source contain logEditsReadRate, shippedBatchesRate, etc, which could indicate how fast the data replicated to peer cluster to some extent. However, it is not clear enough to know how many bytes replicating to peer cluster from these metrics. In production environment, it may be important to know the size of replicating data per second because the services may be affected if the network become busy.</description>
      <version>0.94.14</version>
      <fixedVersion>0.98.0,0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.MetricsSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="10215" opendate="2013-12-20 00:00:00" fixdate="2013-12-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TableNotFoundException should be thrown after removing stale znode in ETH</summary>
      <description>Lets suppose master went down while creating table then znode will be left in ENABLING state. Master to recover them on restart. If there are no meta entries for the table.While recovering the table we are checking whether table exists in meta or not, if not we are removing the znode. After removing znode we need to throw TableNotFoundException. Presently not throwing the exception so the znode will be recrated. It will be stale forever. Even on master restart we cannot delete. We cannot create the table with same name also. // Check if table exists if (!MetaReader.tableExists(catalogTracker, tableName)) { // retainAssignment is true only during recovery. In normal case it is false if (!this.skipTableStateCheck) { throw new TableNotFoundException(tableName); } try { this.assignmentManager.getZKTable().removeEnablingTable(tableName, true); } catch (KeeperException e) { // TODO : Use HBCK to clear such nodes LOG.warn("Failed to delete the ENABLING node for the table " + tableName + ". The table will remain unusable. Run HBCK to manually fix the problem."); } }</description>
      <version>0.96.1,0.94.14</version>
      <fixedVersion>0.98.0,0.94.16,0.96.2,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.EnableTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="1025" opendate="2008-11-23 00:00:00" fixdate="2008-7-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reconstruction log playback has no bounds on memory used</summary>
      <description>Makes a TreeMap and just keeps adding edits without regard for size of edits applied; could cause OOME (I've not seen a definitive case though have seen an OOME around time of a reconstructionlog replay &amp;#8211; perhaps this the straw that broke the fleas antlers?)</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLogSplit.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreReconstruction.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestStore.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.HBaseTestCase.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HMerge.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9346" opendate="2013-8-26 00:00:00" fixdate="2013-12-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBCK should provide an option to check if regions boundaries are the same in META and in stores.</summary>
      <description>If META don't have the same region boundaries as the stores files, writes and read might go to the wrong place. We need to provide a way to check that withing HBCK.</description>
      <version>0.94.14,0.98.1,0.99.0,0.96.1.1</version>
      <fixedVersion>0.98.0,0.94.16,0.96.2,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="981" opendate="2008-11-4 00:00:00" fixdate="2008-11-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase.io.index.interval doesn&amp;#39;t seem to have an effect; interval is 128 rather than the configured 32</summary>
      <description>This fact was discovered up on mailing list by Sijie Cai</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="9849" opendate="2013-10-28 00:00:00" fixdate="2013-11-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[REST] Forbidden schema delete in read only mode</summary>
      <description>If "hbase.rest.readonly" was set, all write operations should be forbidden via REST, right? So table schema deletion should also be forbidden in readonly mode?</description>
      <version>0.98.0,0.94.14</version>
      <fixedVersion>0.98.0,0.96.1,0.94.14</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestSchemaResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.SchemaResource.java</file>
    </fixedFiles>
  </bug>
</bugrepository>
