<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="12770" opendate="2014-12-29 00:00:00" fixdate="2014-8-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Don&amp;#39;t transfer all the queued hlogs of a dead server to the same alive server</summary>
      <description>When a region server is down(or the cluster restart), all the hlog queues will be transferred by the same alive region server. In a shared cluster, we might create several peers replicating data to different peer clusters. There might be lots of hlogs queued for these peers caused by several reasons, such as some peers might be disabled, or errors from peer cluster might prevent the replication, or the replication sources may fail to read some hlog because of hdfs problem. Then, if the server is down or restarted, another alive server will take all the replication jobs of the dead server, this might bring a big pressure to resources(network/disk read) of the alive server and also is not fast enough to replicate the queued hlogs. And if the alive server is down, all the replication jobs including that takes from other dead servers will once again be totally transferred to another alive server, this might cause a server have a large number of queued hlogs(in our shared cluster, we find one server might have thousands of queued hlogs for replication). As an optional way, is it reasonable that the alive server only transfer one peer's hlogs from the dead server one time? Then, other alive region servers might have the opportunity to transfer the hlogs of rest peers. This may also help the queued hlogs be processed more fast. Any discussion is welcome.</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,1.3.1,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationStateHBaseImpl.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationStateBasic.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManagerZkImpl.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.TableBasedReplicationQueuesImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueuesZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueues.java</file>
    </fixedFiles>
  </bug>
  <bug id="15358" opendate="2016-2-29 00:00:00" fixdate="2016-2-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>canEnforceTimeLimitFromScope should use timeScope instead of sizeScope</summary>
      <description>A small but maybe critical bug</description>
      <version>1.2.0,1.3.0,1.1.3,1.4.0,2.0.0</version>
      <fixedVersion>1.3.0,1.2.1,1.1.4,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ScannerContext.java</file>
    </fixedFiles>
  </bug>
  <bug id="15664" opendate="2016-4-17 00:00:00" fixdate="2016-4-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use Long.MAX_VALUE instead of HConstants.FOREVER in CompactionPolicy</summary>
      <description>The TTL per CF is in seconds, we will convert it to milliseconds when construct HStore. And if it is HConstants.FOREVER, we will set it to Long.MAX_VALUE.HStore.java public static long determineTTLFromFamily(final HColumnDescriptor family) { // HCD.getTimeToLive returns ttl in seconds. Convert to milliseconds. long ttl = family.getTimeToLive(); if (ttl == HConstants.FOREVER) { // Default is unlimited ttl. ttl = Long.MAX_VALUE; } else if (ttl == -1) { ttl = Long.MAX_VALUE; } else { // Second -&gt; ms adjust for user data ttl *= 1000; } return ttl; }</description>
      <version>1.3.0,0.98.19,1.4.0,2.0.0</version>
      <fixedVersion>1.3.0,0.98.19,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.RatioBasedCompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.DateTieredCompactionPolicy.java</file>
    </fixedFiles>
  </bug>
  <bug id="15707" opendate="2016-4-25 00:00:00" fixdate="2016-4-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ImportTSV bulk output does not support tags with hfile.format.version=3</summary>
      <description>Running the following command:hbase hbase org.apache.hadoop.hbase.mapreduce.ImportTsv \ -Dhfile.format.version=3 \ -Dmapreduce.map.combine.minspills=1 \ -Dimporttsv.separator=, \ -Dimporttsv.skip.bad.lines=false \ -Dimporttsv.columns="HBASE_ROW_KEY,cf1:a,HBASE_CELL_TTL" \ -Dimporttsv.bulk.output=/tmp/testttl/output/1 \ testttl \ /tmp/testttl/input The content of input is like:row1,data1,00000060 row2,data2,00000660 row3,data3,00000060 row4,data4,00000660When running hfile tool with the output hfile, there is no ttl tag.</description>
      <version>1.3.0,1.0.4,1.4.0,1.1.5,1.2.2,2.0.0</version>
      <fixedVersion>1.3.0,0.98.20,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.HBaseContext.scala</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.java</file>
    </fixedFiles>
  </bug>
  <bug id="15801" opendate="2016-5-9 00:00:00" fixdate="2016-5-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade checkstyle for all branches</summary>
      <description>We should use the same checkstyle for all branches.</description>
      <version>1.3.0,1.2.1,1.0.3,0.98.19,1.4.0,1.1.5,2.0.0</version>
      <fixedVersion>1.3.0,1.0.4,1.2.2,0.98.20,1.1.6,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="15834" opendate="2016-5-16 00:00:00" fixdate="2016-5-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Correct Bloom filter documentation in section 96.4 of Reference Guide</summary>
      <description>In section 96.4, the second paragraph from the bottomSince HBase 0.96, row-based Bloom filters are enabled by default. (HBASE-)</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.performance.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="16080" opendate="2016-6-22 00:00:00" fixdate="2016-6-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix flakey tests</summary>
      <description>Seems like TestTableBasedReplicationSourceManagerImpl.testCleanupFailoverQueues is a little flakey. We should make that more stable even on the apache test infra.https://builds.apache.org/job/HBase-Trunk_matrix/1090/jdk=latest1.7,label=yahoo-not-h2/testReport/junit/org.apache.hadoop.hbase.replication.regionserver/TestTableBasedReplicationSourceManagerImpl/testCleanupFailoverQueues/</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="16135" opendate="2016-6-28 00:00:00" fixdate="2016-7-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>PeerClusterZnode under rs of removed peer may never be deleted</summary>
      <description>One of our cluster run out of space recently, and we found that the .oldlogs directory had almost the same size as the data directory.Finally we found the problem is that, we removed a peer abort 3 months ago, but there are still some replication queue znode under some rs nodes. This prevents the deletion of .oldlogs.</description>
      <version>1.3.0,1.4.0,1.1.5,1.2.2,0.98.20,2.0.0</version>
      <fixedVersion>1.3.0,1.1.6,0.98.21,1.2.3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestTableBasedReplicationSourceManagerImpl.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManagerZkImpl.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueuesZKImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="16144" opendate="2016-6-29 00:00:00" fixdate="2016-7-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replication queue&amp;#39;s lock will live forever if RS acquiring the lock has died prematurely</summary>
      <description>In default, we will use multi operation when we claimQueues from ZK. But if we set hbase.zookeeper.useMulti=false, we will add a lock first, then copy nodes, finally clean old queue and the lock. However, if the RS acquiring the lock crash before claimQueues done, the lock will always be there and other RS can never claim the queue.</description>
      <version>1.3.0,1.4.0,1.2.2,0.98.20,1.1.6,2.0.0</version>
      <fixedVersion>1.3.0,1.1.6,1.2.3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestMultiSlaveReplication.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.ReplicationZKLockCleanerChore.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueuesZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="16266" opendate="2016-7-21 00:00:00" fixdate="2016-7-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Do not throw ScannerTimeoutException when catch UnknownScannerException</summary>
      <description>Now in scanner we have heartbeat to prevent timeout. The time blocked on ResultScanner.next() may much longer than scanner timeout. So it is no need any more to throw ScannerTimeoutException when server throws UnknownScannerException, we can just reset the scanner like NotServingRegionException</description>
      <version>1.3.0,1.4.0,1.2.2,1.1.6,2.0.0</version>
      <fixedVersion>1.3.0,1.1.6,1.2.3,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestPartialResultsFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannerTimeout.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="16285" opendate="2016-7-26 00:00:00" fixdate="2016-8-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Drop RPC requests if it must be considered as timeout at client</summary>
      <description>After HBASE-15593, we have a timeout param in header of RPC requests. We can use it in more scenes.A straightforward scene is to drop requests if it has waited so long in RPC queue and has been dropped by client. Even if we handle this request and send the response back, it will not be used any more. And client may have sent a retry. In an extreme case, if the server is slow, all requests may be timeout or queue-full-exception because we should handle previous requests which have been dropped by client and many resources at server are wasted.</description>
      <version>1.3.0,1.4.0,2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServerInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.CallRunner.java</file>
    </fixedFiles>
  </bug>
  <bug id="16312" opendate="2016-8-1 00:00:00" fixdate="2016-7-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>update jquery version</summary>
      <description>the jquery version we bundle for our web ui is EOM. update to latest jquery 3.y.we can use the jquery migrate plugin to help update APIs.</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.resources.hbase-webapps.thrift.thrift.jsp</file>
      <file type="M">hbase-thrift.src.main.resources.hbase-webapps.static.js.jquery.min.js</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.thrift.thrift.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.js.jquery.min.js</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.regionserver.storeFile.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.regionserver.region.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.regionserver.processRS.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.zk.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.tablesDetailed.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.snapshotsStats.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.snapshot.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.processRS.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.processMaster.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.procedures.jsp</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">hbase-rest.src.main.resources.hbase-webapps.rest.rest.jsp</file>
    </fixedFiles>
  </bug>
  <bug id="16314" opendate="2016-8-1 00:00:00" fixdate="2016-4-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Retry on table snapshot failure during full backup</summary>
      <description>Table snapshot (during full backup) can fail with NotServingRegionException (splits, AM region moves). We need to add retry logic here.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.impl.FullTableBackupClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupRestoreConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="16315" opendate="2016-8-1 00:00:00" fixdate="2016-8-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RegionSizeCalculator prints region names as binary without escapes</summary>
      <description>Region start key is not escaped: 2016-05-20 01:35:04,646|beaver.machine|INFO|8984|140719733470976|MainThread|2016-05-20 01:35:04,637 DEBUG [main] util.RegionSizeCalculator: Region IntegrationTestBigLinkedList,��������,1463706056389.609c5d0e2a3a03eb3d93d608b9722fb9. has size 1300234242016-05-20 01:35:04,647|beaver.machine|INFO|8984|140719733470976|MainThread|2016-05-20 01:35:04,637 DEBUG [main] util.RegionSizeCalculator: Region IntegrationTestBigLinkedList,�"""""" ,1463706056389.6b2d56bc9f04339156a858595b237614. has size 1300234242016-05-20 01:35:04,647|beaver.machine|INFO|8984|140719733470976|MainThread|2016-05-20 01:35:04,637 DEBUG [main] util.RegionSizeCalculator: Region IntegrationTestBigLinkedList,��������,1463706056389.4eab8c5beba325cb8a2731151f8bbe77. has size 1342177282016-05-20 01:35:04,647|beaver.machine|INFO|8984|140719733470976|MainThread|2016-05-20 01:35:04,637 DEBUG [main] util.RegionSizeCalculator: Region IntegrationTestBigLinkedList,�wwwwwwh,1463706056389.406e8bbe17eabb4aca2b246d1242013c. has size 131072000</description>
      <version>None</version>
      <fixedVersion>1.3.0,1.1.6,1.2.3,0.98.22,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionLoad.java</file>
    </fixedFiles>
  </bug>
  <bug id="1632" opendate="2009-7-9 00:00:00" fixdate="2009-7-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Write documentation for configuring/managing ZooKeeper with HBase</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.overview.html</file>
    </fixedFiles>
  </bug>
  <bug id="1633" opendate="2009-7-9 00:00:00" fixdate="2009-7-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Can&amp;#39;t delete in TRUNK shell; makes it hard doing admin repairs</summary>
      <description>Because shell uses old API, it runs into the "Can't add deletes to a BatchUpdate" issue. Add new API to do shell delete and deleteAll. Just a few lines.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.HBase.rb</file>
    </fixedFiles>
  </bug>
  <bug id="16336" opendate="2016-8-2 00:00:00" fixdate="2016-12-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Removing peers seems to be leaving spare queues</summary>
      <description>I have been running IntegrationTestReplication repeatedly with the backported Replication Table changes. Every other iteration of the test fails with, but these queues should have been deleted when we removed the peers. I believe this may be related to HBASE-16096, HBASE-16208, or HBASE-16081.16/08/02 08:36:07 ERROR util.AbstractHBaseTool: Error running command-line toolorg.apache.hadoop.hbase.replication.ReplicationException: undeleted queue for peerId: TestPeer, replicator: hbase4124.ash2.facebook.com,16020,1470150251042, queueId: TestPeer at org.apache.hadoop.hbase.replication.ReplicationPeersZKImpl.checkQueuesDeleted(ReplicationPeersZKImpl.java:544) at org.apache.hadoop.hbase.replication.ReplicationPeersZKImpl.addPeer(ReplicationPeersZKImpl.java:127) at org.apache.hadoop.hbase.client.replication.ReplicationAdmin.addPeer(ReplicationAdmin.java:200) at org.apache.hadoop.hbase.test.IntegrationTestReplication$VerifyReplicationLoop.setupTablesAndReplication(IntegrationTestReplication.java:239) at org.apache.hadoop.hbase.test.IntegrationTestReplication$VerifyReplicationLoop.run(IntegrationTestReplication.java:325) at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70) at org.apache.hadoop.hbase.test.IntegrationTestReplication.runTestFromCommandLine(IntegrationTestReplication.java:418) at org.apache.hadoop.hbase.IntegrationTestBase.doWork(IntegrationTestBase.java:134) at org.apache.hadoop.hbase.util.AbstractHBaseTool.run(AbstractHBaseTool.java:112) at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70) at org.apache.hadoop.hbase.test.IntegrationTestReplication.main(IntegrationTestReplication.java:424)</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.hbck.ReplicationChecker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="16338" opendate="2016-8-2 00:00:00" fixdate="2016-10-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>update jackson to 2.y</summary>
      <description>Our jackson dependency is from ~3 years ago. Update to the jackson 2.y line, using 2.7.0+.</description>
      <version>None</version>
      <fixedVersion>2.0.0-alpha-4,2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.taskmonitor.rb</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-spark.pom.xml</file>
      <file type="M">dev-support.hbase-personality.sh</file>
      <file type="M">hbase-client.pom.xml</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.util.JsonMapper.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestOperation.java</file>
      <file type="M">hbase-it.pom.xml</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.RESTApiClusterManager.java</file>
      <file type="M">hbase-mapreduce.pom.xml</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.TestPerformanceEvaluation.java</file>
      <file type="M">hbase-resource-bundle.src.main.resources.supplemental-models.xml</file>
      <file type="M">hbase-rest.pom.xml</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.CellModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.ColumnSchemaModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.NamespacesModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.RowModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.ScannerModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.StorageClusterStatusModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.StorageClusterVersionModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.TableSchemaModel.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.ProtobufStreamingUtil.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.RESTServer.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.TableScanResource.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.HBaseRESTTestingUtility.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.model.TestColumnSchemaModel.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.model.TestModelBase.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.model.TestTableSchemaModel.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.RowResourceBase.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.TestDeleteRow.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.TestMultiRowResource.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.TestNamespacesInstanceResource.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.TestSchemaResource.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.TestTableScan.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.TestVersionResource.java</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.AgeSnapshot.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.BlockCacheUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.JSONBean.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.JSONMetricUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALPrettyPrinter.java</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.processMaster.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.processRS.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.regionserver.processRS.jsp</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestBlockCacheReporting.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestJSONMetricUtil.java</file>
      <file type="M">hbase-shaded.hbase-shaded-mapreduce.pom.xml</file>
      <file type="M">hbase-shaded.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="16341" opendate="2016-8-2 00:00:00" fixdate="2016-8-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Missing bit on "Regression: Random Read/WorkloadC slower in 1.x than 0.98"</summary>
      <description>larsgeorge found a missing bit in HBASE-15971 "Regression: Random Read/WorkloadC slower in 1.x than 0.98" Let me fix here. Let me quote the man:BTW, in constructor we do this``` String callQueueType = conf.get(CALL_QUEUE_TYPE_CONF_KEY, CALL_QUEUE_TYPE_FIFO_CONF_VALUE);```(edited)[8:19] but in `onConfigurationChange()` we do``` String callQueueType = conf.get(CALL_QUEUE_TYPE_CONF_KEY, CALL_QUEUE_TYPE_DEADLINE_CONF_VALUE);```(edited)</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
    </fixedFiles>
  </bug>
  <bug id="16347" opendate="2016-8-3 00:00:00" fixdate="2016-8-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unevaluated expressions in book</summary>
      <description>Have a look at the quickstart guide, step two$ tar xzvf hbase-&lt;?eval ${project.version}?&gt;-bin.tar.gz$ cd hbase-&lt;?eval ${project.version}?&gt;/</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.getting.started.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="16499" opendate="2016-8-25 00:00:00" fixdate="2016-4-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>slow replication for small HBase clusters</summary>
      <description>For small clusters 10-20 nodes we recently observed that replication is progressing very slowly when we do bulk writes and there is lot of lag accumulation on AgeOfLastShipped / SizeOfLogQueue. From the logs we observed that the number of threads used for shipping wal edits in parallel comes from the following equation in HBaseInterClusterReplicationEndpointint n = Math.min(Math.min(this.maxThreads, entries.size()/100+1), replicationSinkMgr.getSinks().size());... for (int i=0; i&lt;n; i++) { entryLists.add(new ArrayList&lt;HLog.Entry&gt;(entries.size()/n+1)); &lt;-- batch size }... for (int i=0; i&lt;entryLists.size(); i++) { ..... // RuntimeExceptions encountered here bubble up and are handled in ReplicationSource pool.submit(createReplicator(entryLists.get(i), i)); &lt;-- concurrency futures++; } }maxThreads is fixed &amp; configurable and since we are taking min of the three values n gets decided based replicationSinkMgr.getSinks().size() when we have enough edits to replicatereplicationSinkMgr.getSinks().size() is decided based on int numSinks = (int) Math.ceil(slaveAddresses.size() * ratio);where ratio is this.ratio = conf.getFloat("replication.source.ratio", DEFAULT_REPLICATION_SOURCE_RATIO);Currently DEFAULT_REPLICATION_SOURCE_RATIO is set to 10% so for small clusters of size 10-20 RegionServers the value we get for numSinks and hence n is very small like 1 or 2. This substantially reduces the pool concurrency used for shipping wal edits in parallel effectively slowing down replication for small clusters and causing lot of lag accumulation in AgeOfLastShipped. Sometimes it takes tens of hours to clear off the entire replication queue even after the client has finished writing on the source side. We are running tests by varying replication.source.ratio and have seen multi-fold improvement in total replication time (will update the results here). I wanted to propose here that we should increase the default value for replication.source.ratio also so that we have sufficient concurrency even for small clusters. We figured it out after lot of iterations and debugging so probably slightly higher default will save the trouble.</description>
      <version>None</version>
      <fixedVersion>1.5.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSinkManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSinkManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="16535" opendate="2016-8-31 00:00:00" fixdate="2016-8-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use regex to exclude generated classes for findbugs</summary>
      <description>As I tried in HBASE-16526, &lt;Match&gt; &lt;Package name="org.apache.hadoop.hbase.ipc.protobuf.generated"/&gt; &lt;/Match&gt;This does not work.So I propose that we can use regex to match the class name to exclude the generated classes.</description>
      <version>1.3.0,1.4.0,1.1.6,0.98.21,1.2.3,2.0.0</version>
      <fixedVersion>1.3.0,0.98.22,1.1.7,1.2.4,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.findbugs-exclude.xml</file>
    </fixedFiles>
  </bug>
  <bug id="16554" opendate="2016-9-2 00:00:00" fixdate="2016-9-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure V2 - Recover &amp;#39;updated&amp;#39; part of WAL tracker if trailer is corrupted.</summary>
      <description>If the last wal was closed cleanly, the global tracker will be the last wal tracker (no rebuild needed)if the last wal does not have a tracker (corrupted/master-killed). on load() we will rebuild the global tracker.To compute quickly which files should be deleted, we also want the tracker of each file.if the wal was closed properly and has a tracker we are good, if not we need to rebuild the tracker for that file.each file tracker contains a bitmap about what is in the wal (the updated bitmap), which is easy to compute just by reading each entry of the wal.The 'deleted' bitmap keeps track of the "running procedures" up to that wal, however, it's not required by WAL cleaner, so we don't bother recovering it.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.wal.TestWALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALFormatReader.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALFormat.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALFile.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.ProcedureStoreTracker.java</file>
    </fixedFiles>
  </bug>
  <bug id="16562" opendate="2016-9-5 00:00:00" fixdate="2016-10-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ITBLL should fail to start if misconfigured</summary>
      <description>The number of nodes in ITBLL must a multiple of width*wrap (defaults to 25M, but can be configured by adding two more args to the test invocation) or else verification will fail. This can be very expensive in terms of time or hourly billing for on demand test resources. Check the sanity of test parameters before launching any MR jobs and fail fast if invariants aren't met with an indication what parameter(s) need fixing.</description>
      <version>None</version>
      <fixedVersion>1.0.4,1.4.0,1.3.1,1.1.7,0.98.23,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
    </fixedFiles>
  </bug>
  <bug id="16618" opendate="2016-9-12 00:00:00" fixdate="2016-9-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - Add base class for table and ns procedures</summary>
      <description>Now that we have a bunch of procedures implemented, we can add a base class for the Table and Namespace procedure with a couple of the common pattern used (e.g. basic locking, toString, ...).</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.TruncateTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.RestoreSnapshotProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterDDLOperationHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.EnableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DispatchMergingRegionsProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DisableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CreateNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CloneSnapshotProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.AddColumnFamilyProcedure.java</file>
    </fixedFiles>
  </bug>
  <bug id="1670" opendate="2009-7-17 00:00:00" fixdate="2009-7-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>transactions / indexing fixes: trx deletes not handeled, index scan can&amp;#39;t specify stopRow</summary>
      <description>couple of things I missed in api refactor</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">src.contrib.transactional.src.test.org.apache.hadoop.hbase.client.transactional.TestTransactions.java</file>
      <file type="M">src.contrib.transactional.src.test.org.apache.hadoop.hbase.client.tableindexed.TestIndexedTable.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.regionserver.transactional.TransactionState.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegionServer.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegion.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.regionserver.transactional.THLog.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.regionserver.tableindexed.IndexMaintenanceUtils.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.regionserver.tableindexed.IndexedRegion.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.client.transactional.TransactionManager.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.client.transactional.TransactionalTable.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.client.transactional.JtaXAResource.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.client.tableindexed.IndexedTableDescriptor.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.client.tableindexed.IndexedTable.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="16700" opendate="2016-9-24 00:00:00" fixdate="2016-12-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow for coprocessor whitelisting</summary>
      <description>Today one can turn off all non-system coprocessors with hbase.coprocessor.user.enabled however, this disables very useful things like Apache Phoenix's coprocessors. Some tenants of a multi-user HBase may also need to run bespoke coprocessors. But as an operator I would not want wanton coprocessor usage. Ideally, one could do one of two things: Allow coprocessors defined in hbase-site.xml &amp;#8211; this can only be administratively changed in most cases Allow coprocessors from table descriptors but only if the coprocessor is whitelisted</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.cp.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="16886" opendate="2016-10-20 00:00:00" fixdate="2016-12-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase-client: scanner with reversed=true and small=true gets no result</summary>
      <description>Assume HBase have four regions (-oo, b), [b, c), [c, d), [d,+oo) , and all rowKeys are located in region [d, +oo). using a Reversed Small Scanner will get no result.Attached file show this failed test case.</description>
      <version>1.3.0,1.4.0,1.2.3,1.1.7,0.98.23,2.0.0</version>
      <fixedVersion>1.4.0,1.3.1,1.2.5,1.1.8,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestClientSmallReversedScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallReversedScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="1694" opendate="2009-7-24 00:00:00" fixdate="2009-7-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add TOC to &amp;#39;Getting Started&amp;#39;, add references to THBase and ITHBase</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.overview.html</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.Migrate.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="16941" opendate="2016-10-25 00:00:00" fixdate="2016-12-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>FavoredNodes - Split/Merge code paths</summary>
      <description>This jira is to deal with the split/merge logic discussed as part of HBASE-15532. The design document can be seen at HBASE-15531. The specific changes are:Split and merged regions should inherit favored node information from parent regions. For splits also include some randomness so even if there are subsequent splits, the regions will be more or less distributed. For split, we include 2 FN from the parent and generate one random node.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRegionPlacement2.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRegionPlacement.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockNoopMasterServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestFavoredNodeAssignmentHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SnapshotOfRegionAssignmentFromMeta.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionPlacementMaintainer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.FavoredNodeLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.FavoredNodeAssignmentHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentVerificationReport.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ServerName.java</file>
    </fixedFiles>
  </bug>
  <bug id="16949" opendate="2016-10-26 00:00:00" fixdate="2016-10-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix RAT License complaint about the hbase-protocol-shaded/src/main/patches content</summary>
      <description>Noticed by @duo zhang over on HBASE-16835. Let me exclude the patches dir from rat check.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-protocol.README.txt</file>
      <file type="M">hbase-protocol-shaded.README.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1695" opendate="2009-7-24 00:00:00" fixdate="2009-7-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[stargate] differentiate PUT and POST processing for schema upload</summary>
      <description>The Stargate documentation states the following regarding PUT and POST to a table schema resource:PUT or POST creates table as necessary. PUT fully replaces schema. POST modifies schema (add or modify column family). Supply the full table schema for PUT or a well formed schema fragment for POST in the desired encoding.Current implementation punts and treats both PUT and POST as equivalent. Fix before release.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.contrib.stargate.src.java.org.apache.hadoop.hbase.stargate.SchemaResource.java</file>
    </fixedFiles>
  </bug>
  <bug id="16950" opendate="2016-10-27 00:00:00" fixdate="2016-10-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Print raw stats in the end of procedure performance tools for parsing results from scripts</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureSchedulerPerformanceEvaluation.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALPerformanceEvaluation.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALLoaderPerformanceEvaluation.java</file>
    </fixedFiles>
  </bug>
  <bug id="16960" opendate="2016-10-28 00:00:00" fixdate="2016-11-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RegionServer hang when aborting</summary>
      <description>We see regionserver hang when aborting several times and cause all regions on this regionserver out of service and then all affected applications stop works.</description>
      <version>1.3.0,1.4.0,1.2.3,1.1.7,2.0.0</version>
      <fixedVersion>1.3.0,1.2.5,1.1.8,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestWALLockup.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SyncFuture.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.java</file>
    </fixedFiles>
  </bug>
  <bug id="16985" opendate="2016-11-1 00:00:00" fixdate="2016-12-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestClusterId failed due to wrong hbase rootdir</summary>
      <description>https://builds.apache.org/job/PreCommit-HBASE-Build/4253/testReport/org.apache.hadoop.hbase.regionserver/TestClusterId/testClusterId/java.io.IOException: Shutting down at org.apache.hadoop.hbase.util.JVMClusterUtil.startup(JVMClusterUtil.java:230) at org.apache.hadoop.hbase.LocalHBaseCluster.startup(LocalHBaseCluster.java:409) at org.apache.hadoop.hbase.MiniHBaseCluster.init(MiniHBaseCluster.java:227) at org.apache.hadoop.hbase.MiniHBaseCluster.&lt;init&gt;(MiniHBaseCluster.java:96) at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniHBaseCluster(HBaseTestingUtility.java:1071) at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniHBaseCluster(HBaseTestingUtility.java:1037) at org.apache.hadoop.hbase.regionserver.TestClusterId.testClusterId(TestClusterId.java:85)The cluster can not start up because there are no active master. The active master can not finish initialing because the hbase:namespace region can not be assign. In TestClusterId unit test, TEST_UTIL.startMiniHBaseCluster set new hbase root dir. But the regionserver thread which stared first used a different hbase root dir. If assign hbase:namespace region to this regionserver, the region can not be assigned because there are no tableinfo on wrong hbase root dir.When regionserver report to master, it will get back some new config. But the FSTableDescriptors has been initialed so it's root dir didn't changed.if (LOG.isDebugEnabled()) { LOG.info("Config from master: " + key + "=" + value);} I thought FSTableDescriptors need update the rootdir when regionserver get report from master.The master branch has same problem, too. But the balancer always assign hbase:namesapce region to master. So this unit test can passed on master branch.</description>
      <version>1.3.0,1.4.0,1.1.7,1.2.4,2.0.0</version>
      <fixedVersion>1.4.0,1.2.5,1.1.9,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="16986" opendate="2016-11-1 00:00:00" fixdate="2016-11-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add note on how scanner caching has changed since 0.98 to refguid</summary>
      <description>Add note on how scanner caching config changed from 0.98 to the refguide (see parent issue for discussion but basics are we used to have default of 100 but not have unlimited as default)</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="17017" opendate="2016-11-4 00:00:00" fixdate="2016-11-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove the current per-region latency histogram metrics</summary>
      <description></description>
      <version>1.3.0,1.4.0,2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="17058" opendate="2016-11-10 00:00:00" fixdate="2016-11-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Lower epsilon used for jitter verification from HBASE-15324</summary>
      <description>The current epsilon used is 1E-6 and its too big it might overflow the desiredMaxFileSize. A trivial fix is to lower the epsilon to 2^-52 or even 2^-53. An option to consider too is just to shift the jitter to always decrement hbase.hregion.max.filesize (MAX_FILESIZE) instead of increase the size of the region and having to deal with the round off.</description>
      <version>1.3.0,1.4.0,1.1.7,1.2.4,2.0.0</version>
      <fixedVersion>1.3.0,1.2.5,1.1.8,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy.java</file>
    </fixedFiles>
  </bug>
  <bug id="17074" opendate="2016-11-11 00:00:00" fixdate="2016-11-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>PreCommit job always fails because of OOM</summary>
      <description>https://builds.apache.org/job/PreCommit-HBASE-Build/4434/artifact/patchprocess/patch-unit-hbase-server.txtException in thread "Thread-2369" java.lang.OutOfMemoryError: Java heap space at java.util.Arrays.copyOf(Arrays.java:3332) at java.lang.AbstractStringBuilder.ensureCapacityInternal(AbstractStringBuilder.java:124) at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:596) at java.lang.StringBuffer.append(StringBuffer.java:367) at java.io.BufferedReader.readLine(BufferedReader.java:370) at java.io.BufferedReader.readLine(BufferedReader.java:389) at org.apache.maven.surefire.shade.org.apache.maven.shared.utils.cli.StreamPumper.run(StreamPumper.java:66)Exception in thread "Thread-2357" java.lang.OutOfMemoryError: Java heap spaceException in thread "Thread-2365" java.lang.OutOfMemoryError: Java heap spaceRunning org.apache.hadoop.hbase.filter.TestFuzzyRowFilterEndToEndRunning org.apache.hadoop.hbase.filter.TestFilterListOrOperatorWithBlkCntException in thread "Thread-2383" java.lang.OutOfMemoryError: Java heap spaceException in thread "Thread-2397" java.lang.OutOfMemoryError: Java heap spaceException in thread "Thread-2401" java.lang.OutOfMemoryError: Java heap spaceRunning org.apache.hadoop.hbase.TestHBaseTestingUtilityException in thread "Thread-2407" java.lang.OutOfMemoryError: Java heap spaceException in thread "Thread-2411" java.lang.OutOfMemoryError: Java heap spaceException in thread "Thread-2413" java.lang.OutOfMemoryError: Java heap spaceThe OOM happens in the surefire plugin when reading the stdout or stderr of the running test...</description>
      <version>1.3.0,1.4.0,1.1.7,0.98.23,1.2.4,2.0.0</version>
      <fixedVersion>1.3.0,1.2.5,0.98.24,1.1.8,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.docker.Dockerfile</file>
    </fixedFiles>
  </bug>
  <bug id="17149" opendate="2016-11-21 00:00:00" fixdate="2016-12-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure V2 - Fix nonce submission to avoid unnecessary calling coprocessor multiple times</summary>
      <description>instead of having all the logic in submitProcedure(), split in registerNonce() + submitProcedure().In this case we can avoid calling the coprocessor twice and having a clean submit logic knowing that there will only be one submission.</description>
      <version>1.3.0,1.4.0,1.1.7,1.2.4,2.0.0</version>
      <fixedVersion>1.3.0,1.2.5,1.1.9,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestCoprocessorWhitelistMasterObserver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestSplitTableRegionProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestProcedureAdmin.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestModifyTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestModifyColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMasterProcedureEvents.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestEnableTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestDispatchMergingRegionsProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestDisableTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestDeleteTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestCreateTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestAddColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableNamespaceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ClusterSchemaServiceImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ClusterSchema.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.TestProcedureRecovery.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.ProcedureTestingUtility.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureExecutor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestTruncateTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestTableDDLProcedureBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestRestoreSnapshotProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestModifyNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMergeTableRegionsProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestDeleteNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestDeleteColumnFamilyProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestCreateNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestCloneSnapshotProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug id="17178" opendate="2016-11-28 00:00:00" fixdate="2016-11-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add region balance throttling</summary>
      <description>Our online cluster serves dozens of tables and different tables serve for different services. If the balancer moves too many regions in the same time, it will decrease the availability for some table or some services. So we add region balance throttling on our online serve cluster. We introduce a new config hbase.balancer.max.balancing.regions, which means the max number of regions in transition when balancing.If we config this to 1 and a table have 100 regions, then the table will have 99 regions available at any time. It helps a lot for our use case and it has been running a long timeour production cluster.But for some use case, we need the balancer run faster. If a cluster has 100 regionservers, then it add 50 new regionservers for peak requests. Then it need balancer run as soon aspossible and let the cluster reach a balance state soon. Our idea is compute max number of regions in transition by the max balancing time and the average time of region in transition.Then the balancer use the computed value to throttling.Examples for understanding.A cluster has 100 regionservers, each regionserver has 200 regions and the average time of region in transition is 1 seconds, we config the max balancing time is 10 * 60 seconds.Case 1. One regionserver crash, the cluster at most need balance 200 regions. Then 200 / (10 * 60s / 1s) &lt; 1, it means the max number of regions in transition is 1 when balancing. Then the balancer can move region one by one and the cluster will have high availability when balancing.Case 2. Add other 100 regionservers, the cluster at most need balance 10000 regions. Then 10000 / (10 * 60s / 1s) = 16.7, it means the max number of regions in transition is 17 when balancing. Then the cluster can reach a balance state within the max balancing time.Any suggestions are welcomed.Review board: https://reviews.apache.org/r/54191/</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BalancerChore.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="17181" opendate="2016-11-28 00:00:00" fixdate="2016-12-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Let HBase thrift2 support TThreadedSelectorServer</summary>
      <description>Add TThreadedSelectorServer for HBase Thrift2</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="17207" opendate="2016-11-30 00:00:00" fixdate="2016-12-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Arrays.asList() with too few arguments</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStateStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RackManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputSaslHelper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FilterList.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MultiAction.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.BufferedMutatorImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="17210" opendate="2016-11-30 00:00:00" fixdate="2016-2-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Set timeout on trying rowlock according to client&amp;#39;s RPC timeout</summary>
      <description>Now when we want to get a row lock, the timeout is fixed and default is 30s. But the requests from client have different RPC timeout setting. We can use the client's deadline to set timeout on tryLock.</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="17328" opendate="2016-12-16 00:00:00" fixdate="2016-12-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Properly dispose of looped replication peers</summary>
      <description>When adding a looped replication peer (clusterId == peerClusterId), the following code terminates the replication source thread, but since the source manager still holds a reference, WALs continue to get enqueued, and never get cleaned because they're stuck in the queue, leading to an unsustainable buildup. Furthermore, the replication statistics thread will continue to print statistics for the terminated source.if (clusterId.equals(peerClusterId) &amp;&amp; !replicationEndpoint.canReplicateToSameCluster()) { this.terminate("ClusterId " + clusterId + " is replicating to itself: peerClusterId " + peerClusterId + " which is not allowed by ReplicationEndpoint:" + replicationEndpoint.getClass().getName(), null, false); }</description>
      <version>1.3.0,1.4.0,0.98.23,2.0.0</version>
      <fixedVersion>1.3.0,1.2.5,0.98.24,1.1.9,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestMasterReplication.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="17333" opendate="2016-12-19 00:00:00" fixdate="2016-12-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBASE-17294 always ensures CompactingMemstore is default</summary>
      <description>Was the purpose of HBASE-17294 is to make Compacting Memstore as default? Am not sure on that. But that patch makes DefaultMemstore as a Noop. This JIRA is to discuss and revert back to default memstore only if the family is not configured for in memory flush/compaction.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactingMemStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="17352" opendate="2016-12-21 00:00:00" fixdate="2016-5-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix hbase-assembly build with bash 4</summary>
      <description>hbase-assembly fails to build with bash 4.[DEBUG] Executing command line: [env, bash, -c, cat maven-shared-archive-resources/META-INF/NOTICE \ `find /Users/jg/github/hbase/hbase-assembly/target/dependency -iname NOTICE -or -iname NOTICE.txt` \][ERROR] Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.4.0:exec (concat-NOTICE-files) on project hbase-assembly: Command execution failed. Process exited with an error: 1 (Exit value: 1) -&gt; [Help 1]org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.4.0:exec (concat-NOTICE-files) on project hbase-assembly: Command execution failed.The error is caused by the trailing backslash in the bash command for concat-NOTICE-files. You can see the behavioral difference between bash 3 and 4 with the following snippet.$ # Using bash 3$ /bin/bash -c 'cat &lt;(echo foo) \' &amp;&amp; echo good || echo badfoogood$ # Using bash 4$ /usr/local/bin/bash -c 'cat &lt;(echo foo) \' &amp;&amp; echo good || echo badfoocat: \: No such file or directorybad</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.2.6,1.3.2,1.1.11,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-assembly.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="17471" opendate="2017-1-15 00:00:00" fixdate="2017-5-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Region Seqid will be out of order in WAL if using mvccPreAssign</summary>
      <description>mvccPreAssign was brought by HBASE-16698, which truly improved the performance of writing, especially in ASYNC_WAL scenario. But mvccPreAssign was only used in doMiniBatchMutate, not in Increment/Append path. If Increment/Append and batch put are using against the same region in parallel, then seqid of the same region may not monotonically increasing in the WAL. Since one write path acquires mvcc/seqid before append, and the other acquires in the append/sync consume thread.The out of order situation can easily reproduced by a simple UT, which was attached in the attachment. I modified the code to assert on the disorder: if(this.highestSequenceIds.containsKey(encodedRegionName)) { assert highestSequenceIds.get(encodedRegionName) &lt; sequenceid; }I'd like to say, If we allow disorder in WALs, then this is not a issue. But as far as I know, if highestSequenceIds is not properly set, some WALs may not archive to oldWALs correctly.which I haven't figure out yet is that, will disorder in WAL cause data loss when recovering from disaster? If so, then it is a big problem need to be fixed.I have fix this problem in our costom1.1.x branch, my solution is using mvccPreAssign everywhere, making it un-configurable. Since mvccPreAssign it is indeed a better way than assign seqid in the ringbuffer thread while keeping handlers waiting for it.If anyone think it is doable, then I will port it to branch-1 and master branch and upload it.</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestWALFactory.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestSecureWAL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALActionsListener.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.AbstractTestWALReplay.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.AbstractTestFSWAL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestWALLockup.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestWALObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALKey.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSWALEntry.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="17472" opendate="2017-1-16 00:00:00" fixdate="2017-2-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Correct the semantic of permission grant</summary>
      <description>Currently, HBase grant operation has following semantic:hbase(main):019:0&gt; grant 'hbase_tst', 'RW', 'ycsb'0 row(s) in 0.0960 secondshbase(main):020:0&gt; user_permission 'ycsb'User Namespace,Table,Family,Qualifier:Permission hbase_tst default,ycsb,,: [Permission:actions=READ,WRITE] 1 row(s) in 0.0550 secondshbase(main):021:0&gt; grant 'hbase_tst', 'CA', 'ycsb'0 row(s) in 0.0820 secondshbase(main):022:0&gt; user_permission 'ycsb'User Namespace,Table,Family,Qualifier:Permission hbase_tst default,ycsb,,: [Permission: actions=CREATE,ADMIN] 1 row(s) in 0.0490 seconds Later permission will replace previous granted permissions, which confused most of HBase administrator.It's seems more reasonable that HBase merge multiple granted permission.</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestTablePermissions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestNamespaceCommands.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.SecureTestUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlLists.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.AccessControl.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.TablePermission.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="17478" opendate="2017-1-17 00:00:00" fixdate="2017-2-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Avoid sending FSUtilization reports to master when quota support is not enabled</summary>
      <description>Trivial little change to make sure that the RS's do not send the filesystem utilization reports to the master when hbase.quota.enabled=false and, similarly, that the master gracefully handles these reports when the feature is not enabled.</description>
      <version>None</version>
      <fixedVersion>HBASE-16961,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.MasterQuotaManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="17508" opendate="2017-1-22 00:00:00" fixdate="2017-2-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unify the implementation of small scan and regular scan for sync client</summary>
      <description>Implement the same logic with HBASE-17045 for sync client.</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestPartialResultsFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestMetaTableAccessorNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.MobSnapshotTestingUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController2.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestScannerWithBulkload.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMobStoreScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestLeaseRenewal.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide3.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestClientScannerRPCTimeout.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.Canary.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.SyncTable.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestClientSmallScanner.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestClientSmallReversedScanner.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MetaTableAccessor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallReversedScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncNonMetaRegionLocator.java</file>
    </fixedFiles>
  </bug>
  <bug id="17511" opendate="2017-1-23 00:00:00" fixdate="2017-2-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement enable/disable table methods</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.AsyncMetaTableAccessor.java</file>
    </fixedFiles>
  </bug>
  <bug id="17583" opendate="2017-2-2 00:00:00" fixdate="2017-2-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add inclusive/exclusive support for startRow and endRow of scan for sync client</summary>
      <description>Implement the same feature of HBASE-17320 for sync client.</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestMetaTableAccessorNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannersFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.AbstractTestAsyncTableScan.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSimpleScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientAsyncPrefetchScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="17595" opendate="2017-2-4 00:00:00" fixdate="2017-3-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add partial result support for small/limited scan</summary>
      <description>The partial result support is marked as a 'TODO' when implementing HBASE-17045. And when implementing HBASE-17508, we found that if we make small scan share the same logic with general scan, the scan request other than open scanner will not have the small flag so the server may return partial result to the client and cause some strange behavior. It is solved by modifying the logic at server side, but this means the 1.4.x client is not safe to contact with earlier 1.x server. So we'd better address the problem at client side. Marked as blocker as this issue should be finished before any 2.x and 1.4.x releases.</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScanResultCache.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.BatchScanResultCache.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AllowPartialScanResultCache.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestPartialResultsFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannersFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestRawAsyncTableScan.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTableScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTableScanAll.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTableScan.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.AbstractTestAsyncTableScan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ScannerContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Result.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncTableImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.CompleteScanResultCache.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncScanSingleRegionRpcRetryingCaller.java</file>
    </fixedFiles>
  </bug>
  <bug id="17596" opendate="2017-2-4 00:00:00" fixdate="2017-2-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement add/delete/modify column family methods</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="17600" opendate="2017-2-6 00:00:00" fixdate="2017-3-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement get/create/modify/delete/list namespace admin operations</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="17602" opendate="2017-2-7 00:00:00" fixdate="2017-3-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Tweak chore delay/period defaults</summary>
      <description>In testing, found that the default chore periods/delays were a little too lax. This resulted in quotas not being updated as soon as they really should have been.</description>
      <version>None</version>
      <fixedVersion>HBASE-16961,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.SpaceQuotaRefresherChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaObserverChore.java</file>
    </fixedFiles>
  </bug>
  <bug id="17618" opendate="2017-2-9 00:00:00" fixdate="2017-2-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Refactor the implementation of modify table and delete column in MOB</summary>
      <description>Now in the implementation of modify table, delete column in MOB, the MOB directory is removed once for each region which is not necessary and not right. We should only delete the MOB directory only once.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.MobUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterDDLOperationHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
    </fixedFiles>
  </bug>
  <bug id="17627" opendate="2017-2-11 00:00:00" fixdate="2017-2-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Active workers metric for thrift</summary>
      <description>It would be good to have a metric for number of active handlers on thrift servers, which gives a good indication of business of a thrift server.</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.1,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftMetrics.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.TBoundedThreadPoolServer.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.thrift.MetricsThriftServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.thrift.MetricsThriftServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="17634" opendate="2017-2-11 00:00:00" fixdate="2017-2-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up the usage of Result.isPartial</summary>
      <description>We have marked Result.isPartial as deprecated in HBASE-17599. This issue aims to remove the isPartial usage in our code base.</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestPartialResultsFromClientSide.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.java</file>
    </fixedFiles>
  </bug>
  <bug id="17698" opendate="2017-2-24 00:00:00" fixdate="2017-3-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ReplicationEndpoint choosing sinks</summary>
      <description>The only time we choose new sinks is when we have a ConnectException, but we have encountered other exceptions where there is a problem contacting a particular sink and replication gets backed up for any sources that try that sinkHBASE-17675 occurred when there was a bad keytab refresh and the source was stuck.Another issue we recently had was a bad drive controller on the sink side and replication was stuck again. Is there any reason not to choose new sinks anytime we have a RemoteException? I can understand TableNotFound we don't have to choose new sinks, but for all other cases this seems like the safest approach.</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,1.3.1,1.1.10,1.2.6,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint.java</file>
    </fixedFiles>
  </bug>
  <bug id="17699" opendate="2017-2-25 00:00:00" fixdate="2017-2-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix TestLockProcedure</summary>
      <description>TestLockProcedure is failing consistently after HBASE-17605. It's interesting that HadoopQA didn't report any test failures on that jira. Anyways, need to fix the test now.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.SimpleProcedureScheduler.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureScheduler.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureExecutor.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.java</file>
    </fixedFiles>
  </bug>
  <bug id="17712" opendate="2017-3-1 00:00:00" fixdate="2017-3-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove/Simplify the logic of RegionScannerImpl.handleFileNotFound</summary>
      <description>It is introduced in HBASE-13651 and the logic became much more complicated after HBASE-16304 due to a dead lock issue. It is really tough as sequence id is involved in and the method we called is used to serve secondary replica originally which does not handle write.In fact, in 1.x release, the problem described in HBASE-13651 is gone. Now we will write a compaction marker to WAL before deleting the compacted files. We can only consider a RS as dead after its WAL files are all closed so if the region has already been reassigned the compaction will fail as we can not write out the compaction marker.So theoretically, if we still hit FileNotFound exception, it should be a critical bug which means we may loss data. I do not think it is a good idea to just eat the exception and refresh store files. Or even if we want to do this, we can just refresh store files without dropping memstore contents. This will also simplify the logic a lot.Suggestions are welcomed.</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCorruptedRegionStoreFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MockRegionServerServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="17794" opendate="2017-3-16 00:00:00" fixdate="2017-3-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove lingering "violation" in favor of the accurate "snapshot"</summary>
      <description>Previously, quota violations used to be stored in the quota table. Eventually, I realized that I needed to actually persist the utilization of each table/NS, not just the violation state.I know there are cases in the code where "violation" is incorrectly describing things (it should be "snapshot"). Clean these up for clarity.</description>
      <version>None</version>
      <fixedVersion>HBASE-16961,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.TableQuotaSnapshotStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaObserverChore.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.Quota.proto</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaTableUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="17803" opendate="2017-3-18 00:00:00" fixdate="2017-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>PE always re-creates table when we specify the split policy</summary>
      <description>I find this bug when i run the tests for HBASE-17623The critical code is shown below.if ((exists &amp;&amp; opts.presplitRegions != DEFAULT_OPTS.presplitRegions) || (!isReadCmd &amp;&amp; desc != null &amp;&amp; desc.getRegionSplitPolicyClassName() != opts.splitPolicy) || (!isReadCmd &amp;&amp; desc != null &amp;&amp; desc.getRegionReplication() != opts.replicas)) {</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
    </fixedFiles>
  </bug>
  <bug id="17864" opendate="2017-4-1 00:00:00" fixdate="2017-4-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement async snapshot/cloneSnapshot/restoreSnapshot methods</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="17865" opendate="2017-4-1 00:00:00" fixdate="2017-4-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement async listSnapshot/deleteSnapshot methods.</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncSnapshotAdminApi.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="17866" opendate="2017-4-1 00:00:00" fixdate="2017-4-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement async setQuota/getQuota methods.</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaTableUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaRetriever.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="17867" opendate="2017-4-1 00:00:00" fixdate="2017-5-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement async procedure RPC API(list/exec/abort/isFinished)</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="17872" opendate="2017-4-4 00:00:00" fixdate="2017-4-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The MSLABImpl generates the invaild cells when unsafe is not availble</summary>
      <description>We will get the wrong position of buffer in multithreaded environment, so the method makes the invalid cell in MSLAB. public static int copyFromBufferToBuffer(ByteBuffer in, ByteBuffer out, int sourceOffset, int destinationOffset, int length) { if (in.hasArray() &amp;&amp; out.hasArray()) { // ... } else if (UNSAFE_AVAIL) { // ... } else { int outOldPos = out.position(); out.position(destinationOffset); ByteBuffer inDup = in.duplicate(); inDup.position(sourceOffset).limit(sourceOffset + length); out.put(inDup); out.position(outOldPos); } return destinationOffset + length; }</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestByteBufferUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteBufferUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="17905" opendate="2017-4-11 00:00:00" fixdate="2017-4-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbase-spark] bulkload does not work when table not exist</summary>
      <description>when using HBase-Spark bulkload api, an argument of tablename is needed, the bulkload can run successfully only if table exist in HBase. If table not exist, the bulkload can not run successfully and it even do not report any errors or throw exception.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.HBaseContext.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.BulkLoadPartitioner.scala</file>
    </fixedFiles>
  </bug>
  <bug id="17931" opendate="2017-4-17 00:00:00" fixdate="2017-7-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Assign system tables to servers with highest version</summary>
      <description>In branch-1 and master we have some improvement and new features on scanning which is not compatible.A client of old version to a server of new version is compatible (must be a bug if not, maybe need some test?). A client of new version may not be able to read from a server of old version correctly (because of scan limit, moreResults flag, etc), which is ok for major/minor upgrade and we can tell users to upgrade server before upgrading client. But RS also use scan to read meta. If meta table is in RS of old version, all RSs of new version may have trouble while scanning meta table.So we should make sure meta table always in servers of new version. Force meta table in Master and upgrade Master first, or assign meta table in region servers with latest version?</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0-alpha-2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockNoopMasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.RegionServerTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.AssignmentManager.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.VersionInfo.java</file>
    </fixedFiles>
  </bug>
  <bug id="17956" opendate="2017-4-25 00:00:00" fixdate="2017-4-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Raw scan should ignore TTL</summary>
      <description>For now we will also test TTL to check if a cell is expired for raw scan. Since we can even return delete marker for a raw scan, I think it is also reasonable to eliminate the TTL check.</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannersFromClientSide.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="17957" opendate="2017-4-25 00:00:00" fixdate="2017-5-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Custom metrics of replicate endpoints don&amp;#39;t prepend "source." to global metrics</summary>
      <description>Custom metrics for custom replication endpoints is introduced by HBASE-16448.The name of local custom metrics follows the "source.id.metricsName" format, but the name of global custom metrics doesn't follow the "source.metricsName" format.Ex:// default metrics"source.2.shippedOps" : 1234, // peer local"source.shippedOps" : 12345, // global// custom metrics"source.1.failed.start" : 1, // peer local"failed.start" : 1, // globalWhen we consider that default metrics do so, it should be "source.metricsName" like:"source.1.failed.start" : 1,"source.failed.start" : 1,</description>
      <version>1.4.0,0.98.22,2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationEndpoint.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.replication.regionserver.MetricsReplicationGlobalSourceSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="17962" opendate="2017-4-26 00:00:00" fixdate="2017-4-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve documentation on Rest interface</summary>
      <description>The part of the documentation on the rest interface 'hides' the fact that you can retrieve the entire row in one request.It also does not clearly state that it only works for certain mime types.</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.external.apis.adoc</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.RowResource.java</file>
    </fixedFiles>
  </bug>
  <bug id="17994" opendate="2017-5-4 00:00:00" fixdate="2017-8-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add async client test to Performance Evaluation tool</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
    </fixedFiles>
  </bug>
  <bug id="18000" opendate="2017-5-5 00:00:00" fixdate="2017-5-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make sure we always return the scanner id with ScanResponse</summary>
      <description>Some external tooling (like OpenTSDB) relies on the scanner id to tie asynchronous responses back to their requests.(see comments on HBASE-17489)</description>
      <version>1.4.0,1.3.1,2.0.0</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="18049" opendate="2017-5-15 00:00:00" fixdate="2017-5-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>It is not necessary to re-open the region when MOB files cannot be found</summary>
      <description>In HBASE-17712, we try to re-open the region when store files cannot be found. This is useful for store files in a region, but is not necessary when the MOB files cannot be found, because the store files in a region only contain the references to the MOB files and a re-open of a region doesn't help the lost MOB files.In this JIRA, we will directly throw DNRIOE only when the MOB files are not found in MobStoreScanner and ReversedMobStoreScanner. Other logics keep the same.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HMobStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="18081" opendate="2017-5-19 00:00:00" fixdate="2017-5-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The way we process connection preamble in SimpleRpcServer is broken</summary>
      <description>Though very rare, but if the preamble is not sent at once, the logic will be broken.</description>
      <version>1.4.0,1.3.1,1.2.5,1.1.10,2.0.0</version>
      <fixedVersion>1.4.0,1.2.6,1.3.2,1.1.11,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleServerRpcConnection.java</file>
    </fixedFiles>
  </bug>
  <bug id="18113" opendate="2017-5-25 00:00:00" fixdate="2017-5-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Handle old client without include_stop_row flag when startRow equals endRow</summary>
      <description>Now we have include_start_row/include_stop_row flag in new version. Before it, startRow is include and stopRow is exclude, but when startRow=endRow there is a special logic that we consider it as a get and we should return the value of this row to client.In the new client, if user set start=end we will change include_stop_row to true for behavior compatibility. We should also do a special logic if old client access new server for compatibility at server.</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
    </fixedFiles>
  </bug>
  <bug id="18114" opendate="2017-5-25 00:00:00" fixdate="2017-5-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update the config of TestAsync*AdminApi to make test stable</summary>
      <description>2017-05-25 17:56:34,967 INFO [RpcServer.default.FPBQ.Fifo.handler=3,queue=0,port=50801] master.HMaster$11(2297): Client=hao//127.0.0.1 disable testModifyColumnFamily2017-05-25 17:56:37,974 INFO [RpcClient-timer-pool1-t1] client.AsyncHBaseAdmin$TableProcedureBiConsumer(2219): Operation: DISABLE, Table Name: default:testModifyColumnFamily failed with Failed after attempts=3, exceptions: Thu May 25 17:56:35 CST 2017, , java.io.IOException: Call to localhost/127.0.0.1:50801 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call id=294, waitTime=1008, rpcTimeout=1000Thu May 25 17:56:37 CST 2017, , java.io.IOException: Call to localhost/127.0.0.1:50801 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call id=295, waitTime=1299, rpcTimeout=1000Thu May 25 17:56:37 CST 2017, , java.io.IOException: Call to localhost/127.0.0.1:50801 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call id=296, waitTime=668, rpcTimeout=660017-05-25 17:56:38,936 DEBUG [RpcServer.default.FPBQ.Fifo.handler=3,queue=0,port=50801] procedure2.ProcedureExecutor(788): Stored procId=15, owner=hao, state=RUNNABLE:DISABLE_TABLE_PREPARE, DisableTableProcedure table=testModifyColumnFamilyFor this disable table procedure, master return the procedure id when it submit the procedure to ProcedureExecutor. And the above procedure take 4 seconds to submit. So the disable table call failed because the rpc timeout is 1 seconds and the retry number is 3.For admin operation, I thought we don't need change the default timeout config in unit test. And the retry is not need, too. (Or we can set a retry &gt; 1 to test nonce thing). Meanwhile, the default timeout is 60 seconds. So the test type may need change to LargeTests.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTableAdminApi.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncSnapshotAdminApi.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncReplicationAdminApi.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncRegionAdminApi.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncProcedureAdminApi.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncNamespaceAdminApi.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncAdminBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="18122" opendate="2017-5-26 00:00:00" fixdate="2017-5-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scanner id should include ServerName of region server</summary>
      <description>Now the scanner id is a long number from 1 to max in a region server. Each new scanner will have a scanner id.If a client has a scanner whose id is x, when the RS restart and the scanner id is also incremented to x or a little larger, there will be a scanner id collision.So the scanner id should now be same during each time the RS restart. We can add the start timestamp as the highest several bits in scanner id uint64.And because HBASE-18121 is not easy to fix and there are many clients with old version. We can also encode server host:port into the scanner id.So we can use ServerName.</description>
      <version>1.4.0,1.3.1,1.1.10,1.2.6,2.0.0</version>
      <fixedVersion>1.4.0,1.3.2,1.1.11,2.0.0,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRpcRetryingCallerFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="18132" opendate="2017-5-30 00:00:00" fixdate="2017-6-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Low replication should be checked in period in case of datanode rolling upgrade</summary>
      <description>For now, we just check low replication of WALs when there is a sync operation (HBASE-2234), rolling the log if the replica of the WAL is less than configured. But if the WAL has very little writes or no writes at all, low replication will not be detected and thus no log will be rolled. That is a problem when rolling updating datanode, all replica of the WAL with no writes will be restarted and lead to the WAL file end up with a abnormal state. Later operation of opening this file will be always failed.I bring up a patch to check low replication of WALs at a configured period. When rolling updating datanodes, we just make sure the restart interval time between two nodes is bigger than the low replication check time, the WAL will be closed and rolled normally. A UT in the patch will show everything.</description>
      <version>1.4.0,1.1.10</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.LogRoller.java</file>
    </fixedFiles>
  </bug>
  <bug id="18133" opendate="2017-5-30 00:00:00" fixdate="2017-2-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Low-latency space quota size reports</summary>
      <description>Presently space quota enforcement relies on RegionServers sending reports to the master about each Region that they host. This is done by periodically, reading the cached size of each HFile in each Region (which was ultimately computed from HDFS).This means that the Master is unaware of Region size growth until the the next time this chore in a RegionServer fires which is a fair amount of latency (a few minutes, by default). Operations like flushes, compactions, and bulk-loads are delayed even though the RegionServer is running those operations locally.Instead, we can create an API which these operations could invoke that would automatically update the size of the Region being operated on. For example, a successful flush can report that the size of a Region increased by the size of the flush. A compaction can subtract the size of the input files of the compaction and add in the size of the resulting file.This de-couples the computation of a Region's size from sending the Region sizes to the Master, allowing us to send reports more frequently, increasing the responsiveness of the cluster to size changes.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerRegionSpaceUseReport.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestSpaceQuotas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestQuotaObserverChoreRegionReports.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestFileSystemUtilizationChore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.SpaceQuotaHelperForTests.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.policies.TestBulkLoadCheckingViolationPolicyEnforcement.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MockRegionServerServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.SpaceViolationPolicyEnforcement.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.RegionServerSpaceQuotaManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.policies.MissingSnapshotViolationPolicyEnforcement.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.policies.DefaultViolationPolicyEnforcement.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.policies.AbstractViolationPolicyEnforcement.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.FileSystemUtilizationChore.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerQuotaSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="18164" opendate="2017-6-5 00:00:00" fixdate="2017-6-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Much faster locality cost function and candidate generator</summary>
      <description>We noticed that during the stochastic load balancer was not scaling well with cluster size. That is to say that on our smaller clusters (~17 tables, ~12 region servers, ~5k regions), the balancer considers ~100,000 cluster configurations in 60s per balancer run, but only ~5,000 per 60s on our bigger clusters (~82 tables, ~160 region servers, ~13k regions) .Because of this, our bigger clusters are not able to converge on balance as quickly for things like table skew, region load, etc. because the balancer does not have enough time to "think".We have re-written the locality cost function to be incremental, meaning it only recomputes cost based on the most recent region move proposed by the balancer, rather than recomputing the cost across all regions/servers every iteration.Further, we also cache the locality of every region on every server at the beginning of the balancer's execution for both the LocalityBasedCostFunction and the LocalityCandidateGenerator to reference. This way, they need not collect all HDFS blocks of every region at each iteration of the balancer.The changes have been running in all 6 of our production clusters and all 4 QA clusters without issue. The speed improvements we noticed are massive. Our big clusters now consider 20x more cluster configurations.One design decision I made is to consider locality cost as the difference between the best locality that is possible given the current cluster state, and the currently measured locality. The old locality computation would measure the locality cost as the difference from the current locality and 100% locality, but this new computation instead takes the difference between the current locality for a given region and the best locality for that region in the cluster.</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0-alpha-2,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestStochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.BalancerTestBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.java</file>
    </fixedFiles>
  </bug>
  <bug id="18181" opendate="2017-6-7 00:00:00" fixdate="2017-6-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move master branch to version 3.0.0-SNAPSHOT post creation of branch-2</summary>
      <description>busbey caught me pushing stuff last night w/o an associated issue (update to doc around our 'official' color and font) so he probably has his eye out these times....I just branched hbase2.i need to move master version on from 2.0.0-SNAPSHOT. Thats what this issue is for.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-thrift.pom.xml</file>
      <file type="M">hbase-testing-util.pom.xml</file>
      <file type="M">hbase-spark.pom.xml</file>
      <file type="M">hbase-shell.pom.xml</file>
      <file type="M">hbase-shaded.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-server.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-client.pom.xml</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-rsgroup.pom.xml</file>
      <file type="M">hbase-rest.pom.xml</file>
      <file type="M">hbase-resource-bundle.pom.xml</file>
      <file type="M">hbase-protocol.pom.xml</file>
      <file type="M">hbase-protocol-shaded.pom.xml</file>
      <file type="M">hbase-procedure.pom.xml</file>
      <file type="M">hbase-prefix-tree.pom.xml</file>
      <file type="M">hbase-metrics.pom.xml</file>
      <file type="M">hbase-metrics-api.pom.xml</file>
      <file type="M">hbase-it.pom.xml</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-hadoop-compat.pom.xml</file>
      <file type="M">hbase-external-blockcache.pom.xml</file>
      <file type="M">hbase-examples.pom.xml</file>
      <file type="M">hbase-endpoint.pom.xml</file>
      <file type="M">hbase-common.pom.xml</file>
      <file type="M">hbase-client.pom.xml</file>
      <file type="M">hbase-checkstyle.pom.xml</file>
      <file type="M">hbase-assembly.pom.xml</file>
      <file type="M">hbase-archetypes.pom.xml</file>
      <file type="M">hbase-archetypes.hbase-shaded-client-project.pom.xml</file>
      <file type="M">hbase-archetypes.hbase-client-project.pom.xml</file>
      <file type="M">hbase-archetypes.hbase-archetype-builder.pom.xml</file>
      <file type="M">hbase-annotations.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1820" opendate="2009-9-9 00:00:00" fixdate="2009-9-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update jruby from 1.2 to 1.3.1</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">lib.jruby-complete-1.2.0.jar</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1822" opendate="2009-9-10 00:00:00" fixdate="2009-9-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove the deprecated APIs</summary>
      <description>Remove all the deprecated stuff in client and mapred.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.mapreduce.Driver.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.util.TestMigration.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.util.TestMergeTool.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.util.SoftSortedMapTest.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TimestampTestBase.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.thrift.TestThriftServer.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestZooKeeper.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestTable.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestSerialization.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestRegionRebalancing.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestMasterAdmin.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestKeyValue.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestHStoreKey.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestCompare.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestClassMigration.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestStoreFile.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestScanWildcardColumnTracker.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestScanner.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestMemStore.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestLruHashMap.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestKeyValueHeap.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestHLog.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.OOMERegionServer.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.DisabledTestRegionServerExit.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.MultiRegionTable.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.MiniZooKeeperCluster.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.master.OOMEHMaster.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.mapred.TestTableMapReduce.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.mapred.TestTableIndex.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.mapreduce.TestTimeRangeMapRed.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.mapreduce.TestTableMapReduce.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.mapreduce.TestTableIndex.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.io.TestHeapSize.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.io.TestHbaseObjectWritable.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.HBaseTestCase.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.client.TestOldAPITimestamp.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.client.TestOldAPIHTable.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.client.TestOldAPIGetRowVersions.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.client.TestHTable.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.client.TestHBaseAdmin.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.client.TestForceSplit.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.client.TestClient.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.client.TestBatchUpdate.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.AbstractMergeTestBase.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.Writables.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.SoftSortedMap.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.Migrate.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.ThriftUtilities.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.TimestampModel.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.TimestampController.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.TableModel.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.TableController.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.Status.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.serializer.SimpleXMLSerializer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.serializer.RestSerializerFactory.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.serializer.JSONSerializer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.serializer.ISerializable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.serializer.IRestSerializer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.serializer.AbstractRestSerializer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.ScannerModel.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.ScannerController.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.RowModel.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.RowController.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.RESTConstants.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.parser.XMLRestParser.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.parser.JsonRestParser.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.parser.IHBaseRestParser.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.parser.HBaseRestParserFactory.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.package.html</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.filter.WhileMatchRowFilterFactory.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.filter.StopRowFilterFactory.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.filter.RowFilterSetFactory.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.filter.RegExpRowFilterFactory.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.filter.PageRowFilterFactory.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.filter.InclusiveStopRowFilterFactory.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.filter.FilterFactoryConstants.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.filter.FilterFactory.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.filter.ColumnValueFilterFactory.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.exception.HBaseRestException.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.Dispatcher.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.descriptors.TimestampsDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.descriptors.ScannerIdentifier.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.descriptors.ScannerDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.descriptors.RowUpdateDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.descriptors.RestCell.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.DatabaseModel.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.DatabaseController.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.AbstractModel.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.rest.AbstractController.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.ScanQueryMatcher.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.MemStore.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.package-info.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.regionserver.HStoreFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.onelab.filter.RetouchedBloomFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.onelab.filter.RemoveScheme.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.onelab.filter.Key.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.onelab.filter.HashFunction.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.onelab.filter.Filter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.onelab.filter.DynamicBloomFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.onelab.filter.CountingBloomFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.onelab.filter.BloomFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.io.Reference.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.io.HBaseMapFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.io.HalfMapFileReader.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.io.BloomFilterMapFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.HStoreKey.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.migration.nineteen.HStoreFileToStoreFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.RegionManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ProcessServerShutdown.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ProcessRegionStatusChange.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ModifyTableMeta.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.MetaRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ChangeTableState.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableSplit.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableReduce.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableOutputFormat.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableMapReduceUtil.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableMap.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableInputFormatBase.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableInputFormat.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.RowCounter.Counters.properties</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.RowCounter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.package-info.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.LuceneDocumentWrapper.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.IndexTableReduce.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.IndexOutputFormat.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.IndexConfiguration.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.IdentityTableReduce.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.IdentityTableMap.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.HRegionPartitioner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.GroupingTableMap.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.Driver.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.BuildTableIndex.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapreduce.RowCounter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapreduce.IndexTableReducer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapreduce.GroupingTableMapper.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.contrib.stargate.src.java.org.apache.hadoop.hbase.stargate.model.CellModel.java</file>
      <file type="M">src.contrib.stargate.src.java.org.apache.hadoop.hbase.stargate.RESTServlet.java</file>
      <file type="M">src.contrib.stargate.src.java.org.apache.hadoop.hbase.stargate.RowResource.java</file>
      <file type="M">src.contrib.stargate.src.java.org.apache.hadoop.hbase.stargate.RowResultGenerator.java</file>
      <file type="M">src.contrib.stargate.src.java.org.apache.hadoop.hbase.stargate.ScannerInstanceResource.java</file>
      <file type="M">src.contrib.stargate.src.java.org.apache.hadoop.hbase.stargate.ScannerResultGenerator.java</file>
      <file type="M">src.contrib.stargate.src.test.org.apache.hadoop.hbase.stargate.TestRowResource.java</file>
      <file type="M">src.contrib.stargate.src.test.org.apache.hadoop.hbase.stargate.TestScannerResource.java</file>
      <file type="M">src.contrib.stargate.src.test.org.apache.hadoop.hbase.stargate.TestTableResource.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.client.tableindexed.IndexedTable.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.client.tableindexed.IndexedTableAdmin.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.client.transactional.HBaseBackedTransactionLogger.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.client.transactional.TransactionalTable.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.regionserver.tableindexed.IndexedRegion.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.regionserver.tableindexed.IndexMaintenanceUtils.java</file>
      <file type="M">src.contrib.transactional.src.test.org.apache.hadoop.hbase.client.tableindexed.TestIndexedTable.java</file>
      <file type="M">src.contrib.transactional.src.test.org.apache.hadoop.hbase.client.transactional.StressTestTransactions.java</file>
      <file type="M">src.contrib.transactional.src.test.org.apache.hadoop.hbase.client.transactional.TestTransactions.java</file>
      <file type="M">src.contrib.transactional.src.test.org.apache.hadoop.hbase.regionserver.transactional.TestTHLogRecovery.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.Delete.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.Get.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.Put.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.Result.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.Scanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ClusterStatus.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.ColumnValueFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.InclusiveStopRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.PageRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.PrefixRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.RegExpRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.RowFilterInterface.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.RowFilterSet.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.StopRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.ValueFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.WhileMatchRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HStoreKey.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.BatchOperation.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.BatchUpdate.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.Cell.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.CodeToClassAndBack.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.HbaseObjectWritable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.RowResult.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HBaseServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapreduce.BuildTableIndex.java</file>
    </fixedFiles>
  </bug>
  <bug id="18362" opendate="2017-7-11 00:00:00" fixdate="2017-7-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbck should not report split replica parent region from meta as errors</summary>
      <description>As described in HBASE-18247, replica region shows up as key in meta table. We need to find out the code/logic introducing the issue. I suspected that it was introduced by hbck, but last round of code review did not find anything. Create jira to track this effort.Before Catalog Janitor cleans up the split parent region from meta, hbck is reporting split replica parent regions as errors and if -fixSplitParents is used, the replica parent region will show up as key in meta table. It needs to be avoided.t1,,1500931628959.e10212c467b78104c911ea06c102ece0 column=info:regioninfo, timestamp=1500931787651, value={ENCODED =&gt; e10212c467b78104c911ea06c102ece0, NAME =&gt; 't1,,1500931628959.e10212c467b78104c911ea . 06c102ece0.', STARTKEY =&gt; '', ENDKEY =&gt; '', OFFLINE =&gt; true, SPLIT =&gt; true} t1,,1500931628959.e10212c467b78104c911ea06c102ece0 column=info:seqnumDuringOpen, timestamp=1500931742552, value=\x00\x00\x00\x00\x00\x00\x00\x05 . t1,,1500931628959.e10212c467b78104c911ea06c102ece0 column=info:seqnumDuringOpen_0001, timestamp=1500931742492, value=\x00\x00\x00\x00\x00\x00\x00\x02 . t1,,1500931628959.e10212c467b78104c911ea06c102ece0 column=info:server, timestamp=1500931742552, value=dhcp-172-16-1-203.pa.cloudera.com:61099 . t1,,1500931628959.e10212c467b78104c911ea06c102ece0 column=info:server_0001, timestamp=1500931742492, value=dhcp-172-16-1-203.pa.cloudera.com:61099 . t1,,1500931628959.e10212c467b78104c911ea06c102ece0 column=info:serverstartcode, timestamp=1500931742552, value=1500931737158 . t1,,1500931628959.e10212c467b78104c911ea06c102ece0 column=info:serverstartcode_0001, timestamp=1500931742492, value=\x00\x00\x01]v\x80\xC6F . t1,,1500931628959.e10212c467b78104c911ea06c102ece0 column=info:splitA, timestamp=1500931787651, value={ENCODED =&gt; dc471b6d9c0c2c451ee4c6d134e50ccc, NAME =&gt; 't1,,1500931787511.dc471b6d9c0c2c451ee4c6d134 . e50ccc.', STARTKEY =&gt; '', ENDKEY =&gt; 'r'} t1,,1500931628959.e10212c467b78104c911ea06c102ece0 column=info:splitB, timestamp=1500931787651, value={ENCODED =&gt; d86fbd197ca1073e763cb811705587ec, NAME =&gt; 't1,r,1500931787511.d86fbd197ca1073e763cb8117 . 05587ec.', STARTKEY =&gt; 'r', ENDKEY =&gt; ''} t1,,1500931787511.dc471b6d9c0c2c451ee4c6d134e50ccc column=info:regioninfo, timestamp=1500931787651, value={ENCODED =&gt; dc471b6d9c0c2c451ee4c6d134e50ccc, NAME =&gt; 't1,,1500931787511.dc471b6d9c0c2c451ee4c6 . d134e50ccc.', STARTKEY =&gt; '', ENDKEY =&gt; 'r'}</description>
      <version>1.4.0,2.0.0-alpha-1</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsckReplicas.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug id="18364" opendate="2017-7-11 00:00:00" fixdate="2017-7-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Downgrade surefire</summary>
      <description>Seems like 2.20 broke package-wildcard for test specification. Pull this back to something that works.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="18365" opendate="2017-7-11 00:00:00" fixdate="2017-7-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Eliminate the findbugs warnings for hbase-common</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0-alpha-2,2.0.0,1.2.7</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.OrderedBytes.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.DynamicClassLoader.java</file>
    </fixedFiles>
  </bug>
  <bug id="18592" opendate="2017-8-14 00:00:00" fixdate="2017-8-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbase-thirdparty] Doc on new hbase-thirdparty dependency for the refguide</summary>
      <description>Add a bit to the refguide on the new hbase-thirdparty lib and why it exists.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="18599" opendate="2017-8-15 00:00:00" fixdate="2017-8-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add missing @Deprecated annotations</summary>
      <description>There are a couple of places where deprecations have only been added in the Javadoc but the annotation is missing.I'll also change the Javadoc to be consistent with what I've done in HBASE-13462.This is for master/2.0.0 only.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionObserver.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.metrics.ServerSideScanMetrics.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
    </fixedFiles>
  </bug>
  <bug id="18609" opendate="2017-8-16 00:00:00" fixdate="2017-9-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Apply ClusterStatus#getClusterStatus(EnumSet&lt;Option&gt;) in code base</summary>
      <description>HBASE-15511 enable us to get the cluster status by scope, and after refactoring in HBASE-18621. We should apply it in code base so as to prevent the useless information.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestMiniClusterLoadSequential.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsckReplicas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.BaseTestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestRegionLoad.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationStatus.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestMasterReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerReadRequestMetrics.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterOperationsForRegionReplicas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestFavoredStochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestFavoredStochasticBalancerPickers.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMetaWithReplicas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncClusterAdminApi.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionMover.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsckRepair.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.Canary.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionPlacementMaintainer.java</file>
      <file type="M">hbase-rsgroup.src.test.java.org.apache.hadoop.hbase.rsgroup.TestRSGroupsBase.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.StorageClusterVersionResource.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.StorageClusterStatusResource.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.mapreduce.IntegrationTestBulkLoad.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.MoveRegionsOfTableAction.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="18626" opendate="2017-8-18 00:00:00" fixdate="2017-3-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Handle the incompatible change about the replication TableCFs&amp;#39; config</summary>
      <description>About compatibility, there is one incompatible change about the replication TableCFs' config. The old config is a string and it concatenate the list of tables and column families in format "table1:cf1,cf2;table2:cfA,cfB" in zookeeper for table-cf to replication peer mapping. When parse the config, it use ":" to split the string. If table name includes namespace, it will be wrong (See HBASE-11386). It is a problem since we support namespace (0.98). So HBASE-11393 (and HBASE-16653) changed it to a PB object. When rolling update cluster, you need rolling master first. And the master will try to translate the string config to a PB object. But there are two problems.1. Permission problem. The replication client can write the zookeeper directly. So the znode may have different owner. And master may don't have the write permission for the znode. It maybe failed to translate old table-cfs string to new PB Object. See HBASE-169382. We usually keep compatibility between old client and new server. But the old replication client may write a string config to znode directly. Then the new server can't parse them.</description>
      <version>3.0.0-alpha-1,1.4.0,1.5.0,2.0.0-alpha-3</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="18630" opendate="2017-8-18 00:00:00" fixdate="2017-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Prune dependencies; as is branch-2 has duplicates</summary>
      <description>Purge duplicate includes and try to prune back our dependencies (Suggestion by elserj up on the 2.0.0-alpha2 vote). Just looking at my current issue, we have vestiges we include even though the root justification has passed.</description>
      <version>None</version>
      <fixedVersion>2.0.0-alpha-3,2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="18631" opendate="2017-8-18 00:00:00" fixdate="2017-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow configuration of ChaosMonkey properties via hbase-site</summary>
      <description>I noticed in some internal test automation that the code was attempting to configure some of the chaos-monkey actions via hbase-site.xml, but these weren't taking effect.After reading the code, I found that these can only be specified via a special properties file otherwise specified. It would be nice to also allow configuration via hbase-site.</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.2,1.1.13,2.0.0,1.2.7</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestBase.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.factories.MonkeyConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="18635" opendate="2017-8-19 00:00:00" fixdate="2017-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix asciidoc warnings</summary>
      <description>When building docs, I noticed:Failed to parse formatted text: To supply filters to the Scanner object or configure the Scanner in any other way, you can create a text file and add your filter to the file. For example, to return only rows for which keys start with &amp;lt;codeph&amp;gt;u123&amp;lt;/codeph&amp;gt; and use a batch size of 100, the filter file would look like this: &lt;pre&gt; &amp;lt;Scanner batch="100"&amp;gt; &amp;lt;filter&amp;gt; { "type": "PrefixFilter", "value": "u123" } &amp;lt;/filter&amp;gt; &amp;lt;/Scanner&amp;gt; &lt;/pre&gt;Working hypthesis is that we should either be using proper codeblocks rather than pre tags. Otherwise we may need to do something to escape curly braces. Asciidoctor is probably trying to interpret them as Liquid tags.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.schema.design.adoc</file>
      <file type="M">src.main.asciidoc..chapters.external.apis.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="18667" opendate="2017-8-23 00:00:00" fixdate="2017-10-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Disable error-prone for hbase-protocol-shaded</summary>
      <description>This is all generated code that we shouldn't be running extra analysis on because it adds a lot of noise to the build, and also takes a very long time (15 minutes on my machine). Let's make it fast and simple.Even when we run with error-prone enabled for the rest of the build, it should not apply here.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-protocol.pom.xml</file>
      <file type="M">hbase-protocol-shaded.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="18671" opendate="2017-8-24 00:00:00" fixdate="2017-8-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support Append/Increment in rest api</summary>
      <description>Recently we need to call append interface through the rest api, but rest api has not yet implemented it.We implemented it and it is stable in the production environment.</description>
      <version>3.0.0-alpha-1,1.4.0,2.0.0-alpha-2</version>
      <fixedVersion>1.4.0,2.0.0-alpha-3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.TestGetAndPutResource.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.RowResourceBase.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.TableResource.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.RowResource.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.MetricsREST.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.rest.MetricsRESTSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.rest.MetricsRESTSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="18718" opendate="2017-8-30 00:00:00" fixdate="2017-9-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document the coprocessor.Export</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="18740" opendate="2017-9-1 00:00:00" fixdate="2017-9-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade Zookeeper version to 3.4.10</summary>
      <description>Branch 1.4 and branch 1 are still on Zookeeper 3.4.6.Branch 2 and master branch have upgraded to 3.4.9.There are some important fixes we'd like to have. See the linked JIRAs.Another critical fix is ZOOKEEPER-2146, which can be explored maliciously.</description>
      <version>1.4.0,1.5.0</version>
      <fixedVersion>1.4.0,2.0.0-alpha-3,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="18784" opendate="2017-9-8 00:00:00" fixdate="2017-4-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use of filesystem that requires hflush / hsync / append / etc should query outputstream capabilities</summary>
      <description>In places where we rely on the underlying filesystem holding up the promises of hflush/hsync (most importantly the WAL), we should use the new interfaces provided by HDFS-11644 to fail loudly when they are not present (e.g. on S3, on EC mounts, etc).</description>
      <version>1.4.0,2.0.0-alpha-2</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.IOTestProvider.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestFSUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.AbstractTestWALReplay.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.AbstractTestFSWAL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestWALProcedureStoreOnHDFS.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMasterProcedureWalLease.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.assignment.MockMasterServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.asyncfs.TestLocalAsyncOutput.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.FSHLogProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.AsyncFSWALProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AsyncProtobufLogWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AbstractProtobufLogWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureConstants.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.asyncfs.AsyncFSOutputHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.fs.HFileSystem.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.TestYieldProcedures.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.TestStateMachineProcedure.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.TestProcedureReplayOrder.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.TestProcedureRecovery.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.TestProcedureNonce.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.TestProcedureMetrics.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.TestProcedureExecution.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.TestProcedureEvents.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.TestChildProcedures.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.wal.TestWALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.wal.TestStressWALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALPerformanceEvaluation.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALLoaderPerformanceEvaluation.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.ProcedureTestingUtility.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="18786" opendate="2017-9-9 00:00:00" fixdate="2017-9-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>FileNotFoundException should not be silently handled for primary region replicas</summary>
      <description>This is a follow up for HBASE-18186.FileNotFoundException while scanning from a primary region replica can be indicative of a more severe problem. Handling them silently can cause many underlying issues go undetected. We should either1. Hard fail the regionserver if there is a FNFE on a primary region replica, OR2. Report these exceptions as some region / server level metric so that these can be proactively investigated.</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.3,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionUnassigner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCorruptedRegionStoreFile.java</file>
    </fixedFiles>
  </bug>
  <bug id="19097" opendate="2017-10-26 00:00:00" fixdate="2017-11-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>update testing to use Apache Yetus Test Patch version 0.6.0</summary>
      <description>once Yetus does their 0.6.0 release, we should update our nightly and precommit tests to use it. They've added diagnostic info about maven version in use that would help troubleshoot some of our failures.Also the 0.5.0 release removed the maven eclipse plugin tests, since that plugin is EOL.</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0-beta-1,1.1.13,2.0.0,1.2.7</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  <bug id="19098" opendate="2017-10-26 00:00:00" fixdate="2017-10-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Python based compatiblity checker fails if git repo does not have a remote named &amp;#39;origin&amp;#39;</summary>
      <description>The new Python based compatibility checker will fail if the local git repo does not have a remote named "origin". I develop with multiple upstream repos and rename them according to a custom convention. If the requirement that an upstream named "origin" must be present could be removed, that would be good, or otherwise this should be documented next to the example usage in the python source.</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0-alpha-4,2.0.0,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.checkcompatibility.py</file>
    </fixedFiles>
  </bug>
  <bug id="19227" opendate="2017-11-9 00:00:00" fixdate="2017-11-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Nightly jobs should archive JVM dumpstream files</summary>
      <description>came up on dev@ discussion about some of our current nightly test failures. when surefire fails to launch a test JVM instance, the details go into a file that we currently don't archive:&amp;#91;ERROR&amp;#93; Please refer to dump files (if any exist) &amp;#91;date&amp;#93;-jvmRun&amp;#91;N&amp;#93;.dump, &amp;#91;date&amp;#93;.dumpstream and &amp;#91;date&amp;#93;-jvmRun&amp;#91;N&amp;#93;.dumpstream.Add them to the default archive pattern.</description>
      <version>None</version>
      <fixedVersion>1.0.4,1.1.13,2.0.0,1.2.7</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  <bug id="19228" opendate="2017-11-9 00:00:00" fixdate="2017-11-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>nightly job should gather machine stats.</summary>
      <description>leverage the script added in HBASE-19189 to get machine stats when running nightly</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0-beta-1,1.1.13,2.0.0,1.2.7</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
      <file type="M">dev-support.gather.machine.environment.sh</file>
    </fixedFiles>
  </bug>
  <bug id="19229" opendate="2017-11-9 00:00:00" fixdate="2017-11-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Nightly script to check source artifact should not do a destructive git operation without opt-in</summary>
      <description>right now we have a "git please destroy all this stuff" command in the check of the source artifact. we shouldn't do this unless the person invoking the script has indicated that's okay (e..g through a cli flag).</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0-beta-1,1.1.13,2.0.0,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
      <file type="M">dev-support.hbase.nightly.source-artifact.sh</file>
    </fixedFiles>
  </bug>
  <bug id="19406" opendate="2017-12-1 00:00:00" fixdate="2017-12-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix CompactionRequest equals and hashCode</summary>
      <description>This is fallout from an attempt to fix an error prone or findbugs warning. &amp;#91;ERROR&amp;#93; loadTest&amp;#91;0&amp;#93;(org.apache.hadoop.hbase.io.encoding.TestLoadAndSwitchEncodeOnDisk) Time elapsed: 19.632 s &lt;&lt;&lt; ERROR!java.io.IOException: java.io.IOException at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2410) at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:124) at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:297) at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:277)Caused by: java.lang.StackOverflowError at java.util.Objects.equals(Objects.java:59) at org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.equals(CompactionRequest.java:150) at java.util.Objects.equals(Objects.java:59) at org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.equals(CompactionRequest.java:150) at java.util.Objects.equals(Objects.java:59) at org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.equals(CompactionRequest.java:150) (Repeats until the stack blows up)</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0,2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionRequestImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="19417" opendate="2017-12-4 00:00:00" fixdate="2017-12-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove boolean return value from postBulkLoadHFile hook</summary>
      <description>See the discussion at the tail of HBASE-17123 where Appy pointed out that the override of loaded should be placed inside else block: } else { // secure bulk load map = regionServer.secureBulkLoadManager.secureBulkLoadHFiles(region, request); } BulkLoadHFileResponse.Builder builder = BulkLoadHFileResponse.newBuilder(); if (map != null) { loaded = true; }This issue is to address the review comment.After several review iterations, here are the changes: Return value of boolean for postBulkLoadHFile() hook are changed to void. Coprocessor hooks (pre and post) are added for the scenario where bulk load manager is used.</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.SimpleRegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SecureBulkLoadManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionObserver.java</file>
      <file type="M">hbase-backup.src.main.java.org.apache.hadoop.hbase.backup.BackupObserver.java</file>
    </fixedFiles>
  </bug>
  <bug id="19422" opendate="2017-12-4 00:00:00" fixdate="2017-12-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>using hadoop-profile property leads to confusing failures</summary>
      <description>When building master branch against hadoop 3 beta1,mvn clean install -Dhadoop-profile=3.0 -Dhadoop-three.version=3.0.0-beta1 -Dhadoop-two.version=3.0.0-beta1 -DskipTestsI got:[WARNING] Rule 0: org.apache.maven.plugins.enforcer.BannedDependencies failed with message:We don't allow the JSR305 jar from the Findbugs project, see HBASE-16321.Found Banned Dependency: com.google.code.findbugs:jsr305:jar:1.3.9Here is part of the dependency tree showing the dependency:[INFO] org.apache.hbase:hbase-client:jar:3.0.0-SNAPSHOT...[INFO] +- org.apache.hadoop:hadoop-auth:jar:3.0.0-beta1:compile...[INFO] | \- com.google.guava:guava:jar:11.0.2:compile[INFO] | \- com.google.code.findbugs:jsr305:jar:1.3.9:compileWe need to exclude jsr305 so that build succeed.</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0-beta-1,2.0.0,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1943" opendate="2009-10-29 00:00:00" fixdate="2009-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove AgileJSON; unused.</summary>
      <description>Remove unused jar and its TOJSON annotations. We can use jackson instead; thats what apurtell has in stargate its what avro is using.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">lib.AgileJSON-2009-03-30.jar</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="19471" opendate="2017-12-9 00:00:00" fixdate="2017-1-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix remaining Checkstyle errors in hbase-thrift</summary>
      <description>Some Checkstyle errors are left in the hbase-thrift module and should be fixed.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift.TestThriftServerCmdLine.java</file>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift.TestThriftServer.java</file>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift.TestThriftHttpServer.java</file>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift.TestCallQueue.java</file>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift2.TestThriftHBaseServiceHandlerWithLabels.java</file>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift2.TestThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftUtilities.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftMetrics.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.TBoundedThreadPoolServer.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.IncrementCoalescer.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.HbaseHandlerMetricsProxy.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftUtilities.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
      <file type="M">hbase-thrift.pom.xml</file>
      <file type="M">hbase-checkstyle.src.main.resources.hbase.checkstyle-suppressions.xml</file>
    </fixedFiles>
  </bug>
  <bug id="19491" opendate="2017-12-12 00:00:00" fixdate="2017-12-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Exclude flaky tests from nightly master run</summary>
      <description>Testing infra improvements Exclude flaky tests from nightly master run (Old nightly master run used to exclude flaky tests, but new nightly one which is based on Jenkins stages wasn't using it. Adding it to new nightly job) Fixes findbugs check (seems like wasn't working earlier : "0 findbugs 0m 0s Findbugs executables are not available.")</description>
      <version>None</version>
      <fixedVersion>1.3.2,1.4.1,2.0.0-beta-1,2.0.0,1.2.7</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
      <file type="M">dev-support.hbase.nightly.yetus.sh</file>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  <bug id="19494" opendate="2017-12-12 00:00:00" fixdate="2017-12-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create simple WALKey filter that can be plugged in on the Replication Sink</summary>
      <description>hbase-indexer used to look at WALKeys on the sink to see if their time of creation was before the time at which the replication stream was enabled.In the parent redo, there is no means for doing this anymore (because WALKey used to be Private and because to get at the WALKey in the Sink, you had to override all of the Replication which meant importing a million Private objects...).This issue is about adding a simple filter to Replication on the sink-side that just takes a WALKey (now InterfaceAudience LimitedPrivate and recently made read-only).Assigned myself. Need to do this so hbase-indexer can move to hbase2.</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.WALEntryFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSink.java</file>
    </fixedFiles>
  </bug>
  <bug id="19545" opendate="2017-12-18 00:00:00" fixdate="2017-12-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace getBytes(StandardCharsets.UTF_8) with Bytes.toBytes</summary>
      <description>On HBASE-19498 stack mentioned that Bytes.toBytes by default uses UTF_8 encoding so getBytes(StandardCharsets.UTF_8) can be simplified.</description>
      <version>1.4.0,2.0.0-beta-1</version>
      <fixedVersion>1.4.1,2.0.0-beta-2,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.client.example.HttpProxyExample.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestOrderedBytes.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestLoadTestKVGenerator.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.types.TestStruct.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestTableName.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestCellUtil.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.io.crypto.TestKeyStoreKeyProvider.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Base64.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.TestHColumnDescriptor.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.security.TestHBaseSaslRpcClient.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestSimpleRequestController.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestOperation.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestDelayingRunner.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestClientScanner.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestAsyncProcess.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.SaslUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug id="19588" opendate="2017-12-21 00:00:00" fixdate="2017-1-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Additional jar dependencies needed for mapreduce PerformanceEvaluation</summary>
      <description>I have a unit test that runs a simple PerformanceEvaluation test to make sure things are basically workingbin/hbase org.apache.hadoop.hbase.PerformanceEvaluation --rows=50000 sequentialWrite 1This test runs against Hadoop 2.7.0 and works against all past versions 0.99.0 and up. It broke with 1.4.0 with the following error.2017-12-21 13:49:40,974 INFO [main] mapreduce.Job: Task Id : attempt_1513892752187_0002_m_000004_2, Status : FAILEDError: java.io.IOException: java.lang.reflect.InvocationTargetException at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:240) at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:218) at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:119) at org.apache.hadoop.hbase.PerformanceEvaluation$EvaluationMapTask.map(PerformanceEvaluation.java:297) at org.apache.hadoop.hbase.PerformanceEvaluation$EvaluationMapTask.map(PerformanceEvaluation.java:250) at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787) at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341) at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657) at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)Caused by: java.lang.reflect.InvocationTargetException at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:526) at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:238) ... 12 moreCaused by: java.lang.RuntimeException: Could not create interface org.apache.hadoop.hbase.zookeeper.MetricsZooKeeperSource Is the hadoop compatibility jar on the classpath? at org.apache.hadoop.hbase.CompatibilitySingletonFactory.getInstance(CompatibilitySingletonFactory.java:75) at org.apache.hadoop.hbase.zookeeper.MetricsZooKeeper.&lt;init&gt;(MetricsZooKeeper.java:38) at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.&lt;init&gt;(RecoverableZooKeeper.java:130) at org.apache.hadoop.hbase.zookeeper.ZKUtil.connect(ZKUtil.java:143) at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.&lt;init&gt;(ZooKeeperWatcher.java:181) at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.&lt;init&gt;(ZooKeeperWatcher.java:155) at org.apache.hadoop.hbase.client.ZooKeeperKeepAliveConnection.&lt;init&gt;(ZooKeeperKeepAliveConnection.java:43) at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.getKeepAliveZooKeeperWatcher(ConnectionManager.java:1737) at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:104) at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.retrieveClusterId(ConnectionManager.java:945) at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.&lt;init&gt;(ConnectionManager.java:721) ... 17 moreCaused by: java.util.ServiceConfigurationError: org.apache.hadoop.hbase.zookeeper.MetricsZooKeeperSource: Provider org.apache.hadoop.hbase.zookeeper.MetricsZooKeeperSourceImpl could not be instantiated at java.util.ServiceLoader.fail(ServiceLoader.java:224) at java.util.ServiceLoader.access$100(ServiceLoader.java:181) at java.util.ServiceLoader$LazyIterator.next(ServiceLoader.java:377) at java.util.ServiceLoader$1.next(ServiceLoader.java:445) at org.apache.hadoop.hbase.CompatibilitySingletonFactory.getInstance(CompatibilitySingletonFactory.java:59) ... 27 moreCaused by: java.lang.NoClassDefFoundError: Lorg/apache/hadoop/hbase/metrics/MetricRegistry; at java.lang.Class.getDeclaredFields0(Native Method) at java.lang.Class.privateGetDeclaredFields(Class.java:2509) at java.lang.Class.getDeclaredFields(Class.java:1819) at org.apache.hadoop.util.ReflectionUtils.getDeclaredFieldsIncludingInherited(ReflectionUtils.java:323) at org.apache.hadoop.metrics2.lib.MetricsSourceBuilder.initRegistry(MetricsSourceBuilder.java:92) at org.apache.hadoop.metrics2.lib.MetricsSourceBuilder.&lt;init&gt;(MetricsSourceBuilder.java:56) at org.apache.hadoop.metrics2.lib.MetricsAnnotations.newSourceBuilder(MetricsAnnotations.java:42) at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:224) at org.apache.hadoop.hbase.metrics.BaseSourceImpl.&lt;init&gt;(BaseSourceImpl.java:115) at org.apache.hadoop.hbase.zookeeper.MetricsZooKeeperSourceImpl.&lt;init&gt;(MetricsZooKeeperSourceImpl.java:56) at org.apache.hadoop.hbase.zookeeper.MetricsZooKeeperSourceImpl.&lt;init&gt;(MetricsZooKeeperSourceImpl.java:51) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:526) at java.lang.Class.newInstance(Class.java:383) at java.util.ServiceLoader$LazyIterator.next(ServiceLoader.java:373) ... 29 moreCaused by: java.lang.ClassNotFoundException: org.apache.hadoop.hbase.metrics.MetricRegistry at java.net.URLClassLoader$1.run(URLClassLoader.java:366) at java.net.URLClassLoader$1.run(URLClassLoader.java:355) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:354) at java.lang.ClassLoader.loadClass(ClassLoader.java:425) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:312) at java.lang.ClassLoader.loadClass(ClassLoader.java:358) ... 46 moreThe errors are coming from within the map tasks. Suggesting that they are missing some jar/class dependency. I know there are several new jars created in Hbase 1.4.0. Are they missing/should be included in PerformanceEvaluation.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.1,2.0.0-beta-2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="19591" opendate="2017-12-22 00:00:00" fixdate="2017-12-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cleanup the usage of ReplicationAdmin from hbase-shell</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.replication.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug id="19592" opendate="2017-12-22 00:00:00" fixdate="2017-12-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add UTs to test retry on update zk failure</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.ReplicationPeerManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="19593" opendate="2017-12-22 00:00:00" fixdate="2017-12-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Possible NPE if wal is closed during waledit append.</summary>
      <description>There is a possible NPE when a wal is closed during waledit append because of not setting write entry to the wal key. Here is the code we are not setting write entry to wal key when when wal is closed. if (this.closed) { throw new IOException( "Cannot append; log is closed, regionName = " + hri.getRegionNameAsString()); } MutableLong txidHolder = new MutableLong(); MultiVersionConcurrencyControl.WriteEntry we = key.getMvcc().begin(() -&gt; { txidHolder.setValue(ringBuffer.next()); }); long txid = txidHolder.longValue(); try (TraceScope scope = TraceUtil.createTrace(implClassName + ".append")) { FSWALEntry entry = new FSWALEntry(txid, key, edits, hri, inMemstore); entry.stampRegionSequenceId(we); ringBuffer.get(txid).load(entry); } finally { ringBuffer.publish(txid); } return txid;But on failure complete on mvcc will be called with nulll write entry cause NPE. WriteEntry writeEntry = null; try { long txid = this.wal.append(this.getRegionInfo(), walKey, walEdit, true); // Call sync on our edit. if (txid != 0) { sync(txid, durability); } writeEntry = walKey.getWriteEntry(); } catch (IOException ioe) { if (walKey != null) { mvcc.complete(walKey.getWriteEntry()); } throw ioe; }We are able to reproduce with mocking in one of the phoenix test cases to test wal replay.</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="19596" opendate="2017-12-22 00:00:00" fixdate="2017-1-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RegionMetrics/ServerMetrics/ClusterMetrics should apply to all public classes</summary>
      <description>ServerLoad/RegionLoad/ClusterLoad are deprecated now. This issue will deprecate all related methods in our Public classes.</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-2,2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionMover.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestMiniClusterLoadSequential.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.BaseTestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestStochasticBalancerJmxMetrics.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestRegionMetrics.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestRegionLoad.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestClientClusterStatus.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestClientClusterMetrics.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.SnapshotTestingUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationStatus.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestMasterReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerReadRequestMetrics.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MiniHBaseCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterShutdown.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterOperationsForRegionReplicas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterFailoverBalancerPersistence.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestStochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestRegionLocationFinder.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestFavoredStochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestFavoredStochasticBalancerPickers.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestMasterObserver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMultiParallel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMetaWithReplicas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncDecommissionAdminApi.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncClusterAdminApi.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin2.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionSplitter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClusterStatusListener.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionMetricsBuilder.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestInterfaceAlign.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.Action.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.BatchRestartRsAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.DumpClusterStatusAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.MoveRegionsOfTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.RestartActiveMasterAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.RestartRsHoldingMetaAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.UnbalanceKillAndRebalanceAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.UnbalanceRegionsAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.DistributedHBaseCluster.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestIngest.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestingUtility.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestLazyCfLoading.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestRegionReplicaReplication.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.mapreduce.IntegrationTestBulkLoad.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.mttr.IntegrationTestMTTR.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.StripeCompactionsPerformanceEvaluation.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestTimeBoundedRequestsWithRegionReplicas.java</file>
      <file type="M">hbase-mapreduce.src.main.java.org.apache.hadoop.hbase.mapreduce.RegionSizeCalculator.java</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.mapreduce.TestRegionSizeCalculator.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.StorageClusterStatusResource.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.StorageClusterVersionResource.java</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupBasedLoadBalancer.java</file>
      <file type="M">hbase-rsgroup.src.test.java.org.apache.hadoop.hbase.rsgroup.TestRSGroupsBase.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.BackupMasterStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BalancerRegionLoad.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.ClusterStatusChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.RegionLocationFinder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ClusterStatusPublisher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.LoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionPlacementMaintainer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.Canary.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsckRepair.java</file>
    </fixedFiles>
  </bug>
  <bug id="19597" opendate="2017-12-22 00:00:00" fixdate="2017-12-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix Checkstyle errors in hbase-spark</summary>
      <description>Fix the remaining Checkstyle errors in the hbase-spark module and enable Checkstyle to fail on violations.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,connector-1.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.src.test.java.org.apache.hadoop.hbase.spark.TestJavaHBaseContext.java</file>
      <file type="M">hbase-spark.src.main.java.org.apache.hadoop.hbase.spark.SparkSQLPushDownFilter.java</file>
      <file type="M">hbase-spark.src.main.java.org.apache.hadoop.hbase.spark.example.hbasecontext.JavaHBaseMapGetPutExample.java</file>
      <file type="M">hbase-spark.src.main.java.org.apache.hadoop.hbase.spark.example.hbasecontext.JavaHBaseBulkLoadExample.java</file>
      <file type="M">hbase-spark.src.main.java.org.apache.hadoop.hbase.spark.example.hbasecontext.JavaHBaseBulkDeleteExample.java</file>
      <file type="M">hbase-spark.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="19755" opendate="2018-1-10 00:00:00" fixdate="2018-1-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Error message for non-existent namespace is inaccurate</summary>
      <description>On a secure cluster, when I issued this command where ns1 didn't exist:hbase(main):002:0&gt; create 'ns1:t1', 'f1', SPLITS =&gt; ['10', '20', '30', '40']ERROR: Unknown namespace ns1:t1!Creates a table. Pass a table name, and a set of column familyspecifications (at least one), and, optionally, table configurationHere is related code: raise "Unknown namespace #{args.first}!"Simply quoting the argument is not accurate - namespace should be extracted from the argument</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.rb</file>
    </fixedFiles>
  </bug>
  <bug id="20019" opendate="2018-2-19 00:00:00" fixdate="2018-2-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document the ColumnValueFilter</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="2002" opendate="2009-11-21 00:00:00" fixdate="2009-11-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Coprocessors: Client side support</summary>
      <description>"High-level call interface for clients. Unlike RPC, calls addressed to rows or ranges of rows. Coprocessor client library resolves to actual locations. Calls across multiple rows automatically split into multiple parallelized RPCs"Generic multicall RPC facility which incorporates this and multiget/multiput/multidelete and parallel scanners.Group and batch RPCs by region server. Track and retry outstanding RPCs. Ride over region relocations. Support addressing by explicit region identifier or by row key or row key range. Include a facility for merging results client side.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.resources.hbase-default.xml</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HRegionInterface.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HBaseServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HBaseRPCProtocolVersion.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HBaseRPC.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HBaseClient.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.HbaseObjectWritable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.MultiResponse.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.MultiAction.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HTableInterface.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnection.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.Action.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="20027" opendate="2018-2-20 00:00:00" fixdate="2018-2-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add test TestClusterPortAssignment</summary>
      <description>Port assignments for master ports in site configuration appear to be ignored.We are not catching this in tests because there appears to be no positive test for port assignment and the only fixed information we require is the zookeeper quorum and client port. </description>
      <version>1.4.0,1.4.1</version>
      <fixedVersion>1.4.2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MiniHBaseCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.LocalHBaseCluster.java</file>
    </fixedFiles>
  </bug>
  <bug id="2003" opendate="2009-11-23 00:00:00" fixdate="2009-11-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[shell] deleteall ignores column if specified</summary>
      <description>In the shell, a delete must match the value's coordinates exactly. By default the delete command uses the latest timestamp but you can provide on explicitly. So you have to delete each version independent of the others if there are multiple versions of a value. The command 'deleteall' is supposed to clear out a whole row or a whole column of values: deleteall Delete all cells in a given row; pass a table name, row, and optionally a column and timestampbut the code won't work as advertised: def deleteall(row, column = nil, timestamp = HConstants::LATEST_TIMESTAMP) now = Time.now d = Delete.new(row.to_java_bytes, timestamp, nil) @table.delete(d) @formatter.header() @formatter.footer(now) end'column' is ignored.</description>
      <version>None</version>
      <fixedVersion>0.20.3,0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.HBase.rb</file>
    </fixedFiles>
  </bug>
  <bug id="20066" opendate="2018-2-24 00:00:00" fixdate="2018-2-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Region sequence id may go backward after split or merge</summary>
      <description>The problem is that, now we have markers which will be written to WAL but not in store file. For a normal region close, we will write a sequence id file under the region directory, and when opening we will use this as the open sequence id. But for split and merge, we do not copy the sequence id file to the newly generated regions so the sequence id may go backwards since when closing the region we will write flush marker and close marker into WAL...</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.AbstractTestDLS.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.AbstractStateMachineTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.SplitTableRegionProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.MergeTableRegionsProcedure.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.MasterProcedure.proto</file>
    </fixedFiles>
  </bug>
  <bug id="20068" opendate="2018-2-24 00:00:00" fixdate="2018-4-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hadoopcheck project health check uses default maven repo instead of yetus managed ones</summary>
      <description>Recently had a precommit run fail hadoop check for all 3 versions with [ERROR] Failed to execute goal org.apache.maven.plugins:maven-install-plugin:2.5.2:install (default-install) on project hbase-thrift: Failed to install metadata org.apache.hbase:hbase-thrift:3.0.0-SNAPSHOT/maven-metadata.xml: Could not parse metadata /home/jenkins/.m2/repository/org/apache/hbase/hbase-thrift/3.0.0-SNAPSHOT/maven-metadata-local.xml: in epilog non whitespace content is not allowed but got / (position: END_TAG seen ...&lt;/metadata&gt;\n/... @25:2) -&gt; [Help 1]Looks like maven repo corruption.Also the path /home/jenkins/.m2/repository means that those invocations are using the jenkins user repo, which isn't safe since there are multiple executors. either the plugin isn't using the yetus provided maven repo path or our yetus invocation isn't telling yetus to provide its own maven repo path.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0,1.3.3,1.4.4,2.0.1,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  <bug id="20069" opendate="2018-2-24 00:00:00" fixdate="2018-2-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>fix existing findbugs errors in hbase-server</summary>
      <description>now that findbugs is running on precommit we have some cleanup to do.</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-2,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ClusterStatusPublisher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.compaction.MajorCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.CleanerChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.SplitTableRegionProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.StateMachineProcedure.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureExecutor.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.nio.TestMultiByteBuff.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.nio.MultiByteBuff.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.EncodedDataBlock.java</file>
    </fixedFiles>
  </bug>
  <bug id="20070" opendate="2018-2-24 00:00:00" fixdate="2018-3-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>website generation is failing</summary>
      <description>website generation has been failing since Feb 20thChecking out files: 100% (68971/68971), done.Usage: grep [OPTION]... PATTERN [FILE]...Try 'grep --help' for more information.PUSHED is 2 is not yet mentioned in the hbase-site commit log. Assuming we don't have it yet. 2Building HBaseJava HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=256m; support was removed in 8.0Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=256m; support was removed in 8.0Failure: mvn clean siteBuild step 'Execute shell' marked build as failureThe status email saysBuild status: Still FailingThe HBase website has not been updated to incorporate HBase commit ${CURRENT_HBASE_COMMIT}.Looking at the code where that grep happens, it looks like the env variable CURRENT_HBASE_COMMIT isn't getting set. That comes from some git command. I'm guessing the version of git changed on the build hosts and upended our assumptions.we should fix this to 1) rely on git's porcelain interface, and 2) fail as soon as that git command fails</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-zookeeper.pom.xml</file>
      <file type="M">hbase-thrift.pom.xml</file>
      <file type="M">hbase-testing-util.pom.xml</file>
      <file type="M">hbase-spark-it.pom.xml</file>
      <file type="M">hbase-shell.pom.xml</file>
      <file type="M">hbase-shaded.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-check-invariants.pom.xml</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-rsgroup.pom.xml</file>
      <file type="M">hbase-rest.pom.xml</file>
      <file type="M">hbase-resource-bundle.pom.xml</file>
      <file type="M">hbase-replication.pom.xml</file>
      <file type="M">hbase-protocol.pom.xml</file>
      <file type="M">hbase-protocol-shaded.pom.xml</file>
      <file type="M">hbase-procedure.pom.xml</file>
      <file type="M">hbase-metrics.pom.xml</file>
      <file type="M">hbase-metrics-api.pom.xml</file>
      <file type="M">hbase-mapreduce.pom.xml</file>
      <file type="M">hbase-it.pom.xml</file>
      <file type="M">hbase-http.pom.xml</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-hadoop-compat.pom.xml</file>
      <file type="M">hbase-external-blockcache.pom.xml</file>
      <file type="M">hbase-examples.pom.xml</file>
      <file type="M">hbase-endpoint.pom.xml</file>
      <file type="M">hbase-common.pom.xml</file>
      <file type="M">hbase-client.pom.xml</file>
      <file type="M">hbase-build-configuration.pom.xml</file>
      <file type="M">hbase-backup.pom.xml</file>
      <file type="M">hbase-assembly.pom.xml</file>
      <file type="M">hbase-annotations.pom.xml</file>
      <file type="M">dev-support.jenkins-scripts.generate-hbase-website.sh</file>
    </fixedFiles>
  </bug>
  <bug id="20175" opendate="2018-3-12 00:00:00" fixdate="2018-8-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase-spark needs scala dependency convergance</summary>
      <description>This is a follow-on to HBASE-16179 - I think we might need to specify an exclude in the dependency management.[INFO] --- scala-maven-plugin:3.2.0:compile (scala-compile-first) @ hbase-spark ---[WARNING] Expected all dependencies to require Scala version: 2.11.8[WARNING] org.apache.hbase:hbase-spark:3.0.0-SNAPSHOT requires scala version: 2.11.8[WARNING] org.apache.spark:spark-streaming_2.11:2.1.1 requires scala version: 2.11.8[WARNING] org.apache.spark:spark-streaming_2.11:2.1.1 requires scala version: 2.11.8[WARNING] org.scalatest:scalatest_2.11:2.2.4 requires scala version: 2.11.2tedyu - since you're already fiddling in this area, do you want to take a look?</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,connector-1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="20177" opendate="2018-3-12 00:00:00" fixdate="2018-3-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix warning: Class org.apache.hadoop.minikdc.MiniKdc not found in hbase-spark</summary>
      <description>getting warning for[WARNING] warning: Class org.apache.hadoop.minikdc.MiniKdc not found - continuing with a stub. </description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,connector-1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="20178" opendate="2018-3-12 00:00:00" fixdate="2018-3-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[AMv2] Throw exception if hostile environment</summary>
      <description>New pattern where we throw exception on procedure construction if cluster is going down, hosting master is stopping, table is offline, or table is read-only. Fail fast rather than later internal to Procedure so can flag caller there is a problem.Changed Move/Split/Merge Procedures.No point queuing a move region for a table that is offline and which may never be re-enabled.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MockRegionServerServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestTruncateTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestDisableTableProcedure.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockNoopMasterServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.assignment.MockMasterServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.AbstractTestDLS.java</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.rsgroup.jsp</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableNamespaceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.TruncateTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.RestoreSnapshotProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.EnableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DisableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteNamespaceProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.AbstractStateMachineTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MirroringTableStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.SplitTableRegionProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.MoveRegionProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.MergeTableRegionsProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.AssignProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.CallRunner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MetaTableAccessor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.TableState.java</file>
    </fixedFiles>
  </bug>
  <bug id="20219" opendate="2018-3-19 00:00:00" fixdate="2018-4-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>An error occurs when scanning with reversed=true and loadColumnFamiliesOnDemand=true</summary>
      <description>I'm facing the following error when scanning with reversed=true and loadColumnFamiliesOnDemand=true:java.lang.IllegalStateException: requestSeek cannot be called on ReversedKeyValueHeap at org.apache.hadoop.hbase.regionserver.ReversedKeyValueHeap.requestSeek(ReversedKeyValueHeap.java:66) at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.joinedHeapMayHaveData(HRegion.java:6725) at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.nextInternal(HRegion.java:6652) at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.nextRaw(HRegion.java:6364) at org.apache.hadoop.hbase.regionserver.RSRpcServices.scan(RSRpcServices.java:3108) at org.apache.hadoop.hbase.regionserver.RSRpcServices.scan(RSRpcServices.java:3345) at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:41548) at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:409) at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:130) at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:324) at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:304)I will attach a UT patch to reproduce this issue.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestJoinedScanners.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ReversedRegionScannerImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="20296" opendate="2018-3-27 00:00:00" fixdate="2018-4-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove last pushed sequence ids when removing tables from a peer</summary>
      <description>Discussed with zghaobac and openinx offline, this is the only safe thing to do for now. It is not safe to remove barriers and last pushed sequence ids when deleting a table since we may still have edits which should be replicated.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestEnableTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.UpdatePeerConfigProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.ModifyPeerProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.AddPeerProcedure.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ZKReplicationQueueStorage.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueueStorage.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MetaTableAccessor.java</file>
    </fixedFiles>
  </bug>
  <bug id="20298" opendate="2018-3-27 00:00:00" fixdate="2018-4-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Doc change in read/write/total accounting metrics</summary>
      <description>Doc the change wrought by the parent issue. Get it up into the refguide as part of the difference between old hbases and hbase2.The change confused me and took me a while to untangle.The read count is for reads that return a non-empty result now. In old hbase1, we'd increment the read-count even if an empty result. This makes reads look bad in YCSB runs when compared to hbase1 (see how totalRequestCount in hbase2 can be way above the sum of reads+writes; it is because it increments even if the row is not found).Let me get this into refguide otherwise poor old operators will be baffled. The release note on the parent is great; it just needs to be in our guide.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.FastPathBalancedQueueRpcExecutor.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="20581" opendate="2018-5-14 00:00:00" fixdate="2018-5-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase book documentation wrong for REST operations on schema endpoints</summary>
      <description>On https://hbase.apache.org/book.html#_using_rest_endpointsThe documentation states that to update a table schema (the configuration for a column family), the PUT HTTP verb will update the current configuration with the "fragment" of configuration provided, while the POST HTTP verb will replace the current configuration with whatever is provided.In reality, the opposite is true: POST updates the configuration, PUT replaces. The old javadoc for the o.a.h.h.rest package got it right, but the entry on the HBase book transposed this.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.external.apis.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="20582" opendate="2018-5-14 00:00:00" fixdate="2018-5-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bump up JRuby version because of some reported vulnerabilities</summary>
      <description>There are some vulnerabilities reported with two of the libraries used in HBase.Jruby(version:9.1.10.0):CVE-2009-5147CVE-2013-4363CVE-2014-4975CVE-2014-8080CVE-2014-8090CVE-2015-3900CVE-2015-7551CVE-2015-9096CVE-2017-0899CVE-2017-0900CVE-2017-0901CVE-2017-0902CVE-2017-0903CVE-2017-10784CVE-2017-14064CVE-2017-9224CVE-2017-9225CVE-2017-9226CVE-2017-9227CVE-2017-9228Tool somehow able to relate the vulnerability of Ruby with JRuby(Java implementation). (Jackson will be handled in a different issue.)Not all of them directly affects HBase but elserj suggested that it is better to be on the updated version to avoid issues during an audit in security sensitive organization. </description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="20704" opendate="2018-6-7 00:00:00" fixdate="2018-9-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Sometimes some compacted storefiles are not archived on region close</summary>
      <description>During region close compacted files which have not yet been archived by the discharger are archived as part of the region closing process. It is important that these files are wholly archived to insure data consistency. ie a storefile containing delete tombstones can be archived while older storefiles containing cells that were supposed to be deleted are left unarchived thereby undeleting those cells. On region close a compacted storefile is skipped from archiving if it has read references (ie open scanners). This behavior is correct for when the discharger chore runs but on region close consistency is of course more important so we should add a special case to ignore any references on the storefile and go ahead and archive it. Attached patch contains a unit test that reproduces the problem and the proposed fix.</description>
      <version>3.0.0-alpha-1,1.3.0,1.4.0,1.5.0,2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,1.3.3,2.2.0,1.4.8,2.1.1,2.0.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="20705" opendate="2018-6-7 00:00:00" fixdate="2018-8-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Having RPC Quota on a table prevents Space quota to be recreated/removed</summary>
      <description>Property hbase.quota.remove.on.table.delete is set to true by default Create a table and set RPC and Space quotahbase(main):022:0&gt; create 't2','cf1'Created table t2Took 0.7420 seconds=&gt; Hbase::Table - t2hbase(main):023:0&gt; set_quota TYPE =&gt; SPACE, TABLE =&gt; 't2', LIMIT =&gt; '1G', POLICY =&gt; NO_WRITESTook 0.0105 secondshbase(main):024:0&gt; set_quota TYPE =&gt; THROTTLE, TABLE =&gt; 't2', LIMIT =&gt; '10M/sec'Took 0.0186 secondshbase(main):025:0&gt; list_quotasTABLE =&gt; t2 TYPE =&gt; THROTTLE, THROTTLE_TYPE =&gt; REQUEST_SIZE, LIMIT =&gt; 10M/sec, SCOPE =&gt; MACHINETABLE =&gt; t2 TYPE =&gt; SPACE, TABLE =&gt; t2, LIMIT =&gt; 1073741824, VIOLATION_POLICY =&gt; NO_WRITES Drop the table and the Space quota is set to REMOVE =&gt; truehbase(main):026:0&gt; disable 't2'Took 0.4363 secondshbase(main):027:0&gt; drop 't2'Took 0.2344 secondshbase(main):028:0&gt; list_quotasTABLE =&gt; t2 TYPE =&gt; SPACE, TABLE =&gt; t2, REMOVE =&gt; trueUSER =&gt; u1 TYPE =&gt; THROTTLE, THROTTLE_TYPE =&gt; REQUEST_SIZE, LIMIT =&gt; 10M/sec, SCOPE =&gt; MACHINE Recreate the table and set Space quota back. The Space quota on the table is still set to REMOVE =&gt; truehbase(main):029:0&gt; create 't2','cf1'Created table t2Took 0.7348 seconds=&gt; Hbase::Table - t2hbase(main):031:0&gt; set_quota TYPE =&gt; SPACE, TABLE =&gt; 't2', LIMIT =&gt; '1G', POLICY =&gt; NO_WRITESTook 0.0088 secondshbase(main):032:0&gt; list_quotasOWNER QUOTASTABLE =&gt; t2 TYPE =&gt; THROTTLE, THROTTLE_TYPE =&gt; REQUEST_SIZE, LIMIT =&gt; 10M/sec, SCOPE =&gt; MACHINETABLE =&gt; t2 TYPE =&gt; SPACE, TABLE =&gt; t2, REMOVE =&gt; true Remove RPC quota and drop the table, the Space Quota is not removedhbase(main):033:0&gt; set_quota TYPE =&gt; THROTTLE, TABLE =&gt; 't2', LIMIT =&gt; NONETook 0.0193 secondshbase(main):036:0&gt; disable 't2'Took 0.4305 secondshbase(main):037:0&gt; drop 't2'Took 0.2353 secondshbase(main):038:0&gt; list_quotasOWNER QUOTASTABLE =&gt; t2                               TYPE =&gt; SPACE, TABLE =&gt; t2, REMOVE =&gt; true Deleting the quota entry from hbase:quota seems to be the option to reset it.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1,2.0.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestMasterQuotasObserver.java</file>
    </fixedFiles>
  </bug>
  <bug id="20724" opendate="2018-6-13 00:00:00" fixdate="2018-2-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Sometimes some compacted storefiles are still opened after region failover</summary>
      <description>It is important that compacted storefiles of a given compaction execution are wholly opened or archived to insure data consistency. ie a storefile containing delete tombstones can be archived while older storefiles containing cells that were supposed to be deleted are left unarchived thereby undeleting those cells.When a server fails compaction markers (in the wal edit) are used to determine which storefiles are compacted and should be excluded during region open (during failover). But the WALs containing compaction markers can be prematurely archived even though there are still compacted storefiles for that particular compaction event that hasn't been archived yet. Thus losing compaction information that needs to be replayed in the event of an RS crash. This is because hlog archiving logic only keeps track of flushed storefiles and not compacted ones.https://issues.apache.org/jira/browse/HBASE-20704?focusedCommentId=16507680&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16507680</description>
      <version>3.0.0-alpha-1,1.3.0,1.4.0,1.5.0,2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSwitchToStreamRead.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCleanupCompactedFileOnRegionClose.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.compactions.TestCompactor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestSpaceQuotasWithSnapshots.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.quotas.TestSnapshotQuotaObserverChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.StripeCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.DateTieredCompactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.AbstractMultiFileWriter.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.HFile.proto</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="21141" opendate="2018-9-2 00:00:00" fixdate="2018-11-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable MOB in backup / restore test involving incremental backup</summary>
      <description>Currently we only have one test (TestRemoteBackup) where MOB feature is enabled. The test only performs full backup.This issue is to enable MOB in backup / restore test(s) involving incremental backup.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-backup.src.test.java.org.apache.hadoop.hbase.backup.TestIncrementalBackup.java</file>
    </fixedFiles>
  </bug>
  <bug id="21405" opendate="2018-10-30 00:00:00" fixdate="2018-6-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[DOC] Add Details about Output of "status &amp;#39;replication&amp;#39;"</summary>
      <description>Add more information about the meaning of each metric on to http://hbase.apache.org/book.html#_monitoring_replication_status.SOURCE: PeerID AgeOfLastShippedOp SizeOfLogQueue TimeStampsOfLastShippedOp Replication LagSINK AgeOfLastAppliedOp TimeStampsOfLastAppliedOp</description>
      <version>3.0.0-alpha-1,1.4.0,2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="2177" opendate="2010-2-1 00:00:00" fixdate="2010-2-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add timestamping to gc logging options</summary>
      <description>http://forums.sun.com/thread.jspa?threadID=5165451</description>
      <version>None</version>
      <fixedVersion>0.20.4,0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.hbase-env.sh</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="22264" opendate="2019-4-17 00:00:00" fixdate="2019-6-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Separate out jars related to JDK 11 into a folder in /lib</summary>
      <description>UPDATE:Separate out the the jars related to JDK 11 and add control their addition to the classpath using an environment variable or auto-detection of the jdk version installed.OLD:This is in continuation with HBASE-22249. When compiled with jdk 8 and run on jdk 11, the master branch throws the following exception during an attempt to start the hbase rest server:Exception in thread "main" java.lang.NoClassDefFoundError: javax/annotation/Priority at org.glassfish.jersey.model.internal.ComponentBag.modelFor(ComponentBag.java:483) at org.glassfish.jersey.model.internal.ComponentBag.access$100(ComponentBag.java:89) at org.glassfish.jersey.model.internal.ComponentBag$5.call(ComponentBag.java:408) at org.glassfish.jersey.model.internal.ComponentBag$5.call(ComponentBag.java:398) at org.glassfish.jersey.internal.Errors.process(Errors.java:315) at org.glassfish.jersey.internal.Errors.process(Errors.java:297) at org.glassfish.jersey.internal.Errors.process(Errors.java:228) at org.glassfish.jersey.model.internal.ComponentBag.registerModel(ComponentBag.java:398) at org.glassfish.jersey.model.internal.ComponentBag.register(ComponentBag.java:235) at org.glassfish.jersey.model.internal.CommonConfig.register(CommonConfig.java:420) at org.glassfish.jersey.server.ResourceConfig.register(ResourceConfig.java:425) at org.apache.hadoop.hbase.rest.RESTServer.run(RESTServer.java:245) at org.apache.hadoop.hbase.rest.RESTServer.main(RESTServer.java:421)</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-resource-bundle.src.main.resources.supplemental-models.xml</file>
      <file type="M">hbase-resource-bundle.src.main.resources.META-INF.LICENSE.vm</file>
      <file type="M">hbase-assembly.src.main.assembly.hadoop-two-compat.xml</file>
      <file type="M">hbase-assembly.pom.xml</file>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug id="22379" opendate="2019-5-8 00:00:00" fixdate="2019-5-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix Markdown for "Voting on Release Candidates" in book</summary>
      <description>The Markdown in the section "Voting on Release Candidates" of the HBase book seems to be broken. It looks like that there should be a quote, which isn't displayed correctly. Same is true for the formatting of the Maven RAT command.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,1.4.10,2.3.0,2.0.6,2.1.5,1.3.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  <bug id="22935" opendate="2019-8-27 00:00:00" fixdate="2019-8-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TaskMonitor warns MonitoredRPCHandler task may be stuck when it recently started</summary>
      <description>After setting hbase.taskmonitor.rpc.warn.time to 180000, the logs show WARN messages such as these2019-08-08 21:50:02,601 WARN [read for TaskMonitor] monitoring.TaskMonitor - Task may be stuck: RpcServer.FifoWFPBQ.default.handler=4,queue=4,port=60020: status=Servicing call from &lt;ip&gt;:55164: Scan, state=RUNNING, startTime=1563305858103, completionTime=-1, queuetimems=1565301002599, starttimems=1565301002599, clientaddress=&lt;ip&gt;, remoteport=55164, packetlength=370, rpcMethod=ScanNotice that the first starttimems is far in the past. The second starttimems and the queuetimems are much closer to the log timestamp than 180 seconds. I think this is because the warnTime is initialized to the time that MonitoredTaskImpl is created, but never updated until we write a warn message to the log.</description>
      <version>3.0.0-alpha-1,1.4.0,1.5.0,1.3.3,2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,2.2.1,1.3.6,1.4.11,2.1.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.monitoring.TestTaskMonitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.MonitoredRPCHandlerImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="22943" opendate="2019-8-28 00:00:00" fixdate="2019-9-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Various procedures should not cache log trace level</summary>
      <description>several of the procedures have an idiom where they keep a member variable for if the log is at trace level or not, wrapped in a function so that it can be lazily looked up. This gives us an overhead per call of autoboxing and a function call, instead of just the function call from asking the logging system directly.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.1,2.1.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.RestoreSnapshotProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.EnableTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CloneSnapshotProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.SplitTableRegionProcedure.java</file>
    </fixedFiles>
  </bug>
  <bug id="22945" opendate="2019-8-29 00:00:00" fixdate="2019-9-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Show quota infos in master UI</summary>
      <description>Add a page in master UI to show the following quota infos:if rpc throttle is enabled;if exceed throttle quota is enabled;namespace throtlles;user throttles.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.header.jsp</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.MasterQuotaManager.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.ThrottleSettings.java</file>
    </fixedFiles>
  </bug>
  <bug id="22946" opendate="2019-8-29 00:00:00" fixdate="2019-9-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix TableNotFound when grant/revoke if AccessController is not loaded</summary>
      <description>When doing grant, revoke..., a TableNotFoundException will occur if AccessController if is not configured.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug id="23172" opendate="2019-10-14 00:00:00" fixdate="2019-10-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase Canary region success count metrics reflect column family successes, not region successes</summary>
      <description>HBase Canary reads once per column family per region. The current "region success count" should actually be "column family success count," which means we need another metric that actually reflects region success count. Additionally, the region read and write latencies only store the latencies of the last column family of the region read. Instead of a map of regions to a single latency value and success value, we should map each region to a list of such values.</description>
      <version>3.0.0-alpha-1,1.3.0,1.4.0,1.5.0,2.0.0,2.1.5,2.2.1</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,1.6.0,2.1.8,2.2.3</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.tool.TestCanaryTool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.CanaryTool.java</file>
    </fixedFiles>
  </bug>
  <bug id="2327" opendate="2010-3-15 00:00:00" fixdate="2010-3-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[EC2] Allocate elastic IP addresses for ZK and master nodes</summary>
      <description>Amazon EC2 supports Elastic IP Addresses to implement the effect of having a static IP address for public servers running on EC2. Up on hbase-users@ there was some recent discussion, confirmed, that when an EC2 instance queries the external DNS name of an elastic IP address, EC2 DNS returns the internal IP address of the instance to which the elastic IP address is bound, so it is safe to use elastic IPs for the ZK and master nodes. We gain the ability to do transparent replacement of one instance, e.g. failed, with another without incurring any additional cost. Update launch-hbase-zookeeper and launch-hbase-master to allocate elastic IPs: $ ec2-allocate-address ADDRESS 1.1.1.1and then assign the elastic IP address to the appropriate instance(s):$ ec2-associate-address -i i-11111111 1.1.1.1ADDRESS 1.1.1.1 i-11111111and then get the external DNS name to use when performing substitutions on master and slave configs:$ ec2-describe-instances i-11111111 | egrep ^INSTANCE | cut -f4ec2-1-1-1-1.compute-1.amazonaws.comWhen shutting down the cluster, just release the elastic IPs after terminating the instances:ec2-release-address 1.1.1.1...NOTE: AWS accounts default to a limit of 5 Elastic IP addresses but most will run with 1 master and 3 or 1 ZK instances. And, the ZK ensemble can be shared. A follow up issue can address making scripts to launch replacements for failed instances transparently.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">contrib.ec2.bin.terminate-hbase-cluster</file>
      <file type="M">contrib.ec2.bin.launch-hbase-zookeeper</file>
      <file type="M">contrib.ec2.bin.launch-hbase-slaves</file>
      <file type="M">contrib.ec2.bin.launch-hbase-master</file>
      <file type="M">contrib.ec2.bin.image.create-hbase-image-remote</file>
      <file type="M">contrib.ec2.bin.hbase-ec2-env.sh</file>
      <file type="M">contrib.ec2.bin.create-hbase-image</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="23829" opendate="2020-2-11 00:00:00" fixdate="2020-4-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Get `-PrunSmallTests` passing on JDK11</summary>
      <description>Start with the small tests, shaking out issues identified by the harness. So far it seems like -Dhadoop.profile=3.0 and -Dhadoop-three.version=3.3.0-SNAPSHOT maybe be required.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-with-hadoop-check-invariants.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-check-invariants.pom.xml</file>
      <file type="M">hbase-http.src.test.java.org.apache.hadoop.hbase.http.log.TestLogLevel.java</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestFutureUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="24545" opendate="2020-6-12 00:00:00" fixdate="2020-6-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add backoff to SCP check on WAL split completion</summary>
      <description>Crashed cluster. Lots of backed up WALs. Startup. Recover hundreds of servers; each has a running SCP. Taking a thread dump during recovery, I noticed that there were 160 threads each in SCP waiting on split WAL completion. Each thread was scanning zk splitWAL directory every 100ms. The dir had thousands of entries in it so each check was pulling down MB from zk... * 160 (max configured PE threads (16) * 10 for the KeepAlive factor that has us do 10 * configured PEs as max for PE worker pool).If lots of remaining WALs to split, have the SCP backoff on its wait so it checks less frequently.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestSplitLogManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure.java</file>
    </fixedFiles>
  </bug>
  <bug id="9465" opendate="2013-9-9 00:00:00" fixdate="2013-4-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Push entries to peer clusters serially</summary>
      <description>When region-move or RS failure occurs in master cluster, the hlog entries that are not pushed before region-move or RS-failure will be pushed by original RS(for region move) or another RS which takes over the remained hlog of dead RS(for RS failure), and the new entries for the same region(s) will be pushed by the RS which now serves the region(s), but they push the hlog entries of a same region concurrently without coordination.This treatment can possibly lead to data inconsistency between master and peer clusters:1. there are put and then delete written to master cluster2. due to region-move / RS-failure, they are pushed by different replication-source threads to peer cluster3. if delete is pushed to peer cluster before put, and flush and major-compact occurs in peer cluster before put is pushed to peer cluster, the delete is collected and the put remains in peer clusterIn this scenario, the put remains in peer cluster, but in master cluster the put is masked by the delete, hence data inconsistency between master and peer clusters</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestMetaTableAccessor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WAL.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSTableDescriptors.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.Replication.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSWALEntry.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStateStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.WAL.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.WALProtos.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MetaTableAccessor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.replication.ReplicationAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
    </fixedFiles>
  </bug>
  <bug id="9467" opendate="2013-9-9 00:00:00" fixdate="2013-9-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>write can be totally blocked temporarily by a write-heavy region</summary>
      <description>Write to a region can be blocked temporarily if the memstore of that region reaches the threshold(hbase.hregion.memstore.block.multiplier * hbase.hregion.flush.size) until the memstore of that region is flushed.For a write-heavy region, if its write requests saturates all the handler threads of that RS when write blocking for that region occurs, requests of other regions/tables to that RS also can't be served due to no available handler threads...until the pending writes of that write-heavy region are served after the flush is done. Hence during this time period, from the RS perspective it can't serve any request from any table/region just due to a single write-heavy region.This sounds not very reasonable, right? Maybe write requests from a region can only be served by a sub-set of the handler threads, and then write blocking of any single region can't lead to the scenario mentioned above?Comment?</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug id="9468" opendate="2013-9-9 00:00:00" fixdate="2013-9-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Previous active master can still serves RPC request when it is trying recovering expired zk session</summary>
      <description>When the active master's zk session expires, it'll try to recover zk session, but without turn off its RpcServer. What if a previous backup master has already become the now active master, and some client tries to send request to this expired master by using the cached master info? Any problem here?</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.94.12,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.configuration.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="947" opendate="2008-10-21 00:00:00" fixdate="2008-11-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[Optimization] Major compaction should remove deletes as well as the deleted cell</summary>
      <description>Currently major compactions retains both deletes and the deleted cell. It should remove both.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>
