<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HBASE">
  <bug id="8456" opendate="2013-4-29 00:00:00" fixdate="2013-4-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase Windows scripts fail when there&amp;#39;s a blank space in JAVA_HOME</summary>
      <description>If JAVA_HOME is set to a directory with a space in it (e.g. "C:\Program Files\Java\..."), the scripts fail because some of the commands don't properly quote it.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase.cmd</file>
      <file type="M">bin.hbase-config.cmd</file>
    </fixedFiles>
  </bug>
  <bug id="8458" opendate="2013-4-29 00:00:00" fixdate="2013-6-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support for batch version of checkAndMutate()</summary>
      <description>The use case is that the user has multiple threads loading hundreds of keys into a hbase table. Occasionally there are collisions in the keys being uploaded by different threads. So for correctness, it is required to do checkAndMutate() instead of a put(). However, doing a checkAndMutate() rpc for every key update is non optimal. It would be good to have a batch version of checkAndMutate() similar to batch put(). The client can partition the keys on region boundaries.The jira is NOT looking for any type of cross-row locking or multi-row atomicity with checkAndMutate().</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.4.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.client.ThriftTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMalformedCellFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide3.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestCheckAndMutate.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTableBatch.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.DummyAsyncTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-rest.src.test.java.org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.client.Client.proto</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ResponseConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.TableOverAsyncTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Table.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncTableImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Mutation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncBatchRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.RequestConverter.java</file>
    </fixedFiles>
  </bug>
  <bug id="8534" opendate="2013-5-13 00:00:00" fixdate="2013-9-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix coverage for org.apache.hadoop.hbase.mapreduce</summary>
      <description>fix coverage org.apache.hadoop.hbase.mapreducepatch HBASE-8534-0.94.patch for branch-0.94patch HBASE-8534-trunk.patch for branch-0.95 and trunk</description>
      <version>0.94.8,0.95.2</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableMapReduceUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestDriver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestWALPlayer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestRowCounter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestImportExport.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestCopyTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="8543" opendate="2013-5-14 00:00:00" fixdate="2013-10-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>fix coverage org.apache.hadoop.hbase.rest.client</summary>
      <description>fix coverage org.apache.hadoop.hbase.rest.client</description>
      <version>0.94.8,0.95.2</version>
      <fixedVersion>0.98.0,0.96.1,0.94.14</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.client.TestRemoteTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="8588" opendate="2013-5-21 00:00:00" fixdate="2013-5-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[Documentation]: Add information about adding REST and Thrift API kerberos principals to HBase ACL table</summary>
      <description>When users set up secure REST and Thrift API gateways, those principals will need entries in the HBase ACL table in order to interact with HBase.We should add that to the documentation so that they can have success with it right away.</description>
      <version>0.94.8,0.95.1</version>
      <fixedVersion>0.94.8,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.security.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8621" opendate="2013-5-25 00:00:00" fixdate="2013-5-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>More log edits; we log too much</summary>
      <description>Running 0.95.1 candidate on cluster, I notice we are logging too much. Here is an edit of the logs.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.lock.ZKInterProcessLockBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.CreateTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="8760" opendate="2013-6-18 00:00:00" fixdate="2013-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>possible loss of data in snapshot taken after region split</summary>
      <description>Right after a region split but before the daughter regions are compacted, we have two daughter regions containing Reference files to the parent hfiles.If we take snapshot right at the moment, the snapshot will succeed, but it will only contain the daughter Reference files. Since there is no hold on the parent hfiles, they will be deleted by the HFile Cleaner after they are no longer needed by the daughter regions soon after.A minimum we need to do is the keep these parent hfiles from being deleted.</description>
      <version>0.94.8,0.95.1</version>
      <fixedVersion>0.98.0,0.94.12,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.ExportSnapshot.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.RestoreSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.MasterSnapshotVerifier.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.EnabledTableSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.DisabledTableSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.CloneSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.CreateTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.HFileLink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.catalog.MetaEditor.java</file>
    </fixedFiles>
  </bug>
  <bug id="8776" opendate="2013-6-20 00:00:00" fixdate="2013-7-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>tweak retry settings some more (on trunk and 0.94)</summary>
      <description></description>
      <version>0.94.8</version>
      <fixedVersion>0.95.2,0.94.10</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="8780" opendate="2013-6-21 00:00:00" fixdate="2013-7-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>A column Family can have VERSIONS less than zero</summary>
      <description>User can create/alter a columnfam and set its VERSION(aka maxVERSIONS) to a negative or zero value. Although there is a checking in HColumnDesciptor#construtor, hbase shell command will invoke the setter(setMaxVersions and setMinVersions) directly, hence by pass the checking. For example:set VERSIONS = -1hbase(main):016:0&gt; create 't5_dn',{NAME=&gt;'cf1',VERSIONS=&gt;-1}0 row(s) in 1.0420 secondshbase(main):017:0&gt; put 't5_dn','row1','cf1:q1','row1cf1_v1'0 row(s) in 0.0700 secondshbase(main):018:0&gt; scan 't5_dn'ROW COLUMN+CELL 0 row(s) in 0.0090 secondshbase(main):019:0&gt; describe 't5_dn'DESCRIPTION ENABLED 't5_dn', {NAME =&gt; 'cf1', REPLICATION_SCOPE =&gt; '0', true KEEP_DELETED_CELLS =&gt; 'false', COMPRESSION =&gt; 'NONE ', ENCODE_ON_DISK =&gt; 'true', BLOCKCACHE =&gt; 'true', MIN_VERSIONS =&gt; '0', DATA_BLOCK_ENCODING =&gt; 'NONE', IN_MEMORY =&gt; 'false', BLOOMFILTER =&gt; 'NONE', TTL = &gt; '2147483647', VERSIONS =&gt; '-1', BLOCKSIZE =&gt; '655 36'} 1 row(s) in 0.0410 secondsabove example shows VERSIONS =&gt; '-1', and put/scan doesn't keep the data</description>
      <version>0.94.8</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="8807" opendate="2013-6-25 00:00:00" fixdate="2013-5-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase MapReduce Job-Launch Documentation Misplaced</summary>
      <description>Documentation on steps to properly launch a mapreduce job on an HBase + Hadoop cluster is misplaced and is located in Javadocs: http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/package-summary.html#classpath This must be extracted and placed in a separate page with rest of HBase MR guide.</description>
      <version>0.94.8</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.book.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.package-info.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.package-info.java</file>
    </fixedFiles>
  </bug>
  <bug id="8812" opendate="2013-6-27 00:00:00" fixdate="2013-7-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Avoid a wide line on the HMaster webUI if we have many ZooKeeper servers</summary>
      <description>add a line break for every four zookeeper quorums on the HMaster webUI.I don't think this need a test case. just manual testing is enough. I've tested on my testing cluster. everything works well.</description>
      <version>0.94.8</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug id="8855" opendate="2013-7-2 00:00:00" fixdate="2013-7-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestTableInputFormatScan1/2 fail semi-silently with the hadoop 2 profile</summary>
      <description>It looks like TestTableInputFormatScan1 and TestTableInputFormatScan2 never complete and surefire doesn't complain about it. Sure, you may see this:Tests run: 6, Failures: 5, Errors: 1, Skipped: 0, Time elapsed: 269.036 sec &lt;&lt;&lt; FAILURE!org.apache.maven.surefire.util.SurefireReflectionException: ...org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:74)Caused by: java.lang.OutOfMemoryError: PermGen spaceorg.apache.maven.surefire.booter.SurefireBooterForkException: Error occurred in starting fork, check output in log... testScanEmptyToBBA(org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan1) testScanEmptyToBBB(org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan1) testScanEmptyToOPP(org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan1) testScanEmptyToEmpty(org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan1)But then:[INFO] HBase - Server .................................... SUCCESS [10:59.929s]This is on my machine. On our local jenkins it's leaking and the processes never die. And this is only with Hadoop 2. It also looks like other tests are failing with PermGen space.</description>
      <version>0.94.8,0.95.1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8868" opendate="2013-7-4 00:00:00" fixdate="2013-3-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>add metric to report client shortcircuit reads</summary>
      <description>With the availability of shortcircuit reads, when the feature is enabled there is no metric which exposes how many times the regionserver was able to shortcircuit the read and not make a IPC to the datanode.It will be great to add the metric and expose it via Ganglia.</description>
      <version>0.94.8,0.95.1</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,1.7.0,2.2.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.schema.design.adoc</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerMetrics.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperStub.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.FSDataInputStreamWrapper.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
    </fixedFiles>
  </bug>
</bugrepository>
