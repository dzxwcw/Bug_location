<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="HBASE">
  
  
  <bug fixdate="2018-9-12 01:00:00" id="21188" opendate="2018-9-12 00:00:00" resolution="Later">
    <buginformation>
      <summary>Print heap and gc informations in our junit ResourceChecker</summary>
      <description/>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.ResourceCheckerJUnitListener.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-9-12 01:00:00" id="21189" opendate="2018-9-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>flaky job should gather machine stats</summary>
      <description>flaky test should gather all the same environment information as our normal nightly tests.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.3.3,1.2.8,2.2.0,1.4.8,2.1.1,2.0.3</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.flaky-tests.run-flaky-tests.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2018-10-20 01:00:00" id="21215" opendate="2018-9-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Figure how to invoke hbck2; make it easy to find</summary>
      <description>In https://docs.google.com/document/d/1Oun4G3M5fyrM0OxXcCKYF8td0KD7gJQjnU9Ad-2t-uk/edit#, the doc on hbck2 'form', one item to figure is how to invoke hbck2. Related, how to make it easy to find? busbey has some ideas (posted in doc). This issue is for implementation.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1,2.0.3</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  <bug fixdate="2018-10-21 01:00:00" id="21354" opendate="2018-10-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure may be deleted improperly during master restarts resulting in &amp;#39;Corrupt&amp;#39;</summary>
      <description>Good news! stack, Apache9, I may find the root cause of mysterious ‘Corrupted procedure’ or some procedures disappeared after master restarts(happens during ITBLL).This is because during master restarts, we load procedures from the log, and builds the 'holdingCleanupTracker' according each log's tracker. We may mark a procedure in the oldest log as deleted if one log doesn't contain the procedure. This is Inappropriate since one log will not contain info of the log if this procedure was not updated during the time. We can only delete the procedure only if it is not in the global tracker, which have the whole picture.trackerNode = tracker.lookupClosestNode(trackerNode, procId); if (trackerNode == null || !trackerNode.contains(procId) || trackerNode.isModified(procId)) { // the procedure was removed or modified node.delete(procId); }A test case(testProcedureShouldNotCleanOnLoad) shows cleanly how the corruption happened in the patch.</description>
      <version>2.1.0,2.0.2</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1,2.0.3</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.ProcedureStoreTracker.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.ProcedureTestingUtility.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2018-11-26 01:00:00" id="21396" opendate="2018-10-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create 2.1.1 release</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.1.1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.downloads.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2010-1-17 01:00:00" id="2140" opendate="2010-1-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>findbugs issues - 2 performance warnings as suggested by findbugs</summary>
      <description>Integer.valueOf favored instead of new Integer() map.entrySet() favored instead of map.keySet()</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-8-27 01:00:00" id="21400" opendate="2018-10-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>correct spelling error of &amp;#39;initilize&amp;#39; in comment</summary>
      <description>When I learned the code of HBase-RPC,I found a spelling error in the comment.Is the word "initilize" should be "initialize"?</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.1,2.1.6</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.BlockingRpcConnection.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-12-31 01:00:00" id="21413" opendate="2018-10-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Empty meta log doesn&amp;#39;t get split when restart whole cluster</summary>
      <description>After I restart whole cluster, there is a splitting directory still exists on hdfs. Then I found there is only an empty meta wal file in it. I'll dig into this later.</description>
      <version>2.1.1,2.0.2</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.2,2.0.4</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterWalManager.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-12-31 01:00:00" id="21414" opendate="2018-10-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>StoreFileSize growth rate metric</summary>
      <description>A metric on the growth rate of storefile sizes would be nice to have as a way of monitoring traffic patterns. I know you can get the same insight from graphing the delta on the storeFileSize metric, but not all metrics visualization tools support that</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsRegionServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperStub.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-11-1 01:00:00" id="21417" opendate="2018-11-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Pre commit build is broken due to surefire plugin crashes</summary>
      <description>The recent builds are all failed with[ERROR] ExecutionException The forked VM terminated without properly saying goodbye. VM crash or System.exit called?[ERROR] Command was /bin/sh -c cd /testptch/hbase/hbase-rsgroup &amp;&amp; /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java -enableassertions -Dhbase.build.id=2018-10-31T11:09:36Z -Xmx2800m -Djava.security.egd=file:/dev/./urandom -Djava.net.preferIPv4Stack=true -Djava.awt.headless=true -jar /testptch/hbase/hbase-rsgroup/target/surefire/surefirebooter3799876849632796400.jar /testptch/hbase/hbase-rsgroup/target/surefire 2018-10-31T11-09-52_393-jvmRun1 surefire4495583426680149115tmp surefire_05657090267882138674tmp[ERROR] Error occurred in starting fork, check output in log[ERROR] Process Exit Code: 1risdenk provided some useful reference:https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=911925https://github.com/carlossg/docker-maven/issues/90https://github.com/carlossg/docker-maven/issues/92It seems to be an OpenJDK issue.Let's see if there are any workarounds.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.3.3,2.2.0,2.0.3,1.4.9,2.1.2,1.2.9</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-11-1 01:00:00" id="21424" opendate="2018-11-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change flakies and nightlies so scheduled less often</summary>
      <description>Infra wrote us:Chris Thistlethwaite &lt;christ@apache.org&gt;9:09 AM (25 minutes ago) to dev, teamGreetings!During the Jenkins outage yesterday I noticed a ton of builds fromHBase-Flaky-Tests https://builds.apache.org/view/H-L/view/HBase/job/HBase-Flaky-Tests/ inthe queue. Turns out this runs a bunch of pipeline builds every hourwhich clogs up Jenkins, both for you and other projects. For example,branch-2.0 is currently queuing 3 builds, waiting on the 4th to finish,and it's also behind the HBase Nightly.That brings me to HBase Nightly https://builds.apache.org/view/H-L/view/HBase/job/HBase%20Nightly/ itruns every 6 hours, which is a bit excessive for a nightly build whichby definition should be once a day. Especially as it gets dangerouslyclose to running into itself as builds currently around 4-5 hours ofbuild time.I suggest something more like Flaky-Tests every 6 hours and the Nightlyonce a day. If you agree to these changes, feel free to update Jenkins.Otherwise, I'll update the jobs in the next few days if there is noresponse.Please add team@infra.apache.org and/or my address to any replies aswe're not subbed to your dev list.Thank you,Chris T.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.0.3,1.4.9,2.1.2,1.2.9</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.flaky-tests.run-flaky-tests.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2018-7-14 01:00:00" id="21606" opendate="2018-12-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document use of the meta table load metrics added in HBASE-19722</summary>
      <description>HBASE-19722 added a great new tool for figuring out where cluster load is coming from. Needs a section in the ref guide When should I use this? Why shouldn't I use it all the time? What does using it look like? How do I use it?I think all the needed info for making something to answer these questions is in the discussion on HBASE-19722</description>
      <version>3.0.0-alpha-1,1.5.0,1.4.6,2.2.0,2.0.2,2.1.3</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,2.0.6,2.2.1,2.1.6,1.4.11</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-1-19 01:00:00" id="21618" opendate="2018-12-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scan with the same startRow(inclusive=true) and stopRow(inclusive=false) returns one result</summary>
      <description>I expect the following code to return none result, but still return a row:byte[] rowkey = "some key existed";Scan scan = new Scan();scan.withStartRow(rowkey, true);scan.withStopRow(rowkey, false);htable.getScanner(scan);</description>
      <version>2.0.2</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.2,2.0.4,1.4.10</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.protobuf.TestProtobufUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannersFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide3.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.shaded.protobuf.TestProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-3-1 01:00:00" id="21976" opendate="2019-3-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Deal with RetryImmediatelyException for batching request</summary>
      <description/>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.4</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncBatchRpcRetryingCaller.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-3-2 01:00:00" id="21978" opendate="2019-3-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Should close AsyncRegistry if we fail to get cluster id when creating AsyncConnection</summary>
      <description/>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.4</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionFactory.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-3-21 01:00:00" id="22077" opendate="2019-3-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expose sleep time as a command line argument of IntergationTestBackupRestore</summary>
      <description>Extend command line arguments of IntergationTestBackupRestore with a sleep time of chaos monkey options to be able to setup policy of region server restarts more granularly.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestBackupRestore.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2010-6-10 01:00:00" id="2208" opendate="2010-2-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>TableServers # processBatchOfRows - converts from List to [ ] - Expensive copy</summary>
      <description>With autoFlush to false and a large write buffer on HTable, when we write bulk puts - TableServer # processBatchOfRows , convert the input (List) to an [ ] , before sending down the wire. With a write buffer as large as 20 MB , that becomes an expensive copy when we do - list.toArray(new T[ ] ). May be - should we change the wire protocol to support List as well , and then revisit this to prevent the bulk copy ?Batch b = new Batch(this) { @Override int doCall(final List&lt;Row&gt; currentList, final byte [] row, final byte [] tableName) throws IOException, RuntimeException { *final Put [] puts = currentList.toArray(PUT_ARRAY_TYPE);* return getRegionServerWithRetries(new ServerCallable&lt;Integer&gt;(this.c, tableName, row) { public Integer call() throws IOException { return server.put(location.getRegionInfo().getRegionName(), puts); } }); }</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HRegionInterface.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-4-30 01:00:00" id="22135" opendate="2019-3-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>AsyncAdmin will not refresh master address</summary>
      <description>This is a big problem... If we stop the active master and promote the backup master, all methods in AsyncAdmin, which need to connect the master will fail as they try to connect to the old active master forever...</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.5</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncMetaRegionLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncMasterRequestRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncConnectionImpl.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-10-4 01:00:00" id="23118" opendate="2019-10-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[RELEASE SCRIPTS] Allow creating a RC from an existing tag</summary>
      <description>Generating the CHANGES.md requires some manual works such as checking whether the things in git are the same with on jira, so I'd like to do this manually and also make the tag manually.So I think the release scripts should have the ability to start making a release from an existing tag, instead of always start from the very beginning where we will generate and commit CHANGES.md.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.create-release.release-util.sh</file>
      <file type="M">dev-support.create-release.do-release.sh</file>
    </fixedFiles>
  </bug>
</bugrepository>