<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="HBASE">
  <bug fixdate="2014-12-20 01:00:00" id="12735" opendate="2014-12-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Refactor TAG so it can live as unit test and as an integration test</summary>
      <description>Parent task moved TAG to IT wholesale. This is about keeping a bit of ACID coverage going in UT. Jon offered to refactor TAG so can live in IT and UT.</description>
      <version>None</version>
      <fixedVersion>1.0.0,1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestAcidGuarantees.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-12-22 01:00:00" id="12738" opendate="2014-12-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Chunk Ref Guide into file-per-chapter</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.upgrading.xml</file>
      <file type="M">src.main.docbkx.performance.xml</file>
      <file type="M">src.main.docbkx.book.xml</file>
      <file type="M">src.main.docbkx.hbase-default.xml</file>
      <file type="M">src.main.docbkx.configuration.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-2-21 01:00:00" id="12897" opendate="2015-1-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Minimum memstore size is a percentage</summary>
      <description>We have a cluster which is optimized for random reads. Thus we have a large block cache and a small memstore. Currently our heap is 20GB and we wanted to configure the memstore to take 4% or 800MB. Right now the minimum memstore size is 5%. What do you guys think about reducing the minimum size to 1%? Suppose we log a warning if the memstore is below 5% but allow it?What do you folks think?</description>
      <version>0.98.10,1.1.0,2.0.0</version>
      <fixedVersion>1.0.0,1.1.0,0.98.11</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.util.HeapMemorySizeUtil.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-2-10 01:00:00" id="12999" opendate="2015-2-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make foreground_start return the correct exit code</summary>
      <description/>
      <version>1.1.0,0.98.11,2.0.0</version>
      <fixedVersion>1.1.0,0.98.11,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase-daemon.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-11-11 01:00:00" id="13014" opendate="2015-2-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Java Tool For Region Moving</summary>
      <description>As per discussion on HBASE-12989 we should move the functionality of region_mover.rb into a Java tool and use region_mover.rb only only as a wrapper around it.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestRegionMover.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionMover.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-2-18 01:00:00" id="13067" opendate="2015-2-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix caching of stubs to allow IP address changes of restarted remote servers</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionManager.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-2-20 01:00:00" id="13081" opendate="2015-2-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Branch precommit builds are not updating to branch head before patch application</summary>
      <description>See for example https://builds.apache.org/job/PreCommit-HBASE-Build/12922//consolegit checkout 0.98Previous HEAD position was 03d8918... HBASE-13069 Thrift Http Server returns an error code of 500 instead of 401 when authentication fails (Srikanth Srungarapu)Switched to branch '0.98'Your branch is behind 'origin/0.98' by 48 commits, and can be fast-forwarded. (use "git pull" to update your local branch)git statusOn branch 0.98Your branch is behind 'origin/0.98' by 48 commits, and can be fast-forwarded. (use "git pull" to update your local branch)Untracked files: (use "git add &lt;file&gt;..." to include in what will be committed) patchprocess/nothing added to commit but untracked files present (use "git add" to track)Because the local tree is 48 commits behind the head of the 0.98 branch, the contributor's patch based on the head of 0.98 branch cannot cleanly apply.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2015-2-26 01:00:00" id="13111" opendate="2015-2-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>truncate_preserve command is failing with undefined method error</summary>
      <description>hbase(main):001:0&gt; truncate_preserve 't1'Truncating 't1' table (it may take a while):ERROR: undefined method `getTable' for nil:NilClassHere is some help for this command: Disables, drops and recreates the specified table while still maintaing the previous region boundaries.</description>
      <version>1.0.0,1.1.0,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.11,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-3-27 01:00:00" id="13123" opendate="2015-2-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Minor bug in ROW bloom filter</summary>
      <description>While checking the code for Bloom filter found that while checking if a key passes the ROW bloom check we try to create a bloom key. The bloom key should be constructed only with the row part of the key. But try to form the bloom key including the meta data part of the key.</description>
      <version>1.0.0,1.1.0,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.11,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-3-5 01:00:00" id="13156" opendate="2015-3-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix minor rat violation recently introduced (asciidoctor.css).</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2015-3-11 01:00:00" id="13208" opendate="2015-3-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Patch build should match the patch filename and not the whole relative URL in findBranchNameFromPatchName</summary>
      <description>In HBASE-1319 we saw that the patch got applied to the wrong branch, the problem is findBranchNameFromPatchName matching a regex that contains wildcard symbols against the whole URL, in this case the regex is 0.94 and the relativePatchURL is /jira/secure/attachment/12703942/HBASE-13193-v4.patch where 0394 is a match.Thanks to jonathan.lawlor for reporting this.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2015-3-12 01:00:00" id="13218" opendate="2015-3-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Correct the syntax shown for using ExportSnapshot tool in the book</summary>
      <description>It is $ bin/hbase class org.apache.hadoop.hbase.snapshot.ExportSnapshot -snapshot MySnapshot -copy-to hdfs://srv2:8082/hbase -mappers 16It should be$ bin/hbase org.apache.hadoop.hbase.snapshot.ExportSnapshot -snapshot MySnapshot -copy-to hdfs://srv2:8082/hbase -mappers 16</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-3-13 01:00:00" id="13227" opendate="2015-3-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>LoadIncrementalHFile should skip non-files inside a possible family-dir</summary>
      <description>if we have random files/dirs inside the bulkload family dir, we should try to skip them.</description>
      <version>1.0.0,1.1.0,0.98.11,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-3-13 01:00:00" id="13228" opendate="2015-3-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create procedure v2 branch and add it to QA branch list</summary>
      <description>to develop Procedure V2 quickly, we are going to commit stuff to an hbase-12439 branch.In theory we can have QA running if the patch name is HBASE-xyz-hbase-12439.patch</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.properties</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-3-15 01:00:00" id="13244" opendate="2015-3-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Test delegation token generation with kerberos enabled</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.HBaseKerberosUtils.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-3-17 01:00:00" id="13265" opendate="2015-3-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make thrift2 usable from c++</summary>
      <description>Currently the c++ code generated from our thrift2 idl doesn't compile. Mostly this is a naming issue for parameters.</description>
      <version>1.0.0,1.1.0,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.resources.org.apache.hadoop.hbase.thrift2.hbase.thrift</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-3-19 01:00:00" id="13281" opendate="2015-3-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>&amp;#39;hbase.bucketcache.size&amp;#39; description in hbase book is not correct</summary>
      <description>The description about 'hbase.bucketcache.size' is not correct. We either specify it as a float or in MB's and the default value that is mentioned is never used.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.hbase-default.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-4-19 01:00:00" id="13289" opendate="2015-3-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>typo in splitSuccessCount metric</summary>
      <description>Our split metrics have a misspelled Count and it shows up in our jmx metrics "splitSuccessCounnt" : 0,</description>
      <version>1.0.0,0.98.10,1.1.0,0.98.11,0.98.12,0.98.10.1,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2015-3-21 01:00:00" id="13309" opendate="2015-3-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Some tests do not reset EnvironmentEdgeManager</summary>
      <description>while playing with client timeouts, I hit lots of flakys in HBaseFsck. the cause was just an EnvironmentEdge.inject() not followed by a reset().looks like TestFsUtils and TestHRegion are the only other two that have a missing reset(). all the other tests using inject() seems to be written properly.</description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestFSUtils.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-4-20 01:00:00" id="1331" opendate="2009-4-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Lower the default scanner caching value</summary>
      <description>The current default value for the scanner caching is 30; this causing headaches to many new users who may use a row from a scanner for more than 60 seconds. Let's set it at 1, then folks will be able to optimize.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-3-24 01:00:00" id="13326" opendate="2015-3-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Disabled table can&amp;#39;t be enabled after HBase is restarted</summary>
      <description>The folks at Intel discovered a pretty nasty bug in 1.0 and 1.1 (but not master). Steps to reproduce:1. Create a table, any table.2. Disable the table.3. Restart HBase.4. Try enabling the table.The table won't become enabled and the master web UI will indicate a never-ending region in transition. Also worth noting is that mbertozzi dug in and noted that this isn't happening in the master branch.</description>
      <version>1.0.0,1.1.0,0.98.12</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-8-26 01:00:00" id="13339" opendate="2015-3-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update default Hadoop version to latest for master</summary>
      <description>Current default Hadoop version is getting a little long in the tooth. We should update to the latest version. The latest version is backwards compatible with 2.5.1's dfs and mr so this should be painless.</description>
      <version>1.1.0,2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
      <file type="M">dev-support.test-patch.properties</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-3-26 01:00:00" id="13342" opendate="2015-3-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix incorrect interface annotations</summary>
      <description>Still some old annotations. Have slipped in. Lets remove them and add in a patch check for them.</description>
      <version>1.1.0,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.ReplayHLogKey.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.RegionReplicaFlushHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.RegionStateListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.namespace.NamespaceTableAndRegionInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.namespace.NamespaceStateManager.java</file>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-3-28 01:00:00" id="13355" opendate="2015-3-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>QA bot reports checking javac twice</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-4-1 01:00:00" id="13372" opendate="2015-4-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unit tests for SplitTransaction and RegionMergeTransaction listeners</summary>
      <description>We have new Listener interfaces in SplitTransaction and RegionMergeTransaction. There are no use cases for these yet, nor unit tests. We should have unit tests for these that do something just a bit nontrivial so as to provide a useful example.</description>
      <version>1.1.0,2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionMergeTransaction.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-4-1 01:00:00" id="13374" opendate="2015-4-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Small scanners (with particular configurations) do not return all rows</summary>
      <description>I recently ran into a couple data loss issues with small scans. Similar to HBASE-13262, these issues only appear when scans are configured in such a way that the max result size limit is reached before the caching limit is reached. As far as I can tell, this issue affects branches 0.98+I should note that after investigation it looks like the root cause of these issues is not the same as HBASE-13262. Rather, these issue are caused by errors in the small scanner logic (I will explain in more depth below). Furthermore, I do know that the solution from HBASE-13262 has not made its way into small scanners (it is being addressed in HBASE-13335). As a result I made sure to test these issues with the patch from HBASE-13335 applied and I saw that they were still present.The following two issues have been observed (both lead to data loss):1. When a small scan is configured with a caching value of Integer.MAX_VALUE, and a maxResultSize limit that is reached before the region is exhausted, integer overflow will occur. This eventually leads to a preemptive skip of the regions.2. When a small scan is configured with a maxResultSize that is smaller than the size of a single row, the small scanner will jump between regions preemptively. This issue seems to be because small scanners assume that, unless a region is exhausted, at least 2 rows will be returned from the server. This assumption isn't clearly state in the small scanners but is implied through the use of skipRowOfFirstResult.Again, I would like to stress that the root cause of these issues is NOT related to the cause of HBASE-13262. These issues occur because of inappropriate assumption made in the small scanner logic. The inappropriate assumptions are:1. Integer overflow will not occur when incrementing caching2. At least 2 rows will be returned from the server unless the region has been exhaustedI am attaching a patch that contains tests to display these issues. If these issues should be split into separate JIRAs please let me know.</description>
      <version>1.0.0,1.1.0,0.98.13,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannersFromClientSide.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallReversedScanner.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-4-6 01:00:00" id="13409" opendate="2015-4-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add categories to uncategorized tests</summary>
      <description>A couple tests without categories were flagged recently by TestCheckTestClasses in a precommit build.</description>
      <version>1.1.0,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.filter.TestLongComparator.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestClientExponentialBackoff.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-5-23 01:00:00" id="1341" opendate="2009-4-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create HTable Pooler</summary>
      <description>A client class that takes care of properly pooling HTable references for use in multi-threaded, low-latency Java clients.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2015-4-20 01:00:00" id="13516" opendate="2015-4-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Increase PermSize to 128MB</summary>
      <description>HBase uses ~40MB, and with Phoenix we use ~56MB of Perm space out of 64MB by default. Every Filter and Coprocessor increases that.Running out of perm space triggers a stop the world full GC of the entire heap. We have seen this in misconfigured cluster. Should we default to -XX:PermSize=128m -XX:MaxPermSize=128m out of the box as a convenience for users?</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.hbase-env.sh</file>
      <file type="M">conf.hbase-env.cmd</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2015-4-24 01:00:00" id="13554" opendate="2015-4-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update book clarifying API stability guarantees</summary>
      <description>From the "Clarifying interface evolution freedom in patch releases" thread on dev@h.a.oSeems we have consensus that "HBase uses Semantic Versioning" isn't quite correct (or desired) at the moment. Update the documentation to make sure we're not misrepresenting any guarantees to users.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-4-25 01:00:00" id="13563" opendate="2015-4-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add missing table owner to AC tests.</summary>
      <description>As per the description.</description>
      <version>None</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-4-28 01:00:00" id="13586" opendate="2015-4-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update book on Hadoop and Java supported versions for 1.1.x</summary>
      <description>Should update http://hbase.apache.org/book.html#basic.prerequisites with the latest info.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2009-5-30 01:00:00" id="1361" opendate="2009-4-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Disable bloom filters</summary>
      <description>Bloomfilters currently have problems and nobody uses them. Disable this feature for now. Bring it back as part of continuing/ongoing work on the read and write paths, e.g. 1249 and HFile related open issues.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-5-2 01:00:00" id="13611" opendate="2015-5-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>update clover to work for current versions</summary>
      <description>our clover profile uses a super old version of the clover plugin, sufficiently old that it requires maven 2.update to use ~4.x clover version and make sure things work.</description>
      <version>None</version>
      <fixedVersion>1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.SplitLogCounters.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.TestInterfaceAudienceAnnotations.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2015-11-5 01:00:00" id="13622" opendate="2015-5-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>document upgrade rollback</summary>
      <description>I have some docs on doing a rollback of an hbase upgrade that are currently vendor specific. polish them up, make them suitable for HBase generally, and add them to the ref guide.</description>
      <version>0.98.0,1.0.0,1.1.0</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-5-3 01:00:00" id="1366" opendate="2009-5-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBASE-1342 broke splitting (broke build)</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HAbstractScanner.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-5-11 01:00:00" id="13661" opendate="2015-5-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Correct binary compatibility issues discovered in 1.1.0RC0</summary>
      <description>Over on the 1.1.0RC0 VOTE thread, Enis discovered some errors in InterfaceAudience annotations. Let's fix them.Filed by ndimiduk on enis's behalf.</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALEdit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.namespace.NamespaceAuditor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MetricsMaster.java</file>
      <file type="M">hbase-rest.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.StorageClusterStatusMessage.proto</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.java</file>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.model.StorageClusterStatusModel.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.ClusterStatus.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.CorruptedWALProcedureStoreException.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.ProcedureStoreTracker.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterSource.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.AuthUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ServerLoad.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Result.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-6-11 01:00:00" id="13666" opendate="2015-5-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>book.pdf is not renamed during site build</summary>
      <description>Noticed this while testing HBASE-13665. Looks like the post-site hook is broken or not executed, so the file book.pdf is not copied over to the expected name apache_hbase_reference_guide.pdf.</description>
      <version>None</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.1,1.3.0,2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">dev-support.test-patch.sh</file>
      <file type="M">dev-support.publish.hbase.website.sh</file>
      <file type="M">dev-support.make.rc.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-5-15 01:00:00" id="13694" opendate="2015-5-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>CallQueueSize is incorrectly decremented until the response is sent</summary>
      <description>We should decrement the CallQueueSize as soon as we no longer need the call around, e.g. after RpcServer.CurCall.set(null) otherwise we will be only pushing back other client requests while we send the response back to the client that originated the call.</description>
      <version>1.1.0,0.98.12,1.0.2,1.2.0,2.0.0</version>
      <fixedVersion>1.2.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.CallRunner.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-5-15 01:00:00" id="13699" opendate="2015-5-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expand information about HBase quotas</summary>
      <description>See HBASE-13398 and http://blog.cloudera.com/blog/2014/12/new-in-cdh-5-2-improvements-for-running-multiple-workloads-on-a-single-hbase-cluster/.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-5-20 01:00:00" id="13725" opendate="2015-5-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[documentation] Pseudo-Distributed Local Install can link to hadoop instructions</summary>
      <description>The below is no longer true, we can link to http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.htmlHadoop ConfigurationThis procedure assumes that you have configured Hadoop and HDFS on your local system and or a remote system, and that they are running and available. It also assumes you are using Hadoop 2. Currently, the documentation on the Hadoop website does not include a quick start for Hadoop 2, but the guide at link:http://www.alexjf.net/blog/distributed-systems/hadoop-yarn-installation-definitive-guide is a good starting point.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.getting.started.adoc</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2009-1-5 01:00:00" id="1373" opendate="2009-5-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update Thrift to use compact/framed protocol</summary>
      <description>TCompactProtocol/TFramedTransport and nonblocking server option promises better efficiency and performance improvements. Consider moving HBase Thrift bits to this when full platform support is ready for TCompactProtocol.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.package.html</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-5-22 01:00:00" id="13746" opendate="2015-5-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>list_replicated_tables command is not listing table in hbase shell.</summary>
      <description>IN HBase shell prompt execute the following commandlist_replicated_tableshbase(main):014:0&gt; list_replicated_tablesTABLE:COLUMNFAMILY ReplicationTypeERROR: undefined method `TNAME' for Java::OrgApacheHadoopHbaseClientReplication::ReplicationAdmin:ClassHere is some help for this command:List all the tables and column families replicated from this cluster hbase&gt; list_replicated_tables hbase&gt; list_replicated_tables 'abc.*' list.select {|s| pattern.match(s.get(ReplicationAdmin.TNAME))}</description>
      <version>1.1.0,0.98.13,1.0.2,2.0.0</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.replication.admin.rb</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2015-5-28 01:00:00" id="13801" opendate="2015-5-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hadoop src checksum is shown instead of HBase src checksum in master / RS UI</summary>
      <description>Simple bug. We are showing the Hadoop's source MD5 checksum in the master UI instead of the HBase's one.</description>
      <version>None</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2015-6-30 01:00:00" id="13816" opendate="2015-5-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Build shaded modules only in release profile</summary>
      <description>Shaded modules are great, but not needed in the regular build + test cycle. I noticed that around 30-40% of the build time goes in the actual shading. I think we can just build the shaded jars in the release profile. hadoopqe and mvn publishing should not be affected.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shaded.hbase-shaded-server.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-client.pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2015-2-4 01:00:00" id="13839" opendate="2015-6-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix AssgnmentManagerTmpl.jamon issues (coloring, content etc.)</summary>
      <description>The template for the RIT in the Master status page, AssignmentManagerTmpl.jamon) has a few issues: The oldest RIT should not be red, looks like a failed entryThe RIT entries should be for example yellow/amber when over the threshold time, and red if 2x the threshold - or red for the oldest once over the threshold. Region count over RIT threshold should only be colored if &gt; 0The summary line (first of two) should not be colored unless there is a value &gt; 0 in it. Color is overriden by table-stripped CSS style!The Bootstrap stylesheet cancels out the hardcoded coloring! The table-stripped resets the conditional coloring and should be fixed. Best is to use "alert-warning" etc. that come from the Bootstrap theme stylesheet. That should maybe already work in combination with the "table-stripped" from the same. Should sort descending by timeCurrently the list of regions is sorted by encoded region name. Better is to have the table sorted by RIT time descending.We should also think about a pagination option for the currently hardcoded 100 entries max. Maybe a separate issue?</description>
      <version>1.1.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterStatusServlet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-7-8 01:00:00" id="13861" opendate="2015-6-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>BucketCacheTmpl.jamon has wrong bucket free and used labels</summary>
      <description>See this from the template, and note the label and actual values for the last two columns.&lt;table class="table table-striped"&gt; &lt;tr&gt; &lt;th&gt;Bucket Offset&lt;/th&gt; &lt;th&gt;Allocation Size&lt;/th&gt; &lt;th&gt;Free Count&lt;/th&gt; &lt;th&gt;Used Count&lt;/th&gt; &lt;/tr&gt;&lt;%for Bucket bucket: buckets %&gt; &lt;tr&gt; &lt;td&gt;&lt;% bucket.getBaseOffset() %&gt;&lt;/td&gt; &lt;td&gt;&lt;% bucket.getItemAllocationSize() %&gt;&lt;/td&gt; &lt;td&gt;&lt;% bucket.getFreeBytes() %&gt;&lt;/td&gt; &lt;td&gt;&lt;% bucket.getUsedBytes() %&gt;&lt;/td&gt; &lt;/tr&gt;They are labeled "counts" but are "bytes", duh.</description>
      <version>1.1.0</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl.jamon</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2015-8-11 01:00:00" id="13889" opendate="2015-6-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix hbase-shaded-client artifact so it works on hbase-downstreamer</summary>
      <description>The hbase-shaded-client artifact was introduced in HBASE-13517. Thank you very much for this, as I am new to Java building and was having a very slow-moving time resolving conflicts. However, the shaded client artifact seems to be missing javax.xml.transform.TransformerException. I examined the JAR, which does not have this package/class.Steps to reproduce:Java: package com.mycompany.app; import org.apache.hadoop.conf.Configuration; import org.apache.hadoop.hbase.HBaseConfiguration; import org.apache.hadoop.hbase.client.Connection; import org.apache.hadoop.hbase.client.ConnectionFactory; public class App { public static void main( String[] args ) throws java.io.IOException { Configuration config = HBaseConfiguration.create(); Connection connection = ConnectionFactory.createConnection(config); } }POM:&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.mycompany.app&lt;/groupId&gt; &lt;artifactId&gt;my-app&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;my-app&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt; &lt;artifactId&gt;hbase-shaded-client&lt;/artifactId&gt; &lt;version&gt;1.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; Run:$ mvn exec:java -Dexec.mainClass="com.mycompany.app.App"[INFO] Scanning for projects...[INFO] [INFO] ------------------------------------------------------------------------[INFO] Building my-app 1.0-SNAPSHOT[INFO] ------------------------------------------------------------------------[INFO] [INFO] --- exec-maven-plugin:1.4.0:java (default-cli) @ my-app ---[WARNING] java.lang.reflect.InvocationTargetException at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.codehaus.mojo.exec.ExecJavaMojo$1.run(ExecJavaMojo.java:293) at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.NoClassDefFoundError: org/apache/hadoop/hbase/shaded/javax/xml/transform/TransformerException at com.mycompany.app.App.main(App.java:17) ... 6 moreCaused by: java.lang.ClassNotFoundException: org.apache.hadoop.hbase.shaded.javax.xml.transform.TransformerException at java.net.URLClassLoader$1.run(URLClassLoader.java:366) at java.net.URLClassLoader$1.run(URLClassLoader.java:355) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:354) at java.lang.ClassLoader.loadClass(ClassLoader.java:425) at java.lang.ClassLoader.loadClass(ClassLoader.java:358) ... 7 more[INFO] ------------------------------------------------------------------------[INFO] BUILD FAILURE[INFO] ------------------------------------------------------------------------[INFO] Total time: 2.388 s[INFO] Finished at: 2015-06-11T13:23:21-04:00[INFO] Final Memory: 10M/111M[INFO] ------------------------------------------------------------------------</description>
      <version>1.1.0,1.1.0.1</version>
      <fixedVersion>1.2.0,1.1.2,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-shaded.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-12-16 01:00:00" id="13907" opendate="2015-6-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document how to deploy a coprocessor</summary>
      <description>Capture this information:&gt; Where are the dependencies located for these classes? Is there a path on HDFS or local disk that dependencies need to be placed so that each RegionServer has access to them?It is suggested to bundle them as a single jar so that RS can load the whole jar and resolve dependencies. If you are not able to do that, you need place the dependencies in regionservers class path so that they are loaded during RS startup. Do either of these options work for you? Btw, you can load the coprocessors/filters into path specified by hbase.dynamic.jars.dir &amp;#91;1&amp;#93;, so that they are loaded dynamically by regionservers when the class is accessed (or you can place them in the RS class path too, so that they are loaded during RS JVM startup).&gt; How would one deploy these using an automated system? (puppet/chef/ansible/etc)You can probably use these tools to automate shipping the jars to above locations?&gt; Tests our developers have done suggest that simply disabling a coprocessor, replacing the jar with a different version, and enabling the coprocessor again does not load the newest version. With that in mind how does one know which version is currently deployed and enabled without resorting to parsing `hbase shell` output or restarting hbase?Actually this is a design issue with current classloader. You can't reload a class in a JVM unless you delete all the current references to it. Since the current JVM (classloader) has reference to it, you can't overwrite it unless you kill the JVM, which is equivalent to restarting it. So you still have the older class loaded in place. For this to work, classloader design should be changed. If it works for you, you can rename the coprocessor class name and the new version of jar and RS loads it properly.&gt; Where does logging go, and how does one access it? Does logging need to be configured in a certain way?Can you please specify which logging you are referring to?&gt; Where is a good location to place configuration files?Same as above, are these hbase configs or something else? If hbase configs, are these gateway configs/server side?</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.cp.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-6-18 01:00:00" id="13930" opendate="2015-6-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Exclude Findbugs packages from shaded jars</summary>
      <description>Looking at 1.1.1RC0 shaded artifacts, looks like classes from find bugs are under the edu prefix and are not shaded. We should exclude find bugs from the shaded builds, and/or shade shade the edu prefix as well.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.1.2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shaded.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-8-3 01:00:00" id="14021" opendate="2015-7-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Quota table has a wrong description on the UI</summary>
      <description/>
      <version>1.1.0</version>
      <fixedVersion>1.2.0,1.1.2,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2015-9-7 01:00:00" id="14193" opendate="2015-8-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove support for direct upgrade from pre-0.96 versions</summary>
      <description>As discussed on the mailing list this will remove all support for upgrades from pre-0.96 versions.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSTableDescriptorMigrationToSubdir.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">bin.hbase.cmd</file>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-8-19 01:00:00" id="14260" opendate="2015-8-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>don&amp;#39;t build javadocs for hbase-protocol module</summary>
      <description>I'm not sure I have all the affected versions, but it seems that something is amiss in making our javadocs: mvn -Papache-release -Prelease -DskipTests clean package... SNIP ...[INFO] ------------------------------------------------------------------------[INFO] Reactor Summary:[INFO] [INFO] Apache HBase ....................................... SUCCESS [ 11.149 s][INFO] Apache HBase - Checkstyle .......................... SUCCESS [ 1.249 s][INFO] Apache HBase - Resource Bundle ..................... SUCCESS [ 0.539 s][INFO] Apache HBase - Annotations ......................... SUCCESS [ 4.438 s][INFO] Apache HBase - Protocol ............................ SUCCESS [10:15 min][INFO] Apache HBase - Common .............................. SUCCESS [ 48.465 s][INFO] Apache HBase - Procedure ........................... SUCCESS [ 14.375 s][INFO] Apache HBase - Client .............................. SUCCESS [ 45.187 s][INFO] Apache HBase - Hadoop Compatibility ................ SUCCESS [ 6.998 s][INFO] Apache HBase - Hadoop Two Compatibility ............ SUCCESS [ 14.891 s][INFO] Apache HBase - Prefix Tree ......................... SUCCESS [ 14.214 s][INFO] Apache HBase - Server .............................. SUCCESS [02:01 min][INFO] Apache HBase - Testing Util ........................ SUCCESS [ 12.779 s][INFO] Apache HBase - Thrift .............................. SUCCESS [01:15 min][INFO] Apache HBase - Shell ............................... SUCCESS [ 6.649 s][INFO] Apache HBase - Integration Tests ................... SUCCESS [ 6.429 s][INFO] Apache HBase - Examples ............................ SUCCESS [ 13.200 s][INFO] Apache HBase - Rest ................................ SUCCESS [ 27.831 s][INFO] Apache HBase - Assembly ............................ SUCCESS [ 19.400 s][INFO] Apache HBase - Shaded .............................. SUCCESS [ 0.419 s][INFO] Apache HBase - Shaded - Client ..................... SUCCESS [ 23.707 s][INFO] Apache HBase - Shaded - Server ..................... SUCCESS [ 43.654 s][INFO] Apache HBase - Spark ............................... SUCCESS [02:22 min][INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 21:13 min[INFO] Finished at: 2015-08-19T15:48:00-05:00[INFO] Final Memory: 181M/1513M[INFO] ------------------------------------------------------------------------</description>
      <version>0.98.0,1.0.0,1.1.0,1.2.0,2.0.0</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.2,1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-protocol.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-10-20 01:00:00" id="14271" opendate="2015-8-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve Nexus staging instructions</summary>
      <description>Refine the Nexus staging instructions a bit. (A promise I made a long time ago.)</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-10-9 01:00:00" id="14587" opendate="2015-10-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Attach a test-sources.jar for hbase-server</summary>
      <description>It'd be nice to attach a test-sources jar alongside the others as part of the build, to provide test resources.</description>
      <version>1.1.0</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-8-2 01:00:00" id="14745" opendate="2015-11-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Shade the last few dependencies in hbase-shaded-client</summary>
      <description>junit hadoop common</description>
      <version>1.1.0,1.2.0</version>
      <fixedVersion>1.2.0,1.3.0,1.1.13,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-shaded.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-1-23 01:00:00" id="15036" opendate="2015-12-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update HBase Spark documentation to include bulk load with thin records</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.spark.adoc</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2016-8-17 01:00:00" id="15666" opendate="2016-4-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>shaded dependencies for hbase-testing-util</summary>
      <description>Folks that make use of our shaded client but then want to test things using the hbase-testing-util end up getting all of our dependencies again in the test scope.</description>
      <version>1.1.0,1.2.0</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,2.2.1,2.1.6,1.4.11</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">NOTICE.txt</file>
      <file type="M">hbase-shaded.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-with-hadoop-check-invariants.src.test.resources.ensure-jars-have-correct-contents.sh</file>
      <file type="M">hbase-shaded.hbase-shaded-check-invariants.src.test.resources.ensure-jars-have-correct-contents.sh</file>
      <file type="M">hbase-it.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-5-18 01:00:00" id="15667" opendate="2016-4-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add more clarity to Reference Guide related to importing Eclipse Formatter</summary>
      <description>In Hbase Reference Guide: 141.1.1. Code Formattingin procedure bullet point 2: It is not clear what the menu item is. It should be changed to the following:"In Preferences, click Java-&gt;Code Style-&gt;Formatter"</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-7-31 01:00:00" id="15925" opendate="2016-5-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>compat-module maven variable not evaluated</summary>
      <description>Looks like we've regressed on HBASE-8488. Have a look at the dependency artifacts list on http://mvnrepository.com/artifact/org.apache.hbase/hbase-testing-util/1.2.1. Notice the direct dependency's artifactId is ${compat.module}.</description>
      <version>1.0.0,1.1.0,1.2.0,1.2.1,1.0.3,1.1.5</version>
      <fixedVersion>1.3.0,1.2.2,1.1.6,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-7-7 01:00:00" id="15985" opendate="2016-6-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>clarify promises about edits from replication in ref guide</summary>
      <description>we should make clear in a call out that replication only provides at-least-once delivery and doesn't guarantee ordering so that e.g. folks using increments aren't surprised.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2017-5-15 01:00:00" id="18049" opendate="2017-5-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>It is not necessary to re-open the region when MOB files cannot be found</summary>
      <description>In HBASE-17712, we try to re-open the region when store files cannot be found. This is useful for store files in a region, but is not necessary when the MOB files cannot be found, because the store files in a region only contain the references to the MOB files and a re-open of a region doesn't help the lost MOB files.In this JIRA, we will directly throw DNRIOE only when the MOB files are not found in MobStoreScanner and ReversedMobStoreScanner. Other logics keep the same.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HMobStore.java</file>
    </fixedFiles>
  </bug>
  
</bugrepository>