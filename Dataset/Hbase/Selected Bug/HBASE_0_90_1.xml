<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="HBASE">
  <bug fixdate="2018-4-30 01:00:00" id="19890" opendate="2018-1-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Canary usage should document hbase.canary.sink.class config</summary>
      <description>Canary#main uses config hbase.canary.sink.class to instantiate Sink class.The Sink instance affects creation of Monitor.In the refguide for Canary, hbase.canary.sink.class was not mentioned. We should document this config.Additionally, we need to document that using the default sink is not compatible with table parameters as input so the user must change it.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-1-30 01:00:00" id="19891" opendate="2018-1-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Up nightly test run timeout from 6 hours to 8</summary>
      <description>Yesterday, a nightly run for hbase2 passed all unit tests against hadoop2. Hadoop3 tests got cut off at the 6 hour mark, our maximum total run time. This is crazy but for now, just up the max time from 6 to 8 hours to see if we can get a good build in. Can work on breaking this down in subsequent issues. To be clear, the nightly 2.0 runs full test suite against hadoop2 and then hadoop3... this is why it takes a while.</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-2,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-1-30 01:00:00" id="19892" opendate="2018-1-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Checking &amp;#39;patch attach&amp;#39; and yetus 0.7.0 and move to Yetus 0.7.0</summary>
      <description>Yetus-0.7.0 has a fix for the changed Jira behavior that made it so we weren't picking up the latest attached patch. Check it works and if it does move over to yetus 0.7.0</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-2,1.4.2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2018-1-30 01:00:00" id="19899" opendate="2018-1-30 00:00:00" resolution="Won&amp;#39;t Do">
    <buginformation>
      <summary>Dump ulimit -a, fd count, and free output at end of build into system dir</summary>
      <description>We're OOME'ing unable to create threads. I added ulimit -l, free -h, and count of open fds to hadoopqa just now. Add them to the script used by JenkinsFile too.</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-2,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.gather.machine.environment.sh</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2011-10-14 01:00:00" id="3444" opendate="2011-1-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Test to prove Bytes.toBytesBinary and Bytes.toStringBinary() is reversible</summary>
      <description>Bytes.toStringBinary() doesn't escape \.Otherwise the transformation isn't reversiblebyte[] a = {'\', 'x' , '0', '0'}Bytes.toBytesBinary(Bytes.toStringBinary(a)) won't be equal to a</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestBytes.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-2-20 01:00:00" id="3455" opendate="2011-1-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Heap fragmentation in region server</summary>
      <description>Stop-the-world GC pauses have long been a problem in HBase. "Concurrent mode failures" can usually be tuned around by setting the initiating occupancy fraction low, but eventually the heap becomes fragmented and a promotion failure occurs.This JIRA is to do research/experiments about the heap fragmentation issue and possible solutions.</description>
      <version>0.90.1</version>
      <fixedVersion>0.90.1</fixedVersion>
      <type>Brainstorming</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestMemStore.java</file>
      <file type="M">src.main.resources.hbase-default.xml</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.MemStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2011-3-15 01:00:00" id="3533" opendate="2011-2-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow HBASE_LIBRARY_PATH env var to specify extra locations of native libs</summary>
      <description>Would be handy when you have native libs at other spots on the system (eg I often want to test hadoop-lzo changes directly out of its build dir)</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-6-15 01:00:00" id="3537" opendate="2011-2-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[site] Make it so each page of manual allows users comment like mysql&amp;#39;s manual does</summary>
      <description>I like the way the mysql manuals allow users comment, improve or correct mysql manual pages. We should have same.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.customization.xsl</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-3-17 01:00:00" id="3541" opendate="2011-2-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>REST Multi Gets</summary>
      <description>Users currently using the REST interface do not have a way to ask for multiple rows within one http call.For my use case I want to get a set of rows that I know the key before hand. It's a very small percentage of my table and may not be contiguous so the scanner is not the right use-case for me. Currently the http overhead is the largest percentage of my processing time.Ideally I'd like to create a patch that would act very similar to:GET /table/?row[]="rowkey"&amp;row[]="rowkey_two"HTTP/1.1 200 OK{ "Rows":[ &lt;&lt; Array of results equivalent to a single get &gt;&gt;]}This should be pretty backward compatible. As it's just making the row key into a query string.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.rest.TestMultiRowResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.MultiRowResource.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.rest.TableResource.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2011-3-2 01:00:00" id="3589" opendate="2011-3-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>test jar should not include mapred-queues.xml and log4j.properties</summary>
      <description>Right now we include these files in the test jar, which might cause problems when this jar ends up on the MR classpath. Similar to HBASE-3143</description>
      <version>0.90.1</version>
      <fixedVersion>0.90.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-3-3 01:00:00" id="3594" opendate="2011-3-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Rest server fails because of missing asm jar</summary>
      <description>HBASE-3525 turned off the inclusion of transitive dependencies in the hbase/lib/ dir. This means that we no longer get the asm library, which is needed by jersey.</description>
      <version>0.90.1</version>
      <fixedVersion>0.90.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-3-3 01:00:00" id="3595" opendate="2011-3-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>get_counter broken in shell</summary>
      <description>hbase(main):010:0&gt; incr 't', 'r1', 'f1:c1'COUNTER VALUE = 2hbase(main):011:0&gt; get_counter 't', 'r1', 'f1:c1'ERROR: undefined method `first' for #&lt;#&lt;Class:01x79f7abae&gt;:0x73286b10&gt;</description>
      <version>0.90.1</version>
      <fixedVersion>0.90.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.ruby.hbase.table.rb</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2011-3-11 01:00:00" id="3622" opendate="2011-3-11 00:00:00" resolution="Won&amp;#39;t Fix">
    <buginformation>
      <summary>Deadlock in HBaseServer (JVM bug?)</summary>
      <description>On Dmitriy's cluster:"IPC Reader 0 on port 60020" prio=10 tid=0x00002aacb4a82800 nid=0x3a72 waiting on condition [0x00000000429ba000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00002aaabf5fa6d0&gt; (a java.util.concurrent.locks.ReentrantLock$NonfairSync) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158) at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:747) at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:778) at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1114) at java.util.concurrent.locks.ReentrantLock$NonfairSync.lock(ReentrantLock.java:186) at java.util.concurrent.locks.ReentrantLock.lock(ReentrantLock.java:262) at java.util.concurrent.LinkedBlockingQueue.signalNotEmpty(LinkedBlockingQueue.java:103) at java.util.concurrent.LinkedBlockingQueue.put(LinkedBlockingQueue.java:267) at org.apache.hadoop.hbase.ipc.HBaseServer$Connection.processData(HBaseServer.java:985) at org.apache.hadoop.hbase.ipc.HBaseServer$Connection.readAndProcess(HBaseServer.java:946) at org.apache.hadoop.hbase.ipc.HBaseServer$Listener.doRead(HBaseServer.java:522) at org.apache.hadoop.hbase.ipc.HBaseServer$Listener$Reader.run(HBaseServer.java:316) - locked &lt;0x00002aaabf580fb0&gt; (a org.apache.hadoop.hbase.ipc.HBaseServer$Listener$Reader) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)..."IPC Server handler 29 on 60020" daemon prio=10 tid=0x00002aacbc163800 nid=0x3acc waiting on condition [0x00000000462f3000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00002aaabf5e3800&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358) at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1025)"IPC Server handler 28 on 60020" daemon prio=10 tid=0x00002aacbc161800 nid=0x3acb waiting on condition [0x00000000461f2000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00002aaabf5e3800&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358) at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1025...This region server stayed in this state for hours. The reader is waiting to put and the handlers are waiting to take, and they wait on different lock ids. It reminds me of the UseMembar thing about the JVM sometime missing to notify waiters. In any case, that RS needed to be closed in order to get out of that state.</description>
      <version>0.90.1</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-3-11 01:00:00" id="3623" opendate="2011-3-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow non-XML representable separator characters in the ImportTSV tool</summary>
      <description>The current importtsv functionality will not work if one passes a non-XML representable character as the separator character (say, an escape character - \u001b, fairly common in use).-Dimporttsv.separator=$'\x1b' # This param fails the submitter when serialized.While this is a limitation with the Configuration class's being serialized as an XML, it can be circumvented by applying a suitable encoding that makes a string XML-compatible.</description>
      <version>0.90.1</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.mapreduce.TestImportTsv.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.ImportTsv.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-3-11 01:00:00" id="3625" opendate="2011-3-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>improve/fix support excluding Tests via Maven -D property</summary>
      <description>Currently the surefire plugin configuration defines the following exclusion:. &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;forkMode&gt;always&lt;/forkMode&gt; &lt;includes&gt; &lt;include&gt;**/Test*.java&lt;/include&gt; &lt;/includes&gt; &lt;excludes&gt; &lt;exclude&gt;**/*$*&lt;/exclude&gt; &lt;/excludes&gt; &lt;/configuration&gt; &lt;/plugin&gt;AFAICT the '**/*$*' does not resolve to anything meaningful.Adding support to exclude one or more tests via Maven property, i.e. '-Dtest.exclude=&lt;TESTCLASS&gt;' would be useful.</description>
      <version>0.90.1</version>
      <fixedVersion>0.90.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  <bug fixdate="2011-3-16 01:00:00" id="3658" opendate="2011-3-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Alert when heap is over committed</summary>
      <description>Something I just witnessed, the block cache setting was at 70% but the max global memstore size was at the default of 40% meaning that 110% of the heap can potentially be "assigned" and then you need more heap to do stuff like flushing and compacting.We should run a configuration check that alerts the user when that happens and maybe even refuse to start.</description>
      <version>0.90.1</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HBaseConfiguration.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-3-17 01:00:00" id="3660" opendate="2011-3-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HMaster will exit when starting with stale data in cached locations such as -ROOT- or .META.</summary>
      <description>later edit: I've mixed up two issues here. The main problem is that a client (that could be HMaster) will read stale data from ROOT or .META. and not deal correctly with the raised exceptions. I've noticed this when the IP on my machine changed (it's even easier to detect when LZO doesn't work)Master loads .META. successfully and then starts assigning regions.However LZO doesn't work so HRegionServer can't open the regions. A client attempts to get data from a table so it reads the location from .META. but goes to a totally different server (the old value in .META.)This could happen without the LZO story too.</description>
      <version>0.90.1</version>
      <fixedVersion>0.90.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-3-17 01:00:00" id="3665" opendate="2011-3-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>checking the number entries in the unit test case</summary>
      <description>In the unit test function in HBase-3636, add 2 more assertions to check entry number</description>
      <version>None</version>
      <fixedVersion>0.90.2,0.92.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2011-4-21 01:00:00" id="3678" opendate="2011-3-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add Eclipse-based Apache Formatter to HBase Wiki</summary>
      <description>Currently, on http://wiki.apache.org/hadoop/Hbase/HowToContribute , we tell the user to follow Sun's code conventions and then add a couple things. For lazy people like myself, it would be much easier to just tell us to import an Apache formatter into your Eclipse project and not worry about it.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  
  <bug fixdate="2011-4-5 01:00:00" id="3735" opendate="2011-4-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Book.xml - adding section on Schema Design on versions</summary>
      <description>Added section under Schema Design for "Number of Versions"The fact that HBase doesn't overwrite values (but versions them by time) is one of those "obvious but not so obvious" topics, and it recently came up on the dist-list. Added small description of why this is important to consider for schema design, link to HColumnDescriptor javadoc, with internal link to Data Model section.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.performance.xml</file>
      <file type="M">src.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-4-5 01:00:00" id="3738" opendate="2011-4-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Book.xml - expanding Architecture Client section</summary>
      <description>Expanded the Architecture Client section. Broke 'connection' into sub-section, and created 'writebuffer and batch methods' into another sub-section.Both seem to be fairly frequent questions on the dist-list.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.book.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-4-5 01:00:00" id="3740" opendate="2011-4-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbck doesn&amp;#39;t reset the number of errors when retrying</summary>
      <description>Using hbck to fix a problem, I see that when it retries it doesn't reset the number of inconsistencies so the number doubles.</description>
      <version>0.90.1</version>
      <fixedVersion>0.90.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2011-4-7 01:00:00" id="3751" opendate="2011-4-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Book.xml - fixing unit of measure in 2 metrics. added description for compactionQueue</summary>
      <description>The patch I submitted yesterday for 'blockCacheFree' and 'blockCacheSize' said these were in MB. After re-re-confirming against our own cluster, these numbers are actually in bytes. Also added further description of what's actually in the compactionQueueSize (e.g., it's the number of stores targeted for compaction in the region).</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-4-7 01:00:00" id="3753" opendate="2011-4-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Book.xml - architecture, adding more Store info</summary>
      <description>In Architecture...Added a sub-section on 'MemStore' under Store. The description is pretty much from the MemStore javadoc.Added a sub-section on 'compaction' under Store. This is based on stack's comments from this week. A great summary on the difference between minor/major compactions that hopefully won't have to get re-typed again.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.book.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-4-8 01:00:00" id="3757" opendate="2011-4-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade to ZK 3.3.3</summary>
      <description>ZK 3.3.3 has been out since Feb 27th, let's upgrade!</description>
      <version>0.90.1</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-4-11 01:00:00" id="3764" opendate="2011-4-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Book.xml - adding 2 FAQs (SQL and arch question)</summary>
      <description>Adding 2 general FAQs.1) does HBase support SQL? (Hive, but not really for most cases)... 2) how does HBase work on HDFS? (if HDFS is for large files without fast lookup, how does HBase work?) Doesn't answer the question inline but refers to DataModel and Arch.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.book.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  
  
  <bug fixdate="2011-1-31 01:00:00" id="5111" opendate="2011-12-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade zookeeper to 3.4.2 release</summary>
      <description>Zookeeper 3.4.2 has just been released.We should upgrade to this release.</description>
      <version>None</version>
      <fixedVersion>0.92.0,0.94.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-2-14 01:00:00" id="6782" opendate="2012-9-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase shell&amp;#39;s &amp;#39;status &amp;#39;detailed&amp;#39;&amp;#39; should escape the printed keys</summary>
      <description>Currently the HBase shell's status command prints unescaped keys on the terminal causing the terminal to print garbage characters. We should escape the printed keys.</description>
      <version>0.90.1</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
</bugrepository>