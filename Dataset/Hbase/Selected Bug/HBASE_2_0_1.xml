<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="HBASE">
  <bug fixdate="2018-3-8 01:00:00" id="20153" opendate="2018-3-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>enable error-prone analysis in precommit</summary>
      <description>We've done a lot of work to get rid of the error-prone errors, we should make sure they stay out. Let's enable errorProne profile and analysis in precommit.busbey - I tried figuring out how to pass flags (-PerrorProne to the mvn compile precommit check but was unable to unravel that thread. Any help is appreciated.</description>
      <version>None</version>
      <fixedVersion>1.4.3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2018-8-21 01:00:00" id="20772" opendate="2018-6-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Controlled shutdown fills Master log with the disturbing message "No matching procedure found for rit=OPEN, location=ZZZZ, table=YYYYY, region=XXXX transition to CLOSED</summary>
      <description>I just saw this and was disturbed but this is a controlled shutdown. Change message so it doesn't freak out the poor operator</description>
      <version>2.0.1</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1,2.0.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2018-7-4 01:00:00" id="20841" opendate="2018-7-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add note about the limitations when running WAL against the recent versions of hadoop</summary>
      <description>AsyncFSWAL may easily be broken when upgrading the DFSClient, so we introduced a fallback logic in HBASE-20839. And also, WAL can not be written into a directory with EC enabled, but the API for creating a non-EC file in EC directory is not available in hadoop-2.8-, see HBASE-19369 for more details.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.troubleshooting.adoc</file>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-7-4 01:00:00" id="20843" opendate="2018-7-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add release manager for 2.1 in ref guide</summary>
      <description/>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.community.adoc</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2018-1-25 01:00:00" id="20937" opendate="2018-7-25 00:00:00" resolution="Unresolved">
    <buginformation>
      <summary>Update the support matrix in our ref guide about the recent hadoop releases</summary>
      <description>Copied from HBASE-20538 "Upgrade our hadoop versions to 2.7.7 and 3.0.3" and from HBASE-20970Apache9 Duo Zhang added a comment - 6 days agoI think we should mark 2.7.x before 2.7.7 as 'Not Supported' due to the JDK issue? We only support jdk8 for 2.0 or above.Apache9 Duo Zhang added a comment - 6 days ago - Restricted to CommittersAnd IIRC there is a security issue before 2.7.7 so it is important to drop the support and let users upgrade to 2.7.7?Apache9 Duo Zhang added a comment - 6 days agoAlso upgrade hadoop3 dependency to 3.0.3 which contains HADOOP-15473.How does this issue relate to HBASE-20937?Do we support 3.0.3 now?Actually no. We do not support any 3.0.x releases due to the YARN issue YARN-7190. But at least it could let us add back the ignored security UT. There is still no production ready 3.1.x release...</description>
      <version>None</version>
      <fixedVersion>3.0.0-beta-1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-7-30 01:00:00" id="20977" opendate="2018-7-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Don&amp;#39;t use the word "Snapshot" when defining "HBase Snapshots"</summary>
      <description>From http://hbase.apache.org/book.html#ops.snapshotsHBase Snapshots allow you to take a snapshot of a table without too much impact on Region ServersWe should change this to not use the word "snapshot" when defining what HBase Snapshots are. It's confusing enough to English-as-a-first-language individuals; I imagine it's even more cyclical to ESL individuals.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-8-30 01:00:00" id="20979" opendate="2018-7-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Flaky test reporting should specify what JSON it needs and handle HTTP errors</summary>
      <description>Current flaky test report should be including the tree= parameter in its Jenkins API calls (see https://support.cloudbees.com/hc/en-us/articles/217911388-Best-Practice-For-Using-Jenkins-REST-API).Also should provide some info on failure so that when jobs change or go away we don't get blank failures.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1,2.0.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.report-flakies.py</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-8-30 01:00:00" id="20981" opendate="2018-7-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Rollback stateCount accounting thrown-off when exception out of rollbackState</summary>
      <description>Found by might allan163 over in HBASE-20893. Quoting Allan:But, there is truly a bug here, @Override protected void rollback(final TEnvironment env) throws IOException, InterruptedException { if (isEofState()) stateCount--; try { updateTimestamp(); rollbackState(env, getCurrentState()); stateCount--; } finally { updateTimestamp(); } }We need to decrease the stateCount when rolling back, so we can rollback for the previous state correctly. But. since a exception is thrown, the decrease for stateCount never happen. So ProcedureExecutor will continue to rollback for only one state(the one throw a exception) until the end of the execution stack.</description>
      <version>2.0.1</version>
      <fixedVersion>3.0.0-alpha-1,2.1.1,2.0.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.TestYieldProcedures.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.TestStateMachineProcedure.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.StateMachineProcedure.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-8-31 01:00:00" id="20986" opendate="2018-7-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Separate the config of block size when we do log splitting and write Hlog</summary>
      <description>Since the block size of recovered edits and hlog are the same right now, if we set a large value to block size, name node may not able to assign enough space when we do log splitting. But set a large value to hlog block size can help reduce the number of region server asking for a new block. Thus I think separate the config of block size is necessary.</description>
      <version>3.0.0-alpha-1,2.1.0,2.0.1,2.2.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.FSHLogProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALUtil.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2010-1-9 01:00:00" id="2103" opendate="2010-1-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[EC2] pull version from build</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.20.3,0.90.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.contrib.ec2.bin.image.create-hbase-image-remote</file>
      <file type="M">src.contrib.ec2.bin.hbase-ec2-env.sh</file>
      <file type="M">src.contrib.build-contrib.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2018-3-21 01:00:00" id="21082" opendate="2018-8-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reimplement assign/unassign related procedure metrics</summary>
      <description>As after HBASE-20881, we only have one TRSP procedure to handle all the assign/unassign/move/reopen operations, we need to reimplement(redefine?) the metrics for these procedures.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.assignment.TestRegionBypass.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.assignment.TestAssignmentManagerBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.assignment.TestAssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MetricsAssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.TransitRegionStateProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.OpenRegionProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.CloseRegionProcedure.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.MasterProcedure.proto</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsAssignmentManagerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsAssignmentManagerSource.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-8-21 01:00:00" id="21084" opendate="2018-8-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>When cloning a snapshot including a split parent region, the split parent region of the cloned table will be online</summary>
      <description>Investigating HBASE-21015, I found another issue. It seems like after HBASE-20881, the split parent region of the cloned table will be online when cloning a snapshot including a split parent region.Steps to reproduce are as follows, which is the same as the steps in HBASE-21015:1. Create a tablecreate "test", "cf"2. Put some data into the table(0...2000).each{|i| put "test", "row#{i}", "cf:col", "val"}3. Split the tablesplit "test"4. Take a snapshot of the table before CatalogJanitor cleans up the split parent regionsnapshot "test", "snap"5. Clone the snapshotclone_snapshot "snap", "cloned_table"After following the above steps, the split parent region of the cloned table will be online.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestCloneSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CloneSnapshotProcedure.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionReplicaUtil.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-9-23 01:00:00" id="21107" opendate="2018-8-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>add a metrics for netty direct memory</summary>
      <description>This is separated from HBASE-20913 as I realized that netty direct memory usage needs to show up in metrics instead of the web page.</description>
      <version>2.0.1</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapperStub.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.DirectMemoryUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapperImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSource.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2018-4-20 01:00:00" id="21502" opendate="2018-11-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update SyncTable section on RefGuide once HBASE-20586 is committed</summary>
      <description>SyncTable refguide section currently mentions limitation to run it on different kerberos realm. HBASE-20586 is ongoing to resolve this problem. This jira is to make sure RefGuide is updated accordingly once HBASE-20586 is resolved.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-3-1 01:00:00" id="21976" opendate="2019-3-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Deal with RetryImmediatelyException for batching request</summary>
      <description/>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.4</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncBatchRpcRetryingCaller.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-3-2 01:00:00" id="21978" opendate="2019-3-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Should close AsyncRegistry if we fail to get cluster id when creating AsyncConnection</summary>
      <description/>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.4</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionFactory.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-3-21 01:00:00" id="22077" opendate="2019-3-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expose sleep time as a command line argument of IntergationTestBackupRestore</summary>
      <description>Extend command line arguments of IntergationTestBackupRestore with a sleep time of chaos monkey options to be able to setup policy of region server restarts more granularly.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestBackupRestore.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2010-6-10 01:00:00" id="2208" opendate="2010-2-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>TableServers # processBatchOfRows - converts from List to [ ] - Expensive copy</summary>
      <description>With autoFlush to false and a large write buffer on HTable, when we write bulk puts - TableServer # processBatchOfRows , convert the input (List) to an [ ] , before sending down the wire. With a write buffer as large as 20 MB , that becomes an expensive copy when we do - list.toArray(new T[ ] ). May be - should we change the wire protocol to support List as well , and then revisit this to prevent the bulk copy ?Batch b = new Batch(this) { @Override int doCall(final List&lt;Row&gt; currentList, final byte [] row, final byte [] tableName) throws IOException, RuntimeException { *final Put [] puts = currentList.toArray(PUT_ARRAY_TYPE);* return getRegionServerWithRetries(new ServerCallable&lt;Integer&gt;(this.c, tableName, row) { public Integer call() throws IOException { return server.put(location.getRegionInfo().getRegionName(), puts); } }); }</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HRegionInterface.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2020-4-26 01:00:00" id="24055" opendate="2020-3-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make AsyncFSWAL can run on EC cluster</summary>
      <description>We need to enable replicate when creating the file.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHBaseWalOnEC.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.asyncfs.TestFanOutOneBlockAsyncDFSOutput.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputHelper.java</file>
    </fixedFiles>
  </bug>
  
</bugrepository>