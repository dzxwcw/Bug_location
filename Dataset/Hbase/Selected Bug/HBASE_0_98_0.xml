<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="HBASE">
  
  
  <bug fixdate="2013-11-26 01:00:00" id="10038" opendate="2013-11-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix potential Resource Leak in ZNodeCleaner</summary>
      <description/>
      <version>0.98.0,0.96.0</version>
      <fixedVersion>0.98.0,0.96.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ZNodeClearer.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-12-6 01:00:00" id="10098" opendate="2013-12-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[WINDOWS] pass in native library directory from hadoop for unit tests</summary>
      <description>On windows, Hadoop depends on native libraries for doing it's job. The bin scripts already handle finding hadoop's native libs and adding them to java.library.path, but for running HBase's unit tests, we need to pass them in.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.2,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-12-10 01:00:00" id="10124" opendate="2013-12-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make Sub Classes Static When Possible</summary>
      <description>Coverity has found a few places where it's possible to change a private inner class to static with out any other code changes. This will be a small perf win.</description>
      <version>0.98.0,0.96.0</version>
      <fixedVersion>0.98.0,0.96.2,0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ServerNonceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.mttr.IntegrationTestMTTR.java</file>
      <file type="M">hbase-hadoop2-compat.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop1-compat.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsRegionSourceImpl.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-12-12 01:00:00" id="10146" opendate="2013-12-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bump HTrace version to 2.04</summary>
      <description>2.04 has been released with a bug fix for what happens when htrace fails.</description>
      <version>0.98.0,0.96.1,0.99.0</version>
      <fixedVersion>0.98.0,0.96.2,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-12-16 01:00:00" id="10175" opendate="2013-12-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>2-thread ChaosMonkey steps on its own toes</summary>
      <description>ChaosMonkey with one destructive and one volatility (flush-compact-split-etc.) threads steps on its own toes and logs a lot of exceptions.A simple solution would be to catch most (or all), like NotServingRegionException, and log less (not a full callstack for example, it's not very useful anyway).A more complicated/complementary one would be to keep track which regions the destructive thread affects and use other regions for volatile one.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.SplitRandomRegionOfTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.MoveRegionsOfTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.MergeRandomAdjacentRegionsOfTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.FlushTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.FlushRandomRegionOfTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.CompactTableAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.CompactRandomRegionOfTableAction.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-8-18 01:00:00" id="10202" opendate="2013-12-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Documentation is lacking information about rolling-restart.sh script.</summary>
      <description>Current documentation is talking about graceful_stop.sh and how to do a rolling restart but is not talking about the rolling-restart.sh script. We need to document that.</description>
      <version>0.98.0,0.94.14,0.99.0,0.96.1.1</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-12-19 01:00:00" id="10206" opendate="2013-12-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Explain tags in the hbase book</summary>
      <description/>
      <version>0.98.0,0.99.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.security.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-12-20 01:00:00" id="10211" opendate="2013-12-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve AccessControl documentation in hbase book</summary>
      <description>The AccessControl documentation is bit old in the hbase book. Update that to the latest describing cell level ACLs with HFileV3.</description>
      <version>0.98.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.security.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-12-23 01:00:00" id="10226" opendate="2013-12-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[AccessController] Namespace grants not always checked</summary>
      <description>Namespace grants for a user are supposed to supercede table level permissions, a middle tier between table grants and global grants. We are not always checking.</description>
      <version>0.98.0,0.96.2,0.99.0</version>
      <fixedVersion>0.98.0,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestZKPermissionsWatcher.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.TableAuthManager.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-12-23 01:00:00" id="10228" opendate="2013-12-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support setCellVisibility and setAuthorizations in Shell</summary>
      <description>Currently the shell scripts supports attributes but not the new apis in the Query class. So this JIRA is to support them thro shell.</description>
      <version>0.98.0</version>
      <fixedVersion>0.98.0,0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.test.ruby.hbase.table.test.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.scan.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.put.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.incr.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.get.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.append.rb</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.visibility.labels.rb</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.table.rb</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.rb</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-12-23 01:00:00" id="10229" opendate="2013-12-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support OperationAttributes in Increment and Append in Shell</summary>
      <description/>
      <version>0.98.0</version>
      <fixedVersion>0.98.0,0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.test.ruby.hbase.table.test.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.incr.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.rb</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.table.rb</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-12-23 01:00:00" id="10232" opendate="2013-12-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove native profile from hbase-shell</summary>
      <description>HBase shell module has no native source it shouldn't have a native profile. I think I copied that over by mistake.</description>
      <version>0.98.0,0.99.0,0.96.1.1</version>
      <fixedVersion>0.98.0,0.96.2,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-12-23 01:00:00" id="10234" opendate="2013-12-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Correct "column-oriented" descriptor on home page</summary>
      <description>Per the conversation on dev list, update the high-level project description to not describe HBase as "column-oriented".</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.site.xdoc.index.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2008-12-24 01:00:00" id="1027" opendate="2008-11-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make global flusher check work with percentages rather than hard code memory sizes.</summary>
      <description>Currently defaults are 512M for upperbound and 256 for the lowerbound. Comes of HBASE-1023.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.TestGlobalMemcacheLimit.java</file>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.MemcacheFlusher.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-7-8 01:00:00" id="10297" opendate="2014-1-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>LoadAndVerify Integration Test for cell visibility</summary>
      <description/>
      <version>0.98.0</version>
      <fixedVersion>0.98.0,0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestLoadAndVerify.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-1-9 01:00:00" id="10302" opendate="2014-1-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix rat check issues in hbase-native-client.</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-native-client.src.rpc.CMakeLists.txt</file>
      <file type="M">hbase-native-client.cmake.modules.FindLibEv.cmake</file>
      <file type="M">hbase-native-client.cmake.modules.FindGTest.cmake</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-1-9 01:00:00" id="10304" opendate="2014-1-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Running an hbase job jar: IllegalAccessError: class com.google.protobuf.ZeroCopyLiteralByteString cannot access its superclass com.google.protobuf.LiteralByteString</summary>
      <description>(Jimmy has been working on this one internally. I'm just the messenger raising this critical issue upstream).So, if you make job jar and bundle up hbase inside in it because you want to access hbase from your mapreduce task, the deploy of the job jar to the cluster fails with:14/01/05 08:59:19 INFO Configuration.deprecation: topology.node.switch.mapping.impl is deprecated. Instead, use net.topology.node.switch.mapping.impl14/01/05 08:59:19 INFO Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksumException in thread "main" java.lang.IllegalAccessError: class com.google.protobuf.ZeroCopyLiteralByteString cannot access its superclass com.google.protobuf.LiteralByteString at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:792) at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) at java.net.URLClassLoader.defineClass(URLClassLoader.java:449) at java.net.URLClassLoader.access$100(URLClassLoader.java:71) at java.net.URLClassLoader$1.run(URLClassLoader.java:361) at java.net.URLClassLoader$1.run(URLClassLoader.java:355) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:354) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at org.apache.hadoop.hbase.protobuf.ProtobufUtil.toScan(ProtobufUtil.java:818) at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.convertScanToString(TableMapReduceUtil.java:433) at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:186) at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:147) at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:270) at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:100) at com.ngdata.hbaseindexer.mr.HBaseMapReduceIndexerTool.run(HBaseMapReduceIndexerTool.java:124) at com.ngdata.hbaseindexer.mr.HBaseMapReduceIndexerTool.run(HBaseMapReduceIndexerTool.java:64) at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70) at com.ngdata.hbaseindexer.mr.HBaseMapReduceIndexerTool.main(HBaseMapReduceIndexerTool.java:51) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.apache.hadoop.util.RunJar.main(RunJar.java:212)So, ZCLBS is a hack. This class is in the hbase-protocol module. It is "in" the com.google.protobuf package. All is well and good usually.But when we make a job jar and bundle up hbase inside it, our 'trick' breaks. RunJar makes a new class loader to run the job jar. This URLCLassLoader 'attaches' all the jars and classes that are in jobjar so they can be found when it does to do a lookup only Classloaders work by always delegating to their parent first (unless you are a WAR file in a container where delegation is 'off' for the most part) and in this case, the parent classloader will have access to a pb jar since pb is in the hadoop CLASSPATH. So, the parent loads the pb classes.We then load ZCLBS only this is done in the claslsloader made by RunJar; ZKCLBS has a different classloader from its superclass and we get the above IllegalAccessError.Now (Jimmy's work comes in here), this can't be fixed by reflection &amp;#8211; you can't setAccess on a 'Class' &amp;#8211; and though it probably could be fixed by hacking RunJar so it was somehow made configurable so we could put in place our own ClassLoader to do something like containers do for WAR files (probably not a bad idea), there would be some fierce hackery involved and besides, this won't show up in hadoop anytime too soon leaving hadoop 2.2ers out in the cold.So, the alternatives are:1. Undo the ZCLSB hack. We'd lose a lot of nice perf improvement but I'd say this is preferable to crazy CLASSPATH hacks.2. Require folks put hbase-protocol &amp;#8211; thats all you'd need &amp;#8211; on the hadoop CLASSPATH. This is kinda crazy.3. We could try shading the pb jar content or probably better, just pull pb into hbase altogether only under a different package. If it was in our code base, we could do more ZCLSB-like speedups.I was going to experiment with #3 above unless anyone else has a better idea.</description>
      <version>0.98.0,0.96.1.1</version>
      <fixedVersion>0.98.0,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-1-27 01:00:00" id="1031" opendate="2008-11-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add the Zookeeper jar</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-9-10 01:00:00" id="10314" opendate="2014-1-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add Chaos Monkey that doesn&amp;#39;t touch the master</summary>
      <description/>
      <version>0.98.0,0.99.0,0.96.1.1</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.factories.MonkeyFactory.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  
  
  
  
  
  
  
  
  <bug fixdate="2014-1-22 01:00:00" id="10402" opendate="2014-1-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[docs] Add docs on how to create and tag a point release.</summary>
      <description>I've added a few steps to the "How to release" section of the ref guide based on what I learned about doing a quickie release.This is what I think I should have done &amp;#8211; if you disagree please suggest how it should be done.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.developer.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-1-24 01:00:00" id="10412" opendate="2014-1-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Distributed log replay : Cell tags getting missed</summary>
      <description>This is caused by HBASE-10322. The default RPC codec KVCodec strips tags.</description>
      <version>0.98.0</version>
      <fixedVersion>0.98.0,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabels.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALCellCodec.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-1-28 01:00:00" id="10429" opendate="2014-1-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make Visibility Controller to throw a better msg if it is of type RegionServerCoprocessor</summary>
      <description>If Visbility controller is configured as RegionServerCP then we are not throwing the proper response in the error msg. Instead we say zk == null.This JIRA just tries to throw a proper error msg in case Visibility CP is of type RegionServerCP. apurtellIf you are fine with the patch attached, we can include this in our next RC.</description>
      <version>0.98.0</version>
      <fixedVersion>0.98.0,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityController.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-1-28 01:00:00" id="10430" opendate="2014-1-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support compressTags in shell for enabling tag encoding</summary>
      <description>Tags introduces a new configuration in HCD called COMPRESS_TAGS. The same should be supported in shell also.Will come up with a patch shortly.</description>
      <version>0.98.0</version>
      <fixedVersion>0.98.0,0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-1-28 01:00:00" id="10433" opendate="2014-1-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>SecureProtobufWALReader does not handle unencrypted WALs if configured to encrypt</summary>
      <description>The SecureProtobufWALReader does not handle unencrypted WALs if configured to encrypt. Reported by Anoop. Going to hold up RC1 for this.</description>
      <version>0.98.0</version>
      <fixedVersion>0.98.0,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogReader.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2014-2-29 01:00:00" id="10439" opendate="2014-1-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document how to configure REST server impersonation</summary>
      <description>In 0.96, REST server supports impersonation. Let's document how to configure it.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.security.xml</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  
  
  
  <bug fixdate="2014-2-6 01:00:00" id="10477" opendate="2014-2-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Regression from HBASE-10337</summary>
      <description>a piece of code that should not have make it...ping andrew.purtell@gmail.com</description>
      <version>0.98.0,0.99.0</version>
      <fixedVersion>0.98.0,0.99.0,hbase-10070</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClient.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-2-7 01:00:00" id="10481" opendate="2014-2-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>API Compatibility JDiff script does not properly handle arguments in reverse order</summary>
      <description>jmhsieh found an issue when doing a diff between a pre-0.96 branch and a post-0.96 branch.Typically, if the pre-0.96 branch is specified first, and the post-0.96 branch second, the exisitng logic handles it.When it is in the reverse order, that logic is not handled properly.The fix should address this.</description>
      <version>0.98.0,0.94.16,0.99.0,0.96.1.1</version>
      <fixedVersion>0.98.1,0.99.0,0.96.1.1,0.94.17</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.jdiffHBasePublicAPI.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-2-9 01:00:00" id="10488" opendate="2014-2-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>&amp;#39;mvn site&amp;#39; is broken due to org.apache.jasper.JspC not found</summary>
      <description>From https://builds.apache.org/job/PreCommit-HBASE-Build/8642/artifact/trunk/patchprocess/patchSiteOutput.txt :[WARNING] The POM for org.apache.hbase:hbase-server:jar:0.99.0-20140127.165302-1 is invalid, transitive dependencies (if any) will not be available, enable debug logging for more details[WARNING] The POM for org.apache.hbase:hbase-server:jar:tests:0.99.0-20140127.165302-1 is invalid, transitive dependencies (if any) will not be available, enable debug logging for more details...[ERROR] Failed to execute goal org.apache.maven.plugins:maven-site-plugin:3.3:site (default-site) on project hbase: failed to get report for org.apache.maven.plugins:maven-javadoc-plugin: Failed to execute goal org.apache.maven.plugins:maven-antrun-plugin:1.6:run (generate) on project hbase-thrift: An Ant BuildException has occured: taskdef class org.apache.jasper.JspC cannot be found</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.pom.xml</file>
      <file type="M">hbase-server.pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  
  
  <bug fixdate="2014-12-17 01:00:00" id="10560" opendate="2014-2-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Per cell TTLs</summary>
      <description>Now that we have cell tags, we can optionally store TTLs per cell.</description>
      <version>0.98.0</version>
      <fixedVersion>1.0.0,0.98.9</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.test.ruby.hbase.table.test.rb</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.table.rb</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestTags.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestScanWildcardColumnTracker.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestQueryMatcher.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.GetClosestRowBeforeTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TsvImporterMapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TextSortReducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.ImportTsv.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.CellCreator.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.TagType.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Put.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Mutation.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Increment.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Delete.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Append.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-5-17 01:00:00" id="10561" opendate="2014-2-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Forward port: HBASE-10212 New rpc metric: number of active handler</summary>
      <description>The metrics implementation has changed a lot in 0.96.Forward port HBASE-10212 to 0.96 and later.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.96.3,0.98.3</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestRpcMetrics.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapperStub.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.FifoRpcScheduler.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapper.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-2-21 01:00:00" id="10579" opendate="2014-2-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[Documentation]: ExportSnapshot tool package incorrectly documented</summary>
      <description>Documentation Page: http://hbase.apache.org/book/ops.snapshots.htmlExpected documentation:The class should be specified as org.apache.hadoop.hbase.snapshot.ExportSnapshotCurrent documentation:Specified as: org.apache.hadoop.hbase.snapshot.tool.ExportSnapshotThis makes sense because the class is located in the org.apache.hadoop.hbase.snapshot package:https://github.com/apache/hbase/blob/0.98/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java#19</description>
      <version>0.98.0</version>
      <fixedVersion>0.96.2,0.98.1,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-7-12 01:00:00" id="1058" opendate="2008-12-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Prevent runaway compactions</summary>
      <description>A rabid upload will easily outrun our compaction ability dropping flushes faster than we can compact them up. Fix.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.MemcacheFlusher.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2014-2-21 01:00:00" id="10582" opendate="2014-2-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>0.94-&gt;0.96 Upgrade: ACL can&amp;#39;t be repopulated when ACL table contains row for table &amp;#39;-ROOT&amp;#39; or &amp;#39;.META.&amp;#39;</summary>
      <description>When 'ROOT', '.META' rows are contained in ACL table, during upgrade process, ACL zk nodes can't be populated to zookeeper because AccessControlLists#loadAll(HRegion) fails to load table permissions due to parsePermissionRecord throws IllegalArgumentException from TableName.valueof.</description>
      <version>0.98.0,0.96.0,0.96.1</version>
      <fixedVersion>0.96.2,0.98.1,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.migration.TestNamespaceUpgrade.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.migration.NamespaceUpgrade.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-2-22 01:00:00" id="10590" opendate="2014-2-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update contents about tracing in the Reference Guide</summary>
      <description>Adding explanation about client side settings and shell command for tracing.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2014-3-24 01:00:00" id="10599" opendate="2014-2-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace System.currentMillis() with EnvironmentEdge.currentTimeMillis in memstore flusher and related places</summary>
      <description>Memstoreflusher still uses System.currentMillis. Better to replace it with EnvironmentEdge.currentMillis(),</description>
      <version>0.98.0,0.99.0,0.96.1.1</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  
  <bug fixdate="2014-3-13 01:00:00" id="10744" opendate="2014-3-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>AM#CloseRegion no need to retry on FailedServerException</summary>
      <description>When a regionserver restarts, AM#CloseRegion could get FailedServerException, or ServerNotRunningYetException. The call should not be retried since we know the original regionserver should be down.</description>
      <version>None</version>
      <fixedVersion>0.96.2,0.98.1,0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-4-27 01:00:00" id="10855" opendate="2014-3-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable hfilev3 by default</summary>
      <description>Distributed log replay needs this. Should be on by default in 1.0/0.99.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HDFSBlocksDistribution.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-3-28 01:00:00" id="10864" opendate="2014-3-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Spelling nit</summary>
      <description>We should really be more careful about spelling qualifier</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.scan.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.get.rb</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestScanWildcardColumnTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.package.html</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.TablePermission.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Increment.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-4-9 01:00:00" id="10949" opendate="2014-4-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reversed scan could hang</summary>
      <description>When I play with ITBLL (from trunk tip), sometimes, meta scan hangs when the cluster is rolling restarted. When this happens, the master takes about 1000% of CPU. It looks like there is an infinite loop somewhere. The logs show nothing interesting except some meta scanner RPC calls timed out. Jstask shows the 10 high QoS RPC handlers are busy with meta scanning.However, if I run it again without HBASE-10018, things are fine. I suspect there is something to do with the small/reverse scan.By the way, I see this problem even with log replay off and hfile version = 2.</description>
      <version>0.98.0</version>
      <fixedVersion>0.99.0,0.98.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-12-12 01:00:00" id="11153" opendate="2014-5-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document that http webUI&amp;#39;s should redirect to https when enabled</summary>
      <description>When configured to listen on https, we should redirect non-secure requests to the appropriate port/protocol. Currently we respond with a 200 and no data, which is perplexing.</description>
      <version>0.98.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.security.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-7-30 01:00:00" id="11276" opendate="2014-5-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add back support for running ChaosMonkey as standalone tool</summary>
      <description>According to the ref guide, it was once possible to run ChaosMonkey as a standalone tool against a deployed cluster. After 0.94, this is no longer possible.</description>
      <version>0.98.0,0.96.0,0.99.0</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.2,1.3.0,2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestingUtility.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-6-17 01:00:00" id="11371" opendate="2014-6-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Typo in Thrift2 docs</summary>
      <description>There seems to be a typo in the Thrift2 documentation with the example on how to start it. The example shows this:./bin/hbase-daemon.sh stop thriftWhen it should be this:./bin/hbase-daemon.sh stop thrift2</description>
      <version>0.98.0</version>
      <fixedVersion>0.99.0,0.98.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.package.html</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2014-7-22 01:00:00" id="11559" opendate="2014-7-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add dumping of DATA block usage to the BlockCache JSON report.</summary>
      <description>Block cache toJSON was missing reporting on DATA block type size and block count. Add it.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.5</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheViewTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl.jamon</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2014-9-13 01:00:00" id="11730" opendate="2014-8-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document release managers for non-deprecated branches</summary>
      <description>New development goes against trunk and is backported as desired to existing release branches. From what I have seen on the jira, it looks like each branch's release manager makes the call on backporting a particular issue.We should document both this norm and who the relevant release manager is for each branch.In the current docs, I'd suggest adding the RM list to the "Codelines" section (18.11.1) and add a brief explanation of pinging the RM as a new section after "submitting a patch again" (18.12.6).Post HBASE-4593, the note about pinging a prior branch RM should just go as a bullet in the "patch workflow."</description>
      <version>None</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.developer.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-8-13 01:00:00" id="11731" opendate="2014-8-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add option to only run a subset of the shell tests</summary>
      <description>Right now, contributors to the shell can limit testing to just the shell tests but there's no way to limit to just a subset of them.It would be nice if I could just run the test for the thing I'm changing.</description>
      <version>None</version>
      <fixedVersion>0.99.0,0.98.6</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.developer.xml</file>
      <file type="M">hbase-shell.src.test.ruby.tests.runner.rb</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2009-3-20 01:00:00" id="1273" opendate="2009-3-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>ZooKeeper WARN spits out lots of useless messages</summary>
      <description>Example:2009-03-19 22:18:28,139 WARN &amp;#91;main-SendThread&amp;#93; zookeeper.ClientCnxn$SendThread(932): Ignoring exception during shutdown inputjava.net.SocketException: Socket is not connected at sun.nio.ch.SocketChannelImpl.shutdown(Native Method) at sun.nio.ch.SocketChannelImpl.shutdownInput(SocketChannelImpl.java:640) at sun.nio.ch.SocketAdaptor.shutdownInput(SocketAdaptor.java:360) at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:930) at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:901)</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.log4j.properties</file>
      <file type="M">conf.log4j.properties</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2015-2-13 01:00:00" id="13036" opendate="2015-2-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Meta scanner should use its own threadpool</summary>
      <description>Currently, during region location lookups, the meta is scanned and for this the scanner submits a request to the thread pool of the table in question. Sometimes, it might happen that many scan requests are simultaneously submitted on the table - let's say 256, and this is the max size of the thread pool. Each of these scan requests would in turn submit meta scan requests on the same thread pool, but they will be in the queue. The meta scans will not happen and the original table scans would lock up. The meta scans should use a different thread pool.</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMetaWithReplicas.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionManager.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-9-12 01:00:00" id="13221" opendate="2015-3-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HDFS Transparent Encryption breaks WAL writing in Hadoop 2.6.0</summary>
      <description>We need to detect when HDFS Transparent Encryption (Hadoop 2.6.0+) is enabled and fall back to more synchronization in the WAL to prevent catastrophic failure under load.See HADOOP-11708 for more details.</description>
      <version>0.98.0,1.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2009-4-29 01:00:00" id="1356" opendate="2009-4-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>up jruby to 1.2 release and log4j to 1.2.15 (same as hadoop 0.20.0)</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">lib.log4j-1.2.13.jar</file>
      <file type="M">lib.jruby-complete-1.1.6.jar</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-11-5 01:00:00" id="13622" opendate="2015-5-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>document upgrade rollback</summary>
      <description>I have some docs on doing a rollback of an hbase upgrade that are currently vendor specific. polish them up, make them suitable for HBase generally, and add them to the ref guide.</description>
      <version>0.98.0,1.0.0,1.1.0</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-7-13 01:00:00" id="14065" opendate="2015-7-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>ref guide section on release candidate generation refers to old doc files</summary>
      <description>currently it says to copy files from the master version of src/main/docbkx which is incorrect since the move to asciidoc.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-8-19 01:00:00" id="14260" opendate="2015-8-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>don&amp;#39;t build javadocs for hbase-protocol module</summary>
      <description>I'm not sure I have all the affected versions, but it seems that something is amiss in making our javadocs: mvn -Papache-release -Prelease -DskipTests clean package... SNIP ...[INFO] ------------------------------------------------------------------------[INFO] Reactor Summary:[INFO] [INFO] Apache HBase ....................................... SUCCESS [ 11.149 s][INFO] Apache HBase - Checkstyle .......................... SUCCESS [ 1.249 s][INFO] Apache HBase - Resource Bundle ..................... SUCCESS [ 0.539 s][INFO] Apache HBase - Annotations ......................... SUCCESS [ 4.438 s][INFO] Apache HBase - Protocol ............................ SUCCESS [10:15 min][INFO] Apache HBase - Common .............................. SUCCESS [ 48.465 s][INFO] Apache HBase - Procedure ........................... SUCCESS [ 14.375 s][INFO] Apache HBase - Client .............................. SUCCESS [ 45.187 s][INFO] Apache HBase - Hadoop Compatibility ................ SUCCESS [ 6.998 s][INFO] Apache HBase - Hadoop Two Compatibility ............ SUCCESS [ 14.891 s][INFO] Apache HBase - Prefix Tree ......................... SUCCESS [ 14.214 s][INFO] Apache HBase - Server .............................. SUCCESS [02:01 min][INFO] Apache HBase - Testing Util ........................ SUCCESS [ 12.779 s][INFO] Apache HBase - Thrift .............................. SUCCESS [01:15 min][INFO] Apache HBase - Shell ............................... SUCCESS [ 6.649 s][INFO] Apache HBase - Integration Tests ................... SUCCESS [ 6.429 s][INFO] Apache HBase - Examples ............................ SUCCESS [ 13.200 s][INFO] Apache HBase - Rest ................................ SUCCESS [ 27.831 s][INFO] Apache HBase - Assembly ............................ SUCCESS [ 19.400 s][INFO] Apache HBase - Shaded .............................. SUCCESS [ 0.419 s][INFO] Apache HBase - Shaded - Client ..................... SUCCESS [ 23.707 s][INFO] Apache HBase - Shaded - Server ..................... SUCCESS [ 43.654 s][INFO] Apache HBase - Spark ............................... SUCCESS [02:22 min][INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 21:13 min[INFO] Finished at: 2015-08-19T15:48:00-05:00[INFO] Final Memory: 181M/1513M[INFO] ------------------------------------------------------------------------</description>
      <version>0.98.0,1.0.0,1.1.0,1.2.0,2.0.0</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.2,1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-protocol.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-10-20 01:00:00" id="14271" opendate="2015-8-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve Nexus staging instructions</summary>
      <description>Refine the Nexus staging instructions a bit. (A promise I made a long time ago.)</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-1-23 01:00:00" id="15036" opendate="2015-12-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update HBase Spark documentation to include bulk load with thin records</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.spark.adoc</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2016-2-28 01:00:00" id="15184" opendate="2016-1-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>SparkSQL Scan operation doesn&amp;#39;t work on kerberos cluster</summary>
      <description>I was using the HBase Spark Module at a client with Kerberos and I ran into an issue with the Scan. I made a fix for the client but we need to put it back into HBase. I will attach my solution, but it has a major problem. I had to over ride a protected class in spark. I will need help to decover a better approach</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,connector-1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.cp.adoc</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.HBaseContext.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.DefaultSource.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.datasources.HBaseTableScanRDD.scala</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2016-7-7 01:00:00" id="15985" opendate="2016-6-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>clarify promises about edits from replication in ref guide</summary>
      <description>we should make clear in a call out that replication only provides at-least-once delivery and doesn't guarantee ordering so that e.g. folks using increments aren't surprised.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2017-5-15 01:00:00" id="18049" opendate="2017-5-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>It is not necessary to re-open the region when MOB files cannot be found</summary>
      <description>In HBASE-17712, we try to re-open the region when store files cannot be found. This is useful for store files in a region, but is not necessary when the MOB files cannot be found, because the store files in a region only contain the references to the MOB files and a re-open of a region doesn't help the lost MOB files.In this JIRA, we will directly throw DNRIOE only when the MOB files are not found in MobStoreScanner and ReversedMobStoreScanner. Other logics keep the same.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HMobStore.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-10-26 01:00:00" id="3925" opendate="2011-5-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make Shell&amp;#39;s -d and debug cmd behave the same</summary>
      <description>The -d option switches log4j to DEBUG and leaves the backtrace level at the default. When using the supplied debug command we only switch the backtrace, but I would think this also should set the log4j levels:# Debugging methoddef debug if @shell.debug @shell.debug = false conf.back_trace_limit = 0 else @shell.debug = true conf.back_trace_limit = 100 end debug?endcould be something like # Debugging methoddef debug if @shell.debug @shell.debug = false conf.back_trace_limit = 0 log_level = org.apache.log4j.Level::ERROR else @shell.debug = true conf.back_trace_limit = 100 log_level = org.apache.log4j.Level::DEBUG end org.apache.log4j.Logger.getLogger("org.apache.zookeeper").setLevel(log_level) org.apache.log4j.Logger.getLogger("org.apache.hadoop.hbase").setLevel(log_level) debug?end</description>
      <version>0.90.3,0.90.7,0.92.2,0.94.3,0.98.0,0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hirb.rb</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-3-29 01:00:00" id="4284" opendate="2011-8-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>document permissions that need to be set on importtsv output before completebulkload</summary>
      <description>I am using HBase 0.94 from CDH3u1.After running importtsv using the -Dimporttsv.bulk.output=&lt;output dir&gt; option, I find that completebulkload fails due to hbase not having write permissions on the contents of the output dir that importtsv wrote. I have to manually set write permissions on these contents before I can run completebulkload successfully.Ideally, I should not have to do that (set the permissions manually). Given that I do, this should at least be documented as a limitation of the importtsv utility.</description>
      <version>0.90.4,0.98.0,0.95.0</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2012-11-1 01:00:00" id="7083" opendate="2012-11-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>SSH#fixupDaughter should force re-assign missing daughter</summary>
      <description>In looking into flaky test TestSplitTransactionOnCluster#testShutdownSimpleFixup, I found out that a missing daughter is not assigned by SSH properly. It could be open on the dead server. We need to force re-assign it.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-3-1 01:00:00" id="7968" opendate="2013-3-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Packaging of Trunk and 0.95 does not create the dependent jars in the lib folder</summary>
      <description>After recent changes to trunk and 0.95 branch when i try to build and package, i do not find the dependent jars in the lib folder.Prior to the changes, it was working fine.Am not a maven expert. Will try to see what is going wrong here.</description>
      <version>0.98.0,0.95.0</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.assembly.hadoop-two-compat.xml</file>
      <file type="M">src.assembly.hadoop-one-compat.xml</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-protocol.pom.xml</file>
      <file type="M">hbase-prefix-tree.pom.xml</file>
      <file type="M">hbase-it.pom.xml</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-hadoop1-compat.pom.xml</file>
      <file type="M">hbase-hadoop-compat.pom.xml</file>
      <file type="M">hbase-examples.pom.xml</file>
      <file type="M">hbase-common.pom.xml</file>
      <file type="M">hbase-client.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-3-2 01:00:00" id="7977" opendate="2013-3-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Online merge should acquire table lock</summary>
      <description>Once online merge (HBASE-7403) is in, we should ensure that we acquire a table write lock during the merge.</description>
      <version>0.98.0,0.95.0</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionMergeRequest.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2013-3-14 01:00:00" id="8108" opendate="2013-3-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add m2eclispe lifecycle mapping to hbase-common</summary>
      <description>The maven-antrun-plugin execution doesn't have a default mapping in m2eclipse, so if you import the project into eclipse, you will get an error that the mapping is undefined. All that's needed is to define an execution via the org.eclipse.m2 lifecycle-mapping plugin - it doesn't actually affect the usual maven build at all.</description>
      <version>0.98.0,0.95.0</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-3-19 01:00:00" id="8147" opendate="2013-3-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add Integration Test for "The HCat Scenario"</summary>
      <description>HBASE-8140 needs an integration test.</description>
      <version>0.98.0,0.95.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.mapreduce.IntegrationTestImportTsv.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2008-10-11 01:00:00" id="817" opendate="2008-8-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hbase/Shell Truncate</summary>
      <description>Hbase Shell should allow for the truncation of tables, similar to the functionality provided by HQL</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.hirb.rb</file>
      <file type="M">bin.HBase.rb</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-4-22 01:00:00" id="8179" opendate="2013-3-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>JSON formatting for cluster status is sort of broken</summary>
      <description>In our testing on the REST side of things, we discovered that the request curl -H "Accept: application/json" http://localhost:8080/status/cluster" gets a JSON that collapses the node-list array into one node-element (can see if there are more than 1 RS in the cluster).</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.94.7,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RESTServer.java</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2013-6-15 01:00:00" id="8344" opendate="2013-4-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve the assignment when node failures happen to choose the secondary RS as the new primary RS</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.95.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRegionPlacement.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestFavoredNodeAssignmentHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.FavoredNodes.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.FavoredNodeLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.FavoredNodeAssignmentHelper.java</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2013-5-21 01:00:00" id="8389" opendate="2013-4-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBASE-8354 forces Namenode into loop with lease recovery requests</summary>
      <description>We ran hbase 0.94.3 patched with 8354 and observed too many outstanding lease recoveries because of the short retry interval of 1 second between lease recoveries.The namenode gets into the following loop:1) Receives lease recovery request and initiates recovery choosing a primary datanode every second2) A lease recovery is successful and the namenode tries to commit the block under recovery as finalized - this takes &lt; 10 seconds in our environment since we run with tight HDFS socket timeouts.3) At step 2), there is a more recent recovery enqueued because of the aggressive retries. This causes the committed block to get preempted and we enter a vicious cycleSo we do, &lt;initiate_recovery&gt; --&gt; &lt;commit_block&gt; --&gt; &lt;commit_preempted_by_another_recovery&gt;This loop is paused after 300 seconds which is the "hbase.lease.recovery.timeout". Hence the MTTR we are observing is 5 minutes which is terrible. Our ZK session timeout is 30 seconds and HDFS stale node detection timeout is 20 seconds.Note that before the patch, we do not call recoverLease so aggressively - also it seems that the HDFS namenode is pretty dumb in that it keeps initiating new recoveries for every call. Before the patch, we call recoverLease, assume that the block was recovered, try to get the file, it has zero length since its under recovery, we fail the task and retry until we get a non zero length. So things just work.Fixes:1) Expecting recovery to occur within 1 second is too aggressive. We need to have a more generous timeout. The timeout needs to be configurable since typically, the recovery takes as much time as the DFS timeouts. The primary datanode doing the recovery tries to reconcile the blocks and hits the timeouts when it tries to contact the dead node. So the recovery is as fast as the HDFS timeouts.2) We have another issue I report in HDFS 4721. The Namenode chooses the stale datanode to perform the recovery (since its still alive). Hence the first recovery request is bound to fail. So if we want a tight MTTR, we either need something like HDFS 4721 or we need something like this recoverLease(...) sleep(1000) recoverLease(...) sleep(configuredTimeout) recoverLease(...) sleep(configuredTimeout)Where configuredTimeout should be large enough to let the recovery happen but the first timeout is short so that we get past the moot recovery in step #1.</description>
      <version>None</version>
      <fixedVersion>0.94.8</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.configuration.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-8-23 01:00:00" id="8408" opendate="2013-4-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement namespace</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestLoadAndVerify.java</file>
      <file type="M">hbase-server.src.test.ruby.shell.shell.test.rb</file>
      <file type="M">hbase-server.src.test.ruby.hbase.table.test.rb</file>
      <file type="M">hbase-server.src.test.ruby.hbase.hbase.test.rb</file>
      <file type="M">hbase-server.src.test.ruby.hbase.admin.test.rb</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestMiniClusterLoadSequential.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestMergeTool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestMergeTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHFileArchiveUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsckComparator.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestFSTableDescriptors.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestCoprocessorScanPolicy.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.RestartMetaTest.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.ProcessBasedLocalHBaseCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MultiThreadedWriter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MultiThreadedReader.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MultiThreadedAction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MockRegionServerServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.LoadTestTool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.HFileArchiveTestingUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildOverlap.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildHole.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.OfflineMetaRebuildTestCore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.HbckTestingUtil.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.thrift.TestThriftServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.thrift2.TestThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestZooKeeper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestSerialization.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestRegionRebalancing.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestMultiVersions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestIOFencing.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestInfoServers.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestHTableDescriptor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestFSTableDescriptorForceCreation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestDrainingServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestCompare.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestSnapshotTask.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestSnapshotLogSplitter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestRestoreSnapshotHelper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestRestoreFlushSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestReferenceRegionHFilesTask.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestFlushSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.TestExportSnapshot.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.snapshot.SnapshotTestingUtils.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.token.TestTokenAuthentication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestZKPermissionsWatcher.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestTablePermissions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessControlFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestTableResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestStatusResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestScannersWithFilters.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestScannerResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestRowResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestMultiRowResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestGzipFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.PerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestTableRegionModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestStorageClusterStatusModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.client.TestRemoteTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationSource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestMultiSlaveReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestMasterReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationHLogReaderManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALActionsListener.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRollingNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRolling.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRollAbort.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLogSplit.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLogMethods.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLogFiltering.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLog.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestDurability.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.HLogPerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestWideScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSeekOptimizations.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRSStatusServlet.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestResettingCounters.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerNoMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionMergeTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionMergeTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionFavoredNodes.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestParallelPut.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMemStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestJoinedScanners.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionServerBulkLoad.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionInfo.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionFileSystem.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestGetClosestAtOrBefore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestFSErrorsExposed.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestEndToEndSplitTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDefaultCompactSelection.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompactionState.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestColumnSeeking.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCacheOnWriteInSchema.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestBlocksScanned.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestBlocksRead.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestAtomicOperation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.HFileReadWriteTest.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.handler.TestOpenRegionHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.handler.TestCloseRegionHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MiniHBaseCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestZKBasedOpenCloseRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestTableLockManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRollingRestart.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRestartCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRegionPlacement.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestOpenedRegionHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterTransitions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterStatusServlet.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterRestartAfterDisablingTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterMetrics.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.snapshot.TestSnapshotManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.snapshot.TestSnapshotHFileCleaner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.handler.TestTableDescriptorModification.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.handler.TestTableDeleteFamilyHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.handler.TestCreateTableHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.cleaner.TestSnapshotFromMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.cleaner.TestHFileLinkCleaner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestFavoredNodeAssignmentHelper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.BalancerTestBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestWALPlayer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTimeRangeMapRed.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableSplit.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFilesSplitRecovery.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestImportExport.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestHLogRecordReader.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestScannerSelectionUsingTTL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestScannerSelectionUsingKeyRange.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestLoadAndSwitchEncodeOnDisk.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.encoding.TestChangingEncoding.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HTestConst.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestCase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestMultipleColumnPrefixFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestFilterWrapper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestFilterWithScanLimits.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestDependentColumnFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestColumnPrefixFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestWALObserver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithRemove.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithAbort.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverStacking.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverScannerOpenHook.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestOpenTableInCoprocessor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestMasterObserver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestMasterCoprocessorExceptionWithRemove.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestMasterCoprocessorExceptionWithAbort.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorInterface.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorEndpoint.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestClassLoading.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestBigDecimalColumnInterpreter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestAggregateProtocol.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.SimpleRegionObserver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.SampleRegionWALObserver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.constraint.TestConstraints.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.constraint.TestConstraint.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotMetadata.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotCloneIndependence.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestRestoreSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMultipleTimestamps.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMetaScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestIntraRowPagination.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHTablePool.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHTableMultiplexer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHBaseAdminNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide3.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestCloneSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestClientScannerRPCTimeout.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.HConnectionTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.catalog.TestMetaReaderEditorNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.catalog.TestMetaReaderEditor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.catalog.TestMetaMigrationConvertingToPB.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.catalog.TestCatalogTracker.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestHFileArchiving.java</file>
      <file type="M">hbase-server.src.main.ruby.shell.commands.rb</file>
      <file type="M">hbase-server.src.main.ruby.shell.rb</file>
      <file type="M">hbase-server.src.main.ruby.hbase.table.rb</file>
      <file type="M">hbase-server.src.main.ruby.hbase.admin.rb</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.tablesDetailed.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.snapshot.jsp</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ModifyRegionUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.Merge.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HMerge.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HFileArchiveUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsckRepair.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSTableDescriptors.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSTableDescriptorMigrationToSubdir.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.Canary.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.TableDescriptors.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.TableInfoCopyTask.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotLogSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.ExportSnapshot.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.TokenUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.ZKPermissionWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.TableAuthManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AuthResult.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlLists.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.SchemaResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RootResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RegionsResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.TableSchemaModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.TableRegionModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteAdmin.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALEditsReplaySink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogKey.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.snapshot.RegionServerSnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionMergeTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionMergeRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.OnlineRegions.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.KeyPrefixRegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DelimitedKeyPrefixRegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactionTool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.ReplicationProtbufUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableLockManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.SnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.RestoreSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.MasterSnapshotVerifier.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.DisabledTableSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.snapshot.CloneSnapshotHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableModifyFamilyHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableEventHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableDeleteFamilyHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TableAddFamilyHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.OpenedRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ModifyTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.EnableTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DisableTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DeleteTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.CreateTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ClosedRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.RegionLocationFinder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.FavoredNodeAssignmentHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableSplit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapred.TableInputFormatBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.WALPlayer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableSplit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.MultiTableInputFormatBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.ImportTsv.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.LocalHBaseCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.HFileLink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.package-info.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.MasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseMasterObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.constraint.ConstraintProcessor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.HFileArchiver.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">hbase-protocol.src.main.protobuf.ZooKeeper.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.WAL.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.SecureBulkLoad.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.MasterMonitor.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.MasterAdmin.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.hbase.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.AccessControl.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.SecureBulkLoadProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MasterMonitorProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MasterAdminProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.catalog.MetaReader.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.AggregationClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.SecureBulkLoadClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnectionWrapper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTableInterface.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTableMultiplexer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTablePool.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MetaScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MultiServerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionServerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Registry.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.UnmodifyableHTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ZooKeeperRegistry.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.CoprocessorEnvironment.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RegionCoprocessorRpcChannel.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.TablePermission.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.security.access.UserPermission.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.ClientSnapshotDescriptionUtils.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.snapshot.TablePartiallyOpenException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableExistsException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableNotDisabledException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableNotEnabledException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.TableNotFoundException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKTableReadOnly.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestAsyncProcess.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestClientNoCluster.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotFromAdmin.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Bytes.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestKeyValue.java</file>
      <file type="M">hbase-examples.src.test.java.org.apache.hadoop.hbase.coprocessor.example.TestBulkDeleteProtocol.java</file>
      <file type="M">hbase-examples.src.test.java.org.apache.hadoop.hbase.coprocessor.example.TestZooKeeperScanPolicyObserver.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestLazyCfLoading.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestManyRegions.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.mttr.IntegrationTestMTTR.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-4-25 01:00:00" id="8431" opendate="2013-4-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix missing headers</summary>
      <description>Now that rat is testing more files there are some missing.</description>
      <version>0.98.0,0.95.1</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestIPv6NIOServerSocketChannel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationSmallTests.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.NoOpScanPolicyObserver.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestImportTsvParser.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapperStub.java</file>
      <file type="M">hbase-hadoop1-compat.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestMetricsWALSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestMetricsHLogSource.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestShowProperties.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.ipc.TestPayloadCarryingRpcController.java</file>
      <file type="M">bin.test.process.based.cluster.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-4-26 01:00:00" id="8444" opendate="2013-4-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Acknowledge that 0.95+ requires 1.0.3 hadoop at least.</summary>
      <description>As per this mail thread, http://search-hadoop.com/m/stbKO1YNWZe/Compile+does+not+work+against+Hadoop-1.0.0+-+1.0.2&amp;subj=Re+Compile+does+not+work+against+Hadoop+1+0+0+1+0+2... 0.95.x requires hadoop 1.0.3 at least. Note it in the refguide hadoop section.</description>
      <version>None</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.configuration.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-5-30 01:00:00" id="8466" opendate="2013-4-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Netty messages in the logs</summary>
      <description>We've got this:ATTENTION: The pipeline contains no upstream handlers; discarding: [id: 0x1f79354a] OPENATTENTION: The pipeline contains no upstream handlers; discarding: [id: 0x1f79354a] BOUND: 0.0.0.0/0.0.0.0:37250ATTENTION: The pipeline contains no upstream handlers; discarding: [id: 0x1f79354a, 0.0.0.0/0.0.0.0:37250 =&gt; /226.1.1.3:60100] CONNECTED: /226.1.1.3:60100ATTENTION: The pipeline contains no upstream handlers; discarding: [id: 0x1f79354a, 0.0.0.0/0.0.0.0:37250 =&gt; /226.1.1.3:60100] WRITTEN_AMOUNT: 129ATTENTION: The pipeline contains no upstream handlers; discarding: [id: 0x1f79354a, 0.0.0.0/0.0.0.0:37250 :&gt; /226.1.1.3:60100] DISCONNECTEDATTENTION: The pipeline contains no upstream handlers; discarding: [id: 0x1f79354a, 0.0.0.0/0.0.0.0:37250 :&gt; /226.1.1.3:60100] UNBOUNDATTENTION: The pipeline contains no upstream handlers; discarding: [id: 0x1f79354a, 0.0.0.0/0.0.0.0:37250 :&gt; /226.1.1.3:60100] CLOSEDWe can fix this by adding an upstream handler that discards the message without printing them.</description>
      <version>0.98.0,0.95.0</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ClusterStatusPublisher.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-5-30 01:00:00" id="8472" opendate="2013-4-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>mvn -Dhadoop.profile=2.0 -Dhadoop-two.version=2.0.5-SNAPSHOT fails because of Undef Class error wrt o.a.h.IdGenerator</summary>
      <description>&lt;testcase time="1.009" classname="org.apache.hadoop.hbase.replication.TestMasterReplication" name="testCyclicReplication"&gt; &lt;error message="org/apache/hadoop/util/IdGenerator" type="java.lang.NoClassDefFoundError"&gt;java.lang.NoClassDefFoundError: org/apache/hadoop/util/IdGenerator at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:752) at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:261) at org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:146) at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:775) at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:642) at org.apache.hadoop.hdfs.MiniDFSCluster.&amp;lt;init&amp;gt;(MiniDFSCluster.java:585)....</description>
      <version>0.98.0</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-7-1 01:00:00" id="8473" opendate="2013-5-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>add note to ref guide about snapshots and ec2 reverse dns requirements.</summary>
      <description>From IRC from mighty Jeremy Carroll.17:10 &lt;jeremy_carroll&gt; jmhsieh: I think I found the root cuase. All my region servers reach the barrier, but it does not continue.17:11 &lt;jeremy_carroll&gt; jmhsieh: All RS have this in their logs: 2013-05-01 00:04:56,356 DEBUG org.apache.hadoop.hbase.procedure.Subprocedure: Subprocedure 'backup1' coordinator notified of 'acquire', waiting on 'reached' or 'abort' from coordinator.17:11 &lt;jeremy_carroll&gt; jmhsieh: Then the coordinator (Master) never sends anything. They just sit until the timeout.17:12 &lt;jeremy_carroll&gt; jmhsieh: So basically 'reached' is never obtained. Then abort it set, and it fails....17:24 &lt;jeremy_carroll&gt; jmhsieh: Found the bug. The hostnames dont match the master due to DNS resolution17:25 &lt;jeremy_carroll&gt; jmhsieh: The barrier aquired is putting in the local hostname from the regionservers. In EC2 (Where reverse DNS does not work well), the master hands the internal name to the client.17:25 &lt;jeremy_carroll&gt; jmhsieh: https://s3.amazonaws.com/uploads.hipchat.com/23947/185789/au94meik0h3y5ii/Screen%20Shot%202013-04-30%20at%2017.25.50.png 17:26 &lt;jeremy_carroll&gt; jmhsieh: So it's waiting for something like 'ip-10-155-208-202.ec2.internal,60020,1367366580066' zNode to show up, but instead 'hbasemetaclustera-d1b0a484,60020,1367366580066,' is being inserted. Barrier is not reached17:27 &lt;jeremy_carroll&gt; jmhsieh: Reason being in our environment the master does not have a reverse DNS entry. So we get stuff like this on RegionServer startup in our logs.17:27 &lt;jeremy_carroll&gt; jmhsieh: 2013-05-01 00:03:00,614 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Master passed us hostname to use. Was=hbasemetaclustera-d1b0a484, Now=ip-10-155-208-202.ec2.internal17:54 &lt;jeremy_carroll&gt; jmhsieh: That was it. Verified. Now that Reverse DNS is working, snapshots are working. Now how to figure out how to get Reverse DNS working on Route53. I wished there was something like 'slave.host.name' inside of Hadoop for this. Looking at source code.</description>
      <version>0.98.0,0.94.6.1,0.95.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.troubleshooting.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-5-8 01:00:00" id="8507" opendate="2013-5-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HLog tool documentation should be updated to use FSHLog for trunk and 0.95.</summary>
      <description>The WAL tool section in the hbase book suggests $ ./bin/hbase org.apache.hadoop.hbase.regionserver.wal.HLog --dump hdfs://example.org:8020/hbase/.logs/example.org,60020,1283516293161/10.10.21.10%3A60020.1283973724012 but in trunk HLog is an interface and FSHLog is the implementation. The doc has to be updated accordingly. Even if we don't do this now we have to when the trunk version gets released.</description>
      <version>0.98.0</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-5-8 01:00:00" id="8510" opendate="2013-5-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBASE-8469 added a hdfs-site.xml file for tests but it gets included in the test jar</summary>
      <description>aleksshulman found in his tests that HBase recently started ignoring hdfs-site.xml when it's on the classpath. I found that HBASE-8469 added an hdfs-site.xml for the unit tests but it's not excluded when building the jar.</description>
      <version>0.98.0,0.95.1</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-6-12 01:00:00" id="8532" opendate="2013-5-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[Webui] Bootstrap based webui compatibility for IE and also fix some page format issues.</summary>
      <description>HBASE-7425 brings bootstrap based webui to hbase. While trying on trunk version, Firefox works well, but IE 8/9 layout and style look strange due to compatibility issue. Add "&lt;!DOCTYPE html ...&gt;" at the beginning of all jamon html/jsp templates to fix it.Seems HBase-2110 had a work to comment out the DOCTYPE for all .jsp to make the browser run the pages in Quirks mode (http://en.wikipedia.org/wiki/Quirks_mode) due to jetty issue at that time?To support the compatibility of webui across browsers (IE/Firefox/Chrome, etc.), there are some guidelines for choosing rendering the page under standard mode or quirk mode:http://en.wikipedia.org/wiki/Quirks_modehttp://hsivonen.iki.fi/doctype/According to document, "&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd"&gt;" has the most extensive compatibility even for HTML 5. According to my test, add this could make webui works in IE (standard mode), while Firefox could not work well with styles. Looks like if in Firefox, we still need the quirk mode (no DOCTYPE declaration). So just adding conditional DOCTYPE declaration for IE,&lt;!--&amp;#91;if IE&amp;#93;&gt;&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd"&gt;&lt;!&amp;#91;endif&amp;#93;--&gt;this could make webui works for both IE and Firefox, also for Chrome and other browsers.</description>
      <version>0.98.0,0.95.0,0.95.2</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.thrift.thrift.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.rest.rest.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.zk.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.tablesDetailed.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.snapshot.jsp</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-5-13 01:00:00" id="8535" opendate="2013-5-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Test for zk leak does not account for unsynchronized access to zk watcher</summary>
      <description>Test can detect a live zk connection in a closed hconnection because it does not accesses the zk watcher in a synchronized manner.</description>
      <version>0.98.0,0.95.1</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  <bug fixdate="2013-5-22 01:00:00" id="8596" opendate="2013-5-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[docs] Add docs about Region server "draining" mode</summary>
      <description>HBASE-4298 introduced "draining" mode for region servers to optimize rolling restarts to allow for multiple RS's going down simultaneously. There is a good blog post from the original author. I've added highlights from and and a link to it in the Node Decommissioning section of the ref guide.</description>
      <version>0.92.2,0.98.0,0.94.7,0.95.0</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-5-25 01:00:00" id="8618" opendate="2013-5-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Master is providing dead RegionServer ServerName&amp;#39;s to the balancer</summary>
      <description>The balancer should not be passed any ServerName's for RS's that are dead.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-5-29 01:00:00" id="8643" opendate="2013-5-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Do not log full classnames in logs, just the last two levels</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.log4j.properties</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-8-5 01:00:00" id="8693" opendate="2013-6-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>DataType: provide extensible type API</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.types.TestStruct.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-7-11 01:00:00" id="8732" opendate="2013-6-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HFileBlockDefaultEncodingContext isn&amp;#39;t thread-safe but is used by all readers, breaks column encoding</summary>
      <description>Getting an error when opening a scanner on a file that has no encoding.</description>
      <version>0.98.0,0.95.1</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationSmallTests.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationQueueFailoverCompressed.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationQueueFailover.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoderImpl.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-6-12 01:00:00" id="8733" opendate="2013-6-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update our hadoop2 in trunk and 0.95 to 2.0.5-alpha (We are currently 2.0.2)</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-6-12 01:00:00" id="8738" opendate="2013-6-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[refGuide] Overhauled HBase metrics section</summary>
      <description>Overhauled HBase metrics section in Ops chapter. Broke out flat list of metrics into 2 sub-sections: most important, and "other". Added many metrics, and improved descriptions of all metrics. Added warning to Ganglia users about default metric emission.Thanks to Elliot Clark, Greg Waffen, James McDermott, Charles Douthart.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-6-12 01:00:00" id="8739" opendate="2013-6-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[refGuide] corrected map-task "spitting"</summary>
      <description>Nit fix in the MapReduce chapter.Corrected section heading "Map-Task Spitting" to "Map-Task Splitting".</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2013-6-24 01:00:00" id="8796" opendate="2013-6-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add mention of new builds mailing list to site</summary>
      <description>Add mention of new builds list, a list into which will dump all build output (rather than emit into dev).</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-6-27 01:00:00" id="8813" opendate="2013-6-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix time b/w recoverLease invocations from HBASE 8449</summary>
      <description>The time b/w recover lease attempts is conservative but is still not correct. It does not factor in Datanode heartbeat time intervals.</description>
      <version>0.98.0,0.95.1</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-9-16 01:00:00" id="886" opendate="2008-9-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Sort the tables in the web UI</summary>
      <description>From the list:hi all,I just thought that it would be great if you could addArrays.sort(tables);in master.jsp somwhere near"&lt;% HTableDescriptor[] tables = new HBaseAdmin(conf).listTables(); if(tables != null &amp;&amp; tables.length &gt; 0) { %&gt;"it is really annoying if one have to find a table in an unsorted list krzysiek</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-7-5 01:00:00" id="8880" opendate="2013-7-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Integration Tests shouldn&amp;#39;t set the number or reties.</summary>
      <description>Setting the number of client reties should be a function of the environment, not of the test.</description>
      <version>0.98.0,0.95.1</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestDataIngestWithChaosMonkey.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-7-5 01:00:00" id="8882" opendate="2013-7-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create an Integration Test to Test MTTR</summary>
      <description/>
      <version>0.98.0,0.95.2</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.AbstractHBaseTool.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.util.ChaosMonkey.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestRebalanceAndKillServersTargeted.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.mttr.IntegrationTestMTTR.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-7-19 01:00:00" id="8994" opendate="2013-7-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Adding log to chaos monkey actions to show what&amp;#39;re performed</summary>
      <description>I realized that not much is logged in the new chaos monkey actions introduced in HBASE-8845.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.util.ChaosMonkey.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-8-29 01:00:00" id="9077" opendate="2013-7-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make Web ui Fluid width</summary>
      <description>Region names and other unusually long strings really make the ui look weird. We should go with a fluid ui width the minimize the breakage.</description>
      <version>0.98.0,0.95.1</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.thrift.thrift.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.zk.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.tablesDetailed.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-8-29 01:00:00" id="9078" opendate="2013-7-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Downstream build including hbase-client fails because can&amp;#39;t find com.sun.jdmk:jmxtools</summary>
      <description>I've hacked up a downstream maven project. If I include hbase-client, my build fails with this:[INFO] ------------------------------------------------------------------------[INFO] BUILD FAILURE[INFO] ------------------------------------------------------------------------[INFO] Total time: 0.821s[INFO] Finished at: Mon Jul 29 15:58:39 PDT 2013[INFO] Final Memory: 4M/81M[INFO] ------------------------------------------------------------------------[ERROR] Failed to execute goal on project client: Could not resolve dependencies for project org.hbase.downstream:client:jar:1.0-SNAPSHOT: The following artifacts could not be resolved: com.sun.jdmk:jmxtools:jar:1.2.1, com.sun.jmx:jmxri:jar:1.2.1: Failure to find com.sun.jdmk:jmxtools:jar:1.2.1 in http://repo.maven.apache.org/maven2 was cached in the local repository, resolution will not be reattempted until the update interval of central has elapsed or updates are forced -&gt; [Help 1]org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal on project client: Could not resolve dependencies for project org.hbase.downstream:client:jar:1.0-SNAPSHOT: The following artifacts could not be resolved: com.sun.jdmk:jmxtools:jar:1.2.1, com.sun.jmx:jmxri:jar:1.2.1: Failure to find com.sun.jdmk:jmxtools:jar:1.2.1 in http://repo.maven.apache.org/maven2 was cached in the local repository, resolution will not be reattempted until the update interval of central has elapsed or updates are forced at org.apache.maven.lifecycle.internal.LifecycleDependencyResolver.getDependencies(LifecycleDependencyResolver.java:210) at org.apache.maven.lifecycle.internal.LifecycleDependencyResolver.resolveProjectDependencies(LifecycleDependencyResolver.java:117) at org.apache.maven.lifecycle.internal.MojoExecutor.ensureDependenciesAreResolved(MojoExecutor.java:258) at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:201) at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153) at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145) at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:84) at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:59) at org.apache.maven.lifecycle.internal.LifecycleStarter.singleThreadedBuild(LifecycleStarter.java:183) at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:161)Digging, the 1.2.15 log4j pulled in by our transitive zk include has "bad metadata" &amp;#8211; see http://stackoverflow.com/questions/9047949/missing-artifact-com-sun-jdmkjmxtoolsjar1-2-1</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2008-11-1 01:00:00" id="910" opendate="2008-10-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scanner misses columns / rows when the scanner is obtained durring a memcache flush</summary>
      <description>I first noticed that some columns for a row were missing if they are coming from a scanner that was obtained while a memecache flush on the region was in progress. I tried to write a simple unit test to reproduce, however the problem I get in the unit test is that some rows are being missed.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStoreScanner.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-8-8 01:00:00" id="9163" opendate="2013-8-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add timeouts to HBaseAdmin because hanging/zombying</summary>
      <description>Let me add timeouts. HBaseAdmin is acting up since namespaces went in. Add timeouts so hopefully fails faster.</description>
      <version>None</version>
      <fixedVersion>0.95.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-8-9 01:00:00" id="9181" opendate="2013-8-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix javadoc warnings introduce by namespaces</summary>
      <description>javadoc is failing in hadoopqa because we have lingering javadoc warnings.</description>
      <version>0.98.0,0.95.2</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableNamespaceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-10-11 01:00:00" id="920" opendate="2008-10-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make region balancing sloppier</summary>
      <description>The region load balancer is exacting. Here's the logic: if (avgLoad &gt; 2.0 &amp;&amp; thisServersLoad.getNumberOfRegions() &gt; avgLoad) { if (LOG.isDebugEnabled()) { LOG.debug("Server " + serverName + " is overloaded. Server load: " + thisServersLoad.getNumberOfRegions() + " avg: " + avgLoad); }...On a cluster of thousands of regions, especially around startup or if there's been a crash, the above makes for a bunch of churn as load balancer closes and opens nodes to achieve an exact balance (all nodes must be &lt;= to average).I'd suggest that nodes should be left alone if they are within some percentage of the average &amp;#8211; say 10% (should be configurable).</description>
      <version>None</version>
      <fixedVersion>0.18.1,0.19.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStoreFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.RegionManager.java</file>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-8-13 01:00:00" id="9210" opendate="2013-8-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>"hbase shell -d" doesn&amp;#39;t print out exception stack trace</summary>
      <description>when starting shell with "-d" specified, the following line doesn't print anything because debug isn't set when shell is constructed."Backtrace: #{e.backtrace.join("\n ")}" if debugIn addition, the existing code prints the outer most exception while we normally need the root cause exception.</description>
      <version>0.98.0,0.95.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.ruby.shell.commands.rb</file>
      <file type="M">bin.region.status.rb</file>
      <file type="M">bin.region.mover.rb</file>
      <file type="M">bin.hirb.rb</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-12-14 01:00:00" id="9211" opendate="2013-8-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>"ERROR: undefined method `message&amp;#39; for nil:NilClass" in the shell on error</summary>
      <description>Not sure where this is coming from but since today if I try to create a table that already exists in the shell I get:ERROR: undefined method `message' for nil:NilClassinstead of the normal exception.</description>
      <version>0.98.0</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.ruby.shell.commands.rb</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-8-15 01:00:00" id="9229" opendate="2013-8-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix release warning</summary>
      <description/>
      <version>0.98.0</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.trace.HBaseHTraceConfiguration.java</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2008-10-14 01:00:00" id="924" opendate="2008-10-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update hadoop in lib on 0.18 hbase branch to 0.18.1</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.18.1,0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">lib.hadoop-0.18.0-test.jar</file>
      <file type="M">lib.hadoop-0.18.0-core.jar</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-9-16 01:00:00" id="9244" opendate="2013-8-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add CP hooks around StoreFileReader creation</summary>
      <description/>
      <version>0.98.0</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.SimpleRegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-9-18 01:00:00" id="9259" opendate="2013-8-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update hadoop versions grid in refguide adding hadoop-2.1.x and a note on hadoop-2.0.x versions</summary>
      <description>Need to update our hadoop versions grid. Add notes on hadoop-2.1 and hadoop-2.0 (we do the former, not the latter)</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.preface.xml</file>
      <file type="M">src.main.docbkx.getting.started.xml</file>
      <file type="M">src.main.docbkx.configuration.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-8-20 01:00:00" id="9276" opendate="2013-8-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>List tables API should filter with isSystemTable</summary>
      <description/>
      <version>0.98.0,0.95.2,0.96.0</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-8-20 01:00:00" id="9277" opendate="2013-8-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>REST should use listTableNames to list tables</summary>
      <description/>
      <version>0.98.0,0.95.2,0.94.12,0.96.0</version>
      <fixedVersion>0.98.0,0.94.12,0.96.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RootResource.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-8-20 01:00:00" id="9279" opendate="2013-8-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thrift should use listTableNames to list tables</summary>
      <description/>
      <version>0.98.0,0.95.2,0.94.11,0.96.0</version>
      <fixedVersion>0.98.0,0.94.12,0.96.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-8-22 01:00:00" id="9302" opendate="2013-8-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Column family and qualifier should be allowed to be set as null in grant shell command</summary>
      <description>In 0.94, grant.rb has the following:Grant users specific rights.Syntax : grant &lt;user&gt; &lt;permissions&gt; [&lt;table&gt; [&lt;column family&gt; [&lt;column qualifier&gt;]]In 0.95.2, when I tried to grant permission on a table to user hrt_1, I got some exception:hbase(main):003:0&gt; grant 'hrt_1', 'R', 't1'ERROR: java.lang.NullPointerException: nullHere is some help for this command:Grant users specific rights.Syntax : grant &lt;user&gt; &lt;permissions&gt; &lt;table&gt; &lt;column family&gt; &lt;column qualifier&gt;permissions is either zero or more letters from the set "RWXCA".READ('R'), WRITE('W'), EXEC('X'), CREATE('C'), ADMIN('A')For example: hbase&gt; grant 'bobsmith', 'RWXCA' hbase&gt; grant 'bobsmith', 'RW', 't1', 'f1', 'col1'Column family and qualifier should be allowed to be set as null in grant shell command</description>
      <version>0.92.3,0.98.0,0.96.0</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.ruby.hbase.security.rb</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-8-26 01:00:00" id="9342" opendate="2013-8-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>WebUI fixes after bootstrap 3.0 update</summary>
      <description/>
      <version>0.98.0,0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.rest.rest.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.zk.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.tablesDetailed.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.snapshot.jsp</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2013-9-3 01:00:00" id="9419" opendate="2013-9-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add more informative client column to Integration Test Linked List</summary>
      <description/>
      <version>0.98.0,0.96.0</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-9-3 01:00:00" id="9423" opendate="2013-9-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Log splitting should not start till HDFS out of safe mode</summary>
      <description>Distributed log splitting manager is started before we wait for HDFS to be out of safe mode. This leads to log splitting failure since HDFS can't replicate blocks to write the recovered edits.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-9-9 01:00:00" id="9471" opendate="2013-9-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>htrace synchronized on getInstance</summary>
      <description>When doing tests on cached data, one of the bottleneck is the getInstance() on HTrace, called in RequestContext#set() --&gt; Trace.isTracing()When it's fixed, we see threads blocked in sendResponse and in the metrics (with hadoop 1).The difference is not huge (it's in the range 0-5%), but there is no reason to keep this.I'm sending a pull request to htrace.</description>
      <version>0.98.0,0.96.0</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-9-10 01:00:00" id="9492" opendate="2013-9-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>hdfs-site.xml is not excluded from the it-test jar</summary>
      <description>if hbase-it-tests.jar is in the classpath before the hadoop dir conf the user hdfs-site.xml is ignored.A fix was already done with HBASE-8510, but that exclude was applied only to hbase-server.</description>
      <version>0.98.0,0.96.0</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-9-12 01:00:00" id="9518" opendate="2013-9-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>getFakedKey() improvement</summary>
      <description>make generating faked key algo more aggressive</description>
      <version>0.98.0,0.96.1</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.TestHalfStoreFileReader.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestCacheOnWrite.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderV2.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.TestKeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2008-11-26 01:00:00" id="961" opendate="2008-10-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Delete multiple columns by regular expression</summary>
      <description>Hi.I tried to find a way to delete multiple columns that their names match some regular expression, but this functionality is missing (i think).Is it possible to add such functionality ?</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestDeleteFamily.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestDeleteAll.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Memcache.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.ipc.HRegionInterface.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-9-23 01:00:00" id="9630" opendate="2013-9-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add thread which detects JVM pauses like HADOOP&amp;#39;s</summary>
      <description>Todd adds daemon threads for dn&amp;nn to indicate the VM or kernel caused pause in application log, it's pretty handy for diagnose, i thought it's great to have similar ability in HBase.</description>
      <version>0.98.0</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-9-24 01:00:00" id="9650" opendate="2013-9-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Per region metrics are not showing up for system tables.</summary>
      <description>Per region metrics are not showing up for system tables.</description>
      <version>0.98.0,0.96.0</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerMetrics.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperStub.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.thrift.MetricsThriftServerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop1-compat.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop1-compat.src.main.java.org.apache.hadoop.hbase.thrift.MetricsThriftServerSourceImpl.java</file>
      <file type="M">hbase-hadoop1-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapper.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2008-10-27 01:00:00" id="967" opendate="2008-10-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[Optimization] Cache cell maximum length (HCD.getMaxValueLength); its used checking batch size.</summary>
      <description>In profiler, I can see doing an upload that 4% of CPU is spent doing Bytes.toString on HCD String representation of the Cell maximum value. Cache it.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-10-27 01:00:00" id="9670" opendate="2013-9-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Client pause should be 100ms everywhere</summary>
      <description>It was changed to 100ms, but kept as 1000ms in a lot of places...</description>
      <version>0.98.0,0.96.0</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-10-1 01:00:00" id="9693" opendate="2013-10-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix javadoc warnings</summary>
      <description>There are not many javadoc warnings. We can fix them all.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HFileV1Detector.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.TableAuthManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ProcedureCoordinator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.migration.UpgradeTo96.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.Reference.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.executor.EventHandler.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.OrderedBytes.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.Tag.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.compress.Compression.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.AggregationClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.catalog.MetaReader.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-10-1 01:00:00" id="9695" opendate="2013-10-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Some never used local variables cleanup.</summary>
      <description>There is few local variables defined that we can clean-up.</description>
      <version>0.98.0,0.96.1</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestTags.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestQueryMatcher.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.filter.TestComparatorSerialization.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-10-2 01:00:00" id="9699" opendate="2013-10-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>For Downstreamers using HBaseTestingUtility is hard.</summary>
      <description>Maven doesn't seem to play well with trasitive dependencies from -test jars. We should follow the lead of hadoop-common and create a module for test utilities.</description>
      <version>0.98.0,0.95.2,0.96.0</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-thrift.pom.xml</file>
      <file type="M">hbase-shell.pom.xml</file>
      <file type="M">hbase-it.pom.xml</file>
      <file type="M">hbase-examples.pom.xml</file>
      <file type="M">hbase-assembly.pom.xml</file>
      <file type="M">hbase-testing-util.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-10-29 01:00:00" id="970" opendate="2008-10-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update the copy/rename scripts to go against change API</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.rename.table.rb</file>
      <file type="M">bin.copy.table.rb</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-12-5 01:00:00" id="9718" opendate="2013-10-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a test scope dependency on org.slf4j:slf4j-api to hbase-client</summary>
      <description>hbase-client needs a test scope dependency on org.slf4j:slf4j-api in its POM. Without this change at least Eclipse cannot resolve org.slf4j.Logger from RecoverableZooKeeper - the ZooKeeper classes use it - and so the 'hbase-client' project will not build.</description>
      <version>0.98.0</version>
      <fixedVersion>0.98.0,0.96.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-11-30 01:00:00" id="972" opendate="2008-10-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update hbase trunk to use released hadoop 0.19.0</summary>
      <description>HBASE-839 put TRUNK on 0.19.0RC0. This issue is about updating to the released version of 0.19.0.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">lib.native.Linux-i386-32.libhadoop.a</file>
      <file type="M">lib.native.Linux-amd64-64.libhadoop.a</file>
      <file type="M">lib.hadoop-0.19.0-r709583-test.jar</file>
      <file type="M">lib.hadoop-0.19.0-r709583-core.jar</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-10-30 01:00:00" id="973" opendate="2008-10-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[doc] In getting started, make it clear that hbase needs to create its directory in hdfs</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.overview.html</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-6-9 01:00:00" id="9733" opendate="2013-10-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Book should have individual Disqus comment per page</summary>
      <description>Instead of one blob of comments for the whole thing, each page in the book should be it's own "article", or whatever Disqus uses it uniquely identify an comment-able entity.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.customization.xsl</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-10-11 01:00:00" id="9745" opendate="2013-10-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Append HBASE_CLASSPATH to end of Java classpath and use another env var for prefix</summary>
      <description>HBASE-9097 changed the behavior to prefix HBASE_CLASSPATH to end of Java classpath instead of appending it. This break existing behavior (read more on HBASE-9097).We should revert to existing behavior and provide another way to prefix certain jars to the classpath.</description>
      <version>0.98.0,0.95.2,0.94.11</version>
      <fixedVersion>0.98.0,0.94.13,0.96.1,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-11-31 01:00:00" id="975" opendate="2008-10-31 00:00:00" resolution="Won&amp;#39;t Fix">
    <buginformation>
      <summary>Improve MapFile performance for start and end key</summary>
      <description>Keeping a MapFile's start and end key in cache would save us some seeks, see if it can be done.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestSplit.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestHStoreFile.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.HBaseClusterTestCase.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStoreFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.ImmutableBytesWritable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.io.BlockFSInputStream.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-10-12 01:00:00" id="9753" opendate="2013-10-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Excessive readpoint checks in MemstoreScanner</summary>
      <description>Brought up by vrodionov on the mailing list. See also HBASE-9751.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.94.13,0.96.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStore.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-10-14 01:00:00" id="9755" opendate="2013-10-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cannot run classes in hbase-server tests jar from command line</summary>
      <description>cached_classpath.txt no longer contains references to hbase-server-version-tests.jar. This prevents to run classes under hbase-server/src/test from bin/hbase script.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-assembly.pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2008-10-31 01:00:00" id="976" opendate="2008-10-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HADOOP 0.19.0 RC0 is broke; replace with HEAD of branch-0.19</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">lib.hadoop-0.19.0-RC0-test.jar</file>
      <file type="M">lib.hadoop-0.19.0-RC0-core.jar</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-10-15 01:00:00" id="9771" opendate="2013-10-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[WebUI] Humanize store and blockcache statistics on RS</summary>
      <description>Some statistics reported on webui don't include hints about what the unit is, leaving people guessing about what they mean. Clean them up.</description>
      <version>0.98.0,0.96.0</version>
      <fixedVersion>0.98.0,0.96.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl.jamon</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2013-10-30 01:00:00" id="9861" opendate="2013-10-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Location does not have to be refreshed on regionTooBusy</summary>
      <description>Minor improvement. There is already some code to manage the exception, so I've change it to share between the classes.</description>
      <version>0.98.0,0.96.0</version>
      <fixedVersion>0.96.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestHCM.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.RegionOpeningException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.RegionMovedException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-11-1 01:00:00" id="9874" opendate="2013-11-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Append and Increment operation drops Tags</summary>
      <description>We should consider tags in the existing cells as well as tags coming in the cells within Increment/Append</description>
      <version>0.98.0</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestTags.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CellUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-11-4 01:00:00" id="9882" opendate="2013-11-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support Append Operation with thrift</summary>
      <description/>
      <version>0.98.0</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.test.java.org.apache.hadoop.hbase.thrift2.TestThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-thrift.src.main.resources.org.apache.hadoop.hbase.thrift2.hbase.thrift</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftUtilities.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftHBaseServiceHandler.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.THBaseService.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-12-4 01:00:00" id="9884" opendate="2013-11-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add Thrift and REST support for Visibility Labels</summary>
      <description>In HBASE-7663 the REST and thrift support has been seperated out because the patch is becoming bigger. This JIRA is to add the Thrift and REST part as a seperated patch.</description>
      <version>0.98.0</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.resources.org.apache.hadoop.hbase.thrift2.hbase.thrift</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftUtilities.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TScan.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TPut.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIncrement.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TGet.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumnValue.java</file>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TAppend.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestScannerModel.java</file>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.ScannerMessage.proto</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerResultGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RowSpec.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.ScannerMessage.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.ScannerModel.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-11-6 01:00:00" id="9900" opendate="2013-11-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix unintended byte[].toString in AccessController</summary>
      <description>Found while running FindBugs for another change.</description>
      <version>0.98.0,0.96.1</version>
      <fixedVersion>0.98.0,0.96.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.TableAuthManager.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2008-11-11 01:00:00" id="993" opendate="2008-11-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Turn of logging of every catalog table row entry on every scan</summary>
      <description>Just log edits. In an install with many tables and thousands of regions per table, the DEBUG log is clogged with statements of the obvious.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.RootScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.MetaScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.MetaRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.BaseScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableMapReduceUtil.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2008-11-11 01:00:00" id="996" opendate="2008-11-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Migration script to up the versions in catalog tables</summary>
      <description>Rewrite meta regions with the versions set to 10 instead of 1. See HBASE-993.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.util.Migrate.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">conf.hbase-env.sh</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-12-13 01:00:00" id="9966" opendate="2013-11-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create IntegrationTest for Online Bloom Filter Change</summary>
      <description>For online schema change, a user is perfectly with her rights to modify the compression algorithm used, or the bloom filter.Therefore, we should add these actions to our ChaosMonkey tests to ensure that they do not introduce instability.</description>
      <version>0.98.0,0.96.1</version>
      <fixedVersion>0.96.1,0.98.1,0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.factories.SlowDeterministicMonkeyFactory.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-11-19 01:00:00" id="9998" opendate="2013-11-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix javadoc warnings induced by commits</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-3-19 01:00:00" id="9999" opendate="2013-11-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add support for small reverse scan</summary>
      <description>HBASE-4811 adds feature of reverse scan. This JIRA adds the support for small reverse scan.This is activated when both 'reversed' and 'small' attributes are true in Scan Object</description>
      <version>None</version>
      <fixedVersion>0.98.1,0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedScannerCallable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ReversedClientScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
    </fixedFiles>
  </bug>
</bugrepository>