<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="HBASE">
  
  <bug fixdate="2014-5-14 01:00:00" id="11168" opendate="2014-5-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[docs] Remove references to RowLocks in post 0.96 docs.</summary>
      <description>Row locks were removed in 0.95 by HBASE-7315 / HBASE-2332. There are a few vestiges of them in the docs. Remove.</description>
      <version>0.95.0</version>
      <fixedVersion>0.99.0,0.98.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.troubleshooting.xml</file>
      <file type="M">src.main.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2011-3-29 01:00:00" id="4284" opendate="2011-8-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>document permissions that need to be set on importtsv output before completebulkload</summary>
      <description>I am using HBase 0.94 from CDH3u1.After running importtsv using the -Dimporttsv.bulk.output=&lt;output dir&gt; option, I find that completebulkload fails due to hbase not having write permissions on the contents of the output dir that importtsv wrote. I have to manually set write permissions on these contents before I can run completebulkload successfully.Ideally, I should not have to do that (set the permissions manually). Given that I do, this should at least be documented as a limitation of the importtsv utility.</description>
      <version>0.90.4,0.98.0,0.95.0</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-6-30 01:00:00" id="6135" opendate="2012-5-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Style the Web UI to use Twitter&amp;#39;s Bootstrap.</summary>
      <description>Our web ui has lagged a little bit behind. While it's not a huge deal, it is one of the first things that new people see. As such styling it a little bit better would put a good foot forward.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmpl.jamon</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.tablesDetailed.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-10-14 01:00:00" id="6583" opendate="2012-8-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enhance Hbase load test tool to automatically create column families if not present</summary>
      <description>The load test tool currently disables the table and applies any changes to the cf descriptor if any, but does not create the cf if not present.</description>
      <version>None</version>
      <fixedVersion>0.94.3,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.LoadTestTool.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-8-23 01:00:00" id="6643" opendate="2012-8-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Accept encoded region name in compacting/spliting region from shell</summary>
      <description>Sometimes, the region name has binary characters. When compacting/splitting it from shell, the region name is not recognized. If we can support encoded region name, it will make things easier.</description>
      <version>None</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-11-12 01:00:00" id="7151" opendate="2012-11-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Better log message for Per-CF compactions</summary>
      <description>A coworker pointed out that in HBASE-4913 it would be nice to include the column family in the log message for a per-CF compaction.</description>
      <version>None</version>
      <fixedVersion>0.94.3,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-1-25 01:00:00" id="7669" opendate="2013-1-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>ROOT region wouldn&amp;#39;t be handled by PRI-IPC-Handler</summary>
      <description>RPC reuqest about ROOT region should be handled by PRI-IPC-Handler, just the same as META region</description>
      <version>0.94.6,0.95.0</version>
      <fixedVersion>0.94.5,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestPriorityRpc.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-2-4 01:00:00" id="7763" opendate="2013-2-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compactions not sorting based on size anymore.</summary>
      <description>Currently compaction selection is not sorting based on size. This causes selection to choose larger files to re-write than are needed when bulk loads are involved.</description>
      <version>0.94.6,0.95.0</version>
      <fixedVersion>0.94.6,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  <bug fixdate="2013-8-27 01:00:00" id="7954" opendate="2013-2-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix the retrying logic of memstore flushes to avoid extra sleep</summary>
      <description>Matteo pointed out:"We can avoid the redundant sleep in the retrying logic."</description>
      <version>0.94.5,0.95.0</version>
      <fixedVersion>0.98.0,0.94.12</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-3-1 01:00:00" id="7968" opendate="2013-3-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Packaging of Trunk and 0.95 does not create the dependent jars in the lib folder</summary>
      <description>After recent changes to trunk and 0.95 branch when i try to build and package, i do not find the dependent jars in the lib folder.Prior to the changes, it was working fine.Am not a maven expert. Will try to see what is going wrong here.</description>
      <version>0.98.0,0.95.0</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.assembly.hadoop-two-compat.xml</file>
      <file type="M">src.assembly.hadoop-one-compat.xml</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-protocol.pom.xml</file>
      <file type="M">hbase-prefix-tree.pom.xml</file>
      <file type="M">hbase-it.pom.xml</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-hadoop1-compat.pom.xml</file>
      <file type="M">hbase-hadoop-compat.pom.xml</file>
      <file type="M">hbase-examples.pom.xml</file>
      <file type="M">hbase-common.pom.xml</file>
      <file type="M">hbase-client.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-3-2 01:00:00" id="7977" opendate="2013-3-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Online merge should acquire table lock</summary>
      <description>Once online merge (HBASE-7403) is in, we should ensure that we acquire a table write lock during the merge.</description>
      <version>0.98.0,0.95.0</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionMergeRequest.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2013-3-5 01:00:00" id="8004" opendate="2013-3-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Creating an existing table from Shell does not throw TableExistsException</summary>
      <description>When i try to create a same table from shell i don't get TableExistsException instead i getERROR: cannot load Java class org.apache.hadoop.hbase.TableNotFoundExceptionHere is some help for this command:Creates a table. Pass a table name, and a set of column familyspecifications (at least one), and, optionally, table configuration.Column specification can be a simple string (name), or a dictionary(dictionaries are described below in main help output), necessarilyincluding NAME attribute.Examples: hbase&gt; create 't1', {NAME =&gt; 'f1', VERSIONS =&gt; 5} hbase&gt; create 't1', {NAME =&gt; 'f1'}, {NAME =&gt; 'f2'}, {NAME =&gt; 'f3'} hbase&gt; # The above in shorthand would be the following:</description>
      <version>0.95.0</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.ruby.shell.commands.rb</file>
      <file type="M">bin.region.status.rb</file>
      <file type="M">bin.region.mover.rb</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-3-8 01:00:00" id="8041" opendate="2013-3-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>WebUI doesn&amp;#39;t display snapshots correctly</summary>
      <description>It seems that the jamon code got some problem during the merge.The connection is closed too early and the snapshots are not loaded.</description>
      <version>0.95.0</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-3-8 01:00:00" id="8042" opendate="2013-3-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Offline Meta Repair no longer points to the correct location</summary>
      <description>B.4.3. Special case: Root and META are corrupt.The most drastic corruption scenario is the case where the ROOT or META is corrupted and HBase will not start. In this case you can use the OfflineMetaRepair tool create new ROOT and META regions and tables. This tool assumes that HBase is offline. It then marches through the existing HBase home directory, loads as much information from region metadata files (.regioninfo files) as possible from the file system. If the region metadata has proper table integrity, it sidelines the original root and meta table directories, and builds new ones with pointers to the region directories and their data.$ ./bin/hbase org.apache.hadoop.hbase.util.OfflineMetaRepairThe path should be org.apache.hadoop.hbase.util.hbck.OfflineMetaRepair</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-3-8 01:00:00" id="8043" opendate="2013-3-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix a few javadoc warnings...</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlLists.java</file>
      <file type="M">hbase-server.src.main.javadoc.org.apache.hadoop.hbase.thrift.package.html</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-3-9 01:00:00" id="8058" opendate="2013-3-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade site plugin; fix assembly doc up on jenkins builds</summary>
      <description>Up on jenkins, we currently make assemblies but there no doc in them. The site goal runs last. You can't run it anywhere else else build fails. Upgrading the site plugin helps. Upgrading site plugin I notice that there are a bunch of extra reports generated that would be no harm showing on the web site; e.g. dependencies transitively included, what dependencies we have, etc. This issue is about upgrading site plugin to fix jenkins assemblies and to expose reports we are generating anyways (at least one report is new w/ the info-report upgrade from earlier today).</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-3-14 01:00:00" id="8108" opendate="2013-3-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add m2eclispe lifecycle mapping to hbase-common</summary>
      <description>The maven-antrun-plugin execution doesn't have a default mapping in m2eclipse, so if you import the project into eclipse, you will get an error that the mapping is undefined. All that's needed is to define an execution via the org.eclipse.m2 lifecycle-mapping plugin - it doesn't actually affect the usual maven build at all.</description>
      <version>0.98.0,0.95.0</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-3-17 01:00:00" id="8130" opendate="2013-3-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>initialize TableLockManager before initializing AssignmentManager</summary>
      <description>Getting NullPointerException while recovering disabling/enabling tables in AM.AM.tableLockManager is not pointing to HM.tableLockManager initalized after AM initialization.So its always null.</description>
      <version>0.95.0</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2013-3-19 01:00:00" id="8147" opendate="2013-3-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add Integration Test for "The HCat Scenario"</summary>
      <description>HBASE-8140 needs an integration test.</description>
      <version>0.98.0,0.95.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.mapreduce.IntegrationTestImportTsv.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-11-27 01:00:00" id="8203" opendate="2013-3-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>master ui should display region servers with host, port plus startcode</summary>
      <description>in master UI we are displaying only hostname of region servers.some shell commands need servername(host,port,startcode format) as argument A 'server_name' is the host, port plus startcode of a regionserver. Forexample: host187.example.com,60020,1289493121758 (find servername inmaster ui or when you do detailed status in shell)</description>
      <version>0.95.0</version>
      <fixedVersion>0.98.0,0.96.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.RegionServerListTmpl.jamon</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2008-8-12 01:00:00" id="821" opendate="2008-8-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>UnknownScanner happens too often.</summary>
      <description>Jean-Daniel up on the list in an exchange with Dru Jensen solved an issue by recommending longer lease for client scanners in a MR job. Lets make change to conf. This lessens the impact of Andrew Purtell added retry on USE in HBASE-816 in TableMap but will help in MR tasks that don't subclass TableMap.</description>
      <version>None</version>
      <fixedVersion>0.2.1,0.18.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-4-1 01:00:00" id="8236" opendate="2013-4-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Set finalName property in hbase-assembly else basename is hbase-assembly rather than hbase.</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-assembly.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-4-2 01:00:00" id="8242" opendate="2013-4-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unable to start HBase 0.95.0RC0 out of the box because of ZK trying to access /var/folders/</summary>
      <description>HBase 0.95.0RC0 is failing out of the box because of some ZooKeeper exceptions to write in /var/folders/jmspaggi@virtual:~/hbase-0.95.0-hadoop1$ bin/start-hbase.sh jmspaggi@virtual:~/hbase-0.95.0-hadoop1$ tail -100f logs/hbase-jmspaggi-master-virtual.log mardi 2 avril 2013, 07:24:13 (UTC-0400) Starting master on virtualcore file size (blocks, -c) 0data seg size (kbytes, -d) unlimitedscheduling priority (-e) 0file size (blocks, -f) unlimitedpending signals (-i) 31634max locked memory (kbytes, -l) 64max memory size (kbytes, -m) unlimitedopen files (-n) 1024pipe size (512 bytes, -p) 8POSIX message queues (bytes, -q) 819200real-time priority (-r) 0stack size (kbytes, -s) 8192cpu time (seconds, -t) unlimitedmax user processes (-u) 31634virtual memory (kbytes, -v) unlimitedfile locks (-x) unlimited2013-04-02 07:24:16,093 INFO org.apache.hadoop.hbase.util.VersionInfo: HBase 0.95.0-hadoop12013-04-02 07:24:16,132 INFO org.apache.hadoop.hbase.util.VersionInfo: Subversion file:///Users/stack/checkouts/0.95/hbase-common -r Unknown2013-04-02 07:24:16,132 INFO org.apache.hadoop.hbase.util.VersionInfo: Compiled by stack on Mon Apr 1 15:38:48 PDT 20132013-04-02 07:24:17,475 INFO org.apache.zookeeper.server.ZooKeeperServer: Server environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT2013-04-02 07:24:17,475 INFO org.apache.zookeeper.server.ZooKeeperServer: Server environment:host.name=virtual.distparser.com2013-04-02 07:24:17,586 INFO org.apache.zookeeper.server.ZooKeeperServer: Server environment:java.version=1.7.0_132013-04-02 07:24:17,587 INFO org.apache.zookeeper.server.ZooKeeperServer: Server environment:java.vendor=Oracle Corporation2013-04-02 07:24:17,587 INFO org.apache.zookeeper.server.ZooKeeperServer: Server environment:java.home=/home/jmspaggi/jdk/jre2013-04-02 07:24:17,587 INFO org.apache.zookeeper.server.ZooKeeperServer: Server environment:java.class.path=/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../conf:/home/jmspaggi/jdk//lib/tools.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/..:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/activation-1.1.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/asm-3.1.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/commons-beanutils-1.7.0.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/commons-cli-1.2.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/commons-codec-1.7.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/commons-collections-3.2.1.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/commons-configuration-1.6.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/commons-digester-1.8.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/commons-el-1.0.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/commons-httpclient-3.0.1.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/commons-io-2.4.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/commons-lang-2.6.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/commons-logging-1.1.1.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/commons-math-2.1.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/commons-net-1.4.1.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/core-3.1.1.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/guava-12.0.1.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/hadoop-core-1.1.2.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/hbase-client-0.95.0-hadoop1.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/hbase-common-0.95.0-hadoop1.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/hbase-common-0.95.0-hadoop1-tests.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/hbase-examples-0.95.0-hadoop1.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/hbase-hadoop1-compat-0.95.0-hadoop1.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/hbase-hadoop-compat-0.95.0-hadoop1.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/hbase-it-0.95.0-hadoop1.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/hbase-it-0.95.0-hadoop1-tests.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/hbase-prefix-tree-0.95.0-hadoop1.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/hbase-protocol-0.95.0-hadoop1.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/hbase-server-0.95.0-hadoop1.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/hbase-server-0.95.0-hadoop1-tests.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/high-scale-lib-1.1.1.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/htrace-1.50.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/httpclient-4.1.3.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/httpcore-4.1.3.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/jackson-core-asl-1.8.8.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/jackson-xc-1.8.8.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/jamon-runtime-2.3.1.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/jasper-compiler-5.5.23.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/jasper-runtime-5.5.23.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/jaxb-api-2.1.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/jersey-core-1.8.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/jersey-json-1.8.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/jersey-server-1.8.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/jetty-6.1.26.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/jetty-util-6.1.26.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/jruby-complete-1.6.8.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/jsp-2.1-6.1.14.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/jsr305-1.3.9.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/libthrift-0.9.0.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/log4j-1.2.17.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/metrics-core-2.1.2.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/netty-3.5.9.Final.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/protobuf-java-2.4.1.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/slf4j-api-1.4.3.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/slf4j-log4j12-1.4.3.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/stax-api-1.0.1.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/xmlenc-0.52.jar:/home/jmspaggi/hbase-0.95.0-hadoop1/bin/../lib/zookeeper-3.4.5.jar:/etc/hadoop:/usr/lib/jvm/java-6-sun/lib/tools.jar:/usr/libexec/../share/hadoop:/usr/libexec/../share/hadoop/hadoop-core-1.1.1.jar:/usr/libexec/../share/hadoop/lib/asm-3.2.jar:/usr/libexec/../share/hadoop/lib/aspectjrt-1.6.11.jar:/usr/libexec/../share/hadoop/lib/aspectjtools-1.6.11.jar:/usr/libexec/../share/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/libexec/../share/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/libexec/../share/hadoop/lib/commons-cli-1.2.jar:/usr/libexec/../share/hadoop/lib/commons-codec-1.4.jar:/usr/libexec/../share/hadoop/lib/commons-collections-3.2.1.jar:/usr/libexec/../share/hadoop/lib/commons-configuration-1.6.jar:/usr/libexec/../share/hadoop/lib/commons-daemon-1.0.1.jar:/usr/libexec/../share/hadoop/lib/commons-digester-1.8.jar:/usr/libexec/../share/hadoop/lib/commons-el-1.0.jar:/usr/libexec/../share/hadoop/lib/commons-httpclient-3.0.1.jar:/usr/libexec/../share/hadoop/lib/commons-io-2.1.jar:/usr/libexec/../share/hadoop/lib/commons-lang-2.4.jar:/usr/libexec/../share/hadoop/lib/commons-logging-1.1.1.jar:/usr/libexec/../share/hadoop/lib/commons-logging-api-1.0.4.jar:/usr/libexec/../share/hadoop/lib/commons-math-2.1.jar:/usr/libexec/../share/hadoop/lib/commons-net-3.1.jar:/usr/libexec/../share/hadoop/lib/core-3.1.1.jar:/usr/libexec/../share/hadoop/lib/hadoop-capacity-scheduler-1.1.1.jar:/usr/libexec/../share/hadoop/lib/hadoop-fairscheduler-1.1.1.jar:/usr/libexec/../share/hadoop/lib/hadoop-thriftfs-1.1.1.jar:/usr/libexec/../share/hadoop/lib/hsqldb-1.8.0.10.jar:/usr/libexec/../share/hadoop/lib/jackson-core-asl-1.8.8.jar:/usr/libexec/../share/hadoop/lib/jackson-mapper-asl-1.8.8.jar:/usr/libexec/../share/hadoop/lib/jasper-compiler-5.5.12.jar:/usr/libexec/../share/hadoop/lib/jasper-runtime-5.5.12.jar:/usr/libexec/../share/hadoop/lib/jdeb-0.8.jar:/usr/libexec/../share/hadoop/lib/jersey-core-1.8.jar:/usr/libexec/../share/hadoop/lib/jersey-json-1.8.jar:/usr/libexec/../share/hadoop/lib/jersey-server-1.8.jar:/usr/libexec/../share/hadoop/lib/jets3t-0.6.1.jar:/usr/libexec/../share/hadoop/lib/jetty-6.1.26.jar:/usr/libexec/../share/hadoop/lib/jetty-util-6.1.26.jar:/usr/libexec/../share/hadoop/lib/jsch-0.1.42.jar:/usr/libexec/../share/hadoop/lib/junit-4.5.jar:/usr/libexec/../share/hadoop/lib/kfs-0.2.2.jar:/usr/libexec/../share/hadoop/lib/log4j-1.2.15.jar:/usr/libexec/../share/hadoop/lib/mockito-all-1.8.5.jar:/usr/libexec/../share/hadoop/lib/oro-2.0.8.jar:/usr/libexec/../share/hadoop/lib/servlet-api-2.5-20081211.jar:/usr/libexec/../share/hadoop/lib/slf4j-api-1.4.3.jar:/usr/libexec/../share/hadoop/lib/slf4j-log4j12-1.4.3.jar:/usr/libexec/../share/hadoop/lib/xmlenc-0.52.jar:/usr/libexec/../share/hadoop/lib/jsp-2.1/jsp-2.1.jar:/usr/libexec/../share/hadoop/lib/jsp-2.1/jsp-api-2.1.jar2013-04-02 07:24:17,588 INFO org.apache.zookeeper.server.ZooKeeperServer: Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib2013-04-02 07:24:17,588 INFO org.apache.zookeeper.server.ZooKeeperServer: Server environment:java.io.tmpdir=/tmp2013-04-02 07:24:17,588 INFO org.apache.zookeeper.server.ZooKeeperServer: Server environment:java.compiler=&lt;NA&gt;2013-04-02 07:24:17,589 INFO org.apache.zookeeper.server.ZooKeeperServer: Server environment:os.name=Linux2013-04-02 07:24:17,589 INFO org.apache.zookeeper.server.ZooKeeperServer: Server environment:os.arch=amd642013-04-02 07:24:17,589 INFO org.apache.zookeeper.server.ZooKeeperServer: Server environment:os.version=3.2.0-4-amd642013-04-02 07:24:17,589 INFO org.apache.zookeeper.server.ZooKeeperServer: Server environment:user.name=jmspaggi2013-04-02 07:24:17,589 INFO org.apache.zookeeper.server.ZooKeeperServer: Server environment:user.home=/home/jmspaggi2013-04-02 07:24:17,589 INFO org.apache.zookeeper.server.ZooKeeperServer: Server environment:user.dir=/home/jmspaggi/hbase-0.95.0-hadoop12013-04-02 07:24:17,598 ERROR org.apache.hadoop.hbase.master.HMasterCommandLine: Failed to start masterjava.io.IOException: Unable to create data directory /var/folders/bp/2z1cykc92rs6j24251cg__ph0000gp/T/hbase-stack/zookeeper/zookeeper_0/version-2 at org.apache.zookeeper.server.persistence.FileTxnSnapLog.&lt;init&gt;(FileTxnSnapLog.java:85) at org.apache.zookeeper.server.ZooKeeperServer.&lt;init&gt;(ZooKeeperServer.java:213) at org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.startup(MiniZooKeeperCluster.java:161) at org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.startup(MiniZooKeeperCluster.java:131) at org.apache.hadoop.hbase.master.HMasterCommandLine.startMaster(HMasterCommandLine.java:137) at org.apache.hadoop.hbase.master.HMasterCommandLine.run(HMasterCommandLine.java:107) at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65) at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:78) at org.apache.hadoop.hbase.master.HMaster.main(HMaster.java:2482)</description>
      <version>0.95.0</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-common.pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2013-4-9 01:00:00" id="8313" opendate="2013-4-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add Bloom filter testing for HFileOutputFormat</summary>
      <description>HBASE-3776 added Bloom Filter Support to the HFileOutputFormat, but there's no test to verify that.</description>
      <version>None</version>
      <fixedVersion>0.94.7,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-6-10 01:00:00" id="8315" opendate="2013-4-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Documentation should have more information of LRU Stats</summary>
      <description>Unfortunately, there's no documentation to explain the meaning of each LRU Stats in the regionserver logs. So this is for creating a new paragraph regarding this. My current idea is below, but it's a little bit difficult to explain the difference between 'cachingAccesses' and 'accesses' from an administrator or a user views.Could you guys help to improve the content?total: The current memory size of the cache in use.free: The total free memory currently available to store more cache entries.max: Maximum allowed memory size of the cache.blocks: Caches store blocks of data; this number is the current # of blocks stored, which use up the "total" memory space.accesses: The total number of times the cache was accessed, regardless of result.hits: The total number of times the cache was accessed and the result was a successful hit (presence of looked up element in cache is a hit).hitRatio: The current percentage for "hits / accesses".====Unclear:cachingAccesses: cachingHits + The number of getBlock requests that were cache misses, but only from requests that were set to use the block cache.cachingHits: The number of getBlock requests that were cache hits, but only from requests that were set to use the block cache. This is because all reads=====cachingHitsRatio: The current percentage for "cachintHits / cachingAccesses"evictions: The total number of times an eviction has occurred (based on the use of the LRU algorithm)evicted: The total number of blocks that have been evicted (based on the use of the LRU algorithm)evictedPerRun: The total number of blocks that have been evicted overall / The number of times an eviction has occurred overallAnd also, where should we add this paragraph in the documentation?</description>
      <version>0.95.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl.jamon</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2013-6-15 01:00:00" id="8344" opendate="2013-4-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve the assignment when node failures happen to choose the secondary RS as the new primary RS</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.95.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRegionPlacement.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestFavoredNodeAssignmentHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.FavoredNodes.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.FavoredNodeLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.FavoredNodeAssignmentHelper.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-5-17 01:00:00" id="8366" opendate="2013-4-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBaseServer logs the full query.</summary>
      <description>We log the query when we have an error. As a results, the logs are not readable when using stuff like multi.As a side note, this is as well a security issue (no need to encrypt the network and the storage if the logs contain everything). I'm not removing the full log line here; but just ask and I do it .</description>
      <version>0.95.0</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.QosFunction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.IPCUtil.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-10-16 01:00:00" id="837" opendate="2008-8-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add unit tests for ThriftServer.HBaseHandler</summary>
      <description>Tim Sell over in HBASE-697 suggests we add unit tests for our thrift guts (Shouldn't need to fire up thrift to do this IIRC).</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-4-23 01:00:00" id="8390" opendate="2013-4-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Trunk/0.95 cannot simply compile against Hadoop 1.0</summary>
      <description>Currently we can't simply compile against Hadoop 1.0 in 0.95 and newer, we are missing a dependency in common for Apache's commons-io. Easy fix, we could just add that dependency for all the profiles there. But doing it correctly requires adding a new profile.</description>
      <version>0.95.0</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.DefaultLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-it.pom.xml</file>
      <file type="M">hbase-examples.pom.xml</file>
      <file type="M">hbase-common.pom.xml</file>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-5-23 01:00:00" id="8405" opendate="2013-4-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add more custom options to how ClusterManager runs commands</summary>
      <description>You may want to run yet more custom commands (such as su as some local user) depending on test setup.</description>
      <version>None</version>
      <fixedVersion>0.94.8,0.95.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.developer.xml</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.HBaseClusterManager.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-4-23 01:00:00" id="8406" opendate="2013-4-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix rat check and rat warning in trunk</summary>
      <description>See recent trunk hadoop qa where it has test properties for audit set to 84 so when there is actually a rat check problem, it doesn't show up on a hadoop qa build:https://builds.apache.org/job/PreCommit-HBASE-Build/5403/consoleFullGrep for 'There appear to be 84 release audit warnings before the patch and 1 release audit warnings after applying the patch.'Also, we have a rat warning since we did site move back out of hbase-assembly (noticed by JD).</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">dev-support.test-patch.properties</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-4-24 01:00:00" id="8421" opendate="2013-4-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase-0.95.0 tgz does not include lib/junit*.jar</summary>
      <description>The 0.95 release of hbase does not include junit-*.jar in the lib/ dir. This is required to run the hbase-it suite from the tarball.</description>
      <version>0.95.0</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-4-24 01:00:00" id="8425" opendate="2013-4-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Per-region memstore size is missing in the new RS web UI</summary>
      <description>I like that metric, right now all we have is the whole memstore size in bytes.</description>
      <version>0.95.0</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmpl.jamon</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2008-10-25 01:00:00" id="844" opendate="2008-8-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Can&amp;#39;t pass script to hbase shell</summary>
      <description>Shell documentation says:~ stack$ ${HBASE_HOME}/bin/hbase shell PATH_TO_SCRIPTYour script can lean on the methods provided by the HBase Shell.This doesn't actually work.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.hirb.rb</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2008-1-26 01:00:00" id="845" opendate="2008-8-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HCM.isTableEnabled doesn&amp;#39;t really tell if it is, or not</summary>
      <description>In current trunk, if i load a table of 8M rows and then try and delete it, the disable returns saying the table was successfully deleted but when I then try to drop the table, it says table not disabled. I run the disable/drop cycle a few more times and still fails. Eventually, if I wait long enough, it succeeds. Maybe the table drop should just block if table is seen to have disabled regions in it. As is, its a little disorientating the way it works. Could lead admins to distrust status messages emitted.</description>
      <version>None</version>
      <fixedVersion>0.19.1,0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HConnection.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.hirb.rb</file>
      <file type="M">bin.HBase.rb</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-5-30 01:00:00" id="8466" opendate="2013-4-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Netty messages in the logs</summary>
      <description>We've got this:ATTENTION: The pipeline contains no upstream handlers; discarding: [id: 0x1f79354a] OPENATTENTION: The pipeline contains no upstream handlers; discarding: [id: 0x1f79354a] BOUND: 0.0.0.0/0.0.0.0:37250ATTENTION: The pipeline contains no upstream handlers; discarding: [id: 0x1f79354a, 0.0.0.0/0.0.0.0:37250 =&gt; /226.1.1.3:60100] CONNECTED: /226.1.1.3:60100ATTENTION: The pipeline contains no upstream handlers; discarding: [id: 0x1f79354a, 0.0.0.0/0.0.0.0:37250 =&gt; /226.1.1.3:60100] WRITTEN_AMOUNT: 129ATTENTION: The pipeline contains no upstream handlers; discarding: [id: 0x1f79354a, 0.0.0.0/0.0.0.0:37250 :&gt; /226.1.1.3:60100] DISCONNECTEDATTENTION: The pipeline contains no upstream handlers; discarding: [id: 0x1f79354a, 0.0.0.0/0.0.0.0:37250 :&gt; /226.1.1.3:60100] UNBOUNDATTENTION: The pipeline contains no upstream handlers; discarding: [id: 0x1f79354a, 0.0.0.0/0.0.0.0:37250 :&gt; /226.1.1.3:60100] CLOSEDWe can fix this by adding an upstream handler that discards the message without printing them.</description>
      <version>0.98.0,0.95.0</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ClusterStatusPublisher.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-7-1 01:00:00" id="8473" opendate="2013-5-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>add note to ref guide about snapshots and ec2 reverse dns requirements.</summary>
      <description>From IRC from mighty Jeremy Carroll.17:10 &lt;jeremy_carroll&gt; jmhsieh: I think I found the root cuase. All my region servers reach the barrier, but it does not continue.17:11 &lt;jeremy_carroll&gt; jmhsieh: All RS have this in their logs: 2013-05-01 00:04:56,356 DEBUG org.apache.hadoop.hbase.procedure.Subprocedure: Subprocedure 'backup1' coordinator notified of 'acquire', waiting on 'reached' or 'abort' from coordinator.17:11 &lt;jeremy_carroll&gt; jmhsieh: Then the coordinator (Master) never sends anything. They just sit until the timeout.17:12 &lt;jeremy_carroll&gt; jmhsieh: So basically 'reached' is never obtained. Then abort it set, and it fails....17:24 &lt;jeremy_carroll&gt; jmhsieh: Found the bug. The hostnames dont match the master due to DNS resolution17:25 &lt;jeremy_carroll&gt; jmhsieh: The barrier aquired is putting in the local hostname from the regionservers. In EC2 (Where reverse DNS does not work well), the master hands the internal name to the client.17:25 &lt;jeremy_carroll&gt; jmhsieh: https://s3.amazonaws.com/uploads.hipchat.com/23947/185789/au94meik0h3y5ii/Screen%20Shot%202013-04-30%20at%2017.25.50.png 17:26 &lt;jeremy_carroll&gt; jmhsieh: So it's waiting for something like 'ip-10-155-208-202.ec2.internal,60020,1367366580066' zNode to show up, but instead 'hbasemetaclustera-d1b0a484,60020,1367366580066,' is being inserted. Barrier is not reached17:27 &lt;jeremy_carroll&gt; jmhsieh: Reason being in our environment the master does not have a reverse DNS entry. So we get stuff like this on RegionServer startup in our logs.17:27 &lt;jeremy_carroll&gt; jmhsieh: 2013-05-01 00:03:00,614 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Master passed us hostname to use. Was=hbasemetaclustera-d1b0a484, Now=ip-10-155-208-202.ec2.internal17:54 &lt;jeremy_carroll&gt; jmhsieh: That was it. Verified. Now that Reverse DNS is working, snapshots are working. Now how to figure out how to get Reverse DNS working on Route53. I wished there was something like 'slave.host.name' inside of Hadoop for this. Looking at source code.</description>
      <version>0.98.0,0.94.6.1,0.95.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.troubleshooting.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-10-29 01:00:00" id="852" opendate="2008-8-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cannot scan all families in a row with a LIMIT, STARTROW, etc.</summary>
      <description>Suggest moving specification of COLUMNS inside the hash of optional arguments rather than require it proceed the hash of optional LIMIT, STARTROW, etc.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.hirb.rb</file>
      <file type="M">bin.HBase.rb</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-6-12 01:00:00" id="8532" opendate="2013-5-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[Webui] Bootstrap based webui compatibility for IE and also fix some page format issues.</summary>
      <description>HBASE-7425 brings bootstrap based webui to hbase. While trying on trunk version, Firefox works well, but IE 8/9 layout and style look strange due to compatibility issue. Add "&lt;!DOCTYPE html ...&gt;" at the beginning of all jamon html/jsp templates to fix it.Seems HBase-2110 had a work to comment out the DOCTYPE for all .jsp to make the browser run the pages in Quirks mode (http://en.wikipedia.org/wiki/Quirks_mode) due to jetty issue at that time?To support the compatibility of webui across browsers (IE/Firefox/Chrome, etc.), there are some guidelines for choosing rendering the page under standard mode or quirk mode:http://en.wikipedia.org/wiki/Quirks_modehttp://hsivonen.iki.fi/doctype/According to document, "&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd"&gt;" has the most extensive compatibility even for HTML 5. According to my test, add this could make webui works in IE (standard mode), while Firefox could not work well with styles. Looks like if in Firefox, we still need the quirk mode (no DOCTYPE declaration). So just adding conditional DOCTYPE declaration for IE,&lt;!--&amp;#91;if IE&amp;#93;&gt;&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd"&gt;&lt;!&amp;#91;endif&amp;#93;--&gt;this could make webui works for both IE and Firefox, also for Chrome and other browsers.</description>
      <version>0.98.0,0.95.0,0.95.2</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.thrift.thrift.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.rest.rest.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.zk.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.tablesDetailed.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.snapshot.jsp</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2013-5-17 01:00:00" id="8574" opendate="2013-5-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add how to rename a table in the docbook</summary>
      <description>Add a section "how to rename a table" in the doc book.The current easy solution without adding extra code in 94/95 is to use snapshotshbase shell&gt; disable 'tableName'hbase shell&gt; snapshot 'tableName', 'tableSnapshot'hbase shell&gt; clone 'tableSnapshot', 'newTableName'hbase shell&gt; delete_snapshot 'tableSnapshot'void rename(HBaseAdmin admin, String oldTableName, String newTableName) { String snapshotName = randomName(); admin.snapshot(snapshotName, oldTableName); admin.cloneSnapshot(snapshotName, newTableName); admin.deleteSnapshot(snapshotName); admin.deleteTable(oldTableName)}</description>
      <version>0.94.7,0.95.0</version>
      <fixedVersion>0.98.0,0.94.8,0.95.1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-5-21 01:00:00" id="8591" opendate="2013-5-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Doc Improvement: Replication blog</summary>
      <description>Add a section for source level metrics and some truth about table batch ops at sink.</description>
      <version>0.95.0</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.site.xdoc.replication.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-5-22 01:00:00" id="8592" opendate="2013-5-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[documentation] some updates for the reference guide regarding recent questions on the ML</summary>
      <description>I looked at the recent questions that were asked on the mailing list and tried to filled some of our gaps.</description>
      <version>None</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.troubleshooting.xml</file>
      <file type="M">src.main.docbkx.schema.design.xml</file>
      <file type="M">src.main.docbkx.performance.xml</file>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
      <file type="M">src.main.docbkx.configuration.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-5-22 01:00:00" id="8596" opendate="2013-5-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[docs] Add docs about Region server "draining" mode</summary>
      <description>HBASE-4298 introduced "draining" mode for region servers to optimize rolling restarts to allow for multiple RS's going down simultaneously. There is a good blog post from the original author. I've added highlights from and and a link to it in the Node Decommissioning section of the ref guide.</description>
      <version>0.92.2,0.98.0,0.94.7,0.95.0</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-5-29 01:00:00" id="8643" opendate="2013-5-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Do not log full classnames in logs, just the last two levels</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.log4j.properties</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-6-10 01:00:00" id="8723" opendate="2013-6-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase Intgration tests are failing because of new defaults.</summary>
      <description>Currently any IT tests that have chaos monkey fail because we are not recovering regions before the number of RPC reties is exhausted.We should set that default higher.</description>
      <version>0.95.0</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-7-5 01:00:00" id="8875" opendate="2013-7-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>incorrect javadoc for EXCLUDE_FROM_MINOR_COMPACTION</summary>
      <description>/** Major compaction flag in FileInfo */+ /** Minor compaction flag in FileInfo */ public static final byte[] EXCLUDE_FROM_MINOR_COMPACTION_KEY = Bytes.toBytes("EXCLUDE_FROM_MINOR_COMPACTION");</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-7-5 01:00:00" id="8876" opendate="2013-7-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Addendum to HBASE-8774 Add BatchSize and Filter to Thrift2 - Add BatchSize Test</summary>
      <description>HBASE-8774 adds support for batching through large rows. A unit test was missing though, which is added here. Further cleanup as well, to test scan, scan with filter, and scan with batch size separately.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2,0.94.10</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TScan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TGet.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.thrift2.TestThriftHBaseServiceHandler.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2013-12-31 01:00:00" id="9866" opendate="2013-10-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support the mode where REST server authorizes proxy users</summary>
      <description>In one use case, someone was trying to authorize with the REST server as a proxy user. That mode is not supported today. The curl request would be something like (assuming SPNEGO auth) - curl -i --negotiate -u : http://&lt;HOST&gt;:&lt;PORT&gt;/version/cluster?doas=&lt;USER&gt;</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RESTServletContainer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RESTServlet.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  
</bugrepository>