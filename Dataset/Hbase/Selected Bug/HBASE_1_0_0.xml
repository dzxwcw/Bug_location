<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="HBASE">
  
  
  
  <bug fixdate="2014-5-16 01:00:00" id="11196" opendate="2014-5-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update description of -ROOT- in ref guide</summary>
      <description>Since the resolution of HBASE-3171, &amp;#45;ROOT- is no longer used to store the location(s) of .META. . Unfortunately, not all of our documentation has been updated to reflect this change in architecture.</description>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2009-3-21 01:00:00" id="1145" opendate="2009-1-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Ensure that there is only 1 Master with Zookeeper (part of HA Master)</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.master.OOMEHMaster.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.MasterNotRunningException.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.LocalHBaseCluster.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">conf.zoo.cfg</file>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">bin.hbase</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.Hbase.thrift</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.generated.Hbase.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2014-7-2 01:00:00" id="11459" opendate="2014-7-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add more doc on compression codecs, how to hook up native lib, lz4, etc.</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-1-21 01:00:00" id="1146" opendate="2009-1-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace the HRS leases with Zookeeper</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.TestHBaseCluster.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestLogRolling.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.filter.TestRowFilterAfterWrite.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.RegionManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2014-8-24 01:00:00" id="11585" opendate="2014-7-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>PE: Allows warm-up</summary>
      <description>When we measure the latency, warm-up helps to get repeatable and useful measures.</description>
      <version>1.0.0,2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2014-8-11 01:00:00" id="11719" opendate="2014-8-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove some unused paths in AsyncClient</summary>
      <description>sershe you're ok with these changes?</description>
      <version>1.0.0,2.0.0</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2014-10-16 01:00:00" id="11998" opendate="2014-9-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document a workflow for cherry-picking a fix to a different branch</summary>
      <description>We are not all git experts and it will be helpful to have a workflow documented, understanding that there are about a million ways to do everything in git.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.developer.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2014-10-1 01:00:00" id="12147" opendate="2014-10-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Porting Online Config Change from 89-fb</summary>
      <description>This jira is to track the forward port of HBASE-8805 and HBASE-8544 implemented by gaurav.menghani in 89-fb. This improves operational efficiency in managing clusters that are serving production traffic.</description>
      <version>1.0.0</version>
      <fixedVersion>0.99.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MetaScanner.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-10-2 01:00:00" id="12151" opendate="2014-10-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make dev scripts executable</summary>
      <description>Is there any reason not to make dev-support/*.sh executable? It would make it possible to sym-link to them from a directory in the executable path for easier execution of the definitive scripts.</description>
      <version>None</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.publish.hbase.website.sh</file>
      <file type="M">dev-support.jenkinsEnv.sh</file>
      <file type="M">dev-support.jdiffHBasePublicAPI.common.sh</file>
      <file type="M">dev-support.hbase.docker.sh</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2014-10-7 01:00:00" id="12197" opendate="2014-10-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move REST</summary>
      <description>Lets move Rest to it's own module like thrift. That should allow us to remove some dependencies from the class path when running MR tests.</description>
      <version>None</version>
      <fixedVersion>0.98.8,0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RESTServer.java</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-thrift.pom.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestVersionResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestTableScan.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestTableResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestStatusResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestSchemaResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestScannersWithLabels.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestScannersWithFilters.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestScannerResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestResourceFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestMultiRowResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestGZIPResponseWrapper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestGzipFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestGetAndPutResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestDeleteRow.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.RowResourceBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.PerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestVersionModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestTableSchemaModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestTableRegionModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestTableListModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestTableInfoModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestStorageClusterVersionModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestStorageClusterStatusModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestScannerModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestRowModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestModelBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestColumnSchemaModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestCellSetModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestCellModel.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.HBaseRESTTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.DummyFilter.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.client.TestRemoteTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.client.TestRemoteHTableRetries.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.client.TestRemoteAdminRetries.java</file>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.rest.XMLSchema.xsd</file>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.VersionMessage.proto</file>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.TableSchemaMessage.proto</file>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.TableListMessage.proto</file>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.TableInfoMessage.proto</file>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.StorageClusterStatusMessage.proto</file>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.ScannerMessage.proto</file>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.ColumnSchemaMessage.proto</file>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.CellSetMessage.proto</file>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.CellMessage.proto</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.rest.rest.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.rest.index.html</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.VersionResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.TableScanResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.TableResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.StorageClusterVersionResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.StorageClusterStatusResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.SchemaResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerResultGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerInstanceResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RowSpec.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RowResultGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RowResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RootResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ResultGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RESTServletContainer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RESTServlet.java</file>
      <file type="M">hbase-assembly.pom.xml</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.Client.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.Cluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteAdmin.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.client.Response.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.Constants.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ExistsResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.filter.AuthFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.filter.GzipFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.filter.GZIPRequestStream.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.filter.GZIPRequestWrapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.filter.GZIPResponseStream.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.filter.GZIPResponseWrapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.MetricsREST.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.CellModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.CellSetModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.ColumnSchemaModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.RowModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.ScannerModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.StorageClusterStatusModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.StorageClusterVersionModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.TableInfoModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.TableListModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.TableModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.TableRegionModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.TableSchemaModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.VersionModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.MultiRowResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.package.html</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ProtobufMessageHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ProtobufStreamingUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.CellMessage.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.CellSetMessage.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.ColumnSchemaMessage.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.ScannerMessage.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.TableInfoMessage.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.TableListMessage.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.TableSchemaMessage.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.VersionMessage.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.provider.consumer.ProtobufMessageBodyConsumer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.provider.JacksonProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.provider.JAXBContextResolver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.provider.producer.PlainTextMessageBodyProducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.provider.producer.ProtobufMessageBodyProducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RegionsResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ResourceBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ResourceConfig.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-10-7 01:00:00" id="12198" opendate="2014-10-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix the bug of not updating location cache</summary>
      <description>Fix the bug of not updating location cache.Add a testcase for it.</description>
      <version>1.0.0,0.98.7,2.0.0</version>
      <fixedVersion>0.98.8,0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTableMultiplexer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-10-8 01:00:00" id="12200" opendate="2014-10-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>When an RPC server handler thread dies, throw exception</summary>
      <description>When a Rpc server handler thread dies, throws exception so as to find out what issues caused the handler to exit.It relates to HBASE-12028.</description>
      <version>None</version>
      <fixedVersion>0.98.8,0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcExecutor.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2014-11-17 01:00:00" id="12285" opendate="2014-10-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Builds are failing, possibly because of SUREFIRE-1091</summary>
      <description>Our branch-1 builds on builds.apache.org have been failing in recent days after we switched over to an official version of Surefire a few days back (HBASE-4955). The version we're using, 2.17, is hit by a bug (SUREFIRE-1091) that results in an IOException, which looks like what we're seeing on Jenkins.</description>
      <version>1.0.0</version>
      <fixedVersion>0.99.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.resources.log4j.properties</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-10-19 01:00:00" id="12288" opendate="2014-10-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support DirectByteBuffer usage in DataBlock Encoding area</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.99.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.ByteBufferUtils.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.PrefixKeyDeltaEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.FastDiffDeltaEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.DiffKeyDeltaEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.CopyKeyDataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2014-12-1 01:00:00" id="12606" opendate="2014-12-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Sanity check encryption configuration before opening WAL or onlining regions</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.0.0,0.98.9</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestIngestWithEncryption.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2014-12-11 01:00:00" id="12675" opendate="2014-12-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use interface methods in shell scripts</summary>
      <description>There are places in the shell script code that use methods from HTable or HConnection or etc. This patch will fix at least some of them.</description>
      <version>None</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.table.rb</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.security.rb</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-1-18 01:00:00" id="12708" opendate="2014-12-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document newly introduced params for using Thrift-over-HTTPS.</summary>
      <description>Per the description.</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.security.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-12-18 01:00:00" id="12709" opendate="2014-12-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[mvn] Add unit test excludes command line flag to the build.</summary>
      <description>I've added a simple way to specify unit test classes to skip when executing unit test runs. I've added a -D variable called test.exclude.pattern that you can using like this:mvn test -Dtest.exclude.pattern=**/TestFoo.java,**/TestBar.javato exclude the unit tests form TestFoo and TestBar in this run. By default there is nothing excluded.</description>
      <version>1.0.0,0.98.10,2.0.0</version>
      <fixedVersion>1.0.0,hbase-11339,0.98.10,1.1.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-4-20 01:00:00" id="1271" opendate="2009-3-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow multiple tests to run on one machine</summary>
      <description>Currently, if we try to run two tests on one machine (e.g. in two checkouts) the second one will fail because its servers won't be able to bind to ports. We should use random ports in our servers in the tests to fix this.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.MiniZooKeeperCluster.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.MiniHBaseCluster.java</file>
      <file type="M">src.test.hbase-site.xml</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HServerInfo.java</file>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2009-5-20 01:00:00" id="1272" opendate="2009-3-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unreadable log messages -- "... to the only server localhost_1237525439599_56094" &lt;- You&amp;#39;d have to be perverse to recognize that as a hostname, startcode, and port number.</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.HServerInfo.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-10-20 01:00:00" id="1276" opendate="2009-3-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[testing] Upgrade to JUnit 4.x and use @BeforeClass annotations to optimize tests</summary>
      <description>If we upgrade to JUnit 4.x we can get access to @BeforeClass annotations... that allows us to start up DFS &amp; Hbase only once per test class. This should improve the speed of our unit tests substantially.We will also need an ability to reset the hbase state between tests however. Drop all tables for example.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">lib.junit-3.8.1.jar</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-1-29 01:00:00" id="12768" opendate="2014-12-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support enable cache_data_on_write in Shell while creating table</summary>
      <description>A simple approach to support cache_data_on_write while creating table in shell.</description>
      <version>1.0.0,0.94.27,2.0.0</version>
      <fixedVersion>1.0.0,0.98.10,1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-1-29 01:00:00" id="12773" opendate="2014-12-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add warning message when user is trying to bulkload a large HFile.</summary>
      <description>As per the description.</description>
      <version>None</version>
      <fixedVersion>1.0.0,0.98.10</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2014-1-30 01:00:00" id="12785" opendate="2014-12-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use FutureTask to timeout the attempt to get the lock for hbck</summary>
      <description>In reviewing HBASE-12607, Sean pointed out:It would be nice if we used a FutureTask to timeout the attempt to get the lock rather than wait the whole period and then fail.This issue is to address Sean's review comment.</description>
      <version>None</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2015-1-9 01:00:00" id="12831" opendate="2015-1-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Changing the set of vis labels a user has access to doesn&amp;#39;t generate an audit log event</summary>
      <description>Right now, the AccessController makes sure that (when users care about audit events) we generate an audit log event for any access change, like granting or removing a permission from a user.When the set of labels a user has access to is altered, it gets handled by the VisibilityLabelService and we don't log anything to the audit log.</description>
      <version>1.0.0,0.98.6,2.0.0</version>
      <fixedVersion>1.0.0,0.98.10,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityController.java</file>
      <file type="M">conf.log4j.properties</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-2-29 01:00:00" id="12944" opendate="2015-1-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support patches to branches in precommit jenkins build</summary>
      <description>We have a quite a few active branches now, which makes backporting a full time job. I was thinking about whether we can get hadoopqa to test the patches specific to branches with the code from that branch. I think we can grab the branch name from the patch file name and check out that branch prior to running the tests. I have a patch, but not sure whether it will work. Let me experiment a bit. If hadoopqa gets broken, it is probably this issue.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.properties</file>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2015-3-10 01:00:00" id="13006" opendate="2015-2-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document visibility label support for groups</summary>
      <description>This is to document the changes added from HBASE-12745.</description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.security.adoc</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.set.auths.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.get.auths.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.clear.auths.rb</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2015-8-18 01:00:00" id="13062" opendate="2015-2-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add documentation coverage for configuring dns server with thrift and rest gateways</summary>
      <description>Currently, the documentation doesn't cover about configuring DNS with thrift or rest gateways, though code base does provide provision for doing so. The following parameters are being used for accomplishing the same.For REST: hbase.rest.dns.interface hbase.rest.dns.nameserverFor Thrift: hbase.thrift.dns.interface hbase.thrift.dns.nameserver</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.security.adoc</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-2-18 01:00:00" id="13065" opendate="2015-2-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Increasing -Xmx when running TestDistributedLogSplitting</summary>
      <description>Found this in PreCommit Build reportshttps://builds.apache.org/job/PreCommit-HBASE-Build/12885/artifact/hbase-server/target/surefire-reports/org.apache.hadoop.hbase.master.TestDistributedLogSplitting-output.txt2015-02-18 03:45:42,141 WARN [RS:4;asf901:41265] util.Sleeper(97): We slept 59018ms instead of 1000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired2015-02-18 03:45:26,750 WARN [JvmPauseMonitor] util.JvmPauseMonitor$Monitor(167): Detected pause in JVM or host machine (eg GC): pause of approximately 39767msGC pool 'PS MarkSweep' had collection(s): count=65 time=47720msMaybe we should increase the max heap size since this test starts 6 regionservers.</description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,0.98.11,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-2-20 01:00:00" id="13081" opendate="2015-2-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Branch precommit builds are not updating to branch head before patch application</summary>
      <description>See for example https://builds.apache.org/job/PreCommit-HBASE-Build/12922//consolegit checkout 0.98Previous HEAD position was 03d8918... HBASE-13069 Thrift Http Server returns an error code of 500 instead of 401 when authentication fails (Srikanth Srungarapu)Switched to branch '0.98'Your branch is behind 'origin/0.98' by 48 commits, and can be fast-forwarded. (use "git pull" to update your local branch)git statusOn branch 0.98Your branch is behind 'origin/0.98' by 48 commits, and can be fast-forwarded. (use "git pull" to update your local branch)Untracked files: (use "git add &lt;file&gt;..." to include in what will be committed) patchprocess/nothing added to commit but untracked files present (use "git add" to track)Because the local tree is 48 commits behind the head of the 0.98 branch, the contributor's patch based on the head of 0.98 branch cannot cleanly apply.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-2-23 01:00:00" id="13086" opendate="2015-2-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Show ZK root node on Master WebUI</summary>
      <description>Currently we show a well-formed ZK quorum on the master webUI but not the root node. Root node can be changed based on deployment, so we should list it here explicitly. This information is helpful for folks playing around with phoenix.</description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,0.98.11,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-3-25 01:00:00" id="13095" opendate="2015-2-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document how to retrieve replication stats from HBase Shell</summary>
      <description/>
      <version>1.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-2-26 01:00:00" id="13111" opendate="2015-2-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>truncate_preserve command is failing with undefined method error</summary>
      <description>hbase(main):001:0&gt; truncate_preserve 't1'Truncating 't1' table (it may take a while):ERROR: undefined method `getTable' for nil:NilClassHere is some help for this command: Disables, drops and recreates the specified table while still maintaing the previous region boundaries.</description>
      <version>1.0.0,1.1.0,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.11,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-3-27 01:00:00" id="13123" opendate="2015-2-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Minor bug in ROW bloom filter</summary>
      <description>While checking the code for Bloom filter found that while checking if a key passes the ROW bloom check we try to create a bloom key. The bloom key should be constructed only with the row part of the key. But try to form the bloom key including the meta data part of the key.</description>
      <version>1.0.0,1.1.0,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.11,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-4-3 01:00:00" id="13149" opendate="2015-3-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase MR is broken on Hadoop 2.5+ Yarn</summary>
      <description>Running the server MR tools is not working on Yarn version 2.5+.Running org.apache.hadoop.hbase.mapreduce.Export:Exception in thread "main" java.lang.NoSuchMethodError: org.codehaus.jackson.map.ObjectMapper.setSerializationInclusion(Lorg/codehaus/jackson/map/annotate/JsonSerialize$Inclusion;)Lorg/codehaus/jackson/map/ObjectMapper; at org.apache.hadoop.yarn.webapp.YarnJacksonJaxbJsonProvider.configObjectMapper(YarnJacksonJaxbJsonProvider.java:59) at org.apache.hadoop.yarn.util.timeline.TimelineUtils.&lt;clinit&gt;(TimelineUtils.java:47) at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.serviceInit(YarnClientImpl.java:166) at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163) at org.apache.hadoop.mapred.ResourceMgrDelegate.serviceInit(ResourceMgrDelegate.java:102) at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163) at org.apache.hadoop.mapred.ResourceMgrDelegate.&lt;init&gt;(ResourceMgrDelegate.java:96) at org.apache.hadoop.mapred.YARNRunner.&lt;init&gt;(YARNRunner.java:112) at org.apache.hadoop.mapred.YarnClientProtocolProvider.create(YarnClientProtocolProvider.java:34) at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:95) at org.apache.hadoop.mapreduce.Cluster.&lt;init&gt;(Cluster.java:82) at org.apache.hadoop.mapreduce.Cluster.&lt;init&gt;(Cluster.java:75) at org.apache.hadoop.mapreduce.Job$9.run(Job.java:1266) at org.apache.hadoop.mapreduce.Job$9.run(Job.java:1262) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628) at org.apache.hadoop.mapreduce.Job.connect(Job.java:1261) at org.apache.hadoop.mapreduce.Job.submit(Job.java:1290) at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1314) at org.apache.hadoop.hbase.mapreduce.Export.main(Export.java:189)The problem seems to be the jackson jar version. HADOOP-10104 updated jackson version to 1.9.13. YARN-2092 reported a problem as well.HBase is using jackson 1.8.8. This version of the jar in the classpath seem to cause the problem.Should we upgrade to jackson 1.9.13?</description>
      <version>1.0.0,0.98.10.1,2.0.0</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-3-8 01:00:00" id="13174" opendate="2015-3-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Apply HBASE-11804 to Windows scripts</summary>
      <description>HBASE-11804 was only applied to the Linux scripts. Do the same for Windows. Need a +1 here from the Windows supporters, since this patch is a one liner but I need to know if it is OK to do on Windows. I'd say yes, but better ask first. cc enis</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.1,1.1.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase.cmd</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-9-12 01:00:00" id="13221" opendate="2015-3-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HDFS Transparent Encryption breaks WAL writing in Hadoop 2.6.0</summary>
      <description>We need to detect when HDFS Transparent Encryption (Hadoop 2.6.0+) is enabled and fall back to more synchronization in the WAL to prevent catastrophic failure under load.See HADOOP-11708 for more details.</description>
      <version>0.98.0,1.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-3-13 01:00:00" id="13226" opendate="2015-3-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document enable_table_replication and disable_table_replication shell commands</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-3-13 01:00:00" id="13227" opendate="2015-3-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>LoadIncrementalHFile should skip non-files inside a possible family-dir</summary>
      <description>if we have random files/dirs inside the bulkload family dir, we should try to skip them.</description>
      <version>1.0.0,1.1.0,0.98.11,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-3-13 01:00:00" id="13228" opendate="2015-3-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create procedure v2 branch and add it to QA branch list</summary>
      <description>to develop Procedure V2 quickly, we are going to commit stuff to an hbase-12439 branch.In theory we can have QA running if the patch name is HBASE-xyz-hbase-12439.patch</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.properties</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-3-17 01:00:00" id="13265" opendate="2015-3-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make thrift2 usable from c++</summary>
      <description>Currently the c++ code generated from our thrift2 idl doesn't compile. Mostly this is a naming issue for parameters.</description>
      <version>1.0.0,1.1.0,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.resources.org.apache.hadoop.hbase.thrift2.hbase.thrift</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-4-19 01:00:00" id="13289" opendate="2015-3-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>typo in splitSuccessCount metric</summary>
      <description>Our split metrics have a misspelled Count and it shows up in our jmx metrics "splitSuccessCounnt" : 0,</description>
      <version>1.0.0,0.98.10,1.1.0,0.98.11,0.98.12,0.98.10.1,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-4-20 01:00:00" id="13296" opendate="2015-3-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix the deletion of acl notify nodes for namespace.</summary>
      <description>Though we're clearing the permissions of namespaces in AccessControlLists, we're not taking care of clearing acl znodes related to namespace. Looking at the code, we're taking care of this case with tables.</description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController2.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.SecureTestUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.ZKPermissionWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-3-24 01:00:00" id="13326" opendate="2015-3-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Disabled table can&amp;#39;t be enabled after HBase is restarted</summary>
      <description>The folks at Intel discovered a pretty nasty bug in 1.0 and 1.1 (but not master). Steps to reproduce:1. Create a table, any table.2. Disable the table.3. Restart HBase.4. Try enabling the table.The table won't become enabled and the master web UI will indicate a never-ending region in transition. Also worth noting is that mbertozzi dug in and noted that this isn't happening in the master branch.</description>
      <version>1.0.0,1.1.0,0.98.12</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-4-25 01:00:00" id="13334" opendate="2015-3-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>FindBugs should create precise report for new bugs introduced</summary>
      <description>Currently findbugs build process reports only number of bugs introduced. And there is no report on what acutally was introduced.Lets improve that: we can use computeBugHistory to generate precise report on new bugs (and optionally missed bugs).Report should be available in html format.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.properties</file>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2015-4-1 01:00:00" id="13374" opendate="2015-4-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Small scanners (with particular configurations) do not return all rows</summary>
      <description>I recently ran into a couple data loss issues with small scans. Similar to HBASE-13262, these issues only appear when scans are configured in such a way that the max result size limit is reached before the caching limit is reached. As far as I can tell, this issue affects branches 0.98+I should note that after investigation it looks like the root cause of these issues is not the same as HBASE-13262. Rather, these issue are caused by errors in the small scanner logic (I will explain in more depth below). Furthermore, I do know that the solution from HBASE-13262 has not made its way into small scanners (it is being addressed in HBASE-13335). As a result I made sure to test these issues with the patch from HBASE-13335 applied and I saw that they were still present.The following two issues have been observed (both lead to data loss):1. When a small scan is configured with a caching value of Integer.MAX_VALUE, and a maxResultSize limit that is reached before the region is exhausted, integer overflow will occur. This eventually leads to a preemptive skip of the regions.2. When a small scan is configured with a maxResultSize that is smaller than the size of a single row, the small scanner will jump between regions preemptively. This issue seems to be because small scanners assume that, unless a region is exhausted, at least 2 rows will be returned from the server. This assumption isn't clearly state in the small scanners but is implied through the use of skipRowOfFirstResult.Again, I would like to stress that the root cause of these issues is NOT related to the cause of HBASE-13262. These issues occur because of inappropriate assumption made in the small scanner logic. The inappropriate assumptions are:1. Integer overflow will not occur when incrementing caching2. At least 2 rows will be returned from the server unless the region has been exhaustedI am attaching a patch that contains tests to display these issues. If these issues should be split into separate JIRAs please let me know.</description>
      <version>1.0.0,1.1.0,0.98.13,2.0.0</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannersFromClientSide.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClientSmallReversedScanner.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2009-4-22 01:00:00" id="1338" opendate="2009-4-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBASE-1234 lost use of compaction.dir; we were compacting into live store subdirectory</summary>
      <description>Found up on Ryan's cluster.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.BaseScanner.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-4-6 01:00:00" id="13412" opendate="2015-4-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Region split decisions should have jitter</summary>
      <description>Whenever a region splits it causes lots of IO (compactions are queued for a while). Because of this it's important to make sure that well distributed tables don't have all of their regions split at exactly the same time.This is basically the same as our compaction jitter.</description>
      <version>1.0.0,2.0.0</version>
      <fixedVersion>1.1.0,0.98.13,2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-4-6 01:00:00" id="13413" opendate="2015-4-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create an integration test for Replication</summary>
      <description>We want to have an end-to-end test for replication. it can write data into one cluster (with replication setup) and then read data from the other. The test should be capable of running for a long time and be reliant even under chaos monkey testing.</description>
      <version>1.0.0,2.0.0</version>
      <fixedVersion>1.1.0,0.98.13,2.0.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestBase.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-5-24 01:00:00" id="1345" opendate="2009-4-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove distributed mode from MiniZooKeeper</summary>
      <description>MiniZooKeeper currently has a standalone and a distributed mode. For HBase testing we only need (and only use) the standalone mode. We should remove all of the distributed logic.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.TestZooKeeper.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.MiniZooKeeperCluster.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.HBaseClusterTestCase.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-4-15 01:00:00" id="13477" opendate="2015-4-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create metrics on failed requests</summary>
      <description>Add a metric on how many requests failed/errored out.</description>
      <version>1.0.0,2.0.0</version>
      <fixedVersion>1.1.0,0.98.13,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestRpcMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServer.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceFactoryImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSource.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-11-15 01:00:00" id="13478" opendate="2015-4-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document the change of default master ports being used .</summary>
      <description>In 1.0.x, master by default binds to the region server ports. But in 1.1 and 2.0 branches, we have undone this changes and brought back the usage of old master ports to make the migration from 0.98 -&gt; 1.1 hassle free. Please see the parent jira for more background.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2015-4-25 01:00:00" id="13563" opendate="2015-4-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add missing table owner to AC tests.</summary>
      <description>As per the description.</description>
      <version>None</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-4-27 01:00:00" id="13577" opendate="2015-4-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Documentation is pointing to wrong port for Master Web UI</summary>
      <description>At the bottom of section 2.4 in the Hbase Documentation, there is a section about Browsing the web UI that makes several references to port 16610. http://hbase.apache.org/book.html#quickstart_fully_distributed&lt;DOCUMENTATION&gt;"In HBase newer than 0.98.x, the HTTP ports used by the HBase Web UI changed from 60010 for the Master and 60030 for each RegionServer to 16610 for the Master and 16030 for the RegionServer.If everything is set up correctly, you should be able to connect to the UI for the Master http://node-a.example.com:16610/ or the secondary master at http://node-b.example.com:16610/ for the secondary master, using a web browser. If you can connect via localhost but not from another host, check your firewall rules. You can see the web UI for each of the RegionServers at port 16630 of their IP addresses, or by clicking their links in the web UI for the Master."&lt;/DOCUMENTATION&gt;This is the wrong port; it should instead be 16010. The correct port is listed in Section 6: http://hbase.apache.org/book.html#confirmThis might seem like a pretty minor issue, but it took me a couple hours to figure out.</description>
      <version>1.0.0</version>
      <fixedVersion>1.1.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.getting.started.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-5-28 01:00:00" id="13579" opendate="2015-4-28 00:00:00" resolution="Pending Closed">
    <buginformation>
      <summary>Avoid isCellTTLExpired() for NO-TAG cases</summary>
      <description>As observed in this JIRA's performance test, we are always calling the isCellTTLExpired() for every cell and internally it is parsing the keyLength, valueLength() to get the tagsLength after which we decide whether Cell level TTL is present are not.This JIRA aims to avoid this check if all the readers of the storescanner knows that there are no tags to read. Note that, for the memstore scanner we will do that in another JIRA, which I suppose Stack had already raised to avoid tag length while flushing (for the NO-TAG) case.</description>
      <version>1.0.0,1.0.1</version>
      <fixedVersion>0.98.13,1.0.2,1.2.0,1.1.1,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-5-28 01:00:00" id="13582" opendate="2015-4-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update docs for HTrace</summary>
      <description>the ref guide currently points to HTrace at its old location. update it to point at the ASF project. Should also verify that the usage example is still correct.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.tracing.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-5-30 01:00:00" id="13599" opendate="2015-4-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>The Example Provided in Section 69: Examples of the Documentation Does Not Compile</summary>
      <description>I'm trying to build and run the example java code I found in the HBase Documentation, and I'm running into several issues.1. I don't have the code/library used in the following import:import static com.example.hbase.Constants.*;I don't believe it is included in any of the HBase libraries or documentation.2. All of the methods in createOrOverwrite() that use table.getName() should instead be using table.getTableName()3. The interface org.apache.hadoop.hbase.client.Admin is abstract, and can't be instantiated with a Configuration. Constructing an org.apache.hadoop.hbase.client.HBaseAdmin would allow the code to compile, but that constructor is deprecated.4. I have no references to the field "TABLE_NAME" or "CF_DEFAULT". I'm assuming they are Strings in com.example.hbase.Constants. Perhaps those variables should simply be copied into the the Example?Link to the documentation section:http://hbase.apache.org/book.html#_examples&lt;code&gt;package com.example.hbase.admin;import java.io.IOException;import org.apache.hadoop.hbase.HBaseConfiguration;import org.apache.hadoop.hbase.HColumnDescriptor;import org.apache.hadoop.hbase.HTableDescriptor;import org.apache.hadoop.hbase.TableName;import org.apache.hadoop.hbase.client.Admin;import org.apache.hadoop.hbase.io.compress.Compression.Algorithm;import org.apache.hadoop.conf.Configuration;import static com.example.hbase.Constants.*;public class CreateSchema { public static void createOrOverwrite(Admin admin, HTableDescriptor table) throws IOException { if (admin.tableExists(table.getName())) { admin.disableTable(table.getName()); admin.deleteTable(table.getName()); } admin.createTable(table); } public static void createSchemaTables (Configuration config) { try { final Admin admin = new Admin(config); HTableDescriptor table = new HTableDescriptor(TableName.valueOf(TABLE_NAME)); table.addFamily(new HColumnDescriptor(CF_DEFAULT).setCompressionType(Algorithm.SNAPPY)); System.out.print("Creating table. "); createOrOverwrite(admin, table); System.out.println(" Done."); admin.close(); } catch (Exception e) { e.printStackTrace(); System.exit(-1); } }}&lt;/code&gt;</description>
      <version>1.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.hbase.apis.adoc</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2015-11-5 01:00:00" id="13622" opendate="2015-5-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>document upgrade rollback</summary>
      <description>I have some docs on doing a rollback of an hbase upgrade that are currently vendor specific. polish them up, make them suitable for HBase generally, and add them to the ref guide.</description>
      <version>0.98.0,1.0.0,1.1.0</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-7-7 01:00:00" id="13639" opendate="2015-5-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>SyncTable - rsync for HBase tables</summary>
      <description>Given HBase tables in remote clusters with similar but not identical data, efficiently update a target table such that the data in question is identical to a source table. Efficiency in this context means using far less network traffic than would be required to ship all the data from one cluster to the other. Takes inspiration from rsync.Design doc: https://docs.google.com/document/d/1-2c9kJEWNrXf5V4q_wBcoIXfdchN7Pxvxv1IO6PW0-U/</description>
      <version>None</version>
      <fixedVersion>0.98.14,1.2.0,2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestBytes.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Bytes.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  <bug fixdate="2015-12-16 01:00:00" id="13907" opendate="2015-6-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document how to deploy a coprocessor</summary>
      <description>Capture this information:&gt; Where are the dependencies located for these classes? Is there a path on HDFS or local disk that dependencies need to be placed so that each RegionServer has access to them?It is suggested to bundle them as a single jar so that RS can load the whole jar and resolve dependencies. If you are not able to do that, you need place the dependencies in regionservers class path so that they are loaded during RS startup. Do either of these options work for you? Btw, you can load the coprocessors/filters into path specified by hbase.dynamic.jars.dir &amp;#91;1&amp;#93;, so that they are loaded dynamically by regionservers when the class is accessed (or you can place them in the RS class path too, so that they are loaded during RS JVM startup).&gt; How would one deploy these using an automated system? (puppet/chef/ansible/etc)You can probably use these tools to automate shipping the jars to above locations?&gt; Tests our developers have done suggest that simply disabling a coprocessor, replacing the jar with a different version, and enabling the coprocessor again does not load the newest version. With that in mind how does one know which version is currently deployed and enabled without resorting to parsing `hbase shell` output or restarting hbase?Actually this is a design issue with current classloader. You can't reload a class in a JVM unless you delete all the current references to it. Since the current JVM (classloader) has reference to it, you can't overwrite it unless you kill the JVM, which is equivalent to restarting it. So you still have the older class loaded in place. For this to work, classloader design should be changed. If it works for you, you can rename the coprocessor class name and the new version of jar and RS loads it properly.&gt; Where does logging go, and how does one access it? Does logging need to be configured in a certain way?Can you please specify which logging you are referring to?&gt; Where is a good location to place configuration files?Same as above, are these hbase configs or something else? If hbase configs, are these gateway configs/server side?</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.cp.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-6-16 01:00:00" id="13918" opendate="2015-6-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix hbase:namespace description in webUI</summary>
      <description>This inconsistency bothers me.hbase:meta The hbase:meta table holds references to all User Table regionshbase:namespace The .NAMESPACE. table holds information about namespaces.Should it be the .NAMESPACE. table? or should it be hbase:namespace</description>
      <version>1.0.0</version>
      <fixedVersion>0.98.14,1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2015-7-6 01:00:00" id="14027" opendate="2015-7-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up netty dependencies</summary>
      <description>We have multiple copies of Netty (3?) getting shipped around. clean some up.</description>
      <version>1.0.0</version>
      <fixedVersion>1.2.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-it.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-5-7 01:00:00" id="14030" opendate="2015-7-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase Backup/Restore Phase 1</summary>
      <description>This is the umbrella ticket for Backup/Restore Phase 1. See HBASE-7912 design doc for the phase description.</description>
      <version>None</version>
      <fixedVersion>HBASE-7912</fixedVersion>
      <type>Umbrella</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestRemoteBackup.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.procedure.SimpleRSProcedureManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestRestoreBoundaryTests.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestRemoteRestore.java</file>
      <file type="M">bin.hbase</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupCommands.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupCopyService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupManifest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupRestoreConstants.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupRestoreServiceFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupStatus.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupSystemTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupSystemTableHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.BackupUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.HBackupFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.IncrementalBackupManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.IncrementalRestoreService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.mapreduce.MapReduceBackupCopyService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.mapreduce.MapReduceRestoreService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.master.BackupLogCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.master.LogRollMasterProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.regionserver.LogRollBackupSubprocedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.regionserver.LogRollBackupSubprocedurePool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.regionserver.LogRollRegionServerProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.RestoreClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.RestoreUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.BaseCoordinatedStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.WALPlayer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.flush.RegionServerFlushTableProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.RegionServerProcedureManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.RegionServerProcedureManagerHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureCoordinatorRpcs.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureMemberRpcs.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.snapshot.RegionServerSnapshotManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotCopy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.DefaultWALProvider.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestBackupBase.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestBackupBoundaryTests.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestBackupLogCleaner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestBackupSystemTable.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestFullBackup.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestFullRestore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.backup.TestIncrementalBackup.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-9-7 01:00:00" id="14193" opendate="2015-8-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove support for direct upgrade from pre-0.96 versions</summary>
      <description>As discussed on the mailing list this will remove all support for upgrades from pre-0.96 versions.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSTableDescriptorMigrationToSubdir.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">bin.hbase.cmd</file>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-8-19 01:00:00" id="14260" opendate="2015-8-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>don&amp;#39;t build javadocs for hbase-protocol module</summary>
      <description>I'm not sure I have all the affected versions, but it seems that something is amiss in making our javadocs: mvn -Papache-release -Prelease -DskipTests clean package... SNIP ...[INFO] ------------------------------------------------------------------------[INFO] Reactor Summary:[INFO] [INFO] Apache HBase ....................................... SUCCESS [ 11.149 s][INFO] Apache HBase - Checkstyle .......................... SUCCESS [ 1.249 s][INFO] Apache HBase - Resource Bundle ..................... SUCCESS [ 0.539 s][INFO] Apache HBase - Annotations ......................... SUCCESS [ 4.438 s][INFO] Apache HBase - Protocol ............................ SUCCESS [10:15 min][INFO] Apache HBase - Common .............................. SUCCESS [ 48.465 s][INFO] Apache HBase - Procedure ........................... SUCCESS [ 14.375 s][INFO] Apache HBase - Client .............................. SUCCESS [ 45.187 s][INFO] Apache HBase - Hadoop Compatibility ................ SUCCESS [ 6.998 s][INFO] Apache HBase - Hadoop Two Compatibility ............ SUCCESS [ 14.891 s][INFO] Apache HBase - Prefix Tree ......................... SUCCESS [ 14.214 s][INFO] Apache HBase - Server .............................. SUCCESS [02:01 min][INFO] Apache HBase - Testing Util ........................ SUCCESS [ 12.779 s][INFO] Apache HBase - Thrift .............................. SUCCESS [01:15 min][INFO] Apache HBase - Shell ............................... SUCCESS [ 6.649 s][INFO] Apache HBase - Integration Tests ................... SUCCESS [ 6.429 s][INFO] Apache HBase - Examples ............................ SUCCESS [ 13.200 s][INFO] Apache HBase - Rest ................................ SUCCESS [ 27.831 s][INFO] Apache HBase - Assembly ............................ SUCCESS [ 19.400 s][INFO] Apache HBase - Shaded .............................. SUCCESS [ 0.419 s][INFO] Apache HBase - Shaded - Client ..................... SUCCESS [ 23.707 s][INFO] Apache HBase - Shaded - Server ..................... SUCCESS [ 43.654 s][INFO] Apache HBase - Spark ............................... SUCCESS [02:22 min][INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 21:13 min[INFO] Finished at: 2015-08-19T15:48:00-05:00[INFO] Final Memory: 181M/1513M[INFO] ------------------------------------------------------------------------</description>
      <version>0.98.0,1.0.0,1.1.0,1.2.0,2.0.0</version>
      <fixedVersion>0.98.14,1.0.2,1.2.0,1.1.2,1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-protocol.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-10-20 01:00:00" id="14271" opendate="2015-8-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve Nexus staging instructions</summary>
      <description>Refine the Nexus staging instructions a bit. (A promise I made a long time ago.)</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2009-5-29 01:00:00" id="1458" opendate="2009-5-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>64 commit logs as upper bound is too many -- make it half</summary>
      <description>Running an upload, 64 commit logs as upper bound before we force flushes to clear the oldest edit is too much. I can see an upload running in my little cluster and even after running for an hour we still have not hit the 64 logs max. The more logs we have, the longer recovery on crash. We should halve the number I'd say.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HLog.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2015-1-23 01:00:00" id="15036" opendate="2015-12-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update HBase Spark documentation to include bulk load with thin records</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.spark.adoc</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2016-7-31 01:00:00" id="15925" opendate="2016-5-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>compat-module maven variable not evaluated</summary>
      <description>Looks like we've regressed on HBASE-8488. Have a look at the dependency artifacts list on http://mvnrepository.com/artifact/org.apache.hbase/hbase-testing-util/1.2.1. Notice the direct dependency's artifactId is ${compat.module}.</description>
      <version>1.0.0,1.1.0,1.2.0,1.2.1,1.0.3,1.1.5</version>
      <fixedVersion>1.3.0,1.2.2,1.1.6,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2016-7-7 01:00:00" id="15985" opendate="2016-6-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>clarify promises about edits from replication in ref guide</summary>
      <description>we should make clear in a call out that replication only provides at-least-once delivery and doesn't guarantee ordering so that e.g. folks using increments aren't surprised.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2016-11-26 01:00:00" id="16708" opendate="2016-9-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expose endpoint Coprocessor name in "responseTooSlow" log messages</summary>
      <description>Operational diagnostics of a Phoenix install would be easier if we included which endpoint coprocessor was being called in this responseTooSlow WARN message.</description>
      <version>1.0.0</version>
      <fixedVersion>1.4.0,0.98.24,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2017-3-11 01:00:00" id="17447" opendate="2017-1-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Automatically delete quota when table is deleted</summary>
      <description>If a table has a space quota defined on it, we can delete that quota when the table is deleted.</description>
      <version>None</version>
      <fixedVersion>HBASE-16961,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2017-1-27 01:00:00" id="17562" opendate="2017-1-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove documentation for coprocessor execution times after HBASE-14205</summary>
      <description>Thanks, Steen Manniche for reporting. Opened up a subtask. Feel free to pick it up if you want to patch it yourself. Otherwise, I can do a quick patch.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.site.resources.images.coprocessor.stats.png</file>
      <file type="M">src.main.asciidoc..chapters.cp.adoc</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2017-5-15 01:00:00" id="18049" opendate="2017-5-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>It is not necessary to re-open the region when MOB files cannot be found</summary>
      <description>In HBASE-17712, we try to re-open the region when store files cannot be found. This is useful for store files in a region, but is not necessary when the MOB files cannot be found, because the store files in a region only contain the references to the MOB files and a re-open of a region doesn't help the lost MOB files.In this JIRA, we will directly throw DNRIOE only when the MOB files are not found in MobStoreScanner and ReversedMobStoreScanner. Other logics keep the same.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HMobStore.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2017-12-11 01:00:00" id="18988" opendate="2017-10-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add release managers to reference guide</summary>
      <description>Reference guide lists release managers only up to version 1.3. We should have a complete list there.http://hbase.apache.org/book.html#_release_managers</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2009-10-9 01:00:00" id="1899" opendate="2009-10-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use scanner caching in shell count</summary>
      <description>Since the shell count now uses the FirstKeyOnlyFilter, it's safe to combine it with scanner caching for huge count speedups.</description>
      <version>None</version>
      <fixedVersion>0.20.2,0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.HBase.rb</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2010-6-17 01:00:00" id="2233" opendate="2010-2-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support both Hadoop 0.20, 0.21, and 0.22</summary>
      <description>Since Hadoop 0.21 isn't going to be well supported and that a lot of users may wish to stick on 0.20, the next HBase major release should support both 0.20 and 0.21. HDFS-265 support will be swapped for HDFS-200 if running on HDFS 0.20. A cluster without that patchset shouldn't be supported.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.util.TestFSUtils.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.replication.TestReplication.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLogSplit.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.InfoServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.HFileOutputFormat.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.hadoopbackport.InputSampler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.ConnectionHeader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2020-6-22 01:00:00" id="24231" opendate="2020-4-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add hadoop 3.2.x in our support matrix</summary>
      <description/>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
    </fixedFiles>
  </bug>
</bugrepository>