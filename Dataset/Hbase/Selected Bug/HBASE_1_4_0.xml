<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="HBASE">
  
  
  <bug fixdate="2016-4-17 01:00:00" id="15664" opendate="2016-4-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use Long.MAX_VALUE instead of HConstants.FOREVER in CompactionPolicy</summary>
      <description>The TTL per CF is in seconds, we will convert it to milliseconds when construct HStore. And if it is HConstants.FOREVER, we will set it to Long.MAX_VALUE.HStore.java public static long determineTTLFromFamily(final HColumnDescriptor family) { // HCD.getTimeToLive returns ttl in seconds. Convert to milliseconds. long ttl = family.getTimeToLive(); if (ttl == HConstants.FOREVER) { // Default is unlimited ttl. ttl = Long.MAX_VALUE; } else if (ttl == -1) { ttl = Long.MAX_VALUE; } else { // Second -&gt; ms adjust for user data ttl *= 1000; } return ttl; }</description>
      <version>1.3.0,0.98.19,1.4.0,2.0.0</version>
      <fixedVersion>1.3.0,0.98.19,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.RatioBasedCompactionPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.DateTieredCompactionPolicy.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-5-9 01:00:00" id="15801" opendate="2016-5-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade checkstyle for all branches</summary>
      <description>We should use the same checkstyle for all branches.</description>
      <version>1.3.0,1.2.1,1.0.3,0.98.19,1.4.0,1.1.5,2.0.0</version>
      <fixedVersion>1.3.0,1.0.4,1.2.2,0.98.20,1.1.6,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-5-16 01:00:00" id="15834" opendate="2016-5-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Correct Bloom filter documentation in section 96.4 of Reference Guide</summary>
      <description>In section 96.4, the second paragraph from the bottomSince HBase 0.96, row-based Bloom filters are enabled by default. (HBASE-)</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.performance.adoc</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  <bug fixdate="2016-7-1 01:00:00" id="16312" opendate="2016-8-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>update jquery version</summary>
      <description>the jquery version we bundle for our web ui is EOM. update to latest jquery 3.y.we can use the jquery migrate plugin to help update APIs.</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.resources.hbase-webapps.thrift.thrift.jsp</file>
      <file type="M">hbase-thrift.src.main.resources.hbase-webapps.static.js.jquery.min.js</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.thrift.thrift.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.js.jquery.min.js</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.regionserver.storeFile.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.regionserver.region.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.regionserver.processRS.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.zk.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.tablesDetailed.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.snapshotsStats.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.snapshot.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.processRS.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.processMaster.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.procedures.jsp</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">hbase-rest.src.main.resources.hbase-webapps.rest.rest.jsp</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-8-1 01:00:00" id="16315" opendate="2016-8-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>RegionSizeCalculator prints region names as binary without escapes</summary>
      <description>Region start key is not escaped: 2016-05-20 01:35:04,646|beaver.machine|INFO|8984|140719733470976|MainThread|2016-05-20 01:35:04,637 DEBUG [main] util.RegionSizeCalculator: Region IntegrationTestBigLinkedList,��������,1463706056389.609c5d0e2a3a03eb3d93d608b9722fb9. has size 1300234242016-05-20 01:35:04,647|beaver.machine|INFO|8984|140719733470976|MainThread|2016-05-20 01:35:04,637 DEBUG [main] util.RegionSizeCalculator: Region IntegrationTestBigLinkedList,�"""""" ,1463706056389.6b2d56bc9f04339156a858595b237614. has size 1300234242016-05-20 01:35:04,647|beaver.machine|INFO|8984|140719733470976|MainThread|2016-05-20 01:35:04,637 DEBUG [main] util.RegionSizeCalculator: Region IntegrationTestBigLinkedList,��������,1463706056389.4eab8c5beba325cb8a2731151f8bbe77. has size 1342177282016-05-20 01:35:04,647|beaver.machine|INFO|8984|140719733470976|MainThread|2016-05-20 01:35:04,637 DEBUG [main] util.RegionSizeCalculator: Region IntegrationTestBigLinkedList,�wwwwwwh,1463706056389.406e8bbe17eabb4aca2b246d1242013c. has size 131072000</description>
      <version>None</version>
      <fixedVersion>1.3.0,1.1.6,1.2.3,0.98.22,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.RegionLoad.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-7-9 01:00:00" id="1632" opendate="2009-7-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Write documentation for configuring/managing ZooKeeper with HBase</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.overview.html</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-7-9 01:00:00" id="1633" opendate="2009-7-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Can&amp;#39;t delete in TRUNK shell; makes it hard doing admin repairs</summary>
      <description>Because shell uses old API, it runs into the "Can't add deletes to a BatchUpdate" issue. Add new API to do shell delete and deleteAll. Just a few lines.</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.HBase.rb</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2016-8-3 01:00:00" id="16347" opendate="2016-8-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unevaluated expressions in book</summary>
      <description>Have a look at the quickstart guide, step two$ tar xzvf hbase-&lt;?eval ${project.version}?&gt;-bin.tar.gz$ cd hbase-&lt;?eval ${project.version}?&gt;/</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.getting.started.adoc</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-8-31 01:00:00" id="16535" opendate="2016-8-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use regex to exclude generated classes for findbugs</summary>
      <description>As I tried in HBASE-16526, &lt;Match&gt; &lt;Package name="org.apache.hadoop.hbase.ipc.protobuf.generated"/&gt; &lt;/Match&gt;This does not work.So I propose that we can use regex to match the class name to exclude the generated classes.</description>
      <version>1.3.0,1.4.0,1.1.6,0.98.21,1.2.3,2.0.0</version>
      <fixedVersion>1.3.0,0.98.22,1.1.7,1.2.4,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.findbugs-exclude.xml</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2009-7-17 01:00:00" id="1670" opendate="2009-7-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>transactions / indexing fixes: trx deletes not handeled, index scan can&amp;#39;t specify stopRow</summary>
      <description>couple of things I missed in api refactor</description>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">src.contrib.transactional.src.test.org.apache.hadoop.hbase.client.transactional.TestTransactions.java</file>
      <file type="M">src.contrib.transactional.src.test.org.apache.hadoop.hbase.client.tableindexed.TestIndexedTable.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.regionserver.transactional.TransactionState.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegionServer.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegion.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.regionserver.transactional.THLog.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.regionserver.tableindexed.IndexMaintenanceUtils.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.regionserver.tableindexed.IndexedRegion.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.client.transactional.TransactionManager.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.client.transactional.TransactionalTable.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.client.transactional.JtaXAResource.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.client.tableindexed.IndexedTableDescriptor.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.client.tableindexed.IndexedTable.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-12-24 01:00:00" id="16700" opendate="2016-9-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow for coprocessor whitelisting</summary>
      <description>Today one can turn off all non-system coprocessors with hbase.coprocessor.user.enabled however, this disables very useful things like Apache Phoenix's coprocessors. Some tenants of a multi-user HBase may also need to run bespoke coprocessors. But as an operator I would not want wanton coprocessor usage. Ideally, one could do one of two things: Allow coprocessors defined in hbase-site.xml &amp;#8211; this can only be administratively changed in most cases Allow coprocessors from table descriptors but only if the coprocessor is whitelisted</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.cp.adoc</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2009-7-24 01:00:00" id="1694" opendate="2009-7-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add TOC to &amp;#39;Getting Started&amp;#39;, add references to THBase and ITHBase</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.overview.html</file>
      <file type="M">src.java.org.apache.hadoop.hbase.util.Migrate.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-12-25 01:00:00" id="16941" opendate="2016-10-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>FavoredNodes - Split/Merge code paths</summary>
      <description>This jira is to deal with the split/merge logic discussed as part of HBASE-15532. The design document can be seen at HBASE-15531. The specific changes are:Split and merged regions should inherit favored node information from parent regions. For splits also include some randomness so even if there are subsequent splits, the regions will be more or less distributed. For split, we include 2 FN from the parent and generate one random node.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRegionPlacement2.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestRegionPlacement.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockNoopMasterServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestFavoredNodeAssignmentHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SnapshotOfRegionAssignmentFromMeta.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionPlacementMaintainer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.FavoredNodeLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.FavoredNodeAssignmentHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentVerificationReport.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.ServerName.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-10-26 01:00:00" id="16949" opendate="2016-10-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix RAT License complaint about the hbase-protocol-shaded/src/main/patches content</summary>
      <description>Noticed by @duo zhang over on HBASE-16835. Let me exclude the patches dir from rat check.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-protocol.README.txt</file>
      <file type="M">hbase-protocol-shaded.README.txt</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2016-11-1 01:00:00" id="16986" opendate="2016-11-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add note on how scanner caching has changed since 0.98 to refguid</summary>
      <description>Add note on how scanner caching config changed from 0.98 to the refguide (see parent issue for discussion but basics are we used to have default of 100 but not have unlimited as default)</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-11-4 01:00:00" id="17017" opendate="2016-11-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove the current per-region latency histogram metrics</summary>
      <description/>
      <version>1.3.0,1.4.0,2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-11-11 01:00:00" id="17074" opendate="2016-11-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>PreCommit job always fails because of OOM</summary>
      <description>https://builds.apache.org/job/PreCommit-HBASE-Build/4434/artifact/patchprocess/patch-unit-hbase-server.txtException in thread "Thread-2369" java.lang.OutOfMemoryError: Java heap space at java.util.Arrays.copyOf(Arrays.java:3332) at java.lang.AbstractStringBuilder.ensureCapacityInternal(AbstractStringBuilder.java:124) at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:596) at java.lang.StringBuffer.append(StringBuffer.java:367) at java.io.BufferedReader.readLine(BufferedReader.java:370) at java.io.BufferedReader.readLine(BufferedReader.java:389) at org.apache.maven.surefire.shade.org.apache.maven.shared.utils.cli.StreamPumper.run(StreamPumper.java:66)Exception in thread "Thread-2357" java.lang.OutOfMemoryError: Java heap spaceException in thread "Thread-2365" java.lang.OutOfMemoryError: Java heap spaceRunning org.apache.hadoop.hbase.filter.TestFuzzyRowFilterEndToEndRunning org.apache.hadoop.hbase.filter.TestFilterListOrOperatorWithBlkCntException in thread "Thread-2383" java.lang.OutOfMemoryError: Java heap spaceException in thread "Thread-2397" java.lang.OutOfMemoryError: Java heap spaceException in thread "Thread-2401" java.lang.OutOfMemoryError: Java heap spaceRunning org.apache.hadoop.hbase.TestHBaseTestingUtilityException in thread "Thread-2407" java.lang.OutOfMemoryError: Java heap spaceException in thread "Thread-2411" java.lang.OutOfMemoryError: Java heap spaceException in thread "Thread-2413" java.lang.OutOfMemoryError: Java heap spaceThe OOM happens in the surefire plugin when reading the stdout or stderr of the running test...</description>
      <version>1.3.0,1.4.0,1.1.7,0.98.23,1.2.4,2.0.0</version>
      <fixedVersion>1.3.0,1.2.5,0.98.24,1.1.8,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.docker.Dockerfile</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2016-12-30 01:00:00" id="17207" opendate="2016-11-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Arrays.asList() with too few arguments</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStateStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RackManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputSaslHelper.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.FilterList.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MultiAction.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.BufferedMutatorImpl.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2016-12-19 01:00:00" id="17333" opendate="2016-12-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBASE-17294 always ensures CompactingMemstore is default</summary>
      <description>Was the purpose of HBASE-17294 is to make Compacting Memstore as default? Am not sure on that. But that patch makes DefaultMemstore as a Noop. This JIRA is to discuss and revert back to default memstore only if the family is not configured for in memory flush/compaction.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactingMemStore.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-5-21 01:00:00" id="17352" opendate="2016-12-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix hbase-assembly build with bash 4</summary>
      <description>hbase-assembly fails to build with bash 4.[DEBUG] Executing command line: [env, bash, -c, cat maven-shared-archive-resources/META-INF/NOTICE \ `find /Users/jg/github/hbase/hbase-assembly/target/dependency -iname NOTICE -or -iname NOTICE.txt` \][ERROR] Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.4.0:exec (concat-NOTICE-files) on project hbase-assembly: Command execution failed. Process exited with an error: 1 (Exit value: 1) -&gt; [Help 1]org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.4.0:exec (concat-NOTICE-files) on project hbase-assembly: Command execution failed.The error is caused by the trailing backslash in the bash command for concat-NOTICE-files. You can see the behavioral difference between bash 3 and 4 with the following snippet.$ # Using bash 3$ /bin/bash -c 'cat &lt;(echo foo) \' &amp;&amp; echo good || echo badfoogood$ # Using bash 4$ /usr/local/bin/bash -c 'cat &lt;(echo foo) \' &amp;&amp; echo good || echo badfoocat: \: No such file or directorybad</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.2.6,1.3.2,1.1.11,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-assembly.pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2017-2-23 01:00:00" id="17511" opendate="2017-1-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement enable/disable table methods</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.AsyncMetaTableAccessor.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2017-2-4 01:00:00" id="17596" opendate="2017-2-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement add/delete/modify column family methods</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2017-3-6 01:00:00" id="17600" opendate="2017-2-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement get/create/modify/delete/list namespace admin operations</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRpcRetryingCaller.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2017-2-9 01:00:00" id="17618" opendate="2017-2-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Refactor the implementation of modify table and delete column in MOB</summary>
      <description>Now in the implementation of modify table, delete column in MOB, the MOB directory is removed once for each region which is not necessary and not right. We should only delete the MOB directory only once.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.MobUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterDDLOperationHelper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2017-2-11 01:00:00" id="17634" opendate="2017-2-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up the usage of Result.isPartial</summary>
      <description>We have marked Result.isPartial as deprecated in HBASE-17599. This issue aims to remove the isPartial usage in our code base.</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestPartialResultsFromClientSide.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2017-2-25 01:00:00" id="17699" opendate="2017-2-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix TestLockProcedure</summary>
      <description>TestLockProcedure is failing consistently after HBASE-17605. It's interesting that HadoopQA didn't report any test failures on that jira. Anyways, need to fix the test now.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.MasterProcedureScheduler.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.SimpleProcedureScheduler.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureScheduler.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureExecutor.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.AbstractProcedureScheduler.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2017-3-16 01:00:00" id="17794" opendate="2017-3-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove lingering "violation" in favor of the accurate "snapshot"</summary>
      <description>Previously, quota violations used to be stored in the quota table. Eventually, I realized that I needed to actually persist the utilization of each table/NS, not just the violation state.I know there are cases in the code where "violation" is incorrectly describing things (it should be "snapshot"). Clean these up for clarity.</description>
      <version>None</version>
      <fixedVersion>HBASE-16961,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.TableQuotaSnapshotStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.QuotaObserverChore.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.Quota.proto</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaTableUtil.java</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2017-4-1 01:00:00" id="17866" opendate="2017-4-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement async setQuota/getQuota methods.</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaTableUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.QuotaRetriever.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2017-4-11 01:00:00" id="17905" opendate="2017-4-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbase-spark] bulkload does not work when table not exist</summary>
      <description>when using HBase-Spark bulkload api, an argument of tablename is needed, the bulkload can run successfully only if table exist in HBase. If table not exist, the bulkload can not run successfully and it even do not report any errors or throw exception.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.HBaseContext.scala</file>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.BulkLoadPartitioner.scala</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2017-4-25 01:00:00" id="17956" opendate="2017-4-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Raw scan should ignore TTL</summary>
      <description>For now we will also test TTL to check if a cell is expired for raw scan. Since we can even return delete marker for a raw scan, I think it is also reasonable to eliminate the TTL check.</description>
      <version>1.4.0,2.0.0</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannersFromClientSide.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2017-5-15 01:00:00" id="18049" opendate="2017-5-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>It is not necessary to re-open the region when MOB files cannot be found</summary>
      <description>In HBASE-17712, we try to re-open the region when store files cannot be found. This is useful for store files in a region, but is not necessary when the MOB files cannot be found, because the store files in a region only contain the references to the MOB files and a re-open of a region doesn't help the lost MOB files.In this JIRA, we will directly throw DNRIOE only when the MOB files are not found in MobStoreScanner and ReversedMobStoreScanner. Other logics keep the same.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HMobStore.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2017-5-19 01:00:00" id="18081" opendate="2017-5-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>The way we process connection preamble in SimpleRpcServer is broken</summary>
      <description>Though very rare, but if the preamble is not sent at once, the logic will be broken.</description>
      <version>1.4.0,1.3.1,1.2.5,1.1.10,2.0.0</version>
      <fixedVersion>1.4.0,1.2.6,1.3.2,1.1.11,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleServerRpcConnection.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  
  <bug fixdate="2017-6-7 01:00:00" id="18181" opendate="2017-6-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move master branch to version 3.0.0-SNAPSHOT post creation of branch-2</summary>
      <description>busbey caught me pushing stuff last night w/o an associated issue (update to doc around our 'official' color and font) so he probably has his eye out these times....I just branched hbase2.i need to move master version on from 2.0.0-SNAPSHOT. Thats what this issue is for.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-thrift.pom.xml</file>
      <file type="M">hbase-testing-util.pom.xml</file>
      <file type="M">hbase-spark.pom.xml</file>
      <file type="M">hbase-shell.pom.xml</file>
      <file type="M">hbase-shaded.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-server.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-client.pom.xml</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-rsgroup.pom.xml</file>
      <file type="M">hbase-rest.pom.xml</file>
      <file type="M">hbase-resource-bundle.pom.xml</file>
      <file type="M">hbase-protocol.pom.xml</file>
      <file type="M">hbase-protocol-shaded.pom.xml</file>
      <file type="M">hbase-procedure.pom.xml</file>
      <file type="M">hbase-prefix-tree.pom.xml</file>
      <file type="M">hbase-metrics.pom.xml</file>
      <file type="M">hbase-metrics-api.pom.xml</file>
      <file type="M">hbase-it.pom.xml</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-hadoop-compat.pom.xml</file>
      <file type="M">hbase-external-blockcache.pom.xml</file>
      <file type="M">hbase-examples.pom.xml</file>
      <file type="M">hbase-endpoint.pom.xml</file>
      <file type="M">hbase-common.pom.xml</file>
      <file type="M">hbase-client.pom.xml</file>
      <file type="M">hbase-checkstyle.pom.xml</file>
      <file type="M">hbase-assembly.pom.xml</file>
      <file type="M">hbase-archetypes.pom.xml</file>
      <file type="M">hbase-archetypes.hbase-shaded-client-project.pom.xml</file>
      <file type="M">hbase-archetypes.hbase-client-project.pom.xml</file>
      <file type="M">hbase-archetypes.hbase-archetype-builder.pom.xml</file>
      <file type="M">hbase-annotations.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-9-9 01:00:00" id="1820" opendate="2009-9-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update jruby from 1.2 to 1.3.1</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">lib.jruby-complete-1.2.0.jar</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2017-7-11 01:00:00" id="18364" opendate="2017-7-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Downgrade surefire</summary>
      <description>Seems like 2.20 broke package-wildcard for test specification. Pull this back to something that works.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2017-8-14 01:00:00" id="18592" opendate="2017-8-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbase-thirdparty] Doc on new hbase-thirdparty dependency for the refguide</summary>
      <description>Add a bit to the refguide on the new hbase-thirdparty lib and why it exists.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2017-8-15 01:00:00" id="18599" opendate="2017-8-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add missing @Deprecated annotations</summary>
      <description>There are a couple of places where deprecations have only been added in the Javadoc but the annotation is missing.I'll also change the Javadoc to be consistent with what I've done in HBASE-13462.This is for master/2.0.0 only.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionObserver.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.metrics.ServerSideScanMetrics.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Admin.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2017-3-18 01:00:00" id="18626" opendate="2017-8-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Handle the incompatible change about the replication TableCFs&amp;#39; config</summary>
      <description>About compatibility, there is one incompatible change about the replication TableCFs' config. The old config is a string and it concatenate the list of tables and column families in format "table1:cf1,cf2;table2:cfA,cfB" in zookeeper for table-cf to replication peer mapping. When parse the config, it use ":" to split the string. If table name includes namespace, it will be wrong (See HBASE-11386). It is a problem since we support namespace (0.98). So HBASE-11393 (and HBASE-16653) changed it to a PB object. When rolling update cluster, you need rolling master first. And the master will try to translate the string config to a PB object. But there are two problems.1. Permission problem. The replication client can write the zookeeper directly. So the znode may have different owner. And master may don't have the write permission for the znode. It maybe failed to translate old table-cfs string to new PB Object. See HBASE-169382. We usually keep compatibility between old client and new server. But the old replication client may write a string config to znode directly. Then the new server can't parse them.</description>
      <version>3.0.0-alpha-1,1.4.0,1.5.0,2.0.0-alpha-3</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2017-8-18 01:00:00" id="18630" opendate="2017-8-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Prune dependencies; as is branch-2 has duplicates</summary>
      <description>Purge duplicate includes and try to prune back our dependencies (Suggestion by elserj up on the 2.0.0-alpha2 vote). Just looking at my current issue, we have vestiges we include even though the root justification has passed.</description>
      <version>None</version>
      <fixedVersion>2.0.0-alpha-3,2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2017-8-19 01:00:00" id="18635" opendate="2017-8-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix asciidoc warnings</summary>
      <description>When building docs, I noticed:Failed to parse formatted text: To supply filters to the Scanner object or configure the Scanner in any other way, you can create a text file and add your filter to the file. For example, to return only rows for which keys start with &amp;lt;codeph&amp;gt;u123&amp;lt;/codeph&amp;gt; and use a batch size of 100, the filter file would look like this: &lt;pre&gt; &amp;lt;Scanner batch="100"&amp;gt; &amp;lt;filter&amp;gt; { "type": "PrefixFilter", "value": "u123" } &amp;lt;/filter&amp;gt; &amp;lt;/Scanner&amp;gt; &lt;/pre&gt;Working hypthesis is that we should either be using proper codeblocks rather than pre tags. Otherwise we may need to do something to escape curly braces. Asciidoctor is probably trying to interpret them as Liquid tags.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.schema.design.adoc</file>
      <file type="M">src.main.asciidoc..chapters.external.apis.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2017-10-23 01:00:00" id="18667" opendate="2017-8-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Disable error-prone for hbase-protocol-shaded</summary>
      <description>This is all generated code that we shouldn't be running extra analysis on because it adds a lot of noise to the build, and also takes a very long time (15 minutes on my machine). Let's make it fast and simple.Even when we run with error-prone enabled for the rest of the build, it should not apply here.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-protocol.pom.xml</file>
      <file type="M">hbase-protocol-shaded.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2017-9-30 01:00:00" id="18718" opendate="2017-8-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document the coprocessor.Export</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2017-9-1 01:00:00" id="18740" opendate="2017-9-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade Zookeeper version to 3.4.10</summary>
      <description>Branch 1.4 and branch 1 are still on Zookeeper 3.4.6.Branch 2 and master branch have upgraded to 3.4.9.There are some important fixes we'd like to have. See the linked JIRAs.Another critical fix is ZOOKEEPER-2146, which can be explored maliciously.</description>
      <version>1.4.0,1.5.0</version>
      <fixedVersion>1.4.0,2.0.0-alpha-3,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2017-11-26 01:00:00" id="19097" opendate="2017-10-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>update testing to use Apache Yetus Test Patch version 0.6.0</summary>
      <description>once Yetus does their 0.6.0 release, we should update our nightly and precommit tests to use it. They've added diagnostic info about maven version in use that would help troubleshoot some of our failures.Also the 0.5.0 release removed the maven eclipse plugin tests, since that plugin is EOL.</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0-beta-1,1.1.13,2.0.0,1.2.7</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2017-10-26 01:00:00" id="19098" opendate="2017-10-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Python based compatiblity checker fails if git repo does not have a remote named &amp;#39;origin&amp;#39;</summary>
      <description>The new Python based compatibility checker will fail if the local git repo does not have a remote named "origin". I develop with multiple upstream repos and rename them according to a custom convention. If the requirement that an upstream named "origin" must be present could be removed, that would be good, or otherwise this should be documented next to the example usage in the python source.</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0-alpha-4,2.0.0,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.checkcompatibility.py</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2017-11-9 01:00:00" id="19227" opendate="2017-11-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Nightly jobs should archive JVM dumpstream files</summary>
      <description>came up on dev@ discussion about some of our current nightly test failures. when surefire fails to launch a test JVM instance, the details go into a file that we currently don't archive:&amp;#91;ERROR&amp;#93; Please refer to dump files (if any exist) &amp;#91;date&amp;#93;-jvmRun&amp;#91;N&amp;#93;.dump, &amp;#91;date&amp;#93;.dumpstream and &amp;#91;date&amp;#93;-jvmRun&amp;#91;N&amp;#93;.dumpstream.Add them to the default archive pattern.</description>
      <version>None</version>
      <fixedVersion>1.0.4,1.1.13,2.0.0,1.2.7</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2017-11-9 01:00:00" id="19228" opendate="2017-11-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>nightly job should gather machine stats.</summary>
      <description>leverage the script added in HBASE-19189 to get machine stats when running nightly</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0-beta-1,1.1.13,2.0.0,1.2.7</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
      <file type="M">dev-support.gather.machine.environment.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2017-11-9 01:00:00" id="19229" opendate="2017-11-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Nightly script to check source artifact should not do a destructive git operation without opt-in</summary>
      <description>right now we have a "git please destroy all this stuff" command in the check of the source artifact. we shouldn't do this unless the person invoking the script has indicated that's okay (e..g through a cli flag).</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0-beta-1,1.1.13,2.0.0,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
      <file type="M">dev-support.hbase.nightly.source-artifact.sh</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2017-12-4 01:00:00" id="19422" opendate="2017-12-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>using hadoop-profile property leads to confusing failures</summary>
      <description>When building master branch against hadoop 3 beta1,mvn clean install -Dhadoop-profile=3.0 -Dhadoop-three.version=3.0.0-beta1 -Dhadoop-two.version=3.0.0-beta1 -DskipTestsI got:[WARNING] Rule 0: org.apache.maven.plugins.enforcer.BannedDependencies failed with message:We don't allow the JSR305 jar from the Findbugs project, see HBASE-16321.Found Banned Dependency: com.google.code.findbugs:jsr305:jar:1.3.9Here is part of the dependency tree showing the dependency:[INFO] org.apache.hbase:hbase-client:jar:3.0.0-SNAPSHOT...[INFO] +- org.apache.hadoop:hadoop-auth:jar:3.0.0-beta1:compile...[INFO] | \- com.google.guava:guava:jar:11.0.2:compile[INFO] | \- com.google.code.findbugs:jsr305:jar:1.3.9:compileWe need to exclude jsr305 so that build succeed.</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0-beta-1,2.0.0,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-10-29 01:00:00" id="1943" opendate="2009-10-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove AgileJSON; unused.</summary>
      <description>Remove unused jar and its TOJSON annotations. We can use jackson instead; thats what apurtell has in stargate its what avro is using.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">lib.AgileJSON-2009-03-30.jar</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2017-12-12 01:00:00" id="19491" opendate="2017-12-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Exclude flaky tests from nightly master run</summary>
      <description>Testing infra improvements Exclude flaky tests from nightly master run (Old nightly master run used to exclude flaky tests, but new nightly one which is based on Jenkins stages wasn't using it. Adding it to new nightly job) Fixes findbugs check (seems like wasn't working earlier : "0 findbugs 0m 0s Findbugs executables are not available.")</description>
      <version>None</version>
      <fixedVersion>1.3.2,1.4.1,2.0.0-beta-1,2.0.0,1.2.7</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
      <file type="M">dev-support.hbase.nightly.yetus.sh</file>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2017-12-22 01:00:00" id="19591" opendate="2017-12-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cleanup the usage of ReplicationAdmin from hbase-shell</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.replication.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2017-12-22 01:00:00" id="19592" opendate="2017-12-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add UTs to test retry on update zk failure</summary>
      <description/>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.ReplicationPeerManager.java</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2018-1-10 01:00:00" id="19755" opendate="2018-1-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Error message for non-existent namespace is inaccurate</summary>
      <description>On a secure cluster, when I issued this command where ns1 didn't exist:hbase(main):002:0&gt; create 'ns1:t1', 'f1', SPLITS =&gt; ['10', '20', '30', '40']ERROR: Unknown namespace ns1:t1!Creates a table. Pass a table name, and a set of column familyspecifications (at least one), and, optionally, table configurationHere is related code: raise "Unknown namespace #{args.first}!"Simply quoting the argument is not accurate - namespace should be extracted from the argument</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.rb</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-2-19 01:00:00" id="20019" opendate="2018-2-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document the ColumnValueFilter</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2018-2-20 01:00:00" id="20027" opendate="2018-2-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add test TestClusterPortAssignment</summary>
      <description>Port assignments for master ports in site configuration appear to be ignored.We are not catching this in tests because there appears to be no positive test for port assignment and the only fixed information we require is the zookeeper quorum and client port. </description>
      <version>1.4.0,1.4.1</version>
      <fixedVersion>1.4.2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MiniHBaseCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.LocalHBaseCluster.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-11-23 01:00:00" id="2003" opendate="2009-11-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[shell] deleteall ignores column if specified</summary>
      <description>In the shell, a delete must match the value's coordinates exactly. By default the delete command uses the latest timestamp but you can provide on explicitly. So you have to delete each version independent of the others if there are multiple versions of a value. The command 'deleteall' is supposed to clear out a whole row or a whole column of values: deleteall Delete all cells in a given row; pass a table name, row, and optionally a column and timestampbut the code won't work as advertised: def deleteall(row, column = nil, timestamp = HConstants::LATEST_TIMESTAMP) now = Time.now d = Delete.new(row.to_java_bytes, timestamp, nil) @table.delete(d) @formatter.header() @formatter.footer(now) end'column' is ignored.</description>
      <version>None</version>
      <fixedVersion>0.20.3,0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.HBase.rb</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2018-4-24 01:00:00" id="20068" opendate="2018-2-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hadoopcheck project health check uses default maven repo instead of yetus managed ones</summary>
      <description>Recently had a precommit run fail hadoop check for all 3 versions with [ERROR] Failed to execute goal org.apache.maven.plugins:maven-install-plugin:2.5.2:install (default-install) on project hbase-thrift: Failed to install metadata org.apache.hbase:hbase-thrift:3.0.0-SNAPSHOT/maven-metadata.xml: Could not parse metadata /home/jenkins/.m2/repository/org/apache/hbase/hbase-thrift/3.0.0-SNAPSHOT/maven-metadata-local.xml: in epilog non whitespace content is not allowed but got / (position: END_TAG seen ...&lt;/metadata&gt;\n/... @25:2) -&gt; [Help 1]Looks like maven repo corruption.Also the path /home/jenkins/.m2/repository means that those invocations are using the jenkins user repo, which isn't safe since there are multiple executors. either the plugin isn't using the yetus provided maven repo path or our yetus invocation isn't telling yetus to provide its own maven repo path.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0,1.3.3,1.4.4,2.0.1,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2018-3-24 01:00:00" id="20070" opendate="2018-2-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>website generation is failing</summary>
      <description>website generation has been failing since Feb 20thChecking out files: 100% (68971/68971), done.Usage: grep [OPTION]... PATTERN [FILE]...Try 'grep --help' for more information.PUSHED is 2 is not yet mentioned in the hbase-site commit log. Assuming we don't have it yet. 2Building HBaseJava HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=256m; support was removed in 8.0Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=256m; support was removed in 8.0Failure: mvn clean siteBuild step 'Execute shell' marked build as failureThe status email saysBuild status: Still FailingThe HBase website has not been updated to incorporate HBase commit ${CURRENT_HBASE_COMMIT}.Looking at the code where that grep happens, it looks like the env variable CURRENT_HBASE_COMMIT isn't getting set. That comes from some git command. I'm guessing the version of git changed on the build hosts and upended our assumptions.we should fix this to 1) rely on git's porcelain interface, and 2) fail as soon as that git command fails</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-zookeeper.pom.xml</file>
      <file type="M">hbase-thrift.pom.xml</file>
      <file type="M">hbase-testing-util.pom.xml</file>
      <file type="M">hbase-spark-it.pom.xml</file>
      <file type="M">hbase-shell.pom.xml</file>
      <file type="M">hbase-shaded.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-check-invariants.pom.xml</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-rsgroup.pom.xml</file>
      <file type="M">hbase-rest.pom.xml</file>
      <file type="M">hbase-resource-bundle.pom.xml</file>
      <file type="M">hbase-replication.pom.xml</file>
      <file type="M">hbase-protocol.pom.xml</file>
      <file type="M">hbase-protocol-shaded.pom.xml</file>
      <file type="M">hbase-procedure.pom.xml</file>
      <file type="M">hbase-metrics.pom.xml</file>
      <file type="M">hbase-metrics-api.pom.xml</file>
      <file type="M">hbase-mapreduce.pom.xml</file>
      <file type="M">hbase-it.pom.xml</file>
      <file type="M">hbase-http.pom.xml</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-hadoop-compat.pom.xml</file>
      <file type="M">hbase-external-blockcache.pom.xml</file>
      <file type="M">hbase-examples.pom.xml</file>
      <file type="M">hbase-endpoint.pom.xml</file>
      <file type="M">hbase-common.pom.xml</file>
      <file type="M">hbase-client.pom.xml</file>
      <file type="M">hbase-build-configuration.pom.xml</file>
      <file type="M">hbase-backup.pom.xml</file>
      <file type="M">hbase-assembly.pom.xml</file>
      <file type="M">hbase-annotations.pom.xml</file>
      <file type="M">dev-support.jenkins-scripts.generate-hbase-website.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-8-12 01:00:00" id="20175" opendate="2018-3-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase-spark needs scala dependency convergance</summary>
      <description>This is a follow-on to HBASE-16179 - I think we might need to specify an exclude in the dependency management.[INFO] --- scala-maven-plugin:3.2.0:compile (scala-compile-first) @ hbase-spark ---[WARNING] Expected all dependencies to require Scala version: 2.11.8[WARNING] org.apache.hbase:hbase-spark:3.0.0-SNAPSHOT requires scala version: 2.11.8[WARNING] org.apache.spark:spark-streaming_2.11:2.1.1 requires scala version: 2.11.8[WARNING] org.apache.spark:spark-streaming_2.11:2.1.1 requires scala version: 2.11.8[WARNING] org.scalatest:scalatest_2.11:2.2.4 requires scala version: 2.11.2tedyu - since you're already fiddling in this area, do you want to take a look?</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,connector-1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-3-12 01:00:00" id="20177" opendate="2018-3-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix warning: Class org.apache.hadoop.minikdc.MiniKdc not found in hbase-spark</summary>
      <description>getting warning for[WARNING] warning: Class org.apache.hadoop.minikdc.MiniKdc not found - continuing with a stub. </description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,connector-1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2018-4-27 01:00:00" id="20296" opendate="2018-3-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove last pushed sequence ids when removing tables from a peer</summary>
      <description>Discussed with zghaobac and openinx offline, this is the only safe thing to do for now. It is not safe to remove barriers and last pushed sequence ids when deleting a table since we may still have edits which should be replicated.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestEnableTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.UpdatePeerConfigProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.ModifyPeerProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.replication.AddPeerProcedure.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ZKReplicationQueueStorage.java</file>
      <file type="M">hbase-replication.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueueStorage.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.MetaTableAccessor.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2018-5-14 01:00:00" id="20581" opendate="2018-5-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase book documentation wrong for REST operations on schema endpoints</summary>
      <description>On https://hbase.apache.org/book.html#_using_rest_endpointsThe documentation states that to update a table schema (the configuration for a column family), the PUT HTTP verb will update the current configuration with the "fragment" of configuration provided, while the POST HTTP verb will replace the current configuration with whatever is provided.In reality, the opposite is true: POST updates the configuration, PUT replaces. The old javadoc for the o.a.h.h.rest package got it right, but the entry on the HBase book transposed this.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.external.apis.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-5-14 01:00:00" id="20582" opendate="2018-5-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bump up JRuby version because of some reported vulnerabilities</summary>
      <description>There are some vulnerabilities reported with two of the libraries used in HBase.Jruby(version:9.1.10.0):CVE-2009-5147CVE-2013-4363CVE-2014-4975CVE-2014-8080CVE-2014-8090CVE-2015-3900CVE-2015-7551CVE-2015-9096CVE-2017-0899CVE-2017-0900CVE-2017-0901CVE-2017-0902CVE-2017-0903CVE-2017-10784CVE-2017-14064CVE-2017-9224CVE-2017-9225CVE-2017-9226CVE-2017-9227CVE-2017-9228Tool somehow able to relate the vulnerability of Ruby with JRuby(Java implementation). (Jackson will be handled in a different issue.)Not all of them directly affects HBase but elserj suggested that it is better to be on the updated version to avoid issues during an audit in security sensitive organization. </description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2018-6-30 01:00:00" id="21405" opendate="2018-10-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[DOC] Add Details about Output of "status &amp;#39;replication&amp;#39;"</summary>
      <description>Add more information about the meaning of each metric on to http://hbase.apache.org/book.html#_monitoring_replication_status.SOURCE: PeerID AgeOfLastShippedOp SizeOfLogQueue TimeStampsOfLastShippedOp Replication LagSINK AgeOfLastAppliedOp TimeStampsOfLastAppliedOp</description>
      <version>3.0.0-alpha-1,1.4.0,2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2010-2-1 01:00:00" id="2177" opendate="2010-2-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add timestamping to gc logging options</summary>
      <description>http://forums.sun.com/thread.jspa?threadID=5165451</description>
      <version>None</version>
      <fixedVersion>0.20.4,0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.hbase-env.sh</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-6-17 01:00:00" id="22264" opendate="2019-4-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Separate out jars related to JDK 11 into a folder in /lib</summary>
      <description>UPDATE:Separate out the the jars related to JDK 11 and add control their addition to the classpath using an environment variable or auto-detection of the jdk version installed.OLD:This is in continuation with HBASE-22249. When compiled with jdk 8 and run on jdk 11, the master branch throws the following exception during an attempt to start the hbase rest server:Exception in thread "main" java.lang.NoClassDefFoundError: javax/annotation/Priority at org.glassfish.jersey.model.internal.ComponentBag.modelFor(ComponentBag.java:483) at org.glassfish.jersey.model.internal.ComponentBag.access$100(ComponentBag.java:89) at org.glassfish.jersey.model.internal.ComponentBag$5.call(ComponentBag.java:408) at org.glassfish.jersey.model.internal.ComponentBag$5.call(ComponentBag.java:398) at org.glassfish.jersey.internal.Errors.process(Errors.java:315) at org.glassfish.jersey.internal.Errors.process(Errors.java:297) at org.glassfish.jersey.internal.Errors.process(Errors.java:228) at org.glassfish.jersey.model.internal.ComponentBag.registerModel(ComponentBag.java:398) at org.glassfish.jersey.model.internal.ComponentBag.register(ComponentBag.java:235) at org.glassfish.jersey.model.internal.CommonConfig.register(CommonConfig.java:420) at org.glassfish.jersey.server.ResourceConfig.register(ResourceConfig.java:425) at org.apache.hadoop.hbase.rest.RESTServer.run(RESTServer.java:245) at org.apache.hadoop.hbase.rest.RESTServer.main(RESTServer.java:421)</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-resource-bundle.src.main.resources.supplemental-models.xml</file>
      <file type="M">hbase-resource-bundle.src.main.resources.META-INF.LICENSE.vm</file>
      <file type="M">hbase-assembly.src.main.assembly.hadoop-two-compat.xml</file>
      <file type="M">hbase-assembly.pom.xml</file>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-5-8 01:00:00" id="22379" opendate="2019-5-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix Markdown for "Voting on Release Candidates" in book</summary>
      <description>The Markdown in the section "Voting on Release Candidates" of the HBase book seems to be broken. It looks like that there should be a quote, which isn't displayed correctly. Same is true for the formatting of the Maven RAT command.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,1.4.10,2.3.0,2.0.6,2.1.5,1.3.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2019-9-29 01:00:00" id="22945" opendate="2019-8-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Show quota infos in master UI</summary>
      <description>Add a page in master UI to show the following quota infos:if rpc throttle is enabled;if exceed throttle quota is enabled;namespace throtlles;user throttles.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.header.jsp</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.MasterQuotaManager.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.ThrottleSettings.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-9-29 01:00:00" id="22946" opendate="2019-8-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix TableNotFound when grant/revoke if AccessController is not loaded</summary>
      <description>When doing grant, revoke..., a TableNotFoundException will occur if AccessController if is not configured.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-10-14 01:00:00" id="23172" opendate="2019-10-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase Canary region success count metrics reflect column family successes, not region successes</summary>
      <description>HBase Canary reads once per column family per region. The current "region success count" should actually be "column family success count," which means we need another metric that actually reflects region success count. Additionally, the region read and write latencies only store the latencies of the last column family of the region read. Instead of a map of regions to a single latency value and success value, we should map each region to a list of such values.</description>
      <version>3.0.0-alpha-1,1.3.0,1.4.0,1.5.0,2.0.0,2.1.5,2.2.1</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,1.6.0,2.1.8,2.2.3</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.tool.TestCanaryTool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.CanaryTool.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2010-3-15 01:00:00" id="2327" opendate="2010-3-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[EC2] Allocate elastic IP addresses for ZK and master nodes</summary>
      <description>Amazon EC2 supports Elastic IP Addresses to implement the effect of having a static IP address for public servers running on EC2. Up on hbase-users@ there was some recent discussion, confirmed, that when an EC2 instance queries the external DNS name of an elastic IP address, EC2 DNS returns the internal IP address of the instance to which the elastic IP address is bound, so it is safe to use elastic IPs for the ZK and master nodes. We gain the ability to do transparent replacement of one instance, e.g. failed, with another without incurring any additional cost. Update launch-hbase-zookeeper and launch-hbase-master to allocate elastic IPs: $ ec2-allocate-address ADDRESS 1.1.1.1and then assign the elastic IP address to the appropriate instance(s):$ ec2-associate-address -i i-11111111 1.1.1.1ADDRESS 1.1.1.1 i-11111111and then get the external DNS name to use when performing substitutions on master and slave configs:$ ec2-describe-instances i-11111111 | egrep ^INSTANCE | cut -f4ec2-1-1-1-1.compute-1.amazonaws.comWhen shutting down the cluster, just release the elastic IPs after terminating the instances:ec2-release-address 1.1.1.1...NOTE: AWS accounts default to a limit of 5 Elastic IP addresses but most will run with 1 master and 3 or 1 ZK instances. And, the ZK ensemble can be shared. A follow up issue can address making scripts to launch replacements for failed instances transparently.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">contrib.ec2.bin.terminate-hbase-cluster</file>
      <file type="M">contrib.ec2.bin.launch-hbase-zookeeper</file>
      <file type="M">contrib.ec2.bin.launch-hbase-slaves</file>
      <file type="M">contrib.ec2.bin.launch-hbase-master</file>
      <file type="M">contrib.ec2.bin.image.create-hbase-image-remote</file>
      <file type="M">contrib.ec2.bin.hbase-ec2-env.sh</file>
      <file type="M">contrib.ec2.bin.create-hbase-image</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2020-4-11 01:00:00" id="23829" opendate="2020-2-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Get `-PrunSmallTests` passing on JDK11</summary>
      <description>Start with the small tests, shaking out issues identified by the harness. So far it seems like -Dhadoop.profile=3.0 and -Dhadoop-three.version=3.3.0-SNAPSHOT maybe be required.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-with-hadoop-check-invariants.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-check-invariants.pom.xml</file>
      <file type="M">hbase-http.src.test.java.org.apache.hadoop.hbase.http.log.TestLogLevel.java</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestFutureUtils.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2008-11-21 01:00:00" id="947" opendate="2008-10-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[Optimization] Major compaction should remove deletes as well as the deleted cell</summary>
      <description>Currently major compactions retains both deletes and the deleted cell. It should remove both.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>