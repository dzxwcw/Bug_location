<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="HBASE">
  <bug fixdate="2009-6-26 01:00:00" id="1587" opendate="2009-6-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update ganglia config and doc to account for ganglia 3.1 and hadoop-4675</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.hadoop-metrics.properties</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2018-3-8 01:00:00" id="20153" opendate="2018-3-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>enable error-prone analysis in precommit</summary>
      <description>We've done a lot of work to get rid of the error-prone errors, we should make sure they stay out. Let's enable errorProne profile and analysis in precommit.busbey - I tried figuring out how to pass flags (-PerrorProne to the mvn compile precommit check but was unable to unravel that thread. Any help is appreciated.</description>
      <version>None</version>
      <fixedVersion>1.4.3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2018-3-9 01:00:00" id="20164" opendate="2018-3-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>failed hadoopcheck should add footer link</summary>
      <description>thought for sure this already had an issue, busbey, but I can't find it.</description>
      <version>None</version>
      <fixedVersion>1.3.2,1.4.3,2.0.0,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-3-9 01:00:00" id="20165" opendate="2018-3-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Shell command to make a normal peer to be a serial replication peer</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.test.ruby.hbase.replication.admin.test.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.list.peers.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.rb</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.replication.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-11-30 01:00:00" id="2017" opendate="2009-11-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Set configurable max value size check to 10MB</summary>
      <description>Make the user think about whether storing larger values than 10MB is a good idea.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-3-13 01:00:00" id="20189" opendate="2018-3-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Typo in Required Java Version error message while building HBase.</summary>
      <description>Change 'requirs' to 'requires'. See below:$ mvn clean install -DskipTests...[WARNING] Rule 2: org.apache.maven.plugins.enforcer.RequireJavaVersion failed with message:Java is out of date.  HBase requirs at least version 1.8 of the JDK to properly build from source.  You appear to be using an older version. You can use either "mvn -version" or  "mvn enforcer:display-info" to verify what version is active.  See the reference guide on building for more information: http://hbase.apache.org/book.html#build</description>
      <version>None</version>
      <fixedVersion>1.3.2,1.4.3,2.0.0,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-12-1 01:00:00" id="2019" opendate="2009-12-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[EC2] Prompt for and remember credentials if not configured</summary>
      <description/>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.contrib.ec2.bin.image.create-hbase-image-remote</file>
      <file type="M">src.contrib.ec2.bin.hbase-ec2-env.sh</file>
      <file type="M">src.contrib.ec2.bin.create-hbase-image</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-3-14 01:00:00" id="20190" opendate="2018-3-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix default for MIGRATE_TABLE_STATE_FROM_ZK_KEY</summary>
      <description>All works but the flag name will confuse: name is MIGRATE_TABLE_STATE_FROM_ZK_KEY but you'd set it to true to NOT migrate from zk. Found by tedyu in the parent issue.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableStateManager.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2018-4-13 01:00:00" id="20410" opendate="2018-4-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>upgrade protoc compiler to 3.5.1-1</summary>
      <description>See HBASE-20356After doing the cleanup there, I was informed that there's a 3.5.1-1 version of the compiler binaries that work on rhel6, so let's just go to that. Wish I knew about it beforehand.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
      <file type="M">hbase-protocol-shaded.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-4-17 01:00:00" id="20438" opendate="2018-4-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add an HBase antipattern check for reintroducing commons-logging</summary>
      <description>We moved to slf4j in HBASE-10092, but looking at our source tree we've had some regression back to commons-logging:$ git grep -E "org.apache.commons.logging.Log(Factory|;)"hbase-server/src/main/java/org/apache/hadoop/hbase/master/zksyncer/ClientZKSyncer.java:import org.apache.commons.logging.Log;hbase-server/src/main/java/org/apache/hadoop/hbase/master/zksyncer/ClientZKSyncer.java:import org.apache.commons.logging.LogFactory;hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/FileArchiverNotifierImpl.java:import org.apache.commons.logging.Log;hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/FileArchiverNotifierImpl.java:import org.apache.commons.logging.LogFactory;hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/RegionSizeReportingChore.java:import org.apache.commons.logging.Log;hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/RegionSizeReportingChore.java:import org.apache.commons.logging.LogFactory;hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/RegionSizeStoreImpl.java:import org.apache.commons.logging.Log;hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/RegionSizeStoreImpl.java:import org.apache.commons.logging.LogFactory;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/throttle/StoreHotnessProtector.java:import org.apache.commons.logging.Log;hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/throttle/StoreHotnessProtector.java:import org.apache.commons.logging.LogFactory;hbase-server/src/test/java/org/apache/hadoop/hbase/TestClusterPortAssignment.java:import org.apache.commons.logging.Log;hbase-server/src/test/java/org/apache/hadoop/hbase/TestClusterPortAssignment.java:import org.apache.commons.logging.LogFactory;hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFlushFromClient.java:import org.apache.commons.logging.Log;hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFlushFromClient.java:import org.apache.commons.logging.LogFactory;hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSeparateClientZKCluster.java:import org.apache.commons.logging.Log;hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSeparateClientZKCluster.java:import org.apache.commons.logging.LogFactory;hbase-server/src/test/java/org/apache/hadoop/hbase/procedure/TestFailedProcCleanup.java:import org.apache.commons.logging.Log;hbase-server/src/test/java/org/apache/hadoop/hbase/procedure/TestFailedProcCleanup.java:import org.apache.commons.logging.LogFactory;hbase-server/src/test/java/org/apache/hadoop/hbase/wal/TestDisabledWAL.java:import org.apache.commons.logging.Log;hbase-server/src/test/java/org/apache/hadoop/hbase/wal/TestDisabledWAL.java:import org.apache.commons.logging.LogFactory;We should do the same kind of check that we do to avoid e.g. the Hadoop annotations</description>
      <version>3.0.0-alpha-1,2.1.0,2.0.0</version>
      <fixedVersion>3.0.0-alpha-1,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2018-6-12 01:00:00" id="20720" opendate="2018-6-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make 2.0.1 release</summary>
      <description>Let me push out a release off branch-2.0, a 2.0.1. It has a bunch of fixes and some perf improvements. A nightly run just passed clean: https://builds.apache.org/view/H-L/view/HBase/job/HBase%20Nightly/job/branch-2.0/421/</description>
      <version>None</version>
      <fixedVersion>2.0.1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.downloads.xml</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  <bug fixdate="2018-7-30 01:00:00" id="20977" opendate="2018-7-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Don&amp;#39;t use the word "Snapshot" when defining "HBase Snapshots"</summary>
      <description>From http://hbase.apache.org/book.html#ops.snapshotsHBase Snapshots allow you to take a snapshot of a table without too much impact on Region ServersWe should change this to not use the word "snapshot" when defining what HBase Snapshots are. It's confusing enough to English-as-a-first-language individuals; I imagine it's even more cyclical to ESL individuals.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-8-31 01:00:00" id="20985" opendate="2018-7-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>add two attributes when we do normalization</summary>
      <description>Currently when we turn on normalization switch, it will help balance the whole table based on total region size / total region count. I add two attributes so that we can set total region count or average region size we want to achieve when normalization done.</description>
      <version>2.1.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.test.ruby.hbase.admin.test.rb</file>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.alter.rb</file>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.normalizer.TestSimpleRegionNormalizer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.normalizer.SimpleRegionNormalizer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.TableDescriptorBuilder.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.TableDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-8-31 01:00:00" id="20986" opendate="2018-7-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Separate the config of block size when we do log splitting and write Hlog</summary>
      <description>Since the block size of recovered edits and hlog are the same right now, if we set a large value to block size, name node may not able to assign enough space when we do log splitting. But set a large value to hlog block size can help reduce the number of region server asking for a new block. Thus I think separate the config of block size is necessary.</description>
      <version>3.0.0-alpha-1,2.1.0,2.0.1,2.2.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.FSHLogProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALUtil.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2010-1-9 01:00:00" id="2100" opendate="2010-1-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[EC2] Adjust fs.file-max</summary>
      <description>From Robert Gibbon up on hbase-user@:Maybe you are running Red Hat? Just changing limits.conf I think won'twork because RH has a maximum total open files across the whole system,which is 4096 by default, unless you do something like this tooecho "32768" &gt; /proc/sys/fs/file-maxservice network restartTo make it permanent edit /etc/sysctl.conf to include the line: fs.file-max = 32768Update the remote init script appropriately.</description>
      <version>None</version>
      <fixedVersion>0.20.3,0.90.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.contrib.ec2.bin.hbase-ec2-init-remote.sh</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2010-1-9 01:00:00" id="2103" opendate="2010-1-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[EC2] pull version from build</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.20.3,0.90.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.contrib.ec2.bin.image.create-hbase-image-remote</file>
      <file type="M">src.contrib.ec2.bin.hbase-ec2-env.sh</file>
      <file type="M">src.contrib.build-contrib.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2018-8-21 01:00:00" id="21084" opendate="2018-8-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>When cloning a snapshot including a split parent region, the split parent region of the cloned table will be online</summary>
      <description>Investigating HBASE-21015, I found another issue. It seems like after HBASE-20881, the split parent region of the cloned table will be online when cloning a snapshot including a split parent region.Steps to reproduce are as follows, which is the same as the steps in HBASE-21015:1. Create a tablecreate "test", "cf"2. Put some data into the table(0...2000).each{|i| put "test", "row#{i}", "cf:col", "val"}3. Split the tablesplit "test"4. Take a snapshot of the table before CatalogJanitor cleans up the split parent regionsnapshot "test", "snap"5. Clone the snapshotclone_snapshot "snap", "cloned_table"After following the above steps, the split parent region of the cloned table will be online.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestCloneSnapshotFromClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.CloneSnapshotProcedure.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionReplicaUtil.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-9-5 01:00:00" id="21153" opendate="2018-9-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Shaded client jars should always build in relevant phase to avoid confusion</summary>
      <description>edit:Now that our assembly directly relies on the shaded clients, failing to build the actual client jars (e.g. because -P release is required to fill in their contents) causes confusing errors for downstream folks about classes not being found when they run simple commands like hbase version.We should always fill in the shaded artifacts to make our build easier to understand.original report:: When I run the hbase version command it comes back with:$ ./bin/hbase versionError: Could not find or load main class org.apache.hadoop.hbase.util.GetJavaPropertyError: Could not find or load main class org.apache.hadoop.hbase.util.VersionInfoThe two classes are in hbase-commons.The nice shaded refactoring of our bin/hbase &amp;#8211; i.e. using shaded jars wherever possible &amp;#8211; may have overstretched expecting version to work with shaded client (busbey ?). If so, fix is &lt; one-liner.</description>
      <version>3.0.0-alpha-1,2.1.0,2.2.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shaded.hbase-shaded-mapreduce.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-client.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-client-byo-hadoop.pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2018-9-6 01:00:00" id="21157" opendate="2018-9-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Split TableInputFormatScan to individual tests</summary>
      <description>We have done a split in HBASE-8326, which split the test to two parts. But it is still a bit slow, split it into several tests can increase the parallelism and make the 'mvn test' run faster.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1,2.0.3</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScanBase.java</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan2.java</file>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan1.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2018-10-20 01:00:00" id="21215" opendate="2018-9-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Figure how to invoke hbck2; make it easy to find</summary>
      <description>In https://docs.google.com/document/d/1Oun4G3M5fyrM0OxXcCKYF8td0KD7gJQjnU9Ad-2t-uk/edit#, the doc on hbck2 'form', one item to figure is how to invoke hbck2. Related, how to make it easy to find? busbey has some ideas (posted in doc). This issue is for implementation.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1,2.0.3</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2018-9-26 01:00:00" id="21232" opendate="2018-9-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Show table state in Tables view on Master home page</summary>
      <description>Add a column to the Tables panel on the Master home page. Useful when trying to figure if table is enabled/disable/disabling/enabling...</description>
      <version>2.1.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-9-26 01:00:00" id="21233" opendate="2018-9-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow the procedure implementation to skip persistence of the state after a execution</summary>
      <description>Discussed with stack and allan163 on HBASE-21035, that when retrying we do not need to persist the procedure state every time, as the retry timeout is not a critical stuff. It is OK that we loss this information and start from 0 when after restarting.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1,2.0.3</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.ProcedureExecutor.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.Procedure.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2010-1-14 01:00:00" id="2126" opendate="2010-1-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix build break - ec2</summary>
      <description>Because all contrib/** reuses build-contrib.xml -, internally they reuse ivy-retrieve.xml and hence need the presence of an ivy.xml in ec2 directory to succeed. Temporary patch with no dependencies in . Ideal patch should be to refactor build&amp;#42;.xml as appropriate.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  <bug fixdate="2018-11-26 01:00:00" id="21396" opendate="2018-10-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create 2.1.1 release</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.1.1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.downloads.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2010-1-17 01:00:00" id="2140" opendate="2010-1-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>findbugs issues - 2 performance warnings as suggested by findbugs</summary>
      <description>Integer.valueOf favored instead of new Integer() map.entrySet() favored instead of map.keySet()</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-8-27 01:00:00" id="21400" opendate="2018-10-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>correct spelling error of &amp;#39;initilize&amp;#39; in comment</summary>
      <description>When I learned the code of HBase-RPC,I found a spelling error in the comment.Is the word "initilize" should be "initialize"?</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.1,2.1.6</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.BlockingRpcConnection.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-4-20 01:00:00" id="21502" opendate="2018-11-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update SyncTable section on RefGuide once HBASE-20586 is committed</summary>
      <description>SyncTable refguide section currently mentions limitation to run it on different kerberos realm. HBASE-20586 is ongoing to resolve this problem. This jira is to make sure RefGuide is updated accordingly once HBASE-20586 is resolved.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2010-1-23 01:00:00" id="2164" opendate="2010-1-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Ivy nit - clean up configs</summary>
      <description>Ivy nits Hadoop core - renamed to Hadoop HBase as appropriate. irrelevant configurations - s3-server/ s3-client / jetty removed.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ivy.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2019-3-1 01:00:00" id="21976" opendate="2019-3-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Deal with RetryImmediatelyException for batching request</summary>
      <description/>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.4</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncBatchRpcRetryingCaller.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-3-2 01:00:00" id="21978" opendate="2019-3-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Should close AsyncRegistry if we fail to get cluster id when creating AsyncConnection</summary>
      <description/>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.4</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionFactory.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-3-21 01:00:00" id="22077" opendate="2019-3-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expose sleep time as a command line argument of IntergationTestBackupRestore</summary>
      <description>Extend command line arguments of IntergationTestBackupRestore with a sleep time of chaos monkey options to be able to setup policy of region server restarts more granularly.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestBackupRestore.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2010-6-10 01:00:00" id="2208" opendate="2010-2-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>TableServers # processBatchOfRows - converts from List to [ ] - Expensive copy</summary>
      <description>With autoFlush to false and a large write buffer on HTable, when we write bulk puts - TableServer # processBatchOfRows , convert the input (List) to an [ ] , before sending down the wire. With a write buffer as large as 20 MB , that becomes an expensive copy when we do - list.toArray(new T[ ] ). May be - should we change the wire protocol to support List as well , and then revisit this to prevent the bulk copy ?Batch b = new Batch(this) { @Override int doCall(final List&lt;Row&gt; currentList, final byte [] row, final byte [] tableName) throws IOException, RuntimeException { *final Put [] puts = currentList.toArray(PUT_ARRAY_TYPE);* return getRegionServerWithRetries(new ServerCallable&lt;Integer&gt;(this.c, tableName, row) { public Integer call() throws IOException { return server.put(location.getRegionInfo().getRegionName(), puts); } }); }</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HRegionInterface.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-5-25 01:00:00" id="22312" opendate="2019-4-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hadoop 3 profile for hbase-shaded-mapreduce should like mapreduce as a provided dependency</summary>
      <description>the hadoop 3 profile currently misses declaring a provided dependency on the core mapreduce client module. that means we pick it up as a compile dependency from the hbase-mapreduce module, which means we include things in the shaded jar that we don't need to. (and expressly aren't supposed to include because they're supposed to come from Hadoop at runtime).</description>
      <version>2.1.0,2.2.0,2.1.1,2.1.2,2.1.3,2.1.4</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.5</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shaded.hbase-shaded-mapreduce.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-5-25 01:00:00" id="22314" opendate="2019-4-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>shaded byo-hadoop client should list needed hadoop modules as provided scope to avoid inclusion of unnecessary transitive depednencies</summary>
      <description>attempting to build against current hadoop trunk for HBASE-22087 shows that hte byo-hadoop client is trying to package transitive dependencies from the hadoop dependencies that we expressly say we don't need to bring with us.it's because we don't list those modules as provided, so all of their transitives are also in compile scope. The shading module does simple filtering when excluding things in a given scope, it doesn't e.g. make sure to also exclude the transitive dependencies of things it keeps out.since we don't want to list all the transitive dependencies of hadoop in our shading exclusion, we should list the needed hadoop modules as provided.</description>
      <version>2.1.0,2.2.0,2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.5</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shaded.hbase-shaded-client-byo-hadoop.pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2019-5-27 01:00:00" id="22478" opendate="2019-5-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add jackson dependency for hbase-http module</summary>
      <description>We use Configuration.dumpConfiguration method in ConfServlet, which will reference jackson.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-http.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-6-21 01:00:00" id="22616" opendate="2019-6-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>responseTooXXX logging for Multi should characterize the component ops</summary>
      <description>Multi RPC can be a mix of gets and mutations. The responseTooXXX logging for Multi ops should characterize the operations within the request so we have some clue about whether read or write dispatch was involved.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,2.2.1,2.1.6,1.3.6,1.4.11</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-8-25 01:00:00" id="22625" opendate="2019-6-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>documet use scan snapshot feature</summary>
      <description>Add the design doc in dev-support/design-docs{{ and describe }}the feature in the reference guide.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc.book.adoc</file>
      <file type="M">src.main.asciidoc..chapters.snapshot.scanner.adoc</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-9-6 01:00:00" id="22796" opendate="2019-8-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[HBCK2] Add fix of overlaps to fixMeta hbck Service</summary>
      <description>fixMeta currently does holes in meta only courtesy of HBASE-22771 which added fixMeta to hbck Service; missing was fix of overlaps too. This JIRA is about adding fix of overlaps to general fixMeta call.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.1.7,2.2.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMetaFixer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MetaFixer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.RegionStateNode.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-9-26 01:00:00" id="22927" opendate="2019-8-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade mockito version for Java 11 compatibility</summary>
      <description>Pasting the discussion from HBASE-22534 here:"Currently mockito-core version is at 2.1.0. According to https://github.com/mockito/mockito/blob/release/2.x/doc/release-notes/official.md, looks like Java 11 compatibility was introduced in 2.19+. And 2.23.2 claims to have full java 11 support after byte-buddy fix etc."</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.1.7,2.2.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shaded.hbase-shaded-with-hadoop-check-invariants.pom.xml</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-check-invariants.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-9-29 01:00:00" id="22945" opendate="2019-8-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Show quota infos in master UI</summary>
      <description>Add a page in master UI to show the following quota infos:if rpc throttle is enabled;if exceed throttle quota is enabled;namespace throtlles;user throttles.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.header.jsp</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.MasterQuotaManager.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.ThrottleSettings.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-9-29 01:00:00" id="22946" opendate="2019-8-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix TableNotFound when grant/revoke if AccessController is not loaded</summary>
      <description>When doing grant, revoke..., a TableNotFoundException will occur if AccessController if is not configured.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-8-31 01:00:00" id="22959" opendate="2019-8-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add 2.1.6 to download page</summary>
      <description/>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.downloads.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-9-3 01:00:00" id="22970" opendate="2019-9-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>split parents show as overlaps in the HBCK Report</summary>
      <description>Split parents show in the overlap list and continue to do so until cleared up by CatalogJanitor.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.1,2.1.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegionInfo.java</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.hbck.jsp</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RegionInfo.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-9-18 01:00:00" id="23041" opendate="2019-9-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Should not show split parent regions in HBCK report&amp;#39;s unknown server part</summary>
      <description/>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.1.7,2.2.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HbckChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
    </fixedFiles>
  </bug>
  
  
</bugrepository>