<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="HBASE">
  <bug fixdate="2014-1-3 01:00:00" id="10274" opendate="2014-1-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>MiniZookeeperCluster should close ZKDatabase when shutdown ZooKeeperServers</summary>
      <description>HBASE-6820 points out the problem but not fix completely.killCurrentActiveZooKeeperServer() and killOneBackupZooKeeperServer() will shutdown the ZooKeeperServer and need to close ZKDatabase as well.</description>
      <version>0.94.3</version>
      <fixedVersion>0.98.0,0.96.2,0.99.0,0.94.17</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-11-26 01:00:00" id="1028" opendate="2008-11-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>If key does not exist, return null in getRow rather than an empty RowResult</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.thrift.TestThriftServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.ThriftUtilities.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-1-15 01:00:00" id="10346" opendate="2014-1-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add Documentation for stateless scanner</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.98.0,0.99.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.package.html</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2011-10-26 01:00:00" id="3925" opendate="2011-5-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make Shell&amp;#39;s -d and debug cmd behave the same</summary>
      <description>The -d option switches log4j to DEBUG and leaves the backtrace level at the default. When using the supplied debug command we only switch the backtrace, but I would think this also should set the log4j levels:# Debugging methoddef debug if @shell.debug @shell.debug = false conf.back_trace_limit = 0 else @shell.debug = true conf.back_trace_limit = 100 end debug?endcould be something like # Debugging methoddef debug if @shell.debug @shell.debug = false conf.back_trace_limit = 0 log_level = org.apache.log4j.Level::ERROR else @shell.debug = true conf.back_trace_limit = 100 log_level = org.apache.log4j.Level::DEBUG end org.apache.log4j.Logger.getLogger("org.apache.zookeeper").setLevel(log_level) org.apache.log4j.Logger.getLogger("org.apache.hadoop.hbase").setLevel(log_level) debug?end</description>
      <version>0.90.3,0.90.7,0.92.2,0.94.3,0.98.0,0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hirb.rb</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-1-18 01:00:00" id="6816" opendate="2012-9-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[WINDOWS] line endings on checkout for .sh files</summary>
      <description>On code checkout from svn or git, we need to ensure that the line endings for .sh files are LF, so that they work with cygwin. This is important for getting src/saveVersion.sh to work.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.resources.images.hbase.logo.svg</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-6-12 01:00:00" id="682" opendate="2008-6-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Regularize toString</summary>
      <description>Make all of our toStrings work the same. While at it, make them ruby Hash style so they play well in the (jruby) shell</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.TestToString.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.BaseScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Memcache.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-11-18 01:00:00" id="6820" opendate="2012-9-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[WINDOWS] MiniZookeeperCluster should ensure that ZKDatabase is closed upon shutdown()</summary>
      <description>MiniZookeeperCluster.shutdown() shuts down the ZookeeperServer and NIOServerCnxnFactory. However, MiniZookeeperCluster uses a deprecated ZookeeperServer constructor, which in turn constructs its own FileTxnSnapLog, and ZKDatabase. Since ZookeeperServer.shutdown() does not close() the ZKDatabase, we have to explicitly close it in MiniZookeeperCluster.shutdown().Tests effected by this areTestSplitLogManagerTestSplitLogWorkerTestOfflineMetaRebuildBaseTestOfflineMetaRebuildHoleTestOfflineMetaRebuildOverlap</description>
      <version>0.94.3,0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-1-19 01:00:00" id="6825" opendate="2012-9-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[WINDOWS] Java NIO socket channels does not work with Windows ipv6</summary>
      <description>While running the test TestAdmin.testCheckHBaseAvailableClosesConnection(), I noticed that it takes very long, since it sleeps for 2sec * 500, because of zookeeper retries. The root cause of the problem is that ZK uses Java NIO to create ServerSorcket's from ServerSocketChannels. Under windows, the ipv4 and ipv6 is implemented independently, and Java seems that it cannot reuse the same socket channel for both ipv4 and ipv6 sockets. We are getting "java.net.SocketException: Address family not supported by protocolfamily" exceptions. When, ZK client resolves "localhost", it gets both v4 127.0.0.1 and v6 ::1 address, but the socket channel cannot bind to both v4 and v6. The problem is reported as:http://bugs.sun.com/view_bug.do?bug_id=6230761http://stackoverflow.com/questions/1357091/binding-an-ipv6-server-socket-on-windowsAlthough the JDK bug is reported as resolved, I have tested with jdk1.6.0_33 without any success. Although JDK7 seems to have fixed this problem. In ZK, we can replace the ClientCnxnSocket implementation from ClientCnxnSocketNIO to a non-NIO one, but I am not sure that would be the way to go.Disabling ipv6 resolution of "localhost" is one other approach. I'll test it to see whether it will be any good.</description>
      <version>0.94.3,0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-9-19 01:00:00" id="6836" opendate="2012-9-19 00:00:00" resolution="Later">
    <buginformation>
      <summary>[89-fb] Parallel deletes in HBase Thrift server</summary>
      <description>We need to expose server-side parallel batch deletes through the Thrift server.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotsFromAdmin.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSTableDescriptors.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.UnknownSnapshotException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.SnapshotCreationException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.snapshot.HBaseSnapshotException.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.server.errorhandling.impl.ExceptionOrchestrator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.MasterAdminProtocol.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.executor.EventHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.MasterAdmin.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.hbase.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.MasterAdminProtos.java</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-12-30 01:00:00" id="7250" opendate="2012-11-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>create integration test for balancing regions and killing region servers - 2</summary>
      <description>The original test is too general; need another one that would be more targeted and would test master logic in particular (e.g. not kill master). I re-discovered HBASE-6060 using it on the first run</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.util.ChaosMonkey.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-9-7 01:00:00" id="7296" opendate="2012-12-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add hbase.master.loadbalancer.class in the documentation</summary>
      <description>hbase.master.loadbalancer.class information is missing from the documentation. Might be useful to add it.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-7-8 01:00:00" id="730" opendate="2008-7-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>On startup, rinse STARTCODE and SERVER from .META.</summary>
      <description>Look into what it would take purging startcode and server from .META. on startup. It might make startup run faster. In particular, Clint Morgan was asking for faster startup. Below is from a reply. The +1 is from JK.&gt; &gt; Looking at code, we have the concept of an 'initial' scan. I&gt; &gt; wonder if things would run faster for you if on the initial&gt; &gt; scan we just cleared all SERVER and STARTCODE entries in&gt; &gt; .META. rather than wait on regionserver reports?+1</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ProcessRegionOpen.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-12-7 01:00:00" id="7301" opendate="2012-12-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Force ipv4 for unit tests</summary>
      <description>These two tests are failing when I run them locally:Failed tests: testMultiSlaveReplication(org.apache.hadoop.hbase.replication.TestMultiSlaveReplication): Waited too much time for put replication testCyclicReplication(org.apache.hadoop.hbase.replication.TestMasterReplication): Waited too much time for put replication testSimplePutDelete(org.apache.hadoop.hbase.replication.TestMasterReplication): Waited too much time for put replicationThe TestMasterReplication is NPE'ingMighty JD said he'd take a looksee.</description>
      <version>None</version>
      <fixedVersion>0.94.4,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2012-1-18 01:00:00" id="7384" opendate="2012-12-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Introducing waitForCondition function into test cases</summary>
      <description>Recently I'm working on flaky test cases and found we have many places using while loop and sleep to wait for a condition to be true. There are several issues in existing ways:1) Many similar code doing the same thing2) When time out happens, different errors are reported without explicitly indicating a time out situation3) When we want to increase the max timeout value to verify if a test case fails due to a not-enough time out value, we have to recompile &amp; redeploy codeI propose to create a waitForCondition function as a test utility function like the following: public interface WaitCheck { public boolean Check() ; } public boolean waitForCondition(int timeOutInMilliSeconds, int checkIntervalInMilliSeconds, WaitCheck s) throws InterruptedException { int multiplier = 1; String multiplierProp = System.getProperty("extremeWaitMultiplier"); if(multiplierProp != null) { multiplier = Integer.parseInt(multiplierProp); if(multiplier &lt; 1) { LOG.warn(String.format("Invalid extremeWaitMultiplier property value:%s. is ignored.", multiplierProp)); multiplier = 1; } } int timeElapsed = 0; while(timeElapsed &lt; timeOutInMilliSeconds * multiplier) { if(s.Check()) { return true; } Thread.sleep(checkIntervalInMilliSeconds); timeElapsed += checkIntervalInMilliSeconds; } assertTrue("WaitForCondition failed due to time out(" + timeOutInMilliSeconds + " milliseconds expired)", false); return false; }By doing the above way, there are several advantages:1) Clearly report time out error when such situation happens2) Use System property extremeWaitMultiplier to increase max time out dynamically for a quick verification3) Standardize current wait situationsPleas let me know what your thoughts on this.Thanks,-Jeffrey</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitLogWorker.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestSplitLogManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-1-7 01:00:00" id="7505" opendate="2013-1-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Server will hang when stopping cluster, caused by waiting for split threads</summary>
      <description>We will retry 100 times (about 3200 minitues) for HRegionServer#postOpenDeployTasks now, see HConnectionManager#setServerSideHConnectionRetries.However, when we stopping the cluster, we will wait for split threads in HRegionServer#join,if META/ROOT server has already been stopped, the split thread won't exit because it is in the retrying for HRegionServer#postOpenDeployTasks</description>
      <version>0.94.3</version>
      <fixedVersion>0.94.5,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-1-8 01:00:00" id="7516" opendate="2013-1-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make compaction policy pluggable</summary>
      <description>Currently, the compaction selection is pluggable. It will be great to make the compaction algorithm pluggable too so that we can implement and play with other compaction algorithms.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDefaultCompactSelection.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.HFileReadWriteTest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Compactor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactionTool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionPolicy.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-3-10 01:00:00" id="7533" opendate="2013-1-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Write an RPC Specification for 0.96</summary>
      <description>RPC format is changing for 0.96 to accomodate our protobufing all around. Here is a first cut. Please shred: https://docs.google.com/document/d/1-1RJMLXzYldmHgKP7M7ynK6euRpucD03fZ603DlZfGI/edit</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.rpc.xml</file>
      <file type="M">src.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-1-11 01:00:00" id="7540" opendate="2013-1-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make znode dump to print a dump of replication znodes</summary>
      <description>It will be nice to have a dump of replication related znodes on the master UI (along with other znode dump). It helps while using replication.</description>
      <version>0.94.3</version>
      <fixedVersion>0.94.5,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
</bugrepository>