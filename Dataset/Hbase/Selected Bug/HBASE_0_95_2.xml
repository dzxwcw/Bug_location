<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="HBASE">
  
  <bug fixdate="2011-10-26 01:00:00" id="3925" opendate="2011-5-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make Shell&amp;#39;s -d and debug cmd behave the same</summary>
      <description>The -d option switches log4j to DEBUG and leaves the backtrace level at the default. When using the supplied debug command we only switch the backtrace, but I would think this also should set the log4j levels:# Debugging methoddef debug if @shell.debug @shell.debug = false conf.back_trace_limit = 0 else @shell.debug = true conf.back_trace_limit = 100 end debug?endcould be something like # Debugging methoddef debug if @shell.debug @shell.debug = false conf.back_trace_limit = 0 log_level = org.apache.log4j.Level::ERROR else @shell.debug = true conf.back_trace_limit = 100 log_level = org.apache.log4j.Level::DEBUG end org.apache.log4j.Logger.getLogger("org.apache.zookeeper").setLevel(log_level) org.apache.log4j.Logger.getLogger("org.apache.hadoop.hbase").setLevel(log_level) debug?end</description>
      <version>0.90.3,0.90.7,0.92.2,0.94.3,0.98.0,0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hirb.rb</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2011-12-1 01:00:00" id="4922" opendate="2011-12-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[packaging] Assembly tars up hbase in a subdir; i.e. after untar hbase-0.92.0 has a subdir named 0.92.0</summary>
      <description>Reported by Roman.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-8-1 01:00:00" id="4923" opendate="2011-12-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[packaging] Assembly should make only executables executable (docs should not be executable!)</summary>
      <description>Reported by Roman.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.assembly.all.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-3-16 01:00:00" id="5206" opendate="2012-1-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Port HBASE-5155 to 0.92, 0.94, and TRUNK</summary>
      <description>This JIRA ports HBASE-5155 (ServerShutDownHandler And Disable/Delete should not happen parallely leading to recreation of regions that were deleted) to 0.92 and TRUNK</description>
      <version>0.92.2,0.94.0,0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.TestDrainingServer.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKTable.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestMasterRestartAfterDisablingTable.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestMaster.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKTable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.DeleteTableHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-4-6 01:00:00" id="5525" opendate="2012-3-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Truncate and preserve region boundaries option</summary>
      <description>A tool that would be useful for testing (and maybe in prod too) would be a truncate option to keep the current region boundaries. Right now what you have to do is completely kill the table and recreate it with the correct regions.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.1</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.ruby.shell.rb</file>
      <file type="M">hbase-server.src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-6-12 01:00:00" id="5564" opendate="2012-3-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bulkload is discarding duplicate records</summary>
      <description>Duplicate records are getting discarded when duplicate records exists in same input file and more specifically if they exists in same split.Duplicate records are considered if the records are from diffrent different splits.Version under test: HBase 0.92</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.mapreduce.TestImportTsv.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.TsvImporterMapper.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.ImportTsv.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestImportTsv.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TsvImporterMapper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.ImportTsv.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2008-4-3 01:00:00" id="559" opendate="2008-4-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>MR example job to count table rows</summary>
      <description>The Lars' import is a little messy; he's not sure how many records were imported. Running a select takes a couple of hours. He happens to have an idle MR cluster standing by. An example MR job that just did a count of records would be generally useful. Could even output row keys so you'd have a list of what made it in. Later, if this tool becomes popular with derivatives and similiars, we can bundle a jar of MR jobs to run against your tables that can answer common queries and that are amenable to subclassing/modification.</description>
      <version>None</version>
      <fixedVersion>0.1.2,0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.package-info.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-10-16 01:00:00" id="5591" opendate="2012-3-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>ThiftServerRunner.HBaseHandler.toBytes() is identical to Bytes.getBytes()</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionThriftServer.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-4-20 01:00:00" id="5604" opendate="2012-3-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>M/R tool to replay WAL files</summary>
      <description>Just an idea I had. Might be useful for restore of a backup using the HLogs.This could an M/R (with a mapper per HLog file).The tool would get a timerange and a (set of) table(s). We'd pick the right HLogs based on time before the M/R job is started and then have a mapper per HLog file.The mapper would then go through the HLog, filter all WALEdits that didn't fit into the time range or are not any of the tables and then uses HFileOutputFormat to generate HFiles.Would need to indicate the splits we want, probably from a live table.</description>
      <version>None</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.mapreduce.TestWALPlayer.java</file>
      <file type="M">src.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-3-27 01:00:00" id="5642" opendate="2012-3-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[findbugs] Exclude Thrift and Protobuf warnings</summary>
      <description>Exclude thrift and protobuf warnings since these are machine generated.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">dev-support.test-patch.properties</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-4-27 01:00:00" id="5644" opendate="2012-3-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[findbugs] Fix null pointer warnings.</summary>
      <description>See https://builds.apache.org/job/PreCommit-HBASE-Build/1313//artifact/trunk/patchprocess/newPatchFindbugsWarnings.htmlFix the NP category</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.Merge.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.ShutdownHook.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.metrics.SchemaConfigured.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.CellCounter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">dev-support.test-patch.properties</file>
      <file type="M">dev-support.findbugs-exclude.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-4-27 01:00:00" id="5652" opendate="2012-3-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[findbugs] Fix lock release on all paths</summary>
      <description>See https://builds.apache.org/job/PreCommit-HBASE-Build/1313//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html#Warnings_MT_CORRECTNESSCategory UL</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.LogRoller.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">dev-support.test-patch.properties</file>
      <file type="M">dev-support.findbugs-exclude.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-4-27 01:00:00" id="5653" opendate="2012-3-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[findbugs] fix perf warnings</summary>
      <description>See https://builds.apache.org/job/PreCommit-HBASE-Build/1313//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html#Warnings_PERFORMANCE</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.executor.TestExecutorService.java</file>
      <file type="M">src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSinkMetrics.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSink.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.metrics.HBaseInfo.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.DefaultLoadBalancer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.MultithreadedTableMapper.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.WritableRpcEngine.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.slab.SlabCache.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.slab.SingleSizeCache.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.executor.ExecutorService.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException.java</file>
      <file type="M">dev-support.test-patch.properties</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-4-27 01:00:00" id="5654" opendate="2012-3-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[findbugs] Address dodgy bugs</summary>
      <description>See https://builds.apache.org/job/PreCommit-HBASE-Build/1313//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html#Warnings_STYLEThis may be broken down further.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.RegionSplitter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.PoolMap.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.FSHDFSUtils.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.CompressionTest.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.CompoundBloomFilterWriter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.ByteBloomFilter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreLAB.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.compactions.CompactionProgress.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.WritableRpcEngine.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.AbstractHFileWriter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HServerLoad.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.filter.FilterList.java</file>
      <file type="M">src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">dev-support.test-patch.properties</file>
      <file type="M">dev-support.findbugs-exclude.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-4-30 01:00:00" id="5688" opendate="2012-3-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Convert zk root-region-server znode content to pb</summary>
      <description>Move the root-region-server znode content from the versioned bytes that ServerName.getVersionedBytes outputs to instead be pb.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestMasterNoCluster.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.catalog.TestCatalogTrackerOnCluster.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.catalog.TestCatalogTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.RootRegionTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.catalog.RootLocationEditor.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-12-2 01:00:00" id="5699" opendate="2012-4-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Run with &gt; 1 WAL in HRegionServer</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.0.0,1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALFactory.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-4-4 01:00:00" id="5712" opendate="2012-4-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Parallelize load of .regioninfo files in diagnostic/repair portion of hbck.</summary>
      <description>On heavily loaded hdfs's some dfs nodes may not respond quickly and backs off for 60s before attempting to read data from another datanode. Portions of the information gathered from hdfs (.regioninfo files) are loaded serially. With HBase with clusters with 100's, or 1000's, or 10000's regions encountering these 60s delay blocks progress and can be very painful. There is already some parallelization of portions of the hdfs information load operations and the goal here is move the reading of .regioninfos into the parallelized sections..</description>
      <version>0.90.7,0.92.2,0.94.0,0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-4-4 01:00:00" id="5717" opendate="2012-4-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scanner metrics are only reported if you get to the end of a scanner</summary>
      <description>When you turn on Scanner Metrics, the metrics are currently only made available if you run over all records available in the scanner. If you stop iterating before the end, the values are never flushed into the metrics object (in the Scan attribute).Will supply a patch with fix and test.</description>
      <version>None</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-4-4 01:00:00" id="5719" opendate="2012-4-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enhance hbck to sideline overlapped mega regions</summary>
      <description>If there are too many regions in one overlapped group (by default, more than 10), hbck currently doesn't merge them since it takes time.In this case, we can sideline some regions in the group and break the overlapping to fix the inconsistency. Later on, sidelined regions can be bulk loaded manually.</description>
      <version>0.94.0,0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.util.TestRegionSplitCalculator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.RegionSplitCalculator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-4-5 01:00:00" id="5734" opendate="2012-4-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change hbck sideline root</summary>
      <description>Currently hbck sideline root is the root which can run into permission issue. We can change it to /hbck</description>
      <version>0.94.0,0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-4-6 01:00:00" id="5739" opendate="2012-4-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade guava to 11.0.2</summary>
      <description>Hadoop has upgraded to this new version of Guava. We should, too, so we don't have compatibility issues running on Hadoop 2.0+</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.slab.SingleSizeCache.java</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-4-6 01:00:00" id="5740" opendate="2012-4-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compaction interruption may be due to balacing</summary>
      <description>Currently, the log shows Aborting compaction of store LOG in region .... because user requested stop.But it is actually because of balancing.Currently, there is no way to figure out who closed the region. So it is better to change the message to say it is because of user, or balancing.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.Compactor.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-4-9 01:00:00" id="5755" opendate="2012-4-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Region sever looking for master forever with cached stale data.</summary>
      <description>When the master address tracker doesn't have the master address ZK data, or the cached data is wrong, region server should not use the cached data.It should pull the data from ZK directly again.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.MasterAddressTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-5-13 01:00:00" id="5785" opendate="2012-4-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Adding unit tests for protbuf utils introduced for HRegionInterface pb conversion</summary>
      <description>We need to add some unit tests for the probuf utilities to catch issues earlier.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-4-13 01:00:00" id="5787" opendate="2012-4-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Table owner can&amp;#39;t disable/delete his/her own table</summary>
      <description>An user with CREATE privileges can create a table, but can not disable it, because disable operation require ADMIN privileges. Also if a table is already disabled, anyone can remove it.public void preDeleteTable(ObserverContext&lt;MasterCoprocessorEnvironment&gt; c, byte[] tableName) throws IOException { requirePermission(Permission.Action.CREATE);}public void preDisableTable(ObserverContext&lt;MasterCoprocessorEnvironment&gt; c, byte[] tableName) throws IOException { /* TODO: Allow for users with global CREATE permission and the table owner */ requirePermission(Permission.Action.ADMIN);}</description>
      <version>0.92.1,0.94.0,0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">security.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">security.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-4-14 01:00:00" id="5794" opendate="2012-4-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Jenkins builds timing out; undo setting hbase.client.retries.number to 100</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.resources.hbase-site.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-4-16 01:00:00" id="5800" opendate="2012-4-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Birds of a feather link on web page doesn&amp;#39;t work.</summary>
      <description>just missing the http://</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.index.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-4-17 01:00:00" id="5805" opendate="2012-4-17 00:00:00" resolution="Cannot Reproduce">
    <buginformation>
      <summary>TestServerCustomProtocol failing intermittently.</summary>
      <description>Trace:java.lang.AssertionError: Results should contain region test,ccc,1334638013935.b9d77206f6eb226928b898e66fd1d508. for row 'ccc' at org.junit.Assert.fail(Assert.java:93) at org.junit.Assert.assertTrue(Assert.java:43) at org.apache.hadoop.hbase.regionserver.TestServerCustomProtocol.verifyRegionResults(TestServerCustomProtocol.java:363) at org.apache.hadoop.hbase.regionserver.TestServerCustomProtocol.testNullReturn(TestServerCustomProtocol.java:330) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)</description>
      <version>0.95.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-4-18 01:00:00" id="5819" opendate="2012-4-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>SplitLogs function could leak resources</summary>
      <description>You would need to be unlucky and with a system in a bad shape but we have no reason to keep this in production code.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-4-16 01:00:00" id="582" opendate="2008-4-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase 554 forgot to clear results on each iteration caused by a filter</summary>
      <description>I noticed this while working on new filters. Not sure if it will trip up any existing filters, but it is surely a bug.Patch to follow</description>
      <version>None</version>
      <fixedVersion>0.1.2,0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-5-20 01:00:00" id="5844" opendate="2012-4-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Delete the region servers znode after a regions server crash</summary>
      <description>today, if the regions server crashes, its znode is not deleted in ZooKeeper. So the recovery process will stop only after a timeout, usually 30s.By deleting the znode in start script, we remove this delay and the recovery starts immediately.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">bin.hbase-daemon.sh</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2012-4-25 01:00:00" id="5872" opendate="2012-4-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve hadoopqa script to include checks for hadoop 0.23 build</summary>
      <description>There have been a few patches that have made it into hbase trunk that have broken the compile of hbase against hadoop 0.23.x, without being known for a few days.We could have the bot do a few things:1) verify that patch compiles against hadoop 232) verify that unit tests pass against hadoop 23</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-5-25 01:00:00" id="5879" opendate="2012-4-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable JMX metrics collection for the Thrift proxy</summary>
      <description>We need to enable JMX on the Thrift proxy on a separate port different from the JMX port used by regionserver. This is necessary for metrics collection.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase-config.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-4-17 01:00:00" id="588" opendate="2008-4-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Still a &amp;#39;hole&amp;#39; in scanners, even after HBASE-532</summary>
      <description>Before HBASE-532, as soon as a flush started, we called snapshot. Snapshot used to copy current live memcache into a 'snapshot' TreeMap inside in Memcache. This snapshot TreeMap was an accumulation of all snapshots since last flush. Whenever we took out a scanner, we'd do a copy of this snapshot into a new backing map carried by the scanner (Every outstanding Scanner had complete copy). Memcache snapshots were cleared when a flush started. Flushing could take near no time to up to tens of seconds during which an scanners taken out meantime would not see the edits in the snapshot currently being flushed and gets or getFull would also return incorrect answers because the content of the snapshot was not available to them.HBASE-532 made it so the snapshot was available until flush was done &amp;#8211; until a file had made it out to disk. This fixed gets and getFull and any scanners taken out during flushing. But there is still a hole. Any outstanding scanners will be going against the state of Store Readers at time scanner was opened; they will not see the new flush file.Chatting about this on IRC, Jim suggests that we pass either memcache or current snapshot to each Scanner (Pass the snapshot if not empty). The notion is that the Scanner would hold on to the Scanner reference should it be cleared by flushing. Upside is that scanner wouldn't have to be concerned with the new flush that has been put out to disk. Downsides are that Scanner data could be way stale if for instance the memcache was near to flushing but we hadn't done it yet. And we wouldn't be clearing the snapshot promptly so would be some memory pressure.Another suggestion is that flushing send an event. Listeners such as outstanding scanners would notice event and open the new Reader. Would have to skip forward in the new Reader to catch up with the current set but shouldn't be bad. Same mechanism could be used to let compactions be moved into place while scanners were outstanding closing down all existing readers skipping to the current 'next' location in the new compacted store file.</description>
      <version>None</version>
      <fixedVersion>0.1.2,0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.test.org.apache.hadoop.hbase.MultiRegionTable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStoreScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HAbstractScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Flusher.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.CacheFlushListener.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-4-26 01:00:00" id="5884" opendate="2012-4-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>MapReduce package info has broken link to bulk-loads</summary>
      <description>Bulk Loads link goes to an old link, which we have dropped recently.</description>
      <version>0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.package-info.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-5-27 01:00:00" id="5888" opendate="2012-4-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clover profile in build</summary>
      <description>Clover is disabled right now. I would like to add a profile that enables clover reports. We can also backport this to 0.92, and 0.94, since we are also interested in test coverage for those branches.</description>
      <version>0.92.2,0.94.1,0.95.2</version>
      <fixedVersion>0.94.4,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-5-30 01:00:00" id="5903" opendate="2012-4-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Detect the test classes without categories</summary>
      <description>The tests are executed by category. When a test does not have a category, it's not run on prebuild nor central build.This new test checks the test classess and list the ones without category. It fails if it finds one. As it's a small test it will be executed on the developper machine and will fail immediately on the central builds.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.TestHColumnDescriptor.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-5-4 01:00:00" id="5939" opendate="2012-5-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add an autorestart option in the start scripts</summary>
      <description>When a binary dies on a server, we don't try to restart it while it would be possible in most cases.We can have something as:loop start wait if cleanStop then exit if already stopped less than 5 minutes ago sleep 5 minuteendloopThis is simple for master &amp; backup master, a little bit more complex for the region server as it can be stopped by a script or by the shutdown procedure.On a long long term it could allow a restart with exactly the same assignments.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.start-hbase.sh</file>
      <file type="M">bin.hbase-daemon.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-11-5 01:00:00" id="5945" opendate="2012-5-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reduce buffer copies in IPC server response path</summary>
      <description>The new PB code is sloppy with buffers and makes several needless copies. This increases GC time a lot. A few simple changes can cut this back down.</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.96.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestIPC.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide3.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServer.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceImpl.java</file>
      <file type="M">hbase-hadoop1-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSource.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.IPCUtil.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-5-6 01:00:00" id="5948" opendate="2012-5-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Deprecate and remove the Avro gateway</summary>
      <description>Deprecate the Avro gateway in 0.94. Remove in 0.96. Made a blocker against that release.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.avro.package.html</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.avro.AvroUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.avro.AvroServer.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  
  <bug fixdate="2012-5-11 01:00:00" id="5992" opendate="2012-5-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Generalization of region move implementation + manage draining servers in bulk assign</summary>
      <description>The region move implementation now has now a similar behavior whatever the destination server is specified or not. This allows: to benefit from the improvement in HBASE-5877 as a side effect to have the coprocessors calls when the destination server is not specifiedThis includes various fixes around draining servers. Draining servers were not excluded during a bulk assign. This is now fixed.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.TestDrainingServer.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.CreateTableHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-5-15 01:00:00" id="6001" opendate="2012-5-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade slf4j to 1.6.1</summary>
      <description>We need to upgrade slf4j to 1.6.1 since other hadoop components use 1.6.1 now.</description>
      <version>None</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-5-15 01:00:00" id="6004" opendate="2012-5-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Adding more logging to help debugging MR job</summary>
      <description>MR job sometime fails because scanner expired. In this case, it will be helpful to know the last successful row, the ip of the region sever, and so on.</description>
      <version>0.94.0,0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapred.TableRecordReaderImpl.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-5-15 01:00:00" id="6005" opendate="2012-5-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Broken Links on Homepages</summary>
      <description>I ran w3c's link checker on the homepage and there a few broken links.I'll start getting a patch to fix the links that were broken.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.old.news.xml</file>
      <file type="M">src.site.xdoc.cygwin.xml</file>
      <file type="M">src.main.javadoc.overview.html</file>
      <file type="M">src.docbkx.preface.xml</file>
      <file type="M">src.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-5-15 01:00:00" id="6007" opendate="2012-5-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make getTableRegions return an empty list if the table does not exist</summary>
      <description>Making the getTableRegions Thrift API method handle TableNotFoundException and return an empty list in that case. Without this the behavior is dependent on whether an HTable object is present in the thread-local cache in case a table was deleted.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-5-16 01:00:00" id="6022" opendate="2012-5-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Include Junit in the libs when packaging so that TestAcidGaurntee can run</summary>
      <description>If JUnit is not in the libs folder running the test acid command fails.</description>
      <version>None</version>
      <fixedVersion>0.94.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-5-16 01:00:00" id="6023" opendate="2012-5-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Normalize security audit logging level with Hadoop</summary>
      <description>A pretty trivial change, we log failed authentication attempts at WARN level, as does Hadoop, but log successful authentication at TRACE level, where Hadoop instead logs it at INFO level.</description>
      <version>0.92.2,0.94.1,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.HBaseServer.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-9-16 01:00:00" id="6025" opendate="2012-5-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expose Hadoop Dynamic Metrics through JSON Rest interface</summary>
      <description/>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.ruby.shell.formatter.rb</file>
      <file type="M">hbase-server.src.main.ruby.shell.commands.rb</file>
      <file type="M">hbase-server.src.main.ruby.shell.rb</file>
      <file type="M">hbase-server.src.main.ruby.hbase.table.rb</file>
      <file type="M">hbase-server.src.main.ruby.hbase.hbase.rb</file>
      <file type="M">hbase-server.src.main.ruby.hbase.admin.rb</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.zk.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.tablesDetailed.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-5-19 01:00:00" id="6057" opendate="2012-5-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change some tests categories to optimize build time</summary>
      <description>Some tests categorized as small takes more than 15s: it's better if they are executed in // with the medium tests.Some medium tests last less than 2s: it's better to have then executed with the small tests: we save a fork.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.zookeeper.TestHQuorumPeer.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.util.TestPoolMap.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRollingNoCluster.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestMemStore.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestGetClosestAtOrBefore.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestCompoundBloomFilter.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.monitoring.TestTaskMonitor.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.monitoring.TestMemoryBoundedLogMessageBuffer.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.metrics.TestMetricsMBeanBase.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestDefaultLoadBalancer.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestClockSkewDetection.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.ipc.TestPBOnWritableRpc.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.hfile.TestLruBlockCache.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileBlockCompatibility.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.hfile.TestFixedFileTrailer.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.hfile.TestChecksum.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.encoding.TestEncodedSeekers.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.encoding.TestBufferedDataBlockEncoder.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-5-21 01:00:00" id="6061" opendate="2012-5-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix ACL "Admin" Table inconsistent permission check</summary>
      <description>the requirePermission() check for "admin" operation on a table is currently inconsistent.Table Owner with CREATE rights (that means, the owner has created that table) can enable/disable and delete the table but needs ADMIN rights to add/remove/modify a column.</description>
      <version>0.92.1,0.94.0,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-5-22 01:00:00" id="6065" opendate="2012-5-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Log for flush would append a non-sequential edit in the hlog, leading to possible data loss</summary>
      <description>After completing flush region, we will append a log edit in the hlog file through HLog#completeCacheFlush.public void completeCacheFlush(final byte [] encodedRegionName, final byte [] tableName, final long logSeqId, final boolean isMetaRegion){...HLogKey key = makeKey(encodedRegionName, tableName, logSeqId, System.currentTimeMillis(), HConstants.DEFAULT_CLUSTER_ID);...}when we make the hlog key, we use the seqId from the parameter, and it is generated by HLog#startCacheFlush,Here, we may append a lower seq id edit than the last edit in the hlog file.If it is the last edit log in the file, it may cause data loss.because HRegion#replayRecoveredEditsIfAny{...maxSeqId = Math.abs(Long.parseLong(fileName)); if (maxSeqId &lt;= minSeqId) { String msg = "Maximum sequenceid for this log is " + maxSeqId + " and minimum sequenceid for the region is " + minSeqId + ", skipped the whole file, path=" + edits; LOG.debug(msg); continue; }...}We may skip the splitted log file, because we use the lase edit's seq id as its file name, and consider this seqId as the max seq id in this log file.</description>
      <version>None</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2012-6-27 01:00:00" id="6110" opendate="2012-5-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix TestInfoServers</summary>
      <description>With the recent port to modules, we broke a couple of tests, including this one. The fix needs to ensure that the webapp still works from the in-situ and packaged running of HBase.</description>
      <version>0.95.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-site.pom.xml</file>
      <file type="M">hbase-server.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-assembly.pom.xml</file>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-5-28 01:00:00" id="6118" opendate="2012-5-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a testcase for HBASE-6065</summary>
      <description>It would be nice to have a testcase for HBASE-6065. Internally we have written a test case to simulate the problem. Thought that it would be better to contribute the same.</description>
      <version>None</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-6-31 01:00:00" id="6138" opendate="2012-5-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HadoopQA not running findbugs [Trunk]</summary>
      <description>HadoopQA shows like -1 findbugs. The patch appears to cause Findbugs (version 1.3.9) to fail.But not able to see any reports linkWhen I checked the console output for the build I can see[INFO] --- findbugs-maven-plugin:2.4.0:findbugs (default-cli) @ hbase-common ---[INFO] Fork Value is true[INFO] ------------------------------------------------------------------------[INFO] Reactor Summary:[INFO] [INFO] HBase ............................................. SUCCESS [1.890s][INFO] HBase - Common .................................... FAILURE [2.238s][INFO] HBase - Server .................................... SKIPPED[INFO] HBase - Assembly .................................. SKIPPED[INFO] HBase - Site ...................................... SKIPPED[INFO] ------------------------------------------------------------------------[INFO] BUILD FAILURE[INFO] ------------------------------------------------------------------------[INFO] Total time: 4.856s[INFO] Finished at: Thu May 31 03:35:35 UTC 2012[INFO] Final Memory: 23M/154M[INFO] ------------------------------------------------------------------------[ERROR] Could not find resource '${parent.basedir}/dev-support/findbugs-exclude.xml'. -&gt; [Help 1][ERROR] Because of this error Findbugs is getting run!</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-6-4 01:00:00" id="6160" opendate="2012-6-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>META entries from daughters can be deleted before parent entries</summary>
      <description>HBASE-5986 fixed and issue, where the client sees the META entry for the parent, but not the children. However, after the fix, we have seen the following issue in tests: Region A is split to -&gt; B, CRegion B is split to -&gt; D, EAfter some time, META entry for B is deleted since it is not needed anymore, but META entry for Region A stays in META (C still refers it). In this case, the client throws RegionOfflineException for B.</description>
      <version>0.92.2,0.94.0,0.95.2</version>
      <fixedVersion>0.92.2,0.94.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-6-5 01:00:00" id="6167" opendate="2012-6-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix xinclude for docs broke when we multi-moduled</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-6-6 01:00:00" id="6177" opendate="2012-6-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add .idea to RAT excludes</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-9-6 01:00:00" id="6178" opendate="2012-6-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>LoadTest tool no longer packaged after the modularization</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.assembly.hadoop-two-compat.xml</file>
      <file type="M">src.assembly.hadoop-one-compat.xml</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-6-6 01:00:00" id="6179" opendate="2012-6-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix stylesheet broke since multimodule and address feedback gotten in new comment system</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.ops.mgt.xml</file>
      <file type="M">src.docbkx.configuration.xml</file>
      <file type="M">src.docbkx.book.xml</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-11-7 01:00:00" id="6182" opendate="2012-6-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make HBase works with jdk1.7</summary>
      <description>jdk1.7 is out for a while. HBase should support it.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreFile.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestGetClosestAtOrBefore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.GetClosestRowBeforeTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.catalog.MetaReader.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-6-8 01:00:00" id="6192" opendate="2012-6-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document ACL matrix in the book</summary>
      <description>We have an excellent matrix at https://issues.apache.org/jira/secure/attachment/12531252/Security-ACL%20Matrix.pdf for ACL. Once the changes are done, we can adapt that and put it in the book, also add some more documentation about the new authorization features.</description>
      <version>0.94.1,0.95.2</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.security.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-9-12 01:00:00" id="6201" opendate="2012-6-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase integration/system tests</summary>
      <description>Integration and general system tests have been discussed previously, and the conclusion is that we need to unify how we do "release candidate" testing (HBASE-6091).In this issue, I would like to discuss and agree on a general plan, and open subtickets for execution so that we can carry out most of the tests in HBASE-6091 automatically. Initially, here is what I have in mind: 1. Create hbase-it (or hbase-tests) containing forward port of HBASE-4454 (without any tests). This will allow integration test to be run with mvn verify 2. Add ability to run all integration/system tests on a given cluster. Smt like: mvn verify -Dconf=/etc/hbase/conf/ should run the test suite on the given cluster. (Right now we can launch some of the tests (TestAcidGuarantees) from command line). Most of the system tests will be client side, and interface with the cluster through public APIs. We need a tool on top of MiniHBaseCluster or improve HBaseTestingUtility, so that tests can interface with the mini cluster or the actual cluster uniformly.3. Port candidate unit tests to the integration tests module. Some of the candidates are: TestAcidGuarantees / TestAtomicOperation TestRegionBalancing (HBASE-6053) TestFullLogReconstruction TestMasterFailover TestImportExport TestMultiVersions / TestKeepDeletes TestFromClientSide TestShell and src/test/ruby TestRollingRestart Test**OnCluster Balancer testsThese tests should continue to be run as unit tests w/o any change in semantics. However, given an actual cluster, they should use that, instead of spinning a mini cluster. 4. Add more tests, especially, long running ingestion tests (goraci, BigTop's TestLoadAndVerify, LoadTestTool), and chaos monkey style fault tests. All suggestions welcome.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.developer.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-7-12 01:00:00" id="6203" opendate="2012-6-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create hbase-it module</summary>
      <description>Create hbase-it, as per parent issue, and re-introduce HBASE-4454</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-5-9 01:00:00" id="621" opendate="2008-5-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make MAX_VERSIONS work like TTL: In scans and gets, check MAX_VERSIONs setting and return that many only rather than wait on compaction</summary>
      <description>HBASE-47 added specification of TTL on cells. The implementation checks cell timestamp against configured TTL before returning results scanning or getting. You can also set the maximum versions of a cell to keep. The maximum versions is not checked scanning or getting, only when we compact (We'll drop cells that are beyond the maximum version at compaction time). This issue is about adding check for maximum versions to gets and scans so that if you ask for all versions but have configured the store to only keep 3 versions, though 4 may have been inserted, you'll currently get 4 returned (if compactions have not had a chance to run).</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Memcache.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-6-14 01:00:00" id="6211" opendate="2012-6-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Put latencies in jmx</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.metrics.TestMetricsMBeanBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.metrics.MetricsMBeanBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.metrics.histogram.MetricsHistogram.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-10-17 01:00:00" id="6223" opendate="2012-6-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document hbck improvements: HBASE-6173, HBASE-5360</summary>
      <description>We had a couple hbck improvements recently: HBASE-6173 and HBASE-5360.We should document them. Especially, for HBASE-5360, it's somethingone normally doesn't do.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-6-19 01:00:00" id="6238" opendate="2012-6-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Grant on META not taking effect</summary>
      <description>User is not able to perform authorized operations on Meta.</description>
      <version>0.94.0,0.94.1,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlLists.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-6-20 01:00:00" id="6242" opendate="2012-6-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>New UI should color task list entries</summary>
      <description>The old UI changed the background color of tasklist entries according to their final status: green if successful, yellow if aborted, red if failed. Bring this back in the new UI.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-6-20 01:00:00" id="6243" opendate="2012-6-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>New UI should space detailed latency columns equally</summary>
      <description>Spacing between the columns of the detailed latencies tab should be roughly equal. Round latencies to two digits right of decimal point.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-8-20 01:00:00" id="6245" opendate="2012-6-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upon page refresh new UI should return to the previously selected tab</summary>
      <description/>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-6-21 01:00:00" id="6252" opendate="2012-6-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>TABLE ADMIN should be allowed to relocate regions</summary>
      <description/>
      <version>0.94.0,0.94.1,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-7-21 01:00:00" id="6253" opendate="2012-6-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Do not allow user to disable or drop ACL table</summary>
      <description>Currently HTableDescriptor.isLegalTableName API doesn't check for the acl table name, due to this user can able to disable/enable/drop/create the acl table.</description>
      <version>0.94.1,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-6-21 01:00:00" id="6256" opendate="2012-6-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Zk Dump was missed in the move to new UI</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.css.hbase.css</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.zk.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.tablesDetailed.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-6-26 01:00:00" id="6274" opendate="2012-6-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Proto files should be in the same palce</summary>
      <description>Currently, proto files are under hbase-server/src/main/protobuf and hbase-server/src/protobuf. It's better to put them together.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.protobuf.RegionServerStatus.proto</file>
      <file type="M">hbase-server.src.protobuf.Client.proto</file>
      <file type="M">hbase-server.src.protobuf.Admin.proto</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-7-2 01:00:00" id="6303" opendate="2012-7-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HCD.setCompressionType should use Enum support for storing compression types as strings</summary>
      <description>Let's not require an update to HCD every time the HFile compression enum is changed.</description>
      <version>0.94.0,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-10-3 01:00:00" id="6316" opendate="2012-7-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Confirm can upgrade to 0.96 from 0.94 by just stopping and restarting</summary>
      <description>Over in HBASE-6294, LarsH says you have to currently clear zk to get a 0.96 to start over data written by a 0.94. Need to fix it so don't have to do this &amp;#8211; that zk state left over gets auto-migrated.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.Reference.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-7-5 01:00:00" id="6332" opendate="2012-7-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve POM for better integration with downstream ivy projects</summary>
      <description>Currently there are 2 issues affecting the downstream ivy projects: no default value for slf4j.version dependency on a non-standard junit artifactI suggest we correct both of these in order to ensure the smooth upgrade path for things like Sqoop.</description>
      <version>0.94.1,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-7-8 01:00:00" id="6355" opendate="2012-7-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow HBase to compile against JDK7</summary>
      <description/>
      <version>0.94.1,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-5-10 01:00:00" id="6368" opendate="2012-7-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade Guava for critical performance bug fix</summary>
      <description>The bug is http://code.google.com/p/guava-libraries/issues/detail?id=1055See discussion under 'Upgrade to Guava 12.0.1: Performance bug in CacheBuilder/LoadingCache fixed!'</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-7-11 01:00:00" id="6373" opendate="2012-7-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add more context information to audit log messages</summary>
      <description>The attached patch adds more information to the audit log messages; namely, it includes the IP address where the request originated, if it's available.The patch is against trunk, but I've tested it against the 0.92 branch. I didn't find any unit test for this code, please let me know if I missed something.</description>
      <version>0.94.2,0.95.2</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-7-12 01:00:00" id="6380" opendate="2012-7-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>bulkload should update the store.storeSize</summary>
      <description>After bulkloading some HFiles into the Table, we found the force-split didn't work because of the MidKey == NULL. Only if we re-booted the HBase service, the force-split can work normally.</description>
      <version>0.94.0,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-7-12 01:00:00" id="6382" opendate="2012-7-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade Jersey to 1.8 to match Hadoop 1 and 2</summary>
      <description>Upgrade Jersey dependency from 1.4 to 1.8 to match Hadoop dependencies.</description>
      <version>0.90.7,0.92.2,0.94.2,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  
  <bug fixdate="2012-8-20 01:00:00" id="6436" opendate="2012-7-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Netty should be moved off of snapshots.</summary>
      <description>Netty is currently at 3.5.0.final-SNAPSHOT the final 3.5.0.Final should be used when possible so that repositories aren't queried when not needed.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2012-7-24 01:00:00" id="6445" opendate="2012-7-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>rat check fails if hs_err_pid26514.log dropped in tests</summary>
      <description>Let test fail because jvm crashed rather than because of rat license complaint</description>
      <version>None</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2012-8-1 01:00:00" id="6489" opendate="2012-8-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Incorrect TaskTracker logfile name</summary>
      <description>http://hbase.apache.org/book/trouble.log.html"TaskTracker: $HADOOP_HOME/logs/hadoop-&lt;user&gt;jobtracker&lt;hostname&gt;.log"should be "TaskTracker: $HADOOP_HOME/logs/hadoop-&lt;user&gt;tasktracker&lt;hostname&gt;.log"</description>
      <version>0.90.7,0.92.2,0.92.3,0.94.2,0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.troubleshooting.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2008-6-29 01:00:00" id="652" opendate="2008-5-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>dropping table fails silently if table isn&amp;#39;t disabled</summary>
      <description>Rather than fail silently, hbase should throw an exception</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-8-13 01:00:00" id="6574" opendate="2012-8-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add HBase Ref Card pointer to Ref Guide</summary>
      <description>The HBase Refcard is at http://refcardz.dzone.com/refcardz/hbaseMaybe it belongs to Appendix F? dmeil?</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-8-16 01:00:00" id="6594" opendate="2012-8-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move tasks section above regions section in RegionServer UI</summary>
      <description>With the new RegionServer UI, at the top of the page is the server metrics tab, then the region list, then the task list, the software attributes. The region list could be lengthy, so scrolling down to find the task list can take some time. Every refresh of the page resets the view to &amp;#91;0,0&amp;#93;. Therefore "at a glance" information should come first, "above the fold", statistics at the top followed by the tasks section.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-8-16 01:00:00" id="6595" opendate="2012-8-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Wrong book author name on Other HBase Resource page</summary>
      <description>There is a typing miss of the HBase Administration Cookbook's author name on the Other HBase Resource page.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.resources.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-8-17 01:00:00" id="6604" opendate="2012-8-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bump log4j to 1.2.17</summary>
      <description>Hadoop bumped to 1.2.17 log4j (HADOOP-8687), we should probably as well.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-8-17 01:00:00" id="6606" opendate="2012-8-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Test for reconnecting with HBaseAdmin using unmanaged HConnection</summary>
      <description>HBASE-5058 allowed HBaseAdmin to work with an existing and unmanaged HConnection. The retry semantics of managed vs unmanaged connections are different. From the JIRA:"For an HConnection that is passed from the outside, it has to be possible to try again. So if the HConnection is managed we retain the old behavior (i.e. only try once, give up after that, even if that failed).For an unmanaged connection we try again unless we actually found a master. ."I couldn't find any test of this behavior, only that the HBaseAdmin works with an unmanaged connection, i.e. no retry testing.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-9-28 01:00:00" id="6677" opendate="2012-8-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Random ZooKeeper port in test can overrun max port</summary>
      <description>while (true) { try { standaloneServerFactory = new NIOServerCnxnFactory(); standaloneServerFactory.configure( new InetSocketAddress(tentativePort), configuration.getInt(HConstants.ZOOKEEPER_MAX_CLIENT_CNXNS, 1000)); } catch (BindException e) { LOG.debug("Failed binding ZK Server to client port: " + tentativePort); // This port is already in use, try to use another. tentativePort++; continue; } break; }In the case of failure and all the above ports have already been binded, you can extend past the max port. Need to check against a max value.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2008-6-5 01:00:00" id="668" opendate="2008-6-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBASE-533 broke build</summary>
      <description>Build was broken when I committed HBASE-533. Bunch of tests started to fail (I didn't run tests before committing).</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.webapps.master.regionhistorian.jsp</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestRegionRebalancing.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.TestGlobalMemcacheLimit.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.RegionHistorian.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.RegionManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ProcessServerShutdown.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.ProcessRegionOpen.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.BaseScanner.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-9-29 01:00:00" id="6688" opendate="2012-8-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>folder referred by thrift demo app instructions is outdated</summary>
      <description>Due to the source tree module change for 0.96, the instructions in the thrift demo example don't match the folder structure any more.In the instruction, it is referring to:../../../src/main/resources/org/apache/hadoop/hbase/thrift/Hbase.thriftit should be../../hbase-server/src/main/resources/org/apache/hadoop/hbase/thrift/Hbase.thrift</description>
      <version>0.95.2</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.package.html</file>
      <file type="M">hbase-server.src.main.javadoc.org.apache.hadoop.hbase.thrift.package.html</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-8-6 01:00:00" id="669" opendate="2008-6-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>MultiRegion transactions with Optimistic Concurrency Control</summary>
      <description>We have a need for ACID transactions across tables. This issue is about adding transactions which span multiple regions. We do not envision many competing writes, and will be read-dominated in general. This makes Optimistic Concurrency Control (OCC) seem like the way to go.</description>
      <version>None</version>
      <fixedVersion>0.18.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.transactional.TestHLogRecovery.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.HBaseTestCase.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HLogKey.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HLogEdit.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HLog.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HMerge.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.ServerCallable.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-9-7 01:00:00" id="6742" opendate="2012-9-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change default test parallelisation level to 5</summary>
      <description>Tests will be faster.Not visible if a test hangs for 15 minutes. But they should not hang.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-9-7 01:00:00" id="6746" opendate="2012-9-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Impacts of HBASE-6435 vs. HDFS 2.0 trunk</summary>
      <description>When using the trunk of HDFS branch 2, I had two errors linked to HBASE-6435: a missing test to null a method removed.This fixes it: add the test make the test case less dependant on HDFS internal.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.fs.TestBlockReorder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.fs.HFileSystem.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-9-12 01:00:00" id="6766" opendate="2012-9-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove the Thread Dump link on Info pages</summary>
      <description>The Debug Dump page has the thread dump. Fewer links on the page would make things a little clearer for new users.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.zk.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.tablesDetailed.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-9-14 01:00:00" id="6780" opendate="2012-9-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>On the master status page the Number of Requests per second is incorrect for RegionServer&amp;#39;s</summary>
      <description>The number of requests per second is getting divided when it shouldn't be.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ServerLoad.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-9-15 01:00:00" id="6795" opendate="2012-9-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>mvn compile fails on a fresh checkout with empty ~/.m2/repo</summary>
      <description>I have noticed that mvn compile fails if your ~/m2/repository/ does not contain hbase test jars, however mvn test-compile, mvn install, etc works as expected. The patch for HBASE-6706 introduced test-jar dependency from hbase-server and hbase-hadoop1-compat to hbase-hadoop-compat test jar in the test scope. But stupid maven still tries to resolve the test jar when you do maven compile (notice that we are not even in the test scope).mvn test-compile, etc works b/c the test-jar for hbase-hadoop-compat is build before hbase-hadoop1-compat.One way to solve this is to push SNAPSHOT test-jars for hbase-hadoop-compat to the snapshot repository, so next time, they are referenced from there.Other alternative is to move classes under hbase-hadoop{|1|2}-compat/src/test to src/main, and remove the test-jar intra-module dependency. Still, it seems we might need intra-module test-jar dependency in the future. Any other suggestions are welcome.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-9-17 01:00:00" id="6803" opendate="2012-9-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>script hbase should add JAVA_LIBRARY_PATH to LD_LIBRARY_PATH</summary>
      <description>Snappy SO fails to load properly if LD_LIBRARY_PATH does not include the path where snappy SO is.</description>
      <version>None</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-1-18 01:00:00" id="6816" opendate="2012-9-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[WINDOWS] line endings on checkout for .sh files</summary>
      <description>On code checkout from svn or git, we need to ensure that the line endings for .sh files are LF, so that they work with cygwin. This is important for getting src/saveVersion.sh to work.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.resources.images.hbase.logo.svg</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-6-12 01:00:00" id="682" opendate="2008-6-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Regularize toString</summary>
      <description>Make all of our toStrings work the same. While at it, make them ruby Hash style so they play well in the (jruby) shell</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.TestToString.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.BaseScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Memcache.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-1-19 01:00:00" id="6825" opendate="2012-9-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[WINDOWS] Java NIO socket channels does not work with Windows ipv6</summary>
      <description>While running the test TestAdmin.testCheckHBaseAvailableClosesConnection(), I noticed that it takes very long, since it sleeps for 2sec * 500, because of zookeeper retries. The root cause of the problem is that ZK uses Java NIO to create ServerSorcket's from ServerSocketChannels. Under windows, the ipv4 and ipv6 is implemented independently, and Java seems that it cannot reuse the same socket channel for both ipv4 and ipv6 sockets. We are getting "java.net.SocketException: Address family not supported by protocolfamily" exceptions. When, ZK client resolves "localhost", it gets both v4 127.0.0.1 and v6 ::1 address, but the socket channel cannot bind to both v4 and v6. The problem is reported as:http://bugs.sun.com/view_bug.do?bug_id=6230761http://stackoverflow.com/questions/1357091/binding-an-ipv6-server-socket-on-windowsAlthough the JDK bug is reported as resolved, I have tested with jdk1.6.0_33 without any success. Although JDK7 seems to have fixed this problem. In ZK, we can replace the ClientCnxnSocket implementation from ClientCnxnSocketNIO to a non-NIO one, but I am not sure that would be the way to go.Disabling ipv6 resolution of "localhost" is one other approach. I'll test it to see whether it will be any good.</description>
      <version>0.94.3,0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-9-20 01:00:00" id="6849" opendate="2012-9-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make StochasticLoadBalancer the default</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.LoadBalancerFactory.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-9-25 01:00:00" id="6875" opendate="2012-9-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove commons-httpclient, -component, and up versions on other jars (remove unused repository)</summary>
      <description/>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-9-25 01:00:00" id="6876" opendate="2012-9-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up WARNs and log messages around startup</summary>
      <description>I was looking at our startup messages and some of the 'normal' messages are a bit frightening at face value.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileInlineToRootChunkConversion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ActiveMasterManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseRpcMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-9-26 01:00:00" id="6884" opendate="2012-9-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update documentation on unit tests</summary>
      <description>Points to address: we don't have anymore JUnit rules in the tests we should document how to run the test faster. some stuff is not used (run only a category) and should be removed from the doc imho.Below the proposal:&amp;#8211;15.6.2. Unit TestsHBase unit tests are subdivided into three categories: small, medium and large, with corresponding JUnit categories: SmallTests, MediumTests, LargeTests. JUnit categories are denoted using java annotations and look like this in your unit test code....@Category(SmallTests.class)public class TestHRegionInfo { @Test public void testCreateHRegionInfoName() throws Exception { // ... }}The above example shows how to mark a test as belonging to the small category. HBase uses a patched maven surefire plugin and maven profiles to implement its unit test characterizations. 15.6.2.4. Running testsBelow we describe how to run the HBase junit categories.15.6.2.4.1. Default: small and medium category testsRunningmvn testwill execute all small tests in a single JVM (no fork) and then medium tests in a separate JVM for each test instance. Medium tests are NOT executed if there is an error in a small test. Large tests are NOT executed. There is one report for small tests, and one report for medium tests if they are executed.15.6.2.4.2. Running all testsRunningmvn test -P runAllTestswill execute small tests in a single JVM then medium and large tests in a separate JVM for each test. Medium and large tests are NOT executed if there is an error in a small test. Large tests are NOT executed if there is an error in a small or medium test. There is one report for small tests, and one report for medium and large tests if they are executed15.6.2.4.3. Running a single test or all tests in a packageTo run an individual test, e.g. MyTest, domvn test -P localTests -Dtest=MyTestYou can also pass multiple, individual tests as a comma-delimited list:mvn test -P localTests -Dtest=MyTest1,MyTest2,MyTest3You can also pass a package, which will run all tests under the package:mvn test -P localTests -Dtest=org.apache.hadoop.hbase.client.*The -P localTests will remove the JUnit category effect (without this specific profile, the categories are taken into account). Each junit tests is executed in a separate JVM (A fork per test class). There is no parallelization when localTests profile is set. You will see a new message at the end of the report: "&amp;#91;INFO&amp;#93; Tests are skipped". It's harmless.15.6.2.4.4. Running test faster&amp;#91;replace previous chapter&amp;#93;By default, mvn test -P runAllTests runs 5 tests in parallel. It can be increased for many developper machine. Consider that you can have 2 tests in parallel per core, and you need about 2Gb of memory per test. Hence, if you have a 8 cores and 24Gb box, you can have 16 tests in parallel.The setting is:mvn test -P runAllTests -Dsurefire.secondPartThreadCount=12To increase the speed, you can as well use a ramdisk. You will need 2Gb of memory to run all the test. You will also need to delete the files between two test run.The typical way to configure a ramdisk on Linux is:sudo mkdir /ram2Gsudo mount -t tmpfs -o size=2048M tmpfs /ram2GYou can then use it to run all HBase tests with the command:mvn test -P runAllTests -Dsurefire.secondPartThreadCount=8 -Dtest.build.data.basedirectory=/ram2G</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.developer.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-10-26 01:00:00" id="6889" opendate="2012-9-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Ignore source control files with apache-rat</summary>
      <description>Running 'mvn apache-rat:check' locally causes a failure because it finds the source control files, making it hard to check that you didn't include a file without a source header.</description>
      <version>None</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2008-6-16 01:00:00" id="691" opendate="2008-6-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>get* and getScanner are different in how they treat column parameter</summary>
      <description>From the list, cure at xg dot pl there are group of methods "getRow" and group "getScanner" - both get as param array of collumns but in "getRow" methods we have to put it without ":" at the end of column family name, and for "getScanner" the colon is necessary. i think that it will be good to make it identical.</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-10-2 01:00:00" id="6917" opendate="2012-10-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Trunk jdk7 build broke because we moved to zk 3.4.4</summary>
      <description>Chatted w/ Mahadev and he confirmed issues running 3.4.4 w/ jdk7. Will be fixed in zk3.4.5.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-10-4 01:00:00" id="6951" opendate="2012-10-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow the master info server to be started in a read only mode.</summary>
      <description>There are some cases that a user could want a web ui to be accessible but might not want the split and compact functionality to be usable.Allowing the web ui to start in a readOnly mode would be good.</description>
      <version>None</version>
      <fixedVersion>0.92.3,0.94.3,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestInfoServers.java</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-10-9 01:00:00" id="6962" opendate="2012-10-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade hadoop 1 dependency to hadoop 1.1</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-10-15 01:00:00" id="6994" opendate="2012-10-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>minor doc update about DEFAULT_ACCEPTABLE_FACTOR</summary>
      <description>Per trunk code, in LruBlockCache.java:static final float DEFAULT_ACCEPTABLE_FACTOR = 0.99f;but the site doc still :"number of region servers * heap size * hfile.block.cache.size * 0.85"seems the HBASE-6312 forgot to update this doc</description>
      <version>0.95.2</version>
      <fixedVersion>0.99.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2007-6-17 01:00:00" id="7" opendate="2007-12-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbase] Provide a HBase checker and repair tool similar to fsck</summary>
      <description>We need a tool to verify (and repair) HBase much like fsck</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.check.meta.rb</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-10-17 01:00:00" id="7000" opendate="2012-10-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix the "INT_VACUOUS_COMPARISON" WARNING in KeyValue class</summary>
      <description/>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-10-17 01:00:00" id="7005" opendate="2012-10-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade Thrift lib to 0.9.0</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.generated.TScan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.generated.TRowResult.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.generated.TRegionInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.generated.TIncrement.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.generated.TCell.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.generated.Mutation.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.generated.IOError.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.generated.IllegalArgument.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.generated.Hbase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.generated.ColumnDescriptor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.generated.BatchMutation.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.generated.AlreadyExists.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TTimeRange.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TScan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TResult.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TPut.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIOError.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIncrement.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TIllegalArgument.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.THBaseService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TGet.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TDeleteType.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TDelete.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumnValue.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumnIncrement.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.generated.TColumn.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.package.html</file>
      <file type="M">hbase-server.src.main.javadoc.org.apache.hadoop.hbase.thrift.package.html</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-10-20 01:00:00" id="7019" opendate="2012-10-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Can&amp;#39;t pass SplitAlgo in hbase shell</summary>
      <description>hbase(main):002:0&gt; create 't1', 'f1', {NUMREGIONS =&gt; 15, SPLITALGO =&gt; 'HexStringSplit'}ERROR: uninitialized constant Hbase::Admin::RegionSplitter</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.ruby.hbase.admin.test.rb</file>
      <file type="M">hbase-server.src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-10-22 01:00:00" id="7032" opendate="2012-10-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove old IncrementColumnValue code.</summary>
      <description>IncrementColumnValue under the covers now uses Increment. We should remove the old code.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestAtomicOperation.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-10-23 01:00:00" id="7036" opendate="2012-10-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Exclude org.apache.hadoop.hbase.coprocessor.example.generated package from findbugs check</summary>
      <description/>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.findbugs-exclude.xml</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2012-10-31 01:00:00" id="7077" opendate="2012-10-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Test for: CheckAndPut should properly read MVCC</summary>
      <description>checkAndPut should integrate with MVCC, similar to how HBASE-4583 fixed appends and increments.Also need a test, here's one we could use (originally proposed in HBASE-7051):The current value of some cell is 10.I issue two concurrent requests:A) a check and put where check value = 10, put value = 11B) a put where put value = 50The only result at the end of these operations that seems reasonable to me is the value of the cell being 50. If A occurred first (ACID wise), then our values go 10-&gt;11-&gt;50. If B occurred first, then our values go 10-&gt;50 (and the checkAndPut fails)</description>
      <version>None</version>
      <fixedVersion>0.94.3,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHBase7051.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-11-6 01:00:00" id="7104" opendate="2012-11-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase includes multiple versions of netty: 3.5.0; 3.2.4; 3.2.2</summary>
      <description>We've got 3 of them on trunk.&amp;#91;INFO&amp;#93; org.apache.hbase:hbase-server:jar:0.95-SNAPSHOT&amp;#91;INFO&amp;#93; +- io.netty:netty:jar:3.5.0.Final:compile&amp;#91;INFO&amp;#93; +- org.apache.zookeeper:zookeeper:jar:3.4.3:compile&amp;#91;INFO&amp;#93; | &amp;#45; org.jboss.netty:netty:jar:3.2.2.Final:compile&amp;#91;INFO&amp;#93; org.apache.hbase:hbase-hadoop2-compat:jar:0.95-SNAPSHOT&amp;#91;INFO&amp;#93; +- org.apache.hadoop:hadoop-client:jar:2.0.2-alpha:compile&amp;#91;INFO&amp;#93; | +- org.apache.hadoop:hadoop-mapreduce-client-app:jar:2.0.2-alpha:compile&amp;#91;INFO&amp;#93; | | &amp;#45; org.jboss.netty:netty:jar:3.2.4.Final:compileThe patch attached: fixes this for hadoop 1 profile bump the netty version to 3.5.9 does not fix it for hadoop 2. I don't know why, but I haven't investigate: as it's still alpha may be they will change the version on hadoop side anyway.Tests are ok.I haven't really investigated the differences between netty 3.2 and 3.5. A quick search seems to say it's ok, but don't hesitate to raise a warning...</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-11-6 01:00:00" id="7107" opendate="2012-11-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Snapshot References Utils (FileSystem Visitor)</summary>
      <description>Utils to traverse the table and snapshot directory.Used by Restore and Export and should be used by cleaner, and other that want to look inside the snapshot folder.It provides an abstraction to the "snapshot metadata" format, and allows to get information about files, logs and recovered.edits snapshotted.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-11-6 01:00:00" id="7109" opendate="2012-11-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>integration tests on cluster are not getting picked up from distribution</summary>
      <description>The method of finding test classes only works on local build (or its full copy), not if the distribution is used.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestCheckTestClasses.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestsDriver.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-12-26 01:00:00" id="711" opendate="2008-6-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Complain if clock skew across the cluster is badly out of sync</summary>
      <description>hbase-710 and hbase-609 are issues where the system has broken in presence of clock skew over the cluster. Would be a nice service if master could flag very bad clock skew. Regionservers could report their local time when they ping the master. It could do a compare.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.overview.html</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-11-7 01:00:00" id="7121" opendate="2012-11-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix TestHFileOutputFormat after moving RS to metrics2</summary>
      <description>When spinning up lots of threads in a single jvm it's possible that the metrics wrapper can touch variables that are not initialized.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-11-8 01:00:00" id="7130" opendate="2012-11-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>NULL qualifier is ignored</summary>
      <description>HBASE-6206 ignored NULL qualifier so the qualifier list could be empty. But the request converter skips empty qualifier list too.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestAggregateProtocol.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScan.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestGet.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.AggregateImplementation.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Get.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-11-12 01:00:00" id="7148" opendate="2012-11-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Some files in hbase-examples module miss license header</summary>
      <description>Trunk build 3530 got to building hbase-examples module but failed:[INFO] HBase - Examples .................................. FAILURE [3.222s][INFO] ------------------------------------------------------------------------[INFO] BUILD FAILURE[INFO] ------------------------------------------------------------------------[INFO] Total time: 29:21.569s[INFO] Finished at: Sun Nov 11 15:17:35 UTC 2012[INFO] Final Memory: 68M/642M[INFO] ------------------------------------------------------------------------[ERROR] Failed to execute goal org.apache.rat:apache-rat-plugin:0.8:check (default) on project hbase-examples: Too many unapproved licenses: 20 -&gt; [Help 1]Looks like license headers are missing in some of the files in hbase-examples module</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-11-15 01:00:00" id="7168" opendate="2012-11-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[dev] in the script called &amp;#39;hbase&amp;#39;, we don&amp;#39;t check for errors when generating the classpath with mvn</summary>
      <description>When it happens, it's difficult to guess. Let's fix this.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-12-19 01:00:00" id="7187" opendate="2012-11-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create empty hbase-client module</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.BackupMasterListTmpl.jamon</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-common.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-11-21 01:00:00" id="7200" opendate="2012-11-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>create integration test for balancing regions and killing region servers</summary>
      <description>See related JIRA</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.LoadTestTool.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.util.ChaosMonkey.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestDataIngestWithChaosMonkey.java</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2012-11-27 01:00:00" id="7223" opendate="2012-11-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[refguide] Addition to SchemaDesign - RowKey design about understanding keyspace and region splits</summary>
      <description>Adding an entry in the RowKey design section in the Schema Design chapter about understanding the keyspace and splits when pre-splitting tables.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-11-28 01:00:00" id="7225" opendate="2012-11-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>on trunk, integration tests are not packaged into distribution</summary>
      <description/>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.assembly.components.xml</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-11-28 01:00:00" id="7228" opendate="2012-11-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[refguide] Addition to SchemaDesign -added entry to "Rows as Columns"</summary>
      <description>There are two schema design approaches in the RefGuide currently, rows vs. versions and rows vs. columns. But as OpenTSDB demonstrates there is a third: rows as columns.Adding a reference to that "middle" approach.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-4-29 01:00:00" id="7239" opendate="2012-11-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Verify protobuf serialization is correctly chunking upon read to avoid direct memory OOMs</summary>
      <description>Result.readFields() used to read from the input stream in 8k chunks to avoid OOM issues with direct memory.(Reading variable sized chunks into direct memory prevent the JVM from reusing the allocated direct memory and direct memory is only collected during full GCs)This is just to verify protobufs parseFrom type methods do the right thing as well so that we do not reintroduce this problem.</description>
      <version>None</version>
      <fixedVersion>0.95.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.IPCUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.HBaseClient.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-12-30 01:00:00" id="7250" opendate="2012-11-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>create integration test for balancing regions and killing region servers - 2</summary>
      <description>The original test is too general; need another one that would be more targeted and would test master logic in particular (e.g. not kill master). I re-discovered HBASE-6060 using it on the first run</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.util.ChaosMonkey.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-12-3 01:00:00" id="7264" opendate="2012-12-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve Snappy installation documentation</summary>
      <description>Snappy installation process is lacking some details. I tried to give some.There is also some mistakes "it's" vs "its".</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.developer.xml</file>
      <file type="M">src.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-12-3 01:00:00" id="7265" opendate="2012-12-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make Maven skip module test properties consistent</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-it.pom.xml</file>
      <file type="M">hbase-hadoop2-compat.pom.xml</file>
      <file type="M">hbase-hadoop1-compat.pom.xml</file>
      <file type="M">hbase-hadoop-compat.pom.xml</file>
      <file type="M">hbase-examples.pom.xml</file>
      <file type="M">hbase-common.pom.xml</file>
      <file type="M">hbase-client.pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-12-7 01:00:00" id="7304" opendate="2012-12-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>assembly:assembly doesn&amp;#39;t include the correct hbase-hadoop compat jars for hadoop 2</summary>
      <description>When executing mvn clean package assembly:assembly -Dhadoop.profile=2.0hbase-hadoop1-compat is placed in the tar.gz erroneously.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.assembly.hadoop-two-compat.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-12-10 01:00:00" id="7311" opendate="2012-12-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add snapshot information to hbase master webui</summary>
      <description>Similarly to how tables are listed in the web interface, snapshots should be listed as well.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-12-10 01:00:00" id="7314" opendate="2012-12-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Can&amp;#39;t start REST/Thrift server if HBASE_JMX_OPTS not set</summary>
      <description>By default JMX is enabled for REST server and Thrift server. However, if HBASE_JMX_OPTS is not set, and JMX remote access rule is not set, we can't bring up the REST/Thrift server due to JMX remote access rule errors.We need to enhance the hbase script not to enable JMX for REST/Thrift server is HBASE_JMX_OPTS is not set.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase-config.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-7-9 01:00:00" id="732" opendate="2008-7-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>shell formatting error with the describe command</summary>
      <description>The formatting of the output of the shell command "describe" repeats some of the text. The following is an example of the problem:hbase(main):001:0&gt; describe 'table2'NAME =&gt; 'table2', FAMILIES =&gt; [{NAME =&gt; 'fam3', VERSIONS =&gt; 3, COMPRESSION =&gt; 'NONE', IN_MEMORY =&gt; false, BLOCKCACHE =&gt; false, LENGTH =&gt; 2147483647, TTL =&gt; FOREVER, BLOOMFILTER =&gt; NONE}, {NAME =&gt; 'fam2', VERSIONS =&gt; 6, COMPRESSION =&gt; 'NONE', IN_MEMORY =&gt; false, BLOCKCACHE =&gt; false, LENGTH =&gt; 2147483647, TTL =&gt; FOREVER, BLOOMFILTOMPRESSION =&gt; 'NONE', IN_MEMORY =&gt; false, BLOCKCACHE =&gt; false, LENGTH =&gt; 2147483647, TTL =&gt; FOREVER, BLOOMFILTER =&gt; NONE}, {NAME =&gt; 'fam1', VERSIONS =&gt; 5, COMPRESSION =&gt; 'NONE', IN_MEMORY =&gt; false, BLOCKCACHE =&gt; false, LENGTH =&gt; 2147483647, TTL =&gt; FOREVER, BLOOMFILTER =&gt; NONE}]ER =&gt; NONE}, {NAME =&gt; 'fam1', VERSIONS =&gt; 5, COMPRESSION =&gt; 'NONE', IN_MEMORY =&gt; false, BLOCKCACHE =&gt; false, LENGTH =&gt; 2147483647, TTL =&gt; FOREVER, BLOOMFILTER =&gt; NONE}]ENGTH =&gt; 2147483647, TTL =&gt; FOREVER, BLOOMFILTER =&gt; NONE}] 1 row(s) in 0.2520 seconds</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.Formatter.rb</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  
  
  
  
  
  
  <bug fixdate="2012-12-21 01:00:00" id="7417" opendate="2012-12-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestReplication is flaky</summary>
      <description>See discussion at the end of HBASE-5778.TestReplication failed in all recent 0.94 jenkins builds.</description>
      <version>None</version>
      <fixedVersion>0.94.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-12-21 01:00:00" id="7425" opendate="2012-12-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move to the newest BootStrap css and js for the webui.</summary>
      <description/>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.js.tab.js</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.js.jquery.min.js</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.js.bootstrap.min.js</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.js.bootstrap.js</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.css.hbase.css</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.css.bootstrap.min.css</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.css.bootstrap.css</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.css.bootstrap-responsive.min.css</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.css.bootstrap-responsive.css</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.zk.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.tablesDetailed.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RegionListTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.RegionServerListTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-12-21 01:00:00" id="7426" opendate="2012-12-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix PreCheckin script to error out when there are Javadoc errors.</summary>
      <description>Currently the script stays green for up to ~130 javadoc errors. Since these errors have been fixed the number should be lowered.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.token.TokenProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationHLogReaderManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.ChecksumUtil.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.FirstKeyValueMatchingQualifiersFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.coprocessor.Batch.java</file>
      <file type="M">dev-support.test-patch.properties</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-12-27 01:00:00" id="7443" opendate="2012-12-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>More findbugs fixes</summary>
      <description>It adds the dependency to findbugs for the annotations. It's a compile only dependency. License is LGPL. suppresses a few not critical warnings fixes a few othersLocally, I'm now at 144.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.Canary.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.StorageClusterStatusModel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.LogMonitoring.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HFileOutputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseClient.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.DependentColumnFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.CompareFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.ByteArrayComparable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.catalog.MetaReader.java</file>
      <file type="M">dev-support.findbugs-exclude.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.HBasePolicyProvider.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-1-30 01:00:00" id="7464" opendate="2012-12-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[REST] Sending HTML for errors is unhelpful</summary>
      <description>The large HTML 404 page returned by Stargate is not helpful. The REST interface is not intended for humans to read, esp. when the client is known to be a program because it's asking for binary, but really any time. Nice big readable error pages use bandwidth and clutter network traces to no purpose.Please allow the 404 and other error pages to be configured away, or just stop sending them (my preference). If some body must be sent, a simple text/plain "Not found" would be fine, I think.</description>
      <version>0.94.5,0.95.2</version>
      <fixedVersion>0.94.4,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.StorageClusterVersionResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.StorageClusterStatusResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.SchemaResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerInstanceResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RowResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RootResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RegionsResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.MultiRowResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ExistsResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.Constants.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-12-31 01:00:00" id="7469" opendate="2012-12-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[REST] Share a HBaseAdmin instance</summary>
      <description>Simplification.</description>
      <version>0.94.5,0.95.2</version>
      <fixedVersion>0.94.4,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.TableResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.StorageClusterVersionResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.StorageClusterStatusResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.SchemaResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RootResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RESTServlet.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-1-31 01:00:00" id="7472" opendate="2012-12-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[REST] Support MIME type application/protobuf</summary>
      <description>Protobuf representation is currently selected with 'application/x-protobuf'. We should also consider supporting 'application/protobuf' because it appears in an IETF draft. See http://tools.ietf.org/id/draft-rfernando-protocol-buffers-00.txt</description>
      <version>0.94.5,0.95.2</version>
      <fixedVersion>0.94.4,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestVersionResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestTableResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestStatusResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestSchemaResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestScannersWithFilters.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestScannerResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestRowResource.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.TestMultiRowResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.VersionResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.StorageClusterStatusResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.SchemaResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerInstanceResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RowResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RootResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RegionsResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.provider.producer.ProtobufMessageBodyProducer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.provider.consumer.ProtobufMessageBodyConsumer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.MultiRowResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ExistsResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.Constants.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-1-4 01:00:00" id="7498" opendate="2013-1-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make REST server thread pool size configurable</summary>
      <description>Currently, the REST server thread pool size is the default: 250. It can't be configured. We need to make it configurable so that it can be adjusted per traffic/load so that REST server is less likely to OOM and die.</description>
      <version>0.94.5,0.95.2</version>
      <fixedVersion>0.94.5,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RESTServer.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-1-7 01:00:00" id="7508" opendate="2013-1-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix simple findbugs</summary>
      <description/>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.EmptyWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ServerName.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.Permission.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.KeyPrefixRegionSplitPolicy.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.SplitRegionHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.HLogInputFormat.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HealthCheckChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.executor.EventHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.AggregateImplementation.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Scan.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.OperationWithAttributes.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.thrift.DemoClient.java</file>
      <file type="M">hbase-examples.src.main.java.org.apache.hadoop.hbase.coprocessor.example.ZooKeeperScanPolicyObserver.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.JVM.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">dev-support.test-patch.properties</file>
      <file type="M">dev-support.findbugs-exclude.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-1-8 01:00:00" id="7512" opendate="2013-1-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document the findbugs library annotation</summary>
      <description>See HBASE-7508</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.developer.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-1-10 01:00:00" id="7527" opendate="2013-1-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>integration tests STILL won&amp;#39;t run from tar.gz in trunk</summary>
      <description>The problem is that the class used to find test classes sits in common test jar, which is not included in the package.However, if we move the class to the common jar itself, we'll have a JUnit dependency.And if we cannot just move it to integration tests, because a test that verifies test categories makes use of it too.This is all very sad.I will see if there's any way to not have junit dependency (we already seem to deploy junit so it might not be such a big deal).</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.assembly.components.xml</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-1-14 01:00:00" id="7555" opendate="2013-1-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Kill the remaining processus from other builds in the precommit env</summary>
      <description>We have some process surviving hdfs builds.Let's kill them before starting our own build.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-1-15 01:00:00" id="7574" opendate="2013-1-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Migrate to JUnit 4.11</summary>
      <description/>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-1-16 01:00:00" id="7586" opendate="2013-1-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix two findbugs warnings to get our count down to the tolerated number again</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.filter.FirstKeyOnlyFilter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-12-22 01:00:00" id="759" opendate="2008-7-22 00:00:00" resolution="Won&amp;#39;t Fix">
    <buginformation>
      <summary>TestMetaUtils failing on hudson</summary>
      <description/>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.util.DisabledTestMetaUtils.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-8-21 01:00:00" id="7639" opendate="2013-1-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable online schema update by default</summary>
      <description>After we get HBASE-7305 and HBASE-7546, things will become stable enough to enable online schema update to be enabled by default. &lt;property&gt; &lt;name&gt;hbase.online.schema.update.enable&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;description&gt; Set true to enable online schema changes. This is an experimental feature. There are known issues modifying table schemas at the same time a region split is happening so your table needs to be quiescent or else you have to be running with splits disabled. &lt;/description&gt; &lt;/property&gt;</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-1-22 01:00:00" id="7646" opendate="2013-1-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make forkedProcessTimeoutInSeconds configurable</summary>
      <description>Command line property "surefire.timeout" somehow doesn't work. It may be because forkedProcessTimeoutInSeconds is hard-coded to 900.</description>
      <version>None</version>
      <fixedVersion>0.94.5,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-1-24 01:00:00" id="7656" opendate="2013-1-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up line endings to be LF in the repo</summary>
      <description>After HBASE-6816, there are still 2 files in the repo with CRLF line endings. We should change recommit them with LF line endings.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.zookeeper.TestRecoverableZooKeeper.java</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.js.jquery.min.js</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-1-25 01:00:00" id="7674" opendate="2013-1-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>add shell documentation for HBASE-7571</summary>
      <description>When the patch was split from HBASE-7236, shell documentation (e.g. how to use the new thing and examples) fell thru the cracks. Need to add it...</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.ruby.shell.commands.create.rb</file>
      <file type="M">hbase-server.src.main.ruby.shell.commands.alter.rb</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-10-26 01:00:00" id="7679" opendate="2013-1-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>implement store file management for stripe compactions</summary>
      <description>Needs loving. Moving out for now. Can pull in on point release after goes into trunk.</description>
      <version>None</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDefaultCompactSelection.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-2-4 01:00:00" id="7757" opendate="2013-2-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add web UI to REST server and Thrift server</summary>
      <description>Add Hadoop HttpServer (web UI) to REST server and Thrift server. The Hadoop HttpServer supports metrics/jmx/conf/logLevel/stacks, which is useful to monitor REST/Thrift server.For REST server, use a separate listener/context to avoid path mapping conflicts.</description>
      <version>None</version>
      <fixedVersion>0.94.5,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RESTServer.java</file>
      <file type="M">hbase-server.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-2-4 01:00:00" id="7758" opendate="2013-2-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update book to include documentation of CellCounter utility</summary>
      <description>The book documents RowCounter but not cell counter. Describe them together.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-2-6 01:00:00" id="7779" opendate="2013-2-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[snapshot 130201 merge] Fix TestMultiParallel</summary>
      <description>TestMultiParallel has three tests that always fail on the merged branch: #testFlushCommitsWithAbort, #testActiveThreadsCount and #testflushCommitsNoAbort. There were some changes introduced in HBASE-7299 which happend on trunk before the merge and are likely related. (that patch addresses problems on the same tests).</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestSnapshotMetadata.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ZKProcedureUtil.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-2-7 01:00:00" id="7788" opendate="2013-2-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[snapshot 130201 merge] Fix flakey TestRestore*SnapshotFromClient#testCloneSnapshot</summary>
      <description>In the current implementation the clone call waits until after the newly created table isTableEnabled. However there is another state (apparently orthogonal) that a newly created table is assumed to be  isTableAvailable (all regions assigned). The logic for checking after table creation and after clone creation are slightly different  creation does the equivalent of isTableAvailable but clone does not check this availability condition.This causes flaky failures in tests that quickly try to use/delete a newly cloned table.TestRestoreSnapshotFromClient#testCloneSnapshotTestRestoreFlushSnapshotFromCleitn#testCloneSnapshotI believe there also are race conditions because of the postTableCreateHandler corpco and postTableDeleteHandler coproc hooks.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-7-26 01:00:00" id="779" opendate="2008-7-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Test changing hbase.hregion.memcache.block.multiplier to 2</summary>
      <description>Currently its set to 1. Under load, seeing fill-cache/pause-while-cache-is-flushed cycle. Changing multiplier to 2 could make hbase take on load faster (Was set to 1 because compactions used to overwhelm the system but now HBASE-745 added a not-so-dumb compaction algorithim, we might be able to run w/ a value of 2).</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2008-7-28 01:00:00" id="780" opendate="2008-7-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Can&amp;#39;t scan &amp;#39;.META.&amp;#39; from new shell</summary>
      <description>Need scan of .META. debugging.</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.UnmodifyableHTableDescriptor.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-2-9 01:00:00" id="7800" opendate="2013-2-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>RegionMovedException can cause servers to play ping pong with client</summary>
      <description>I need to double check the code, but from some logs it appears that if region moves from A to B, then from B to A, and then closed on A for reason that is not move (not clear what), and is assigned to C, A and B will play ping-pong with the client for a while until some serendipitous occasion refreshes meta.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-3-9 01:00:00" id="7803" opendate="2013-2-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[REST] Support caching on scan</summary>
      <description>I have a YCSB client using the REST API. My testing shows the performance for scan with REST API is much worse than that with the java client API. We need to look into it and find out the root cause, either the test issue, or our REST API issue.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.model.TestScannerModel.java</file>
      <file type="M">hbase-server.src.main.resources.org.apache.hadoop.hbase.rest.protobuf.ScannerMessage.proto</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerResultGenerator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ScannerResource.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.protobuf.generated.ScannerMessage.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.model.ScannerModel.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-12-14 01:00:00" id="7846" opendate="2013-2-14 00:00:00" resolution="Won&amp;#39;t Fix">
    <buginformation>
      <summary>Add support for merging implicit regions in Merge tool</summary>
      <description>Currently org.apache.hadoop.hbase.util.Merge needs 2 region names to be explicitly specified to perform a merge. This can be cumbersome.One idea for improvement is to have Merge to figure out all the adjacent regions and perform the merges. For example:regions before merge: row-10, row-20, row-30, row-40, row-50regions after merge: row-10, row-30, row-50In the above example, region names of "row-10" and "row-20" are merged to become a new bigger region of "row-10".</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.stop-hbase.sh</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  <bug fixdate="2013-2-20 01:00:00" id="7883" opendate="2013-2-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update memstore size when removing the entries in append operation</summary>
      <description>In case of Appends/Increments with VERSION of CF set to 1, the memstore size is not updated when the previous entries are removed from the memstore.</description>
      <version>0.95.2</version>
      <fixedVersion>0.94.6,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStore.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-2-25 01:00:00" id="7926" opendate="2013-2-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>SmallTests pollute the META descriptor</summary>
      <description>Running tests on my jenkins I've noticed that the META_TABLEDESC at some point gets changed, and gets SNAPPY encoding and other settings.A couple of SmallTest take the META_TABLEDESC as base and change it directly, to verify the serialization, without creating a copy.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestHTableDescriptor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestHColumnDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-3-9 01:00:00" id="8058" opendate="2013-3-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade site plugin; fix assembly doc up on jenkins builds</summary>
      <description>Up on jenkins, we currently make assemblies but there no doc in them. The site goal runs last. You can't run it anywhere else else build fails. Upgrading the site plugin helps. Upgrading site plugin I notice that there are a bunch of extra reports generated that would be no harm showing on the web site; e.g. dependencies transitively included, what dependencies we have, etc. This issue is about upgrading site plugin to fix jenkins assemblies and to expose reports we are generating anyways (at least one report is new w/ the info-report upgrade from earlier today).</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-3-18 01:00:00" id="8138" opendate="2013-3-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Using [packed=true] for repeated field of primitive numeric types (types which use the varint, 32-bit, or 64-bit wire types)</summary>
      <description>It's recommended to do the following for numeric primitive typesFor historical reasons, repeated fields of basic numeric types aren't encoded as efficiently as they could be. New code should use the special option &amp;#91;packed=true&amp;#93; to get a more efficient encodingSee details at https://developers.google.com/protocol-buffers/docs/proto</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-protocol.src.main.protobuf.Filter.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.FilterProtos.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-9-18 01:00:00" id="8139" opendate="2013-3-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow job names to be overridden</summary>
      <description>As a general feature, we should allow mr job names to be overridden by the user. See also HBASE-8077.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.WALPlayer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.RowCounter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.ImportTsv.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.Import.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.Export.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.CopyTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.CellCounter.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2008-8-12 01:00:00" id="821" opendate="2008-8-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>UnknownScanner happens too often.</summary>
      <description>Jean-Daniel up on the list in an exchange with Dru Jensen solved an issue by recommending longer lease for client scanners in a MR job. Lets make change to conf. This lessens the impact of Andrew Purtell added retry on USE in HBASE-816 in TableMap but will help in MR tasks that don't subclass TableMap.</description>
      <version>None</version>
      <fixedVersion>0.2.1,0.18.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-4-1 01:00:00" id="8236" opendate="2013-4-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Set finalName property in hbase-assembly else basename is hbase-assembly rather than hbase.</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-assembly.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-4-2 01:00:00" id="8241" opendate="2013-4-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix the bad dependency on netty from HDFS</summary>
      <description>Even if it's fixed on trunk &amp; branch-2, the current version of hdfs still has a previous version of netty, with a different group id. Let's fix this.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.1,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-4-4 01:00:00" id="8267" opendate="2013-4-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add some resources checker for tests</summary>
      <description>This may help to understand why precommit is often ok while trunk is always bad.</description>
      <version>0.95.2</version>
      <fixedVersion>0.95.1,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.ResourceCheckerJUnitListener.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.HBaseCommonTestingUtility.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.JVM.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-6-12 01:00:00" id="8532" opendate="2013-5-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[Webui] Bootstrap based webui compatibility for IE and also fix some page format issues.</summary>
      <description>HBASE-7425 brings bootstrap based webui to hbase. While trying on trunk version, Firefox works well, but IE 8/9 layout and style look strange due to compatibility issue. Add "&lt;!DOCTYPE html ...&gt;" at the beginning of all jamon html/jsp templates to fix it.Seems HBase-2110 had a work to comment out the DOCTYPE for all .jsp to make the browser run the pages in Quirks mode (http://en.wikipedia.org/wiki/Quirks_mode) due to jetty issue at that time?To support the compatibility of webui across browsers (IE/Firefox/Chrome, etc.), there are some guidelines for choosing rendering the page under standard mode or quirk mode:http://en.wikipedia.org/wiki/Quirks_modehttp://hsivonen.iki.fi/doctype/According to document, "&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd"&gt;" has the most extensive compatibility even for HTML 5. According to my test, add this could make webui works in IE (standard mode), while Firefox could not work well with styles. Looks like if in Firefox, we still need the quirk mode (no DOCTYPE declaration). So just adding conditional DOCTYPE declaration for IE,&lt;!--&amp;#91;if IE&amp;#93;&gt;&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd"&gt;&lt;!&amp;#91;endif&amp;#93;--&gt;this could make webui works for both IE and Firefox, also for Chrome and other browsers.</description>
      <version>0.98.0,0.95.0,0.95.2</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.thrift.thrift.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.rest.rest.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.zk.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.tablesDetailed.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.snapshot.jsp</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2013-5-29 01:00:00" id="8643" opendate="2013-5-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Do not log full classnames in logs, just the last two levels</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.log4j.properties</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-7-5 01:00:00" id="8882" opendate="2013-7-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create an Integration Test to Test MTTR</summary>
      <description/>
      <version>0.98.0,0.95.2</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.AbstractHBaseTool.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.util.ChaosMonkey.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestRebalanceAndKillServersTargeted.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.mttr.IntegrationTestMTTR.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-6-13 01:00:00" id="8943" opendate="2013-7-13 00:00:00" resolution="Won&amp;#39;t Fix">
    <buginformation>
      <summary>Split Thrift2&amp;#39;s ThriftServer into separate classes for easier testing and modularization</summary>
      <description>Currently the ThriftServer class in Thrift 2 sets up and starts the actual server. Better follow a similar pattern to Thrift 1 where there is some factory setting up the server, and a separate start section. That way it is easier to test if the setup of the server is picking up everything it needs.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DispatchMergingRegionHandler.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-7-19 01:00:00" id="8994" opendate="2013-7-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Adding log to chaos monkey actions to show what&amp;#39;re performed</summary>
      <description>I realized that not much is logged in the new chaos monkey actions introduced in HBASE-8845.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.util.ChaosMonkey.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2008-11-1 01:00:00" id="910" opendate="2008-10-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scanner misses columns / rows when the scanner is obtained durring a memcache flush</summary>
      <description>I first noticed that some columns for a row were missing if they are coming from a scanner that was obtained while a memecache flush on the region was in progress. I tried to write a simple unit test to reproduce, however the problem I get in the unit test is that some rows are being missed.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStoreScanner.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2013-8-9 01:00:00" id="9181" opendate="2013-8-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix javadoc warnings introduce by namespaces</summary>
      <description>javadoc is failing in hadoopqa because we have lingering javadoc warnings.</description>
      <version>0.98.0,0.95.2</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableNamespaceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-8-10 01:00:00" id="9185" opendate="2013-8-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>mvn site target fails when building with Maven 3.1</summary>
      <description>mvn site fails when building with mvn 3.1 due to various class changes inside maven. They promise that switching to new versions of some mvn modules will result in builds that work in both 3.0.x and 3.1:https://cwiki.apache.org/confluence/display/MAVEN/AetherClassNotFound</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2008-10-11 01:00:00" id="920" opendate="2008-10-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make region balancing sloppier</summary>
      <description>The region load balancer is exacting. Here's the logic: if (avgLoad &gt; 2.0 &amp;&amp; thisServersLoad.getNumberOfRegions() &gt; avgLoad) { if (LOG.isDebugEnabled()) { LOG.debug("Server " + serverName + " is overloaded. Server load: " + thisServersLoad.getNumberOfRegions() + " avg: " + avgLoad); }...On a cluster of thousands of regions, especially around startup or if there's been a crash, the above makes for a bunch of churn as load balancer closes and opens nodes to achieve an exact balance (all nodes must be &lt;= to average).I'd suggest that nodes should be left alone if they are within some percentage of the average &amp;#8211; say 10% (should be configurable).</description>
      <version>None</version>
      <fixedVersion>0.18.1,0.19.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStoreFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.master.RegionManager.java</file>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-8-13 01:00:00" id="9210" opendate="2013-8-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>"hbase shell -d" doesn&amp;#39;t print out exception stack trace</summary>
      <description>when starting shell with "-d" specified, the following line doesn't print anything because debug isn't set when shell is constructed."Backtrace: #{e.backtrace.join("\n ")}" if debugIn addition, the existing code prints the outer most exception while we normally need the root cause exception.</description>
      <version>0.98.0,0.95.2</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.ruby.shell.commands.rb</file>
      <file type="M">bin.region.status.rb</file>
      <file type="M">bin.region.mover.rb</file>
      <file type="M">bin.hirb.rb</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-8-14 01:00:00" id="9224" opendate="2013-8-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Print out name of the method we do not support rather than throw NPE</summary>
      <description>If a client is trying to invoke a method we do not support, we just NPE, rather than return an unsupported exception w/ name of the method we do not support. Makes it hard debugging what client is doing wrong.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2013-9-18 01:00:00" id="9259" opendate="2013-8-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update hadoop versions grid in refguide adding hadoop-2.1.x and a note on hadoop-2.0.x versions</summary>
      <description>Need to update our hadoop versions grid. Add notes on hadoop-2.1 and hadoop-2.0 (we do the former, not the latter)</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.preface.xml</file>
      <file type="M">src.main.docbkx.getting.started.xml</file>
      <file type="M">src.main.docbkx.configuration.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-8-20 01:00:00" id="9276" opendate="2013-8-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>List tables API should filter with isSystemTable</summary>
      <description/>
      <version>0.98.0,0.95.2,0.96.0</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-8-20 01:00:00" id="9277" opendate="2013-8-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>REST should use listTableNames to list tables</summary>
      <description/>
      <version>0.98.0,0.95.2,0.94.12,0.96.0</version>
      <fixedVersion>0.98.0,0.94.12,0.96.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.RootResource.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-8-20 01:00:00" id="9279" opendate="2013-8-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thrift should use listTableNames to list tables</summary>
      <description/>
      <version>0.98.0,0.95.2,0.94.11,0.96.0</version>
      <fixedVersion>0.98.0,0.94.12,0.96.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-3-21 01:00:00" id="9294" opendate="2013-8-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>NPE in /rs-status during RS shutdown</summary>
      <description>While hitting reload to see when a kill-initiated RS shutdown would make the Web UI go away, I got a stack trace from an NPE</description>
      <version>0.95.2</version>
      <fixedVersion>0.96.2,0.98.1,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSStatusServlet.java</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2013-8-22 01:00:00" id="9309" opendate="2013-8-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>The links in the backup masters template are bad</summary>
      <description>If you try to go to a backup master web UI's, it doesn't work because the link is is missing "http://".</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.BackupMasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2013-8-26 01:00:00" id="9337" opendate="2013-8-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>shell &amp;#39;user_permission&amp;#39; throws no method &amp;#39;toStringBinary&amp;#39; for (o.a.h.h.TableName)</summary>
      <description>the user_permission shell code is trying to convert a TableName object to a string, and it throwshbase(main):010:0&gt; user_permission User Table,Family,Qualifier:Permission ERROR: no method 'toStringBinary' for arguments (org.apache.hadoop.hbase.TableName) on Java::OrgApacheHadoopHbaseUtil::Bytes available overloads: (java.nio.ByteBuffer) (byte[])</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.ruby.hbase.security.rb</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-8-26 01:00:00" id="9340" opendate="2013-8-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>revoke &amp;#39;user&amp;#39; throws ArrayIndexOutOfBoundsException</summary>
      <description>Trying to revoke a global rights throwshbase(main):004:0&gt; revoke 'test'Java::JavaLang::ArrayIndexOutOfBoundsException: 3The problem is that jruby is not able to do the bind with revoke(..., Permission.Action... actions)</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.ruby.hbase.security.rb</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-8-26 01:00:00" id="9342" opendate="2013-8-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>WebUI fixes after bootstrap 3.0 update</summary>
      <description/>
      <version>0.98.0,0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.rest.rest.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.zk.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.tablesDetailed.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.snapshot.jsp</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-10-19 01:00:00" id="937" opendate="2008-10-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thrift getRow does not support specifying columns</summary>
      <description>Thrift interface has a getRow function but it does not support asking for specific columns.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.thrift.TestThriftServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.Hbase.thrift</file>
      <file type="M">src.java.org.apache.hadoop.hbase.thrift.generated.Hbase.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-8-29 01:00:00" id="9379" opendate="2013-8-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Doc that localfs is not durable</summary>
      <description>Lets at least doc. that localfs is not durable. qwertymaniac put up a patch on the parent issue.</description>
      <version>None</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.getting.started.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-8-29 01:00:00" id="9382" opendate="2013-8-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>replicateWALEntry doesn&amp;#39;t use the replication handlers</summary>
      <description>By default we assign 3 handlers for replication, but as far as I can tell the replication traffic uses the normal handlers in 0.96</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.QosFunction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2013-9-30 01:00:00" id="9400" opendate="2013-8-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[UI] Catalog tables section isn&amp;#39;t aligned</summary>
      <description>I attached a picture of what I got. You can see it doesn't look right.One more thing is that the page doesn't auto-refresh when you switch tabs. For example, click Catalog tables, create a new table, click User tables, you don't see the new table. You need to refresh the page to see it.</description>
      <version>0.95.2,0.96.0</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.static.css.hbase.css</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2008-10-21 01:00:00" id="945" opendate="2008-10-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Be consistent in use of qualified/unqualified mapfile paths</summary>
      <description>A store that was made up in hdfs can't be examined using local filesystem because we &amp;#8211; or hadoop &amp;#8211; is inconsistent.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-9-5 01:00:00" id="9450" opendate="2013-9-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestDistributedLogSplitting fails</summary>
      <description>Would you mind taking a look at a recent set of failures please jeffreyz? It seems to be failing more recently of late:https://issues.apache.org/jira/browse/HBASE-9438?page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel&amp;focusedCommentId=13759275#comment-13759275https://builds.apache.org/job/PreCommit-HBASE-Build/7060//testReport/https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/703/Thank you.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2008-10-21 01:00:00" id="946" opendate="2008-10-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Row with 55k deletes timesout scanner lease</summary>
      <description>Made a blocker because it was found by Jon Gray (smile)So, Jon Gray has a row with 55k deletes all in the same row. When he tries to scan, his scanner timesout when it gets to this row. The root cause is the mechanism we use to make sure a delete in a new store file overshadows an entry at same address in an old file. We accumulate a List of all deletes encountered. Before adding a delete to the List, we check if already a deleted. This check is whats killing us. One issue is that its doing super inefficient check of whether table is root but even fixing this inefficency &amp;#8211; and then removing the check for root since its redundant we're still too slow.Chatting with Jim K, he suggested that ArrayList check is linear. Changing the aggregation of deletes to instead use HashSet makes all run an order of magnitude faster.Also part of this issue, need to figure why on compaction we are not letting go of these deletes.Filing this issue against 0.18.1 so it gets into the RC2 (after chatting w/ J-D and JK &amp;#8211; J-D is seeing the issue also).</description>
      <version>None</version>
      <fixedVersion>0.18.1,0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestHStoreFile.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStoreScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.BeforeThisStoreKey.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HStoreKey.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-9-7 01:00:00" id="9461" opendate="2013-9-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Some doc and cleanup in RPCServer</summary>
      <description>RPC is a dog to follow. I want to do buffer pooling for reading requests but its tough drawing the diagram of who is doing what when. HBASE-8884 seems to have made it more involved still. This issue is about doing a bit of untangling.</description>
      <version>None</version>
      <fixedVersion>0.98.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.TestIPC.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServerInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcScheduler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RequestContext.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.FifoRpcScheduler.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-9-10 01:00:00" id="9487" opendate="2013-9-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>create_namespace with property value throws error</summary>
      <description>Creating a namespace with properties fails from shell: hbase(main):002:0&gt; create_namespace 'ns1',{'PROERTY_NAME'=&gt;'PROPERTY_VALUE'}ERROR: undefined method `addProperty' for #&lt;Java::OrgApacheHadoopHbase::NamespaceDescriptor::Builder:0x71b98cbb&gt;Here is some help for this command:Create namespace; pass namespace name,and optionally a dictionary of namespace configuration.Examples:hbase&gt; create_namespace 'ns1'hbase&gt; create_namespace 'ns1', {'PROERTY_NAME'=&gt;'PROPERTY_VALUE'}</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-12-10 01:00:00" id="9489" opendate="2013-9-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add cp hooks in online merge before and after setting PONR</summary>
      <description>As we need to merge index region along with user region we need the hooks before and after setting PONR in region merge transtion.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.99.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionMergeTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionMergeTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionServerObserver.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-10-22 01:00:00" id="949" opendate="2008-10-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add an HBase Manual</summary>
      <description>HBase needs a Manual. Manual can be checked in under docs and evolve as hbase does (Hopefully we get to a state where new feature can't be closed unless manual has been updated to include mention and howto). Let this issue be about adding under docs an outline with some basic getting started info. Thereafter, we can open individual issues to add "chapters" or topics.Made it a blocker on 0.20.0.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docs.src.documentation.content.xdocs.site.xml</file>
      <file type="M">docs.skin.images.rc-t-r-5-1header-2tab-unselected-3tab-unselected.png</file>
      <file type="M">docs.skin.images.rc-t-r-5-1header-2tab-selected-3tab-selected.png</file>
      <file type="M">docs.skin.images.rc-t-r-5-1header-2searchbox-3searchbox.png</file>
      <file type="M">docs.skin.images.rc-t-r-15-1body-2menu-3menu.png</file>
      <file type="M">docs.skin.images.rc-t-l-5-1header-2tab-unselected-3tab-unselected.png</file>
      <file type="M">docs.skin.images.rc-t-l-5-1header-2tab-selected-3tab-selected.png</file>
      <file type="M">docs.skin.images.rc-t-l-5-1header-2searchbox-3searchbox.png</file>
      <file type="M">docs.skin.images.rc-b-r-5-1header-2tab-selected-3tab-selected.png</file>
      <file type="M">docs.skin.images.rc-b-r-15-1body-2menu-3menu.png</file>
      <file type="M">docs.skin.images.rc-b-l-15-1body-2menu-3menu.png</file>
      <file type="M">docs.linkmap.pdf</file>
      <file type="M">docs.linkmap.html</file>
      <file type="M">docs.index.html</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-9-12 01:00:00" id="9517" opendate="2013-9-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Include only InterfaceAudiencePublic elements in generated Javadoc</summary>
      <description>We should generate two sets of javadoc a la HADOOP-6658 &amp;#8211; one for api users that excludes all InterfaceAudiencePrivate apis, and one for hbase core developers. Eventually when we tighten up the other modules we might add another for coproc developers, and other custom 3rd party pluggable elements.</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.site.site.xml</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  <bug fixdate="2013-10-18 01:00:00" id="9570" opendate="2013-9-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>With AccessDeniedException, HBase shell would be better to just display the error message to be user friendly</summary>
      <description>When access unauthorized resource like table, AccessDeniedException will be thrown. In HBase shell, the error message with stack trace will be displayed as follows. It would be better to just display the error message avoiding the stack trace to be user friendly. ERROR: org.apache.hadoop.hbase.security.AccessDeniedException: Insufficient permissions for user 'u1' for scanner open on table t1 at org.apache.hadoop.hbase.security.access.AccessController.preScannerOpen(AccessController.java:1116) at org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preScannerOpen(RegionCoprocessorHost.java:1293) at org.apache.hadoop.hbase.regionserver.HRegionServer.scan(HRegionServer.java:3026) at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:26971) at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2083) at org.apache.hadoop.hbase.ipc.RpcServer$CallRunner.run(RpcServer.java:1820) at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.consumerLoop(SimpleRpcScheduler.java:165) at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.access$000(SimpleRpcScheduler.java:41) at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler$1.run(SimpleRpcScheduler.java:113) at java.lang.Thread.run(Thread.java:662)</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.shell.commands.rb</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2013-5-19 01:00:00" id="9580" opendate="2013-9-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document the meaning of @InterfaceAudience in hbase ref guide</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.99.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.developer.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-9-25 01:00:00" id="9656" opendate="2013-9-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove decimal places from Requests Per Second stats</summary>
      <description>The Requests Per Second stats on the Master and RegionServer UI pages would look better without decimal places.</description>
      <version>0.95.2</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.RegionServerListTmpl.jamon</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2008-10-28 01:00:00" id="969" opendate="2008-10-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Won&amp;#39;t when storefile &gt; 2G (WAS -&gt; Won&amp;#39;t split under load)</summary>
      <description>Looks like a new bug where we won't split when under load. Some recent refactoring seems to have dropped our split provoker.</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.io.BlockFSInputStream.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-10-2 01:00:00" id="9699" opendate="2013-10-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>For Downstreamers using HBaseTestingUtility is hard.</summary>
      <description>Maven doesn't seem to play well with trasitive dependencies from -test jars. We should follow the lead of hadoop-common and create a module for test utilities.</description>
      <version>0.98.0,0.95.2,0.96.0</version>
      <fixedVersion>0.98.0,0.96.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-thrift.pom.xml</file>
      <file type="M">hbase-shell.pom.xml</file>
      <file type="M">hbase-it.pom.xml</file>
      <file type="M">hbase-examples.pom.xml</file>
      <file type="M">hbase-assembly.pom.xml</file>
      <file type="M">hbase-testing-util.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-10-29 01:00:00" id="970" opendate="2008-10-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update the copy/rename scripts to go against change API</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.rename.table.rb</file>
      <file type="M">bin.copy.table.rb</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-11-4 01:00:00" id="9710" opendate="2013-10-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use the region name, not the encoded name, when region is not on current server</summary>
      <description>When we throw a RegionOpeningException or a NotServingRegionException we put the encoded region name in the exception, which isn't super useful. I propose putting the region name instead.</description>
      <version>0.95.2,0.96.0</version>
      <fixedVersion>0.98.0,0.96.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-10-4 01:00:00" id="9711" opendate="2013-10-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve HBASE-9428 - avoid copying bytes for RegexFilter unless necessary</summary>
      <description>Parent patch copies input for RegexFilter unconditionally.We should only do this if the KV portion into the passed byte[] is &lt; 1/2 of the passed byte[]. Otherwise we waste cycles.Patch is trivial and will be coming momentarily.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.0,0.94.13</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.filter.RegexStringComparator.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-10-11 01:00:00" id="9745" opendate="2013-10-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Append HBASE_CLASSPATH to end of Java classpath and use another env var for prefix</summary>
      <description>HBASE-9097 changed the behavior to prefix HBASE_CLASSPATH to end of Java classpath instead of appending it. This break existing behavior (read more on HBASE-9097).We should revert to existing behavior and provide another way to prefix certain jars to the classpath.</description>
      <version>0.98.0,0.95.2,0.94.11</version>
      <fixedVersion>0.98.0,0.94.13,0.96.1,0.99.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-10-11 01:00:00" id="9748" opendate="2013-10-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Address outstanding comments raised for HBASE-9696</summary>
      <description>This is a follow-up issue of HBASE-9696.There are some outstanding review comments in https://reviews.apache.org/r/14470/ that haven't been addressed. I will address them later in this jira.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.96.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerNoMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.handler.TestCloseRegionHandler.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionMergeTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DeleteTableHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.BulkReOpen.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.master.RegionState.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKAssign.java</file>
    </fixedFiles>
  </bug>
</bugrepository>