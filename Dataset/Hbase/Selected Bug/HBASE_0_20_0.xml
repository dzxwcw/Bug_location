<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="HBASE">
  
  
  <bug fixdate="2014-8-1 01:00:00" id="11640" opendate="2014-8-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add syntax highlighting support to HBase Ref Guide programlistings</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">src.main.docbkx.zookeeper.xml</file>
      <file type="M">src.main.docbkx.upgrading.xml</file>
      <file type="M">src.main.docbkx.troubleshooting.xml</file>
      <file type="M">src.main.docbkx.tracing.xml</file>
      <file type="M">src.main.docbkx.thrift.filter.language.xml</file>
      <file type="M">src.main.docbkx.security.xml</file>
      <file type="M">src.main.docbkx.schema.design.xml</file>
      <file type="M">src.main.docbkx.preface.xml</file>
      <file type="M">src.main.docbkx.performance.xml</file>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
      <file type="M">src.main.docbkx.hbase.apis.xml</file>
      <file type="M">src.main.docbkx.getting.started.xml</file>
      <file type="M">src.main.docbkx.developer.xml</file>
      <file type="M">src.main.docbkx.customization.xsl</file>
      <file type="M">src.main.docbkx.cp.xml</file>
      <file type="M">src.main.docbkx.configuration.xml</file>
      <file type="M">src.main.docbkx.case.studies.xml</file>
      <file type="M">src.main.docbkx.book.xml</file>
      <file type="M">src.main.docbkx.appendix.contributing.to.documentation.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-9-1 01:00:00" id="11643" opendate="2014-8-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Read and write MOB in HBase</summary>
      <description>The read/write MOB in HBase are implemented in this JIRA. Normally, the Cells are saved in the MemStore, and flushed to the HFiles when necessary. For MOB, the Cells are saved in the MemStore as well, but they're flushed to elsewhere out of HBase in the format of HFiles.</description>
      <version>None</version>
      <fixedVersion>hbase-11339,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultStoreEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.DeleteTableHandler.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.TagType.java</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2009-4-19 01:00:00" id="1205" opendate="2009-2-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>RegionServers should find new master when a new master comes up.</summary>
      <description/>
      <version>0.20.0</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-3-2 01:00:00" id="1230" opendate="2009-3-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document installation of HBase on Windows</summary>
      <description>Provide documentation on how to run HBase on Windows.</description>
      <version>0.18.1,0.19.0,0.19.1,0.20.0</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.overview.html</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-5-3 01:00:00" id="1236" opendate="2009-3-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve readability of table descriptions in the UI</summary>
      <description>The current ruby hash style dump displayed in the UI makes it hard for a human to quickly understand the details of a given table. Improve the print out to have more layout. Due to the fact that there could be many tables and even more column families, probably use a light Javascript based open and collapse layout. I would look for example at how the webdeveloper toolbar in Firefox does that for the Javascript tab it opens.</description>
      <version>0.20.0,0.20.1,0.90.0</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.webapps.master.master.jsp</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-11-28 01:00:00" id="12362" opendate="2014-10-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Interim documentation of important master and regionserver metrics</summary>
      <description>Currently we have a section of the manual titled "Most Important RegionServer Metrics" but all it says is:Previously, this section contained a list of the most important RegionServer metrics. However, the list was extremely out of date. In some cases, the name of a given metric has changed. In other cases, the metric seems to no longer be exposed. An effort is underway to create automatic documentation for each metric based upon information pulled from its implementationIn the meantime, let's continue to maintain a list of operationally useful metrics.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-11-28 01:00:00" id="12363" opendate="2014-10-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve how KEEP_DELETED_CELLS works with MIN_VERSIONS</summary>
      <description>Brainstorming...This morning in the train (of all places) I realized a fundamental issue in how KEEP_DELETED_CELLS is implemented.The problem is around knowing when it is safe to remove a delete marker (we cannot remove it unless all cells affected by it are remove otherwise).This was particularly hard for family marker, since they sort before all cells of a row, and hence scanning forward through an HFile you cannot know whether the family markers are still needed until at least the entire row is scanned.My solution was to keep the TS of the oldest put in any given HFile, and only remove delete markers older than that TS.That sounds good on the face of it... But now imagine you wrote a version of ROW 1 and then never update it again. Then later you write a billion other rows and delete them all. Since the TS of the cells in ROW 1 is older than all the delete markers for the other billion rows, these will never be collected... At least for the region that hosts ROW 1 after a major compaction.Note, in a sense that is what HBase is supposed to do when keeping deleted cells: Keep them until they would be removed by some other means (for example TTL, or MAX_VERSION when new versions are inserted).The specific problem here is that even as all KVs affected by a delete marker are expired this way the marker would not be removed if there just one older KV in the HStore.I don't see a good way out of this. In parent I outlined these four solutions:So there are three options I think: Only allow the new flag set on CFs with TTL set. MIN_VERSIONS would not apply to deleted rows or delete marker rows (wouldn't know how long to keep family deletes in that case). (MAX)VERSIONS would still be enforced on all rows types except for family delete markers. Translate family delete markers to column delete marker at (major) compaction time. Change HFileWriterV* to keep track of the earliest put TS in a store and write it to the file metadata. Use that use expire delete marker that are older and hence can't affect any puts in the file. Have Store.java keep track of the earliest put in internalFlushCache and compactStore and then append it to the file metadata. That way HFileWriterV* would not need to know about KVs.And I implemented #4.I'd love to get input on ideas.</description>
      <version>None</version>
      <fixedVersion>0.98.8,0.99.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shell.src.main.ruby.hbase.admin.rb</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestReversibleScanners.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestQueryMatcher.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMinVersions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestKeepDeletes.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestDefaultMemStore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestCase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ScanInfo.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.TestHColumnDescriptor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-10-31 01:00:00" id="12390" opendate="2014-10-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change revision style from svn to git</summary>
      <description>This was bothering me. We should change the -r &lt;revision_id&gt; style that is an svn thing. We can do: 2.0.0-SNAPSHOT, revision=64b6109ce917a47e4fa4b88cdb800bcc7a228484</description>
      <version>None</version>
      <fixedVersion>0.99.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.StateDumpServlet.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">hbase-rest.src.main.resources.hbase-webapps.rest.rest.jsp</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.VersionInfo.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-10-31 01:00:00" id="12391" opendate="2014-10-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Correct a typo in the mob metrics</summary>
      <description>There's a typo in the temp variable in the region server metrics for mob. It's now "testMobCompactedFromMobCellsSize", and should be changed to "tempMobCompactedFromMobCellsSize"</description>
      <version>None</version>
      <fixedVersion>hbase-11339,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-3-19 01:00:00" id="1267" opendate="2009-3-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>binary keys broken in trunk (again).</summary>
      <description>Binary keys, specifically ones where the first byte of the key is nul '\0' don't work: Splits happen Logfile indicates everything normalBut the .META. doesnt list all the regions. It only lists the 'basic' regions: 'table,,1234'. The other regions with the binary keys in the middle just dont seem to be in .META....</description>
      <version>0.20.0</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Memcache.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HStoreKey.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2015-3-12 01:00:00" id="13023" opendate="2015-2-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document multiWAL</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2015-3-6 01:00:00" id="13163" opendate="2015-3-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add HBase version to header and footer of HTML and PDF docs</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc.book.adoc</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2009-4-20 01:00:00" id="1330" opendate="2009-4-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>binary keys broken on trunk</summary>
      <description>The symptom is commits fail with 'table not found' exception - even though the table does in fact exist!Digging in a little with debug logs indicate that getClosestRowBefore() is returning NULL, which for a table that exists should never be! A key always falls into a region - either the first or the last one at the very least.</description>
      <version>0.20.0</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-4-31 01:00:00" id="13370" opendate="2015-3-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>PE tool could give option for using Explicit Column Tracker which leads to seeks</summary>
      <description>Currently in PE tool all the scans and gets adds explicitly the columns to be scanned. The tool by default adds only one Qualifier. Doing this addColumns leads to Explicit Column Tracker which does seeks frequently. If we want to know a simple scan performance as a basic scenario then we should have the option to add this columns explicitly.</description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0,0.98.12,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-5-15 01:00:00" id="13700" opendate="2015-5-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow Thrift2 HSHA server to have configurable threads</summary>
      <description>The half sync half async server by default starts 5 worker threads. For busy servers that might not be enough. That should be configurable.For the threadpool there should be a way to set the max number of threads so that creating threads doesn't run away. That should be configurable.</description>
      <version>None</version>
      <fixedVersion>1.2.0,0.98.19,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.src.main.java.org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-7-16 01:00:00" id="13701" opendate="2015-5-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Consolidate SecureBulkLoadEndpoint into HBase core as default for bulk load</summary>
      <description>HBASE-12052 makes SecureBulkLoadEndpoint work in a non-secure env to solve HDFS permission issues.We have encountered some of the permission issues and have to use this SecureBulkLoadEndpoint to workaround issues.We should probably consolidate SecureBulkLoadEndpoint into HBase core as default for bulk load since it is able to handle both secure Kerberos and non-secure cases.Maintaining two versions of bulk load implementation is also a cause of confusion, and having to explicitly set it is also inconvenient.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-5-6 01:00:00" id="1383" opendate="2009-5-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase shell needs to warn on deleting multi-region table</summary>
      <description>if a multi-region table is deleted, then re-created, the old regions in the storefiles can interfere with the new table. to fix this, a major compaction should be issued before loading the new table. the shell should warn people of this so we don't end up with unhappy users.</description>
      <version>0.20.0</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.hirb.rb</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-6-16 01:00:00" id="13920" opendate="2015-6-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Exclude Java files generated from protobuf from javadoc</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-8-15 01:00:00" id="14081" opendate="2015-7-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>(outdated) references to SVN/trunk in documentation</summary>
      <description>Looking athttps://svn.apache.org/repos/asf/hbase/tags/SVN is no longer seems to be updated.Is http://hbase.apache.org/ being built from Git? https://issues.apache.org/jira/browse/INFRA-7768 is also being discussed.Can those updated to master (or removed)?Thanks</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.site.resources.doap.Hbase.rdf</file>
      <file type="M">src.main.asciidoc..chapters.rpc.adoc</file>
      <file type="M">src.main.asciidoc..chapters.performance.adoc</file>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
      <file type="M">src.main.asciidoc..chapters.community.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-9-15 01:00:00" id="14082" opendate="2015-7-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add replica id to JMX metrics names</summary>
      <description>Today, via JMX, one cannot distinguish a primary region from a replica. A possible solution is to add replica id to JMX metrics names. The benefits may include, for example: Knowing the latency of a read request on a replica region means the first attempt to the primary region has timeout. Write requests on replicas are due to the replication process, while the ones on primary are from clients. In case of looking for hot spots of read operations, replicas should be excluded since TIMELINE reads are sent to all replicas.To implement, we can change the format of metrics names found at Hadoop-&gt;HBase-&gt;RegionServer-&gt;Regions-&gt;Attributesfrom namespace_&lt;namespace&gt;_table_&lt;tablename&gt;_region_&lt;regionname&gt;_metric_&lt;metricname&gt;tonamespace_&lt;namespace&gt;_table_&lt;tablename&gt;_region_&lt;regionname&gt;_replicaid_&lt;replicaid&gt;_metric_&lt;metricname&gt;</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperStub.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSource.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2015-11-3 01:00:00" id="14751" opendate="2015-11-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Book seems to be broken</summary>
      <description>Seems that the content after: https://hbase.apache.org/book.html#jython seems to be broken. No more titles and links. misty FYI.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.external.apis.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-9-5 01:00:00" id="1485" opendate="2009-6-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Wrong or indeterminate behavior when there are duplicate versions of a column</summary>
      <description>As of now, both gets and scanners will end up returning all duplicate versions of a column. The ordering of them is indeterminate.We need to decide what the desired/expected behavior should be and make it happen.Note: It's nearly impossible for this to work with Gets as they are now implemented in 1304 so this is really a Scanner issue. To implement this correctly with Gets, we would have to undo basically all the optimizations that Gets do and making them far slower than a Scanner.</description>
      <version>0.20.0</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestScanWildcardColumnTracker.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestKeyValueHeap.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestExplicitColumnTracker.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.KeyValueScanFixture.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.ScanWildcardColumnTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.ScanQueryMatcher.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.MinorCompactingStoreScanner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.MemStore.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.KeyValueScanner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.KeyValueHeap.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.ExplicitColumnTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.ColumnTracker.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2015-12-16 01:00:00" id="14991" opendate="2015-12-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix the feature warning in scala code</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-spark.src.main.scala.org.apache.hadoop.hbase.spark.datasources.HBaseResources.scala</file>
      <file type="M">hbase-spark.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-12-18 01:00:00" id="15011" opendate="2015-12-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>turn off the jdk8 javadoc linter. :(</summary>
      <description>there's a new javadoc warning that causes warnings on all of our new patches and (I believe) breaks us on jdk8.Thanks to saint.ack@gmail.com for chasing it down on HBASE-14849.1 warning[WARNING] Javadoc Warnings[WARNING] /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/hbase/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java:430: warning - @param argument "hfilesDir" is not a parameter name.[INFO]</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,0.98.17,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2009-6-10 01:00:00" id="1509" opendate="2009-6-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add explanation to shell "help" command on how to use binary keys</summary>
      <description>Now that we know (HBASE-1363) how to input binary keys also add that bit to the help page.</description>
      <version>0.20.0</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.hirb.rb</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2016-3-21 01:00:00" id="15300" opendate="2016-2-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade to zookeeper 3.4.8</summary>
      <description>zookeeper 3.4.8 has been released.Among the fixes the following are desirable:ZOOKEEPER-706 large numbers of watches can cause session re-establishment to fail ZOOKEEPER-1797 PurgeTxnLog may delete data logs during rollThis issue upgrades zookeeper dependency to 3.4.8</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-6-26 01:00:00" id="15353" opendate="2016-2-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add metric for number of CallQueueTooBigExceptions</summary>
      <description>This exception is being thrown more. We should add a metric for this one.</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServer.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSource.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2009-6-19 01:00:00" id="1545" opendate="2009-6-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>atomicIncrements creating new values with Long.MAX_VALUE</summary>
      <description>Atomic increment is creating new key values with timestamp of Long.MAX_VALUE. This is not good, makes it hard to do range queries (as most of Thrift queries are).</description>
      <version>0.20.0</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-6-19 01:00:00" id="1547" opendate="2009-6-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>atomicIncrement doesnt increase hregion.memcacheSize</summary>
      <description>this prevents flushing!</description>
      <version>0.20.0</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-6-19 01:00:00" id="1553" opendate="2009-6-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>ClassSize missing in trunk</summary>
      <description>Patch for HBASE-1387 went in without ClassSize.</description>
      <version>0.20.0</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2016-4-16 01:00:00" id="15662" opendate="2016-4-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hook up JvmPauseMonitor to REST server</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.98.19,1.4.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-rest.src.main.java.org.apache.hadoop.hbase.rest.RESTServlet.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.rest.MetricsRESTSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.rest.MetricsRESTSource.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-4-18 01:00:00" id="15671" opendate="2016-4-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add per-table metrics on memstore, storefile and regionsize</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsTableAggregate.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.MetricsTableWrapperStub.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregateImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.test.java.org.apache.hadoop.hbase.regionserver.TestMetricsTableSourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsTableSourceImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsTableWrapperAggregate.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsTableSource.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-4-20 01:00:00" id="15683" opendate="2016-4-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Min latency in latency histograms are emitted as Long.MAX_VALUE</summary>
      <description>See attached graph.</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.FastLongHistogram.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2009-6-23 01:00:00" id="1576" opendate="2009-6-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>TIF needs to be able to set scanner caching size for smaller row tables &amp; performance</summary>
      <description>TIF goes with the default scanner caching size (1). When each row is processed very fast and is small, this limits the overall performance. By setting a higher scanner caching level you can achieve 100x+ the performance with the exact same map-reduce and table.</description>
      <version>0.20.0</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableMapReduceUtil.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-6-24 01:00:00" id="1580" opendate="2009-6-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Store scanner does not consult filter.filterRow at end of scan</summary>
      <description>I have impelemented a columnValueFilter (with new interface) that should filter out the last of two rows in a table. However, I notice that filterRow is only being called on the first row, and the second row is returned.This patch fixes it, but needs review. My first attempt at adding the call in the DONE_SCAN case did not fix it, but still seems right. The second addition at the end of the method fixed it.</description>
      <version>0.20.0</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-5-28 01:00:00" id="15910" opendate="2016-5-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update hbase ref guide to explain submit-patch.py</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-6-7 01:00:00" id="15981" opendate="2016-6-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Stripe and Date-tiered compactions inaccurately suggest disabling table in docs</summary>
      <description>hbase.online.schema.update.enable is set to true in later versions of HBase. However, the documentation in the book around configuration Stripe and Date-tiered compactions instruct the user to disable a table before changing configuration. According to Enis on the user list, this is not necessary:Disabling the table should not be needed. From the stripe compactionperspective, deploying this in a disabled table versus in an online altertable is not different at all. The "hbase.online.schema.update.enable"property was fixing some possible race conditions that were fixed long timeago.We should update the book to remove this inaccurate messaging.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-6-9 01:00:00" id="16002" opendate="2016-6-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Many DataType constructors are not public</summary>
      <description>Using the Struct class to build a rowkey, I noticed than many of the provided DataType implementations' constructors are protected. They should be public in most (all?) cases.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.types.TestTerminatedWrapper.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.types.TestStructNullExtension.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.types.TestStruct.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.types.TestRawString.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.types.TestOrderedString.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.types.TestOrderedBlobVar.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.types.TestOrderedBlob.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.types.TestFixedLengthWrapper.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawStringTerminated.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawStringFixedLength.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawString.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawBytesTerminated.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawBytesFixedLength.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.RawBytes.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedString.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedNumeric.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedInt8.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedInt64.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedInt32.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedInt16.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedFloat64.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedFloat32.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedBytesBase.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedBlobVar.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.types.OrderedBlob.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-2-17 01:00:00" id="16060" opendate="2016-6-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>1.x clients cannot access table state talking to 2.0 cluster</summary>
      <description>Since table state is migrated to meta instead of zk in 2.0, 1.x clients talking to 2.0 cluster cannot access the table state. This causes some weird behavior since from a client perspective, Admin.isTableEnabled() and Admin.isTableDisabled() both return false. One option we can do is to add code in 1.x clients so that they can access the table state in meta if needed. Otherwise, we can mirror the table state in zk (while keeping meta as the source of truth) during 2.x lifecycle so that any 1.x client can still work correctly.</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-2,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestTableStateManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterNoCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ZKDataMigrator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableStateManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.TruncateTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.ProcedureSyncWait.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterMetaBootstrap.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.AssignmentManager.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.ZooKeeper.proto</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZNodePaths.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.CoordinatedStateException.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-8-4 01:00:00" id="16355" opendate="2016-8-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase-client dependency on hbase-common test-jar should be test scope</summary>
      <description>https://github.com/apache/hbase/pull/12</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-8-17 01:00:00" id="16440" opendate="2016-8-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>MemstoreChunkPool might cross its maxCount of chunks to pool</summary>
      <description>void putbackChunks(BlockingQueue&lt;Chunk&gt; chunks) { int maxNumToPutback = this.maxCount - reclaimedChunks.size(); if (maxNumToPutback &lt;= 0) { return; } chunks.drainTo(reclaimedChunks, maxNumToPutback); // clear reference of any non-reclaimable chunks if (chunks.size() &gt; 0) { if (LOG.isTraceEnabled()) { LOG.trace("Left " + chunks.size() + " unreclaimable chunks, removing them from queue"); } chunks.clear(); } }There is no synchroization. 2 threads might be calling this API as part of a MSLAB close. (Once the memstore is flushed). It pass all the chunks used by it. (Those might not have been come from pool also). We try to put back chunks such that it is not crossing maxCount. Suppose maxCount is 10 and currently no chunks in 'reclaimedChunks'. Say both threads at line one. Both see 'maxNumToPutback ' as 10 and that will make 20 chunks being pooled. Similar issue is in putbackChunk(Chunk chunk) API also.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMemStoreChunkPool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreChunkPool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HeapMemStoreLAB.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-11-7 01:00:00" id="16570" opendate="2016-9-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compute region locality in parallel at startup</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestRegionLocationFinder.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestBaseLoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.RegionLocationFinder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2016-10-22 01:00:00" id="16672" opendate="2016-9-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add option for bulk load to always copy hfile(s) instead of renaming</summary>
      <description>This is related to HBASE-14417, to support incrementally restoring to multiple destinations, this issue adds option which would always copy hfile(s) during bulk load.</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFilesSplitRecovery.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SecureBulkLoadManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Region.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
      <file type="M">hbase-protocol.src.main.protobuf.Client.proto</file>
      <file type="M">hbase-protocol.src.main.java.org.apache.hadoop.hbase.protobuf.generated.ClientProtos.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.SecureBulkLoadClient.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-9-22 01:00:00" id="16675" opendate="2016-9-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Average region size may be incorrect when there is region whose RegionLoad cannot be retrieved</summary>
      <description>HBASE-15933 fixed the NullPointerException bug.When there is one or more region whose RegionLoad cannot be retrieved, the average region size may be incorrect.We should not use tableRegions.size() as denominator - the number of regions whose RegionLoad can be retrieved should be used.</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.normalizer.SimpleRegionNormalizer.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-9-27 01:00:00" id="16720" opendate="2016-9-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Sort build ids in flaky dashboard</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.report-flakies.py</file>
      <file type="M">dev-support.flaky-dashboard-template.html</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-11-14 01:00:00" id="16840" opendate="2016-10-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reuse cell&amp;#39;s timestamp and type in ScanQueryMatcher</summary>
      <description>Reuse cell's timestamp and type in ScanQueryMatcher, this is useful for KeyValue.</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.UserScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.StripeCompactionScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.RawScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.NormalUserScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.MinorCompactionScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.MajorCompactionScanQueryMatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.querymatcher.LegacyScanQueryMatcher.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-7-23 01:00:00" id="1692" opendate="2009-7-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Web UI is extremely slow / freezes up if you have many tables</summary>
      <description>I have 40 tables and every time the web ui loads (or i refresh it) the browser locks up and it takes 5-10 seconds to render the page.In a dev cluster I had 3 tables and it was fast.I thought there was a jira for this already but I couldn't find it... please correct me if there is.</description>
      <version>0.20.0</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.webapps.static.scripts.jquery.treeview.pack.js</file>
      <file type="M">src.webapps.static.scripts.jquery.cookie.js</file>
      <file type="M">src.webapps.static.scripts.jquery-1.3.1.min.js</file>
      <file type="M">src.webapps.static.jquery.treeview.css</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.webapps.master.master.jsp</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  <bug fixdate="2009-7-28 01:00:00" id="1718" opendate="2009-7-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reuse of KeyValue during log replay could cause the wrong data to be used</summary>
      <description>Our meta table got a row key of METAROW in it. Hard to explain how it happened, but under code inspection stack found that we are reusing the same KV instance for each replayed key.</description>
      <version>0.20.0</version>
      <fixedVersion>0.20.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2017-1-20 01:00:00" id="17500" opendate="2017-1-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement getTable/creatTable/deleteTable/truncateTable methods</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncHBaseAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncAdmin.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.AsyncMetaTableAccessor.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2017-10-3 01:00:00" id="17590" opendate="2017-2-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Drop cache hint should work for StoreFile write path</summary>
      <description>We have this in the code right now. public Builder withShouldDropCacheBehind(boolean shouldDropCacheBehind/*NOT USED!!*/) { // TODO: HAS NO EFFECT!!! FIX!! return this; }Creating jira to track it.</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.1,2.0.0,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileWriter.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2017-2-4 01:00:00" id="17593" opendate="2017-2-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix build with hadoop 3 profile</summary>
      <description>mvn clean install -DskipTests -Dhadoop-three.version=3.0.0-alpha1 -Dhadoop.profile=3.0 fails for me, but passes with -Dhadoop-three.version=3.0.0-alpha2. The failure with alpha1 is given below.Haven't investigated the failure, maybe we can simply update the hadoop three version to alpha2?[ERROR] Failed to execute goal org.apache.maven.plugins:maven-antrun-plugin:1.8:run (generate) on project hbase-server: An Ant BuildException has occured: java.lang.NoSuchMethodError: javax.servlet.ServletContext.getJspConfigDescriptor()Ljavax/servlet/descriptor/JspConfigDescriptor;[ERROR] around Ant part ...&lt;jspcompiler uriroot="${src.webapps}/master" outputdir="${generated.sources}/java" package="org.apache.hadoop.hbase.generated.master" webxml="${build.webapps}/master/WEB-INF/web.xml"/&gt;... @ 17:187 in /Users/appy/apache/hbase/hbase-server/target/antrun/build-main.xml</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2017-5-8 01:00:00" id="17757" opendate="2017-3-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unify blocksize after encoding to decrease memory fragment</summary>
      <description>Usually, we store encoded block(uncompressed) in blockcache/bucketCache. Though we have set the blocksize, after encoding, blocksize is varied. Varied blocksize will cause memory fragment problem, which will result in more FGC finally.In order to relief the memory fragment, This issue adjusts the encoded block to a unified size.</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileWriterImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2017-6-27 01:00:00" id="17840" opendate="2017-3-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update book</summary>
      <description>Need to update the book to include the new feature.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2017-3-29 01:00:00" id="17851" opendate="2017-3-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[TEST]: WAL to HFile conversion phase MUST detect and handle missing WAL files</summary>
      <description>The code is implemented - we need UT to verify correctness of a failure handling algo.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-mapreduce.src.test.java.org.apache.hadoop.hbase.mapreduce.TestWALRecordReader.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2017-2-9 01:00:00" id="18020" opendate="2017-5-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update API Compliance Checker to Incorporate Improvements Done in Hadoop</summary>
      <description>Recently the Hadoop community has made a number of improvements in their api compliance checker based on feedback from the hbase and kudu community. We should adopt these changes ourselves.</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.3.2,2.0.0,1.2.7</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.check.compatibility.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-9-31 01:00:00" id="1804" opendate="2009-8-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Puts are permitted (and stored) when including an appended colon</summary>
      <description>If I have a table with family "testFamily", currently I can do Puts using the new API by specifying the family name with or without a colon. The KV is then stored w/ or w/o depending on how the Put was done.If you try to Put.add("testFamily:", "qualifier", "value") this should throw a NoSuchColumnFamilyException</description>
      <version>0.20.0</version>
      <fixedVersion>0.20.0,0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2009-9-11 01:00:00" id="1827" opendate="2009-9-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add disabling block cache scanner flag to the shell, option for scan and count</summary>
      <description>HBASE-1823 added an option for individual Scans to not cache blocks. Expose this as an option in the shell for scan and count.</description>
      <version>0.20.0</version>
      <fixedVersion>0.20.1,0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.hirb.rb</file>
      <file type="M">bin.HBase.rb</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-11-11 01:00:00" id="1829" opendate="2009-9-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make use of start/stop row in TableInputFormat</summary>
      <description>Since we can now specify a start and stop row with the Scan that is handed to the TIF we can reduce the splits to the regions that contain these rows. That allows to test large MR jobs on a single region for example.</description>
      <version>0.20.0</version>
      <fixedVersion>0.20.2,0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HConnection.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-9-12 01:00:00" id="1830" opendate="2009-9-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HbaseObjectWritable methods should allow null HBaseConfigurations for when Writable is not Configurable</summary>
      <description>HBASE-1828 dealt with a broken scanner because we were passing null for HBaseConfiguration. Previous patches attempted to make it so HbaseObjectWritable would work with null HBC but it appears there is still a problem here. Fix it so we allow null HBC.</description>
      <version>0.20.0</version>
      <fixedVersion>0.20.1,0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.TestSerialization.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.CompareFilter.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2017-9-20 01:00:00" id="18421" opendate="2017-7-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>update hadoop prerequisites docs to call out 2.8.1</summary>
      <description>The Hadoop PMC has release 2.8.1 with the same "not ready for production" caveat as 2.8.0 (ref announce email)We should update our docs proactively.</description>
      <version>None</version>
      <fixedVersion>2.0.0-alpha-3,2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2017-12-23 01:00:00" id="18440" opendate="2017-7-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>ITs and Actions modify immutable TableDescriptors</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.IntegrationTestIngestWithEncryption.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.DecreaseMaxHFileSizeAction.java</file>
      <file type="M">hbase-it.src.test.java.org.apache.hadoop.hbase.chaos.actions.AddColumnAction.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2017-7-24 01:00:00" id="18441" opendate="2017-7-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>ZookeeperWatcher#interruptedException should throw exception</summary>
      <description>Currently Zookeeper#interruptedException will swallow the InterruptedException and only log, which might cause unexpected behavior, such as when invoking ZKUtil#checkExists and the watcher thread somehow interrupted, the method will return -1 which means the checked znode doesn't exist, while actually the znode exists.We could also see a TODO tag in the javadoc, which indicates we need some fix/improvement here: /** * Handles InterruptedExceptions in client calls. * &lt;p&gt; * This may be temporary but for now this gives one place to deal with these. * &lt;p&gt; * TODO: Currently, this method does nothing. * Is this ever expected to happen? Do we abort or can we let it run? * Maybe this should be logged as WARN? It shouldn't happen? * &lt;p&gt; * @param ie */Here we propose to throw a KeeperException$SystemErrorException in ZookeeperWatcher#interruptedException, and will add a UT case to cover the interruption scenario.</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0,1.2.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2009-11-24 01:00:00" id="1867" opendate="2009-9-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Tool to regenerate an hbase table from the data files</summary>
      <description>The purpose of this JIRA is provide a place to coordinate the development of a utility that will regenerate an hbase table from the data files.Here are some comments from stack on this subject from the hbase-user mailing list:Well, in the bin directory, there are scripts that do various things withthe .META. (copy a table, move a table, load a table whose source is hfileswritten by a mapreduce job; i.e. hbase-48).So, to 'regenerate an hbase table from the data files', you'd need to dosomething like the following:+ delete all exisiting table references from .META.+ move the backuped up table into position under hbase.rootdir+ per region under hbase.rootdir, add an entry to .META. Do this by openingthe .regioninfo file. Its content is needed to generate the rowid for.META. and its value becomes the info:regioninfo cell value.HBase does not need to be down. On next .META. scan, the newly addedregions will be noticed. They won't have associated info:server andinfo:startcode entries so master will go ahead and assign them and youshould be up and running.Code-wise, a study of copy_table.rb (this uses old api ... needs updatingbut the concepts are the same) and loadtable.rb would probably be fruitful.</description>
      <version>0.20.0</version>
      <fixedVersion>0.20.2,0.90.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2017-8-28 01:00:00" id="18710" opendate="2017-8-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move on to hbase-thirdparty 1.0.1 (it was just released).</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.0.0-alpha-3,2.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2017-9-1 01:00:00" id="18737" opendate="2017-9-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Display configured max size of memstore and cache on RS UI</summary>
      <description>Displaying the configured size of memstore and cache will help non-admin users understand the cluster capacity. Attached screenshot with proposed usability related changes and the current RS UI.</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0-alpha-3,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHeapMemoryManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperStub.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.BlockCache.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl.jamon</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper.java</file>
      <file type="M">hbase-external-blockcache.src.main.java.org.apache.hadoop.hbase.io.hfile.MemcachedBlockCache.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2017-9-3 01:00:00" id="18750" opendate="2017-9-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cleanup the docs saying "HTable use write buffer"</summary>
      <description>Cleanup the docs saying "HTable use write buffer"Default size of the HTable client write buffer in bytes. A bigger buffer takes more memory — on both the client and server side since server instantiates the passed write buffer to process it — but a larger buffer size reduces the number of RPCs made. For an estimate of server-side memory-used, evaluate hbase.client.write.buffer * hbase.regionserver.handler.countPut either adds new rows to a table (if the key is new) or can update existing rows (if the key already exists). Puts are executed via Table.put (writeBuffer) or Table.batch (non-writeBuffer).</description>
      <version>None</version>
      <fixedVersion>2.0.0-alpha-3,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.hbase-default.adoc</file>
      <file type="M">src.main.asciidoc..chapters.datamodel.adoc</file>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2017-10-4 01:00:00" id="18752" opendate="2017-9-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Recalculate the TimeRange in flushing snapshot to store file</summary>
      <description>We drop superfluous cells in flushing, hence the TimeRange from snapshot is inaccurate for the storefile. We should recalculate the TimeRange for the storefile, but the side-effect is the extra cost - we need to extract the timestamp from cell (ByteBufferCell).</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StripeStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileWriter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mob.DefaultMobStoreFlusher.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2017-9-5 01:00:00" id="18760" opendate="2017-9-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make hbase-shaded-check-invariants part of precommit</summary>
      <description/>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2017-9-12 01:00:00" id="18801" opendate="2017-9-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bulk load cleanup may falsely deem file deletion successful</summary>
      <description>Toward the cleanupBulkLoad() method: fs.delete(new Path(request.getBulkToken()), true);The return value from delete() call is ignore, potentially leading to file lying around after the cleanup.This applies to all branches.Discovered when investigating bulk load test failure.</description>
      <version>None</version>
      <fixedVersion>1.4.0,2.0.0-alpha-3,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SecureBulkLoadManager.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2017-9-16 01:00:00" id="18831" opendate="2017-9-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add explicit dependency on javax.el</summary>
      <description>Previous build would search for it running up through all point version from 3.0.1-b1 until it hit b8.</description>
      <version>None</version>
      <fixedVersion>2.0.0-alpha-4,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-thrift.pom.xml</file>
      <file type="M">hbase-server.pom.xml</file>
      <file type="M">hbase-rest.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-10-3 01:00:00" id="1885" opendate="2009-10-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Simplify use of IndexedTable outside Java API</summary>
      <description>I'm using TableIndexed to manage a secondary key that I use for lookups from Thrift. I think this is a potentially common use case. Add a UniqueIndexKeyGenerator to use the exact value of the indexed column in the primary table as the row key in the index table. Add support for creating indexes to the Hbase shellI'm attaching the UniqueIndexKeyGenerator patch. I will add a test and also add the changes to the shell soon.</description>
      <version>0.20.0</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.client.tableindexed.SimpleIndexKeyGenerator.java</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.client.tableindexed.package.html</file>
      <file type="M">src.contrib.transactional.src.java.org.apache.hadoop.hbase.client.tableindexed.IndexSpecification.java</file>
      <file type="M">src.contrib.transactional.build.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2017-9-19 01:00:00" id="18852" opendate="2017-9-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Take down the hbasecon asia banner on home page</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.0.0-alpha-4,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.site.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2017-9-20 01:00:00" id="18853" opendate="2017-9-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase-protocol-shaded includes protobuf (since we moved to hbase-thirdparty)</summary>
      <description>I didn't follow my own comment when I added hbase-thirdparty hbase-shaded-protobuf to hbase-shaded-protocol as a dependency instead of original protobuf. It meant that our jar had protobuf bundled up inside it.Change is small, and I don't think we were actually using the non-shaded protobuf anywhere, but if anyone was, it'd make for interesting issue to debug. Let me see if it breaks anything...(Found by our vickyuec on internal deploy...)</description>
      <version>None</version>
      <fixedVersion>2.0.0-alpha-4,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-protocol-shaded.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2017-10-5 01:00:00" id="18951" opendate="2017-10-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use Builder pattern to remove nullable parameters for checkAndXXX methods in RawAsyncTable/AsyncTable interface</summary>
      <description>As Optional is not supposed to be used as method parameters but we do not want nullable parameters.</description>
      <version>None</version>
      <fixedVersion>2.0.0-alpha-4,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncTableImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncTableBase.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-11-12 01:00:00" id="1904" opendate="2009-10-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add tutorilal for installing HBase on Windows using Cygwin as a test and development environment</summary>
      <description>Installing HBase on Windows using Cywin is more than just unpacking the distributables and running the shell scripts. Sure, Windows is for testing and development, only, but the complexity might scare new comers. A proper how-to guide should help a lot.</description>
      <version>0.20.0</version>
      <fixedVersion>0.20.2,0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.overview.html</file>
      <file type="M">src.docs.src.documentation.content.xdocs.tabs.xml</file>
      <file type="M">src.docs.src.documentation.content.xdocs.site.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2017-3-30 01:00:00" id="19128" opendate="2017-10-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Purge Distributed Log Replay from codebase, configurations, text; mark the feature as unsupported, broken.</summary>
      <description>Kill it. It keeps coming up and over again. Needs proper burial.</description>
      <version>None</version>
      <fixedVersion>2.0.0-beta-1,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
      <file type="M">src.main.asciidoc..chapters.hbase-default.adoc</file>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestWALSplit.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.wal.TestWALReaderOnSecureWAL.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestSerialization.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestIOFencing.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityWithCheckAuths.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithDeletes.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithDefaultVisLabelService.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithCustomVisLabService.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsReplication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabels.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelReplicationWithExpAsString.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestRegionReplicaReplicationEndpointNoMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.AbstractTestWALReplay.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitWalDataLoss.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitLogWorker.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionServerNoMaster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestRegionReplicaFailover.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestPerColumnFamilyFlush.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.exceptions.RegionInRecoveryException.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.executor.EventType.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.shaded.protobuf.RequestConverter.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZNodePaths.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZooKeeperWatcher.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.wal.MetricsEditsReplaySource.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.wal.MetricsEditsReplaySourceImpl.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.resources.META-INF.services.org.apache.hadoop.hbase.regionserver.wal.MetricsEditsReplaySource</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.Admin.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.MasterProcedure.proto</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.ZooKeeper.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.Admin.proto</file>
      <file type="M">hbase-protocol.src.main.protobuf.ZooKeeper.proto</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.SplitLogManagerCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.SplitLogWorkerCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coordination.ZkSplitLogWorkerCoordination.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionObserver.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterWalManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.procedure.RSProcedureDispatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.FinishRegionRecoveringHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.handler.WALSplitterHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Region.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitLogWorker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.MetricsWALEditsReplay.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALEditsReplaySink.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.visibility.VisibilityController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.SplitLogTask.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.WALSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.RecoveringRegionWatcher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKSplitLog.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestReplicasClient.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterWalManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestSplitLogManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.MockRegionServerServices.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2017-12-20 01:00:00" id="19570" opendate="2017-12-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add hadoop3 tests to Nightly master/branch-2 runs</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.3.2,1.4.1,2.0.0-beta-1,2.0.0,1.2.7</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
      <file type="M">dev-support.hbase.nightly.yetus.sh</file>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2017-12-20 01:00:00" id="19571" opendate="2017-12-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Minor refactor of Nightly run scripts</summary>
      <description>Was trying to split out common code in separate lib, but it's not at all trivial. The way to do it for declarative syntax Jenkinsfile is by using Shared Libraries which requires separate repo!The patch ended up being just naming refactors. Renames OUTPUTDIR to OUTPUT_DIR Renames OUTPUT_RELATIVE to OUTPUT_DIR_RELATIVE</description>
      <version>None</version>
      <fixedVersion>1.3.2,1.4.1,2.0.0-beta-1,2.0.0,1.2.7</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
      <file type="M">dev-support.hbase.nightly.yetus.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-3-24 01:00:00" id="22100" opendate="2019-3-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>False positive for error prone warnings in pre commit job</summary>
      <description>https://builds.apache.org/job/PreCommit-HBASE-Build/16516/artifact/patchprocess/branch-compile-javac-hbase-client.txt[WARNING] /testptch/hbase/hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncRpcRetryingCaller.java:[125,69] [UnusedVariable] The parameter 'updateCachedLocation' is never read.[WARNING] /testptch/hbase/hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncRpcRetryingCaller.java:[125,42] [UnusedVariable] The parameter 'error' is never read.https://builds.apache.org/job/PreCommit-HBASE-Build/16516/artifact/patchprocess/patch-compile-javac-hbase-client.txt[WARNING] /testptch/hbase/hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncRpcRetryingCaller.java:[125,42] [UnusedVariable] The parameter 'error' is never read.[WARNING] /testptch/hbase/hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncRpcRetryingCaller.java:[125,69] [UnusedVariable] The parameter 'updateCachedLocation' is never read.And the output is 1 new and 1 fixed, the new one is[WARNING] /testptch/hbase/hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncRpcRetryingCaller.java:[125,69] [UnusedVariable] The parameter 'updateCachedLocation' is never read.I think here we should report nothing, as it is just an order change...</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.0.6,2.1.5</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-3-25 01:00:00" id="22101" opendate="2019-3-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>AsyncAdmin.isTableAvailable should not throw TableNotFoundException</summary>
      <description>Should return false instead.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.5</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncTableAdminApi.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.RawAsyncHBaseAdmin.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2011-7-5 01:00:00" id="3855" opendate="2011-5-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Performance degradation of memstore because reseek is linear</summary>
      <description>The scanner use reseek to find the next row (or next column) as part of a scan. The reseek code iterates over a Set to position itself at the right place. If there are many thousands of kvs that need to be skipped over, then the time-cost is very high. In this case, a seek would be far lesser in cost than a reseek.</description>
      <version>None</version>
      <fixedVersion>0.90.4</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.MemStore.java</file>
    </fixedFiles>
  </bug>
</bugrepository>