<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="HBASE">
  
  
  <bug fixdate="2018-8-31 01:00:00" id="20986" opendate="2018-7-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Separate the config of block size when we do log splitting and write Hlog</summary>
      <description>Since the block size of recovered edits and hlog are the same right now, if we set a large value to block size, name node may not able to assign enough space when we do log splitting. But set a large value to hlog block size can help reduce the number of region server asking for a new block. Thus I think separate the config of block size is necessary.</description>
      <version>3.0.0-alpha-1,2.1.0,2.0.1,2.2.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.wal.FSHLogProvider.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALUtil.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2018-10-23 01:00:00" id="21103" opendate="2018-8-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>nightly test cache of yetus install needs to be more thorough in verification</summary>
      <description>branch-1.2 nightly failed because it couldn't find yetus:https://builds.apache.org/job/HBase%20Nightly/job/branch-1.2/443/walking through steps, we checked and thought we had an existing install:https://builds.apache.org/blue/organizations/jenkins/HBase%20Nightly/detail/branch-1.2/443/pipeline/12[HBase_Nightly_branch-1.2-AEAO7LJNYKPIH3O4GB2IR4TEIHRS6EXOJCJPGWYXWO6BFPUEZT3Q] Running shell scriptEnsure we have a copy of Apache Yetus.Checking for Yetus 0.6.0 in '/home/jenkins/jenkins-slave/workspace/HBase_Nightly_branch-1.2-AEAO7LJNYKPIH3O4GB2IR4TEIHRS6EXOJCJPGWYXWO6BFPUEZT3Q/yetus-0.6.0'Reusing cached download of Apache Yetus version 0.6.0.So we stashed and then tried to use it.Examining the workspace present before the stash shows the directory we look for was present, but the contents were garbage:https://builds.apache.org/job/HBase%20Nightly/job/branch-1.2/443/execution/node/3/ws/$ unzip -l yetus-0.6.0.zip Archive: yetus-0.6.0.zip Length Date Time Name--------- ---------- ----- ---- 0 00-00-1980 04:08 yetus-0.6.0/lib/precommit/qbt.sh--------- ------- 0 1 filewe should probably check for an executable that will successfully give us a version or something like that.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.3.3,1.2.8,2.2.0,2.1.1,2.0.3,1.4.9</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2018-9-5 01:00:00" id="21153" opendate="2018-9-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Shaded client jars should always build in relevant phase to avoid confusion</summary>
      <description>edit:Now that our assembly directly relies on the shaded clients, failing to build the actual client jars (e.g. because -P release is required to fill in their contents) causes confusing errors for downstream folks about classes not being found when they run simple commands like hbase version.We should always fill in the shaded artifacts to make our build easier to understand.original report:: When I run the hbase version command it comes back with:$ ./bin/hbase versionError: Could not find or load main class org.apache.hadoop.hbase.util.GetJavaPropertyError: Could not find or load main class org.apache.hadoop.hbase.util.VersionInfoThe two classes are in hbase-commons.The nice shaded refactoring of our bin/hbase &amp;#8211; i.e. using shaded jars wherever possible &amp;#8211; may have overstretched expecting version to work with shaded client (busbey ?). If so, fix is &lt; one-liner.</description>
      <version>3.0.0-alpha-1,2.1.0,2.2.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shaded.hbase-shaded-mapreduce.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-client.pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-client-byo-hadoop.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2018-9-11 01:00:00" id="21182" opendate="2018-9-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Failed to execute start-hbase.sh</summary>
      <description>Built master branch like below:mvn clean install -DskipTestsThen tried to execute start-hbase.sh failed with NoClassDefFoundError./bin/start-hbase.sh Error: A JNI error has occurred, please check your installation and try againException in thread "main" java.lang.NoClassDefFoundError: org/apache/hadoop/hbase/shaded/org/eclipse/jetty/server/Connectorat java.lang.Class.getDeclaredMethods0(Native Method)at java.lang.Class.privateGetDeclaredMethods(Class.java:2701)at java.lang.Class.privateGetMethodRecursive(Class.java:3048)at java.lang.Class.getMethod0(Class.java:3018)at java.lang.Class.getMethod(Class.java:1784)at sun.launcher.LauncherHelper.validateMainClass(LauncherHelper.java:544)at sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:526)Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hbase.shaded.org.eclipse.jetty.server.ConnectorNote: It worked after reverting HBASE-21153</description>
      <version>3.0.0-alpha-1,2.2.0,2.1.1</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-assembly.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2010-1-14 01:00:00" id="2123" opendate="2010-1-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove &amp;#39;master&amp;#39; command-line option from PE.</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.20.3,0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2018-3-30 01:00:00" id="21410" opendate="2018-10-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>A helper page that help find all problematic regions and procedures</summary>
      <description>This page is mainly focus on finding the regions stuck in some state that cannot be assigned. My proposal of the page is as follows:From this page we can see all regions in RIT queue and their related procedures. If we can determine that these regions' state are abnormal, we can click the link 'Procedures as TXT' to get a full list of procedure IDs to bypass them. Then click 'Regions as TXT' to get a full list of encoded region names to assign.Some region names are covered by the navigator bar, I'll fix it later.</description>
      <version>3.0.0-alpha-1,2.2.0,2.1.1</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.rits.jsp</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.AssignmentManagerStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2010-1-20 01:00:00" id="2149" opendate="2010-1-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase.regionserver.global.memstore.lowerLimit is too low</summary>
      <description>The default value of hbase.regionserver.global.memstore.lowerLimit of 25% is very wrong and in almost all cases was problematic (I've seen this in at least 3 occurrences). The cost of flushing a memstore is fairly high and when the global size reaches 40% then ALL inserts are blocked. This means that with a heap of 1GB you could be flushing for 10-20 seconds or worse.I suggest a default setting of 38% or even 40% so that only a region or two will be flushed (the biggest ones) for maximum availability.</description>
      <version>None</version>
      <fixedVersion>0.20.3,0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2010-1-22 01:00:00" id="2154" opendate="2010-1-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix Client#next(int) javadoc</summary>
      <description>Its not clear what signifies scanner end and noobs probably think that batch size is how much we fetch in an RPC (thats different, thats Scan#setCaching).</description>
      <version>None</version>
      <fixedVersion>0.20.3,0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2018-7-14 01:00:00" id="21606" opendate="2018-12-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document use of the meta table load metrics added in HBASE-19722</summary>
      <description>HBASE-19722 added a great new tool for figuring out where cluster load is coming from. Needs a section in the ref guide When should I use this? Why shouldn't I use it all the time? What does using it look like? How do I use it?I think all the needed info for making something to answer these questions is in the discussion on HBASE-19722</description>
      <version>3.0.0-alpha-1,1.5.0,1.4.6,2.2.0,2.0.2,2.1.3</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,2.0.6,2.2.1,2.1.6,1.4.11</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2010-3-29 01:00:00" id="2174" opendate="2010-1-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Stop from resolving HRegionServer addresses to names using DNS on every heartbeat</summary>
      <description>Over the time many parts of the code have evolved in different ways and one issue is that addresses are handled differently in different parts of the code. We need to set a standard and correct any inconsistencies.</description>
      <version>None</version>
      <fixedVersion>0.20.4,0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.ProcessServerShutdown.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.master.ProcessRegionOpen.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.HServerInfo.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-1-18 01:00:00" id="21741" opendate="2019-1-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a note in "HFile Tool" section regarding &amp;#39;seqid=0&amp;#39;</summary>
      <description>In few parts of the HFile, where the seqid is irrelevant such as: firstKey=Optional&amp;#91;row0/cf:column/1547846312435/Put/seqid=0&amp;#93; lastKey=Optional&amp;#91;row9/cf:column/1547846312490/Put/seqid=0&amp;#93;Let's make a note on the doc in the 'HFile Tool' section, that seqid=0 in such cases means seqid is irrelevant here because it's a 'KeyOnlyKeyValue'.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2019-2-27 01:00:00" id="21794" opendate="2019-1-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update the Coprocessor observer example given in section 111.1 of the ref guide.</summary>
      <description>The given example should be changed after the CP changes (HBASE-17732)</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.cp.adoc</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2019-2-2 01:00:00" id="21828" opendate="2019-2-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make sure we do not return CompletionException when locating region</summary>
      <description/>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.1.3,2.0.5,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncRegionLocatorTimeout.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncRegionLocator.java</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2019-2-13 01:00:00" id="21889" opendate="2019-2-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use thrift 0.12.0 when build thrift by compile-thrift profile</summary>
      <description>Build command.mvn compile -Pcompile-thrift</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.0.5,2.3.0,2.1.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-thrift.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-3-7 01:00:00" id="22010" opendate="2019-3-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>docs on upgrade from 2.0,2.1 -&gt; 2.2 renders incorrectly</summary>
      <description>heading doesn't work, which also means no linking to it.the rendered page has an unrendered bit, e.g.[[upgrade 2.2]] === Upgrade from 2.0 or 2.1 to 2.2+HBase 2.2+ uses a new Procedure form assiging/unassigning/moving Regions. It does not process HBase 2.1 and 2.0’s Unassign/Assign Procedure types. Upgrade requires that we first drain the Master Procedure Store of old style Procedures before starting the new 2.2 Master. So you need to make sure that before you kill the old version (2.0 or 2.1) Master, there is no region in transition. And once the new version (2.2+) Master is up, you can rolling upgrade RegionServers one by one.</description>
      <version>3.0.0-alpha-1,2.2.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2010-2-12 01:00:00" id="2220" opendate="2010-2-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a binary comparator that only compares up to the length of the supplied byte array</summary>
      <description>This new comparator is similar to the existing BinaryComparator, but only compares up to the length of the supplied byte array.The use-case I need this for is secondary indexes. I build a table where the row keys have the form {value}{row key}, where {value} is a fixed length byte array. On this index table I then would like to perform range scans on just the fixed length {value} part. The BinaryPrefixComparator supplied in this patch enables exactly this, when used in combination with the RowFilter.See also mail athttp://mail-archives.apache.org/mod_mbox/hadoop-hbase-user/201002.mbox/%3Cf5a74c8e1002100716y56371298xc96e482a6486d939@mail.gmail.com%3E</description>
      <version>None</version>
      <fixedVersion>0.20.4,0.90.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-4-12 01:00:00" id="22222" opendate="2019-4-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Site build fails after hbase-thirdparty upgrade</summary>
      <description>After hbase-thirdparty upgrade the hbase_generate_website job is failing in mvn site target on javadoc. [ERROR] Failed to execute goal org.apache.maven.plugins:maven-site-plugin:3.7.1:site (default-site) on project hbase: Error generating maven-javadoc-plugin:3.0.1:aggregate report:[ERROR] Exit code: 1 - /home/jenkins/jenkins-slave/workspace/hbase_generate_website/hbase/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java:1034: warning - Tag @link: can't find tagsIterator(Cell) in org.apache.hadoop.hbase.CellUtil[ERROR] javadoc: error - class file for org.apache.hbase.thirdparty.com.google.errorprone.annotations.Immutable not foundAfter reverting thirdparty upgrade locally the site build passed. </description>
      <version>3.0.0-alpha-1,2.2.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-resource-bundle.src.main.resources.supplemental-models.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-4-12 01:00:00" id="22223" opendate="2019-4-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement RegionLocator based on AsyncTableRegionLocator</summary>
      <description/>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ConnectionOverAsyncConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncConnectionImpl.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-4-23 01:00:00" id="22299" opendate="2019-4-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Documentation has incorrect default number of versions</summary>
      <description>Reference guide has this section under compaction.Compaction and VersionsWhen you create a Column Family, you can specify the maximum number of versions to keep, by specifying HColumnDescriptor.setMaxVersions(int versions). The default value is 3. If more versions than the specified maximum exist, the excess versions are filtered out and not written back to the compacted StoreFile.This is incorrect, the default value is 1.Additionally, HColumnDescriptor is deprecated and the example should use ColumnFamilyDescriptorBuilder$setMaxVersions(int) instead.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-5-25 01:00:00" id="22312" opendate="2019-4-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hadoop 3 profile for hbase-shaded-mapreduce should like mapreduce as a provided dependency</summary>
      <description>the hadoop 3 profile currently misses declaring a provided dependency on the core mapreduce client module. that means we pick it up as a compile dependency from the hbase-mapreduce module, which means we include things in the shaded jar that we don't need to. (and expressly aren't supposed to include because they're supposed to come from Hadoop at runtime).</description>
      <version>2.1.0,2.2.0,2.1.1,2.1.2,2.1.3,2.1.4</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.5</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shaded.hbase-shaded-mapreduce.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-5-25 01:00:00" id="22314" opendate="2019-4-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>shaded byo-hadoop client should list needed hadoop modules as provided scope to avoid inclusion of unnecessary transitive depednencies</summary>
      <description>attempting to build against current hadoop trunk for HBASE-22087 shows that hte byo-hadoop client is trying to package transitive dependencies from the hadoop dependencies that we expressly say we don't need to bring with us.it's because we don't list those modules as provided, so all of their transitives are also in compile scope. The shading module does simple filtering when excluding things in a given scope, it doesn't e.g. make sure to also exclude the transitive dependencies of things it keeps out.since we don't want to list all the transitive dependencies of hadoop in our shading exclusion, we should list the needed hadoop modules as provided.</description>
      <version>2.1.0,2.2.0,2.3.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.5</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shaded.hbase-shaded-client-byo-hadoop.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-4-26 01:00:00" id="22317" opendate="2019-4-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support reading from meta replicas</summary>
      <description/>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestZKAsyncRegistry.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMetaWithReplicas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestConnectionImplementation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncMetaRegionLocator.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestAsyncAdminWithRegionReplicas.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.RegionReplicaTestHelper.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.AbstractTestRegionLocator.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncNonMetaRegionLocator.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2019-4-30 01:00:00" id="22341" opendate="2019-4-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add explicit guidelines for removing deprecations in book</summary>
      <description>Based on the discussion on the mailing list about the removal of deprecated versions, the client API compatibility should be extended to make it clear when a deprecated API will be removed.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,1.4.10,2.3.0,2.0.6,2.1.5,1.3.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.upgrading.adoc</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  
  
  <bug fixdate="2019-5-8 01:00:00" id="22384" opendate="2019-5-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Formatting issues in administration section of book</summary>
      <description>The administration section in the book (64.3.2. Administration) has some formatting issues. Due to that issues the list count is not accurate, as well as the indentation of some code snippets.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,1.4.10,2.3.0,2.0.6,2.1.5,1.3.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.security.adoc</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-5-13 01:00:00" id="22405" opendate="2019-5-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update Ref Guide for EOL of Hadoop 2.7</summary>
      <description/>
      <version>3.0.0-alpha-1,1.5.0,2.2.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.configuration.adoc</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-5-14 01:00:00" id="22411" opendate="2019-5-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Refactor codes of moving reigons in RSGroup</summary>
      <description>Essentially RSGroup managed regions. Organizing tables or servers' RSGroups is to move relevant regions. Codes of moving regions can be refactored.So that some problems caused by moving regions can be fixed elegantly.</description>
      <version>2.2.0</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupAdminServer.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-7-14 01:00:00" id="22414" opendate="2019-5-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Interruption of moving regions in RSGroup will cause regions on wrong rs</summary>
      <description>We bulk moving regions to target RSGroup, and each movement of region will submit a TRSP, but one TRSP encounters exception will make the whole movement action terminate. Later regions will not be moved to correct servers unless reassign.I think we can skip failed moved regions, and retry to move after all has been traversed.</description>
      <version>2.2.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-rsgroup.src.test.java.org.apache.hadoop.hbase.rsgroup.TestRSGroupsBase.java</file>
      <file type="M">hbase-rsgroup.src.test.java.org.apache.hadoop.hbase.rsgroup.TestRSGroupsAdmin2.java</file>
      <file type="M">hbase-rsgroup.src.main.java.org.apache.hadoop.hbase.rsgroup.RSGroupAdminServer.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2010-2-19 01:00:00" id="2242" opendate="2010-2-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[EC2] Downgrade JDK to 6u17 and rebuild AMIs</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.20.4,0.90.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.contrib.ec2.bin.hbase-ec2-env.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-5-18 01:00:00" id="22442" opendate="2019-5-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Nightly build is failing with hadoop 3.x</summary>
      <description>[ERROR] Found artifact with unexpected contents: '/testptch/hbase/hbase-shaded/hbase-shaded-client/target/hbase-shaded-client-2.2.1-SNAPSHOT.jar' Please check the following and either correct the build or update the allowed list with reasoning. javax/ javax/servlet/ javax/servlet/annotation/ javax/servlet/annotation/HandlesTypes.class javax/servlet/annotation/HttpConstraint.class javax/servlet/annotation/HttpMethodConstraint.class javax/servlet/annotation/MultipartConfig.class javax/servlet/annotation/package.html javax/servlet/annotation/ServletSecurity$EmptyRoleSemantic.class javax/servlet/annotation/ServletSecurity$TransportGuarantee.class javax/servlet/annotation/ServletSecurity.class javax/servlet/annotation/WebFilter.class javax/servlet/annotation/WebInitParam.class javax/servlet/annotation/WebListener.class javax/servlet/annotation/WebServlet.class javax/servlet/AsyncContext.class javax/servlet/AsyncEvent.class javax/servlet/AsyncListener.class javax/servlet/descriptor/ javax/servlet/descriptor/JspConfigDescriptor.class javax/servlet/descriptor/JspPropertyGroupDescriptor.class javax/servlet/descriptor/package.html javax/servlet/descriptor/TaglibDescriptor.class javax/servlet/DispatcherType.class javax/servlet/Filter.class javax/servlet/FilterChain.class javax/servlet/FilterConfig.class javax/servlet/FilterRegistration$Dynamic.class javax/servlet/FilterRegistration.class javax/servlet/GenericServlet.class javax/servlet/http/ javax/servlet/http/Cookie.class javax/servlet/http/HttpServlet.class javax/servlet/http/HttpServletRequest.class javax/servlet/http/HttpServletRequestWrapper.class javax/servlet/http/HttpServletResponse.class javax/servlet/http/HttpServletResponseWrapper.class javax/servlet/http/HttpSession.class javax/servlet/http/HttpSessionActivationListener.class javax/servlet/http/HttpSessionAttributeListener.class javax/servlet/http/HttpSessionBindingEvent.class javax/servlet/http/HttpSessionBindingListener.class javax/servlet/http/HttpSessionContext.class javax/servlet/http/HttpSessionEvent.class javax/servlet/http/HttpSessionIdListener.class javax/servlet/http/HttpSessionListener.class javax/servlet/http/HttpUpgradeHandler.class javax/servlet/http/HttpUtils.class javax/servlet/http/LocalStrings.properties javax/servlet/http/LocalStrings_es.properties javax/servlet/http/LocalStrings_fr.properties javax/servlet/http/LocalStrings_ja.properties javax/servlet/http/NoBodyOutputStream.class javax/servlet/http/NoBodyResponse.class javax/servlet/http/package.html javax/servlet/http/Part.class javax/servlet/http/WebConnection.class javax/servlet/HttpConstraintElement.class javax/servlet/HttpMethodConstraintElement.class javax/servlet/LocalStrings.properties javax/servlet/LocalStrings_fr.properties javax/servlet/LocalStrings_ja.properties javax/servlet/MultipartConfigElement.class javax/servlet/package.html javax/servlet/ReadListener.class javax/servlet/Registration$Dynamic.class javax/servlet/Registration.class javax/servlet/RequestDispatcher.class javax/servlet/Servlet.class javax/servlet/ServletConfig.class javax/servlet/ServletContainerInitializer.class javax/servlet/ServletContext.class javax/servlet/ServletContextAttributeEvent.class javax/servlet/ServletContextAttributeListener.class javax/servlet/ServletContextEvent.class javax/servlet/ServletContextListener.class javax/servlet/ServletException.class javax/servlet/ServletInputStream.class javax/servlet/ServletOutputStream.class javax/servlet/ServletRegistration$Dynamic.class javax/servlet/ServletRegistration.class javax/servlet/ServletRequest.class javax/servlet/ServletRequestAttributeEvent.class javax/servlet/ServletRequestAttributeListener.class javax/servlet/ServletRequestEvent.class javax/servlet/ServletRequestListener.class javax/servlet/ServletRequestWrapper.class javax/servlet/ServletResponse.class javax/servlet/ServletResponseWrapper.class javax/servlet/ServletSecurityElement.class javax/servlet/SessionCookieConfig.class javax/servlet/SessionTrackingMode.class javax/servlet/SingleThreadModel.class javax/servlet/UnavailableException.class javax/servlet/WriteListener.class com/ com/sun/ com/sun/jersey/ com/sun/jersey/api/ com/sun/jersey/api/core/ com/sun/jersey/api/core/servlet/ com/sun/jersey/api/core/servlet/WebAppResourceConfig.class com/sun/jersey/server/ com/sun/jersey/server/impl/ com/sun/jersey/server/impl/cdi/ com/sun/jersey/server/impl/cdi/AbstractBean.class com/sun/jersey/server/impl/cdi/AnnotatedCallableImpl.class com/sun/jersey/server/impl/cdi/AnnotatedConstructorImpl.class com/sun/jersey/server/impl/cdi/AnnotatedFieldImpl.class com/sun/jersey/server/impl/cdi/AnnotatedImpl.class com/sun/jersey/server/impl/cdi/AnnotatedMemberImpl.class com/sun/jersey/server/impl/cdi/AnnotatedMethodImpl.class com/sun/jersey/server/impl/cdi/AnnotatedParameterImpl.class com/sun/jersey/server/impl/cdi/AnnotatedTypeImpl.class com/sun/jersey/server/impl/cdi/BeanGenerator$1.class com/sun/jersey/server/impl/cdi/BeanGenerator.class com/sun/jersey/server/impl/cdi/CDIComponentProviderFactory$1.class com/sun/jersey/server/impl/cdi/CDIComponentProviderFactory$2.class com/sun/jersey/server/impl/cdi/CDIComponentProviderFactory$ComponentProviderDestroyable.class com/sun/jersey/server/impl/cdi/CDIComponentProviderFactory.class com/sun/jersey/server/impl/cdi/CDIComponentProviderFactoryInitializer.class com/sun/jersey/server/impl/cdi/CDIExtension$1.class com/sun/jersey/server/impl/cdi/CDIExtension$2.class com/sun/jersey/server/impl/cdi/CDIExtension$3.class com/sun/jersey/server/impl/cdi/CDIExtension$ContextAnnotationLiteral.class com/sun/jersey/server/impl/cdi/CDIExtension$InjectAnnotationLiteral.class com/sun/jersey/server/impl/cdi/CDIExtension$JNDIContextDiver.class com/sun/jersey/server/impl/cdi/CDIExtension$ParameterBean.class com/sun/jersey/server/impl/cdi/CDIExtension$PatchInformation.class com/sun/jersey/server/impl/cdi/CDIExtension$PredefinedBean.class com/sun/jersey/server/impl/cdi/CDIExtension$SyntheticQualifierAnnotationImpl.class com/sun/jersey/server/impl/cdi/CDIExtension.class com/sun/jersey/server/impl/cdi/DiscoveredParameter.class com/sun/jersey/server/impl/cdi/InitializedLater.class com/sun/jersey/server/impl/cdi/ProviderBasedBean.class com/sun/jersey/server/impl/cdi/SyntheticQualifier.class com/sun/jersey/server/impl/cdi/Utils.class com/sun/jersey/server/impl/container/ com/sun/jersey/server/impl/container/servlet/ com/sun/jersey/server/impl/container/servlet/Include.class com/sun/jersey/server/impl/container/servlet/JSPTemplateProcessor.class com/sun/jersey/server/impl/container/servlet/JerseyServletContainerInitializer.class com/sun/jersey/server/impl/container/servlet/PerSessionFactory$1.class com/sun/jersey/server/impl/container/servlet/PerSessionFactory$AbstractPerSession.class com/sun/jersey/server/impl/container/servlet/PerSessionFactory$PerSesson.class com/sun/jersey/server/impl/container/servlet/PerSessionFactory$PerSessonInstantiated.class com/sun/jersey/server/impl/container/servlet/PerSessionFactory$PerSessonProxied.class com/sun/jersey/server/impl/container/servlet/PerSessionFactory$SessionMap.class com/sun/jersey/server/impl/container/servlet/PerSessionFactory.class com/sun/jersey/server/impl/container/servlet/RequestDispatcherWrapper.class com/sun/jersey/server/impl/container/servlet/ServletAdaptor$1$1.class com/sun/jersey/server/impl/container/servlet/ServletAdaptor$1.class com/sun/jersey/server/impl/container/servlet/ServletAdaptor.class com/sun/jersey/server/impl/container/servlet/Wrapper.class com/sun/jersey/server/impl/ejb/ com/sun/jersey/server/impl/ejb/EJBComponentProviderFactory$EJBManagedComponentProvider.class com/sun/jersey/server/impl/ejb/EJBComponentProviderFactory.class com/sun/jersey/server/impl/ejb/EJBComponentProviderFactoryInitilizer.class com/sun/jersey/server/impl/ejb/EJBExceptionMapper.class com/sun/jersey/server/impl/ejb/EJBInjectionInterceptor$1.class com/sun/jersey/server/impl/ejb/EJBInjectionInterceptor.class com/sun/jersey/server/impl/ejb/EJBRequestDispatcherProvider$1.class com/sun/jersey/server/impl/ejb/EJBRequestDispatcherProvider.class com/sun/jersey/server/impl/managedbeans/ com/sun/jersey/server/impl/managedbeans/ManagedBeanComponentProviderFactory$ManagedBeanComponentProvider.class com/sun/jersey/server/impl/managedbeans/ManagedBeanComponentProviderFactory.class com/sun/jersey/server/impl/managedbeans/ManagedBeanComponentProviderFactoryInitilizer.class com/sun/jersey/spi/ com/sun/jersey/spi/container/ com/sun/jersey/spi/container/servlet/ com/sun/jersey/spi/container/servlet/PerSession.class com/sun/jersey/spi/container/servlet/ServletContainer$ContextInjectableProvider.class com/sun/jersey/spi/container/servlet/ServletContainer$InternalWebComponent.class com/sun/jersey/spi/container/servlet/ServletContainer.class com/sun/jersey/spi/container/servlet/WebComponent$1.class com/sun/jersey/spi/container/servlet/WebComponent$2.class com/sun/jersey/spi/container/servlet/WebComponent$3.class com/sun/jersey/spi/container/servlet/WebComponent$4.class com/sun/jersey/spi/container/servlet/WebComponent$ContextInjectableProvider.class com/sun/jersey/spi/container/servlet/WebComponent$Writer.class com/sun/jersey/spi/container/servlet/WebComponent.class com/sun/jersey/spi/container/servlet/WebConfig$ConfigType.class com/sun/jersey/spi/container/servlet/WebConfig.class com/sun/jersey/spi/container/servlet/WebFilterConfig.class com/sun/jersey/spi/container/servlet/WebServletConfig.class com/sun/jersey/spi/scanning/ com/sun/jersey/spi/scanning/servlet/ com/sun/jersey/spi/scanning/servlet/WebAppResourcesScanner$1.class com/sun/jersey/spi/scanning/servlet/WebAppResourcesScanner$2.class com/sun/jersey/spi/scanning/servlet/WebAppResourcesScanner.class[ERROR] Command execution failed.org.apache.commons.exec.ExecuteException: Process exited with an error: 1 (Exit value: 1) at org.apache.commons.exec.DefaultExecutor.executeInternal (DefaultExecutor.java:404) at org.apache.commons.exec.DefaultExecutor.execute (DefaultExecutor.java:166) at org.codehaus.mojo.exec.ExecMojo.executeCommandLine (ExecMojo.java:804) at org.codehaus.mojo.exec.ExecMojo.executeCommandLine (ExecMojo.java:751) at org.codehaus.mojo.exec.ExecMojo.execute (ExecMojo.java:313) at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:137) at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:208) at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:154) at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:146) at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117) at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81) at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:56) at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128) at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:305) at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192) at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105) at org.apache.maven.cli.MavenCli.execute (MavenCli.java:954) at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:288) at org.apache.maven.cli.MavenCli.main (MavenCli.java:192) at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke (Method.java:498) at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:289) at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:229) at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:415) at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:356)</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.5</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.pom.xml</file>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-5-18 01:00:00" id="22443" opendate="2019-5-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add hbase-vote script details to documentation</summary>
      <description>In HBASE-21963 taklwu provided hbase-vote.sh which helps with verification of new release. Adding it to the documentation will help anyone who would like to understand the verification process.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-5-24 01:00:00" id="22467" opendate="2019-5-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>WebUI changes to enable Apache Knox UI proxying</summary>
      <description>Apache Knox's gateway is nice in that it can provide centralized authentication and authorization for a collection of service. Additionally, it can expose "private" nodes through a single point (e.g. a gateway). This makes our life as developers much easier in cloud deployments where it's not straightforward to access nodes (e.g. they're running on some private network).KNOX-1866 captures the changes over there required to make HBase's proxying actually work (definition lives there), but there were a few things we do in our UI which made it hard/impossible to proxy it correctly. ProfilerServlet was dropping extra query parameters in the URL JSON task output on master/regionserver couldn't be disambiguated Some missing /master-status and /rs-status links couldn't be disambiguated properly due to a lack of context Missing content-type set on a profiler servlet response</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl.jamon</file>
      <file type="M">hbase-http.src.main.java.org.apache.hadoop.hbase.http.ProfileServlet.java</file>
      <file type="M">hbase-http.src.main.java.org.apache.hadoop.hbase.http.ProfileOutputServlet.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-5-26 01:00:00" id="22471" opendate="2019-5-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Our nightly jobs for master and branch-2 are still using hadoop-2.7.1 in integration test</summary>
      <description>We use ls to get the hadoop 2 jars, so maybe the problem is that the 2.7.1 jars are already there for a long time. We need to clean the workspace.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-5-26 01:00:00" id="22472" opendate="2019-5-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>The newly split TestReplicationStatus* tests are flaky</summary>
      <description>They are introduced by HBASE-22455, from the original TestReplicationStatus tests. Need to dig more.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationStatusSourceStartedTargetStoppedWithRecovery.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationStatusSourceStartedTargetStoppedNoOps.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationStatusSourceStartedTargetStoppedNewOp.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationStatusBothNormalAndRecoveryLagging.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationStatusAfterLagging.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-5-26 01:00:00" id="22474" opendate="2019-5-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add --mvn-custom-repo parameter to yetus calls</summary>
      <description>PreCommit validation from yetus uses a shared .m2 repository. By adding --mvn-custom-repo and --jenkins paramters yetus will use a custom .m2 directory for executions for PR validations.https://yetus.apache.org/documentation/0.9.0/precommit-buildtools/</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,1.4.10,2.0.6,2.1.5,1.3.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile.GitHub</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-5-30 01:00:00" id="22511" opendate="2019-5-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>More missing /rs-status links</summary>
      <description>Found some more broken links when running behind Knox. Trivial changes that just avoid our redirect to /master-status and /rs-status, and explicitly load that page instead.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.6</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.table.jsp</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-6-10 01:00:00" id="22563" opendate="2019-6-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reduce retained jobs for Jenkins pipelines</summary>
      <description>Our jobs are taking up lots of space. Try to help out infra quickly by reducing the number of old builds we keep.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.2.0,2.3.0,2.0.6,2.1.6,1.3.6,1.4.11</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile.GitHub</file>
      <file type="M">dev-support.Jenkinsfile</file>
      <file type="M">dev-support.flaky-tests.run-flaky-tests.Jenkinsfile</file>
      <file type="M">dev-support.flaky-tests.flaky-reporting.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-8-20 01:00:00" id="22609" opendate="2019-6-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[Docs] More detail documentation about "hbase.server.thread.wakefrequency"</summary>
      <description/>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2010-2-24 01:00:00" id="2262" opendate="2010-2-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>ZKW.ensureExists should check for existence</summary>
      <description>The fact that ZKW.ensureExists relies on KeeperException.NodeExistsException creates a lot of chatter in HBase and Zookeeper logs and also confuses users. We should use ZooKeeper.exists instead.</description>
      <version>None</version>
      <fixedVersion>0.20.4,0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2019-8-14 01:00:00" id="22852" opendate="2019-8-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase nightlies leaking gpg-agents</summary>
      <description>FYI, just triggered yetus master, which includes code to find and kill long-running processes still attached to the Jenkins workspace directory. It came up with this:https://builds.apache.org/view/S-Z/view/Yetus/job/yetus-github-multibranch/job/master/134/consoleUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND jenkins 752 0.0 0.0 93612 584 ? Ss Aug12 0:00 gpg-agent --homedir /home/jenkins/jenkins-slave/workspace/HBase_Nightly_HBASE-20952/downloads-hadoop-2/.gpg --use-standard-socket --daemon Killing 752 ***(repeat 10s of times, which slightly different dates, pids, versions, etc)Also, be aware that any other process running on the node (such as the other executor) has extremely easy access to whatever gpg creds you are using...</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.1,2.1.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.jenkins-scripts.cache-apache-project-artifact.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-8-24 01:00:00" id="22911" opendate="2019-8-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>fewer concurrent github PR builds</summary>
      <description>we've been regularly getting 4-5 concurrent builds of PRs.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,2.2.1,2.1.6,1.3.6,1.4.11,2.0.7</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile.GitHub</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-8-24 01:00:00" id="22913" opendate="2019-8-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use Hadoop label for nightly builds</summary>
      <description/>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,2.2.1,2.1.6,1.3.6,1.4.11</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-9-26 01:00:00" id="22927" opendate="2019-8-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade mockito version for Java 11 compatibility</summary>
      <description>Pasting the discussion from HBASE-22534 here:"Currently mockito-core version is at 2.1.0. According to https://github.com/mockito/mockito/blob/release/2.x/doc/release-notes/official.md, looks like Java 11 compatibility was introduced in 2.19+. And 2.23.2 claims to have full java 11 support after byte-buddy fix etc."</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.1.7,2.2.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-shaded.hbase-shaded-with-hadoop-check-invariants.pom.xml</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-shaded.hbase-shaded-check-invariants.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-9-29 01:00:00" id="22945" opendate="2019-8-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Show quota infos in master UI</summary>
      <description>Add a page in master UI to show the following quota infos:if rpc throttle is enabled;if exceed throttle quota is enabled;namespace throtlles;user throttles.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-webapps.master.header.jsp</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.quotas.MasterQuotaManager.java</file>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.quotas.ThrottleSettings.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-9-5 01:00:00" id="22975" opendate="2019-9-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add read and write QPS metrics at server level and table level</summary>
      <description>Use HBase‘s existing class DropwizardMeter to collect read and write QPS. The collected location is the same as metrics readRequestsCount and writeRequestsCount.</description>
      <version>2.2.0,1.4.10</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,1.4.11,2.1.7,2.2.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerTableMetrics.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsTableLatenciesImpl.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-10-12 01:00:00" id="23017" opendate="2019-9-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[Forward-port] Verify the file integrity in persistent IOEngine</summary>
      <description>Verify the persistent cache file integrity before retrieve from persistence file.</description>
      <version>2.2.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.FileMmapIOEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.FileIOEngine.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketProtoUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.java</file>
      <file type="M">hbase-protocol-shaded.src.main.protobuf.BucketCacheEntry.proto</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-9-18 01:00:00" id="23041" opendate="2019-9-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Should not show split parent regions in HBCK report&amp;#39;s unknown server part</summary>
      <description/>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.1.7,2.2.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HbckChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2019-11-23 01:00:00" id="23334" opendate="2019-11-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>The table-lock node of zk is not needed since HBASE-16786</summary>
      <description>The table-lock znode still be created when init,and it may cause confusion.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.3</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-zookeeper.src.main.java.org.apache.hadoop.hbase.zookeeper.ZKWatcher.java</file>
      <file type="M">hbase-client.src.test.java.org.apache.hadoop.hbase.zookeeper.TestZNodePaths.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.zookeeper.ZNodePaths.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2020-1-8 01:00:00" id="23664" opendate="2020-1-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade JUnit to 4.13</summary>
      <description>New JUnit released a week ago. Let's give it a spin.https://github.com/junit-team/junit4/blob/master/doc/ReleaseNotes4.13.md</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2020-3-10 01:00:00" id="23953" opendate="2020-3-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>SimpleBalancer bug when second pass to fill up to min</summary>
      <description/>
      <version>2.2.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.TestDefaultLoadBalancer.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.balancer.BalancerTestBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.balancer.SimpleLoadBalancer.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2020-3-10 01:00:00" id="23954" opendate="2020-3-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>SplitParent region should not be balanced</summary>
      <description>SplitParent region  may be in deadserver .balancer will move region onto these deadserver if SplitParent region participate balancing</description>
      <version>2.2.0</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,2.2.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.assignment.RegionStates.java</file>
    </fixedFiles>
  </bug>
  
  
</bugrepository>