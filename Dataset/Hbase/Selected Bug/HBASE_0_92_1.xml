<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="HBASE">
  
  
  
  <bug fixdate="2011-10-14 01:00:00" id="3444" opendate="2011-1-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Test to prove Bytes.toBytesBinary and Bytes.toStringBinary() is reversible</summary>
      <description>Bytes.toStringBinary() doesn't escape \.Otherwise the transformation isn't reversiblebyte[] a = {'\', 'x' , '0', '0'}Bytes.toBytesBinary(Bytes.toStringBinary(a)) won't be equal to a</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.util.TestBytes.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2011-11-22 01:00:00" id="4851" opendate="2011-11-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>hadoop maven dependency needs to be an optional one</summary>
      <description>Given that HBase 0.92/0.94 is likely to be used with at least 3 different versions of Hadoop (0.20, 0.22 and 0.23) it seems appropriate to make hadoop maven dependencies into optional ones (IOW, the build of HBase will see NO changes in behavior, but any component that has HBase as a dependency will be in control of what version of Hadoop gets used).</description>
      <version>0.92.0,0.92.1,0.94.0</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-6-9 01:00:00" id="5360" opendate="2012-2-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[uberhbck] Add options for how to handle offline split parents.</summary>
      <description>In a recent case, we attempted to repair a cluster that suffered from HBASE-4238 that had about 6-7 generations of "leftover" split data. The hbck repair options in an development version of HBASE-5128 treat HDFS as ground truth but didn't check SPLIT and OFFLINE flags only found in meta. The net effect was that it essentially attempted to merge many regions back into its eldest geneneration's parent's range. More safe guards to prevent "mega-merges" are being added on HBASE-5128.This issue would automate the handling of the "mega-merge" avoiding cases such as "lingering grandparents". The strategy here would be to add more checks against .META., and perform part of the catalog janitor's responsibilities for lingering grandparents. This would potentially include options to sideline regions, deleting grandparent regions, min size for sidelining, and mechanisms for cleaning .META.. Note: There already exists an mechanism to reload these regions &amp;#8211; the bulk loaded mechanisms in LoadIncrementalHFiles can be used to re-add grandparents (automatically splitting them if necessary) to HBase.</description>
      <version>0.90.7,0.92.1,0.94.0</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-3-16 01:00:00" id="5596" opendate="2012-3-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Few minor bugs from HBASE-5209</summary>
      <description>A few leftover bugs from HBASE-5209. Comments are documented here:https://reviews.apache.org/r/3892/</description>
      <version>0.92.1,0.94.0</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ServerName.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.ActiveMasterManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ClusterStatus.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-3-26 01:00:00" id="5638" opendate="2012-3-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Backport to 0.90 and 0.92 - NPE reading ZK config in HBase</summary>
      <description/>
      <version>0.90.6,0.92.1</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKConfig.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.LocalHBaseCluster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-3-27 01:00:00" id="5657" opendate="2012-3-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[book] updating development chapter for 100 chars/line (from 80)</summary>
      <description>Per a recent discussion on the dist-list, updating the max-chars from 80 to 100.Also updating the "long lines" example.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.developer.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-3-29 01:00:00" id="5671" opendate="2012-3-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbase.metrics.showTableName should be true by default</summary>
      <description>HBASE-4768 added per-cf metrics and a new configuration option "hbase.metrics.showTableName". We should switch the conf option to true by default, since it is not intuitive (at least to me) to aggregate per-cf across tables by default, and it seems confusing to report on cf's without table names.</description>
      <version>None</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.resources.hbase-default.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-4-1 01:00:00" id="5694" opendate="2012-4-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>getRowsWithColumnsTs() in Thrift service handles timestamps incorrectly</summary>
      <description>The getRowsWithColumnsTs() method in the Thrift interface only applies the timestamp if columns are explicitly specified. However, this method also allows for columns to be unspecified (this is even used internally to implement e.g. getRows()). The cause of the bug is a minor scoping issue: the time range is set inside a wrong if statement.</description>
      <version>0.92.1</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  <bug fixdate="2012-4-14 01:00:00" id="5792" opendate="2012-4-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HLog Performance Evaluation Tool</summary>
      <description>Related to HDFS-3280 and the HBase WAL slowdown on 0.23+It would be nice to have a simple tool like HFilePerformanceEvaluation, ...to be able to check easily the HLog performance.</description>
      <version>None</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  <bug fixdate="2012-4-25 01:00:00" id="5871" opendate="2012-4-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Usability regression, we don&amp;#39;t parse compression algos anymore</summary>
      <description>It seems that string with 0.92.0 we can't create tables in the shell by specifying "lzo" anymore. I remember we used to do better parsing than that, but right now if you follow the wiki doing this:create 'mytable', {NAME=&gt;'colfam:', COMPRESSION=&gt;'lzo'}You'll get:ERROR: java.lang.IllegalArgumentException: No enum const class org.apache.hadoop.hbase.io.hfile.Compression$Algorithm.lzoBad for usability.</description>
      <version>0.92.1</version>
      <fixedVersion>0.92.2,0.94.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-6-27 01:00:00" id="5892" opendate="2012-4-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbck] Refactor parallel WorkItem* to Futures.</summary>
      <description>This would convert WorkItem* logic (with low level notifies, and rough exception handling) into a more canonical Futures pattern.Currently there are two instances of this pattern (for loading hdfs dirs, for contacting regionservers for assignments, and soon &amp;#8211; for loading hdfs .regioninfo files).</description>
      <version>0.90.6,0.92.1,0.94.0</version>
      <fixedVersion>0.92.2,0.94.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-7-1 01:00:00" id="5909" opendate="2012-5-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>SlabStats should be a daemon thread</summary>
      <description>I had a hanging JVM on shutdown caused by:"Slab Statistics #0" prio=5 tid=7fc0238bc800 nid=0x10dadf000 waiting on condition [10dade000] java.lang.Thread.State: TIMED_WAITING (parking)</description>
      <version>0.92.1</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.slab.SlabCache.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-5-3 01:00:00" id="5930" opendate="2012-5-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Limits the amount of time an edit can live in the memstore.</summary>
      <description>A colleague of mine ran into an interesting issue.He inserted some data with the WAL disabled, which happened to fit in the aggregate Memstores memory.Two weeks later he a had problem with the HDFS cluster, which caused the region servers to abort. He found that his data was lost. Looking at the log we found that the Memstores were not flushed at all during these two weeks.Should we have an option to flush memstores periodically. There are obvious downsides to this, like many small storefiles, etc.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.94.8,0.95.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.FlushRequester.java</file>
      <file type="M">hbase-server.src.test.resources.hbase-site.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestMemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MultiThreadedWriter.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-4-5 01:00:00" id="5946" opendate="2012-5-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thrift Filter Language documentation is inconsistent</summary>
      <description>Syntax: SingleColumnValueFilter(&lt;compare operator&gt;, '&lt;comparator&gt;', '&lt;family&gt;', '&lt;qualifier&gt;), as described here: http://hbase.apache.org/book/thrift.html is not correct.The correct syntax is: SingleColumnValueFilter('&lt;family&gt;', '&lt;qualifier&gt;', &lt;compare operator&gt;, '&lt;comparator&gt;')Also, &lt;comparator&gt; parameter must always contain the comparator, e.g. binary: or binaryprefix: etc. Without it (except PrefixFilter and maybe some other filters) TSocket class throws TTransportException: TSocket read 0 bytes. All examples in section 9.3.1.9. Individual Filter Syntax are written without comparator.There also a typo: in section 9.3.1.9.12 - Family Filter, syntax and example described for QualifierFilter</description>
      <version>0.92.1</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.external.apis.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2008-4-20 01:00:00" id="598" opendate="2008-4-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Loggging, no .log file; all goes into .out</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-5-23 01:00:00" id="600" opendate="2008-4-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Filters have excessive DEBUG logging</summary>
      <description>Downgrade most to trace</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.WhileMatchRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.StopRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.RowFilterSet.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.RegExpRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.PageRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.InclusiveStopRowFilter.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-8-18 01:00:00" id="6052" opendate="2012-5-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Convert .META. and -ROOT- content to pb</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.OfflineMetaRebuildTestCore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestSerialization.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestGetClosestAtOrBefore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestEndToEndSplitTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.migration.TestMigrationFrom090To092.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestZKBasedOpenCloseRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterTransitions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.Mocking.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMetaMigrationRemovingHTD.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.catalog.TestMetaReaderEditorNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.catalog.TestCatalogTracker.java</file>
      <file type="M">hbase-server.src.main.ruby.hbase.table.rb</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.Writables.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.MetaUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.Merge.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HMerge.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsckRepair.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.migration.HRegionInfo090x.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Result.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.MetaScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.catalog.MetaReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.catalog.MetaMigrationRemovingHTD.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.catalog.MetaEditor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-server.src.test.data.hbase-4388-root.dir.tgz</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-2-18 01:00:00" id="6055" opendate="2012-5-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Offline Snapshots in HBase 0.96</summary>
      <description>Continuation of HBASE-50 for the current trunk. Since the implementation has drastically changed, opening as a new ticket.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.CheckedArchivingHFileCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.FileCleanerDelegate.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.CleanerChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.BaseLogCleanerDelegate.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.example.LongTermArchivingHFileCleaner.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-5-21 01:00:00" id="6061" opendate="2012-5-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix ACL "Admin" Table inconsistent permission check</summary>
      <description>the requirePermission() check for "admin" operation on a table is currently inconsistent.Table Owner with CREATE rights (that means, the owner has created that table) can enable/disable and delete the table but needs ADMIN rights to add/remove/modify a column.</description>
      <version>0.92.1,0.94.0,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-5-21 01:00:00" id="6062" opendate="2012-5-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>preCheckAndPut/Delete() checks for READ when also a WRITE is performed</summary>
      <description>preCheckAndPut() and preCheckAndDelete() checks for READ when they also want to WRITE... for me checking for WRITE permission is the right thing... what do you say about that? keep READ, replace with WRITE?</description>
      <version>0.92.1,0.94.0,0.95.2</version>
      <fixedVersion>0.92.2,0.94.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-5-24 01:00:00" id="6089" opendate="2012-5-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>SSH and AM.joinCluster causes Concurrent Modification exception.</summary>
      <description>AM.regions map is parallely accessed in SSH and Master initialization leading to ConcurrentModificationException.</description>
      <version>0.92.1,0.94.0</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-6-11 01:00:00" id="6200" opendate="2012-6-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>KeyComparator.compareWithoutRow can be wrong when families have the same prefix</summary>
      <description>As reported by Desert Rose on IRC and on the ML, Result has a weird behavior when some families share the same prefix. He posted a link to his code to show how it fails, http://pastebin.com/7TBA1XGhBasically KeyComparator.compareWithoutRow doesn't differentiate families and qualifiers so "f:a" is said to be bigger than "f1:", which is false. Then what happens is that the KVs are returned in the right order from the RS but then doing Result.binarySearch it uses KeyComparator.compareWithoutRow which has a different sorting so the end result is undetermined.I added some debug and I can see that the data is returned in the right order but Arrays.binarySearch returned the wrong KV, which is then verified agains the passed family and qualifier which fails so null is returned.I don't know how frequent it is for users to have families with the same prefix, but those that do have that and that use those families at the same time will have big correctness issues. This is why I mark this as a blocker.</description>
      <version>0.90.6,0.92.1,0.94.0</version>
      <fixedVersion>0.92.2,0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestKeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-7-3 01:00:00" id="6313" opendate="2012-7-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Client hangs because the client is not notified</summary>
      <description>If the call first remove from the calls, when some exception happened in reading from the DataInputStream, the call will not be notified, cause the client hangs.</description>
      <version>0.92.1,0.94.0</version>
      <fixedVersion>0.92.2,0.94.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseClient.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-9-4 01:00:00" id="6327" opendate="2012-7-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HLog can be null when create table</summary>
      <description>As HBASE-4010 discussed, the HLog can be null.We have meet createTable failed because the no use hlog.When createHReagion, the HLog.LogSyncer is run sync(), in under layer it call the DFSClient.DFSOutputStream.sync(). Then the hlog.closeAndDelete() was called，firstly the HLog.close() will interrupt the LogSyncer, and interrupt DFSClient.DFSOutputStream.sync().The DFSClient.DFSOutputStream will store the exception and throw it when we called DFSClient.close(). The HLog.close() call the writer.close()/DFSClient.close() after interrupt the LogSyncer. And there is no catch exception for the close().So the Master throw exception to the client. There is no need to throw this exception, further， the hlog is no use.Our cluster is 0.90, the logs is attached, after "closing hlog writer", there is no log for the createTable().The trunk and 0.92, 0.94, we used just one hlog, and if the exception happends, the client will got createTable failed, but indeed ,we expect all the regions for the table can also be assigned.I will give the patch for this later.</description>
      <version>None</version>
      <fixedVersion>0.94.4,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.CreateTableHandler.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-7-6 01:00:00" id="6336" opendate="2012-7-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Split point should not be equal to start row or end row</summary>
      <description>Should we allow split point equal with region's start row or end row?// if the midkey is the same as the first and last keys, then we cannot // (ever) split this region. if (this.comparator.compareRows(mk, firstKey) == 0 &amp;&amp; this.comparator.compareRows(mk, lastKey) == 0) { if (LOG.isDebugEnabled()) { LOG.debug("cannot split because midkey is the same as first or " + "last row"); }Here, I think it is a mistake.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-7-24 01:00:00" id="6450" opendate="2012-7-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase startup should be with MALLOC_MAX_ARENA set</summary>
      <description>I think we should do the same as what HADOOP-7154 has done in terms of starting up daemons with MALLOC_MAX_ARENA set. I recently noticed that there were RS crashes on RHEL6 due to memory (could be avoided by setting MALLOC_MAX_ARENA).</description>
      <version>0.92.1</version>
      <fixedVersion>0.92.2,0.94.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase-config.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-8-2 01:00:00" id="6502" opendate="2012-8-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Typo in loaded coprocessors on master status page</summary>
      <description>The master status Web UI page says:"Coprocessors currently loaded loaded by the master"Should be one "loaded" there.</description>
      <version>0.92.1</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-9-24 01:00:00" id="6659" opendate="2012-8-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Port HBASE-6508 Filter out edits at log split time</summary>
      <description>HBASE-6508 is for 0.89-fb branch.This JIRA ports the feature to trunk.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLogSplit.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLogFiltering.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">hbase-server.src.main.protobuf.RegionServerStatus.proto</file>
      <file type="M">hbase-server.src.main.protobuf.hbase.proto</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitLogWorker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.RegionLoad.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.ResponseConverter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-9-21 01:00:00" id="6853" opendate="2012-9-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>IllegalArgumentException is thrown when an empty region is splitted</summary>
      <description>This is w.r.t a mail sent in the dev mail list.Empty region split should be handled gracefully. Either we should not allow the split to happen if we know that the region is empty or we should allow the split to happen by setting the no of threads to the thread pool executor as 1.int nbFiles = hstoreFilesToSplit.size();ThreadFactoryBuilder builder = new ThreadFactoryBuilder(); builder.setNameFormat("StoreFileSplitter-%1$d"); ThreadFactory factory = builder.build(); ThreadPoolExecutor threadPool = (ThreadPoolExecutor) Executors.newFixedThreadPool(nbFiles, factory); List&lt;Future&lt;Void&gt;&gt; futures = new ArrayList&lt;Future&lt;Void&gt;&gt;(nbFiles);Here the nbFiles needs to be a non zero positive value.</description>
      <version>0.92.1,0.94.1</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-10-2 01:00:00" id="6917" opendate="2012-10-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Trunk jdk7 build broke because we moved to zk 3.4.4</summary>
      <description>Chatted w/ Mahadev and he confirmed issues running 3.4.4 w/ jdk7. Will be fixed in zk3.4.5.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-4-10 01:00:00" id="6969" opendate="2012-10-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow for injecting MiniZookeeperCluster instance</summary>
      <description>While not an official part of the HBase API, it'd be nice if HBaseTestingUtility allowed for consumer to inject their own instance of the MiniZookeeperCluster when executing tests.Currently there is no way to control how the ZK instance is started which we've had to hack around when there were ZK version conflicts (3.3 vs 3.4). Or if you want to control which specific port it starts on vs random.Allowing consumers to inject an instance (unstarted) gives them the freedom to implement their own without having to fork the entire HBaseTestingUtility class</description>
      <version>0.92.1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.ruby.shell.commands.list.rb</file>
      <file type="M">hbase-server.src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-10-11 01:00:00" id="6977" opendate="2012-10-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Multithread processing ZK assignment events</summary>
      <description>Related to HBASE-6976 and HBASE-6611. ZK events processing is a bottle neck for assignments, since there is only one ZK event thread. If we can use multiple threads, it should be better.With multiple threads, the order of events could be messed up. However, if we pass all events related to one region always to the same worker thread, the order should be kept.We need to play with it and find out how much performance imrovement we can get.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.OfflineCallback.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-10-11 01:00:00" id="6979" opendate="2012-10-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>recovered.edits file should not break distributed log splitting</summary>
      <description>Distributed log splitting fails in creating the recovered.edits folder during upgrade because there is a file called recovered.edits there.Instead of checking if the patch exists, we need to check if it exists and is a path.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLogSplit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-12-4 01:00:00" id="7274" opendate="2012-12-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable JMX metrics collection for REST Server</summary>
      <description>REST server should accept JMX options.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.hbase-env.sh</file>
      <file type="M">bin.hbase-config.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-12-5 01:00:00" id="7277" opendate="2012-12-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thrift default JMX port should be 10103 instead of 8093</summary>
      <description>HBASE-5879 set Thrift JMX port to 8093. In conf/hbase-env.sh, the default one is 10103</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase-config.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-3-1 01:00:00" id="7975" opendate="2013-3-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>ImportTsv documentation update for table creation</summary>
      <description>HBASE-5741 updated ImportTsv to create the target table if it doesn't exist. This ticket updates the documentation as appropriate.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-4-24 01:00:00" id="8427" opendate="2013-4-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Apache Rat is incorrectly excluding test source files</summary>
      <description>HBASE-5524 added &amp;#42;&amp;#42;/test/&amp;#42;&amp;#42; as a rat exclude. This unfortunately excludes directories like hbase-it/src/test/* from the rat checks and has allowed a few unit tests to get in without proper licenses. Tightening it to only the directory HBASE-5524 was concerned about (and fixing files with non-compliant licenses)</description>
      <version>0.92.1,0.94.0</version>
      <fixedVersion>0.98.0,0.94.7,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-8-10 01:00:00" id="8913" opendate="2013-7-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove ".replogs" reference as we no longer use it</summary>
      <description>Code has a single reference remaining of .replogs, that we can now remove as we do not use that dir nor create it anymore.Previous desc:The /hbase/ dir can also have .replogs under it, which isn't accounted for during Master's check for user-table dirs, and we end up receiving warnings for missing .tableinfo files under it.</description>
      <version>0.92.1</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSink.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2013-7-10 01:00:00" id="8916" opendate="2013-7-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Optimize usage of Jackson&amp;#39;s ObjectMapper</summary>
      <description>ObjectMapper is fully thread-safe and "relatively" expensive to build. As such it is recommended to share an instance where possible.I'll attach a patch that fixes every instance of ObjectMapper usage to use a private static field instead.</description>
      <version>None</version>
      <fixedVersion>0.95.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogPrettyPrinter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.MonitoredTaskImpl.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Operation.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-7-10 01:00:00" id="8918" opendate="2013-7-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Removes redundant identifiers from interfaces</summary>
      <description>A lot of interfaces in HBase's source have things like "public" or "abstract" modifiers which make no sense. They add to visual clutter, generate warnings in lots of IDEs and serve no purpose.This is a patch that just removes them all. I understand that it's touching a lot of files etc. Your call if you want this kind of patch.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.constraint.Constraint.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.token.TestTokenAuthentication.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.rest.PerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestSplitLogManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.io.hfile.RandomDistribution.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestCase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.RegionSplitter.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.ModifyRegionUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.KeyRange.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.CancelableProgressable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.Canary.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.IncrementCoalescerMBean.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.TableDescriptors.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.CodeToClassAndBackFor96Migration.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.ProtobufMessageHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.rest.Constants.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.WALActionsListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.Dictionary.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.StoreConfigInformation.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitLogWorker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ReplicationSourceService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ReplicationSinkService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ReplicationService.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.OnlineRegions.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.LeaseListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.LastSequenceId.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.KeyValueScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.InternalScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.DeleteTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.CompactionRequestor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.ColumnTracker.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.SubprocedureFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ProcedureMemberRpcs.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.procedure.ProcedureCoordinatorRpcs.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.MonitoredTask.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.monitoring.MonitoredRPCHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableLockManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.SnapshotSentinel.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.LoadBalancer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.TotesHRegionInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.ClusterStatusPublisher.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.FileCleanerDelegate.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServerInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseRPCErrorHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.Delayable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.WritableWithSize.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.CacheableDeserializer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.Cacheable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.io.hfile.BlockCache.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.InterProcessReadWriteLock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.InterProcessLock.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.fs.HFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.executor.EventHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.errorhandling.ForeignExceptionSnare.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.errorhandling.ForeignExceptionListener.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.WALCoprocessorEnvironment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorService.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.Abortable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.catalog.MetaReader.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.AsyncProcess.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Attributes.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ClusterStatusListener.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.coprocessor.Batch.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.HTableInterface.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MasterAdminKeepAliveConnection.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.MetaScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.ResultScanner.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.Row.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.Coprocessor.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.CoprocessorEnvironment.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationPeers.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueues.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueuesClient.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.Server.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.Stoppable.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.util.PoolMap.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.codec.Codec.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.CompoundConfiguration.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.DataBlockEncoder.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.HFileBlockDecodingContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.encoding.HFileBlockEncodingContext.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.HeapSize.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.Bytes.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.ClassFinder.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.Waiter.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.master.MetricsMasterSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.metrics.BaseSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionAggregateSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.MetricsRegionSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.wal.MetricsEditsReplaySource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.regionserver.wal.MetricsWALSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.replication.regionserver.MetricsReplicationSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.rest.MetricsRESTSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.thrift.MetricsThriftServerSource.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.thrift.MetricsThriftServerSourceFactory.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.metrics2.MetricHistogram.java</file>
      <file type="M">hbase-hadoop-compat.src.test.java.org.apache.hadoop.hbase.HadoopShims.java</file>
      <file type="M">hbase-hadoop-compat.src.test.java.org.apache.hadoop.hbase.test.MetricsAssertHelper.java</file>
      <file type="M">hbase-prefix-tree.src.test.java.org.apache.hadoop.hbase.codec.prefixtree.builder.TestTokenizerData.java</file>
      <file type="M">hbase-prefix-tree.src.test.java.org.apache.hadoop.hbase.codec.prefixtree.column.TestColumnData.java</file>
      <file type="M">hbase-prefix-tree.src.test.java.org.apache.hadoop.hbase.codec.prefixtree.row.TestRowData.java</file>
      <file type="M">hbase-prefix-tree.src.test.java.org.apache.hadoop.hbase.codec.prefixtree.timestamp.TestTimestampData.java</file>
    </fixedFiles>
  </bug>
</bugrepository>