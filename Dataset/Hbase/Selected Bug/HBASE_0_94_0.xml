<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="HBASE">
  
  
  
  
  <bug fixdate="2017-5-15 01:00:00" id="18049" opendate="2017-5-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>It is not necessary to re-open the region when MOB files cannot be found</summary>
      <description>In HBASE-17712, we try to re-open the region when store files cannot be found. This is useful for store files in a region, but is not necessary when the MOB files cannot be found, because the store files in a region only contain the references to the MOB files and a re-open of a region doesn't help the lost MOB files.In this JIRA, we will directly throw DNRIOE only when the MOB files are not found in MobStoreScanner and ReversedMobStoreScanner. Other logics keep the same.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HMobStore.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  
  
  <bug fixdate="2011-9-21 01:00:00" id="4454" opendate="2011-9-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add failsafe plugin to build and rename integration tests</summary>
      <description>Add the maven-failsafe-plugin to the build process so we can run integration tests with "mvn verify". This will also involve a renaming of integration tests to conform to a new integration test regex.This is a stopgap measure while we until break them out into their own module.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.developer.xml</file>
      <file type="M">pom.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2011-10-29 01:00:00" id="4510" opendate="2011-9-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Check and workaround usage of internal HDFS APIs in HBase</summary>
      <description>HBase isn't seemingly compiling anymore on 0.23 after the HDFS-1620 naming refactorings were carried out.Two solutions: We use new classnames. This breaks HBase's backward compatibility with older Hadoop releases (is that a concern with future releases?) HBase gets its own sets of constants as the upstream one is not marked for public usage. This needs a little more maintenance on HBases' side.</description>
      <version>0.94.0</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.FSHDFSUtils.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-11-12 01:00:00" id="4583" opendate="2011-10-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Integrate RWCC with Append and Increment operations</summary>
      <description>Currently Increment and Append operations do not work with RWCC and hence a client could see the results of multiple such operation mixed in the same Get/Scan.The semantics might be a bit more interesting here as upsert adds and removes to and from the memstore.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestAtomicOperation.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MemStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-10-13 01:00:00" id="4588" opendate="2011-10-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>The floating point arithmetic to validate memory allocation configurations need to be done as integers</summary>
      <description>The floating point arithmetic to validate memory allocation configurations need to be done as integers.On our cluster, we had block cache = 0.6 and memstore = 0.2. It was saying this was &gt; 0.8 when it is actually equal.Minor bug but annoying nonetheless.</description>
      <version>0.92.0,0.94.0</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HBaseConfiguration.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-12-17 01:00:00" id="4605" opendate="2011-10-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Constraints</summary>
      <description>From Jesse's comment on dev:What I would like to propose is a simple interface that people can use to implement a 'constraint' (matching the classic database definition). This would help ease of adoption by helping HBase more easily check that box, help minimize code duplication across organizations, and lead to easier adoption.Essentially, people would implement a 'Constraint' interface for checking keys before they are put into a table. Puts that are valid get written to the table, but if not people can will throw an exception that gets propagated back to the client explaining why the put was invalid.Constraints would be set on a per-table basis and the user would be expected to ensure the jars containing the constraint are present on the machines serving that table.Yes, people could roll their own mechanism for doing this via coprocessors each time, but this would make it easier to do so, so you only have to implement a very minimal interface and not worry about the specifics.</description>
      <version>0.94.0</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
      <file type="M">src.docbkx.book.xml</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.constraint.WorksConstraint.java.orig</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.constraint.TestConstraints.java.orig</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.constraint.TestConstraint.java.orig</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.constraint.RuntimeFailConstraint.java.orig</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.constraint.CheckConfigurationConstraint.java.orig</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.constraint.AllPassConstraint.java.orig</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.constraint.AllFailConstraint.java.orig</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.constraint.package-info.java.orig</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.constraint.Constraints.java.orig</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.constraint.ConstraintProcessor.java.orig</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.constraint.ConstraintException.java.orig</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.constraint.Constraint.java.orig</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.constraint.BaseConstraint.java.orig</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-10-17 01:00:00" id="4606" opendate="2011-10-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove spam in HCM and fix a list.size == 0</summary>
      <description>As discussed on the ML, HCM in 0.92 is being spammy with "expecting X results" which is a debug leftover. Also right next to it I see a list.size == 0, which should be converted into isEmpty.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-10-19 01:00:00" id="4629" opendate="2011-10-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>enable automated patch testing for hbase</summary>
      <description>enable jenkins automated patch testing for hbase project</description>
      <version>None</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-10-20 01:00:00" id="4642" opendate="2011-10-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add Apache License Header</summary>
      <description>executing mvn apache-rat:check fails with &amp;#91;ERROR&amp;#93; Failed to execute goal org.apache.rat:apache-rat-plugin:0.6:check (default-cli) on project hbase: Too many unapproved licenses: 84 -&gt; &amp;#91;Help 1&amp;#93;org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.rat:apache-rat-plugin:0.6:check (default-cli) on project hbase: Too many unapproved licenses: 84there are about 70 + files which are missing the Apache License Headers and rest of them should be added to the exclude list.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.set.meta.memstore.size.rb</file>
      <file type="M">bin.set.meta.block.caching.rb</file>
      <file type="M">bin.local-regionservers.sh</file>
      <file type="M">bin.local-master-backup.sh</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2011-12-28 01:00:00" id="4698" opendate="2011-10-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Let the HFile Pretty Printer print all the key values for a specific row.</summary>
      <description>When using HFile Pretty Printer to debug HBase issues, it would very nice to allow the Pretty Printer to seek to a specific row, and only print all the key values for this row.</description>
      <version>None</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-10-28 01:00:00" id="4699" opendate="2011-10-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cleanup the UIs</summary>
      <description>UIs have had a bunch of stuff dumped into them of late. Its all good stuff its just not sitting nicely in the web page. Fix.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.resources.hbase-webapps.static.hbase.css</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HServerLoad.java</file>
      <file type="M">src.main.jamon.org.apache.hbase.tmpl.regionserver.RSStatusTmpl.jamon</file>
      <file type="M">src.main.jamon.org.apache.hbase.tmpl.master.MasterStatusTmpl.jamon</file>
      <file type="M">src.main.jamon.org.apache.hbase.tmpl.common.TaskMonitorTmpl.jamon</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2011-11-2 01:00:00" id="4734" opendate="2011-11-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[bulk load] Warn if bulk load directory contained no files</summary>
      <description>Bulk load exits if no files are found in the specified directory. This can happen if a directory has been bulk loaded already (bulk load renames/moves files). It would be good to provide some sort of warning when this happens.</description>
      <version>0.90.5,0.92.0,0.94.0</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-8-3 01:00:00" id="4744" opendate="2011-11-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove @Ignore for testLogRollAfterSplitStart</summary>
      <description>We fixed a data loss bug in HBASE-2312 by adding non-recursive creates to HDFS. Although a number of HDFS versions have this fix, the official HDFS 0.20.205 branch currently doesn't, so we needed to mark the test as ignored. Please revisit before the RC of 0.94, which should have 0.20.205.1 or later &amp; the necessary HDFS patches.</description>
      <version>0.94.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestLogRollAbort.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLogSplit.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2011-11-4 01:00:00" id="4747" opendate="2011-11-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade maven surefire plugin to 2.10</summary>
      <description>Quite often, we see the following when running unit tests:Running org.apache.hadoop.hbase.master.TestMasterFailoverException in thread "ThreadedStreamConsumer" java.lang.OutOfMemoryError: Java heap space at java.util.Arrays.copyOf(Arrays.java:2882) at java.lang.AbstractStringBuilder.expandCapacity(AbstractStringBuilder.java:100) at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:390) at java.lang.StringBuffer.append(StringBuffer.java:224) at org.apache.maven.surefire.report.TestSetRunListener.getAsString(TestSetRunListener.java:201) at org.apache.maven.surefire.report.TestSetRunListener.testError(TestSetRunListener.java:139) at org.apache.maven.plugin.surefire.booterclient.output.ForkClient.consumeLine(ForkClient.java:112) at org.apache.maven.plugin.surefire.booterclient.output.ThreadedStreamConsumer$Pumper.run(ThreadedStreamConsumer.java:67) at java.lang.Thread.run(Thread.java:680)This was due to https://jira.codehaus.org/browse/SUREFIRE-754 which has been fixed in surefire 2.10We should upgrade to version 2.10</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-11-8 01:00:00" id="4759" opendate="2011-11-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Migrate from JUnit 4.8.2 to JUnit 4.10</summary>
      <description>Rationale: better to stay up to date we're going to start Categories, there are bug fixes around this in the last releases</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-11-8 01:00:00" id="4761" opendate="2011-11-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add Developer Debug Options to HBase Config</summary>
      <description>Add in optional HBase configuration options that core developers will commonly use: an option to enable JDWP debugging &amp; an option to use a separate logfile for GC information. (Part of the effort to move 89-fb features over to trunk)</description>
      <version>0.94.0</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.hbase-env.sh</file>
      <file type="M">bin.stop-hbase.sh</file>
      <file type="M">bin.hbase-daemon.sh</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2011-11-16 01:00:00" id="4801" opendate="2011-11-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>alter_status shell prints sensible message at completion</summary>
      <description>The alter_status command used to print 0/0 once an alter operation had completed and its progress was no longer available. Now it instad indicates that all regions were updated.</description>
      <version>0.94.0</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.ruby.hbase.admin.rb</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2011-11-18 01:00:00" id="4820" opendate="2011-11-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Distributed log splitting coding enhancement to make it easier to understand, no semantics change</summary>
      <description>In reviewing distributed log splitting feature, we found some cosmetic issues. They make the code hard to understand.It will be great to fix them. For this issue, there should be no semantic change.</description>
      <version>0.92.0,0.94.0</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestSplitLogManager.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.SplitLogWorker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-11-19 01:00:00" id="4829" opendate="2011-11-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix javadoc warnings in 0.92 branch</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKLeaderManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.FSUtils.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.security.User.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormat.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ipc.RequestContext.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.Result.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.catalog.CatalogTracker.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2011-11-22 01:00:00" id="4851" opendate="2011-11-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>hadoop maven dependency needs to be an optional one</summary>
      <description>Given that HBase 0.92/0.94 is likely to be used with at least 3 different versions of Hadoop (0.20, 0.22 and 0.23) it seems appropriate to make hadoop maven dependencies into optional ones (IOW, the build of HBase will see NO changes in behavior, but any component that has HBase as a dependency will be in control of what version of Hadoop gets used).</description>
      <version>0.92.0,0.92.1,0.94.0</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-12-23 01:00:00" id="4859" opendate="2011-11-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Correctly PreWarm HBCK ThreadPool</summary>
      <description>See description at HBASE-3553. We had a patch ready for this in HBASE-3620 but never applied it publicly. Testing showed massive speedup in HBCK, especially when RegionServers were down or had long response times.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-11-24 01:00:00" id="4861" opendate="2011-11-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix some misspells and extraneous characters in logs; set some to TRACE</summary>
      <description>Some small clean up in logs.</description>
      <version>None</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.BloomFilterFactory.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.SplitRegionHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFileReaderV2.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.catalog.MetaEditor.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2011-11-28 01:00:00" id="4886" opendate="2011-11-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>truncate fails in HBase shell</summary>
      <description>Seeing this in trunk:hbase(main):001:0&gt; truncate 'table'Truncating 'table' table (it may take a while):ERROR: wrong number of arguments (1 for 3)Here is some help for this command: Disables, drops and recreates the specified table.... caused by the removal of the HTable(String) constructor.</description>
      <version>0.94.0</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.ruby.hbase.admin.rb</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2011-12-7 01:00:00" id="4974" opendate="2011-12-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove some resources leaks on the tests</summary>
      <description>Cf. title and HBASE-4965</description>
      <version>0.94.0</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.rest.TestScannersWithFilters.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2011-12-9 01:00:00" id="4993" opendate="2011-12-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Performance regression in minicluster creation</summary>
      <description>Side effect of 4610: the mini cluster needs 4,5 seconds to start</description>
      <version>0.94.0</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.resources.hbase-site.xml</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.ServerManager.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2011-1-14 01:00:00" id="5030" opendate="2011-12-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Some tests do not close the HFile.Reader they use, leaving some file descriptors open</summary>
      <description/>
      <version>0.94.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.TestHalfStoreFileReader.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.hfile.TestSeekTo.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.hfile.TestReseekTo.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFilePerformance.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.hfile.TestHFileBlockIndex.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  <bug fixdate="2012-8-3 01:00:00" id="5115" opendate="2012-1-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change HBase "color" from purple to "International Orange (Engineering)"</summary>
      <description>See http://en.wikipedia.org/wiki/International_orange See the bit about the color of the golden gate bridge.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.resources.images.hbase.small.gif</file>
      <file type="M">src.site.resources.images.hbase.logo.med.gif</file>
      <file type="M">src.site.resources.images.hbase.logo.png</file>
      <file type="M">src.site.resources.images.favicon.ico</file>
      <file type="M">src.main.resources.hbase-webapps.static.hbase.logo.png</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-1-9 01:00:00" id="5150" opendate="2012-1-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Failure in a thread may not fail a test, clean up log splitting test</summary>
      <description>This is to clean up some tests for HBASE-5081. The Assert.fail method in a separate thread will terminate the thread, but may not fail the test.We can use callable, so that we can get the error in getting the result. Some documentation to explain the test will be helpful too.</description>
      <version>0.94.0</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestSplitLogManager.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-1-9 01:00:00" id="5152" opendate="2012-1-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Region is on service before completing initialization when doing rollback of split, it will affect read correctness</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.92.0,0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-2-13 01:00:00" id="5195" opendate="2012-1-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[Coprocessors] preGet hook does not allow overriding or wrapping filter on incoming Get</summary>
      <description>Without the ability to wrap the internal Scan on the Get, we can't override (or protect, in the case of access control) Gets as we can Scans. The result is inconsistent behavior.</description>
      <version>0.92.0,0.94.0</version>
      <fixedVersion>0.92.1,0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-3-16 01:00:00" id="5206" opendate="2012-1-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Port HBASE-5155 to 0.92, 0.94, and TRUNK</summary>
      <description>This JIRA ports HBASE-5155 (ServerShutDownHandler And Disable/Delete should not happen parallely leading to recreation of regions that were deleted) to 0.92 and TRUNK</description>
      <version>0.92.2,0.94.0,0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.TestDrainingServer.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.zookeeper.TestZKTable.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestMasterRestartAfterDisablingTable.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestMaster.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.client.TestAdmin.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ZKTable.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.handler.DeleteTableHandler.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-1-25 01:00:00" id="5278" opendate="2012-1-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase shell script refers to removed "migrate" functionality</summary>
      <description>$ hbase migrateException in thread "main" java.lang.NoClassDefFoundError: org/apache/hadoop/hbase/util/MigrateCaused by: java.lang.ClassNotFoundException: org.apache.hadoop.hbase.util.Migrateat java.net.URLClassLoader$1.run(URLClassLoader.java:202)at java.security.AccessController.doPrivileged(Native Method)at java.net.URLClassLoader.findClass(URLClassLoader.java:190)at java.lang.ClassLoader.loadClass(ClassLoader.java:306)at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)at java.lang.ClassLoader.loadClass(ClassLoader.java:247)Could not find the main class: org.apache.hadoop.hbase.util.Migrate. Program will exit.The 'hbase' shell script has docs referring to a 'migrate' command which no longer exists.</description>
      <version>0.90.5,0.92.0,0.94.0</version>
      <fixedVersion>0.92.1,0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-2-2 01:00:00" id="5318" opendate="2012-2-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support Eclipse Indigo</summary>
      <description>The current 'standard' release of Eclipse (indigo) comes with m2eclipse installed. However, as of m2e v1.0, "interesting lifecycle phases" are now handled via a 'connector'. However, several of the plugins we use don't support connectors. This means that eclipse bails out and won't build the project or view it as 'working' even though it builds just fine from the the command line.Since Eclipse is one of the major java IDEs and that Indigo has been around for a while, we should make it easy to for new devs to pick up the code and for older devs to upgrade painlessly. The original build should not be modified in any significant way.</description>
      <version>0.94.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-6-9 01:00:00" id="5360" opendate="2012-2-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[uberhbck] Add options for how to handle offline split parents.</summary>
      <description>In a recent case, we attempted to repair a cluster that suffered from HBASE-4238 that had about 6-7 generations of "leftover" split data. The hbck repair options in an development version of HBASE-5128 treat HDFS as ground truth but didn't check SPLIT and OFFLINE flags only found in meta. The net effect was that it essentially attempted to merge many regions back into its eldest geneneration's parent's range. More safe guards to prevent "mega-merges" are being added on HBASE-5128.This issue would automate the handling of the "mega-merge" avoiding cases such as "lingering grandparents". The strategy here would be to add more checks against .META., and perform part of the catalog janitor's responsibilities for lingering grandparents. This would potentially include options to sideline regions, deleting grandparent regions, min size for sidelining, and mechanisms for cleaning .META.. Note: There already exists an mechanism to reload these regions &amp;#8211; the bulk loaded mechanisms in LoadIncrementalHFiles can be used to re-add grandparents (automatically splitting them if necessary) to HBase.</description>
      <version>0.90.7,0.92.1,0.94.0</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  <bug fixdate="2012-2-22 01:00:00" id="5439" opendate="2012-2-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix some performance findbugs issues</summary>
      <description>Given 0.94 is the "performance" release, I took a look at some performance findbugs.This patch should fixeall of the following types of findbugs (except one case in generated code):Bug type DM_NUMBER_CTORBug type DM_STRING_CTORBug type DM_BOOLEAN_CTOR(these are simple constructor issues where Type.valueOf is more efficientFixes one of:Bug type SIC_INNER_SHOULD_BE_STATIC (Inner class should be static)</description>
      <version>0.94.0</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.MasterSchemaChangeTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.SplitLogManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.DefaultLoadBalancer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.ImportTsv.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.slab.SlabCache.java</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2012-9-7 01:00:00" id="5536" opendate="2012-3-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make it clear that hbase 0.96 requires hadoop 1.0.0 at least; we will no longer work on older versions</summary>
      <description>Looks like there is pretty much consensus that depending on 1.0.0 in 0.96 should be fine? See http://search-hadoop.com/m/dSbVW14EsUb2/discuss+0.96&amp;subj=RE+DISCUSS+Have+hbase+require+at+least+hadoop+1+0+0+in+hbase+0+96+0+</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.configuration.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-3-13 01:00:00" id="5574" opendate="2012-3-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>DEFAULT_MAX_FILE_SIZE defaults to a negative value</summary>
      <description>HBASE-4365 changed the value of DEFAULT_MAX_FILE_SIZE from 256MB to 10G. Here is the line of code:public static final long DEFAULT_MAX_FILE_SIZE = 10 * 1024 * 1024 * 1024;The problem is that java evaluates the constant as an int which wraps and gets assigned to a long. I verified this with a test. The quick fix is to change the end to 1024L;</description>
      <version>0.94.0</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-4-14 01:00:00" id="5577" opendate="2012-3-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>improve &amp;#39;patch submission&amp;#39; section in HBase book</summary>
      <description>Improve patch section in the book http://hbase.apache.org/book/submitting.patches.html</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.developer.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2008-4-3 01:00:00" id="559" opendate="2008-4-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>MR example job to count table rows</summary>
      <description>The Lars' import is a little messy; he's not sure how many records were imported. Running a select takes a couple of hours. He happens to have an idle MR cluster standing by. An example MR job that just did a count of records would be generally useful. Could even output row keys so you'd have a list of what made it in. Later, if this tool becomes popular with derivatives and similiars, we can bundle a jar of MR jobs to run against your tables that can answer common queries and that are amenable to subclassing/modification.</description>
      <version>None</version>
      <fixedVersion>0.1.2,0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.package-info.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-3-16 01:00:00" id="5596" opendate="2012-3-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Few minor bugs from HBASE-5209</summary>
      <description>A few leftover bugs from HBASE-5209. Comments are documented here:https://reviews.apache.org/r/3892/</description>
      <version>0.92.1,0.94.0</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ServerName.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.ActiveMasterManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.ClusterStatus.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-4-20 01:00:00" id="5604" opendate="2012-3-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>M/R tool to replay WAL files</summary>
      <description>Just an idea I had. Might be useful for restore of a backup using the HLogs.This could an M/R (with a mapper per HLog file).The tool would get a timerange and a (set of) table(s). We'd pick the right HLogs based on time before the M/R job is started and then have a mapper per HLog file.The mapper would then go through the HLog, filter all WALEdits that didn't fit into the time range or are not any of the tables and then uses HFileOutputFormat to generate HFiles.Would need to indicate the splits we want, probably from a live table.</description>
      <version>None</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.mapreduce.TestWALPlayer.java</file>
      <file type="M">src.docbkx.ops.mgt.xml</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2012-4-3 01:00:00" id="5704" opendate="2012-4-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBASE-4398 mistakenly rolled back on trunk</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.HRegionPartitioner.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-4-3 01:00:00" id="5707" opendate="2012-4-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move clusterid and clusterup (shutdown) znodes over to pb</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.protobuf.ZooKeeper.proto</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.RootRegionTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ClusterStatusTracker.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.zookeeper.ClusterId.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  <bug fixdate="2012-4-4 01:00:00" id="5719" opendate="2012-4-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enhance hbck to sideline overlapped mega regions</summary>
      <description>If there are too many regions in one overlapped group (by default, more than 10), hbck currently doesn't merge them since it takes time.In this case, we can sideline some regions in the group and break the overlapping to fix the inconsistency. Later on, sidelined regions can be bulk loaded manually.</description>
      <version>0.94.0,0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.util.TestRegionSplitCalculator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.RegionSplitCalculator.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-4-5 01:00:00" id="5721" opendate="2012-4-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update bundled hadoop to be 1.0.2 (it was just released)</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.94.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2012-4-12 01:00:00" id="5772" opendate="2012-4-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unable to open the few links in http://hbase.apache.org/</summary>
      <description>Few links in http://hbase.apache.org/ is not working. For example, Ref Guide (multi-page) will actually link to http://hbase.apache.org/book/book.html and if I try to open this, Page not found error is coming.If I add /book in the url, like http://hbase.apache.org/book/book/book.html, it is taking me to the Apache HBase Reference Guide I think the folder structure has been changed.</description>
      <version>0.94.0</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.resources.css.site.css</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-4-13 01:00:00" id="5784" opendate="2012-4-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable mvn deploy of website</summary>
      <description>Up to this, deploy of website has been build local and then copy up to apache and put it into place under /www/hbase.apache.org. Change it so can have maven deploy the site. The good thing about having the latter do it is that its regular; permissions will always be the same so Doug and I won't be fighting each other when we stick stuff up there. Also, its a one step process rather than multiple.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.old.news.xml</file>
      <file type="M">src.site.xdoc.index.xml</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-4-16 01:00:00" id="5800" opendate="2012-4-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Birds of a feather link on web page doesn&amp;#39;t work.</summary>
      <description>just missing the http://</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.index.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-5-20 01:00:00" id="5840" opendate="2012-4-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Open Region FAILED_OPEN doesn&amp;#39;t clear the TaskMonitor Status, keeps showing the old status</summary>
      <description>TaskMonitor Status will not be cleared in case Regions FAILED_OPEN. This will keeps showing old status.This will miss leads the user.</description>
      <version>0.94.0</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2012-6-27 01:00:00" id="5892" opendate="2012-4-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbck] Refactor parallel WorkItem* to Futures.</summary>
      <description>This would convert WorkItem* logic (with low level notifies, and rough exception handling) into a more canonical Futures pattern.Currently there are two instances of this pattern (for loading hdfs dirs, for contacting regionservers for assignments, and soon &amp;#8211; for loading hdfs .regioninfo files).</description>
      <version>0.90.6,0.92.1,0.94.0</version>
      <fixedVersion>0.92.2,0.94.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-7-8 01:00:00" id="5955" opendate="2012-5-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Guava 11 drops MapEvictionListener and Hadoop 2.0.0-alpha requires it</summary>
      <description>Hadoop 2.0.0-alpha depends on Guava 11.0.2. Updating HBase dependencies to match produces the following compilation errors:[ERROR] SingleSizeCache.java:[41,32] cannot find symbol[ERROR] symbol : class MapEvictionListener[ERROR] location: package com.google.common.collect[ERROR] [ERROR] SingleSizeCache.java:[94,4] cannot find symbol[ERROR] symbol : class MapEvictionListener[ERROR] location: class org.apache.hadoop.hbase.io.hfile.slab.SingleSizeCache[ERROR] [ERROR] SingleSizeCache.java:[94,69] cannot find symbol[ERROR] symbol : class MapEvictionListener[ERROR] location: class org.apache.hadoop.hbase.io.hfile.slab.SingleSizeCache</description>
      <version>0.94.0</version>
      <fixedVersion>0.94.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2012-5-15 01:00:00" id="6004" opendate="2012-5-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Adding more logging to help debugging MR job</summary>
      <description>MR job sometime fails because scanner expired. In this case, it will be helpful to know the last successful row, the ip of the region sever, and so on.</description>
      <version>0.94.0,0.95.2</version>
      <fixedVersion>0.94.0,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapred.TableRecordReaderImpl.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.ScannerCallable.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-5-15 01:00:00" id="6005" opendate="2012-5-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Broken Links on Homepages</summary>
      <description>I ran w3c's link checker on the homepage and there a few broken links.I'll start getting a patch to fix the links that were broken.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.site.xdoc.old.news.xml</file>
      <file type="M">src.site.xdoc.cygwin.xml</file>
      <file type="M">src.main.javadoc.overview.html</file>
      <file type="M">src.docbkx.preface.xml</file>
      <file type="M">src.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2012-8-18 01:00:00" id="6052" opendate="2012-5-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Convert .META. and -ROOT- content to pb</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.hbck.OfflineMetaRebuildTestCore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestSerialization.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestScanner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestGetClosestAtOrBefore.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestEndToEndSplitTransaction.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.migration.TestMigrationFrom090To092.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestZKBasedOpenCloseRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterTransitions.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestMasterNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestAssignmentManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.Mocking.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestMetaMigrationRemovingHTD.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.catalog.TestMetaReaderEditorNoCluster.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.catalog.TestCatalogTracker.java</file>
      <file type="M">hbase-server.src.main.ruby.hbase.table.rb</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.Writables.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.MetaUtils.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.Merge.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HMerge.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsckRepair.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.migration.HRegionInfo090x.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HRegionInfo.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Result.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.MetaScanner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HConnectionManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.catalog.MetaReader.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.catalog.MetaMigrationRemovingHTD.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.catalog.MetaEditor.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">hbase-server.src.test.data.hbase-4388-root.dir.tgz</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-2-18 01:00:00" id="6055" opendate="2012-5-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Offline Snapshots in HBase 0.96</summary>
      <description>Continuation of HBASE-50 for the current trunk. Since the implementation has drastically changed, opening as a new ticket.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.CheckedArchivingHFileCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.FileCleanerDelegate.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.CleanerChore.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.cleaner.BaseLogCleanerDelegate.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.backup.example.LongTermArchivingHFileCleaner.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-5-21 01:00:00" id="6061" opendate="2012-5-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix ACL "Admin" Table inconsistent permission check</summary>
      <description>the requirePermission() check for "admin" operation on a table is currently inconsistent.Table Owner with CREATE rights (that means, the owner has created that table) can enable/disable and delete the table but needs ADMIN rights to add/remove/modify a column.</description>
      <version>0.92.1,0.94.0,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-5-21 01:00:00" id="6062" opendate="2012-5-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>preCheckAndPut/Delete() checks for READ when also a WRITE is performed</summary>
      <description>preCheckAndPut() and preCheckAndDelete() checks for READ when they also want to WRITE... for me checking for WRITE permission is the right thing... what do you say about that? keep READ, replace with WRITE?</description>
      <version>0.92.1,0.94.0,0.95.2</version>
      <fixedVersion>0.92.2,0.94.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-5-24 01:00:00" id="6089" opendate="2012-5-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>SSH and AM.joinCluster causes Concurrent Modification exception.</summary>
      <description>AM.regions map is parallely accessed in SSH and Master initialization leading to ConcurrentModificationException.</description>
      <version>0.92.1,0.94.0</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-6-4 01:00:00" id="6157" opendate="2012-6-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Revoke of Global permission is not taking effect without restart.</summary>
      <description>Revoke of Global permission is not taking effect without restart.Revoke is updating the acl table but it's not updating the USER_CACHE.</description>
      <version>0.94.0</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.TableAuthManager.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-6-4 01:00:00" id="6158" opendate="2012-6-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Data loss if the words &amp;#39;merges&amp;#39; or &amp;#39;splits&amp;#39; are used as Column Family name</summary>
      <description>If a table is creates with either 'merges' or 'splits' as one of the Column Family name it can never be flushed to the disk even though the table creation (and data population) succeeds.The reason for this is that these two are used as temporary directory names inside the region folder or merge and splits respectively and hence conflicts with the directories created for CF with same name.A simple fix would be to uses ".merges' and ".splits" as the working folder (patch attached). This will also be consistent with other work folder names. An alternate fix would be to declare these words (and other similar) as reserve words and throw exception when they are used. However, I do find the alternate approach as unnecessarily restrictive.</description>
      <version>0.94.0</version>
      <fixedVersion>0.92.2,0.94.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-6-4 01:00:00" id="6160" opendate="2012-6-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>META entries from daughters can be deleted before parent entries</summary>
      <description>HBASE-5986 fixed and issue, where the client sees the META entry for the parent, but not the children. However, after the fix, we have seen the following issue in tests: Region A is split to -&gt; B, CRegion B is split to -&gt; D, EAfter some time, META entry for B is deleted since it is not needed anymore, but META entry for Region A stays in META (C still refers it). In this case, the client throws RegionOfflineException for B.</description>
      <version>0.92.2,0.94.0,0.95.2</version>
      <fixedVersion>0.92.2,0.94.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-7-6 01:00:00" id="6170" opendate="2012-6-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Timeouts for row lock and scan should be separate</summary>
      <description>Apparently the timeout used for row locking and for scanning is global. It would be better to have two separate timeouts.(opening the issue to make Lars George happy)</description>
      <version>0.94.0</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorInterface.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.TestScannerTimeout.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Leases.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.ClientScanner.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.HConstants.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-6-7 01:00:00" id="6188" opendate="2012-6-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove the concept of table owner</summary>
      <description>The table owner concept was a design simplification in the initial drop.First, the design changes under review means only a user with GLOBAL CREATE permission can create a table, which will probably be an administrator.Then, granting implicit permissions may lead to oversights and it adds unnecessary conditionals to our code. So instead the administrator with GLOBAL CREATE permission should make the appropriate grants at table create time.</description>
      <version>0.94.0,0.94.1,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlLists.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HTableDescriptor.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-6-11 01:00:00" id="6200" opendate="2012-6-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>KeyComparator.compareWithoutRow can be wrong when families have the same prefix</summary>
      <description>As reported by Desert Rose on IRC and on the ML, Result has a weird behavior when some families share the same prefix. He posted a link to his code to show how it fails, http://pastebin.com/7TBA1XGhBasically KeyComparator.compareWithoutRow doesn't differentiate families and qualifiers so "f:a" is said to be bigger than "f1:", which is false. Then what happens is that the KVs are returned in the right order from the RS but then doing Result.binarySearch it uses KeyComparator.compareWithoutRow which has a different sorting so the end result is undetermined.I added some debug and I can see that the data is returned in the right order but Arrays.binarySearch returned the wrong KV, which is then verified agains the passed family and qualifier which fails so null is returned.I don't know how frequent it is for users to have families with the same prefix, but those that do have that and that use those families at the same time will have big correctness issues. This is why I mark this as a blocker.</description>
      <version>0.90.6,0.92.1,0.94.0</version>
      <fixedVersion>0.92.2,0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestKeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-5-9 01:00:00" id="621" opendate="2008-5-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make MAX_VERSIONS work like TTL: In scans and gets, check MAX_VERSIONs setting and return that many only rather than wait on compaction</summary>
      <description>HBASE-47 added specification of TTL on cells. The implementation checks cell timestamp against configured TTL before returning results scanning or getting. You can also set the maximum versions of a cell to keep. The maximum versions is not checked scanning or getting, only when we compact (We'll drop cells that are beyond the maximum version at compaction time). This issue is about adding check for maximum versions to gets and scans so that if you ask for all versions but have configured the store to only keep 3 versions, though 4 may have been inserted, you'll currently get 4 returned (if compactions have not had a chance to run).</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.Memcache.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.HConstants.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-6-14 01:00:00" id="6211" opendate="2012-6-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Put latencies in jmx</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.metrics.TestMetricsMBeanBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.metrics.MetricsMBeanBase.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.metrics.histogram.MetricsHistogram.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-6-19 01:00:00" id="6238" opendate="2012-6-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Grant on META not taking effect</summary>
      <description>User is not able to perform authorized operations on Meta.</description>
      <version>0.94.0,0.94.1,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessControlLists.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-6-21 01:00:00" id="6252" opendate="2012-6-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>TABLE ADMIN should be allowed to relocate regions</summary>
      <description/>
      <version>0.94.0,0.94.1,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-7-25 01:00:00" id="6265" opendate="2012-6-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Calling getTimestamp() on a KV in cp.prePut() causes KV not to be flushed</summary>
      <description>There is an issue when you call getTimestamp() on any KV handed into a Coprocessor's prePut(). It initializes the internal "timestampCache" variable. When you then pass it to the normal processing, the region server sets the time to the server time in case you have left it unset from the client side (updateLatestStamp() call). The TimeRangeTracker then calls getTimestamp() later on to see if it has to include the KV, but instead of getting the proper time it sees the cached timestamp from the prePut() call.</description>
      <version>0.92.0,0.94.0,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.TestKeyValue.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-9-27 01:00:00" id="6286" opendate="2012-6-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade maven-compiler-plugin to 2.5.1</summary>
      <description>time mvn -PlocalTests clean install -DskipTests With 2.5.1:user1m35.634s1m31.178s1m31.366ssys0m06.540s0m05.376s0m05.488sWith 2.0.2 (current):user2m01.168s1m54.027s1m57.799ssys0m05.896s0m05.912s0m06.032s</description>
      <version>None</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.docbkx.upgrading.xml</file>
      <file type="M">src.main.docbkx.developer.xml</file>
      <file type="M">src.main.docbkx.configuration.xml</file>
      <file type="M">src.main.docbkx.community.xml</file>
      <file type="M">src.main.docbkx.case.studies.xml</file>
      <file type="M">src.main.docbkx.book.xml</file>
      <file type="M">pom.xml</file>
      <file type="M">hbase-common.src.main.resources.hbase-default.xml</file>
      <file type="M">hbase-assembly.src.xslt.configuration.to.docbook.section.xsl</file>
      <file type="M">hbase-assembly.src.site.xdoc.sponsors.xml</file>
      <file type="M">hbase-assembly.src.site.xdoc.resources.xml</file>
      <file type="M">hbase-assembly.src.site.xdoc.replication.xml</file>
      <file type="M">hbase-assembly.src.site.xdoc.pseudo-distributed.xml</file>
      <file type="M">hbase-assembly.src.site.xdoc.old.news.xml</file>
      <file type="M">hbase-assembly.src.site.xdoc.metrics.xml</file>
      <file type="M">hbase-assembly.src.site.xdoc.index.xml</file>
      <file type="M">hbase-assembly.src.site.xdoc.cygwin.xml</file>
      <file type="M">hbase-assembly.src.site.xdoc.bulk-loads.xml</file>
      <file type="M">hbase-assembly.src.site.xdoc.acid-semantics.xml</file>
      <file type="M">hbase-assembly.src.site.site.xml</file>
      <file type="M">hbase-assembly.src.site.site.vm</file>
      <file type="M">hbase-assembly.src.site.resources.images.hbase.logo.svg</file>
      <file type="M">hbase-assembly.src.site.resources.images.hbase.logo.png</file>
      <file type="M">hbase-assembly.src.site.resources.images.big.h.logo.svg</file>
      <file type="M">hbase-assembly.src.site.resources.doap.Hbase.rdf</file>
      <file type="M">hbase-assembly.src.site.resources.css.site.css</file>
      <file type="M">hbase-assembly.src.site.resources.css.freebsd.docbook.css</file>
      <file type="M">hbase-assembly.src.docbkx.zookeeper.xml</file>
      <file type="M">hbase-assembly.src.docbkx.upgrading.xml</file>
      <file type="M">hbase-assembly.src.docbkx.troubleshooting.xml</file>
      <file type="M">hbase-assembly.src.docbkx.shell.xml</file>
      <file type="M">hbase-assembly.src.docbkx.security.xml</file>
      <file type="M">hbase-assembly.src.docbkx.schema.design.xml</file>
      <file type="M">hbase-assembly.src.docbkx.rpc.xml</file>
      <file type="M">hbase-assembly.src.docbkx.preface.xml</file>
      <file type="M">hbase-assembly.src.docbkx.performance.xml</file>
      <file type="M">hbase-assembly.src.docbkx.ops.mgt.xml</file>
      <file type="M">hbase-assembly.src.docbkx.getting.started.xml</file>
      <file type="M">hbase-assembly.src.docbkx.external.apis.xml</file>
      <file type="M">hbase-assembly.src.docbkx.developer.xml</file>
      <file type="M">hbase-assembly.src.docbkx.customization.xsl</file>
      <file type="M">hbase-assembly.src.docbkx.configuration.xml</file>
      <file type="M">hbase-assembly.src.docbkx.community.xml</file>
      <file type="M">hbase-assembly.src.docbkx.case.studies.xml</file>
      <file type="M">hbase-assembly.src.docbkx.book.xml</file>
      <file type="M">hbase-assembly.src.assembly.src.xml</file>
      <file type="M">hbase-assembly.src.assembly.hadoop-two-compat.xml</file>
      <file type="M">hbase-assembly.src.assembly.hadoop-one-compat.xml</file>
      <file type="M">hbase-assembly.src.assembly.components.xml</file>
      <file type="M">hbase-assembly.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2008-5-20 01:00:00" id="630" opendate="2008-5-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Default hbase.rootdir is garbage</summary>
      <description>Always writes to '/tmp/hbase-'.</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.hbase-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-7-2 01:00:00" id="6303" opendate="2012-7-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HCD.setCompressionType should use Enum support for storing compression types as strings</summary>
      <description>Let's not require an update to HCD every time the HFile compression enum is changed.</description>
      <version>0.94.0,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.HColumnDescriptor.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-7-3 01:00:00" id="6313" opendate="2012-7-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Client hangs because the client is not notified</summary>
      <description>If the call first remove from the calls, when some exception happened in reading from the DataInputStream, the call will not be notified, cause the client hangs.</description>
      <version>0.92.1,0.94.0</version>
      <fixedVersion>0.92.2,0.94.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.HBaseClient.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-9-4 01:00:00" id="6327" opendate="2012-7-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HLog can be null when create table</summary>
      <description>As HBASE-4010 discussed, the HLog can be null.We have meet createTable failed because the no use hlog.When createHReagion, the HLog.LogSyncer is run sync(), in under layer it call the DFSClient.DFSOutputStream.sync(). Then the hlog.closeAndDelete() was calledfirstly the HLog.close() will interrupt the LogSyncer, and interrupt DFSClient.DFSOutputStream.sync().The DFSClient.DFSOutputStream will store the exception and throw it when we called DFSClient.close(). The HLog.close() call the writer.close()/DFSClient.close() after interrupt the LogSyncer. And there is no catch exception for the close().So the Master throw exception to the client. There is no need to throw this exception, further the hlog is no use.Our cluster is 0.90, the logs is attached, after "closing hlog writer", there is no log for the createTable().The trunk and 0.92, 0.94, we used just one hlog, and if the exception happends, the client will got createTable failed, but indeed ,we expect all the regions for the table can also be assigned.I will give the patch for this later.</description>
      <version>None</version>
      <fixedVersion>0.94.4,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.handler.CreateTableHandler.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-7-6 01:00:00" id="6336" opendate="2012-7-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Split point should not be equal to start row or end row</summary>
      <description>Should we allow split point equal with region's start row or end row?// if the midkey is the same as the first and last keys, then we cannot // (ever) split this region. if (this.comparator.compareRows(mk, firstKey) == 0 &amp;&amp; this.comparator.compareRows(mk, lastKey) == 0) { if (LOG.isDebugEnabled()) { LOG.debug("cannot split because midkey is the same as first or " + "last row"); }Here, I think it is a mistake.</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-7-7 01:00:00" id="6350" opendate="2012-7-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Some logging improvements for RegionServer bulk loading</summary>
      <description>The current logging in the bulk loading RPC call to a RegionServer lacks some info in certain cases. For instance, I recently noticed that it is possible that IOException may be caused during bulk load file transfer (copy) off of another FS and that during the same time the client already times the socket out and thereby does not receive a thrown Exception back remotely (HBase prints a ClosedChannelException for the IPC when it attempts to send the real message, and hence the real cause is lost).Improvements around this kind of issue, wherein we could first log the IOException at the RS before sending, and a few other wording improvements are present in my patch.</description>
      <version>0.94.0</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-10-22 01:00:00" id="636" opendate="2008-5-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>java6 as a requirement</summary>
      <description>Make java6 a requirement running hbase. Our hand will proably be forced by hadoop making java6 a requirement (0.19?).</description>
      <version>None</version>
      <fixedVersion>0.19.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
      <file type="M">src.java.overview.html</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2008-5-22 01:00:00" id="638" opendate="2008-5-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Purge \r from src</summary>
      <description>Bunch of our src has carriage-returns. Remove them.</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.hadoop.hbase.filter.TestWhileMatchRowFilter.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.filter.TestStopRowFilter.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.filter.TestRowFilterSet.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.filter.TestRegExpRowFilter.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.filter.TestPageRowFilter.java</file>
      <file type="M">src.test.org.apache.hadoop.hbase.filter.TestInclusiveStopRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStoreScanner.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.mapred.TableOutputFormat.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.WhileMatchRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.StopRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.RowFilterSet.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.RowFilterInterface.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.RegExpRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.PageRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.filter.InclusiveStopRowFilter.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-7-12 01:00:00" id="6380" opendate="2012-7-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>bulkload should update the store.storeSize</summary>
      <description>After bulkloading some HFiles into the Table, we found the force-split didn't work because of the MidKey == NULL. Only if we re-booted the HBase service, the force-split can work normally.</description>
      <version>0.94.0,0.95.2</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-7-13 01:00:00" id="6392" opendate="2012-7-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>UnknownRegionException blocks hbck from sideline big overlap regions</summary>
      <description>Before sidelining a big overlap region, hbck tries to close it and offline it at first. However, sometimes, it throws NotServingRegion or UnknownRegionException.It could be because the region is not open/assigned at all, or some other issue.We should figure out why and fix it.By the way, it's better to print out in the log the command line to bulk load back sidelined regions, if any.</description>
      <version>None</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-7-16 01:00:00" id="6397" opendate="2012-7-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hbck] print out bulk load commands for sidelined regions if necessary</summary>
      <description>It's better to print out in the log the command line to bulk load back sidelined regions, if any.Separate it out from HBASE-6392 since it is a different issue.</description>
      <version>None</version>
      <fixedVersion>0.94.1,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-12-18 01:00:00" id="6423" opendate="2012-7-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Writes should not block reads on blocking updates to memstores</summary>
      <description>We have a big data use case where we turn off WAL and have a ton of reads and writes. We found that:1. flushing a memstore takes a while (GZIP compression)2. incoming writes cause the new memstore to grow in an unbounded fashion3. this triggers blocking memstore updates4. in turn, this causes all the RPC handler threads to block on writes to that memstore5. we are not able to read during this time as RPC handlers are blockedAt a higher level, we should not hold up the RPC threads while blocking updates, and we should build in some sort of rate control.</description>
      <version>None</version>
      <fixedVersion>0.94.4,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.RegionStates.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-8-26 01:00:00" id="6460" opendate="2012-7-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>hbck "-repairHoles" usage inconsistent with "-fixHdfsOrphans"</summary>
      <description>According to the hbck's help info, shortcut - "-repairHoles" will enable "-fixHdfsOrphans" as below. -repairHoles Shortcut for -fixAssignments -fixMeta -fixHdfsHoles -fixHdfsOrphansHowever, in the implementation, the function "fsck.setFixHdfsOrphans(false);" is called in "-repairHoles". This is not consistent with the usage information.</description>
      <version>0.94.0,0.95.2</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.util.HBaseFsck.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-8-2 01:00:00" id="6505" opendate="2012-8-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow shared RegionObserver state</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.coprocessor.TestCoprocessorInterface.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.coprocessor.CoprocessorHost.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-9-24 01:00:00" id="6649" opendate="2012-8-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[0.92 UNIT TESTS] TestReplication.queueFailover occasionally fails [Part-1]</summary>
      <description>Have seen it twice in the recent past: http://bit.ly/MPCykB &amp; http://bit.ly/O79Dq7 .. Looking briefly at the logs hints at a pattern - in both the failed test instances, there was an RS crash while the test was running.</description>
      <version>None</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-6-4 01:00:00" id="665" opendate="2008-6-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>server side scanner doesn&amp;#39;t honor stop row</summary>
      <description>I have a large table. If I create a scanner with a stop row near the beginning of the table, the last hasNext call hangs for a while. If I do the same with the stop row near the end of the table, the last hasNext call is pretty quick.I suspect that the server side scanner isn't terminating early, and is actually scanning through the whole table returning nothing.</description>
      <version>None</version>
      <fixedVersion>0.1.3,0.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2008-6-6 01:00:00" id="671" opendate="2008-6-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>New UI page displaying all regions in a table should be sorted</summary>
      <description>Sort the regions displayed in the new regions-in-a-table page</description>
      <version>None</version>
      <fixedVersion>0.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.java.org.apache.hadoop.hbase.client.HTable.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-9-4 01:00:00" id="6716" opendate="2012-9-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hadoopqa is hosed</summary>
      <description>See this thread on list: http://search-hadoop.com/m/PtDLC19vEd62/%2522Looks+like+HadoopQA+is+hosed%2522&amp;subj=Looks+like+HadoopQA+is+hosed+Lots of the hadoopqa builds are failing complaining about missing dir.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.test-patch.sh</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2012-9-17 01:00:00" id="6798" opendate="2012-9-17 00:00:00" resolution="Duplicate">
    <buginformation>
      <summary>HDFS always read checksum form meta file</summary>
      <description>I use hbase0.941 and hadoop-0.20.2-cdh3u5 version.The HBase support checksums in HBase block cache in HBASE-5074 jira.The HBase support checksums for decrease the iops of HDFS, so that HDFSdont't need to read the checksum from meta file of block file.But in hadoop-0.20.2-cdh3u5 version, BlockSender still read the metadata file even if the hbase.regionserver.checksum.verify property is ture.</description>
      <version>0.94.0,0.94.1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.performance.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-9-18 01:00:00" id="6806" opendate="2012-9-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBASE-4658 breaks backward compatibility / example scripts</summary>
      <description>HBASE-4658 introduces the new 'attributes' argument as a non optional parameter. This is not backward compatible and also breaks the code in the example section. Resolution: Mark as 'optional'</description>
      <version>0.94.0</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">examples.thrift.Makefile</file>
      <file type="M">examples.thrift.DemoClient.rb</file>
      <file type="M">examples.thrift.DemoClient.py</file>
      <file type="M">examples.thrift.DemoClient.pl</file>
      <file type="M">examples.thrift.DemoClient.php</file>
      <file type="M">examples.thrift.DemoClient.java</file>
      <file type="M">examples.thrift.DemoClient.cpp</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2012-9-23 01:00:00" id="6869" opendate="2012-9-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update our hadoop-2 to 2.0.1-alpha</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-10-26 01:00:00" id="6889" opendate="2012-9-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Ignore source control files with apache-rat</summary>
      <description>Running 'mvn apache-rat:check' locally causes a failure because it finds the source control files, making it hard to check that you didn't include a file without a source header.</description>
      <version>None</version>
      <fixedVersion>0.94.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-10-24 01:00:00" id="7045" opendate="2012-10-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add some comments to MVCC code</summary>
      <description>I've been digging through the MVCC/transaction code and adding some comments to help me (or others) understand quicker the next time through</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.MultiVersionConsistencyControl.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-10-31 01:00:00" id="7077" opendate="2012-10-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Test for: CheckAndPut should properly read MVCC</summary>
      <description>checkAndPut should integrate with MVCC, similar to how HBASE-4583 fixed appends and increments.Also need a test, here's one we could use (originally proposed in HBASE-7051):The current value of some cell is 10.I issue two concurrent requests:A) a check and put where check value = 10, put value = 11B) a put where put value = 50The only result at the end of these operations that seems reasonable to me is the value of the cell being 50. If A occurred first (ACID wise), then our values go 10-&gt;11-&gt;50. If B occurred first, then our values go 10-&gt;50 (and the checkAndPut fails)</description>
      <version>None</version>
      <fixedVersion>0.94.3,0.95.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHBase7051.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-3-13 01:00:00" id="7153" opendate="2012-11-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>print gc option in hbase-env.sh affects hbase zkcli</summary>
      <description>I un-commented the -verbose:gc option in hbase-env.sh, which print out the gc info.but when I use hbase zkcli to check zk, it can not connect to the server.the problem is zkcli uses "hbase org.apache.hadoop.hbase.zookeeper.ZooKeeperMainServerArg" to get the server_arg in the script hbase. when gc verbose option is open, the output of ZooKeeperMainServerArg is with gc info, which masses up with server_arg. and this is the reason stop zkcli working.I think the easiest way to fix this is to trim the gc info out of server_arg in the hbase script.</description>
      <version>0.94.0</version>
      <fixedVersion>0.98.0,0.94.6,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-12-13 01:00:00" id="7158" opendate="2012-11-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow CopyTable to identify the source cluster (for replication scenarios)</summary>
      <description>When I worked on HBASE-2195 I added a mechanism for an edit to identify its source cluster, so that replication would not bounce it back to the source.See: this.clusterId = zkHelper.getUUIDForCluster(zkHelper.getZookeeperWatcher()); in ReplicationSource, and put.setClusterId(entry.getKey().getClusterId()); in ReplicationSink.In master-master replication scenarios, it would very useful if CopyTable would identify the source cluster (by tagging each Put/Delete with the source clusterId before applying it).</description>
      <version>None</version>
      <fixedVersion>0.94.4,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.Import.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.client.Mutation.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-11-14 01:00:00" id="7159" opendate="2012-11-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade zookeeper dependency to 3.4.5</summary>
      <description>zookeeper 3.4.5 works with Oracle JDK 1.7We should upgrade to zookeeper 3.4.5 in trunk</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2012-5-30 01:00:00" id="7244" opendate="2012-11-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Provide a command or argument to startup, that formats znodes if provided</summary>
      <description>Many a times I've had to, and have seen instructions being thrown, to stop cluster, clear out ZK and restart.While this is only a quick (and painful to master) fix, it is certainly nifty to some smaller cluster users but the process is far too long, roughly:1. Stop HBase2. Start zkCli.sh and connect to the right quorum3. Find and ensure the HBase parent znode from the configs (/hbase only by default)4. Run an "rmr /hbase" in the zkCli.sh shell, or manually delete each znode if on a lower version of ZK.5. Quit zkCli.sh and start HBase againPerhaps it may be useful, if the start-hbase.sh itself accepted a formatZK parameter. Such that, when you do a start-hbase.sh -formatZK, it does steps 2-4 automatically for you.For safety, we could make the formatter code ensure that no HBase instance is actually active, and skip the format process if it is. Similar to a HDFS NameNode's format, which would disallow if the name directories are locked.Would this be a useful addition for administrators? Bigtop too can provide a service subcommand that could do this.</description>
      <version>0.94.0</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hbase</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-1-9 01:00:00" id="7526" opendate="2013-1-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>create table does not log the table name in audit log</summary>
      <description>If I issue a create table command - create 'test', 'f1'Then from the audit log, there is no way to identify what table was createdrequest: createTable; context: (user=th30z, scope=GLOBAL, family=, action=CREATE)</description>
      <version>None</version>
      <fixedVersion>0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.security.access.AccessController.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-3-11 01:00:00" id="7546" opendate="2013-1-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Obtain a table read lock on region split operations</summary>
      <description>As discussed in the parent issue HBASE-7305, we should be coordinating between splits and table operations to ensure that they don't happen at the same time. In this issue we will acquire shared read locks for region splits.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.MockRegionServerServices.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.TestTableLockManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.MockRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SplitRequest.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RegionServerServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.TableLockManager.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-3-12 01:00:00" id="7827" opendate="2013-2-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve the speed of Hbase Thirft Batch mutation for deletes</summary>
      <description>A batch mutate operation does both puts and deletes. Batch mutate for put uses table.put(puts) however batch mutate for delete loops over all deletes and calls table.delete for every single cell. This causes delete performance to degrade.</description>
      <version>0.94.0</version>
      <fixedVersion>0.98.0,0.94.6,0.95.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2008-12-1 01:00:00" id="792" opendate="2008-8-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Rewrite getClosestAtOrJustBefore; doesn&amp;#39;t scale as currently written</summary>
      <description>As currently written, as a table gets bigger, the number of rows .META. needs to keep count of grows.As written, our getClosestAtOrJustBefore, goes through every storefile and in each picks up any row that could be a possible candidate for closest before. It doesn't just get the closest from the storefile, but all keys that are closest before. Its not selective because how can it tell at the store file level which of the candidates will survive deletes that are sitting in later store files or up in memcache.So, if a store file has keys 0-10 and we ask to get the row that is closest or just before 7, it returns rows 0-7.. and so on per store file.Can bet big and slow weeding key wanted.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.hadoop.hbase.regionserver.HStore.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-4-12 01:00:00" id="8334" opendate="2013-4-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable essential column family support by default</summary>
      <description>Essential column family support has gone through several iterations of refinement.We should enable this feature by default.</description>
      <version>None</version>
      <fixedVersion>0.98.0,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-4-24 01:00:00" id="8427" opendate="2013-4-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Apache Rat is incorrectly excluding test source files</summary>
      <description>HBASE-5524 added &amp;#42;&amp;#42;/test/&amp;#42;&amp;#42; as a rat exclude. This unfortunately excludes directories like hbase-it/src/test/* from the rat checks and has allowed a few unit tests to get in without proper licenses. Tightening it to only the directory HBASE-5524 was concerned about (and fixing files with non-compliant licenses)</description>
      <version>0.92.1,0.94.0</version>
      <fixedVersion>0.98.0,0.94.7,0.95.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  
</bugrepository>