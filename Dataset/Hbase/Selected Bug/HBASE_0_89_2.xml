<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="HBASE">
  
  
  <bug fixdate="2010-6-24 01:00:00" id="2783" opendate="2010-6-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Quick edit of &amp;#39;Getting Started&amp;#39; for development release 0.89.x</summary>
      <description>Hack on the javadoc overview to remove egregious stuff like recommended hdfs patches and to make mention of difference between plain hadoop 0.20 and 0.20-append.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2010-7-14 01:00:00" id="2836" opendate="2010-7-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Speed mvn site building by removing generation of useless reports</summary>
      <description>We don't care about dependency report, javadoc for tests, etc. Let me tell mvn not to gen them.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2010-7-20 01:00:00" id="2852" opendate="2010-7-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bloom filter NPE</summary>
      <description>When a rowcol Bloom filter is being used and the user submits a query for all columns, a null pointer exception is thrown. This is because there is no checking if columns have been specified or not.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2010-7-22 01:00:00" id="2862" opendate="2010-7-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Name DFSClient for Improved Debugging</summary>
      <description>Reported by Hairong. We had an HDFS error on our test cluster. It was hard to debug the HDFS NameNode logs because there was no way to map DFClient =&gt; RegionServer. Hadoop guys added a hacky config value, "mapred.task.id", which allows you to add a suffix to the DFSClient ID for logging. We should piggyback upon that for our HLog/HFile code</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.HMaster.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2010-7-22 01:00:00" id="2865" opendate="2010-7-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cleanup of LRU logging; its hard to read, uses custom MB&amp;#39;maker, repeats info, too many numbers after the point, etc.</summary>
      <description>Sorry, I got stuck on this. I wanted to clear the LRU logging from the log but I suppose its of use... then I started to study it.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.hfile.TestLruBlockCache.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.io.hfile.TestCachedBlockQueue.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.CachedBlockQueue.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.CachedBlock.java</file>
      <file type="M">src.assembly.bin.xml</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2010-7-22 01:00:00" id="2869" opendate="2010-7-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Regularize how we log sequenceids -- sometimes its myseqid, other times its sequence id, etc.</summary>
      <description>I'm trying to trace sequenceids over time to make sure all is working properly over crashes, etc., in an HRS and its way too painful. Regularize how we log so whenever a sequence id is mentioned in logs its named sequenceid.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.HRegion.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2010-7-24 01:00:00" id="2876" opendate="2010-7-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase hbck: false positive error reported for parent regions that are in offline state in meta after a split</summary>
      <description>HBase Checker will sometimes report something like the following:ERROR: Region test1,9922400000,1279934604048.8cb65b1882960f230abb97860dd13c53. is not served by any region server but is listed in META to be on server nullThe region in question is a parent region that has been offlined following a split. META still contains for the above region only because there are daughter regions which still have references to the parent region. Once the daughter regions undergo compaction, these references will be gone; and the parent region's entry will be removed from META. But "hbck" should detect entries in this condition and not complain. test1,9922400000,12799346 column=info:regioninfo, timestamp=1279938675016, value=REGION =&gt; {NAME =&gt; 04048.8cb65b1882960f230ab 'test1,9922400000,1279934604048.8cb65b1882960f230abb97860dd13c53.', STAR b97860dd13c53. TKEY =&gt; '9922400000', ENDKEY =&gt; '', ENCODED =&gt; 8cb65b1882960f230abb97860d d13c53, OFFLINE =&gt; true, SPLIT =&gt; true, TABLE =&gt; {{NAME =&gt; 'test1', FAMIL IES =&gt; [{NAME =&gt; 'actions', BLOOMFILTER =&gt; 'NONE', REPLICATION_SCOPE =&gt; ' 0', VERSIONS =&gt; '3', COMPRESSION =&gt; 'NONE', TTL =&gt; '2147483647', BLOCKSIZ E =&gt; '65536', IN_MEMORY =&gt; 'false', BLOCKCACHE =&gt; 'true'}]}} test1,9922400000,12799346 column=info:server, timestamp=1279938675016, value= 04048.8cb65b1882960f230ab b97860dd13c53. test1,9922400000,12799346 column=info:serverstartcode, timestamp=1279938675016, value= 04048.8cb65b1882960f230ab b97860dd13c53. test1,9922400000,12799346 column=info:splitA, timestamp=1279938675016, value=\x00\x0A9961500000\x00 04048.8cb65b1882960f230ab \x00\x00\x01*\x02J9'@test1,9922400000,1279938672935.94425ba581acd336d1cbd b97860dd13c53. 11181ee2785.\x00\x0A9922400000\x00\x00\x00\x05\x05test1\x00\x00\x00\x00\x 00\x02\x00\x00\x00\x07IS_ROOT\x00\x00\x00\x05false\x00\x00\x00\x07IS_META \x00\x00\x00\x05false\x00\x00\x00\x01\x08\x07actions\x00\x00\x00\x08\x00\ x00\x00\x0BBLOOMFILTER\x00\x00\x00\x04NONE\x00\x00\x00\x11REPLICATION_SCO PE\x00\x00\x00\x010\x00\x00\x00\x0BCOMPRESSION\x00\x00\x00\x04NONE\x00\x0 0\x00\x08VERSIONS\x00\x00\x00\x013\x00\x00\x00\x03TTL\x00\x00\x00\x0A2147 483647\x00\x00\x00\x09BLOCKSIZE\x00\x00\x00\x0565536\x00\x00\x00\x09IN_ME MORY\x00\x00\x00\x05false\x00\x00\x00\x0ABLOCKCACHE\x00\x00\x00\x04true\x B7\x04q\x18 test1,9922400000,12799346 column=info:splitB, timestamp=1279938675016, value=\x00\x00\x00\x00\x00\x 04048.8cb65b1882960f230ab 01*\x02J9'@test1,9961500000,1279938672935.bb521c9d8c51fd8133f145dc3c75013 b97860dd13c53. 6.\x00\x0A9961500000\x00\x00\x00\x05\x05test1\x00\x00\x00\x00\x00\x02\x00 \x00\x00\x07IS_ROOT\x00\x00\x00\x05false\x00\x00\x00\x07IS_META\x00\x00\x 00\x05false\x00\x00\x00\x01\x08\x07actions\x00\x00\x00\x08\x00\x00\x00\x0 BBLOOMFILTER\x00\x00\x00\x04NONE\x00\x00\x00\x11REPLICATION_SCOPE\x00\x00 \x00\x010\x00\x00\x00\x0BCOMPRESSION\x00\x00\x00\x04NONE\x00\x00\x00\x08V ERSIONS\x00\x00\x00\x013\x00\x00\x00\x03TTL\x00\x00\x00\x0A2147483647\x00 \x00\x00\x09BLOCKSIZE\x00\x00\x00\x0565536\x00\x00\x00\x09IN_MEMORY\x00\x 00\x00\x05false\x00\x00\x00\x0ABLOCKCACHE\x00\x00\x00\x04true"\xE8XD</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.client.HBaseFsck.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2010-11-3 01:00:00" id="2896" opendate="2010-8-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Retain assignment information between cluster shutdown/startup</summary>
      <description>Over in HBASE-57 we want to consider block locations for region assignment. This is most important during cluster startup where you currently lose all locality because regions are assignment randomly.This jira is about a shot-term solution to the cluster startup problem by retaining assignment information after a cluster shutdown and using it on the next cluster startup.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestLoadBalancer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.LoadBalancer.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.AssignmentManager.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.catalog.MetaReader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2010-10-13 01:00:00" id="2917" opendate="2010-8-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reseek directly to next row</summary>
      <description>When done with the current row, reseek directly to the next row rather than spending time reading more keys of current row which are not required.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2010-12-26 01:00:00" id="2936" opendate="2010-8-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Differentiate between daemon &amp; restart sleep periods</summary>
      <description>Trivial change for rolling restart scripts. Right now, both the stop-&gt;start time and per-daemon sleep time is controlled via HBASE_SLAVE_SLEEP. This param will normally be set relatively high (1-2 min), but we should be able to start up an RS very soon after the stop has successfully completed. Add new variable HBASE_RESTART_SLEEP to allow for lower downtime on a per-daemon basis.</description>
      <version>0.89.20100621</version>
      <fixedVersion>0.92.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.hbase-daemon.sh</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2010-9-1 01:00:00" id="2944" opendate="2010-9-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>cannot alter bloomfilter setting for a column family from hbase shell</summary>
      <description>hbase(main):002:0&gt; create 't1', 'cf'create 't1', 'cf'0 row(s) in 1.1320 secondshbase(main):003:0&gt; disable 't1'disable 't1'0 row(s) in 1.0810 secondshbase(main):004:0&gt; alter 't1', {NAME =&gt; 'cf', BLOOMFILTER =&gt; 'ROW'}alter 't1', {NAME =&gt; 'cf', BLOOMFILTER =&gt; 'ROW'}ERROR: no constructor with arguments matching [class org.jruby.java.proxies.ArrayJavaProxy, class org.jruby.RubyFixnum, class org.jruby.RubyString, class org.jruby.RubyBoolean, class org.jruby.RubyBoolean, class org.jruby.RubyFixnum, class org.jruby.RubyFixnum, class org.jruby.RubyBoolean, class org.jruby.RubyFixnum] on object #&lt;Java::OrgApacheHadoopHbase::HColumnDescriptor:0x1e4218cb&gt;</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.ruby.hbase.admin.rb</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  
  
  
  
  
  
  
  <bug fixdate="2010-5-16 01:00:00" id="3117" opendate="2010-10-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update Thrift to 0.5 version</summary>
      <description>Thrift 0.5 has been released already and we want to upgrade to at least 0.3 but 0.5 has a lot of improvements so that would be the best.Unfortunately the Java lib has changed so that we'll have to regenerate the current Thrift interface and fix the implementation (byte[] -&gt; ByteBuffer).They also have problems getting Thrift into a Maven repository so we'll need to do our current workaround again unfortunately and upload it to a repository. That would be Ryan's I think?I'll upload an updated thrift jar and a patch for the old Thrift code.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  
  <bug fixdate="2011-10-14 01:00:00" id="4591" opendate="2011-10-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>TTL for old HLogs should be calculated from last modification time.</summary>
      <description/>
      <version>0.89.20100621</version>
      <fixedVersion>0.92.0,0.94.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.java.org.apache.hadoop.hbase.master.TimeToLiveLogCleaner.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.master.TestLogsCleaner.java</file>
    </fixedFiles>
  </bug>
  
</bugrepository>