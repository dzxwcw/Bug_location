<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="HBASE">
  <bug fixdate="2018-7-9 01:00:00" id="21462" opendate="2018-11-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add note for CopyTable section explained it does not perform a diff, but a full write from source to target</summary>
      <description>Performance is a common issue with CopyTable is when the key/time range for the data to be copied is large because it basically scans all rows on the specified range, in the source and perform related puts on the source. We should add extra note explaining that on the reference guide, to help users/admins understand when to choose between the different tools/approaches for syncing clusters.</description>
      <version>3.0.0-alpha-1,2.1.5</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-4-16 01:00:00" id="22249" opendate="2019-4-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Rest Server throws NoClassDefFoundError with Java 11 (run-time)</summary>
      <description>While starting the rest server multiple instances of the following error can be seen:java.lang.NoClassDefFoundError: javax/activation/DataSourceAfter start-up of the server, while serving requests, following errors can be seen:Caused by: A MultiException has 3 exceptions. They are:1. java.lang.NoClassDefFoundError: Could not initialize class com.sun.xml.bind.v2.model.impl.RuntimeBuiltinLeafInfoImpl2. java.lang.IllegalStateException: Unable to perform operation: create on org.apache.hadoop.hbase.rest.provider.JAXBContextResolver3. java.lang.IllegalStateException: Unable to perform operation: create on org.glassfish.jersey.internal.ContextResolverFactoryAnd the requests failed like this:&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html;charset=ISO-8859-1"/&gt;&lt;title&gt;Error 500 &lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h2&gt;HTTP ERROR: 500&lt;/h2&gt;&lt;p&gt;Problem accessing /. Reason:&lt;pre&gt; Request failed.&lt;/pre&gt;&lt;/p&gt;&lt;hr /&gt;&lt;/body&gt;&lt;/html&gt;</description>
      <version>2.1.5</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.5</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-rest.pom.xml</file>
      <file type="M">hbase-resource-bundle.src.main.resources.META-INF.LICENSE.vm</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-5-8 01:00:00" id="22379" opendate="2019-5-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix Markdown for "Voting on Release Candidates" in book</summary>
      <description>The Markdown in the section "Voting on Release Candidates" of the HBase book seems to be broken. It looks like that there should be a quote, which isn't displayed correctly. Same is true for the formatting of the Maven RAT command.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,1.4.10,2.3.0,2.0.6,2.1.5,1.3.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-5-8 01:00:00" id="22384" opendate="2019-5-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Formatting issues in administration section of book</summary>
      <description>The administration section in the book (64.3.2. Administration) has some formatting issues. Due to that issues the list count is not accurate, as well as the indentation of some code snippets.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,1.4.10,2.3.0,2.0.6,2.1.5,1.3.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.security.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2010-2-19 01:00:00" id="2242" opendate="2010-2-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[EC2] Downgrade JDK to 6u17 and rebuild AMIs</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.20.4,0.90.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.contrib.ec2.bin.hbase-ec2-env.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-5-26 01:00:00" id="22471" opendate="2019-5-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Our nightly jobs for master and branch-2 are still using hadoop-2.7.1 in integration test</summary>
      <description>We use ls to get the hadoop 2 jars, so maybe the problem is that the 2.7.1 jars are already there for a long time. We need to clean the workspace.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,2.3.0,2.1.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-5-26 01:00:00" id="22472" opendate="2019-5-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>The newly split TestReplicationStatus* tests are flaky</summary>
      <description>They are introduced by HBASE-22455, from the original TestReplicationStatus tests. Need to dig more.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationStatusSourceStartedTargetStoppedWithRecovery.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationStatusSourceStartedTargetStoppedNoOps.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationStatusSourceStartedTargetStoppedNewOp.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationStatusBothNormalAndRecoveryLagging.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationStatusAfterLagging.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-5-26 01:00:00" id="22474" opendate="2019-5-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add --mvn-custom-repo parameter to yetus calls</summary>
      <description>PreCommit validation from yetus uses a shared .m2 repository. By adding --mvn-custom-repo and --jenkins paramters yetus will use a custom .m2 directory for executions for PR validations.https://yetus.apache.org/documentation/0.9.0/precommit-buildtools/</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.2.0,1.4.10,2.0.6,2.1.5,1.3.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile.GitHub</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-6-6 01:00:00" id="22547" opendate="2019-6-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Align the config keys and add document for offheap read in HBase Book.</summary>
      <description>We found many useful tips about offheap reading when developing &amp; testing HBASE-21879, will prepare a doc for this.Some of them are in google doc now : https://docs.google.com/document/d/1xSy9axGxafoH-Qc17zbD2Bd--rWjjI00xTWQZ8ZwI_E/edit?usp=sharing</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.architecture.adoc</file>
      <file type="M">src.main.asciidoc.book.adoc</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mob.TestMobWithByteBuffAllocator.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
      <file type="M">hbase-common.src.test.java.org.apache.hadoop.hbase.io.TestByteBuffAllocator.java</file>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.io.ByteBuffAllocator.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-6-6 01:00:00" id="22549" opendate="2019-6-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document how to re-run github PR checks</summary>
      <description>Our psomogyi has a trick for re-running github PR checks that is not force-push of original patch. Lets get it into the refguide.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.developer.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2010-3-23 01:00:00" id="2255" opendate="2010-2-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>take trunk back to hadoop 0.20</summary>
      <description>revert the dependency on hadoop 0.21, back to hadoop 0.20 (we hardly knew ye)</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.wal.TestHLog.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreReconstruction.java</file>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.RowCounter.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.Import.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.Export.java</file>
      <file type="M">core.src.main.java.org.apache.hadoop.hbase.mapreduce.CopyTable.java</file>
      <file type="M">core.pom.xml</file>
      <file type="M">contrib.transactional.pom.xml</file>
      <file type="M">contrib.stargate.pom.xml</file>
      <file type="M">contrib.mdc.replication.pom.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-6-9 01:00:00" id="22554" opendate="2019-6-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade to surefire 2.22.2</summary>
      <description>Surefire 2.22.2 has a fix for corrupted output: SUREFIRE-1614 </description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.2.0,2.3.0,2.0.6,2.1.6,1.3.6,1.4.11</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-6-10 01:00:00" id="22563" opendate="2019-6-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reduce retained jobs for Jenkins pipelines</summary>
      <description>Our jobs are taking up lots of space. Try to help out infra quickly by reducing the number of old builds we keep.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.2.0,2.3.0,2.0.6,2.1.6,1.3.6,1.4.11</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile.GitHub</file>
      <file type="M">dev-support.Jenkinsfile</file>
      <file type="M">dev-support.flaky-tests.run-flaky-tests.Jenkinsfile</file>
      <file type="M">dev-support.flaky-tests.flaky-reporting.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2010-7-25 01:00:00" id="2265" opendate="2010-2-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HFile and Memstore should maintain minimum and maximum timestamps</summary>
      <description>In order to fix HBASE-1485 and HBASE-29, it would be very helpful to have HFile and Memstore track their maximum and minimum timestamps. This has the following nice properties: for a straight Get, if an entry has been already been found with timestamp X, and X &gt;= HFile.maxTimestamp, the HFile doesn't need to be checked. Thus, the current fast behavior of get can be maintained for those who use strictly increasing timestamps, but "correct" behavior for those who sometimes write out-of-order. for a scan, the "latest timestamp" of the storage can be used to decide which cell wins, even if the timestamp of the cells is equal. In essence, rather than comparing timestamps, instead you are able to compare tuples of (row timestamp, storage.max_timestamp) in general, min_timestamp(storage A) &gt;= max_timestamp(storage B) if storage A was flushed after storage B.</description>
      <version>None</version>
      <fixedVersion>0.90.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestStoreFile.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestStore.java</file>
      <file type="M">src.test.java.org.apache.hadoop.hbase.regionserver.TestMemStore.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.Store.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.MemStore.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.regionserver.KeyValueHeap.java</file>
      <file type="M">src.main.java.org.apache.hadoop.hbase.KeyValue.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-7-19 01:00:00" id="22714" opendate="2019-7-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>BuffferedMutatorParams opertationTimeOut() is misspelt</summary>
      <description>The method `opertationTimeOut()` in `BuffferedMutatorParams` is misspelt. </description>
      <version>2.1.5</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.client.BufferedMutatorParams.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-8-24 01:00:00" id="22911" opendate="2019-8-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>fewer concurrent github PR builds</summary>
      <description>we've been regularly getting 4-5 concurrent builds of PRs.</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,2.2.1,2.1.6,1.3.6,1.4.11,2.0.7</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile.GitHub</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-8-24 01:00:00" id="22913" opendate="2019-8-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use Hadoop label for nightly builds</summary>
      <description/>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,1.5.0,2.3.0,2.2.1,2.1.6,1.3.6,1.4.11</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.Jenkinsfile</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-10-14 01:00:00" id="23172" opendate="2019-10-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase Canary region success count metrics reflect column family successes, not region successes</summary>
      <description>HBase Canary reads once per column family per region. The current "region success count" should actually be "column family success count," which means we need another metric that actually reflects region success count. Additionally, the region read and write latencies only store the latencies of the last column family of the region read. Instead of a map of regions to a single latency value and success value, we should map each region to a list of such values.</description>
      <version>3.0.0-alpha-1,1.3.0,1.4.0,1.5.0,2.0.0,2.1.5,2.2.1</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0,1.6.0,2.1.8,2.2.3</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.tool.TestCanaryTool.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.tool.CanaryTool.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2020-1-8 01:00:00" id="23664" opendate="2020-1-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade JUnit to 4.13</summary>
      <description>New JUnit released a week ago. Let's give it a spin.https://github.com/junit-team/junit4/blob/master/doc/ReleaseNotes4.13.md</description>
      <version>None</version>
      <fixedVersion>3.0.0-alpha-1,2.3.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2010-4-23 01:00:00" id="2367" opendate="2010-3-23 00:00:00" resolution="Won&amp;#39;t Fix">
    <buginformation>
      <summary>[PE] add an option to toggle writeToWAL false on puts</summary>
      <description/>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">core.src.test.java.org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
    </fixedFiles>
  </bug>
</bugrepository>