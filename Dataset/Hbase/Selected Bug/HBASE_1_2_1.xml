<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="HBASE">
  
  
  
  <bug fixdate="2016-5-9 01:00:00" id="15801" opendate="2016-5-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade checkstyle for all branches</summary>
      <description>We should use the same checkstyle for all branches.</description>
      <version>1.3.0,1.2.1,1.0.3,0.98.19,1.4.0,1.1.5,2.0.0</version>
      <fixedVersion>1.3.0,1.0.4,1.2.2,0.98.20,1.1.6,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2016-5-18 01:00:00" id="15854" opendate="2016-5-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Log the cause of SASL connection failures</summary>
      <description>This is the same fix as for HADOOP-11291 to add more info during logging of SASL connection failures.</description>
      <version>1.2.1</version>
      <fixedVersion>1.3.0,1.2.2,0.98.20,1.1.6,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.RpcClientImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.ipc.AsyncRpcChannelImpl.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2016-8-23 01:00:00" id="15882" opendate="2016-5-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade to yetus precommit 0.3.0</summary>
      <description>Now that Yetus 0.3.0 is out, we should update our precommit builds so we can use docker again.Most of the changes to our personality should be covered in the updated hbase example that ships with 0.3.0. we'll have to forward port the flakey test work.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.hbase-personality.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-6-23 01:00:00" id="15883" opendate="2016-5-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Adding WAL files and tracking offsets in HBase.</summary>
      <description>Implemented simple offset tracking for WAL files inside of an HBase table along with Unit Testing. Have not implemented queue claiming yet</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.util.TestHBaseFsckOneRS.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationStateZKImpl.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.TestReplicationStateBasic.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.cleaner.TestReplicationHFileCleaner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.cleaner.TestLogsCleaner.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.client.replication.TestReplicationAdmin.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.replication.regionserver.Replication.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueuesZKImpl.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationQueues.java</file>
      <file type="M">hbase-client.src.main.java.org.apache.hadoop.hbase.replication.ReplicationFactory.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-7-31 01:00:00" id="15925" opendate="2016-5-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>compat-module maven variable not evaluated</summary>
      <description>Looks like we've regressed on HBASE-8488. Have a look at the dependency artifacts list on http://mvnrepository.com/artifact/org.apache.hbase/hbase-testing-util/1.2.1. Notice the direct dependency's artifactId is ${compat.module}.</description>
      <version>1.0.0,1.1.0,1.2.0,1.2.1,1.0.3,1.1.5</version>
      <fixedVersion>1.3.0,1.2.2,1.1.6,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-6-2 01:00:00" id="15948" opendate="2016-6-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Port "HADOOP-9956 RPC listener inefficiently assigns connections to readers"</summary>
      <description>Esteban noticed we were missing this upstream issue. Seems to make no difference in profiling but here is the patch anyways.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.ipc.AbstractTestIPC.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.regionserver.SimpleRpcSchedulerFactory.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.RpcServer.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerWrapperImpl.java</file>
      <file type="M">hbase-hadoop-compat.src.main.java.org.apache.hadoop.hbase.ipc.MetricsHBaseServerSource.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-6-7 01:00:00" id="15977" opendate="2016-6-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Failed variable substitution on home page</summary>
      <description>Check out the top-left of hbase.apache.org, there's an unevaluated variable $banner.name leaking through.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.site.site.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-6-15 01:00:00" id="16031" opendate="2016-6-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Documents about "hbase.replication" default value seems wrong</summary>
      <description>public static final String REPLICATION_ENABLE_KEY = "hbase.replication"; public static final boolean REPLICATION_ENABLE_DEFAULT = true;The code shows that default value is true, but documents shows the default value is false.| hbase.replication| Whether replication is enabled or disabled on a given cluster| false</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.ops.mgt.adoc</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-6-15 01:00:00" id="16035" opendate="2016-6-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Nested AutoCloseables might not all get closed</summary>
      <description>Subtle problem in HBASE-15891:try (A myA = new A(new B()))An exception thrown between B starting to open an A finishing initialization may not result in B being closed. A safer syntax would be:try(B myB = new B(); A myA = newA(myB))</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.JarFinder.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.http.log.LogLevel.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-6-17 01:00:00" id="16061" opendate="2016-6-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow logging to a buffered console</summary>
      <description>We've seen some stalls when logging to the ConsoleLogger that's getting redirected to a file. We should allow people to use a buffered console appender to keep from having stalls when the logging disk is busy.</description>
      <version>1.2.1</version>
      <fixedVersion>1.3.0,0.98.21,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.log4j.properties</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-6-20 01:00:00" id="16068" opendate="2016-6-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - use consts for conf properties in tests</summary>
      <description>replace the hardcoded properties string conf.set("foo.key", v) in the tests with the use of the configuration property constants that we already have</description>
      <version>1.3.0,1.2.1,2.0.0</version>
      <fixedVersion>1.3.0,1.2.2,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestWALProcedureStoreOnHDFS.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMasterProcedureEvents.java</file>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.master.procedure.TestMasterFailoverWithProcedures.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.TestProcedureReplayOrder.java</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.wal.TestStressWALProcedureStore.java</file>
      <file type="M">hbase-procedure.src.main.java.org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-6-20 01:00:00" id="16069" opendate="2016-6-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Typo "trapsparently" in item 3 of chapter 87.2 of Reference Guide</summary>
      <description>In Chapter 87.2. Coprocessor Implementation Overview...3. Call the coprocessor from your client-side code. HBase handles the coprocessor trapsparently....Correct "trapsparently" into "transparently"</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.main.asciidoc..chapters.cp.adoc</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2016-9-24 01:00:00" id="16101" opendate="2016-6-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Procedure v2 - Perf Tool for WAL</summary>
      <description>Add upstream tools to measure procedure perf There are 2 main thing to measure: Procedure Loading Procedure Writing</description>
      <version>None</version>
      <fixedVersion>1.3.0,1.2.4,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-common.src.main.java.org.apache.hadoop.hbase.util.AbstractHBaseTool.java</file>
      <file type="M">hbase-assembly.pom.xml</file>
      <file type="M">hbase-procedure.src.test.java.org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALPerformanceEvaluation.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-7-26 01:00:00" id="16114" opendate="2016-6-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Get regionLocation of required regions only for MR jobs</summary>
      <description>We should only get the location of regions required during the MR job. This will help for jobs with large regions but the job itself scans only a small portion of it. Similar changes can be seen in MultiInputFormatBase.java.</description>
      <version>1.2.1</version>
      <fixedVersion>1.4.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-7-5 01:00:00" id="16177" opendate="2016-7-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>In dev mode thrift server can&amp;#39;t be run</summary>
      <description>Error: Could not find or load main class org.apache.hadoop.hbase.thrift2.ThriftServer</description>
      <version>1.3.0,1.2.1</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-assembly.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2009-1-7 01:00:00" id="1621" opendate="2009-7-7 00:00:00" resolution="Duplicate">
    <buginformation>
      <summary>merge tool should work on online cluster</summary>
      <description>taking down the entire cluster to merge 2 regions is a pain, i dont see why the table or regions specifically couldnt be taken offline, then merged then brought back up.this might need a new API to the regionservers so they can take direction from not just the master.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.docbkx.ops.mgt.xml</file>
      <file type="M">src.docbkx.book.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-7-11 01:00:00" id="16211" opendate="2016-7-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>JMXCacheBuster restarting the metrics system might cause tests to hang</summary>
      <description>JMXCacheBuster restarts the metrics system. In Phoenix we are manually injecting a sink to the metric system which gets lost when we restart the metric system. See PHOENIX-3062</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-hadoop2-compat.src.main.java.org.apache.hadoop.metrics2.impl.JmxCacheBuster.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-9-22 01:00:00" id="16678" opendate="2016-9-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>MapReduce jobs do not update counters from ScanMetrics</summary>
      <description>Was inspecting a perf issue, where we needed the scanner metrics as counters for a MR job. Turns out that the HBase scan counters are no longer working in 1.0+. I think it got broken via HBASE-13030. These are the counters: HBase Counters BYTES_IN_REMOTE_RESULTS=0 BYTES_IN_RESULTS=280 MILLIS_BETWEEN_NEXTS=11 NOT_SERVING_REGION_EXCEPTION=0 NUM_SCANNER_RESTARTS=0 NUM_SCAN_RESULTS_STALE=0 REGIONS_SCANNED=1 REMOTE_RPC_CALLS=0 REMOTE_RPC_RETRIES=0 RPC_CALLS=3 RPC_RETRIES=0</description>
      <version>None</version>
      <fixedVersion>1.3.0,1.1.7,1.2.4,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.test.java.org.apache.hadoop.hbase.mapreduce.TestTableMapReduce.java</file>
      <file type="M">hbase-server.src.main.java.org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-9-22 01:00:00" id="16682" opendate="2016-9-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix Shell tests failure. NoClassDefFoundError for MiniKdc</summary>
      <description>Stacktracejava.lang.NoClassDefFoundError: org/apache/hadoop/minikdc/MiniKdc at java.lang.Class.getDeclaredMethods0(Native Method) at java.lang.Class.privateGetDeclaredMethods(Class.java:2701) at java.lang.Class.getDeclaredMethods(Class.java:1975) at org.jruby.javasupport.JavaClass.getMethods(JavaClass.java:2110) at org.jruby.javasupport.JavaClass.setupClassMethods(JavaClass.java:955) at org.jruby.javasupport.JavaClass.access$700(JavaClass.java:99) at org.jruby.javasupport.JavaClass$ClassInitializer.initialize(JavaClass.java:650) at org.jruby.javasupport.JavaClass.setupProxy(JavaClass.java:689) at org.jruby.javasupport.Java.createProxyClass(Java.java:526) at org.jruby.javasupport.Java.getProxyClass(Java.java:455) at org.jruby.javasupport.Java.getInstance(Java.java:364) at org.jruby.javasupport.JavaUtil.convertJavaToUsableRubyObject(JavaUtil.java:166) at org.jruby.javasupport.JavaEmbedUtils.javaToRuby(JavaEmbedUtils.java:291) at org.jruby.embed.variable.AbstractVariable.updateByJavaObject(AbstractVariable.java:81) at org.jruby.embed.variable.GlobalVariable.&lt;init&gt;(GlobalVariable.java:69) at org.jruby.embed.variable.GlobalVariable.getInstance(GlobalVariable.java:60) at org.jruby.embed.variable.VariableInterceptor.getVariableInstance(VariableInterceptor.java:97) at org.jruby.embed.internal.BiVariableMap.put(BiVariableMap.java:321) at org.jruby.embed.ScriptingContainer.put(ScriptingContainer.java:1123) at org.apache.hadoop.hbase.client.AbstractTestShell.setUpBeforeClass(AbstractTestShell.java:61) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24) at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.junit.runners.Suite.runChild(Suite.java:128) at org.junit.runners.Suite.runChild(Suite.java:27) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at org.junit.runner.JUnitCore.run(JUnitCore.java:115) at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.createRequestAndRun(JUnitCoreWrapper.java:108) at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.executeEager(JUnitCoreWrapper.java:78) at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:54) at org.apache.maven.surefire.junitcore.JUnitCoreProvider.invoke(JUnitCoreProvider.java:144) at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:203) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:155) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:103)Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.minikdc.MiniKdc at java.net.URLClassLoader.findClass(URLClassLoader.java:381) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at java.lang.Class.getDeclaredMethods0(Native Method) at java.lang.Class.privateGetDeclaredMethods(Class.java:2701) at java.lang.Class.getDeclaredMethods(Class.java:1975) at org.jruby.javasupport.JavaClass.getMethods(JavaClass.java:2110) at org.jruby.javasupport.JavaClass.setupClassMethods(JavaClass.java:955) at org.jruby.javasupport.JavaClass.access$700(JavaClass.java:99) at org.jruby.javasupport.JavaClass$ClassInitializer.initialize(JavaClass.java:650) at org.jruby.javasupport.JavaClass.setupProxy(JavaClass.java:689) at org.jruby.javasupport.Java.createProxyClass(Java.java:526) at org.jruby.javasupport.Java.getProxyClass(Java.java:455) at org.jruby.javasupport.Java.getInstance(Java.java:364) at org.jruby.javasupport.JavaUtil.convertJavaToUsableRubyObject(JavaUtil.java:166) at org.jruby.javasupport.JavaEmbedUtils.javaToRuby(JavaEmbedUtils.java:291) at org.jruby.embed.variable.AbstractVariable.updateByJavaObject(AbstractVariable.java:81) at org.jruby.embed.variable.GlobalVariable.&lt;init&gt;(GlobalVariable.java:69) at org.jruby.embed.variable.GlobalVariable.getInstance(GlobalVariable.java:60) at org.jruby.embed.variable.VariableInterceptor.getVariableInstance(VariableInterceptor.java:97) at org.jruby.embed.internal.BiVariableMap.put(BiVariableMap.java:321) at org.jruby.embed.ScriptingContainer.put(ScriptingContainer.java:1123) at org.apache.hadoop.hbase.client.AbstractTestShell.setUpBeforeClass(AbstractTestShell.java:61) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24) at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.junit.runners.Suite.runChild(Suite.java:128) at org.junit.runners.Suite.runChild(Suite.java:27) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at org.junit.runner.JUnitCore.run(JUnitCore.java:115) at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.createRequestAndRun(JUnitCoreWrapper.java:108) at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.executeEager(JUnitCoreWrapper.java:78) at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:54) at org.apache.maven.surefire.junitcore.JUnitCoreProvider.invoke(JUnitCoreProvider.java:144) at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:203) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:155) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:103)</description>
      <version>None</version>
      <fixedVersion>1.3.0,1.2.4,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-testing-util.pom.xml</file>
      <file type="M">hbase-shell.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2017-3-24 01:00:00" id="19075" opendate="2017-10-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Task tabs on master UI cause page scroll</summary>
      <description>On the master info page, the clicking the tabs under Tasks causes the page to scroll back to the top of the page.TasksShow All Monitored Tasks Show non-RPC Tasks Show All RPC Handler Tasks Show Active RPC Calls Show Client Operations View as JSON^^ Any of thoseThe other tab-like links on the page keep the scroll in the same location.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-server.src.main.jamon.org.apache.hadoop.hbase.tmpl.common.TaskMonitorTmpl.jamon</file>
    </fixedFiles>
  </bug>
</bugrepository>