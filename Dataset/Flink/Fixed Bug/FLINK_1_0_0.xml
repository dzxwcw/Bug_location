<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="FLINK">
  <bug id="27470" opendate="2022-5-2 00:00:00" fixdate="2022-5-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[JUnit5 Migration] Module: flink-statebackend-heap-spillable</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-state-backends.flink-statebackend-heap-spillable.src.test.java.org.apache.flink.runtime.state.heap.TestAllocator.java</file>
      <file type="M">flink-state-backends.flink-statebackend-heap-spillable.src.test.java.org.apache.flink.runtime.state.heap.SkipListUtilsTest.java</file>
      <file type="M">flink-state-backends.flink-statebackend-heap-spillable.src.test.java.org.apache.flink.runtime.state.heap.SkipListSerializerTest.java</file>
      <file type="M">flink-state-backends.flink-statebackend-heap-spillable.src.test.java.org.apache.flink.runtime.state.heap.SkipListKeyComparatorTest.java</file>
      <file type="M">flink-state-backends.flink-statebackend-heap-spillable.src.test.java.org.apache.flink.runtime.state.heap.OnHeapLevelIndexHeaderTest.java</file>
      <file type="M">flink-state-backends.flink-statebackend-heap-spillable.src.test.java.org.apache.flink.runtime.state.heap.CopyOnWriteSkipListStateMapTestUtils.java</file>
      <file type="M">flink-state-backends.flink-statebackend-heap-spillable.src.test.java.org.apache.flink.runtime.state.heap.CopyOnWriteSkipListStateMapComplexOpTest.java</file>
      <file type="M">flink-state-backends.flink-statebackend-heap-spillable.src.test.java.org.apache.flink.runtime.state.heap.CopyOnWriteSkipListStateMapBasicOpTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="27471" opendate="2022-5-2 00:00:00" fixdate="2022-2-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add ARRAY_DISTINCT supported in SQL &amp; Table API</summary>
      <description>Removes duplicate values from the array.Syntax:array_distinct(array) Arguments: array: An ARRAY to be handled.Returns:An ARRAY. If value is NULL, the result is NULL. Keeps order of elements.Examples:SELECT array_distinct(ARRAY[1, 2, 3, 2, 1]);-- [1, 2, 3]SELECT array_distinct(ARRAY[1, NULL, 1]);-- [1, NULL]See also https://spark.apache.org/docs/latest/api/sql/index.html#array_distinct</description>
      <version>None</version>
      <fixedVersion>1.18.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.functions.CollectionFunctionsITCase.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.functions.BuiltInFunctionDefinitions.java</file>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.api.internal.BaseExpressions.java</file>
      <file type="M">flink-python.pyflink.table.expression.py</file>
      <file type="M">flink-python.docs.reference.pyflink.table.expressions.rst</file>
      <file type="M">docs.data.sql.functions.yml</file>
    </fixedFiles>
  </bug>
  <bug id="27476" opendate="2022-5-2 00:00:00" fixdate="2022-5-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Build new import option that only focus on maven main classes</summary>
      <description>ImportOption.DoNotIncludeTests.class used currently has some issue when running test with testContainer. It would be good to define the target class path precisely.</description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-architecture-tests.flink-architecture-tests-production.src.main.java.org.apache.flink.architecture.rules.ApiAnnotationRules.java</file>
      <file type="M">flink-architecture-tests.flink-architecture-tests-base.src.main.java.org.apache.flink.architecture.common.SourcePredicates.java</file>
      <file type="M">flink-architecture-tests.flink-architecture-tests-base.src.main.java.org.apache.flink.architecture.common.ImportOptions.java</file>
    </fixedFiles>
  </bug>
  <bug id="27477" opendate="2022-5-2 00:00:00" fixdate="2022-5-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Drop flink-yarn test-jar</summary>
      <description>We could do just fine without this test-jar.</description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn.pom.xml</file>
      <file type="M">flink-yarn-tests.src.test.java.org.apache.flink.yarn.YarnTestBase.java</file>
      <file type="M">flink-yarn-tests.src.test.java.org.apache.flink.yarn.YarnPrioritySchedulingITCase.java</file>
      <file type="M">flink-yarn-tests.src.test.java.org.apache.flink.yarn.YarnConfigurationITCase.java</file>
      <file type="M">flink-yarn-tests.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="28310" opendate="2022-6-30 00:00:00" fixdate="2022-7-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Introduce aggregating task metrics</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.messages.JobVertexTaskManagersInfoTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.messages.JobVertexDetailsInfoTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.job.SubtaskExecutionAttemptDetailsInfo.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.job.metrics.IOMetricsInfo.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.JobVertexTaskManagersInfo.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.JobVertexDetailsInfo.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler.java</file>
      <file type="M">flink-runtime-web.src.test.resources.rest.api.v1.snapshot</file>
      <file type="M">docs.static.generated.rest.v1.dispatcher.yml</file>
      <file type="M">docs.layouts.shortcodes.generated.rest.v1.dispatcher.html</file>
    </fixedFiles>
  </bug>
  <bug id="28311" opendate="2022-6-30 00:00:00" fixdate="2022-7-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Introduce REST APIs for the environmental information</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.webmonitor.WebMonitorEndpoint.java</file>
      <file type="M">flink-runtime-web.src.test.resources.rest.api.v1.snapshot</file>
      <file type="M">docs.static.generated.rest.v1.dispatcher.yml</file>
      <file type="M">docs.layouts.shortcodes.generated.rest.v1.dispatcher.html</file>
    </fixedFiles>
  </bug>
  <bug id="28312" opendate="2022-6-30 00:00:00" fixdate="2022-7-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Introduce REST APIs for log URL retrieval</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.webmonitor.WebMonitorEndpoint.java</file>
      <file type="M">flink-runtime-web.src.test.resources.rest.api.v1.snapshot</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.history.HistoryServer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.HistoryServerOptions.java</file>
      <file type="M">docs.static.generated.rest.v1.dispatcher.yml</file>
      <file type="M">docs.layouts.shortcodes.generated.rest.v1.dispatcher.html</file>
      <file type="M">docs.layouts.shortcodes.generated.history.server.configuration.html</file>
    </fixedFiles>
  </bug>
  <bug id="2909" opendate="2015-10-23 00:00:00" fixdate="2015-4-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Gelly Graph Generators</summary>
      <description>Include a selection of graph generators in Gelly. Generated graphs will be useful for performing scalability, stress, and regression testing as well as benchmarking and comparing algorithms, for both Flink users and developers. Generated data is infinitely scalable yet described by a few simple parameters and can often substitute for user data or sharing large files when reporting issues.There are at multiple categories of graphs as documented by NetworkX and elsewhere.Graphs may be a well-defined, i.e. the Chv√°tal graph. These may be sufficiently small to populate locally.Graphs may be scalable, i.e. complete and star graphs. These should use Flink's distributed parallelism.Graphs may be stochastic, i.e. RMat graphs . A key consideration is that the graphs should source randomness from a seedable PRNG and generate the same Graph regardless of parallelism.</description>
      <version>1.0.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.Utils.java</file>
      <file type="M">docs.page.css.flink.css</file>
      <file type="M">docs.apis.batch.libs.gelly.md</file>
    </fixedFiles>
  </bug>
  <bug id="2967" opendate="2015-11-4 00:00:00" fixdate="2015-11-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TM address detection might not always detect the right interface on slow networks / overloaded JMs</summary>
      <description>I'm talking to a user which is facing the following issue:Some of the TaskManagers select the wrong IP address out of the available network interfaces.The first address we try to connect to is the one returned by InetAddress.getLocalHost(). This address is the right IP address to use, but the JobManager is not able to respond within the timeout (50ms) to that connection request.So the TM tries the next address, which is not publicly reachable. However, the TM can connect to the JM from there. Netty will later fail to connect to the TM from the other TMs.There are two solutions for this issue: Allow users to configure a higher timeout for the first address detection strategy. In most cases, the address returned by InetAddress.getLocalHost() is correct. By setting a high timeout, users with slow networks / overloaded JMs can make sure the TM picks this address add an Akka message which we send from the TM to the JM, and the JM tries to connect to the TM. If that succeeds, we know that the TM is reachable from the outside.The problem is that we have to start a separate actor system on the TaskManager first. We have to do this because might use a wrong ip address for the TM (so we might end up starting actor systems until we found an externally reachable ip)I'm first going to implement the first approach. If that solution works well for my user, I'll contribute this to 0.10 / 1.0.If not, I'll implement the second approach.</description>
      <version>0.9,0.10.0,1.0.0</version>
      <fixedVersion>0.10.1,1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.net.ConnectionUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="29721" opendate="2022-10-21 00:00:00" fixdate="2022-1-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Supports hive min function by native implementation</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-hive.src.test.java.org.apache.flink.connectors.hive.HiveDialectAggITCase.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.module.hive.HiveModule.java</file>
    </fixedFiles>
  </bug>
  <bug id="29722" opendate="2022-10-21 00:00:00" fixdate="2022-1-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Supports hive max function by native implementation</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-hive.src.test.java.org.apache.flink.connectors.hive.HiveDialectQueryPlanTest.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.test.java.org.apache.flink.connectors.hive.HiveDialectAggITCase.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.module.hive.HiveModule.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.functions.hive.HiveSumAggFunction.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.functions.hive.HiveMinAggFunction.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.functions.hive.HiveDeclarativeAggregateFunction.java</file>
    </fixedFiles>
  </bug>
  <bug id="2991" opendate="2015-11-10 00:00:00" fixdate="2015-2-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Extend Window Operators to Allow Efficient Fold Operation</summary>
      <description>Right now, a window fold is implemented as a WindowFunction that gets all the elements as input. No pre-aggregation is performed. The window operator should be extended to also allow the fold to also be pre-aggregated.This requires changing the signature of the WindowBuffer so that it can emit a type other than the input type.</description>
      <version>None</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBFoldingState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.AbstractRocksDBState.java</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.WindowedStream.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.AllWindowedStream.scala</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.state.StateBackendITCase.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.WindowOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.FoldWindowFunctionTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.ReduceWindowFunctionWithWindow.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.ReduceWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.ReduceAllWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.FoldWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.FoldAllWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.WindowedStream.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.AllWindowedStream.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.StateBackendTestBase.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.memory.MemoryStateBackend.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.GenericReducingState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.GenericListState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.filesystem.FsStateBackend.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.AbstractStateBackend.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.StateDescriptor.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.StateBackend.java</file>
      <file type="M">flink-contrib.flink-streaming-contrib.src.main.java.org.apache.flink.contrib.streaming.state.DbStateBackend.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBValueState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackend.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBReducingState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBListState.java</file>
    </fixedFiles>
  </bug>
  <bug id="3011" opendate="2015-11-13 00:00:00" fixdate="2015-11-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cannot cancel failing/restarting streaming job from the command line</summary>
      <description>I cannot seem to be able to cancel a failing/restarting job from the command line client. The job cannot be rescheduled so it keeps failing:The exception I get:13:58:11,240 INFO org.apache.flink.runtime.jobmanager.JobManager - Status of job 0c895d22c632de5dfe16c42a9ba818d5 (player-id) changed to RESTARTING.13:58:25,234 INFO org.apache.flink.runtime.jobmanager.JobManager - Trying to cancel job with ID 0c895d22c632de5dfe16c42a9ba818d5.13:58:25,561 WARN akka.remote.ReliableDeliverySupervisor - Association with remote system &amp;#91;akka.tcp://flink@127.0.0.1:42012&amp;#93; has failed, address is now gated for &amp;#91;5000&amp;#93; ms. Reason is: &amp;#91;Disassociated&amp;#93;.</description>
      <version>0.10.0,1.0.0</version>
      <fixedVersion>0.10.1,1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.scala.org.apache.flink.runtime.executiongraph.ExecutionGraphRestartTest.scala</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.executiongraph.ExecutionGraphRestartTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.ExecutionGraph.java</file>
    </fixedFiles>
  </bug>
  <bug id="3025" opendate="2015-11-17 00:00:00" fixdate="2015-2-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Flink Kafka consumer may get stuck due to Kafka/Zookeeper client bug</summary>
      <description>In some cases the Flink kafka consumer might fail due to https://issues.apache.org/jira/browse/KAFKA-824.Subsequently it can happen that the sources gets stuck in a Zookeeper client call (zookeeper bug).A proposed fix would be bumping the zookeeper dependency to a version that includes the fix for this bug.</description>
      <version>0.10.0,1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-connectors.flink-connector-kafka.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3032" opendate="2015-11-17 00:00:00" fixdate="2015-11-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Flink does not start on Hadoop 2.7.1 (HDP), due to class conflict</summary>
      <description>Steps to reproduce: Build flink mvn clean install -DskipTests -Dhadoop.version=2.7.1.2.3.2.0-2950 -Pvendor-repos Start it on a HDP 2.3.2 Hadoop as a yarn-session Watch it fail with6:18:56,459 INFO org.apache.flink.runtime.filecache.FileCache - User file cache uses directory /hadoop/yarn/local/usercache/flink/appcache/application_1447687546708_0005/flink-dist-cache-f4710796-598c-4778-992c-5df000faffae16:18:56,561 ERROR akka.actor.OneForOneStrategy - exception during creationakka.actor.ActorInitializationException: exception during creation at akka.actor.ActorInitializationException$.apply(Actor.scala:164) at akka.actor.ActorCell.create(ActorCell.scala:596) at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:456) at akka.actor.ActorCell.systemInvoke(ActorCell.scala:478) at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:279) at akka.dispatch.Mailbox.run(Mailbox.scala:220) at akka.dispatch.Mailbox.exec(Mailbox.scala:231) at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.pollAndExecAll(ForkJoinPool.java:1253) at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1346) at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)Caused by: java.lang.reflect.InvocationTargetException at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:526) at akka.util.Reflect$.instantiate(Reflect.scala:66) at akka.actor.ArgsReflectConstructor.produce(Props.scala:352) at akka.actor.Props.newActor(Props.scala:252) at akka.actor.ActorCell.newActor(ActorCell.scala:552) at akka.actor.ActorCell.create(ActorCell.scala:578) ... 10 moreCaused by: java.lang.NoSuchMethodError: com.fasterxml.jackson.core.JsonFactory.requiresPropertyOrdering()Z at com.fasterxml.jackson.databind.ObjectMapper.&lt;init&gt;(ObjectMapper.java:458) at com.fasterxml.jackson.databind.ObjectMapper.&lt;init&gt;(ObjectMapper.java:379) at org.apache.flink.runtime.taskmanager.TaskManager.&lt;init&gt;(TaskManager.scala:153) at org.apache.flink.yarn.YarnTaskManager.&lt;init&gt;(YarnTaskManager.scala:32) ... 19 more16:18:56,564 ERROR org.apache.flink.runtime.taskmanager.TaskManager - Actor akka://flink/user/taskmanager#-1189186354 terminated, stopping process...</description>
      <version>0.10.0,1.0.0</version>
      <fixedVersion>0.10.1,1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-shaded-hadoop.pom.xml</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.util.EnvironmentInformation.java</file>
      <file type="M">.travis.yml</file>
    </fixedFiles>
  </bug>
  <bug id="30584" opendate="2023-1-6 00:00:00" fixdate="2023-1-6 01:00:00" resolution="Done">
    <buginformation>
      <summary>Update the flame graph doc of subtask level</summary>
      <description>Update the flame graph doc of subtask level</description>
      <version>None</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.content.docs.ops.debugging.flame.graphs.md</file>
      <file type="M">docs.content.zh.docs.ops.debugging.flame.graphs.md</file>
    </fixedFiles>
  </bug>
  <bug id="3093" opendate="2015-12-1 00:00:00" fixdate="2015-2-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Introduce annotations for interface stability</summary>
      <description>For the upcoming 1.0 release, we want to mark interfaces as public/stable so that we can automatically ensure that newer Flink releases (1.1, 1.2, ..) are not breaking them.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.builder.Tuple9Builder.java</file>
      <file type="M">pom.xml</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.XORShiftRandom.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.TraversableOnceException.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.SplittableIterator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.NumberSequenceIterator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.Collector.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.Value.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.StringValue.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.ShortValue.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.ResettableValue.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.Record.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.NullValue.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.NullKeyFieldException.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.NullFieldException.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.NormalizableKey.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.MapValue.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.LongValue.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.ListValue.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.KeyFieldOutOfBoundsException.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.IntValue.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.FloatValue.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.DoubleValue.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.DeserializationException.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.CopyableValue.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.CharValue.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.ByteValue.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.BooleanValue.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.DataOutputView.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.DataInputView.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.io.LocatableInputSplit.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.io.IOReadableWritable.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.io.InputSplitSource.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.io.InputSplitAssigner.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.io.InputSplit.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.io.GenericInputSplit.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.Path.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.FSDataOutputStream.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.FSDataInputStream.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.FileSystem.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.FileStatus.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.FileInputSplit.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.BlockLocation.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.UnmodifiableConfiguration.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.Configuration.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.ConfigConstants.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.OperatorState.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.Order.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.AbstractUdfOperator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.JobSubmissionResult.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.JobID.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.JobExecutionResult.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.StrictlyLocalAssignment.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.SerializedOutputFormat.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.SerializedInputFormat.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.RichOutputFormat.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.RichInputFormat.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.OutputFormat.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.NonParallelInput.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.LocatableInputSplitAssigner.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.InputStreamFSInputWrapper.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.InputFormat.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.InitializeOnMaster.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.GenericInputFormat.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.FinalizeOnMaster.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.FileOutputFormat.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.FileInputFormat.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.DelimitedInputFormat.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.CleanupWhenUnsuccessful.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.BlockInfo.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.BinaryOutputFormat.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.BinaryInputFormat.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.RichReduceFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.RichMapPartitionFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.RichMapFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.RichJoinFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.RichGroupReduceFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.RichGroupCombineFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.RichFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.RichFoldFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.RichFlatMapFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.RichFlatJoinFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.RichFilterFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.RichCrossFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.RichCoGroupFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.ReduceFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.Partitioner.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.MapPartitionFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.MapFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.JoinFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.IterationRuntimeContext.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.InvalidTypesException.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.GroupReduceFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.GroupCombineFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.Function.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.FoldFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.FlatMapFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.FlatJoinFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.FilterFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.CrossFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.CombineFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.CoGroupFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.BroadcastVariableInitializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.AbstractRichFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.ExecutionMode.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.ExecutionConfig.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.CodeAnalysisMode.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.cache.DistributedCache.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.accumulators.SimpleAccumulator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.accumulators.ListAccumulator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.accumulators.IntCounter.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.accumulators.Histogram.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.accumulators.DoubleCounter.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.accumulators.AverageAccumulator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.accumulators.Accumulator.java</file>
      <file type="M">flink-core.pom.xml</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.WindowedStream.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.StreamExecutionEnvironment.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.SplitStream.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.KeyedStream.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.JoinedStreams.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.function.StatefulFunction.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.DataStream.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.ConnectedStreams.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.CoGroupedStreams.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.AllWindowedStream.scala</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.util.serialization.TypeInformationSerializationSchema.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.util.serialization.SerializationSchema.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.util.serialization.DeserializationSchema.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.streamrecord.StreamRecord.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.windows.Window.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.time.Time.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.TimeCharacteristic.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.ChainingStrategy.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.AbstractStreamOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.WindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.RichWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.RichAllWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.AllWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.SourceFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.RichSourceFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.ParallelSourceFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.EventTimeSourceFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.SinkFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.RichSinkFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.DiscardingSink.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.co.RichCoMapFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.co.RichCoFlatMapFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.co.CoMapFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.co.CoFlatMapFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.environment.RemoteStreamEnvironment.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.environment.LocalStreamEnvironment.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.environment.CheckpointConfig.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.WindowedStream.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.SplitStream.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.KeyedStream.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.JoinedStreams.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.IterativeStream.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.DataStreamSource.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.DataStreamSink.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.DataStream.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.ConnectedStreams.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.CoGroupedStreams.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.AllWindowedStream.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.checkpoint.CheckpointedAsynchronously.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.CheckpointingMode.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-filesystem.src.main.java.org.apache.flink.streaming.connectors.fs.SystemClock.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-filesystem.src.main.java.org.apache.flink.streaming.connectors.fs.Clock.java</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.utils.package.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.UnfinishedCoGroupOperation.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.UnitTypeInfo.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.TryTypeInfo.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.TraversableTypeInfo.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.ScalaNothingTypeInfo.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.OptionTypeInfo.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.EnumValueTypeInfo.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.EitherTypeInfo.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.CaseClassTypeInfo.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.PartitionSortedDataSet.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.joinDataSet.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.hadoop.mapred.HadoopOutputFormat.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.hadoop.mapred.HadoopInputFormat.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.hadoop.mapreduce.HadoopOutputFormat.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.hadoop.mapreduce.HadoopInputFormat.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.GroupedDataSet.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.ExecutionEnvironment.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.DataSet.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.CrossDataSet.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.CoGroupDataSet.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.AggregateDataSet.scala</file>
      <file type="M">flink-scala.src.main.java.org.apache.flink.api.scala.operators.ScalaAggregateOperator.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.StateHandle.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.CheckpointListener.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobgraph.tasks.InputSplitProvider.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.utils.ParameterTool.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.utils.DataSetUtils.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sampling.BernoulliSampler.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.RemoteEnvironment.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.UnsortedGrouping.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.UnionOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.UdfOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.TwoInputUdfOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.TwoInputOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.SortPartitionOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.SortedGrouping.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.SingleInputUdfOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.SingleInputOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.ReduceOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.ProjectOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.PartitionOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.Operator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.MapPartitionOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.MapOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.join.JoinType.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.join.JoinOperatorSetsBase.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.join.JoinFunctionAssigner.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.JoinOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.IterativeDataSet.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.GroupReduceOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.Grouping.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.GroupCombineOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.FlatMapOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.FilterOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.DistinctOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.DeltaIterationResultSet.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.DeltaIteration.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.DataSource.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.DataSink.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.CustomUnaryOperation.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.CrossOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.CoGroupOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.BulkIterationResultSet.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.AggregateOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.LocalEnvironment.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.TextOutputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.TextInputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.DiscardingOutputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.CsvReader.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.hadoop.mapred.HadoopOutputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.hadoop.mapred.HadoopInputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.hadoop.mapreduce.HadoopOutputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.hadoop.mapreduce.HadoopInputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.functions.FunctionAnnotation.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.ExecutionEnvironmentFactory.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.ExecutionEnvironment.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.DataSet.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.aggregation.Aggregations.java</file>
      <file type="M">flink-java.pom.xml</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.java.tuple.TupleGenerator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.Nothing.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.Either.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.WritableTypeInfo.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.ValueTypeInfo.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.TypeInfoParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.TypeExtractor.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.TupleTypeInfo.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.ResultTypeQueryable.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.PojoTypeInfo.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.ObjectArrayTypeInfo.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.InputTypeConfigurable.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.GenericTypeInfo.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.EnumTypeInfo.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.EitherTypeInfo.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.AvroTypeInfo.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.Tuple9.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.Tuple8.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.Tuple7.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.Tuple6.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.Tuple5.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.Tuple4.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.Tuple3.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.Tuple25.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.Tuple24.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.Tuple23.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.Tuple22.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.Tuple21.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.Tuple20.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.Tuple2.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.Tuple19.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.Tuple18.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.Tuple17.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.Tuple16.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.Tuple15.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.Tuple14.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.Tuple13.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.Tuple12.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.Tuple11.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.Tuple10.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.Tuple1.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.Tuple0.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.Tuple.java</file>
      <file type="M">flink-annotations.src.main.java.org.apache.flink.annotation.Experimental.java</file>
      <file type="M">flink-annotations.src.main.java.org.apache.flink.annotation.Internal.java</file>
      <file type="M">flink-annotations.src.main.java.org.apache.flink.annotation.Public.java</file>
      <file type="M">flink-batch-connectors.flink-avro.src.main.java.org.apache.flink.api.java.io.AvroInputFormat.java</file>
      <file type="M">flink-batch-connectors.flink-avro.src.main.java.org.apache.flink.api.java.io.AvroOutputFormat.java</file>
      <file type="M">flink-batch-connectors.flink-hadoop-compatibility.src.main.java.org.apache.flink.hadoopcompatibility.mapred.HadoopMapFunction.java</file>
      <file type="M">flink-batch-connectors.flink-hadoop-compatibility.src.main.java.org.apache.flink.hadoopcompatibility.mapred.HadoopReduceCombineFunction.java</file>
      <file type="M">flink-batch-connectors.flink-hadoop-compatibility.src.main.java.org.apache.flink.hadoopcompatibility.mapred.HadoopReduceFunction.java</file>
      <file type="M">flink-batch-connectors.flink-hbase.src.main.java.org.apache.flink.addons.hbase.TableInputFormat.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.RuntimeContext.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.util.AbstractRuntimeUDFContext.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.GenericCsvInputFormat.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.statistics.BaseStatistics.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.SingleInputSemanticProperties.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeinfo.AtomicType.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeinfo.BasicArrayTypeInfo.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeinfo.BasicTypeInfo.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeinfo.FractionalTypeInfo.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeinfo.IntegerTypeInfo.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeinfo.NothingTypeInfo.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeinfo.NumericTypeInfo.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeinfo.PrimitiveArrayTypeInfo.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeinfo.TypeInformation.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.CompositeType.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.functions.KeySelector.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.builder.Tuple0Builder.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.builder.Tuple10Builder.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.builder.Tuple11Builder.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.builder.Tuple12Builder.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.builder.Tuple13Builder.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.builder.Tuple14Builder.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.builder.Tuple15Builder.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.builder.Tuple16Builder.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.builder.Tuple17Builder.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.builder.Tuple18Builder.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.builder.Tuple19Builder.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.builder.Tuple1Builder.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.builder.Tuple20Builder.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.builder.Tuple21Builder.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.builder.Tuple22Builder.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.builder.Tuple23Builder.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.builder.Tuple24Builder.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.builder.Tuple25Builder.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.builder.Tuple2Builder.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.builder.Tuple3Builder.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.builder.Tuple4Builder.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.builder.Tuple5Builder.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.builder.Tuple6Builder.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.builder.Tuple7Builder.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.tuple.builder.Tuple8Builder.java</file>
    </fixedFiles>
  </bug>
  <bug id="30950" opendate="2023-2-7 00:00:00" fixdate="2023-4-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove flink-connector-aws-base from Flink main repo</summary>
      <description>Remove flink-connector-aws-base from Flink main repo</description>
      <version>None</version>
      <fixedVersion>1.18.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.ci.stage.sh</file>
      <file type="M">pom.xml</file>
      <file type="M">flink-connectors.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-aws-base.src.test.resources.profile</file>
      <file type="M">flink-connectors.flink-connector-aws-base.src.test.resources.META-INF.services.org.junit.jupiter.api.extension.Extension</file>
      <file type="M">flink-connectors.flink-connector-aws-base.src.test.resources.log4j2-test.properties</file>
      <file type="M">flink-connectors.flink-connector-aws-base.src.test.resources.archunit.properties</file>
      <file type="M">flink-connectors.flink-connector-aws-base.src.test.java.org.apache.flink.connector.aws.util.TestUtil.java</file>
      <file type="M">flink-connectors.flink-connector-aws-base.src.test.java.org.apache.flink.connector.aws.util.AWSGeneralUtilTest.java</file>
      <file type="M">flink-connectors.flink-connector-aws-base.src.test.java.org.apache.flink.connector.aws.util.AWSAsyncSinkUtilTest.java</file>
      <file type="M">flink-connectors.flink-connector-aws-base.src.test.java.org.apache.flink.connector.aws.testutils.LocalstackContainer.java</file>
      <file type="M">flink-connectors.flink-connector-aws-base.src.test.java.org.apache.flink.connector.aws.testutils.AWSServicesTestUtils.java</file>
      <file type="M">flink-connectors.flink-connector-aws-base.src.test.java.org.apache.flink.connector.aws.table.util.AWSOptionsUtilTest.java</file>
      <file type="M">flink-connectors.flink-connector-aws-base.src.test.java.org.apache.flink.connector.aws.table.util.AsyncClientOptionsUtilsTest.java</file>
      <file type="M">flink-connectors.flink-connector-aws-base.src.test.java.org.apache.flink.architecture.TestCodeArchitectureTest.java</file>
      <file type="M">flink-connectors.flink-connector-aws-base.src.main.resources.log4j2.properties</file>
      <file type="M">flink-connectors.flink-connector-aws-base.src.main.java.org.apache.flink.connector.aws.util.AWSGeneralUtil.java</file>
      <file type="M">flink-connectors.flink-connector-aws-base.src.main.java.org.apache.flink.connector.aws.util.AWSCredentialFatalExceptionClassifiers.java</file>
      <file type="M">flink-connectors.flink-connector-aws-base.src.main.java.org.apache.flink.connector.aws.util.AWSAuthenticationException.java</file>
      <file type="M">flink-connectors.flink-connector-aws-base.src.main.java.org.apache.flink.connector.aws.util.AWSAsyncSinkUtil.java</file>
      <file type="M">flink-connectors.flink-connector-aws-base.src.main.java.org.apache.flink.connector.aws.table.util.AWSOptionUtils.java</file>
      <file type="M">flink-connectors.flink-connector-aws-base.src.main.java.org.apache.flink.connector.aws.table.util.AsyncClientOptionsUtils.java</file>
      <file type="M">flink-connectors.flink-connector-aws-base.src.main.java.org.apache.flink.connector.aws.config.AWSConfigConstants.java</file>
      <file type="M">flink-connectors.flink-connector-aws-base.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-aws-base.archunit-violations.stored.rules</file>
      <file type="M">flink-connectors.flink-connector-aws-base.archunit-violations.733a854b-2487-43da-a5fa-9b089af5fb4e</file>
      <file type="M">flink-connectors.flink-connector-aws-base.archunit-violations.33252236-fc9f-4f63-b537-39e2322f7ccd</file>
      <file type="M">flink-architecture-tests.pom.xml</file>
      <file type="M">flink-architecture-tests.flink-architecture-tests-production.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3098" opendate="2015-12-2 00:00:00" fixdate="2015-12-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cast from Date to Long throw compile error.</summary>
      <description>While cast Date to Long in Table API, the generated code throw comile error. Looks like:Caused by: org.codehaus.commons.compiler.CompileException: Line 33, Column 23: Expression "result$5" is not an rvalue at org.codehaus.janino.UnitCompiler.compileError(UnitCompiler.java:10062) at org.codehaus.janino.UnitCompiler.toRvalueOrCompileException(UnitCompiler.java:5960) at org.codehaus.janino.UnitCompiler.compileContext2(UnitCompiler.java:3172) at org.codehaus.janino.UnitCompiler.access$5400(UnitCompiler.java:182)</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-staging.flink-table.src.test.scala.org.apache.flink.api.scala.table.test.CastingITCase.scala</file>
      <file type="M">flink-staging.flink-table.src.test.java.org.apache.flink.api.java.table.test.CastingITCase.java</file>
      <file type="M">flink-staging.flink-table.src.main.scala.org.apache.flink.api.table.codegen.ExpressionCodeGenerator.scala</file>
    </fixedFiles>
  </bug>
  <bug id="3100" opendate="2015-12-2 00:00:00" fixdate="2015-12-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Signal handler prints error on normal shutdown of cluster</summary>
      <description>On a regular cluster shutdown, the following messages are printed in the jobmanager/taskmanager log:16:03:22,877 ERROR org.apache.flink.runtime.jobmanager.JobManager - RECEIVED SIGNAL 15: SIGTERM16:03:22,878 ERROR org.apache.flink.runtime.jobmanager.JobManager - This JVM will shut down because it was killed from the outside.The log level ERROR is not correct and tools which rely on checking the log for errors and exceptions choke on this.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.util.SignalHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="3115" opendate="2015-12-4 00:00:00" fixdate="2015-3-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update Elasticsearch connector to 2.X</summary>
      <description>The Elasticsearch connector is not up to date anymore. In version 2.X the API changed. The code needs to be adapted. Probably it makes sense to have a new class ElasticsearchSink2.</description>
      <version>0.10.0,0.10.1,1.0.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-connectors.pom.xml</file>
      <file type="M">docs.apis.streaming.connectors.index.md</file>
    </fixedFiles>
  </bug>
  <bug id="3135" opendate="2015-12-7 00:00:00" fixdate="2015-1-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add chainable driver for UNARY_NO_OP strategy</summary>
      <description>A chainable driver for UNARY_NO_OP strategy would decrease the serialization overhead in certain situations.Should be fairly easy to implement.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.NoOpDriver.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.DriverStrategy.java</file>
    </fixedFiles>
  </bug>
  <bug id="31540" opendate="2023-3-21 00:00:00" fixdate="2023-7-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support to set source idle-timeout options in sql layer</summary>
      <description>Support to configure the source idle-timeout for the source which implements the `SupportsWatermarkPushDown` interface.User can configure the source idle-timeout in flink sql job with table options or 'OPTIONS' hint, as disgussed in https://cwiki.apache.org/confluence/display/FLINK/FLIP-296%3A+Extend+watermark-related+features+for+SQL</description>
      <version>None</version>
      <fixedVersion>1.18.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.test.resources.org.apache.flink.table.planner.plan.rules.logical.PushWatermarkIntoTableSourceScanRuleTest.xml</file>
      <file type="M">flink-table.flink-table-planner.src.test.resources.org.apache.flink.table.planner.plan.nodes.exec.stream.TableSourceJsonPlanTest.jsonplan.testWatermarkPushDown.out</file>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.plan.rules.logical.PushWatermarkIntoTableSourceScanRuleTest.java</file>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.plan.nodes.exec.serde.DynamicTableSourceSpecSerdeTest.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.rules.logical.PushWatermarkIntoTableSourceScanRuleBase.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.abilities.source.WatermarkPushDownSpec.java</file>
      <file type="M">flink-table.flink-table-common.src.test.java.org.apache.flink.table.factories.FactoryUtilTest.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.watermark.WatermarkParams.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.factories.FactoryUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="3155" opendate="2015-12-9 00:00:00" fixdate="2015-5-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update Flink docker version to latest stable Flink version</summary>
      <description>It would be nice to always set the Docker Flink binary URL to point to the latest Flink version. Until then, this JIRA keeps track of the updates for releases.</description>
      <version>1.0.0,1.1.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-contrib.docker-flink.Dockerfile</file>
      <file type="M">flink-contrib.docker-flink.docker-compose.yml</file>
      <file type="M">flink-contrib.docker-flink.flink.Dockerfile</file>
      <file type="M">flink-contrib.docker-flink.base.Dockerfile</file>
    </fixedFiles>
  </bug>
  <bug id="3158" opendate="2015-12-10 00:00:00" fixdate="2015-2-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Shading does not remove google guava from flink-dist fat jar</summary>
      <description>It seems that guava somehow slipped our checks and made it into the flink-dist fat jar again.</description>
      <version>0.10.1,1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3161" opendate="2015-12-11 00:00:00" fixdate="2015-2-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Externalize cluster start-up and tear-down when available</summary>
      <description>I have been using pdsh, pdcp, and rpdcp to both distribute compiled Flink and to start and stop the TaskManagers. The current shell script initializes TaskManagers one-at-a-time. This is trivial to background but would be unthrottled.From pdsh's archived homepage: "uses a sliding window of threads to execute remote commands, conserving socket resources while allowing some connections to timeout if needed".What other tools could be supported when available?</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-dist.src.main.flink-bin.bin.stop-cluster.sh</file>
      <file type="M">flink-dist.src.main.flink-bin.bin.start-cluster.sh</file>
    </fixedFiles>
  </bug>
  <bug id="3178" opendate="2015-12-16 00:00:00" fixdate="2015-1-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make Closing Behavior of Window Operators Configurable</summary>
      <description>Right now, all window operators emit (incomplete) in-flight windows when they are closing down. This happens for two reasons:1. sources emit a final Long.MAX_VALUE watermark to flush out windows when they close.2. window operators emit in-flight windows in their close() methodFor some users this might not be the desired behavior so we should either change it or make it configurable.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.OneInputStreamOperatorTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.AggregatingAlignedProcessingTimeWindowOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.AccumulatingAlignedProcessingTimeWindowOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.complex.ComplexIntegrationTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.NonKeyedWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.AbstractAlignedProcessingTimeWindowOperator.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.java.org.apache.flink.streaming.examples.windowing.util.TopSpeedWindowingExampleData.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.java.org.apache.flink.streaming.examples.windowing.SessionWindowing.java</file>
    </fixedFiles>
  </bug>
  <bug id="31780" opendate="2023-4-12 00:00:00" fixdate="2023-5-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow users to disable "Ensemble tracking" for ZooKeeper</summary>
      <description>In Apache Curator an option to skip ensemble tracking was added since version 5.0.0 (CURATOR-568)This can be useful in certain scenarios in which CuratorFramework is accessing to ZK clusters via load balancer or Virtual IPs. Thus in case Zookeeper of Flink user is running behind LB or Virtual IP ensemble tracking could be disabled too.In case ZooKeeper is hidden under VIP it can return URL during Ensemble Tracking, which would lead to Unresolved Host Exception inside Curator Framework. On Flink level it would lead to cluster restart.Currently HA with ZooKeeper can even lead to the JobManager failure. The scenario of the failure is next: Flink connects to ZooKeeper via configured URL. Ensemble tracking gets a new URL of ensemble, which is not obligatory accessible for Flink, because Zookeeper is under VIP. In case of reconnect Flink fails to Zookeeper, moreover due to "UnresolvedHostException" Flink's jobManager is killed.Acceptance Criteria: Users of Apache Flink has a Zookeeper config option to disable ensemble tracking for ZooKeeper.</description>
      <version>None</version>
      <fixedVersion>1.18.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.util.ZooKeeperUtils.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.HighAvailabilityOptions.java</file>
      <file type="M">docs.layouts.shortcodes.generated.high.availability.configuration.html</file>
      <file type="M">docs.layouts.shortcodes.generated.expert.high.availability.zk.section.html</file>
    </fixedFiles>
  </bug>
  <bug id="31786" opendate="2023-4-12 00:00:00" fixdate="2023-5-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Removing unused HighAvailabilityServices implementations</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.highavailability.TestingManualHighAvailabilityServices.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.highavailability.ManualLeaderService.java</file>
    </fixedFiles>
  </bug>
  <bug id="31787" opendate="2023-4-12 00:00:00" fixdate="2023-4-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add the explicit ROW constructor to the system function doc</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.18.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.layouts.shortcodes.sql.functions.zh.html</file>
      <file type="M">docs.layouts.shortcodes.sql.functions.html</file>
      <file type="M">docs.data.sql.functions.zh.yml</file>
      <file type="M">docs.data.sql.functions.yml</file>
    </fixedFiles>
  </bug>
  <bug id="3194" opendate="2015-12-30 00:00:00" fixdate="2015-1-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove web client</summary>
      <description>With FLINK-2978 (integrating program upload and start into the regular dashboard), we can remove the outdated web client.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-dist.src.main.resources.flink-conf.yaml</file>
      <file type="M">flink-dist.src.main.flink-bin.bin.webclient.sh</file>
      <file type="M">flink-dist.src.main.flink-bin.bin.stop-webclient.sh</file>
      <file type="M">flink-dist.src.main.flink-bin.bin.start-webclient.sh</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.web.WebInterfaceServer.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.web.PlanDisplayServlet.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.web.JobSubmissionServlet.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.web.JobsServlet.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.web.JobJSONServlet.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.web.GUIServletStub.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.WebFrontend.java</file>
      <file type="M">flink-clients.pom.xml</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.ConfigConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="32000" opendate="2023-5-4 00:00:00" fixdate="2023-5-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expose vertex max parallelism in the WebUI</summary>
      <description>It would be great to expose max parallelism in the vertex detail drawer for debug purposes .</description>
      <version>None</version>
      <fixedVersion>1.18.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.detail.job-overview-drawer-detail.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.detail.job-overview-drawer-detail.component.html</file>
    </fixedFiles>
  </bug>
  <bug id="3220" opendate="2016-1-12 00:00:00" fixdate="2016-1-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Flink does not start on Hortonworks Sandbox 2.3.2 due to missing class</summary>
      <description>Steps to reproduce: Check out current master build flink mvn clean install -DskipTests -Dhadoop.version=2.7.1.2.3.2.0-2950 -Pvendor-repos start flink ./bin/yarn-session.sh -n 1 failure:[root@sandbox build-target]# ./bin/yarn-session.sh -n 113:29:58,170 WARN org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable13:29:58,709 INFO org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl - Timeline service address: http://sandbox.hortonworks.com:8188/ws/v1/timeline/13:29:58,849 INFO org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at sandbox.hortonworks.com/10.0.2.15:805013:29:59,039 INFO org.apache.flink.yarn.FlinkYarnClient - Using values:13:29:59,040 INFO org.apache.flink.yarn.FlinkYarnClient - TaskManager count = 113:29:59,040 INFO org.apache.flink.yarn.FlinkYarnClient - JobManager memory = 102413:29:59,040 INFO org.apache.flink.yarn.FlinkYarnClient - TaskManager memory = 1024Exception in thread "main" java.lang.NoClassDefFoundError: javax/servlet/Filter at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:800) at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) at java.net.URLClassLoader.defineClass(URLClassLoader.java:449) at java.net.URLClassLoader.access$100(URLClassLoader.java:71) at java.net.URLClassLoader$1.run(URLClassLoader.java:361) at java.net.URLClassLoader$1.run(URLClassLoader.java:355) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:354) at java.lang.ClassLoader.loadClass(ClassLoader.java:425) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308) at java.lang.ClassLoader.loadClass(ClassLoader.java:358) at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:800) at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) at java.net.URLClassLoader.defineClass(URLClassLoader.java:449) at java.net.URLClassLoader.access$100(URLClassLoader.java:71) at java.net.URLClassLoader$1.run(URLClassLoader.java:361) at java.net.URLClassLoader$1.run(URLClassLoader.java:355) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:354) at java.lang.ClassLoader.loadClass(ClassLoader.java:425) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308) at java.lang.ClassLoader.loadClass(ClassLoader.java:358) at org.apache.hadoop.hdfs.DFSConfigKeys.&lt;clinit&gt;(DFSConfigKeys.java:245) at org.apache.hadoop.hdfs.DFSClient$Conf.&lt;init&gt;(DFSClient.java:509) at org.apache.hadoop.hdfs.DFSClient.&lt;init&gt;(DFSClient.java:638) at org.apache.hadoop.hdfs.DFSClient.&lt;init&gt;(DFSClient.java:619) at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:149) at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2653) at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:92) at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2687) at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2669) at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:170) at org.apache.flink.yarn.FlinkYarnClientBase.deployInternal(FlinkYarnClientBase.java:516) at org.apache.flink.yarn.FlinkYarnClientBase.deploy(FlinkYarnClientBase.java:337) at org.apache.flink.client.FlinkYarnSessionCli.run(FlinkYarnSessionCli.java:406) at org.apache.flink.client.FlinkYarnSessionCli.main(FlinkYarnSessionCli.java:348)Caused by: java.lang.ClassNotFoundException: javax.servlet.Filter at java.net.URLClassLoader$1.run(URLClassLoader.java:366) at java.net.URLClassLoader$1.run(URLClassLoader.java:355) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:354) at java.lang.ClassLoader.loadClass(ClassLoader.java:425) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308) at java.lang.ClassLoader.loadClass(ClassLoader.java:358) ... 39 moreThis is a similar issue https://issues.apache.org/jira/browse/FLINK-3032</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-shaded-hadoop.flink-shaded-hadoop2.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="32290" opendate="2023-6-8 00:00:00" fixdate="2023-6-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable -XX:+IgnoreUnrecognizedVMOptions</summary>
      <description>We can make our lives a lot easier by enabling IgnoreUnrecognizedVMOptions for all processes. With this we can set add-opens/add-exports independent of what JDK is actually being used, removing a major source of complexity.</description>
      <version>None</version>
      <fixedVersion>1.18.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn.src.test.java.org.apache.flink.yarn.YarnClusterDescriptorTest.java</file>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.YarnClusterDescriptor.java</file>
      <file type="M">flink-test-utils-parent.flink-test-utils.src.main.java.org.apache.flink.test.util.TestProcessBuilder.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.testutils.TestJvmProcess.java</file>
      <file type="M">flink-python.pyflink.pyflink.gateway.server.py</file>
      <file type="M">flink-dist.src.main.flink-bin.bin.config.sh</file>
    </fixedFiles>
  </bug>
  <bug id="3241" opendate="2016-1-15 00:00:00" fixdate="2016-1-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scala 2.11 Flink binaries pull in Scala 2.10 dependencies</summary>
      <description>A user reported that Flink Scala 2.11 jars depend on Scala 2.10 dependencies. This might be caused by the recent changes to the project structure (removing flink-staging) which broke apparently the Scala version changing scripts.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.deploy.to.maven.sh</file>
      <file type="M">tools.change-scala-version.sh</file>
      <file type="M">flink-quickstart.flink-quickstart-scala.src.main.resources.archetype-resources.pom.xml</file>
      <file type="M">flink-quickstart.flink-quickstart-java.src.main.resources.archetype-resources.pom.xml</file>
      <file type="M">flink-java8.pom.xml</file>
      <file type="M">flink-dist.pom.xml</file>
      <file type="M">docs.quickstart.java.api.quickstart.md</file>
      <file type="M">docs.index.md</file>
      <file type="M">docs.apis.local.execution.md</file>
      <file type="M">docs.apis.batch.index.md</file>
      <file type="M">docs.apis.batch.examples.md</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.explain.PlanJsonParser.java</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.explain.Node.java</file>
    </fixedFiles>
  </bug>
  <bug id="32410" opendate="2023-6-21 00:00:00" fixdate="2023-1-21 01:00:00" resolution="Unresolved">
    <buginformation>
      <summary>Allocate hash-based collections with sufficient capacity for expected size</summary>
      <description>The JDK API to create hash-based collections for a certain capacity is arguable misleading because it doesn't size the collections to "hold a specific number of items" like you'd expect it would. Instead it sizes it to hold load-factor% of the specified number.For the common pattern to allocate a hash-based collection with the size of expected elements to avoid rehashes, this means that a rehash is essentially guaranteed.We should introduce helper methods (similar to Guava's `Maps.newHashMapWithExpectedSize(int)`) for allocations for expected size and replace the direct constructor calls with those.</description>
      <version>None</version>
      <fixedVersion>1.18.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.OperatorState.java</file>
      <file type="M">flink-test-utils-parent.flink-test-utils.src.main.java.org.apache.flink.connector.upserttest.sink.UpsertTestFileUtil.java</file>
      <file type="M">flink-table.flink-table-runtime.src.main.java.org.apache.flink.table.runtime.functions.SqlFunctionUtils.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.dataview.NullAwareMapSerializer.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.catalog.stats.CatalogColumnStatistics.java</file>
      <file type="M">flink-table.flink-table-code-splitter.src.main.java.org.apache.flink.table.codesplit.BlockStatementSplitter.java</file>
      <file type="M">flink-table.flink-table-code-splitter.src.main.java.org.apache.flink.table.codesplit.BlockStatementGrouper.java</file>
      <file type="M">flink-table.flink-sql-client.src.main.java.org.apache.flink.table.client.gateway.result.MaterializedCollectStreamResult.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.SubtaskCheckpointCoordinatorImpl.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.OperatorChain.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.sink.committables.CommittableCollectorSerializer.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.recovery.RescalingStreamTaskNetworkInput.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.co.CoBroadcastWithNonKeyedOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.co.CoBroadcastWithKeyedOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.datagen.RandomGenerator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.filesystem.BucketStateSerializer.java</file>
      <file type="M">flink-state-backends.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBStateUploader.java</file>
      <file type="M">flink-state-backends.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.PredefinedOptions.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.ThreadInfoSampleService.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.slot.TaskSlot.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.slot.DefaultTimerService.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.ttl.TtlMapState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.RegisteredKeyValueStateBackendMetaInfo.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.RegisteredBroadcastStateBackendMetaInfo.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.OperatorStateCheckpointOutputStream.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.metainfo.StateMetaInfoSnapshotReadersWriters.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.heap.HeapSnapshotResources.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.heap.HeapPriorityQueueSet.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.DefaultOperatorStateBackendSnapshotStrategy.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.checkpoints.CheckpointStatistics.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.metrics.MetricStore.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.job.JobDetailsHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.HandlerRequest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.resourcemanager.ResourceManager.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.resourcemanager.DefaultJobLeaderIdService.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.scope.ScopeFormat.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.ReporterSetup.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobmaster.slotpool.LocationPreferenceSlotSelectionStrategy.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.partition.ResultPartitionManager.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.dispatcher.Dispatcher.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.dispatcher.DefaultJobManagerRunnerRegistry.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.TaskStateSnapshot.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.TaskStateAssignment.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.TaskState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.StateAssignmentOperation.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.RoundRobinOperatorStateRepartitioner.java</file>
      <file type="M">flink-connectors.flink-connector-files.src.test.java.org.apache.flink.connector.file.table.PartitionWriterTest.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.planner.delegation.hive.copy.HiveParserBaseSemanticAnalyzer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.runtime.PojoSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.runtime.PojoSerializerSnapshot.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.runtime.PojoSerializerSnapshotData.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.runtime.ValueSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.LinkedOptionalMap.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.nfa.sharedbuffer.SharedBufferAccessor.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.Execution.java</file>
      <file type="M">flink-table.flink-table-common.src.test.java.org.apache.flink.table.connector.sink.TestManagedSinkCommittableSerializer.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.planner.delegation.hive.HiveParserCalcitePlanner.java</file>
      <file type="M">flink-end-to-end-tests.flink-datastream-allround-test.src.main.java.org.apache.flink.streaming.tests.artificialstate.ArtificialKeyedStateMapper.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.PendingCheckpoint.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.RescaleMappings.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.execution.librarycache.BlobLibraryCacheManager.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.memory.MemoryManager.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.sort.SpillChannelManager.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.job.metrics.AbstractAggregatingMetricsHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.partition.PartitionTable.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskExecutor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.MessageAcknowledgingSourceBase.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.SerializedCheckpointData.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.async.queue.UnorderedStreamElementQueue.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.InternalTimersSnapshotReaderWriters.java</file>
      <file type="M">flink-table.flink-table-runtime.src.main.java.org.apache.flink.table.runtime.operators.sort.SpillChannelManager.java</file>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.YarnClusterDescriptor.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.connectors.hive.util.HivePartitionUtils.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.functions.hive.conversion.HiveInspectors.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.accumulators.AccumulatorHelper.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.MapSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.TupleTypeInfo.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.Configuration.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.CollectionUtil.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.InstantiationUtil.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.util.CollectionUtilTest.java</file>
      <file type="M">flink-docs.src.main.java.org.apache.flink.docs.configuration.ConfigOptionsDocGenerator.java</file>
      <file type="M">flink-end-to-end-tests.flink-tpcds-test.src.main.java.org.apache.flink.table.tpcds.schema.TpcdsSchemaProvider.java</file>
      <file type="M">flink-formats.flink-avro.src.main.java.org.apache.flink.formats.avro.RowDataToAvroConverters.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.utils.MultipleParameterTool.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.utils.ParameterTool.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.nfa.NFA.java</file>
      <file type="M">flink-libraries.flink-state-processing-api.src.main.java.org.apache.flink.state.api.runtime.metadata.SavepointMetadata.java</file>
      <file type="M">flink-libraries.flink-state-processing-api.src.main.java.org.apache.flink.state.api.runtime.metadata.SavepointMetadataV2.java</file>
      <file type="M">flink-rpc.flink-rpc-akka.src.main.java.org.apache.flink.runtime.rpc.akka.AkkaRpcService.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.Checkpoints.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.CheckpointStatsHistory.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.metadata.MetadataSerializers.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.metadata.MetadataV2V3SerializerBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="3243" opendate="2016-1-15 00:00:00" fixdate="2016-2-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix Interplay of TimeCharacteristic and Time Windows</summary>
      <description>As per the discussion on the Dev ML: http://apache-flink-mailing-list-archive.1008284.n3.nabble.com/DISCUSS-Time-Behavior-in-Streaming-Jobs-Event-time-processing-time-td9616.html.The discussion seems to have converged on option 2): Add dedicated WindowAssigners for processing time and event time timeWindow() and timeWindowAll() respect the set TimeCharacteristic.This will make the easy stuff easy, i.e. using time windows and quickly switching the time characteristic. Users will then have the flexibility to mix different kinds of window assigners in their job.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-scala.src.test.scala.org.apache.flink.streaming.api.scala.WindowTranslationTest.scala</file>
      <file type="M">flink-streaming-scala.src.test.scala.org.apache.flink.streaming.api.scala.AllWindowTranslationTest.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.KeyedStream.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.DataStream.scala</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.WindowTranslationTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.TimeWindowTranslationTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.AllWindowTranslationTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.NonKeyedWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.EvictingWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.EvictingNonKeyedWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.assigners.TumblingTimeWindows.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.assigners.SlidingTimeWindows.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.WindowedStream.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.KeyedStream.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.DataStream.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.AllWindowedStream.java</file>
      <file type="M">docs.apis.streaming.index.md</file>
    </fixedFiles>
  </bug>
  <bug id="32430" opendate="2023-6-25 00:00:00" fixdate="2023-7-25 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Support configuring CatalogStore through flink conf</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.18.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.api.EnvironmentTest.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.catalog.CommonCatalogOptions.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.catalog.CatalogStoreHolder.java</file>
      <file type="M">flink-table.flink-table-api-scala-bridge.src.main.scala.org.apache.flink.table.api.bridge.scala.internal.StreamTableEnvironmentImpl.scala</file>
      <file type="M">flink-table.flink-table-api-java.src.test.java.org.apache.flink.table.catalog.CatalogManagerTest.java</file>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.operations.ddl.CreateCatalogOperation.java</file>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.factories.TableFactoryUtil.java</file>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.api.TableEnvironment.java</file>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.api.internal.TableEnvironmentImpl.java</file>
      <file type="M">flink-table.flink-table-api-java-bridge.src.main.java.org.apache.flink.table.api.bridge.java.internal.StreamTableEnvironmentImpl.java</file>
      <file type="M">flink-table.flink-sql-gateway.src.test.java.org.apache.flink.table.gateway.service.session.SessionManagerImplTest.java</file>
      <file type="M">flink-table.flink-sql-gateway.src.main.java.org.apache.flink.table.gateway.service.context.SessionContext.java</file>
      <file type="M">flink-table.flink-sql-gateway.pom.xml</file>
      <file type="M">flink-python.pyflink.table.tests.test.environment.completeness.py</file>
    </fixedFiles>
  </bug>
  <bug id="32431" opendate="2023-6-25 00:00:00" fixdate="2023-7-25 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Support configuring CatalogStore in Table API</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.18.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.api.EnvironmentSettings.java</file>
      <file type="M">flink-python.pyflink.table.tests.test.environment.settings.completeness.py</file>
    </fixedFiles>
  </bug>
  <bug id="32433" opendate="2023-6-25 00:00:00" fixdate="2023-7-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add built-in FileCatalogStore</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.18.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-common.src.test.java.org.apache.flink.table.factories.TestCatalogStoreFactory.java</file>
      <file type="M">flink-table.flink-table-common.src.test.java.org.apache.flink.table.factories.FactoryUtilTest.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.factories.FactoryUtil.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.factories.CatalogStoreFactory.java</file>
      <file type="M">flink-table.flink-table-api-java.src.test.java.org.apache.flink.table.catalog.GenericInMemoryCatalogStoreFactoryTest.java</file>
      <file type="M">flink-table.flink-table-api-java.src.main.resources.META-INF.services.org.apache.flink.table.factories.Factory</file>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.catalog.GenericInMemoryCatalogStoreFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="3247" opendate="2016-1-17 00:00:00" fixdate="2016-2-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Kafka Connector unusable with quickstarts - shading issue</summary>
      <description>The Kafka Connector now requires Curator, which is referenced as flink-shaded-curator. The quickstarts make sure it is not packaged into the jar file via exclusions.The curator classes are however only in relocated form in the flink-dist.jar - relocated manually in the flink-runtime project. The connector can thus not use find the Curator classes and fails.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-quickstart.flink-quickstart-scala.src.main.resources.archetype-resources.pom.xml</file>
      <file type="M">flink-quickstart.flink-quickstart-java.src.main.resources.archetype-resources.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="32473" opendate="2023-6-28 00:00:00" fixdate="2023-7-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Introduce base interfaces for time travel</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.catalog.ResolvedCatalogTable.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.catalog.DefaultCatalogTable.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.catalog.CatalogTable.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.catalog.Catalog.java</file>
    </fixedFiles>
  </bug>
  <bug id="32474" opendate="2023-6-28 00:00:00" fixdate="2023-7-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support time travel in table planner</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.18.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.plan.stream.sql.join.TemporalJoinTest.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.plan.stream.sql.join.LookupJoinTest.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.plan.batch.sql.join.LookupJoinTest.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalSnapshot.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.calcite.FlinkPlannerImpl.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.catalog.FlinkSchema.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.catalog.DatabaseCalciteSchema.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.catalog.CatalogManagerCalciteSchema.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.catalog.CatalogCalciteSchema.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.calcite.FlinkCalciteSqlValidator.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.calcite.sql2rel.SqlToRelConverter.java</file>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.catalog.CatalogManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="32475" opendate="2023-6-28 00:00:00" fixdate="2023-9-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add doc for time travel</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.18.0,1.19.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.content.docs.dev.table.sql.queries.overview.md</file>
      <file type="M">docs.content.docs.dev.table.catalogs.md</file>
      <file type="M">docs.content.zh.docs.dev.table.sql.queries.overview.md</file>
      <file type="M">docs.content.zh.docs.dev.table.catalogs.md</file>
    </fixedFiles>
  </bug>
  <bug id="3254" opendate="2016-1-18 00:00:00" fixdate="2016-2-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CombineFunction interface not respected</summary>
      <description>The DataSet API offers a CombineFunction interface, which differs from the GroupCombineFunction interface by being restricted to return a single value instead of returning arbitrary many values through a Collector.The JavaDocs of the GroupCombineFunction point to the CombineFunction interface, advertising it as more efficient.However, the CombineFunction interface is nor respected by Flink, i.e., a GroupReduceFunction that implements this interface is executed without leveraging the combine method.</description>
      <version>0.10.1,1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.GroupReduceOperator.java</file>
    </fixedFiles>
  </bug>
  <bug id="3274" opendate="2016-1-22 00:00:00" fixdate="2016-1-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Prefix Kafka connector accumulators with unique id</summary>
      <description>Flink might chain together two data sinks under certain conditions.In that case, the metrics accumulators will have a name clash (each task can have an accumulator only once, with chaining multiple sinks are sharing a task).Also, when merging accumulators from different tasks for a per-job result, having multiple kafka producers or consumers will lead to wrong results as the merging happens only on a per-name basis.With this issue, I'd like to introduce a unique id for consumers and producers when registering accumulators</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducerBase.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer09.java</file>
    </fixedFiles>
  </bug>
  <bug id="3287" opendate="2016-1-25 00:00:00" fixdate="2016-2-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Flink Kafka Consumer fails due to Curator version conflict</summary>
      <description>14:32:38,542 INFO org.apache.flink.yarn.YarnJobManager - Status of job 8eb92c1e3a1c050ecaccd50c6298ac7a (Flink Streaming Job) changed to FAILING.java.lang.NoSuchMethodError: org.apache.curator.utils.ZKPaths.fixForNamespace(Ljava/lang/String;Ljava/lang/String;Z)Ljava/lang/String; at org.apache.curator.framework.imps.NamespaceImpl.fixForNamespace(NamespaceImpl.java:82) at org.apache.curator.framework.imps.NamespaceImpl.newNamespaceAwareEnsurePath(NamespaceImpl.java:87) at org.apache.curator.framework.imps.CuratorFrameworkImpl.newNamespaceAwareEnsurePath(CuratorFrameworkImpl.java:457) at org.apache.flink.streaming.connectors.kafka.internals.ZookeeperOffsetHandler.getOffsetFromZooKeeper(ZookeeperOffsetHandler.java:122) at org.apache.flink.streaming.connectors.kafka.internals.ZookeeperOffsetHandler.seekFetcherToInitialOffsets(ZookeeperOffsetHandler.java:90) at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer.open(FlinkKafkaConsumer.java:401) at org.apache.flink.api.common.functions.util.FunctionUtils.openFunction(FunctionUtils.java:36) at org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.open(AbstractUdfStreamOperator.java:89) at org.apache.flink.streaming.runtime.tasks.StreamTask.openAllOperators(StreamTask.java:305) at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:227) at org.apache.flink.runtime.taskmanager.Task.run(Task.java:567) at java.lang.Thread.run(Thread.java:745)This flink snapshot version was built from master commit c7ada8d785087e0209071a8219ff841006b96639</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3289" opendate="2016-1-25 00:00:00" fixdate="2016-1-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Double reference to flink-contrib</summary>
      <description>A commit to solve FLINK-1452 introduced the flink-contrib sub-project in the documentation. This other commit to solve FLINK-1712 duplicated the flink-contrib line to specify it as a container of early-stage project.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.internals.general.arch.md</file>
    </fixedFiles>
  </bug>
  <bug id="3300" opendate="2016-1-28 00:00:00" fixdate="2016-2-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Concurrency Bug in Yarn JobManager</summary>
      <description>The change to use the async ResourceManager client introduced concurrency problems: The ResourceManager callback threads run and change data structures at the same time as the actor methods, voiding the actor concurrency model.One example that can happen is that the callback tries to start containers while the ContainerLaunchContext is still not set (because the actor method is still in the StartYarnSession method).Bug introducing commit: https://github.com/apache/flink/commit/4e52fe4304566e5239996b3d48290e0c1f0772e8Quick fix could be to revert the commit. Better solution would be to let the callback methods send actor messages to the YobManager, rather than directly acting.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn.src.main.scala.org.apache.flink.yarn.YarnMessages.scala</file>
      <file type="M">flink-yarn.src.main.scala.org.apache.flink.yarn.YarnJobManager.scala</file>
    </fixedFiles>
  </bug>
  <bug id="3313" opendate="2016-2-2 00:00:00" fixdate="2016-2-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Kafka08ITCase.testOneSourceMultiplePartitions fails with EOFException</summary>
      <description>The deserialization has recently been modified: https://github.com/apache/flink/commit/92efcd34a5da2bccb07666f2c647974ea3e7c94fthis is the log: https://s3.amazonaws.com/archive.travis-ci.org/jobs/106401688/log.txt</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.LegacyFetcher.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.InstantiationUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="3314" opendate="2016-2-2 00:00:00" fixdate="2016-2-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Early cancel calls can cause Tasks to not cancel properly</summary>
      <description>When a task receives the "cancel()" call before the operators are properly instantiated, it can be that the operator never receives a cancel call.In certain cases, this causes the operator to hang.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTask.java</file>
    </fixedFiles>
  </bug>
  <bug id="3315" opendate="2016-2-2 00:00:00" fixdate="2016-3-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix Slot Sharing in Streaming API</summary>
      <description>Right now, the slot sharing/resource group logic is a bit "nebulous". The slot sharing group that operators are put in depends on the order in which operations are created. For example, in this case:Source a = env.source()Source b = env.source()a.map().startNewResourceGroup().sink() b.map().sink()We end up with two resource groups: group 1: source a group 2: map(), sink(), source b, map(), sink()The reason is that the slot sharing id is incremented when transforming the startNewResouceGroup() call and all operators that are transformed afterwards in graph traversal get that new slot sharing id.(There is also isolateResources() which can be used to isolate an operator.)What I propose is to remove startNewResourceGroup() and isolateResouces() and replace it with slotSharingGroup(String). By default, operations would be in slot sharing group "default". This allows very fine grained control over what operators end up in which slot sharing group. For example, I could have this topology:Source a = env.source().slotSharingGroup("sources")Source b = env.source().slotSharingGroup("sources")a.map().slotSharingGroup("heavy a").sink().slotSharingGroup("sinks") b.map().slotSharingGroup("heavy b").sink().slotSharingGroup("sinks")Which would isolate the lightweight sources and sinks in a group and put heavy operations inside their own slot groups.This is a bit more low level than the previous API and requires more calls than a simple startNewResourceGroup() but I think not many people would use this feature and this design makes it very clear what operations end up in the same group.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.DataStream.scala</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.TwoInputStreamTaskTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.graph.SlotAllocationTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.StreamTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.CoFeedbackTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamNode.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamGraphGenerator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamGraph.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.DataStreamSink.java</file>
    </fixedFiles>
  </bug>
  <bug id="3323" opendate="2016-2-3 00:00:00" fixdate="2016-6-3 01:00:00" resolution="Done">
    <buginformation>
      <summary>Add documentation for NiFi connector</summary>
      <description>Add Nifi-connector documentation to the "Data Stream / Connectors" web page docs. See also FLINK-3324</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.apis.streaming.connectors.index.md</file>
      <file type="M">docs.apis.streaming.connectors.elasticsearch2.md</file>
      <file type="M">docs.apis.streaming.connectors.elasticsearch.md</file>
    </fixedFiles>
  </bug>
  <bug id="3328" opendate="2016-2-3 00:00:00" fixdate="2016-2-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Incorrectly shaded dependencies in flink-runtime</summary>
      <description>There are apparently some dependencies shaded into flink-runtime fat jar that are not relocated. (the flink-runtime jar is now 70 MB)From the output of the shading in flink-dist, it looks as if this concerns at least Zookeeper slf4j jline netty (3.x)Possible more.[WARNING] zookeeper-3.4.6.jar, flink-runtime_2.10-1.0-SNAPSHOT.jar define 440 overlapping classes: [WARNING] - org.apache.zookeeper.server.NettyServerCnxnFactory[WARNING] - org.apache.jute.compiler.JFile[WARNING] - org.apache.zookeeper.server.SessionTracker$Session[WARNING] - org.apache.zookeeper.server.quorum.AuthFastLeaderElection$1[WARNING] - org.apache.jute.compiler.JLong[WARNING] - org.apache.zookeeper.client.ZooKeeperSaslClient$SaslState[WARNING] - org.apache.zookeeper.server.auth.KerberosName$Rule[WARNING] - org.apache.jute.CsvOutputArchive[WARNING] - org.apache.zookeeper.server.quorum.QuorumPeer[WARNING] - org.apache.zookeeper.ZooKeeper$DataWatchRegistration[WARNING] - 430 more...[WARNING] slf4j-api-1.7.7.jar, flink-runtime_2.10-1.0-SNAPSHOT.jar define 24 overlapping classes: [WARNING] - org.slf4j.spi.MarkerFactoryBinder[WARNING] - org.slf4j.helpers.SubstituteLogger[WARNING] - org.slf4j.helpers.BasicMarker[WARNING] - org.slf4j.helpers.Util[WARNING] - org.slf4j.LoggerFactory[WARNING] - org.slf4j.Marker[WARNING] - org.slf4j.helpers.NamedLoggerBase[WARNING] - org.slf4j.Logger[WARNING] - org.slf4j.spi.LocationAwareLogger[WARNING] - org.slf4j.ILoggerFactory[WARNING] - 14 more...[WARNING] jansi-1.4.jar, jline-2.10.4.jar define 23 overlapping classes: [WARNING] - org.fusesource.jansi.Ansi$Erase[WARNING] - org.fusesource.jansi.Ansi[WARNING] - org.fusesource.jansi.AnsiOutputStream[WARNING] - org.fusesource.jansi.internal.CLibrary[WARNING] - org.fusesource.jansi.Ansi$2[WARNING] - org.fusesource.jansi.WindowsAnsiOutputStream[WARNING] - org.fusesource.jansi.AnsiRenderer$Code[WARNING] - org.fusesource.jansi.AnsiConsole[WARNING] - org.fusesource.jansi.Ansi$Attribute[WARNING] - org.fusesource.jansi.internal.Kernel32[WARNING] - 13 more...[WARNING] commons-beanutils-core-1.8.0.jar, commons-collections-3.2.2.jar, commons-beanutils-1.7.0.jar define 10 overlapping classes: [WARNING] - org.apache.commons.collections.FastHashMap$EntrySet[WARNING] - org.apache.commons.collections.ArrayStack[WARNING] - org.apache.commons.collections.FastHashMap$1[WARNING] - org.apache.commons.collections.FastHashMap$KeySet[WARNING] - org.apache.commons.collections.FastHashMap$CollectionView[WARNING] - org.apache.commons.collections.BufferUnderflowException[WARNING] - org.apache.commons.collections.Buffer[WARNING] - org.apache.commons.collections.FastHashMap$CollectionView$CollectionViewIterator[WARNING] - org.apache.commons.collections.FastHashMap$Values[WARNING] - org.apache.commons.collections.FastHashMap[WARNING] flink-streaming-scala_2.10-1.0-SNAPSHOT.jar, flink-core-1.0-SNAPSHOT.jar, flink-runtime_2.10-1.0-SNAPSHOT.jar, flink-java-1.0-SNAPSHOT.jar, flink-streaming-java_2.10-1.0-SNAPSHOT.jar, flink-scala_2.10-1.0-SNAPSHOT.jar, flink-clients_2.10-1.0-SNAPSHOT.jar, flink-optimizer_2.10-1.0-SNAPSHOT.jar, flink-runtime-web_2.10-1.0-SNAPSHOT.jar define 1690 overlapping classes: [WARNING] - org.apache.flink.shaded.com.google.common.collect.LinkedListMultimap[WARNING] - org.apache.flink.shaded.com.google.common.io.ByteSource$AsCharSource[WARNING] - org.apache.flink.shaded.com.google.common.escape.Platform[WARNING] - org.apache.flink.shaded.com.google.common.util.concurrent.Futures$ImmediateFailedCheckedFuture[WARNING] - org.apache.flink.shaded.com.google.common.primitives.SignedBytes$LexicographicalComparator[WARNING] - org.apache.flink.shaded.com.google.common.cache.LocalCache$WriteQueue$2[WARNING] - org.apache.flink.shaded.com.google.common.escape.Escaper$1[WARNING] - org.apache.flink.shaded.com.google.common.collect.MultimapBuilder$SetMultimapBuilder[WARNING] - org.apache.flink.shaded.com.google.common.collect.Ordering$ArbitraryOrdering[WARNING] - org.apache.flink.shaded.com.google.common.collect.Synchronized$SynchronizedAsMapEntries$1[WARNING] - 1680 more...[WARNING] flink-scala_2.10-1.0-SNAPSHOT.jar, flink-java-1.0-SNAPSHOT.jar, flink-streaming-scala_2.10-1.0-SNAPSHOT.jar, flink-runtime_2.10-1.0-SNAPSHOT.jar define 25 overlapping classes: [WARNING] - org.apache.flink.shaded.org.objectweb.asm.Context[WARNING] - org.apache.flink.shaded.org.objectweb.asm.FieldWriter[WARNING] - org.apache.flink.shaded.org.objectweb.asm.TypePath[WARNING] - org.apache.flink.shaded.org.objectweb.asm.Handler[WARNING] - org.apache.flink.shaded.org.objectweb.asm.TypeReference[WARNING] - org.apache.flink.shaded.org.objectweb.asm.signature.SignatureVisitor[WARNING] - org.apache.flink.shaded.org.objectweb.asm.Frame[WARNING] - org.apache.flink.shaded.org.objectweb.asm.FieldVisitor[WARNING] - org.apache.flink.shaded.org.objectweb.asm.ByteVector[WARNING] - org.apache.flink.shaded.org.objectweb.asm.ClassVisitor[WARNING] - 15 more...[WARNING] jline-0.9.94.jar, flink-runtime_2.10-1.0-SNAPSHOT.jar define 35 overlapping classes: [WARNING] - jline.ArgumentCompletor$ArgumentList[WARNING] - jline.UnsupportedTerminal[WARNING] - jline.Terminal[WARNING] - jline.WindowsTerminal$ReplayPrefixOneCharInputStream[WARNING] - jline.History[WARNING] - jline.WindowsTerminal$1[WARNING] - jline.ConsoleReader[WARNING] - jline.ClassNameCompletor[WARNING] - jline.SimpleCompletor$SimpleCompletorFilter[WARNING] - jline.CandidateCycleCompletionHandler[WARNING] - 25 more...[WARNING] netty-3.8.0.Final.jar, flink-runtime_2.10-1.0-SNAPSHOT.jar define 810 overlapping classes: [WARNING] - org.jboss.netty.handler.codec.http.websocketx.WebSocketClientHandshaker[WARNING] - org.jboss.netty.handler.codec.base64.Base64Decoder[WARNING] - org.jboss.netty.channel.socket.nio.NioDatagramPipelineSink$1[WARNING] - org.jboss.netty.util.VirtualExecutorService[WARNING] - org.jboss.netty.util.DefaultObjectSizeEstimator[WARNING] - org.jboss.netty.util.internal.ConcurrentIdentityHashMap$HashEntry[WARNING] - org.jboss.netty.channel.socket.oio.OioDatagramChannel[WARNING] - org.jboss.netty.logging.InternalLoggerFactory[WARNING] - org.jboss.netty.handler.codec.spdy.DefaultSpdyDataFrame[WARNING] - org.jboss.netty.channel.LifeCycleAwareChannelHandler[WARNING] - 800 more...[WARNING] flink-java-1.0-SNAPSHOT.jar, flink-runtime_2.10-1.0-SNAPSHOT.jar define 141 overlapping classes: [WARNING] - org.apache.flink.shaded.org.objectweb.asm.tree.ClassNode[WARNING] - org.apache.flink.shaded.org.objectweb.asm.commons.JSRInlinerAdapter$Instantiation[WARNING] - org.apache.flink.shaded.org.objectweb.asm.tree.analysis.BasicValue[WARNING] - org.apache.flink.shaded.org.objectweb.asm.xml.Processor$SingleDocElement[WARNING] - org.apache.flink.shaded.org.objectweb.asm.tree.TypeAnnotationNode[WARNING] - org.apache.flink.shaded.org.objectweb.asm.commons.CodeSizeEvaluator[WARNING] - org.apache.flink.shaded.org.objectweb.asm.xml.Processor$SAXWriter[WARNING] - org.apache.flink.shaded.org.objectweb.asm.util.TraceFieldVisitor[WARNING] - org.apache.flink.shaded.org.objectweb.asm.xml.Processor$ContentHandlerFactory[WARNING] - org.apache.flink.shaded.org.objectweb.asm.xml.ASMContentHandler$FrameTypeRule[WARNING] - 131 more...[WARNING] commons-beanutils-core-1.8.0.jar, commons-beanutils-1.7.0.jar define 82 overlapping classes: [WARNING] - org.apache.commons.beanutils.Converter[WARNING] - org.apache.commons.beanutils.WrapDynaBean[WARNING] - org.apache.commons.beanutils.converters.IntegerConverter[WARNING] - org.apache.commons.beanutils.locale.LocaleBeanUtilsBean[WARNING] - org.apache.commons.beanutils.locale.converters.DoubleLocaleConverter[WARNING] - org.apache.commons.beanutils.locale.converters.DecimalLocaleConverter[WARNING] - org.apache.commons.beanutils.converters.ShortConverter[WARNING] - org.apache.commons.beanutils.converters.StringArrayConverter[WARNING] - org.apache.commons.beanutils.locale.LocaleConvertUtilsBean[WARNING] - org.apache.commons.beanutils.LazyDynaClass[WARNING] - 72 more...[WARNING] commons-lang3-3.3.2.jar, flink-runtime_2.10-1.0-SNAPSHOT.jar define 217 overlapping classes: [WARNING] - org.apache.commons.lang3.builder.DiffResult[WARNING] - org.apache.commons.lang3.CharRange[WARNING] - org.apache.commons.lang3.builder.ToStringStyle$ShortPrefixToStringStyle[WARNING] - org.apache.commons.lang3.concurrent.ConcurrentException[WARNING] - org.apache.commons.lang3.builder.DiffBuilder$1[WARNING] - org.apache.commons.lang3.builder.DiffBuilder[WARNING] - org.apache.commons.lang3.builder.Diff[WARNING] - org.apache.commons.lang3.time.FastDatePrinter$TwoDigitYearField[WARNING] - org.apache.commons.lang3.ObjectUtils$Null[WARNING] - org.apache.commons.lang3.reflect.MemberUtils[WARNING] - 207 more...</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-shaded-curator.pom.xml</file>
      <file type="M">flink-shaded-curator.flink-shaded-curator-recipes.pom.xml</file>
      <file type="M">flink-runtime.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3332" opendate="2016-2-4 00:00:00" fixdate="2016-6-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Provide an exactly-once Cassandra connector</summary>
      <description>With FLINK-3311, we are adding a Cassandra connector to Flink.It would be good to also provide an "exactly-once" C* connector.I would like to first discuss how we are going to implement this in Flink.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.GenericAtLeastOnceSinkTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.AtLeastOnceSinkTestBase.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.GenericAtLeastOnceSink.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.test.resources.log4j-test.properties</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.test.resources.cassandra.yaml</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.test.java.org.apache.flink.streaming.connectors.cassandra.example.CassandraTupleAtLeastOnceSinkExample.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.test.java.org.apache.flink.streaming.connectors.cassandra.example.CassandraPojoAtLeastOnceSinkExample.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.test.java.org.apache.flink.streaming.connectors.cassandra.example.CassandraIdempotentExactlyOnceSinkExample.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.test.java.org.apache.flink.streaming.connectors.cassandra.CassandraConnectorTest.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.test.java.org.apache.flink.batch.connectors.cassandra.example.BatchExample.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.main.java.org.apache.flink.streaming.connectors.cassandra.ClusterBuilder.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.main.java.org.apache.flink.streaming.connectors.cassandra.CassandraTupleAtLeastOnceSink.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.main.java.org.apache.flink.streaming.connectors.cassandra.CassandraSink.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.main.java.org.apache.flink.streaming.connectors.cassandra.CassandraPojoAtLeastOnceSink.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.main.java.org.apache.flink.streaming.connectors.cassandra.CassandraIdempotentExactlyOnceSink.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.main.java.org.apache.flink.streaming.connectors.cassandra.CassandraCommitter.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.main.java.org.apache.flink.streaming.connectors.cassandra.CassandraAtLeastOnceSink.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.main.java.org.apache.flink.batch.connectors.cassandra.CassandraOutputFormat.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.main.java.org.apache.flink.batch.connectors.cassandra.CassandraInputFormat.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.pom.xml</file>
      <file type="M">docs.apis.streaming.connectors.cassandra.md</file>
      <file type="M">.travis.yml</file>
      <file type="M">flink-streaming-connectors.pom.xml</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.api.writer.ResultPartitionWriter.java</file>
      <file type="M">docs.apis.streaming.fault.tolerance.md</file>
      <file type="M">docs.apis.streaming.connectors.index.md</file>
    </fixedFiles>
  </bug>
  <bug id="3339" opendate="2016-2-4 00:00:00" fixdate="2016-2-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Checkpointing NPE when using filterWithState</summary>
      <description>(1.0-SNAPSHOT)I am using the Scala API keyedStream.filterWithState(..), where the state is an Option&amp;#91;Long&amp;#93;I am seeing the following error which goes away if I remove the filter.02/04/2016 14:10:19 Job execution switched to status FAILING.java.lang.RuntimeException: Error triggering a checkpoint as the result of receiving checkpoint barrier at org.apache.flink.streaming.runtime.tasks.StreamTask$2.onEvent(StreamTask.java:651) at org.apache.flink.streaming.runtime.tasks.StreamTask$2.onEvent(StreamTask.java:644) at org.apache.flink.streaming.runtime.io.BarrierBuffer.processBarrier(BarrierBuffer.java:201) at org.apache.flink.streaming.runtime.io.BarrierBuffer.getNextNonBlocked(BarrierBuffer.java:127) at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:173) at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63) at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:218) at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562) at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.NullPointerException at org.apache.flink.api.common.typeutils.base.LongSerializer.serialize(LongSerializer.java:63) at org.apache.flink.api.common.typeutils.base.LongSerializer.serialize(LongSerializer.java:27) at org.apache.flink.runtime.state.memory.AbstractMemState.snapshot(AbstractMemState.java:74) at org.apache.flink.runtime.state.AbstractStateBackend.snapshotPartitionedState(AbstractStateBackend.java:245) at org.apache.flink.streaming.api.operators.AbstractStreamOperator.snapshotOperatorState(AbstractStreamOperator.java:174) at org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.snapshotOperatorState(AbstractUdfStreamOperator.java:119) at org.apache.flink.streaming.runtime.tasks.StreamTask.triggerCheckpoint(StreamTask.java:470) at org.apache.flink.streaming.runtime.tasks.StreamTask$2.onEvent(StreamTask.java:648) ... 8 more</description>
      <version>None</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.StateBackendTestBase.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.memory.MemValueState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.filesystem.FsValueState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBValueState.java</file>
    </fixedFiles>
  </bug>
  <bug id="3342" opendate="2016-2-5 00:00:00" fixdate="2016-2-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Operator checkpoint statistics state size overflow</summary>
      <description>State sizes (long) of checkpoint stats overflow when summing them up per operator, because the sum is stored in an int.</description>
      <version>None</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.checkpoint.stats.SimpleCheckpointStatsTrackerTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.stats.SimpleCheckpointStatsTracker.java</file>
    </fixedFiles>
  </bug>
  <bug id="3350" opendate="2016-2-6 00:00:00" fixdate="2016-2-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Increase timeouts on Travis Builds</summary>
      <description>We see a lot of failures on Travis because of Timeouts.I think the problem is simply that the default ask timeouts of "10 seconds" is too short to reliably execute tests in parallel on the small containers on Travis, especially when many services (like zookeeper mini clusters, etc) are involved. The tests work most of the time, but with the large amount of tests we have, builds fail if 1 out of 1000 tests experiences a timeout.I suggest that we change the ForkableMiniCluster such that it multiplies the default timeout by a factor from an environment variable, which we set in the travis build scripts.Something like export TEST_TIMEOUT_FACTOR=3.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.recovery.ProcessFailureCancelingITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.recovery.JobManagerCheckpointRecoveryITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.recovery.AbstractTaskManagerProcessFailureRecoveryTest.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.9.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaTestEnvironmentImpl.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaTestEnvironmentImpl.java</file>
      <file type="M">flink-runtime.src.test.scala.org.apache.flink.runtime.testingUtils.TestingCluster.scala</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.testutils.ZooKeeperTestUtils.java</file>
      <file type="M">flink-runtime.src.main.scala.org.apache.flink.runtime.minicluster.LocalFlinkMiniCluster.scala</file>
      <file type="M">flink-runtime.src.main.scala.org.apache.flink.runtime.minicluster.FlinkMiniCluster.scala</file>
    </fixedFiles>
  </bug>
  <bug id="3354" opendate="2016-2-6 00:00:00" fixdate="2016-10-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RocksDB should compute checkpoint size based on backup file size</summary>
      <description>Currently the RocksDB backend returns 0 for state size, the actual state size could be computed using:fs.getContentSummary(path).getLength();</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.AbstractRocksDBState.java</file>
    </fixedFiles>
  </bug>
  <bug id="3359" opendate="2016-2-7 00:00:00" fixdate="2016-2-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make RocksDB file copies asynchronous</summary>
      <description>While the incremental backup of the RocksDB files needs to be synchronous, the copying of that file to the backup file system can be fully asynchronous.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.EventTimeWindowCheckpointingITCase.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskAsyncCheckpointTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.OneInputStreamTaskTestHarness.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTaskStateList.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTask.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.StateBackendTestBase.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackendTest.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBValueState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackend.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBReducingState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBListState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBFoldingState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.AbstractRocksDBState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3367" opendate="2016-2-8 00:00:00" fixdate="2016-2-8 01:00:00" resolution="Done">
    <buginformation>
      <summary>Annotate all user-facing API classes with @Public or @PublicEvolving</summary>
      <description>At the moment, only stable public classes are annotated with @Public. It is not possible to identify whether a non-annotated class is supposed to be API-facing or not.This issue proposes to annotate all API classes either with @Public or @PublicEvolving. Classes which are not annotated belong to Flink's internals.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.InnerJoinOperatorBase.java</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.unfinishedKeyPairOperation.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.UnitSerializer.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.TypeUtils.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.TrySerializer.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.TraversableSerializer.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.OptionSerializer.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.NothingSerializer.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.EnumValueSerializer.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.EnumValueComparator.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.EitherSerializer.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.CaseClassSerializer.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.CaseClassComparator.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.joinDataSet.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.CrossDataSet.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.codegen.TypeInformationGen.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.codegen.TypeDescriptors.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.codegen.TypeAnalyzer.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.codegen.TreeGen.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.codegen.MacroContextHolder.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.codegen.Counter.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.ClosureCleaner.scala</file>
      <file type="M">flink-scala.src.main.java.org.apache.flink.api.scala.operators.ScalaCsvOutputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.utils.RequiredParametersException.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.utils.RequiredParameters.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.utils.OptionType.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.utils.Option.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.Utils.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sca.UdfAnalyzerUtils.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sca.UdfAnalyzer.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sca.TaggedValue.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sca.NestedMethodAnalyzer.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sca.ModifiedASMFrame.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sca.ModifiedASMAnalyzer.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sca.CodeErrorException.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sca.CodeAnalyzerException.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sampling.ReservoirSamplerWithReplacement.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sampling.ReservoirSamplerWithoutReplacement.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sampling.RandomSampler.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sampling.PoissonSampler.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sampling.IntermediateSampleData.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sampling.DistributedRandomSampler.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sampling.BernoulliSampler.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.UdfOperatorUtils.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.WrappingFunction.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.TwoKeyExtractingMapper.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.TupleWrappingCollector.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.TupleUnwrappingJoiner.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.TupleUnwrappingIterator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.TupleRightUnwrappingJoiner.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.TupleLeftUnwrappingJoiner.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.Tuple3WrappingCollector.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.Tuple3UnwrappingIterator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.PlanUnwrappingSortedReduceGroupOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.PlanUnwrappingSortedGroupCombineOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.PlanUnwrappingReduceOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.PlanUnwrappingReduceGroupOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.PlanUnwrappingGroupCombineOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.PlanRightUnwrappingCoGroupOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.PlanProjectOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.PlanLeftUnwrappingCoGroupOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.PlanFilterOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.PlanBothUnwrappingCoGroupOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.KeyRemovingMapper.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.KeyExtractingMapper.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.CombineToGroupCombineWrapper.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.OperatorTranslation.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.KeyFunctions.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.CoGroupRawOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.TypeSerializerOutputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.TypeSerializerInputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.TupleCsvInputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.TextValueInputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.TextOutputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.TextInputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.SplitDataProperties.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.PrintingOutputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.PrimitiveInputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.PojoCsvInputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.ParallelIteratorInputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.LocalCollectionOutputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.IteratorInputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.CsvOutputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.CsvInputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.CollectionInputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.hadoop.mapred.wrapper.HadoopInputSplit.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.hadoop.mapred.wrapper.HadoopDummyReporter.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.hadoop.mapred.wrapper.HadoopDummyProgressable.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.hadoop.mapred.utils.HadoopUtils.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.hadoop.mapred.HadoopOutputFormatBase.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.hadoop.mapred.HadoopInputFormatBase.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.hadoop.mapreduce.utils.HadoopUtils.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.hadoop.mapreduce.HadoopOutputFormatBase.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.hadoop.mapreduce.HadoopInputFormatBase.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.hadoop.common.HadoopOutputFormatCommonBase.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.hadoop.common.HadoopInputFormatCommonBase.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.functions.SemanticPropUtil.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.functions.SelectByMinFunction.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.functions.SelectByMaxFunction.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.functions.SampleWithFraction.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.functions.SampleInPartition.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.functions.SampleInCoordinator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.functions.IdPartitioner.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.functions.GroupReduceIterator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.functions.FormattingMapper.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.functions.FlatMapIterator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.functions.FirstReducer.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.CollectionEnvironment.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.ClosureCleaner.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.aggregation.UnsupportedAggregationTypeException.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.aggregation.SumAggregationFunction.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.aggregation.MinAggregationFunction.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.aggregation.MaxAggregationFunction.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.aggregation.AggregationFunctionFactory.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.aggregation.AggregationFunction.java</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.ConnectedStreams.scala</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.util.serialization.SimpleStringSchema.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.util.keys.KeySelectorUtil.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.util.FieldAccessor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.TwoInputStreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.TimerException.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTaskStateList.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTaskState.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTaskException.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamIterationTail.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamIterationHead.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.SourceStreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.OperatorChain.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.ExceptionInChainedOperatorException.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.AsynchronousException.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.streamrecord.StreamRecordSerializer.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.streamrecord.StreamRecord.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.streamrecord.StreamElement.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.streamrecord.MultiplexingStreamRecordSerializer.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.partitioner.StreamPartitioner.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.partitioner.ShufflePartitioner.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.partitioner.RescalePartitioner.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.partitioner.RebalancePartitioner.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.partitioner.HashPartitioner.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.partitioner.GlobalPartitioner.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.partitioner.ForwardPartitioner.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.partitioner.CustomPartitionerWrapper.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.partitioner.BroadcastPartitioner.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.NonKeyedWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.KeyMap.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.EvictingWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.EvictingNonKeyedWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.buffers.WindowBufferFactory.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.buffers.WindowBuffer.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.buffers.PreAggregatingHeapWindowBuffer.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.buffers.HeapWindowBuffer.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.buffers.EvictingWindowBuffer.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.AggregatingProcessingTimeWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.AggregatingKeyedTimePanes.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.AccumulatingProcessingTimeWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.AccumulatingKeyedTimePanes.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.AbstractKeyedTimePanes.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.AbstractAlignedProcessingTimeWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.Triggerable.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.StreamingOperatorMetrics.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.ExtractTimestampsOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.BucketStreamSortOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.StreamTwoInputProcessor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.StreamRecordWriter.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.StreamInputProcessor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.StreamingReader.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.RecordWriterOutput.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.InputGateUtil.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.CheckpointBarrierHandler.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.BufferSpiller.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.BlockingQueueBroker.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.BarrierTracker.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.BarrierBuffer.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.windows.Window.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.windows.TimeWindow.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.windows.GlobalWindow.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.triggers.Trigger.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.triggers.PurgingTrigger.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.triggers.ProcessingTimeTrigger.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.triggers.EventTimeTrigger.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.triggers.DeltaTrigger.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.triggers.CountTrigger.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.triggers.ContinuousProcessingTimeTrigger.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.triggers.ContinuousEventTimeTrigger.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.evictors.TimeEvictor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.evictors.Evictor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.evictors.DeltaEvictor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.evictors.CountEvictor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.assigners.WindowAssigner.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.assigners.TumblingTimeWindows.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.assigners.SlidingTimeWindows.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.assigners.GlobalWindows.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.watermark.Watermark.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.UnionTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.TwoInputTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.StreamTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.SplitTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.SourceTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.SinkTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.SelectTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.PartitionTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.OneInputTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.FeedbackTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.CoFeedbackTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.TimeCharacteristic.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.TwoInputStreamOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.TimestampedCollector.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamSource.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamSink.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamProject.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamMap.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamingRuntimeContext.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamGroupedReduce.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamGroupedFold.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamFlatMap.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamFilter.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamCounter.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.OutputTypeConfigurable.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.Output.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.OneInputStreamOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.co.CoStreamMap.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.co.CoStreamFlatMap.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.ChainingStrategy.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.AbstractStreamOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamNode.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamGraphGenerator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamGraph.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamEdge.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamConfig.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.JSONGenerator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.RichWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.ReduceIterableWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.ReduceIterableAllWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.ReduceApplyWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.ReduceApplyAllWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.PassThroughWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.PassThroughAllWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.FoldApplyWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.FoldApplyAllWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.delta.extractor.FieldsFromTuple.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.delta.extractor.FieldsFromArray.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.delta.extractor.FieldFromTuple.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.delta.extractor.FieldFromArray.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.delta.extractor.Extractor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.delta.extractor.ConcatenatedExtract.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.delta.extractor.ArrayFromTuple.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.delta.ExtractionAwareDeltaFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.delta.EuclideanDistance.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.delta.DeltaFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.delta.CosineDistance.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.TimestampExtractor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.StatefulSequenceSource.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.SocketTextStreamFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.RichEventTimeSourceFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.MultipleIdsMessageAcknowledgingSourceBase.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.MessageAcknowledgingSourceBase.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.FromSplittableIteratorFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.FromIteratorFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.FromElementsFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.FileSourceFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.FileReadFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.FileMonitoringFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.ConnectorSource.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.WriteSinkFunctionByMillis.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.WriteSinkFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.WriteFormatAsText.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.WriteFormatAsCsv.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.WriteFormat.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.SocketClientSink.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.PrintSinkFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.FileSinkFunctionByMillis.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.FileSinkFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.AscendingTimestampExtractor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.aggregation.SumFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.aggregation.SumAggregator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.aggregation.Comparator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.aggregation.ComparableAggregator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.aggregation.AggregationFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.environment.StreamPlanEnvironment.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.environment.StreamExecutionEnvironmentFactory.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.environment.StreamContextEnvironment.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.StreamProjection.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.collector.selector.OutputSelectorWrapper.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.collector.selector.OutputSelector.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.checkpoint.CheckpointedAsynchronously.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.checkpoint.Checkpointed.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.Visitor.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.Visitable.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.StringUtils.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.SimpleStringUtils.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.SerializedValue.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.ReflectionUtil.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.OperatingSystem.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.NetUtils.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.MutableObjectIterator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.MavenForkNumberPrefixLayout.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.IterableIterator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.InstantiationUtil.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.ExternalProcessRunner.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.ExceptionUtils.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.AbstractID.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.StringValueParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.StringParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.ShortValueParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.ShortParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.LongValueParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.LongParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.IntValueParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.IntParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.FloatValueParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.FloatParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.FieldParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.DoubleValueParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.DoubleParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.ByteValueParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.ByteParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.BooleanValueParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.BooleanParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.Pair.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.NullKeyFieldException.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.Key.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.JavaToValueConverter.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.SeekableDataOutputView.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.SeekableDataInputView.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.MemoryUtils.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.MemoryType.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.MemorySegmentSource.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.MemorySegmentFactory.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.MemorySegment.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.HybridMemorySegment.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.HeapMemorySegment.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.DataOutputViewStreamWrapper.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.DataInputViewStreamWrapper.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.io.InputSplitAssigner.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.local.LocalFileSystem.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.local.LocalFileStatus.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.local.LocalDataOutputStream.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.local.LocalDataInputStream.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.local.LocalBlockLocation.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.HadoopFileSystemWrapper.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.IllegalConfigurationException.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.GlobalConfiguration.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.runtime.kryo.Serializers.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.runtime.KryoUtils.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.PojoField.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.TypeSerializerFactory.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.TypeSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.TypePairComparatorFactory.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.TypePairComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.TypeComparatorFactory.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.TypeComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.GenericPairComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.CompositeTypeComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.VoidSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.TypeSerializerSingleton.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.StringValueSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.StringSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.StringComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.ShortValueSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.ShortSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.ShortComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.LongValueSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.LongSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.LongComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.IntValueSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.IntSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.IntComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.GenericArraySerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.FloatValueSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.FloatSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.FloatComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.EnumSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.EnumComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.DoubleValueSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.DoubleSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.DoubleComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.DateSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.DateComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.CharValueSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.CharSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.CharComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.ByteValueSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.ByteSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.ByteComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.BooleanValueSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.BooleanSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.BooleanComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.BasicTypeComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.StringArraySerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.ShortPrimitiveArraySerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.ShortPrimitiveArrayComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.PrimitiveArrayComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.LongPrimitiveArraySerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.LongPrimitiveArrayComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.IntPrimitiveArraySerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.IntPrimitiveArrayComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.FloatPrimitiveArraySerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.FloatPrimitiveArrayComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.DoublePrimitiveArraySerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.DoublePrimitiveArrayComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.CharPrimitiveArraySerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.CharPrimitiveArrayComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArrayComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.BooleanPrimitiveArraySerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.BooleanPrimitiveArrayComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.TaskInfo.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.ValueStateDescriptor.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.ValueState.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.StateDescriptor.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.StateBackend.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.State.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.ReducingStateDescriptor.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.ReducingState.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.OperatorState.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.MergingState.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.ListStateDescriptor.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.ListState.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.FoldingStateDescriptor.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.FoldingState.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.ProgramDescription.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.Program.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.PlanExecutor.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.Plan.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.util.UserCodeWrapper.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.util.UserCodeObjectWrapper.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.util.UserCodeClassWrapper.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.util.TypeComparable.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.util.ListKeyGroupedIterator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.util.JoinHashMap.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.util.FieldSet.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.util.FieldList.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.Union.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.UnaryOperatorInformation.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.SingleInputSemanticProperties.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.SingleInputOperator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.SemanticProperties.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.Ordering.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.OperatorInformation.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.Operator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.Keys.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.IterationOperator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.GenericDataSourceBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.GenericDataSinkBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.DualInputSemanticProperties.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.DualInputOperator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.CompilerHints.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.CollectionExecutor.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.BinaryOperatorInformation.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.SortPartitionOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.ReduceOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.PartitionOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.OuterJoinOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.MapPartitionOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.MapOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.JoinOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.accumulators.AccumulatorHelper.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.accumulators.DoubleCounter.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.accumulators.IntCounter.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.accumulators.LongCounter.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.accumulators.SerializedListAccumulator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.aggregators.Aggregator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.aggregators.AggregatorRegistry.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.aggregators.AggregatorWithName.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.aggregators.ConvergenceCriterion.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.aggregators.DoubleSumAggregator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.aggregators.DoubleZeroConvergence.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.aggregators.LongSumAggregator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.aggregators.LongZeroConvergence.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.ApplicationID.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.CodeAnalysisMode.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.distributions.CommonRangeBoundaries.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.distributions.DataDistribution.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.distributions.RangeBoundaries.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.distributions.SimpleDistribution.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.distributions.SimpleIntegerDistribution.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.distributions.UniformDoubleDistribution.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.distributions.UniformIntegerDistribution.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.util.AbstractRuntimeUDFContext.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.util.CopyingIterator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.util.CopyingListCollector.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.util.FunctionUtils.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.util.ListCollector.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.util.NoOpFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.util.RuntimeUDFContext.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.InvalidProgramException.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.compression.DeflateInflaterInputStreamFactory.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.compression.GzipInflaterInputStreamFactory.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.compression.InflaterInputStreamFactory.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.DefaultInputSplitAssigner.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.GenericCsvInputFormat.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.ParseException.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.ReplicatingInputFormat.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.ReplicatingInputSplitAssigner.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.StrictlyLocalAssignment.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.NonSerializableUserCodeException.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.AbstractUdfOperator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.BulkIterationBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.CoGroupOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.CoGroupRawOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.CrossOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.DeltaIterationBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.FilterOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.FlatMapOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.GroupCombineOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.GroupReduceOperatorBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="3375" opendate="2016-2-9 00:00:00" fixdate="2016-4-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow Watermark Generation in the Kafka Source</summary>
      <description>It is a common case that event timestamps are ascending inside one Kafka Partition. Ascending timestamps are easy for users, because they are handles by ascending timestamp extraction.If the Kafka source has multiple partitions per source task, then the records become out of order before timestamps can be extracted and watermarks can be generated.If we make the FlinkKafkaConsumer an event time source function, it can generate watermarks itself. It would internally implement the same logic as the regular operators that merge streams, keeping track of event time progress per partition and generating watermarks based on the current guaranteed event time progress.</description>
      <version>1.0.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.AssignerWithPunctuatedWatermarks.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.testutils.JobManagerCommunicationUtils.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaShortRetentionTestBase.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaProducerTestBase.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaConsumerPartitionAssignmentTest.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.partitioner.KafkaPartitioner.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.KafkaPartitionState.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.9.src.test.resources.log4j-test.properties</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.9.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaShortRetention09ITCase.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.9.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaProducerTest.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.src.test.resources.log4j-test.properties</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaShortRetention08ITCase.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.internals.ZookeeperOffsetHandlerTest.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.PartitionerWrapper.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.OffsetHandler.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.testutils.MockRuntimeContext.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.util.KafkaUtils.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.ExceptionProxy.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.AssignerWithPeriodicWatermarks.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaConsumerTestBase.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.9.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka09ITCase.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer09.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaConsumerTest.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka08ITCase.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.ZookeeperOffsetHandler.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.LegacyFetcher.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.Fetcher.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer08.java</file>
    </fixedFiles>
  </bug>
  <bug id="3383" opendate="2016-2-9 00:00:00" fixdate="2016-3-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Separate Maven deployment from CI testing</summary>
      <description>We currently handle our tests and the deployment of the Maven artifacts via Travis CI. Travis has a maximum allowed build time of two hours which we reach nearly every time. By that time, the tests have already been run but the deployment is still undergoing.I propose to remove the Maven deployment from Travis. Instead, we could use Apache's Jenkins service or Apache's Buildbot service to trigger a deployment once a day.</description>
      <version>1.0.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.force-shading.pom.xml</file>
      <file type="M">tools.deploy.to.maven.sh</file>
      <file type="M">pom.xml</file>
      <file type="M">.travis.yml</file>
    </fixedFiles>
  </bug>
  <bug id="3386" opendate="2016-2-11 00:00:00" fixdate="2016-2-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Kafka consumers are not properly respecting the "auto.offset.reset" behavior</summary>
      <description>Currently if the data in a kafka topic expires while reading from it, it causes an unrecoverable failure as subsequent retries will also fail on invalid offsets.While this might be the desired behaviour under some circumstances, it would probably be better in most cases to automatically jump to the earliest valid offset in these cases.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionLeader.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducerBase.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.pom.xml</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.9.pom.xml</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.ZookeeperOffsetHandler.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.OffsetHandler.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer08.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.pom.xml</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.testutils.DataGenerators.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaTestEnvironment.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaTestBase.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaConsumerTestBase.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.ZooKeeperStringSerializer.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.9.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaTestEnvironmentImpl.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer09.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaTestEnvironmentImpl.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka08ITCase.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.LegacyFetcher.java</file>
    </fixedFiles>
  </bug>
  <bug id="3389" opendate="2016-2-11 00:00:00" fixdate="2016-4-11 01:00:00" resolution="Done">
    <buginformation>
      <summary>Add Pre-defined Options settings for RocksDB State backend</summary>
      <description>The RocksDB State Backend performance can be optimized for certain settings (for example running on disk or SSD) with certain options.Since it is hard to tune for users, we should add a set of predefined options for certain settings.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackend.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.OptionsFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="3390" opendate="2016-2-11 00:00:00" fixdate="2016-2-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Savepoint resume is not retried</summary>
      <description>When during resuming from a savepoint, restoreState fails for a task node, job is retried but without retrying resume from savepoint state. This leads to the job being restarted with empty state.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.SavepointITCase.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.ExecutionGraph.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.SavepointCoordinator.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.CheckpointCoordinator.java</file>
    </fixedFiles>
  </bug>
  <bug id="3396" opendate="2016-2-12 00:00:00" fixdate="2016-3-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Job submission Savepoint restore logic flawed</summary>
      <description>When savepoint restoring fails, the thrown Exception fails the execution graph, but the client is not informed about the failure.The expected behaviour is that the submission should be acked with success or failure in any case. With savepoint restore failures, the ack message will be skipped.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.scala.org.apache.flink.runtime.jobmanager.JobManager.scala</file>
    </fixedFiles>
  </bug>
  <bug id="3398" opendate="2016-2-15 00:00:00" fixdate="2016-3-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Flink Kafka consumer should support auto-commit opt-outs</summary>
      <description>Currently the Kafka source will commit consumer offsets to Zookeeper, either upon a checkpoint if checkpointing is enabled, otherwise periodically based on auto.commit.interval.msIt should be possible to opt-out of committing consumer offsets to Zookeeper. Kafka has this config as auto.commit.enable (0.8) and enable.auto.commit (0.9).</description>
      <version>None</version>
      <fixedVersion>1.3.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.PropertiesUtil.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBaseTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBaseMigrationTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka09FetcherTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.internal.Kafka09Fetcher.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer09.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaConsumer08Test.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka08ITCase.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer08.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka010FetcherTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.main.java.org.apache.flink.streaming.connectors.kafka.internal.Kafka010Fetcher.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer010.java</file>
      <file type="M">docs.dev.connectors.kafka.md</file>
    </fixedFiles>
  </bug>
  <bug id="3410" opendate="2016-2-15 00:00:00" fixdate="2016-2-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>setting setNumberOfExecutionRetries to 0 still leads to RESTARTs.</summary>
      <description>While testing the RC0 for 1.0.0 I found the following issue:Setting the number of retries to 0 still leads to the job being restarted:final StreamExecutionEnvironment see = StreamExecutionEnvironment.getExecutionEnvironment();see.setNumberOfExecutionRetries(0);21:19:50,677 INFO org.apache.flink.runtime.jobmanager.JobManager - Status of job 0e78d0825da485167aabee7e63c8e913 (Data Generator) changed to RESTARTING.21:19:50,678 INFO org.apache.flink.runtime.executiongraph.restart.FixedDelayRestartStrategy - Delaying retry of job execution for 10000 ms ...While looking through the code, it seems that the execution config is returning null when the number of retries is set to 0. With null the jobManager picks the default restart strategy.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.ExecutionConfig.java</file>
    </fixedFiles>
  </bug>
  <bug id="3416" opendate="2016-2-16 00:00:00" fixdate="2016-2-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[py] .bat files fail when path contains spaces</summary>
      <description></description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-dist.src.main.flink-bin.bin.pyflink3.bat</file>
      <file type="M">flink-dist.src.main.flink-bin.bin.pyflink2.bat</file>
    </fixedFiles>
  </bug>
  <bug id="3455" opendate="2016-2-19 00:00:00" fixdate="2016-2-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bump Kafka 0.9 connector dependency to Kafka 0.9.0.1</summary>
      <description>The Kafka project released the 0.9.0.1 version.I saw some issues (in our integration tests) while developing the code. My hope is that the upgraded version will improve stability.</description>
      <version>None</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaConsumerTestBase.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.pom.xml</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.9.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaShortRetention09Test.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.9.pom.xml</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaShortRetention08Test.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3458" opendate="2016-2-21 00:00:00" fixdate="2016-2-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Shading broken in flink-shaded-hadoop</summary>
      <description>The shading in flink-shaded-hadoop relocates the guava dependencies of Hadoop twice.Once under org.apache.flink.shaded.hadoop.com.google and org.apache.flink.shaded.com.google. This causes merge resolution problems when building a fat jar including the flink-shaded-hadoop jar.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-shaded-hadoop.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3459" opendate="2016-2-21 00:00:00" fixdate="2016-2-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make build SBT compatible</summary>
      <description>The current flink-shaded-hadoop2 dependency is not SBT compatible because it contains commons-collection:3.2.1, commons-beanutils:1.7 and commons-beanutils-core:1.8 dependencies. These dependencies contain overlapping classes which are binary compatible but not binary identical. This is a problem for the SBT assembly plugin which requires binary identity for merging them. Otherwise, the build is aborted. I propose to exclude the conflicting dependencies and use instead the commons-beanutils-bean-collection class which contains only then non-conflicting classes.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-shaded-hadoop.flink-shaded-hadoop2.pom.xml</file>
      <file type="M">flink-core.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3460" opendate="2016-2-21 00:00:00" fixdate="2016-2-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make flink-streaming-connectors&amp;#39; flink dependencies provided</summary>
      <description>All of the flink-streaming-connectors depend on flink-streaming-java (compile scope). This entails that whenever you have a project which depends on the a connector this will also pull in the heavy-weight flink-streaming-java dependency. If you now build a fat-jar, you have to use exclusion rules to filter them out again.It would be more natural to simply declare the dependencies as provided which will automatically avoid the inclusion in the fat jar with respect to the connector dependency.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-connectors.flink-connector-twitter.pom.xml</file>
      <file type="M">flink-streaming-connectors.flink-connector-rabbitmq.pom.xml</file>
      <file type="M">flink-streaming-connectors.flink-connector-nifi.pom.xml</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.pom.xml</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.9.pom.xml</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.pom.xml</file>
      <file type="M">flink-streaming-connectors.flink-connector-flume.pom.xml</file>
      <file type="M">flink-streaming-connectors.flink-connector-filesystem.pom.xml</file>
      <file type="M">flink-streaming-connectors.flink-connector-elasticsearch.pom.xml</file>
      <file type="M">flink-libraries.flink-ml.pom.xml</file>
      <file type="M">flink-libraries.flink-gelly.pom.xml</file>
      <file type="M">flink-libraries.flink-gelly-scala.pom.xml</file>
      <file type="M">flink-libraries.flink-cep.pom.xml</file>
      <file type="M">flink-batch-connectors.flink-jdbc.pom.xml</file>
      <file type="M">flink-batch-connectors.flink-hcatalog.pom.xml</file>
      <file type="M">flink-batch-connectors.flink-hbase.pom.xml</file>
      <file type="M">flink-batch-connectors.flink-hadoop-compatibility.pom.xml</file>
      <file type="M">flink-batch-connectors.flink-avro.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3463" opendate="2016-2-22 00:00:00" fixdate="2016-2-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement Calc Support</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.logical.FlinkProjectRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.logical.FlinkFilterRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.FlinkRuleSets.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.dataset.DataSetProjectRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.dataset.DataSetFilterRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.dataset.DataSetCalcRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.logical.FlinkProject.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.logical.FlinkFilter.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetMap.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetFlatMap.scala</file>
    </fixedFiles>
  </bug>
  <bug id="3469" opendate="2016-2-22 00:00:00" fixdate="2016-4-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve documentation for grouping keys</summary>
      <description>The transformation documentation for "Reduce on DataSet Grouped by KeySelector Function" uses a field expression in the Java example.There are four ways to specify keys and only two have named examples in the documentation. Expand the documentation to cover all cases.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.1,1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.apis.batch.dataset.transformations.md</file>
    </fixedFiles>
  </bug>
  <bug id="3478" opendate="2016-2-23 00:00:00" fixdate="2016-2-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Flink serves arbitary files through the web interface</summary>
      <description>Flink serves arbitrary files through the web server of the 8081 port, e.g. ../../../../../../../../../../etc/passwd.The requested path needs to be validated before it is served.</description>
      <version>0.10.0,0.10.1,1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.WebRuntimeMonitorITCase.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.WebRuntimeMonitor.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.files.StaticFileServerHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="3482" opendate="2016-2-23 00:00:00" fixdate="2016-2-23 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Implement Union Support</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.table.test.UnionITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.table.test.UnionITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.FlinkRuleSets.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetUnion.scala</file>
    </fixedFiles>
  </bug>
  <bug id="3483" opendate="2016-2-23 00:00:00" fixdate="2016-2-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Job graph visualization not working properly in OS X Chrome</summary>
      <description>In the Chrome browser on OS X (Version 48.0.2564.116 (64-bit)) the job graph visualization does not work properly. There are no edges displayed in the graph, and dragging the mouse does not move the graph.However, Safari (9.0.3) and Firefox (41.0.2) on OS X do display the job graph visualization properly.This is the example application I used to create the job:package com.bannoimport org.apache.flink.streaming.api.scala._object JobGraphUIProblem extends App { val environment = StreamExecutionEnvironment.getExecutionEnvironment val ints1 = environment.fromElements((1 to 100): _*) val ints2 = environment.fromElements((101 to 200): _*) ints1.union(ints2) .map(_.toString) .print() println(environment.getExecutionPlan) environment.execute("JobGraphUIProblem")}Here is the execution plan json:{ "nodes": [ { "id": 1, "type": "Source: Collection Source", "pact": "Data Source", "contents": "Source: Collection Source", "parallelism": 1 }, { "id": 2, "type": "Source: Collection Source", "pact": "Data Source", "contents": "Source: Collection Source", "parallelism": 1 }, { "id": 4, "type": "Map", "pact": "Operator", "contents": "Map", "parallelism": 8, "predecessors": [ { "id": 1, "ship_strategy": "REBALANCE", "side": "second" }, { "id": 2, "ship_strategy": "REBALANCE", "side": "second" } ] }, { "id": 5, "type": "Sink: Unnamed", "pact": "Data Sink", "contents": "Sink: Unnamed", "parallelism": 8, "predecessors": [ { "id": 4, "ship_strategy": "FORWARD", "side": "second" } ] } ]}</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime-web.web-dashboard.web.js.vendor.js</file>
      <file type="M">flink-runtime-web.web-dashboard.web.js.index.js</file>
      <file type="M">flink-runtime-web.web-dashboard.bower.json</file>
    </fixedFiles>
  </bug>
  <bug id="3484" opendate="2016-2-23 00:00:00" fixdate="2016-3-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add setSlotSharingGroup documentation</summary>
      <description>The newly introduced setSlotSharingGroup functionality replaces the setNewResourceGroup and isoloateResources API calls. Documentation should be added for the new API calls. Outdated documentation for the old API calls should be removed.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.apis.streaming.index.md</file>
    </fixedFiles>
  </bug>
  <bug id="3488" opendate="2016-2-24 00:00:00" fixdate="2016-5-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Kafka08ITCase.testBigRecordJob fails on Travis</summary>
      <description>The test case Kafka08ITCase.testBigRecordJob failed on Travis &amp;#91;1&amp;#93;.&amp;#91;1&amp;#93; https://s3.amazonaws.com/archive.travis-ci.org/jobs/111268604/log.txt</description>
      <version>1.0.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaConsumerTestBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="3490" opendate="2016-2-24 00:00:00" fixdate="2016-2-24 01:00:00" resolution="Done">
    <buginformation>
      <summary>Bump Chill version to 0.7.4</summary>
      <description>Chill's version 0.7.3 includes fixes which are relevant for Flink (see release nodes).It would be good to bump Chill to the latest version 0.7.x version (0.7.4) for the 1.0.0 release to include these fixes. Chill 0.7.4's dependency are the same as our current version Chill 0.5.2.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3496" opendate="2016-2-24 00:00:00" fixdate="2016-3-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Flink-ml tests fail on Windows</summary>
      <description>&amp;#91;INFO&amp;#93; &amp;#8212; maven-surefire-plugin:2.18.1:test (default-test) @ flink-ml_2.10 &amp;#8212;&amp;#91;INFO&amp;#93;&amp;#91;INFO&amp;#93; &amp;#8212; scalatest-maven-plugin:1.0:test (scala-test) @ flink-ml_2.10 &amp;#8212;The system cannot find the file specified.&amp;#91;INFO&amp;#93; ------------------------------------------------------------------------&amp;#91;INFO&amp;#93; BUILD FAILURE&amp;#91;INFO&amp;#93; ------------------------------------------------------------------------&amp;#91;INFO&amp;#93; Total time: 01:03 min&amp;#91;INFO&amp;#93; Finished at: 2016-02-24T12:47:23+01:00&amp;#91;INFO&amp;#93; Final Memory: 28M/506M</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-ml.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3497" opendate="2016-2-24 00:00:00" fixdate="2016-3-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add SQL scalar functions to Table API</summary>
      <description>In order to use the Table API as ETL tool and prepare for FLINK-2099, we need to add more scalar functions such as trim(), abs(), like(), etc.Calcite implements the most important functions. We can basically forward calls to Calcites built-in runtime functions. Some functions need special treatment because of Flink specifics.I would propose the following steps: Implement TRIM, SUBSTRING as reference design remaining string functions math functions Date/time functions System functions Case function Array functions otherEach step includes implementation, test and documentation.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.ExpressionParser.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.comparison.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.generated.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.CodeGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.ScalarOperators.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.stringExpressions.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.expressions.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.validate.FunctionCatalog.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.mathExpressions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.ScalarFunctions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.BuiltInMethods.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.scala.table.expressionDsl.scala</file>
      <file type="M">docs.dev.table.api.md</file>
    </fixedFiles>
  </bug>
  <bug id="3498" opendate="2016-2-24 00:00:00" fixdate="2016-3-24 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Implement TRIM, SUBSTRING as reference design for Table API</summary>
      <description>As described in FLINK-3497 TRIM and SUBSTRING are the first scalar functions implemented in Calcite and used in Table API.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.test.utils.ExpressionEvaluator.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.test.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.TypeConverter.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.TranslationContext.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.RexNodeTranslator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.parser.ExpressionParser.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.stringExpressions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.CodeGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.ScalarFunctions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.scala.table.expressionDsl.scala</file>
    </fixedFiles>
  </bug>
  <bug id="3499" opendate="2016-2-24 00:00:00" fixdate="2016-2-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Possible ghost references in ZooKeeper completed checkpoint store</summary>
      <description>The ZooKeeper completed checkpoint store can have references to recovered entries, which have been removed already. A simple fix is to clear these references on recovery.</description>
      <version>None</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.recovery.JobManagerCheckpointRecoveryITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.checkpoint.ZooKeeperCompletedCheckpointStoreITCase.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.ZooKeeperCompletedCheckpointStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="3513" opendate="2016-2-25 00:00:00" fixdate="2016-2-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix interplay of automatic Operator UID and Changing name of WindowOperator</summary>
      <description>WindowOperator can have a changing name because it has the TypeSerializer .toString() output in it's name. For some type serializers that don't implement toString() this means that the name changes.This means that savepoint restore does not work for the automatically generated UID.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.graph.StreamingJobGraphGeneratorNodeHashTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator.java</file>
    </fixedFiles>
  </bug>
  <bug id="3530" opendate="2016-2-29 00:00:00" fixdate="2016-6-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Kafka09ITCase.testBigRecordJob fails on Travis</summary>
      <description>The test case Kafka09ITCase.testBigRecordJob failed on Travis.https://s3.amazonaws.com/archive.travis-ci.org/jobs/112049279/log.txt</description>
      <version>1.0.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaConsumerTestBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="3532" opendate="2016-2-29 00:00:00" fixdate="2016-2-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Flink-gelly-examples jar contains an underscore instead of an hyphen</summary>
      <description>The newly introduced flink-gelly-examples module uses an underscore to separate examples from flink-gelly in it's artifact id. This is not consistent and, thus, the artifact id flink-gelly_examples_2.10 should be changed to flink-gelly-examples_2.10.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-gelly-examples.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3533" opendate="2016-2-29 00:00:00" fixdate="2016-3-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update the Gelly docs wrt examples and cluster execution</summary>
      <description>Links to examples and cluster execution instructions are currently broken in the Gelly docs.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.1,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.apis.batch.libs.gelly.md</file>
    </fixedFiles>
  </bug>
  <bug id="3537" opendate="2016-2-29 00:00:00" fixdate="2016-3-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Faulty code generation for disjunctions</summary>
      <description>The Table API generates conjunction (&amp;&amp;) code for disjunctions (||).</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.table.test.JoinITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.table.test.FilterITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.table.test.FilterITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.ScalarOperators.scala</file>
    </fixedFiles>
  </bug>
  <bug id="3540" opendate="2016-2-29 00:00:00" fixdate="2016-2-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hadoop 2.6.3 build contains /com/google/common (guava) classes in flink-dist.jar</summary>
      <description>While testing the 1.0.0 RC2, I found that the "flink-dist.jar" contains unshaded guava classes.The dependency tree of "flink-dist" shows where the dependency is coming from[INFO] | \- org.apache.flink:flink-shaded-hadoop2:jar:1.1-SNAPSHOT:compile[INFO] | +- xmlenc:xmlenc:jar:0.52:compile[INFO] | +- commons-codec:commons-codec:jar:1.4:compile[INFO] | +- commons-io:commons-io:jar:2.4:compile[INFO] | +- commons-net:commons-net:jar:3.1:compile[INFO] | +- commons-collections:commons-collections:jar:3.2.2:compile[INFO] | +- javax.servlet:servlet-api:jar:2.5:compile[INFO] | +- org.mortbay.jetty:jetty-util:jar:6.1.26:compile[INFO] | +- com.sun.jersey:jersey-core:jar:1.9:compile[INFO] | +- commons-el:commons-el:jar:1.0:runtime[INFO] | +- commons-logging:commons-logging:jar:1.1.3:compile[INFO] | +- com.jamesmurty.utils:java-xmlbuilder:jar:0.4:compile[INFO] | +- commons-lang:commons-lang:jar:2.6:compile[INFO] | +- commons-configuration:commons-configuration:jar:1.7:compile[INFO] | +- commons-digester:commons-digester:jar:1.8.1:compile[INFO] | +- org.xerial.snappy:snappy-java:jar:1.0.5:compile[INFO] | +- com.google.code.gson:gson:jar:2.2.4:compile[INFO] | +- org.apache.directory.server:apacheds-kerberos-codec:jar:2.0.0-M15:compile[INFO] | +- org.apache.directory.server:apacheds-i18n:jar:2.0.0-M15:compile[INFO] | +- org.apache.directory.api:api-asn1-api:jar:1.0.0-M20:compile[INFO] | +- org.apache.directory.api:api-util:jar:1.0.0-M20:compile[INFO] | +- com.jcraft:jsch:jar:0.1.42:compile[INFO] | +- org.htrace:htrace-core:jar:3.0.4:compile[INFO] | | \- com.google.guava:guava:jar:12.0.1:compile[INFO] | | \- com.google.code.findbugs:jsr305:jar:1.3.9:compile</description>
      <version>None</version>
      <fixedVersion>1.0.0,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-shaded-hadoop.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3550" opendate="2016-2-29 00:00:00" fixdate="2016-3-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Rework stream join example</summary>
      <description>The example should be reworked with generated streams that show the continuous nature of the window join</description>
      <version>1.0.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.typeutils.TryTypeInfoTest.scala</file>
      <file type="M">flink-examples.flink-examples-streaming.src.test.java.org.apache.flink.streaming.test.exampleScalaPrograms.join.WindowJoinITCase.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.test.java.org.apache.flink.streaming.test.exampleJavaPrograms.join.WindowJoinITCase.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.scala.org.apache.flink.streaming.scala.examples.join.WindowJoin.scala</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.java.org.apache.flink.streaming.examples.join.WindowJoin.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.java.org.apache.flink.streaming.examples.join.util.WindowJoinData.java</file>
      <file type="M">flink-examples.flink-examples-streaming.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3551" opendate="2016-2-29 00:00:00" fixdate="2016-6-29 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Sync Scala and Java Streaming Examples</summary>
      <description>The Scala Examples lack behind the Java Examples</description>
      <version>1.0.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-examples.flink-examples-streaming.src.test.scala.org.apache.flink.streaming.scala.examples.WindowJoinITCase.scala</file>
      <file type="M">flink-examples.flink-examples-streaming.src.test.java.org.apache.flink.streaming.test.examples.wordcount.WordCountITCase.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.test.java.org.apache.flink.streaming.test.examples.wordcount.PojoExampleITCase.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.test.java.org.apache.flink.streaming.test.examples.windowing.WindowWordCountITCase.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.test.java.org.apache.flink.streaming.test.examples.windowing.SessionWindowingITCase.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.test.java.org.apache.flink.streaming.test.examples.twitter.TwitterStreamITCase.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.test.java.org.apache.flink.streaming.test.examples.ml.IncrementalLearningSkeletonITCase.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.test.java.org.apache.flink.streaming.test.examples.join.WindowJoinITCase.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.test.java.org.apache.flink.streaming.test.examples.iteration.IterateExampleITCase.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.scala.org.apache.flink.streaming.scala.examples.socket.SocketWindowWordCount.scala</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.scala.org.apache.flink.streaming.scala.examples.join.WindowJoin.scala</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.java.org.apache.flink.streaming.examples.wordcount.PojoExample.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.java.org.apache.flink.streaming.examples.windowing.SessionWindowing.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.java.org.apache.flink.streaming.examples.windowing.GroupedProcessingTimeWindowExample.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.java.org.apache.flink.streaming.examples.ml.IncrementalLearningSkeleton.java</file>
    </fixedFiles>
  </bug>
  <bug id="3552" opendate="2016-2-29 00:00:00" fixdate="2016-3-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change socket WordCount to be properly windowed</summary>
      <description></description>
      <version>1.0.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.SocketProgramITCaseBase.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.test.java.org.apache.flink.streaming.test.exampleScalaPrograms.socket.SocketTextStreamWordCountITCase.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.test.java.org.apache.flink.streaming.test.exampleJavaPrograms.socket.SocketTextStreamWordCountITCase.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.scala.org.apache.flink.streaming.scala.examples.socket.SocketTextStreamWordCount.scala</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.java.org.apache.flink.streaming.examples.socket.SocketTextStreamWordCount.java</file>
      <file type="M">flink-examples.flink-examples-streaming.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3557" opendate="2016-3-1 00:00:00" fixdate="2016-3-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scala DataStream fold method should take fold function in secondary parameter list</summary>
      <description>The current Scala DataStream API offers a fold method. The fold method takes two parameters, the initial value and the fold function. However, both parameters are specified in the same parameter list. This makes it clumsy to provide a multi-line anonymous function as the fold function parameter in Scala. One would have to wrap the function in an additional pair of curly braces. This could be avoided by having a second parameter list which takes the fold function. This would, additionally, be consistent with Scala's collection API.Old stylewindowedStream.fold(("R:", 0), { (acc: (String, Int), v: (String, Int)) =&gt; (acc._1 + v._1, acc._2 + v._2) })vs. new stylewindowedStream.fold(("R:", 0)){ (acc, v) =&gt; (acc._1 + v._1, acc._2 + v._2) }These changes are API breaking.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-scala.src.test.scala.org.apache.flink.streaming.api.scala.WindowFoldITCase.scala</file>
      <file type="M">flink-streaming-scala.src.test.scala.org.apache.flink.streaming.api.scala.DataStreamTest.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.WindowedStream.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.KeyedStream.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.AllWindowedStream.scala</file>
    </fixedFiles>
  </bug>
  <bug id="3559" opendate="2016-3-1 00:00:00" fixdate="2016-3-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Don&amp;#39;t print pid file check if no active PID</summary>
      <description>If there is a pid file but no alive process for the pids:[INFO] 0 instance(s) of jobmanager are already running on pablo.</description>
      <version>None</version>
      <fixedVersion>1.0.0,1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-dist.src.main.flink-bin.bin.flink-daemon.sh</file>
    </fixedFiles>
  </bug>
  <bug id="3560" opendate="2016-3-1 00:00:00" fixdate="2016-4-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Examples shouldn&amp;#39;t always print usage statement</summary>
      <description>At the moment all our examples print a usage statement no matter whether the parameters have been provided or not. This can be confusing for people because an usage statement is usually only printed if one has specified a wrong parameter or if a parameter is missing.I propose to remove the unchecked printing of the usage statement.</description>
      <version>1.0.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-quickstart.flink-quickstart-scala.src.main.resources.archetype-resources.src.main.scala.SocketTextStreamWordCount.scala</file>
      <file type="M">flink-quickstart.flink-quickstart-java.src.main.resources.archetype-resources.src.main.java.SocketTextStreamWordCount.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.scala.org.apache.flink.streaming.scala.examples.windowing.TopSpeedWindowing.scala</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.java.org.apache.flink.streaming.examples.wordcount.WordCount.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.java.org.apache.flink.streaming.examples.wordcount.PojoExample.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.java.org.apache.flink.streaming.examples.windowing.WindowWordCount.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.java.org.apache.flink.streaming.examples.windowing.TopSpeedWindowing.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.java.org.apache.flink.streaming.examples.windowing.SessionWindowing.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.java.org.apache.flink.streaming.examples.ml.IncrementalLearningSkeleton.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.java.org.apache.flink.streaming.examples.kafka.WriteIntoKafka.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.java.org.apache.flink.streaming.examples.iteration.IterateExample.java</file>
      <file type="M">flink-examples.flink-examples-batch.src.main.scala.org.apache.flink.examples.scala.wordcount.WordCount.scala</file>
      <file type="M">flink-examples.flink-examples-batch.src.main.scala.org.apache.flink.examples.scala.relational.WebLogAnalysis.scala</file>
      <file type="M">flink-examples.flink-examples-batch.src.main.scala.org.apache.flink.examples.scala.relational.TPCHQuery3.scala</file>
      <file type="M">flink-examples.flink-examples-batch.src.main.scala.org.apache.flink.examples.scala.relational.TPCHQuery10.scala</file>
      <file type="M">flink-examples.flink-examples-batch.src.main.scala.org.apache.flink.examples.scala.ml.LinearRegression.scala</file>
      <file type="M">flink-examples.flink-examples-batch.src.main.scala.org.apache.flink.examples.scala.graph.TransitiveClosureNaive.scala</file>
      <file type="M">flink-examples.flink-examples-batch.src.main.scala.org.apache.flink.examples.scala.graph.PageRankBasic.scala</file>
      <file type="M">flink-examples.flink-examples-batch.src.main.scala.org.apache.flink.examples.scala.graph.EnumTriangles.scala</file>
      <file type="M">flink-examples.flink-examples-batch.src.main.scala.org.apache.flink.examples.scala.graph.ConnectedComponents.scala</file>
      <file type="M">flink-examples.flink-examples-batch.src.main.scala.org.apache.flink.examples.scala.clustering.KMeans.scala</file>
      <file type="M">flink-examples.flink-examples-batch.src.main.java.org.apache.flink.examples.java.wordcount.WordCount.java</file>
      <file type="M">flink-examples.flink-examples-batch.src.main.java.org.apache.flink.examples.java.relational.WebLogAnalysis.java</file>
      <file type="M">flink-examples.flink-examples-batch.src.main.java.org.apache.flink.examples.java.relational.TPCHQuery3.java</file>
      <file type="M">flink-examples.flink-examples-batch.src.main.java.org.apache.flink.examples.java.relational.TPCHQuery10.java</file>
      <file type="M">flink-examples.flink-examples-batch.src.main.java.org.apache.flink.examples.java.relational.EmptyFieldsCountAccumulator.java</file>
      <file type="M">flink-examples.flink-examples-batch.src.main.java.org.apache.flink.examples.java.ml.LinearRegression.java</file>
      <file type="M">flink-examples.flink-examples-batch.src.main.java.org.apache.flink.examples.java.graph.TransitiveClosureNaive.java</file>
      <file type="M">flink-examples.flink-examples-batch.src.main.java.org.apache.flink.examples.java.graph.PageRank.java</file>
      <file type="M">flink-examples.flink-examples-batch.src.main.java.org.apache.flink.examples.java.graph.EnumTriangles.java</file>
      <file type="M">flink-examples.flink-examples-batch.src.main.java.org.apache.flink.examples.java.graph.ConnectedComponents.java</file>
      <file type="M">flink-examples.flink-examples-batch.src.main.java.org.apache.flink.examples.java.distcp.DistCp.java</file>
      <file type="M">flink-examples.flink-examples-batch.src.main.java.org.apache.flink.examples.java.clustering.KMeans.java</file>
    </fixedFiles>
  </bug>
  <bug id="3566" opendate="2016-3-2 00:00:00" fixdate="2016-3-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Input type validation often fails on custom TypeInfo implementations</summary>
      <description>Input type validation often fails when used with custom type infos. One example of this behaviour can be reproduced by creating a custom type info with our own field type:StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();env.generateSequence(1, 10).map(new MapFunction&lt;Long, Tuple1&lt;Optional&lt;Long&gt;&gt;&gt;() { @Override public Tuple1&lt;Optional&lt;Long&gt;&gt; map(Long value) throws Exception { return Tuple1.of(Optional.of(value)); } }).returns(new TupleTypeInfo&lt;&gt;(new OptionTypeInfo&lt;Long&gt;(BasicTypeInfo.LONG_TYPE_INFO))) .keyBy(new KeySelector&lt;Tuple1&lt;Optional&lt;Long&gt;&gt;, Optional&lt;Long&gt;&gt;() { @Override public Optional&lt;Long&gt; getKey(Tuple1&lt;Optional&lt;Long&gt;&gt; value) throws Exception { return value.f0; } });This will fail on Input type validation at the KeySelector (or any other function for example a mapper) with the following exception:Input mismatch: Basic type expected.</description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.java.typeutils.TypeExtractorTest.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.TypeExtractor.java</file>
    </fixedFiles>
  </bug>
  <bug id="3573" opendate="2016-3-3 00:00:00" fixdate="2016-3-3 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Implement more String functions for Table API</summary>
      <description>Implement the remaining string functions:CHARACTER_LENGTHCONCATUPPERLOWERINITCAPLIKESIMILAR</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.test.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.RexNodeTranslator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.call.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.CodeGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.TrimCallGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.ScalarFunctions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.MethodCallGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.CallGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.scala.table.expressionDsl.scala</file>
    </fixedFiles>
  </bug>
  <bug id="3574" opendate="2016-3-3 00:00:00" fixdate="2016-3-3 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Implement math functions for Table API</summary>
      <description>MODEXPPOWERLNLOG10ABS</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.test.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.RexNodeTranslator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.parser.ExpressionParser.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.call.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.arithmetic.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.ScalarFunctions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.scala.table.expressionDsl.scala</file>
    </fixedFiles>
  </bug>
  <bug id="3577" opendate="2016-3-4 00:00:00" fixdate="2016-3-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Display anchor links when hovering over headers.</summary>
      <description>This is useful to share the document url if display anchor links when hovering over headers. Currently we must scroll up to the TOC, find the section,click it, then copy the url.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">LICENSE</file>
      <file type="M">docs..layouts.base.html</file>
      <file type="M">docs.page.js.codetabs.js</file>
      <file type="M">docs.page.css.flink.css</file>
    </fixedFiles>
  </bug>
  <bug id="3578" opendate="2016-3-4 00:00:00" fixdate="2016-3-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scala DataStream API does not support Rich Window Functions</summary>
      <description>The Scala Window functions are currently wrapped in a way that RichFunction method calls are not forwarded.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.1,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-scala.src.test.scala.org.apache.flink.streaming.api.scala.WindowFoldITCase.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.WindowedStream.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.function.AllWindowFunction.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.AllWindowedStream.scala</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.functions.InternalIterableWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.RichWindowFunction.java</file>
    </fixedFiles>
  </bug>
  <bug id="3579" opendate="2016-3-4 00:00:00" fixdate="2016-4-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve String concatenation</summary>
      <description>Concatenation of a String and non-String does not work properly.e.g. f0 + 42 leads to RelBuilder ExceptionExpressionParser does not like f0 + 42.cast(STRING) either.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.table.test.StringExpressionsITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.RexNodeTranslator.scala</file>
    </fixedFiles>
  </bug>
  <bug id="3580" opendate="2016-3-4 00:00:00" fixdate="2016-1-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reintroduce Date/Time and implement scalar functions for it</summary>
      <description>This task includes:DATETIME_PLUSEXTRACT_DATEFLOORCEILCURRENT_TIMECURRENT_TIMESTAMPLOCALTIMELOCALTIMESTAMP</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.expressions.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.validate.FunctionCatalog.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.time.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.ScalarFunctions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.FloorCeilCallGen.scala</file>
      <file type="M">docs.dev.table.api.md</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.ExpressionsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.sql.ExpressionsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.typeutils.TypeConverter.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.typeutils.TypeCoercion.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.typeutils.TypeCheckUtils.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.FunctionCompiler.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.literals.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.ExpressionParser.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.comparison.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.CodeGenUtils.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.CodeGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.ScalarOperators.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.scala.table.expressionDsl.scala</file>
      <file type="M">docs.apis.table.md</file>
    </fixedFiles>
  </bug>
  <bug id="3585" opendate="2016-3-7 00:00:00" fixdate="2016-3-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Deploy scripts don&amp;#39;t support spaces in paths</summary>
      <description></description>
      <version>1.0.0,1.1.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.generate.specific.pom.sh</file>
      <file type="M">tools.deploy.to.maven.sh</file>
    </fixedFiles>
  </bug>
  <bug id="3586" opendate="2016-3-8 00:00:00" fixdate="2016-5-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Risk of data overflow while use sum/count to calculate AVG value</summary>
      <description>Now, we use (sum: Long, count: Long to store AVG partial aggregate data, which may have data overflow risk, we should use unbounded data type(such as BigInteger) to store them for necessary data types.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.aggregate.SumAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.aggregate.MinAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.aggregate.MaxAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.aggregate.CountAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.aggregate.AvgAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.aggregate.AggregateUtil.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.aggregate.Aggregate.scala</file>
    </fixedFiles>
  </bug>
  <bug id="3587" opendate="2016-3-8 00:00:00" fixdate="2016-4-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bump Calcite version to 1.7.0</summary>
      <description>We currently depend on Calcite 1.5.0. The latest stable release is 1.6.0, but I propose we bump the version to 1.7.0-SNAPSHOT to benefit from latest features. If we do that, we can also get rid of the custom FlinkJoinUnionTransposeRule.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.StreamTableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.FlinkRuleSets.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.dataSet.FlinkFilterAggregateTransposeRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.dataSet.DataSetUnionRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.dataSet.DataSetScanRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.dataSet.DataSetJoinRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.dataSet.DataSetCalcRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.dataSet.DataSetAggregateRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.datastream.DataStreamUnion.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.datastream.DataStreamSource.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.datastream.DataStreamRel.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.datastream.DataStreamCalc.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetUnion.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetSource.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetRel.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetJoin.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetCalc.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.CodeGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.BatchTableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.scala.table.StreamTableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.scala.table.BatchTableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.java.table.StreamTableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.java.table.BatchTableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3591" opendate="2016-3-8 00:00:00" fixdate="2016-3-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace Quickstart K-Means Example by Streaming Example</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.quickstart.run.example.quickstart.md</file>
      <file type="M">docs.page.img.quickstart-example.result015.png</file>
      <file type="M">docs.page.img.quickstart-example.result008.png</file>
      <file type="M">docs.page.img.quickstart-example.result003.png</file>
      <file type="M">docs.page.img.quickstart-example.kmeans015.png</file>
      <file type="M">docs.page.img.quickstart-example.kmeans008.png</file>
      <file type="M">docs.page.img.quickstart-example.kmeans003.png</file>
      <file type="M">docs.page.img.quickstart-example.jobmanager.kmeans.submit.png</file>
      <file type="M">docs.page.img.quickstart-example.jobmanager.kmeans.execute.png</file>
    </fixedFiles>
  </bug>
  <bug id="3593" opendate="2016-3-8 00:00:00" fixdate="2016-3-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>DistinctITCase is failing</summary>
      <description>Failed tests: DistinctITCase.testDistinctAfterAggregate:70 Internal error: Error while applying rule DataSetAggregateRule, args [rel#28:FlinkAggregate.FLINK.[](input=rel#27:Subset#5.FLINK.[],group={1})] DistinctITCase.testDistinctAfterAggregate:70 Internal error: Error while applying rule DataSetAggregateRule, args [rel#86:FlinkAggregate.FLINK.[](input=rel#85:Subset#17.FLINK.[],group={1})] DistinctITCase.testDistinct:53 Internal error: Error while applying rule DataSetAggregateRule, args [rel#53:FlinkAggregate.FLINK.[](input=rel#52:Subset#10.FLINK.[],group={1})] DistinctITCase.testDistinct:53 Internal error: Error while applying rule DataSetAggregateRule, args [rel#111:FlinkAggregate.FLINK.[](input=rel#110:Subset#22.FLINK.[],group={1})] DistinctITCase.testDistinctAfterAggregate:56 Internal error: Error while applying rule DataSetAggregateRule, args [rel#28:FlinkAggregate.FLINK.[](input=rel#27:Subset#5.FLINK.[],group={1})] DistinctITCase.testDistinctAfterAggregate:56 Internal error: Error while applying rule DataSetAggregateRule, args [rel#86:FlinkAggregate.FLINK.[](input=rel#85:Subset#17.FLINK.[],group={1})] DistinctITCase.testDistinct:44 Internal error: Error while applying rule DataSetAggregateRule, args [rel#53:FlinkAggregate.FLINK.[](input=rel#52:Subset#10.FLINK.[],group={1})] DistinctITCase.testDistinct:44 Internal error: Error while applying rule DataSetAggregateRule, args [rel#111:FlinkAggregate.FLINK.[](input=rel#110:Subset#22.FLINK.[],group={1})]</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.aggregate.AggregateUtil.scala</file>
    </fixedFiles>
  </bug>
  <bug id="3595" opendate="2016-3-9 00:00:00" fixdate="2016-4-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Kafka09 consumer thread does not interrupt when stuck in record emission</summary>
      <description>When canceling a job, the Kafka 0.9 Consumer Thread may be stuck in a blocking method (output emitting) and never wakes up.The thread as a whole cannot be simply interrupted, because of a bug in Kafka that makes the consumer freeze/hang up on interrupt.There are two possible solutions: allow and call interrupt when the consumer thread is emitting elements destroy the output network buffer pools eagerly on canceling. The Kafka thread will then throw an exception if it is stuck in emitting elements and it will terminate, which is accepted in case the status is canceled.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.1,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.partition.consumer.SingleInputGateTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskmanager.Task.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate.java</file>
    </fixedFiles>
  </bug>
  <bug id="3603" opendate="2016-3-11 00:00:00" fixdate="2016-3-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Re-enable Table API explain</summary>
      <description>The Table API explain was temporarily disabled to port the Table API on top of Calcite. It should be re-enabled before merge the changes back to the master branch.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.resources.testUnion1.out</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.resources.testUnion0.out</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.resources.testJoin1.out</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.resources.testJoin0.out</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.resources.testFilter1.out</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.resources.testFilter0.out</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.table.test.SqlExplainITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.table.test.SqlExplainITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.table.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.TranslationContext.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetJoin.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetAggregate.scala</file>
    </fixedFiles>
  </bug>
  <bug id="3604" opendate="2016-3-11 00:00:00" fixdate="2016-3-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable ignored Table API tests</summary>
      <description>Several tests were disabled to move the Table API on top of Calcite. These tests should be enabled again before merging the changes back to the master branch.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.table.test.StringExpressionsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.table.test.FilterITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.table.test.CastingITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.table.test.AsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.table.test.AggregationsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.scala.table.test.PageRankTableITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.table.test.StringExpressionsITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.table.test.PojoGroupingITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.table.test.GroupedAggregationsITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.table.test.AsITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.table.test.AggregationsITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.typeinfo.RowTypeInfo.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.table.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.TypeConverter.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.scala.table.package.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.scala.table.DataSetConversions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.java.table.JavaBatchTranslator.scala</file>
    </fixedFiles>
  </bug>
  <bug id="3607" opendate="2016-3-11 00:00:00" fixdate="2016-5-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Decrease default forkCount for tests</summary>
      <description>I'm seeing many tests failures because of timeouts:https://builds.apache.org/job/flink-ci/1/testReport/The forkCount is set to the aggressive value 1.5C. We should consider to reduce it at least to 1C (1 fork per exposed physical/virtual core). That could improve the test stability.I did another test using 1C on Jenkins and had only one failed test and a decreased run time: https://builds.apache.org/job/flink-ci/2/testReport/1.5C: 1h 57m1C: 1h 35mI'll run some more tests to verify this.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3626" opendate="2016-3-16 00:00:00" fixdate="2016-6-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>zipWithIndex in Python API</summary>
      <description>Implementation of a `zipWithIndex` method for the Python API on Flink. This will affix each record with a sequential integer ID, consistent across the distributed data structure.Work here: https://github.com/magsol/flink</description>
      <version>1.0.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-python.src.test.python.org.apache.flink.python.api.test.main.py</file>
      <file type="M">flink-libraries.flink-python.src.main.python.org.apache.flink.python.api.flink.plan.Environment.py</file>
      <file type="M">flink-libraries.flink-python.src.main.python.org.apache.flink.python.api.flink.plan.DataSet.py</file>
      <file type="M">flink-libraries.flink-python.src.main.python.org.apache.flink.python.api.flink.functions.RuntimeContext.py</file>
      <file type="M">flink-libraries.flink-python.src.main.python.org.apache.flink.python.api.flink.functions.ReduceFunction.py</file>
      <file type="M">flink-libraries.flink-python.src.main.python.org.apache.flink.python.api.flink.functions.GroupReduceFunction.py</file>
      <file type="M">flink-libraries.flink-python.src.main.python.org.apache.flink.python.api.flink.functions.Function.py</file>
      <file type="M">flink-libraries.flink-python.src.main.python.org.apache.flink.python.api.flink.functions.CoGroupFunction.py</file>
      <file type="M">flink-libraries.flink-python.src.main.java.org.apache.flink.python.api.streaming.data.PythonStreamer.java</file>
      <file type="M">docs.apis.batch.zip.elements.guide.md</file>
      <file type="M">docs.apis.batch.python.md</file>
    </fixedFiles>
  </bug>
  <bug id="3638" opendate="2016-3-21 00:00:00" fixdate="2016-4-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Invalid default ports in documentation</summary>
      <description>Documentation has invalid information about ports by default. For example look at `taskmanager.data.port` option. It has default port 6121 in documentation but in code default port set to 0.Please review all ports in documentation and set valid default values.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.setup.config.md</file>
    </fixedFiles>
  </bug>
  <bug id="3644" opendate="2016-3-22 00:00:00" fixdate="2016-4-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>WebRuntimMonitor set java.io.tmpdir does not work for change upload dir.</summary>
      <description>flink-conf.yaml &amp; -Djava.io.tmpdir=. does not work for me.I don't know why.I look for the code System.getProperty("java.io.tmpdir") should work.but it is not worked.but in web ui in job manager configuration could see the java.io.tmpdir is set.</description>
      <version>1.0.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.WebRuntimeMonitorITCase.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.WebRuntimeMonitor.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.HttpRequestHandler.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.ConfigConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="3654" opendate="2016-3-22 00:00:00" fixdate="2016-4-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Disable Write-Ahead-Log in RocksDB State</summary>
      <description>We do our own checkpointing of the RocksDB database so the WAL is useless to us. Disabling writes to the WAL should give us a very large performance boost.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBValueState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBReducingState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBListState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBFoldingState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.AbstractRocksDBState.java</file>
    </fixedFiles>
  </bug>
  <bug id="3656" opendate="2016-3-22 00:00:00" fixdate="2016-11-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Rework Table API tests</summary>
      <description>The flink-table component consists of several APIs Scala-embedded Table API String-based Table API (for Java) SQLand compiles to two execution backends: DataStream API DataSet APIThere are many different translation paths involved until a query is executed: Table API String -&gt; Table API logical plan Table API Scala-expressions -&gt; Table API logical plan Table API logical plan -&gt; Calcite RelNode plans SQL -&gt; Calcite RelNode plans (done by exclusively via Calcite) Calcite RelNodes -&gt; DataSet RelNodes DataSet RelNodes -&gt; DataSet program Calcite RelNodes -&gt; DataStream RelNodes DataStream RelNodes -&gt; DataStream program Calcite RexNode expressions -&gt; generated codewhich need to be thoroughly tested.Initially, many tests were done as end-to-end integration tests with high overhead.However, due to the combinations of APIs and execution back-ends, this approach causes many redundant tests and long build times.Therefore, I propose the following testing scheme:1. Table API String -&gt; Table API expression: The String-based Table API is tested by comparing the resulting logical plan (Table.logicalPlan) to the logical plan of an equivalent Table program that uses the Scala-embedded syntax. The logical plan is the Table API internal representation which is later converted into a Calcite RelNode plan.All existing integration tests that check the "Java" Table API should be ported to unit tests. There will also be duplicated tests because, the Java Table API is tested for batch and streaming which is not necessary anymore.2. Table API Scala-expressions -&gt; Table API logical plan -&gt; Calcite RelNodes -&gt; DataSet RelNodes / DataStream RelNodesThese tests cover the translation and optimization of Table API queries and verify the Calcite optimized plan. We need distinct tests for DataSet and DataStream environments since features and translation rules vary. These test will also identify if added or modified rules or cost functions result in different plans. These should be the main tests for the Table API and very extensive. These tests should be implemented by extending the TableTestBase which is a base class for unit tests and hence very lightweight.3. SQL -&gt; Calcite RelNodes -&gt; DataSet RelNodes / DataStream RelNodesThese are the same tests as described for 2. (Table API Scala-expressions -&gt; DataSet / DataStream RelNodes) but just for SQL.4. DataSet RelNode -&gt; DataSet programUnfortunately, the DataSet API lacks a good mechanism to test generated programs, i.e., get a plan traversable of all operators with access to all user-defined functions. Until such a testing utility is available, I propose to test the translation to DataSet programs as end-to-end integration tests. However, I think we can run most tests on a Collection ExecutionEnvironment, which does not start a Flink cluster but runs all code on Java collections. This makes these tests much more lightweight than cluster-based ITCases. The goal of these tests should be to cover all translation paths from DataSetRel to DataSet program, i.e., all DataSetRel nodes and their translation logic. These tests should be implemented by extending the TableProgramsCollectionTestBase (see FLINK-5268).Moreover, we should have very few cluster-based ITCases in place that check the execution path with the actual operators, serializers, and comparators. However, we should limit these tests to the minimum to keep build time low. These tests should be implemented by extending the TableProgramsClusterTestBase (FLINK-5268) and all be located in the same class to avoid repeated instantiation of the Flink MiniCluster.5. DataStream RelNode -&gt; DataStream programHere basically the same applies as for the DataSet programs. I'm not aware of a good way to test generated DataStream programs without executing them. A testing utility would be great for all libraries that are built on top of the API. Until then, I propose to use end-to-end integration tests. Unfortunately, the DataStream API does not feature a collection execution mode, so all tests need to be run on a MiniCluster. Therefore, we should again keep these tests to the minimum. These tests should be implemented by extending the StreamingMultipleProgramsTestBase and be located in few classes to avoid repeated instantiations of the FLink MiniCluster.6. (Scala expressions | String-parsed expressions | SQL expressions) -&gt; RexNode expressions -&gt; Generated CodeIn order to avoid extensive optimization tests for each supported expression or built-in function, we have the ExpressionTestBase which compiles expressions into generated code and tests for the correctness of results. All supported expressions and built-in function should be tested by extending the ExpressionTestBase instead of running a full integration test.I will add a few JIRAs to migrate existing tests to the new testing scheme.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.stream.table.SelectITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.stream.table.FilterITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.ToTableITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.SelectITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.JoinITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.GroupedAggregationsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.FilterITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.DistinctITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.AggregationsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.TableSourceITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.TableSinkITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.TableEnvironmentITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.sql.SelectITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.sql.FilterITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.SelectITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.PojoGroupingITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.JoinITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.GroupedAggregationsITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.FromDataSetITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.FilterITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.DistinctITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.CastingITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.AggregationsITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.TableEnvironmentITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.utils.TableProgramsTestBase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.ExpressionReductionTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.expressions.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.StringExpressionsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.ExpressionsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.CastingITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.CalcITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.sql.ExpressionsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.sql.CalcITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.StringExpressionsITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.ExpressionsITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.CalcITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.ExpressionParser.scala</file>
    </fixedFiles>
  </bug>
  <bug id="3664" opendate="2016-3-23 00:00:00" fixdate="2016-4-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create a method to easily Summarize a DataSet</summary>
      <description>Here is an example:/** * Summarize a DataSet of Tuples by collecting single pass statistics for all columns */public Tuple summarize()Dataset&lt;Tuple3&lt;Double, String, Boolean&gt;&gt; input = // [...]Tuple3&lt;DoubleColumnSummary,StringColumnSummary,BooleanColumnSummary&gt; summary = input.summarize()summary.getField(0).stddev()summary.getField(1).maxStringLength()</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.util.DataSetUtilsITCase.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.utils.DataSetUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="3674" opendate="2016-3-29 00:00:00" fixdate="2016-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add an interface for Time aware User Functions</summary>
      <description>I suggest to add an interface that UDFs can implement, which will let them be notified upon watermark updates.Example usage:public interface EventTimeFunction { void onWatermark(Watermark watermark);}public class MyMapper implements MapFunction&lt;String, String&gt;, EventTimeFunction { private long currentEventTime = Long.MIN_VALUE; public String map(String value) { return value + " @ " + currentEventTime; } public void onWatermark(Watermark watermark) { currentEventTime = watermark.getTimestamp(); }}</description>
      <version>1.0.0</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.runtime.TimestampITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.SavepointITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.RescalingITCase.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.OneInputStreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.TestProcessingTimeService.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.EvictingWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.AggregatingKeyedTimePanes.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.AccumulatingKeyedTimePanes.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.AbstractAlignedProcessingTimeWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.GenericWriteAheadSink.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamSink.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamProject.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamMap.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamGroupedReduce.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamGroupedFold.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamFlatMap.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamFilter.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.co.CoStreamMap.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.co.CoStreamFlatMap.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.AbstractStreamOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.ContinuousFileReaderOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.query.AbstractQueryableStateOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.KeyedStream.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.operator.AbstractKeyedCEPPatternOperator.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.operator.AbstractCEPPatternOperator.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.wrappers.BoltWrapper.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBAsyncSnapshotTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="3676" opendate="2016-3-29 00:00:00" fixdate="2016-3-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>WebClient hasn&amp;#39;t been removed from the docs</summary>
      <description></description>
      <version>1.0.0,1.1.0</version>
      <fixedVersion>1.0.0,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-contrib.docker-flink.flink.conf.flink-conf.yaml</file>
      <file type="M">flink-contrib.docker-flink.flink.config-flink.sh</file>
      <file type="M">docs.apis.common.index.md</file>
    </fixedFiles>
  </bug>
  <bug id="3680" opendate="2016-3-30 00:00:00" fixdate="2016-11-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove or improve (not set) text in the Job Plan UI</summary>
      <description>When running streaming jobs the UI display (not set) in the UI in a few different places. This is not the case for batch jobs.To illustrate I've included screen shots of the UI for the batch and streaming WordCount examples.</description>
      <version>None</version>
      <fixedVersion>1.1.4,1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobgraph.jsonplan.JsonPlanGenerator.java</file>
      <file type="M">flink-runtime-web.web-dashboard.app.scripts.modules.jobs.jobs.dir.coffee</file>
    </fixedFiles>
  </bug>
  <bug id="3684" opendate="2016-3-31 00:00:00" fixdate="2016-3-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CEP operator does not forward watermarks properly</summary>
      <description>The CEP stream operator don't emit a proper watermark when using event time.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.1,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.operator.KeyedCEPPatternOperator.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.operator.CEPPatternOperator.java</file>
    </fixedFiles>
  </bug>
  <bug id="3697" opendate="2016-4-4 00:00:00" fixdate="2016-4-4 01:00:00" resolution="Resolved">
    <buginformation>
      <summary>keyBy() with nested POJO computes invalid field position indexes</summary>
      <description>Using named keys in keyBy() for nested POJO types results in failure. The iindexes for named key fields are used inconsistently with nested POJO types. In particular, PojoTypeInfo.getFlatFields() returns the field's position after (apparently) flattening the structure but is referenced in the unflattened version of the POJO type by PojoTypeInfo.getTypeAt().In the example below, getFlatFields() returns positions 0, 1, and 14. These positions appear correct in the flattened structure of the Data class. However, in KeySelector&lt;X, Tuple&gt; getSelectorForKeys(Keys&lt;X&gt; keys, TypeInformation&lt;X&gt; typeInfo, ExecutionConfig executionConfig), a call to compositeType.getTypeAt(logicalKeyPositions&amp;#91;i&amp;#93;) for the third key results PojoTypeInfo.getTypeAt() declaring it out of range, as it compares the length of the directly named fields of the object vs the length of flattened version of that type.Concrete Example:Consider this graph:DataStream&lt;TimesliceData&gt; dataStream = see.addSource(new FlinkKafkaConsumer08&lt;&gt;(timesliceConstants.topic, new DataDeserialzer(), kafkaConsumerProperties));dataStream .flatMap(new DataMapper()) .keyBy("aaa", "abc", "wxyz")DataDeserialzer returns a "NativeDataFormat" object; DataMapper takes this NativeDataFormat object and extracts individual Data objects: public class Data { public int aaa; public int abc; public long wxyz; public int t1; public int t2; public Policy policy; public Stats stats; public Data() {}A Policy object is an instance of this class:public class Policy { public short a; public short b; public boolean c; public boolean d; public Policy() {}}A Stats object is an instance of this class:public class Stats { public long count; public float a; public float b; public float c; public float d; public float e; public Stats() {}}</description>
      <version>1.0.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.CoStreamITCase.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.util.keys.KeySelectorUtil.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.util.FieldAccessor.java</file>
    </fixedFiles>
  </bug>
  <bug id="3711" opendate="2016-4-7 00:00:00" fixdate="2016-4-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scala fold() example syntax incorrect</summary>
      <description>Scala's KeyedStream#fold which accepts scala.Function2 is defined as a partially appliable function. The documentation, however, is written as if it is a non-partial function.</description>
      <version>1.0.0,1.0.1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.apis.streaming.index.md</file>
    </fixedFiles>
  </bug>
  <bug id="3712" opendate="2016-4-7 00:00:00" fixdate="2016-4-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>YARN client dynamic properties are not passed correctly to the leader election service on the client</summary>
      <description>The issue was reported here: http://apache-flink-user-mailing-list-archive.2336050.n4.nabble.com/YARN-High-Availability-td3558.htmlDynamic properties (for example the zookeeper root path) are not properly passed to the leader election service on the client.The election service is using the configuration values from the config file instead of the properties dynamically passed.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.2,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.FlinkYarnClientBase.java</file>
      <file type="M">flink-yarn-tests.src.main.java.org.apache.flink.yarn.YARNSessionFIFOITCase.java</file>
      <file type="M">flink-yarn-tests.src.main.java.org.apache.flink.yarn.YARNHighAvailabilityITCase.java</file>
      <file type="M">flink-scala-shell.src.main.scala.org.apache.flink.api.scala.FlinkShell.scala</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.yarn.AbstractFlinkYarnClient.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.leaderretrieval.StandaloneLeaderRetrievalService.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.FlinkYarnSessionCli.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.CliFrontend.java</file>
    </fixedFiles>
  </bug>
  <bug id="3718" opendate="2016-4-8 00:00:00" fixdate="2016-4-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add Option For Completely Async Backup in RocksDB State Backend</summary>
      <description>Right now, the snapshotting for RocksDB has a synchronous part where a backup of the RocksDB database is drawn and an asynchronous part where this backup is written to HDFS.We should add an option that uses the snapshot feature of RocksDB to get an iterator over all keys at a set point in time. The iterator can be used to store everything to HDFS. Normal operation can continue while we store the keys. This makes the snapshot completely asynchronous.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.EventTimeWindowCheckpointingITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.StateBackendTestBase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.MemoryStateBackendTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.FileStateBackendTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.AbstractStateBackend.java</file>
      <file type="M">flink-fs-tests.src.test.java.org.apache.flink.hdfstests.FileStateBackendTest.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.ValueStateDescriptor.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.StateDescriptor.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.ReducingStateDescriptor.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.ListStateDescriptor.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.FoldingStateDescriptor.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackendConfigTest.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBAsyncKVSnapshotTest.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBValueState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackend.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBReducingState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBListState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBFoldingState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.PredefinedOptions.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.OptionsFactory.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.AbstractRocksDBState.java</file>
      <file type="M">flink-state-backends.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.OptionsFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="3754" opendate="2016-4-14 00:00:00" fixdate="2016-5-14 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Add a validation phase before construct RelNode using TableAPI</summary>
      <description>Unlike sql string's execution, which have a separate validation phase before RelNode construction, Table API lacks the counterparts and the validation is scattered in many places.I suggest to add a single validation phase and detect problems as early as possible.</description>
      <version>1.0.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.stream.table.UnsupportedOpsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.stream.table.UnionITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.expression.utils.ExpressionEvaluator.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.UnionITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.StringExpressionsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.SelectITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.JoinITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.GroupedAggregationsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.FilterITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.ExpressionsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.AggregationsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.TableEnvironmentITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.UnionITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.StringExpressionsITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.SelectITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.JoinITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.GroupedAggregationsITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.FilterITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.ExpressionsITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.AggregationsITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.TableEnvironmentITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.TableException.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.TableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.table.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.StreamTableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.RexNodeTranslator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.FlinkPlannerImpl.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.TreeNode.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.ordering.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.logic.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.literals.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.fieldExpression.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.ExpressionParser.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.Expression.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.comparison.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.cast.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.call.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.arithmetic.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.aggregations.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.ExpressionParserException.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.BatchTableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.scala.table.expressionDsl.scala</file>
    </fixedFiles>
  </bug>
  <bug id="3761" opendate="2016-4-14 00:00:00" fixdate="2016-9-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Refactor State Backends/Make Keyed State Key-Group Aware</summary>
      <description>After an off-line discussion with aljoscha, we came to the conclusion that it would be beneficial to reflect the differences between a keyed and a non-keyed stream also in the state backends. A state backend which is used for a keyed stream offers a value, list, folding and value state and has to group its keys into key groups. A state backend for non-keyed streams can only offer a union state to make it work with dynamic scaling. A union state is a state which is broadcasted to all tasks in case of a recovery. The state backends can then select what information they need to recover from the whole state (formerly distributed).</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.filesystem.FsStateBackend.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.memory.MemCheckpointStreamFactory.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackend.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.runtime.StateBackendITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.state.StateHandleSerializationTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.classloading.jar.CustomKvStateProgram.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.classloading.ClassLoaderITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.EventTimeWindowCheckpointingITCase.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.WindowingTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.TestHarnessUtil.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.OneInputStreamOperatorTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.MockContext.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamMockEnvironment.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.OneInputStreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.InterruptSensitiveRestoreTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.WindowOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.EvictingWindowOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.AggregatingAlignedProcessingTimeWindowOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.AccumulatingAlignedProcessingTimeWindowOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.StreamOperatorChainingTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.StreamingRuntimeContextTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.StreamGroupedReduceTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.StreamGroupedFoldTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.AbstractAlignedProcessingTimeWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.GenericWriteAheadSink.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.AbstractStreamOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamGraphGenerator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.ContinuousFileReaderOperator.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskmanager.TaskTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskmanager.TaskManagerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskmanager.TaskAsyncCallTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.StateBackendTestBase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.MemoryStateBackendTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.filesystem.FsCheckpointStateOutputStreamTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.FileStateBackendTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.QueryableStateClientTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.netty.KvStateServerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.netty.KvStateServerHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.netty.KvStateClientTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.testutils.MockEnvironment.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.testutils.DummyEnvironment.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.groups.TaskManagerGroupTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.messages.CheckpointMessagesTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.deployment.TaskDeploymentDescriptorTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.checkpoint.savepoint.SavepointLoaderTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.StreamStateHandle.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.StateObject.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.RetrievableStreamStateHandle.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.memory.MemValueState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.memory.MemReducingState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.memory.MemoryStateBackend.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.memory.MemListState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.memory.MemFoldingState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.memory.ByteStreamStateHandle.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.memory.AbstractMemStateSnapshot.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.memory.AbstractMemState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.KvStateSnapshot.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.KvState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.KeyGroupRange.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.GenericReducingState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.GenericListState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.GenericFoldingState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.filesystem.FsValueState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.AbstractRocksDBState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBFoldingState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBListState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBReducingState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackend.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBValueState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.FullyAsyncRocksDBStateBackendTest.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBAsyncKVSnapshotTest.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackendConfigTest.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackendTest.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.test.java.org.apache.flink.storm.tests.StormFieldsGroupingITCase.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.wrappers.BoltWrapper.java</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.wrappers.BoltWrapperTest.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.CollectionExecutor.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.TaskInfo.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.FSDataOutputStream.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.local.LocalDataOutputStream.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.functions.util.RuntimeUDFContextTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.io.RichInputFormatTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.io.RichOutputFormatTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.operators.base.FlatMapOperatorCollectionTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.operators.base.InnerJoinOperatorBaseTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.operators.base.MapOperatorTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.operators.base.PartitionMapOperatorTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.operators.GenericDataSinkBaseTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.operators.GenericDataSourceBaseTest.java</file>
      <file type="M">flink-fs-tests.src.test.java.org.apache.flink.hdfstests.FileStateBackendTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.common.operators.base.CoGroupOperatorCollectionTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.common.operators.base.GroupReduceOperatorTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.common.operators.base.InnerJoinOperatorBaseTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.common.operators.base.ReduceOperatorTest.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.nfa.NFA.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.operator.AbstractKeyedCEPPatternOperator.java</file>
      <file type="M">flink-libraries.flink-cep.src.test.java.org.apache.flink.cep.operator.CEPOperatorTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.CheckpointCoordinator.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.deployment.TaskDeploymentDescriptor.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.ExecutionVertex.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.fs.hdfs.HadoopDataOutputStream.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.KvStateRegistry.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.KvStateServerHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.TaskKvStateRegistry.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.AbstractHeapState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.AbstractStateBackend.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.AsynchronousKvStateSnapshot.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.filesystem.AbstractFsState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.filesystem.AbstractFsStateSnapshot.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.filesystem.FileStateHandle.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.filesystem.FsFoldingState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.filesystem.FsListState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.filesystem.FsReducingState.java</file>
    </fixedFiles>
  </bug>
  <bug id="3786" opendate="2016-4-19 00:00:00" fixdate="2016-5-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add BigDecimal and BigInteger as Basic types</summary>
      <description>We already had the discussion on the mailing list some months ago about adding BigDecimal and BigInteger as basic types.Especially for business or scientific applications it makes sense to support the BigInteger and BigDecimal types natively. In my opinion they are as important as Date or Void and should be added as BasicTypes. The Table API would also benefit from it.http://mail-archives.apache.org/mod_mbox/flink-dev/201511.mbox/%3C564CAD71.8070001@apache.org%3E</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-core.src.test.java.org.apache.flink.types.BasicTypeInfoTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.java.typeutils.TypeInfoParserTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.java.typeutils.TypeExtractorTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.typeutils.ComparatorTestBase.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.typeutils.base.LongSerializerTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.typeutils.base.IntSerializerTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.typeutils.base.FloatSerializerTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.typeutils.base.DoubleSerializerTest.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.TypeInfoParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeinfo.BasicTypeInfo.java</file>
      <file type="M">docs.internals.types.serialization.md</file>
    </fixedFiles>
  </bug>
  <bug id="3815" opendate="2016-4-26 00:00:00" fixdate="2016-4-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace Guava Preconditions usage in flink-gelly</summary>
      <description></description>
      <version>1.0.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.spargel.ScatterGatherIteration.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.pregel.VertexCentricIteration.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.IterationConfiguration.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.gsa.GatherSumApplyIteration.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.GraphCsvReader.java</file>
      <file type="M">flink-libraries.flink-gelly.pom.xml</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.program.Client.java</file>
      <file type="M">flink-clients.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3817" opendate="2016-4-26 00:00:00" fixdate="2016-4-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove unused Guava dependency from RocksDB StateBackend</summary>
      <description></description>
      <version>1.0.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3818" opendate="2016-4-26 00:00:00" fixdate="2016-4-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove Guava dependency from flink-gelly-examples</summary>
      <description></description>
      <version>1.0.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.examples.data.SummarizationData.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3819" opendate="2016-4-26 00:00:00" fixdate="2016-4-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace Guava Preconditions usage in flink-gelly-scala</summary>
      <description></description>
      <version>1.0.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-gelly-scala.src.main.scala.org.apache.flink.graph.scala.Graph.scala</file>
      <file type="M">flink-libraries.flink-gelly-scala.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3821" opendate="2016-4-26 00:00:00" fixdate="2016-5-26 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Reduce Guava usage in flink-java</summary>
      <description></description>
      <version>1.0.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.tuple.TupleGenerator.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.sampling.RandomSamplerTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.io.CsvInputFormatTest.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.utils.ParameterTool.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.utils.DataSetUtils.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sampling.ReservoirSamplerWithReplacement.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sampling.ReservoirSamplerWithoutReplacement.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sampling.PoissonSampler.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sampling.BernoulliSampler.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.UnsortedGrouping.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.RichCombineToGroupCombineWrapper.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.CombineToGroupCombineWrapper.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.SortedGrouping.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.ProjectOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.JoinOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.DeltaIteration.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.CrossOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.AggregateOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.TextValueInputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.PojoCsvInputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.CsvReader.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.CsvInputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.hadoop.mapreduce.HadoopInputFormatBase.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.ExecutionEnvironment.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.DataSet.java</file>
      <file type="M">flink-java.pom.xml</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.Preconditions.java</file>
    </fixedFiles>
  </bug>
  <bug id="3840" opendate="2016-4-28 00:00:00" fixdate="2016-4-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RocksDB local parent dir is polluted with empty folders with random names</summary>
      <description>For some reason when the job starts the rocksdb root dir filled with hundreds of empty folders with random names like:041da1c-5fec-42ed-a69c-298240f1a065 4e6061aa-0c69-4755-a1ad-5ac4dec1d3f0 a7004bd1-778c-4a0f-96d4-9941208d188800db8406-6cb4-46ad-aac9-beeaa3247d16</description>
      <version>1.0.0,1.0.1,1.0.2,1.1.0</version>
      <fixedVersion>1.0.3,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackend.java</file>
    </fixedFiles>
  </bug>
  <bug id="3891" opendate="2016-5-10 00:00:00" fixdate="2016-7-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a class containing all supported Table API types</summary>
      <description>In order to make working with the Table API easier. It would be great to have a class that contains the supported types.Such that an expression could look like:.select(42.cast(TableType.INT), 43.cast(TableType.DECIMAL))The constants would map to the original TypeInformation object (in BasicTypeInfo, SqlTimeTypeInfo, etc.).</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.expressions.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.expressions.DecimalTypeTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.expression.TimeTypesTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.ExpressionsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.CastingITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.CastingITCase.java</file>
    </fixedFiles>
  </bug>
  <bug id="3964" opendate="2016-5-24 00:00:00" fixdate="2016-2-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Job submission times out with recursive.file.enumeration</summary>
      <description>When using "recursive.file.enumeration" with a big enough folder structure to list, flink batch job fails right at the beginning because of a timeout.Problem detailsWe get this error: Communication with JobManager failed: Job submission to the JobManager timed out.The code we have is basically this:val env = ExecutionEnvironment.getExecutionEnvironmentval parameters = new Configuration// set the recursive enumeration parameterparameters.setBoolean("recursive.file.enumeration", true)val parameter = ParameterTool.fromArgs(args)val input_data_path : String = parameter.get("input_data_path", null )val data : DataSet[(Text,Text)] = env.readSequenceFile(classOf[Text], classOf[Text], input_data_path).withParameters(parameters)data.first(10).printIf we set input_data_path parameter to s3n://bucket/path/date=*/ it times out. If we use a more restrictive pattern like s3n://bucket/path/date=20160523/, it doesn't time out.To me it seems that time taken to list files shouldn't cause any timeouts on job submission level.For us this was "fixed" by adding akka.client.timeout: 600 s in flink-conf.yaml, but I wonder if the timeout would still occur if we have even more files to list?P.S. Is there any way to set akka.client.timeout when calling bin/flink run instead of editing flink-conf.yaml. I tried to add it as a -yD flag but couldn't get it working.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.client.JobClientActor.java</file>
    </fixedFiles>
  </bug>
  <bug id="4038" opendate="2016-6-9 00:00:00" fixdate="2016-6-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Impossible to set more than 1 JVM argument in env.java.opts</summary>
      <description>The Taskmanager start scripts fail when env.java.opts contains more than 1 jvm opts due to:if [[ $FLINK_TM_MEM_PRE_ALLOCATE == "false" ]] &amp;&amp; [ -z $FLINK_ENV_JAVA_OPTS ]; then-z checks the length of the first argument but it fails if it has more than 1 argument</description>
      <version>1.0.0,1.1.0</version>
      <fixedVersion>1.0.4,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-dist.src.main.flink-bin.bin.taskmanager.sh</file>
    </fixedFiles>
  </bug>
  <bug id="4150" opendate="2016-7-4 00:00:00" fixdate="2016-7-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Problem with Blobstore in Yarn HA setting on recovery after cluster shutdown</summary>
      <description>Submitting a job in Yarn with HA can lead to the following exception:org.apache.flink.streaming.runtime.tasks.StreamTaskException: Cannot load user class: org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer09ClassLoader info: URL ClassLoader: file: '/tmp/blobStore-ccec0f4a-3e07-455f-945b-4fcd08f5bac1/cache/blob_7fafffe9595cd06aff213b81b5da7b1682e1d6b0' (invalid JAR: zip file is empty)Class not resolvable through given classloader. at org.apache.flink.streaming.api.graph.StreamConfig.getStreamOperator(StreamConfig.java:207) at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:222) at org.apache.flink.runtime.taskmanager.Task.run(Task.java:588) at java.lang.Thread.run(Thread.java:745)Some job information, including the Blob ids, are stored in Zookeeper. The actual Blobs are stored in a dedicated BlobStore, if the recovery mode is set to Zookeeper. This BlobStore is typically located in a FS like HDFS. When the cluster is shut down, the path for the BlobStore is deleted. When the cluster is then restarted, recovering jobs cannot restore because it's Blob ids stored in Zookeeper now point to deleted files.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.leaderelection.TestingLeaderElectionService.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.execution.librarycache.BlobLibraryCacheRecoveryITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.blob.BlobRecoveryITCase.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.execution.librarycache.BlobLibraryCacheManager.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.FileSystemBlobStore.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobServerConnection.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="4151" opendate="2016-7-5 00:00:00" fixdate="2016-7-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Address Travis CI build time: We are exceeding the 2 hours limit</summary>
      <description>We've recently started hitting the two hours limit for Travis CI.I'll look into some approaches to get our build stable again.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">.travis.yml</file>
    </fixedFiles>
  </bug>
  <bug id="4169" opendate="2016-7-7 00:00:00" fixdate="2016-7-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CEP Does Not Work with RocksDB StateBackend</summary>
      <description>A job will never match any patterns because ValueState.update() is not called in the keyed CEP operators for updating the NFA state and the priority queue state.The reason why it works for other state backends is that they are very lax in their handling of state: if the object returned from ValueState.value()) is mutable changes to this will be reflected in checkpoints even if ValueState.update() is not called. RocksDB, on the other hand, does always deserialize/serialize state values when accessing/updating them, so changes to the returned object will not be reflected in the state unless update() is called.We should fix this and also add a test for it. This might be tricky because we have to pull together RocksDB and CEP.</description>
      <version>1.0.0,1.0.1,1.0.2,1.0.3,1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-cep.src.test.java.org.apache.flink.cep.operator.CEPOperatorTest.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.operator.AbstractKeyedCEPPatternOperator.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.operator.AbstractCEPPatternOperator.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.operator.AbstractCEPBasePatternOperator.java</file>
      <file type="M">flink-libraries.flink-cep.pom.xml</file>
    </fixedFiles>
  </bug>
</bugrepository>
