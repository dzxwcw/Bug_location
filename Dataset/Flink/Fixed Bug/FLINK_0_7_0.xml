<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="FLINK">
  <bug id="1062" opendate="2014-8-25 00:00:00" fixdate="2014-9-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Type Extraction for Lambdas</summary>
      <description>Lambdas currently work only for filter and reduce(a,b), because Lambda type extraction is not in place right now.We need to extend the type extraction for lambdas to support the other functions.</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>0.7.0-incubating</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-quickstart.README.md</file>
      <file type="M">flink-quickstart.flink-quickstart-java.src.main.resources.archetype-resources.src.main.java.Job.java</file>
      <file type="M">flink-quickstart.flink-quickstart-java.src.main.resources.archetype-resources.pom.xml</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.type.extractor.TypeExtractorTest.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.typeutils.TypeExtractor.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.UnsortedGrouping.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.SortedGrouping.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.PartitionedDataSet.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.JoinOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.CrossOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.CoGroupOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.functions.UnsupportedLambdaExpressionException.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.DataSet.java</file>
      <file type="M">flink-java8-tests.src.test.java.org.apache.flink.test.javaApiOperators.lambdas.ReduceITCase.java</file>
      <file type="M">flink-java8-tests.src.test.java.org.apache.flink.test.javaApiOperators.lambdas.MapITCase.java</file>
      <file type="M">flink-java8-tests.src.test.java.org.apache.flink.test.javaApiOperators.lambdas.LambdaExtractionTest.java</file>
      <file type="M">flink-java8-tests.src.test.java.org.apache.flink.test.javaApiOperators.lambdas.KeySelectorTest.java</file>
      <file type="M">flink-java8-tests.src.test.java.org.apache.flink.test.javaApiOperators.lambdas.JoinITCase.java</file>
      <file type="M">flink-java8-tests.src.test.java.org.apache.flink.test.javaApiOperators.lambdas.GroupReduceITCase.java</file>
      <file type="M">flink-java8-tests.src.test.java.org.apache.flink.test.javaApiOperators.lambdas.FlatMapITCase.java</file>
      <file type="M">flink-java8-tests.src.test.java.org.apache.flink.test.javaApiOperators.lambdas.FlatJoinITCase.java</file>
      <file type="M">flink-java8-tests.src.test.java.org.apache.flink.test.javaApiOperators.lambdas.FilterITCase.java</file>
      <file type="M">flink-java8-tests.src.test.java.org.apache.flink.test.javaApiOperators.lambdas.CrossITCase.java</file>
      <file type="M">flink-java8-tests.src.test.java.org.apache.flink.test.javaApiOperators.lambdas.CoGroupITCase.java</file>
      <file type="M">flink-java8-tests.pom.xml</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.util.FunctionUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="1065" opendate="2014-8-26 00:00:00" fixdate="2014-8-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>"flink-streaming-core" build fails with Hadoop 2.4.0 dependencies</summary>
      <description>Hi,building Flink with "mvn clean package -Dhadoop.profile=2 -DskipTests -Dhadoop-two.version=2.4.0"results in the following error[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project flink-streaming-core: Compilation failure: Compilation failure:[ERROR] /home/robert/incubator-flink/flink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/invokable/operator/BatchReduceInvokable.java:[22,36] package org.apache.commons.math.util does not exist[ERROR] /home/robert/incubator-flink/flink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/invokable/operator/WindowReduceInvokable.java:[22,36] package org.apache.commons.math.util does not exist[ERROR] /home/robert/incubator-flink/flink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/invokable/operator/BatchReduceInvokable.java:[39,36] cannot find symbol[ERROR] symbol: variable MathUtils[ERROR] location: class org.apache.flink.streaming.api.invokable.operator.BatchReduceInvokable&lt;IN,OUT&gt;[ERROR] /home/robert/incubator-flink/flink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/invokable/operator/BatchReduceInvokable.java:[48,36] cannot find symbol[ERROR] symbol: variable MathUtils[ERROR] location: class org.apache.flink.streaming.api.invokable.operator.BatchReduceInvokable&lt;IN,OUT&gt;[ERROR] /home/robert/incubator-flink/flink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/invokable/operator/WindowReduceInvokable.java:[40,36] cannot find symbol[ERROR] symbol: variable MathUtils[ERROR] location: class org.apache.flink.streaming.api.invokable.operator.WindowReduceInvokable&lt;IN,OUT&gt;[ERROR] /home/robert/incubator-flink/flink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/invokable/operator/WindowReduceInvokable.java:[49,36] cannot find symbol[ERROR] symbol: variable MathUtils[ERROR] location: class org.apache.flink.streaming.api.invokable.operator.WindowReduceInvokable&lt;IN,OUT&gt;[ERROR] -&gt; [Help 1][ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.[ERROR] Re-run Maven using the -X switch to enable full debug logging.[ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles:[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException[ERROR] [ERROR] After correcting the problems, you can resume the build with the command[ERROR] mvn &lt;goals&gt; -rf :flink-streaming-coreI think older Hadoop versions (its working with Hadoop 2.2.0) are pulling in transitive dependencies that are not present with Hadoop 2.4.0 anymore.</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>0.7.0-incubating</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-dist.src.main.flink-bin.LICENSE</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.pom.xml</file>
      <file type="M">DEPENDENCIES</file>
    </fixedFiles>
  </bug>
  <bug id="1068" opendate="2014-8-27 00:00:00" fixdate="2014-8-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace "cdh4" profile with generic "hadoop 2.0.0-alpha" support</summary>
      <description>As per mailing list discussion, we decided to remove the vendor specific "cdh4" profile.Users compiling against "hadoop 2.0.0-alpha" can use Flink with CDH4 and other distributions relying on hadoop 2.0.0-alpha.I'm planning to include this into 0.6.1 and 0.7</description>
      <version>0.6-incubating,0.7.0-incubating</version>
      <fixedVersion>0.6.1-incubating,0.7.0-incubating</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.create.release.files.sh</file>
      <file type="M">pom.xml</file>
      <file type="M">flink-tests.pom.xml</file>
      <file type="M">flink-test-utils.pom.xml</file>
      <file type="M">flink-runtime.pom.xml</file>
      <file type="M">flink-dist.pom.xml</file>
      <file type="M">flink-addons.flink-spargel.pom.xml</file>
      <file type="M">flink-addons.flink-hadoop-compatibility.pom.xml</file>
      <file type="M">flink-addons.flink-avro.pom.xml</file>
      <file type="M">docs.building.md</file>
    </fixedFiles>
  </bug>
  <bug id="1070" opendate="2014-8-27 00:00:00" fixdate="2014-9-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change return type of "getBroadcastVariable()" from Collection to List</summary>
      <description>The type is actually a List.Collections are a very reduces interface, it is much easier to work with Lists.</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>0.7.0-incubating</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.udf.RuntimeUDFContext.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.WrappingFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.RuntimeContext.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.MapFunction.java</file>
    </fixedFiles>
  </bug>
  <bug id="1073" opendate="2014-8-27 00:00:00" fixdate="2014-9-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>SortGroup() does not sort Combiner input</summary>
      <description>Flink supports sorted input for GroupReduce operators by calling for examplemyData.groupBy(1).sortGroup(2, Order.ASCENDING).reduceGroup(new MyReducer());This code will sort the input of the function MyReducer.reduce() on the third field.However, the input of MyReducer.combine() is not sorted, which is an unexpected behavior, IMO.</description>
      <version>0.6.1-incubating,0.7.0-incubating</version>
      <fixedVersion>0.6.1-incubating,0.7.0-incubating</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.compiler.examples.WordCountCompilerTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.nephele.customdanglingpagerank.CustomCompensatableDanglingPageRankWithCombiner.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.compiler.iterations.IterativeKMeansTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.GroupReduceITCase.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.operators.GroupReduceWithCombineProperties.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.operators.PartialGroupProperties.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.plantranslate.NepheleJobGraphGenerator.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.plan.SingleInputPlanNode.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.postpass.GenericFlatTypePostPass.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.postpass.JavaApiPostPass.java</file>
      <file type="M">flink-compiler.src.test.java.org.apache.flink.compiler.GroupOrderTest.java</file>
      <file type="M">flink-compiler.src.test.java.org.apache.flink.compiler.GroupReduceCompilationTest.java</file>
      <file type="M">flink-compiler.src.test.java.org.apache.flink.compiler.ReduceCompilationTest.java</file>
      <file type="M">flink-compiler.src.test.java.org.apache.flink.compiler.WorksetIterationsJavaApiCompilerTest.java</file>
      <file type="M">flink-compiler.src.test.java.org.apache.flink.compiler.WorksetIterationsRecordApiCompilerTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.AbstractCachedBuildSideMatchDriver.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.AllGroupReduceDriver.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.AllReduceDriver.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.chaining.SynchronousChainedCombineDriver.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.CoGroupDriver.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.CoGroupWithSolutionSetFirstDriver.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.CoGroupWithSolutionSetSecondDriver.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.CollectorMapDriver.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.CrossDriver.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.DriverStrategy.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.FlatMapDriver.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.GroupReduceCombineDriver.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.GroupReduceDriver.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.JoinWithSolutionSetFirstDriver.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.JoinWithSolutionSetSecondDriver.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.MapDriver.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.MapPartitionDriver.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.MatchDriver.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.NoOpDriver.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.PactDriver.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.PactTaskContext.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.ReduceCombineDriver.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.ReduceDriver.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.RegularPactTask.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.CachedMatchTaskTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.chaining.ChainTaskTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.CoGroupTaskExternalITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.CoGroupTaskTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.CombineTaskExternalITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.CombineTaskTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.drivers.TestTaskContext.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.MatchTaskExternalITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.MatchTaskTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.ReduceTaskExternalITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.ReduceTaskTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.testutils.DriverTestBase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.compiler.examples.KMeansSingleStepTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.compiler.examples.RelationalQueryCompilerTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="10740" opendate="2018-10-31 00:00:00" fixdate="2018-1-31 01:00:00" resolution="Unresolved">
    <buginformation>
      <summary>FLIP-27: Refactor Source Interface</summary>
      <description>Please see the FLIP for any details: https://cwiki.apache.org/confluence/display/FLINK/FLIP-27%3A+Refactor+Source+Interface</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.collect.CollectSinkFunctionTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.source.coordinator.SourceCoordinatorTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.coordination.TestingOperatorCoordinator.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.coordination.MockOperatorCoordinator.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.source.coordinator.SourceCoordinator.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.scheduler.DefaultScheduler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.coordination.OperatorCoordinator.java</file>
      <file type="M">docs.dev.stream.sources.zh.md</file>
      <file type="M">docs.dev.stream.sources.md</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.SourceOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.SourceOperator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.CollectionUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="1080" opendate="2014-9-1 00:00:00" fixdate="2014-9-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add aggregations for streaming</summary>
      <description>Add support for summation, mimimum and maximum aggregations based on the reduce functionality.</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.test.java.org.apache.flink.streaming.api.invokable.operator.CoFlatMapTest.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.test.java.org.apache.flink.streaming.api.AggregationFunctionTest.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.invokable.operator.WindowGroupReduceInvokable.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.invokable.operator.BatchIterator.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.invokable.operator.BatchGroupReduceInvokable.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.function.aggregation.StreamingSumAggregationFunction.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.function.aggregation.StreamingMinAggregationFunction.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.function.aggregation.StreamingMaxAggregationFunction.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.function.aggregation.StreamingAggregationFunction.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.function.aggregation.ComparableAggregationFunction.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-examples.src.main.java.org.apache.flink.streaming.examples.wordcount.WordCountLocal.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.JobGraphBuilder.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.datastream.GroupedDataStream.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.datastream.DataStream.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.collector.StreamCollector.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-connectors.src.main.java.org.apache.flink.streaming.connectors.twitter.TwitterLocal.java</file>
    </fixedFiles>
  </bug>
  <bug id="1081" opendate="2014-9-1 00:00:00" fixdate="2014-1-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add HDFS file-stream source for streaming</summary>
      <description>Add data stream source that will monitor a slected directory on HDFS (or other filesystems as well) and will process all new files created.</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.function.source.FileStreamFunction.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.StreamExecutionEnvironment.scala</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.function.source.FileMonitoringFunction.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.fs.s3.S3DataInputStream.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.fs.hdfs.HadoopDataInputStream.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.local.LocalDataInputStream.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.FSDataInputStream.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.InflaterInputStreamFSInputWrapper.java</file>
    </fixedFiles>
  </bug>
  <bug id="1095" opendate="2014-9-9 00:00:00" fixdate="2014-11-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>./flink info -d command is not working for the examples</summary>
      <description>It seems that the info -d is not working for all of our examples and its probably not documented anywhere../flink info -d ../examples/flink-java-examples-0.6-incubating-rc1-WebLogAnalysis.jarNo description available for this program.We should consider removing the option.</description>
      <version>0.6-incubating,0.7.0-incubating</version>
      <fixedVersion>0.8.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-clients.src.test.java.org.apache.flink.client.CliFrontendInfoTest.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.CliFrontend.java</file>
    </fixedFiles>
  </bug>
  <bug id="1102" opendate="2014-9-20 00:00:00" fixdate="2014-9-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Projection operator for streaming</summary>
      <description>Enable the following code with the usual semantics:stream.project(1,2).types(String.class, Integer.class)Consider whether providing the types is necessary.</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.test.java.org.apache.flink.streaming.util.serialization.TypeSerializationTest.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.test.java.org.apache.flink.streaming.util.MockCollector.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.test.java.org.apache.flink.streaming.api.streamvertex.StreamVertexTest.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.util.serialization.TypeSerializerWrapper.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.util.serialization.ObjectTypeWrapper.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.util.serialization.FunctionTypeWrapper.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.StreamConfig.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.JobGraphBuilder.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.invokable.StreamInvokable.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.invokable.operator.BatchReduceInvokable.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.datastream.DataStreamSource.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.datastream.DataStreamSink.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.datastream.DataStream.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.datastream.ConnectedDataStream.java</file>
    </fixedFiles>
  </bug>
  <bug id="1106" opendate="2014-9-22 00:00:00" fixdate="2014-10-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Deprecate old Record API</summary>
      <description>For the upcoming 0.7 release, we should mark all user-facing methods from the old Record Java API as deprecated, with a warning that we are going to remove it at some point.I would suggest to wait one or two releases from the 0.7 release (given our current release cycle). I'll start a mailing-list discussion at some point regarding this.</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>0.7.0-incubating</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.OperatorInfoHelper.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.MapPartitionOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.MapOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.JoinOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.GenericDataSource.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.GenericDataSink.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.FileDataSource.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.FileDataSink.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.DeltaIteration.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.CrossWithSmallOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.CrossWithLargeOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.CrossOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.CollectionDataSource.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.CoGroupOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.BulkIteration.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.functions.ReduceFunction.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.functions.MapPartitionFunction.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.functions.MapFunction.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.functions.JoinFunction.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.functions.FunctionAnnotation.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.functions.CrossFunction.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.functions.CoGroupFunction.java</file>
    </fixedFiles>
  </bug>
  <bug id="1107" opendate="2014-9-22 00:00:00" fixdate="2014-2-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document how to use Avro files and the Hadoop Input Format Wrappers</summary>
      <description>The documentation lacks any examples or description on how to read from avro files. Also, we should document the Hadoop Input Formats a bit.</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs..includes.sidenav.html</file>
      <file type="M">docs.spargel.guide.md</file>
      <file type="M">docs.hadoop.compatibility.md</file>
    </fixedFiles>
  </bug>
  <bug id="1119" opendate="2014-9-23 00:00:00" fixdate="2014-9-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>StreamComponentTest fails with NoResourceAvailableException</summary>
      <description>On my machine, the current master branch (commit f329fe2b654eea078de085442d68dd1d5a9fc09a) fails to build due to two tests in error in StreamComponentTest.Both tests fail with a NoResourceAvailableException:22:08:56.779 [IPC Server handler 0 on 1624] ERROR org.apache.flink.runtime.jobmanager.JobManager - Job submission failed.org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Not enough free slots available to run the job. You can decrease the operator parallelism or increase the number of slots per TaskManager in the configuration. at org.apache.flink.runtime.jobmanager.scheduler.Scheduler.scheduleTask(Scheduler.java:201) ~[flink-runtime-0.7-incubating-SNAPSHOT.jar:0.7-incubating-SNAPSHOT] at org.apache.flink.runtime.jobmanager.scheduler.Scheduler.scheduleImmediately(Scheduler.java:116) ~[flink-runtime-0.7-incubating-SNAPSHOT.jar:0.7-incubating-SNAPSHOT] at org.apache.flink.runtime.executiongraph.Execution.scheduleForExecution(Execution.java:203) ~[flink-runtime-0.7-incubating-SNAPSHOT.jar:0.7-incubating-SNAPSHOT] at org.apache.flink.runtime.executiongraph.ExecutionVertex.scheduleForExecution(ExecutionVertex.java:326) ~[flink-runtime-0.7-incubating-SNAPSHOT.jar:0.7-incubating-SNAPSHOT] at org.apache.flink.runtime.executiongraph.ExecutionJobVertex.scheduleAll(ExecutionJobVertex.java:238) ~[flink-runtime-0.7-incubating-SNAPSHOT.jar:0.7-incubating-SNAPSHOT] at org.apache.flink.runtime.executiongraph.ExecutionGraph.scheduleForExecution(ExecutionGraph.java:293) ~[flink-runtime-0.7-incubating-SNAPSHOT.jar:0.7-incubating-SNAPSHOT] at org.apache.flink.runtime.jobmanager.JobManager.submitJob(JobManager.java:377) ~[flink-runtime-0.7-incubating-SNAPSHOT.jar:0.7-incubating-SNAPSHOT] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.7.0_67] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.7.0_67] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_67] at java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_67] at org.apache.flink.runtime.ipc.RPC$Server.call(RPC.java:418) [flink-runtime-0.7-incubating-SNAPSHOT.jar:0.7-incubating-SNAPSHOT] at org.apache.flink.runtime.ipc.Server$Handler.run(Server.java:947) [flink-runtime-0.7-incubating-SNAPSHOT.jar:0.7-incubating-SNAPSHOT]</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>0.7.0-incubating</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.minicluster.NepheleMiniCluster.java</file>
    </fixedFiles>
  </bug>
  <bug id="1121" opendate="2014-9-24 00:00:00" fixdate="2014-9-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add minBy and maxBy operators to the streaming api</summary>
      <description>The minBy and maxBy operators are missing from the streaming api, so a similar operator as in batch should be added.The operator would always return the current min/max element in the datastream so far. An optional parameter should be added to choose to return the first or last min/max value occurance.</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.test.java.org.apache.flink.streaming.api.AggregationFunctionTest.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.datastream.GroupedDataStream.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.datastream.DataStream.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.datastream.BatchedDataStream.java</file>
      <file type="M">docs.streaming.guide.md</file>
    </fixedFiles>
  </bug>
  <bug id="1123" opendate="2014-9-24 00:00:00" fixdate="2014-9-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add First-N operator to Scala API</summary>
      <description>The first&amp;#40;n&amp;#41; operator is only supported by the Java API (see FLINK-970).This functionality needs to be ported to the ScalaAPI as well. Right now, the corresponding methods are excluded from the ScalaAPICompletenessTest.</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>0.7.0-incubating</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.GroupedDataSet.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.DataSet.scala</file>
    </fixedFiles>
  </bug>
  <bug id="1133" opendate="2014-10-1 00:00:00" fixdate="2014-10-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Type extractor cannot determine type of function</summary>
      <description>This function fails in the type extractor.public static final class DuplicateValue&lt;T&gt; implements MapFunction&lt;Tuple1&lt;T&gt;, Tuple2&lt;T, T&gt;&gt; { @Override public Tuple2&lt;T, T&gt; map(Tuple1&lt;T&gt; vertex) { return new Tuple2&lt;T, T&gt;(vertex.f0, vertex.f0); }}</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>0.7.0-incubating</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.type.extractor.TypeExtractorTest.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.typeutils.TypeExtractor.java</file>
    </fixedFiles>
  </bug>
  <bug id="1142" opendate="2014-10-8 00:00:00" fixdate="2014-11-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Log IOManager temp path directories</summary>
      <description></description>
      <version>0.6.1-incubating,0.7.0-incubating</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskmanager.TaskManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="11461" opendate="2019-1-30 00:00:00" fixdate="2019-1-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove unused MockRecordWriter</summary>
      <description>The MockRecordWriter is not used in current code path, so delete it directly.</description>
      <version>None</version>
      <fixedVersion>1.8.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.sort.MockRecordReader.java</file>
    </fixedFiles>
  </bug>
  <bug id="11463" opendate="2019-1-30 00:00:00" fixdate="2019-1-30 01:00:00" resolution="Unresolved">
    <buginformation>
      <summary>Rework end-to-end tests in Java</summary>
      <description>This is the (long-term) umbrella issue for reworking our end-to-tests in Java on top of a new set of utilities.Below are some areas where problems have been identified that I want to address with a prototype soon. This prototype primarily aims to introduce certain patterns to be built upon in the future.EnvironmentsProblemOur current tests directly work against flink-dist and setup local clusters with/-out HA. Similar issues apply to Kafka and ElasticSearch.This prevents us from re-using tests for other environments (Yarn, Docker) and distributed settings.We also frequently have issues with cleaning up resources as it is the responsibility of the test itself.ProposalIntroduce a common interface for a given resource type (i.e. Flink, Kafka) that tests will work against.These resources should be implemented as jUnit external resources to allow reasonable life-cycle management.Tests get access to an instance of this resource through a factory method.Each resource implementation has a dedicated factory that is loaded with a ServiceLoader. Factories evaluate system-properties to determine whether the implementation should be loaded, and then optionally configure the resource.Example:public interface FlinkResource { ... common methods .../** * Returns the configured FlinkResource implementation, or a {@link LocalStandaloneFlinkResource} if none is configured. * * @return configured FlinkResource, or {@link LocalStandaloneFlinkResource} is none is configured */ FlinkResource get() { // load factories // evaluate system properties // return instance }}public interface FlinkResourceFactory { /** * Returns a {@link FlinkResource} instance. If the instance could not be instantiated (for example, because a * mandatory parameter was missing), then an empty {@link Optional} should be returned. * * @return FlinkResource instance, or an empty Optional if the instance could not be instantiated */ Optional&lt;FlinkResource&gt; create();}As example, running mvn verify -De2e.flink.mode=localStandalone could load a FlinkResource that sets up a local standalone cluster, while for mvn verify -De2e.flink.mode=distributedStandalone -De2e.flink.hosts=... it would connect to the given host and setup a distributed cluster.Tests are not required to work against the common interface, and may be hard-wired to run against specific implementations. Simply put, the resource implementations should be public.Future considerationsThe factory method may be extended to allow tests to specify a set of conditions that must be fulfilled, for example HA to be enabled. If this requirement cannot be fulfilled the test should be skipped.Split ManagementProblemEnd-to-end tests are run in separate cron-&lt;version&gt;-e2e branches. To accommodate the Travis time limits we run a total of 6 jobs each covering a subset of the tests.These so-called splits are currently managed in the respective branches, and not on master/release branches.This is a rather hidden detail that not everyone is aware of, nor is it easily discoverable. This has resulted several times in newly added tests not actually being run. Furthermore, if the arguments for tests are modified these changes have to be replicated to each branch.ProposalUse jUnit Categories to assign each test explicitly to one of the Travis jobs.@Category(TravisGroup1.class)public class MyTestRunningInTheFirstJob { ...}It's a bit on the nose but a rather simple solution.A given group of tests could be executed by running mvn verify -Dcategories="org.apache.flink.tests.util.TravisGroup1".All tests can be executed by running mvn verify -Dcategories=""org.apache.flink.tests.util.TravisGroup1""Future considerationsTests may furthermore be categorized based on what they are testing (e.g. "Metrics", "Checkpointing", "Kafka") to allow running a certain subset of tests quickly.Caching of downloaded artifactsProblemSeveral tests download archives for setting up systems, like Kafka of Elasticsearch. We currently do not cache downloads in any way, resulting in less stable tests (as mirrors aren't always available) and overall increased test duration (since the downloads at times are quite slow). The duration issue becomes especially apparent when running tests in a loop for debugging or release-testing purposes.Finally, it also puts unnecessary strain on the download mirrors.ProposalAdd a DownloadCache interface with a single Path getOrDownload(String url, Path targetDir) method.Access to and loading of implementations are handled like resources (see above).The caching behavior is implementation-dependent.A reasonable implementation should allow files may be cached in a user-provided directory, with an optional time-to-live for long-term setups.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-end-to-end-tests.flink-end-to-end-tests-common.src.main.java.org.apache.flink.tests.util.AutoClosableProcess.java</file>
      <file type="M">flink-end-to-end-tests.flink-end-to-end-tests-common.src.main.java.org.apache.flink.tests.util.FlinkDistribution.java</file>
    </fixedFiles>
  </bug>
  <bug id="11466" opendate="2019-1-30 00:00:00" fixdate="2019-11-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement LocalStandaloneKafkaResource</summary>
      <description>Implement a common KafkaResource interface for interacting with Kafka across various environments, and provide a LocalStandaloneKafkaResource implementation that downloads kafka sets up a local standalone cluster with the bundled zookeeper.Effectively this is JIRA is about porting the logic in kafka-common.sh to Java.</description>
      <version>None</version>
      <fixedVersion>1.10.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-end-to-end-tests.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11467" opendate="2019-1-30 00:00:00" fixdate="2019-11-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Port Kafka Streaming end-to-end test</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.10.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-end-to-end-tests.test-scripts.test.streaming.kafka.common.sh</file>
      <file type="M">flink-end-to-end-tests.test-scripts.test.streaming.kafka011.sh</file>
      <file type="M">flink-end-to-end-tests.test-scripts.test.streaming.kafka010.sh</file>
      <file type="M">flink-end-to-end-tests.test-scripts.test.streaming.kafka.sh</file>
      <file type="M">flink-end-to-end-tests.run-pre-commit-tests.sh</file>
      <file type="M">flink-end-to-end-tests.flink-streaming-kafka011-test.pom.xml</file>
      <file type="M">flink-end-to-end-tests.flink-streaming-kafka010-test.pom.xml</file>
      <file type="M">flink-end-to-end-tests.flink-streaming-kafka-test.pom.xml</file>
      <file type="M">flink-end-to-end-tests.flink-end-to-end-tests-common-kafka.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11468" opendate="2019-1-30 00:00:00" fixdate="2019-11-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Setup jUnit categories</summary>
      <description>ProblemEnd-to-end tests are run in separate cron-&lt;version&gt;-e2e branches. To accomodate the Travis time limits we run a total of 6 jobs each covering a subset of the tests.These so-called splits are currently managed in the respective branches, and not on master/release branches.This is a rather hidden detail that not everyone is aware of, nor is it easily discoverable. This has resulted several times in newly added tests not actually being run. Furthermore, if the arguments for tests are modified these changes have to be replicated to each branch.ProposalUse jUnit Categories to assign each test explicitly to one of the Travis jobs.@Category(TravisGroup1.class)public class MyTestRunningInTheFirstJob { ...}It's a bit on the nose but a rather simple solution.A given group of tests could be executed by running mvn verify -Dcategories="org.apache.flink.tests.util.TravisGroup1".All tests can be executed by running mvn verify -Dcategories=""org.apache.flink.tests.util.TravisGroup1""Future considerationsTests may furthermore be categorized based on what they are testing (e.g. "Metrics", "Checkpointing", "Kafka") to allow running a certain subset of tests quickly.</description>
      <version>None</version>
      <fixedVersion>1.10.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.travis.watchdog.sh</file>
      <file type="M">flink-end-to-end-tests.run-nightly-tests.sh</file>
      <file type="M">flink-end-to-end-tests.pom.xml</file>
      <file type="M">flink-end-to-end-tests.flink-metrics-reporter-prometheus-test.src.test.java.org.apache.flink.metrics.prometheus.tests.PrometheusReporterEndToEndITCase.java</file>
      <file type="M">flink-end-to-end-tests.flink-metrics-reporter-prometheus-test.pom.xml</file>
      <file type="M">flink-end-to-end-tests.flink-metrics-availability-test.src.test.java.org.pache.flink.metrics.tests.MetricsAvailabilityITCase.java</file>
      <file type="M">flink-end-to-end-tests.flink-metrics-availability-test.pom.xml</file>
      <file type="M">.travis.yml</file>
    </fixedFiles>
  </bug>
  <bug id="1147" opendate="2014-10-9 00:00:00" fixdate="2014-1-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TypeInference on POJOs</summary>
      <description>On Tuples, we currently use type inference that figures out the types of output type variables relative to the input type variable.We need a similar functionality for POJOs.</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>0.9</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.type.extractor.TypeExtractorTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.type.extractor.PojoTypeExtractionTest.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.typeutils.TypeInfoParser.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.typeutils.TypeExtractor.java</file>
    </fixedFiles>
  </bug>
  <bug id="1148" opendate="2014-10-9 00:00:00" fixdate="2014-10-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create a writeAsCsv(path, writemode) variant</summary>
      <description>For convenience</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>0.7.0-incubating</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.DataSet.java</file>
    </fixedFiles>
  </bug>
  <bug id="11480" opendate="2019-1-31 00:00:00" fixdate="2019-6-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create HiveTableFactory that creates TableSource/Sink from a Hive table</summary>
      <description>This may requires some design thoughts because HiveTableFactory is different from existing TableFactory implementations.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.catalog.DatabaseCalciteSchema.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.factories.TableSourceFactory.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.factories.TableSinkFactory.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.catalog.Catalog.java</file>
      <file type="M">flink-table.flink-table-api-java.src.test.java.org.apache.flink.table.catalog.AbstractCatalogTableTest.java</file>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.factories.TableFactoryUtil.java</file>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.catalog.AbstractCatalogTable.java</file>
      <file type="M">flink-python.pyflink.table.catalog.py</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.catalog.hive.HiveCatalog.java</file>
      <file type="M">flink-connectors.flink-connector-hive.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1149" opendate="2014-10-9 00:00:00" fixdate="2014-10-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Operators cannot adapt DOP for NonParallelInputs</summary>
      <description>InputFormats that cannot be processed in parallel implement the NonParallelInput interface.During optimization, the optimizer checks for this interface and sets the DOP of an operator to 1 if it is found. Other operators such as Mappers set their DOP during program construction to the DOP of their preceding task (if not specified otherwise). Since non-splittable data sources are only considered later by the optimizer, a Map operator will not have the same DOP as an preceding non-splittable data source.The simple solution is to set the DOP of a non-splittable data source during program construction.</description>
      <version>0.6.1-incubating,0.7.0-incubating</version>
      <fixedVersion>0.7.0-incubating</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.DataSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="11491" opendate="2019-1-31 00:00:00" fixdate="2019-11-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support all TPC-DS queries</summary>
      <description>A more detailed description can be found in FLIP-32.This issue describes the goal of supporting all TPC-DS queries on a unified runtime for batch and streaming.Operations might not be executed with the full performance until changes in other Flink core components have taken place.This includes external catalog support and Hive integration.</description>
      <version>None</version>
      <fixedVersion>1.10.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-end-to-end-tests.run-nightly-tests.sh</file>
      <file type="M">flink-end-to-end-tests.pom.xml</file>
      <file type="M">.travis.yml</file>
    </fixedFiles>
  </bug>
  <bug id="11495" opendate="2019-1-31 00:00:00" fixdate="2019-2-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove legacy job archiving paths</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.8.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.scala.org.apache.flink.runtime.jobmanager.MemoryArchivist.scala</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.webmonitor.history.JsonArchivist.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.history.FsJobArchivist.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.history.FsJobArchivistTest.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.history.HistoryServerArchiveFetcher.java</file>
    </fixedFiles>
  </bug>
  <bug id="1167" opendate="2014-10-15 00:00:00" fixdate="2014-10-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CompilerException caused by NullPointerException</summary>
      <description>Run into it during working on my code. Seems not caused by my plan, or anyway the compiler should have a NullPointer isssue:org.apache.flink.compiler.CompilerException: An error occurred while translating the optimized plan to a nephele JobGraph: Error translating node 'Union "Union" : UNION [[ GlobalProperties [partitioning=HASH_PARTITIONED, on fields &amp;#91;0&amp;#93;] ]] [[ LocalProperties &amp;#91;ordering=null, grouped=null, unique=null&amp;#93; ]]': null at org.apache.flink.compiler.plantranslate.NepheleJobGraphGenerator.postVisit(NepheleJobGraphGenerator.java:543) at org.apache.flink.compiler.plantranslate.NepheleJobGraphGenerator.postVisit(NepheleJobGraphGenerator.java:95) at org.apache.flink.compiler.plan.DualInputPlanNode.accept(DualInputPlanNode.java:170) at org.apache.flink.compiler.plan.SingleInputPlanNode.accept(SingleInputPlanNode.java:196) at org.apache.flink.compiler.plan.SingleInputPlanNode.accept(SingleInputPlanNode.java:196) at org.apache.flink.compiler.plan.OptimizedPlan.accept(OptimizedPlan.java:165) at org.apache.flink.compiler.plantranslate.NepheleJobGraphGenerator.compileJobGraph(NepheleJobGraphGenerator.java:163) at org.apache.flink.client.program.Client.getJobGraph(Client.java:218) at org.apache.flink.client.program.Client.run(Client.java:290) at org.apache.flink.client.program.Client.run(Client.java:285) at org.apache.flink.client.program.Client.run(Client.java:230) at org.apache.flink.client.CliFrontend.executeProgram(CliFrontend.java:347) at org.apache.flink.client.CliFrontend.run(CliFrontend.java:334) at org.apache.flink.client.CliFrontend.parseParameters(CliFrontend.java:1001) at org.apache.flink.client.CliFrontend.main(CliFrontend.java:1025)Caused by: org.apache.flink.compiler.CompilerException: Error translating node 'Union "Union" : UNION [[ GlobalProperties [partitioning=HASH_PARTITIONED, on fields &amp;#91;0&amp;#93;] ]] [[ LocalProperties &amp;#91;ordering=null, grouped=null, unique=null&amp;#93; ]]': null at org.apache.flink.compiler.plantranslate.NepheleJobGraphGenerator.preVisit(NepheleJobGraphGenerator.java:338) at org.apache.flink.compiler.plantranslate.NepheleJobGraphGenerator.preVisit(NepheleJobGraphGenerator.java:95) at org.apache.flink.compiler.plan.DualInputPlanNode.accept(DualInputPlanNode.java:162) at org.apache.flink.compiler.plan.WorksetIterationPlanNode.acceptForStepFunction(WorksetIterationPlanNode.java:196) at org.apache.flink.compiler.plantranslate.NepheleJobGraphGenerator.postVisit(NepheleJobGraphGenerator.java:398) ... 14 moreCaused by: java.lang.NullPointerException at org.apache.flink.runtime.operators.util.TaskConfig.setDriver(TaskConfig.java:307) at org.apache.flink.compiler.plantranslate.NepheleJobGraphGenerator.createDualInputVertex(NepheleJobGraphGenerator.java:793) at org.apache.flink.compiler.plantranslate.NepheleJobGraphGenerator.preVisit(NepheleJobGraphGenerator.java:286) ... 18 more</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>0.7.0-incubating</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-compiler.src.test.java.org.apache.flink.compiler.java.IterationCompilerTest.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.plandump.PlanJSONDumpGenerator.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.dag.WorksetIterationNode.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.dag.BulkIterationNode.java</file>
    </fixedFiles>
  </bug>
  <bug id="1168" opendate="2014-10-16 00:00:00" fixdate="2014-1-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support multi-character field delimiters in CSVInputFormats</summary>
      <description>The CSVInputFormat supports multi-char (String) line delimiters, but only single-char (char) field delimiters.This issue proposes to add support for multi-char field delimiters.</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-examples.flink-scala-examples.src.main.scala.org.apache.flink.examples.scala.graph.EnumTrianglesOpt.scala</file>
      <file type="M">flink-tests.src.test.scala.org.apache.flink.api.scala.io.CsvInputFormatTest.scala</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.util.testjar.KMeansForTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.ConnectedComponentsWithObjectMapITCase.java</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.ExecutionEnvironment.scala</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.record.io.CsvInputFormatTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.io.CsvInputFormatTest.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.io.CsvInputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.PrimitiveInputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.CsvReader.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.CsvInputFormat.java</file>
      <file type="M">flink-java8.src.main.java.org.apache.flink.examples.java8.relational.TPCHQuery10.java</file>
      <file type="M">flink-examples.flink-scala-examples.src.main.scala.org.apache.flink.examples.scala.relational.WebLogAnalysis.scala</file>
      <file type="M">flink-examples.flink-scala-examples.src.main.scala.org.apache.flink.examples.scala.relational.TPCHQuery3.scala</file>
      <file type="M">flink-examples.flink-scala-examples.src.main.scala.org.apache.flink.examples.scala.relational.TPCHQuery10.scala</file>
      <file type="M">flink-examples.flink-scala-examples.src.main.scala.org.apache.flink.examples.scala.ml.LinearRegression.scala</file>
      <file type="M">flink-examples.flink-scala-examples.src.main.scala.org.apache.flink.examples.scala.graph.TransitiveClosureNaive.scala</file>
      <file type="M">flink-examples.flink-scala-examples.src.main.scala.org.apache.flink.examples.scala.graph.PageRankBasic.scala</file>
      <file type="M">flink-addons.flink-avro.src.test.java.org.apache.flink.api.avro.AvroOutputFormatTest.java</file>
      <file type="M">flink-clients.src.test.java.org.apache.flink.client.program.ExecutionPlanCreationTest.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.DelimitedInputFormat.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.GenericCsvInputFormat.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.ByteParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.ByteValueParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.DoubleParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.DoubleValueParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.FieldParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.FloatParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.FloatValueParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.IntParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.IntValueParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.LongParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.LongValueParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.ShortParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.ShortValueParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.StringParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.StringValueParser.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.io.GenericCsvInputFormatTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.types.parser.ByteParserTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.types.parser.ByteValueParserTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.types.parser.DoubleParserTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.types.parser.DoubleValueParserTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.types.parser.FloatParserTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.types.parser.FloatValueParserTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.types.parser.IntParserTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.types.parser.IntValueParserTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.types.parser.LongParserTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.types.parser.LongValueParserTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.types.parser.ParserTestBase.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.types.parser.ShortParserTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.types.parser.ShortValueParserTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.types.parser.StringParserTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.types.parser.StringValueParserTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.types.parser.VarLengthStringParserTest.java</file>
      <file type="M">flink-examples.flink-java-examples.src.main.java.org.apache.flink.examples.java.clustering.KMeans.java</file>
      <file type="M">flink-examples.flink-java-examples.src.main.java.org.apache.flink.examples.java.graph.ConnectedComponents.java</file>
      <file type="M">flink-examples.flink-java-examples.src.main.java.org.apache.flink.examples.java.graph.EnumTrianglesBasic.java</file>
      <file type="M">flink-examples.flink-java-examples.src.main.java.org.apache.flink.examples.java.graph.EnumTrianglesOpt.java</file>
      <file type="M">flink-examples.flink-java-examples.src.main.java.org.apache.flink.examples.java.graph.PageRankBasic.java</file>
      <file type="M">flink-examples.flink-java-examples.src.main.java.org.apache.flink.examples.java.graph.TransitiveClosureNaive.java</file>
      <file type="M">flink-examples.flink-java-examples.src.main.java.org.apache.flink.examples.java.ml.LinearRegression.java</file>
      <file type="M">flink-examples.flink-java-examples.src.main.java.org.apache.flink.examples.java.relational.EmptyFieldsCountAccumulator.java</file>
      <file type="M">flink-examples.flink-java-examples.src.main.java.org.apache.flink.examples.java.relational.TPCHQuery10.java</file>
      <file type="M">flink-examples.flink-java-examples.src.main.java.org.apache.flink.examples.java.relational.TPCHQuery3.java</file>
      <file type="M">flink-examples.flink-java-examples.src.main.java.org.apache.flink.examples.java.relational.WebLogAnalysis.java</file>
      <file type="M">flink-examples.flink-scala-examples.src.main.scala.org.apache.flink.examples.scala.clustering.KMeans.scala</file>
      <file type="M">flink-examples.flink-scala-examples.src.main.scala.org.apache.flink.examples.scala.graph.ConnectedComponents.scala</file>
      <file type="M">flink-examples.flink-scala-examples.src.main.scala.org.apache.flink.examples.scala.graph.EnumTrianglesBasic.scala</file>
    </fixedFiles>
  </bug>
  <bug id="1169" opendate="2014-10-16 00:00:00" fixdate="2014-1-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Join Hint Specification in .join() Function is not Documented</summary>
      <description></description>
      <version>0.7.0-incubating</version>
      <fixedVersion>0.9</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.JoinOperatorBase.java</file>
      <file type="M">docs.programming.guide.md</file>
      <file type="M">docs.dataset.transformations.md</file>
    </fixedFiles>
  </bug>
  <bug id="11802" opendate="2019-3-4 00:00:00" fixdate="2019-3-4 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Create TypeInfo and TypeSerializer for blink data format</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.util.SegmentsUtil.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.dataformat.TypeGetterSetters.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.dataformat.BinaryWriter.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.dataformat.BinaryString.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.dataformat.BinaryRow.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.dataformat.BinaryMap.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.dataformat.BinaryArray.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.pom.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.java.org.apache.flink.table.type.InternalTypeTest.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.TypeConverters.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.TimeType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.TimestampType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.StringType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.ShortType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.RowType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.PrimitiveType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.MapType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.LongType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.IntType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.InternalTypes.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.InternalType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.GenericType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.FloatType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.DoubleType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.DecimalType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.DateType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.CharType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.ByteType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.BooleanType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.AtomicType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.ArrayType.java</file>
    </fixedFiles>
  </bug>
  <bug id="1186" opendate="2014-10-27 00:00:00" fixdate="2014-11-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Join key selection for nested Tuples is broken</summary>
      <description>When using strings to select join keys of nested tuples (e.g. "f0.f1") an incorrect join key is chosen and the operator produces an erroneous result.The join works fine when using KeySelectors.I will attach a program to reproduce the bug.</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>0.8.0,0.7.1-incubating</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.JoinITCase.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.typeutils.TupleTypeInfoBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="1194" opendate="2014-10-27 00:00:00" fixdate="2014-10-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Wrong manifest entries and compiler configuration in Java Quickstarts</summary>
      <description>The quickstart archetype for java: sets wrong main class attribute in jar sets wrong main class attribute in fat jar is unnecessarily compilcated to enable for java 8 unnecessarily requires an extra m2e connector in eclipsePull request is pending</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>0.8.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-quickstart.flink-quickstart-java.src.main.resources.archetype-resources.pom.xml</file>
      <file type="M">flink-java8.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1209" opendate="2014-11-4 00:00:00" fixdate="2014-11-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Forgetting to close an iteration leads to a confusing error message</summary>
      <description>The rror message you get is "Unknown operator - SolutionSetPlaceholder / WorksetPlaceholder / PartialSolutionPlaceholder"</description>
      <version>0.7.0-incubating,0.8.0</version>
      <fixedVersion>0.8.0,0.7.1-incubating</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.OperatorTranslation.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.IterativeDataSet.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.PactCompiler.java</file>
    </fixedFiles>
  </bug>
  <bug id="1210" opendate="2014-11-4 00:00:00" fixdate="2014-11-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve Error Message in Delta Iteratione when Next Workset does not Depend on Workset.</summary>
      <description>Currently, the job fails with a NullPointerException in the NepheleJobGraphGenerator</description>
      <version>0.7.0-incubating,0.8.0</version>
      <fixedVersion>0.8.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.PactCompiler.java</file>
    </fixedFiles>
  </bug>
  <bug id="12100" opendate="2019-4-3 00:00:00" fixdate="2019-4-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Kafka 0.10/0.11 tests fail on Java 9</summary>
      <description>java.lang.NoClassDefFoundError: javax/xml/bind/DatatypeConverter at kafka.utils.CoreUtils$.urlSafeBase64EncodeNoPadding(CoreUtils.scala:294) at kafka.utils.CoreUtils$.generateUuidAsBase64(CoreUtils.scala:282) at kafka.server.KafkaServer$$anonfun$getOrGenerateClusterId$1.apply(KafkaServer.scala:335) at kafka.server.KafkaServer$$anonfun$getOrGenerateClusterId$1.apply(KafkaServer.scala:335) at scala.Option.getOrElse(Option.scala:121) at kafka.server.KafkaServer.getOrGenerateClusterId(KafkaServer.scala:335) at kafka.server.KafkaServer.startup(KafkaServer.scala:190) at org.apache.flink.streaming.connectors.kafka.KafkaTestEnvironmentImpl.getKafkaServer(KafkaTestEnvironmentImpl.java:430) at org.apache.flink.streaming.connectors.kafka.KafkaTestEnvironmentImpl.prepare(KafkaTestEnvironmentImpl.java:256) at org.apache.flink.streaming.connectors.kafka.KafkaTestBase.startClusters(KafkaTestBase.java:137) at org.apache.flink.streaming.connectors.kafka.KafkaTestBase.prepare(KafkaTestBase.java:100) at org.apache.flink.streaming.connectors.kafka.KafkaTestBase.prepare(KafkaTestBase.java:92) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:564) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24) at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48) at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48) at org.junit.rules.RunRules.evaluate(RunRules.java:20) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365) at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159) at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345) at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)Caused by: java.lang.ClassNotFoundException: javax.xml.bind.DatatypeConverter at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:582) at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:185) at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:496) ... 33 more</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-kafka-0.11.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="12481" opendate="2019-5-10 00:00:00" fixdate="2019-9-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make processing time timer trigger run via the mailbox</summary>
      <description>This sub-task integrates the mailbox with processing time timer triggering. Those triggers should now be enqueued as mailbox events and picked up by the stream task's main thread for processing.</description>
      <version>None</version>
      <fixedVersion>1.10.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-scala.src.test.scala.org.apache.flink.streaming.api.scala.AsyncDataStreamITCase.scala</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.async.AsyncWaitOperatorTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskmanager.DispatcherThreadFactory.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.SystemProcessingTimeServiceTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamMockEnvironment.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.TestProcessingTimeServiceTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.StreamTaskTimerTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.SystemProcessingTimeService.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTask.java</file>
      <file type="M">flink-state-backends.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBAsyncSnapshotTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="12482" opendate="2019-5-10 00:00:00" fixdate="2019-9-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make checkpoint trigger/notifyComplete run via the mailbox queue</summary>
      <description>For the stream source, we also need to enqueue checkpoint related signals (trigger, notifyComplete) to the mailbox now so that they run in the stream task's main-thread.</description>
      <version>None</version>
      <fixedVersion>1.10.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.state.StatefulOperatorChainedTaskTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.runtime.jobmaster.JobMasterTriggerSavepointITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.runtime.jobmaster.JobMasterStopWithSavepointIT.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.SynchronousCheckpointTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.SynchronousCheckpointITCase.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskCancellationBarrierTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.SourceTaskTerminationTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.SourceStreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.SourceExternalCheckpointTriggerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.RestoreStreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.OneInputStreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.io.CheckpointSequenceValidator.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.io.CheckpointBarrierAlignerTestBase.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.async.AsyncWaitOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.AbstractUdfStreamOperatorLifecycleTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.SourceStreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.mailbox.execution.MailboxExecutor.java</file>
      <file type="M">flink-state-backends.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBAsyncSnapshotTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobgraph.tasks.AbstractInvokable.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskmanager.TaskAsyncCallTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskmanager.Task.java</file>
    </fixedFiles>
  </bug>
  <bug id="12483" opendate="2019-5-10 00:00:00" fixdate="2019-5-10 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Support (legacy) SourceFunctions with mailbox</summary>
      <description>We need to modify the current source stream task to run sources in a separate thread that is mutually exclusive to the mailbox mode thread. See section 4 in https://docs.google.com/document/d/1eDpsUKv2FqwZiS1Pm6gYO5eFHScBHfULKmH1-ZEWB4g</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.SourceStreamTask.java</file>
    </fixedFiles>
  </bug>
  <bug id="12484" opendate="2019-5-10 00:00:00" fixdate="2019-2-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Drop unnecessary locking for code-paths that now use the mailbox</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.11.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.mailbox.MailboxExecutorImplTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.mailbox.MailboxExecutorImpl.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.mailbox.Mail.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.MockStreamTask.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.AbstractStreamOperatorTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.StreamSourceOperatorWatermarksTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.SourceStreamTask.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.StreamTaskTimerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.async.AsyncWaitOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.TwoInputStreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamIterationHead.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.SourceReaderStreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.StreamTwoInputProcessor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.AbstractDataOutput.java</file>
    </fixedFiles>
  </bug>
  <bug id="1255" opendate="2014-11-19 00:00:00" fixdate="2014-2-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Problems with generic types in Scala API</summary>
      <description>the code below produces the following exception:Error:(47, 18) could not find implicit value for evidence parameter of type org.apache.flink.api.common.typeinfo.TypeInformation[K] data.groupBy { extractKey }Fixing K to Long made the code run though def groupCount[T, K](data: DataSet[T], extractKey: (T) =&gt; K): DataSet[(K, Long)] = { data.groupBy { extractKey } .reduceGroup { group =&gt; countBy(extractKey, group) } } private[this] def countBy[T, K](extractKey: T =&gt; K, group: Iterator[T]): (K, Long) = { val key = extractKey(group.next()) var count = 1L while (group.hasNext) { group.next() count += 1 } key -&gt; count }</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>0.9</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.faq.md</file>
    </fixedFiles>
  </bug>
  <bug id="12600" opendate="2019-5-23 00:00:00" fixdate="2019-5-23 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Introduce planner rules to do deterministic rewriting on RelNode</summary>
      <description>This issue aims to introduce planner rules to to do deterministic rewriting on RelNode , rules include:1. FlinkLimit0RemoveRule that rewrites `limit 0` to empty Values2. FlinkRewriteSubQueryRule that rewrites a Filter with condition: `(select count from T) &gt; 0` to a Filter with condition: `exists(select * from T)` which could be converted to SEMI Join by FlinkSubQueryRemoveRule3. ReplaceIntersectWithSemiJoinRule that rewrites distinct Intersect to a distinct Aggregate on a SEMI Join.4. ReplaceMinusWithAntiJoinRule that rewrites distinct Minus to a distinct Aggregate on an ANTI Join.</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.runtime.utils.TestSinkUtil.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.runtime.utils.StreamTestSink.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.util.pojos.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.stream.sql.SubplanReuseTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.stream.sql.SortLimitTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.stream.sql.LimitTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.batch.sql.SubplanReuseTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.batch.sql.SortLimitTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.batch.sql.LimitTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.plan.stream.sql.SubplanReuseTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.plan.stream.sql.SortLimitTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.plan.stream.sql.LimitTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.plan.batch.sql.SubplanReuseTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.plan.batch.sql.SortLimitTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.plan.batch.sql.LimitTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.rules.logical.FlinkCalcMergeRule.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.rules.FlinkStreamRuleSets.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.rules.FlinkBatchRuleSets.scala</file>
    </fixedFiles>
  </bug>
  <bug id="1265" opendate="2014-11-20 00:00:00" fixdate="2014-11-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>configure() not called with usercode classloader as context classloader</summary>
      <description>The configure() method of user functions is called with the system classloader as context classloader.Since, configure() is usercode, context classloader must be the usercode classloader to have acccess usercode classes.</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>0.7.1-incubating</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.execution.RuntimeEnvironment.java</file>
    </fixedFiles>
  </bug>
  <bug id="12690" opendate="2019-5-31 00:00:00" fixdate="2019-6-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Introduce Table API Planner interface</summary>
      <description>The planner interface is the bridge between base API and different planner modules.</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.operations.Operation.java</file>
    </fixedFiles>
  </bug>
  <bug id="12697" opendate="2019-5-31 00:00:00" fixdate="2019-11-31 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Support on-disk state storage for spill-able heap backend</summary>
      <description>We need to store state on disk after spilling, and to support this, we need:1. A data structure to efficiently support copy-on-write for asynchronous snapshot2. An allocator to allocate and manage chunks from the memory mapped file(s)</description>
      <version>None</version>
      <fixedVersion>1.10.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-state-backends.flink-statebackend-heap-spillable.src.main.java.org.apache.flink.runtime.state.heap.SkipListKeySerializer.java</file>
      <file type="M">flink-state-backends.flink-statebackend-heap-spillable.src.main.java.org.apache.flink.runtime.state.heap.CopyOnWriteSkipListStateMap.java</file>
      <file type="M">flink-state-backends.flink-statebackend-heap-spillable.pom.xml</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.core.memory.MemorySegmentTestBase.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.core.memory.ByteArrayInputStreamWithPosTest.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.MemorySegment.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.ByteArrayInputStreamWithPos.java</file>
    </fixedFiles>
  </bug>
  <bug id="12891" opendate="2019-6-18 00:00:00" fixdate="2019-6-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>remove hadoop/hive writable from boundaries of Hive functions and Flink</summary>
      <description>if we don't need such conversion, we should remove writable related code</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.functions.hive.conversion.HiveInspectors.java</file>
    </fixedFiles>
  </bug>
  <bug id="12892" opendate="2019-6-18 00:00:00" fixdate="2019-6-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>serialize catalog table to properties for table discovery service</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.descriptors.DescriptorProperties.java</file>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.catalog.GenericCatalogTable.java</file>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.catalog.AbstractCatalogTable.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.catalog.hive.HiveTableConfig.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.catalog.hive.HiveCatalogTable.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.catalog.hive.HiveCatalog.java</file>
    </fixedFiles>
  </bug>
  <bug id="13060" opendate="2019-7-2 00:00:00" fixdate="2019-7-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>FailoverStrategies should respect restart constraints</summary>
      <description>RestartStrategies can define their own restrictions for whether job can be restarted or not. For example, they could count the number of total failures or observe failure rates.FailoverStrategies are used for partial restarts of jobs, and currently largely bypass the restrictions defined by the restart strategies.My proposal is the following:Introduce a new method into the RestartStrategy interface to notify the strategy of failed task executions. Currently, strategies implicitly handle this in RestartStrategy#restart, as such the migration of our existing strategies should be trivial.Next, before calling RestartStrategy#restart, inform the strategy about the task failure. This retains existing behavior.Additionally, the FailoverStrategy implementation may additionally inform the restart strategy about task failures, if and when they perform a local failover. Additionally, all implementation have to check RestartStrategy#canRestart before attempting a failover.</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.executiongraph.AdaptedRestartPipelinedRegionStrategyNGFailoverTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.executiongraph.AdaptedRestartPipelinedRegionStrategyNGConcurrentFailoverTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.failover.AdaptedRestartPipelinedRegionStrategyNG.java</file>
    </fixedFiles>
  </bug>
  <bug id="1328" opendate="2014-12-15 00:00:00" fixdate="2014-1-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Rework Constant Field Annotations</summary>
      <description>Constant field annotations are used by the optimizer to determine whether physical data properties such as sorting or partitioning are retained by user defined functions.The current implementation is limited and can be extended in several ways: Fields that are copied to other positions Field definitions for non-tuple data types (Pojos)There is a pull request (#83) that goes into this direction and which can be extended.</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-examples.flink-java-examples.src.main.java.org.apache.flink.examples.java.ml.LinearRegression.java</file>
      <file type="M">flink-tests.src.test.scala.org.apache.flink.api.scala.types.TypeInformationGenTest.scala</file>
      <file type="M">flink-tests.src.test.scala.org.apache.flink.api.scala.functions.SemanticPropertiesTranslationTest.scala</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.CoGroupConnectedComponentsSecondITCase.java</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.CaseClassTypeInfo.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.DataSet.scala</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.type.extractor.TypeExtractorTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.type.extractor.PojoTypeExtractionTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.typeutils.runtime.PojoSerializerTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.record.ReduceWrappingFunctionTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.record.CoGroupWrappingFunctionTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.operators.KeysTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.functions.SemanticPropUtilTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.functions.SemanticPropertiesTranslationTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.functions.SemanticPropertiesProjectionTest.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.typeutils.TupleTypeInfoBase.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.typeutils.PojoTypeInfo.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.TwoInputUdfOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.PlanFilterOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.KeyRemovingMapper.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.KeyExtractingMapper.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.SingleInputUdfOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.ProjectOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.Keys.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.JoinOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.DistinctOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.CrossOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.functions.SemanticPropUtil.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.functions.FunctionAnnotation.java</file>
      <file type="M">flink-examples.flink-scala-examples.src.main.scala.org.apache.flink.examples.scala.relational.WebLogAnalysis.scala</file>
      <file type="M">flink-examples.flink-scala-examples.src.main.scala.org.apache.flink.examples.scala.graph.TransitiveClosureNaive.scala</file>
      <file type="M">flink-examples.flink-scala-examples.src.main.scala.org.apache.flink.examples.scala.graph.PageRankBasic.scala</file>
      <file type="M">flink-examples.flink-scala-examples.src.main.scala.org.apache.flink.examples.scala.graph.EnumTrianglesOpt.scala</file>
      <file type="M">flink-examples.flink-scala-examples.src.main.scala.org.apache.flink.examples.scala.graph.EnumTrianglesBasic.scala</file>
      <file type="M">flink-examples.flink-scala-examples.src.main.scala.org.apache.flink.examples.scala.graph.DeltaPageRank.scala</file>
      <file type="M">flink-examples.flink-scala-examples.src.main.scala.org.apache.flink.examples.scala.graph.ConnectedComponents.scala</file>
      <file type="M">flink-examples.flink-scala-examples.src.main.scala.org.apache.flink.examples.scala.clustering.KMeans.scala</file>
      <file type="M">flink-examples.flink-java-examples.src.main.java.org.apache.flink.examples.java.relational.WebLogAnalysis.java</file>
      <file type="M">docs.programming.guide.md</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.dag.AbstractPartialSolutionNode.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.dag.BinaryUnionNode.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.dag.BulkIterationNode.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.dag.DataSinkNode.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.dag.DataSourceNode.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.dag.FilterNode.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.dag.OptimizerNode.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.dag.SingleInputNode.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.dag.TwoInputNode.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.dag.UnaryOperatorNode.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.dag.WorksetIterationNode.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.dataproperties.GlobalProperties.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.dataproperties.InterestingProperties.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.dataproperties.LocalProperties.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.dataproperties.RequestedGlobalProperties.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.dataproperties.RequestedLocalProperties.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.postpass.GenericFlatTypePostPass.java</file>
      <file type="M">flink-compiler.src.test.java.org.apache.flink.compiler.DOPChangeTest.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.DualInputSemanticProperties.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.Ordering.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.SemanticProperties.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.SingleInputSemanticProperties.java</file>
      <file type="M">flink-examples.flink-java-examples.src.main.java.org.apache.flink.examples.java.graph.ConnectedComponents.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.functions.FunctionAnnotation.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.postpass.JavaApiPostPass.java</file>
      <file type="M">flink-addons.flink-spargel.src.main.java.org.apache.flink.spargel.java.VertexCentricIteration.java</file>
      <file type="M">flink-addons.flink-spargel.src.test.java.org.apache.flink.spargel.java.SpargelTranslationTest.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.function.aggregation.ComparableAggregator.java</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.function.aggregation.SumAggregator.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.dag.PartitionNode.java</file>
      <file type="M">flink-compiler.src.test.java.org.apache.flink.compiler.custompartition.CoGroupCustomPartitioningTest.java</file>
      <file type="M">flink-compiler.src.test.java.org.apache.flink.compiler.custompartition.JoinCustomPartitioningTest.java</file>
      <file type="M">flink-compiler.src.test.java.org.apache.flink.compiler.dataproperties.GlobalPropertiesFilteringTest.java</file>
      <file type="M">flink-compiler.src.test.java.org.apache.flink.compiler.dataproperties.GlobalPropertiesMatchingTest.java</file>
      <file type="M">flink-compiler.src.test.java.org.apache.flink.compiler.dataproperties.GlobalPropertiesPushdownTest.java</file>
      <file type="M">flink-compiler.src.test.java.org.apache.flink.compiler.dataproperties.MockPartitioner.java</file>
      <file type="M">flink-compiler.src.test.java.org.apache.flink.compiler.IterationsCompilerTest.java</file>
      <file type="M">flink-compiler.src.test.java.org.apache.flink.compiler.java.WorksetIterationsJavaApiCompilerTest.java</file>
      <file type="M">flink-compiler.src.test.java.org.apache.flink.compiler.SemanticPropOptimizerTest.java</file>
      <file type="M">flink-compiler.src.test.java.org.apache.flink.compiler.SortPartialReuseTest.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.PartitionOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.DualInputOperator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.SingleInputOperator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.CompositeType.java</file>
      <file type="M">flink-examples.flink-java-examples.src.main.java.org.apache.flink.examples.java.clustering.KMeans.java</file>
      <file type="M">flink-examples.flink-java-examples.src.main.java.org.apache.flink.examples.java.graph.EnumTrianglesBasic.java</file>
      <file type="M">flink-examples.flink-java-examples.src.main.java.org.apache.flink.examples.java.graph.EnumTrianglesOpt.java</file>
      <file type="M">flink-examples.flink-java-examples.src.main.java.org.apache.flink.examples.java.graph.PageRankBasic.java</file>
      <file type="M">flink-examples.flink-java-examples.src.main.java.org.apache.flink.examples.java.graph.TransitiveClosureNaive.java</file>
    </fixedFiles>
  </bug>
  <bug id="1378" opendate="2015-1-9 00:00:00" fixdate="2015-1-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>could not find implicit value for evidence parameter of type TypeInformation</summary>
      <description>This is an example of one of many cases that I cannot get to compile with the scala API. I have tried using T : TypeInformation and : ClassTag but still cannot get it to work.//libraryDependencies += "org.apache.flink" % "flink-scala" % "0.7.0-incubating"////libraryDependencies += "org.apache.flink" % "flink-clients" % "0.7.0-incubating"import org.apache.flink.api.scala._import scala.util.{Success, Try}object Main extends App { val env = ExecutionEnvironment.getExecutionEnvironment val data: DataSet&amp;#91;Double&amp;#93; = env.fromElements(1.0, 2.0, 3.0, 4.0) def f&amp;#91;T&amp;#93;(data: DataSet&amp;#91;T&amp;#93;): DataSet[(T, Try[Seq&amp;#91;Double&amp;#93;])] = { data.mapPartition((iterator: Iterator&amp;#91;T&amp;#93;) =&gt; { val first = iterator.next() val second = iterator.next() Iterator((first, Success(Seq(2.0, 3.0))), (second, Success(Seq(3.0, 1.0)))) }) } val g = f(data) g.print() env.execute("Flink Test")}</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>0.8.0,0.9</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.scala.org.apache.flink.api.scala.runtime.ScalaSpecialTypesSerializerTest.scala</file>
      <file type="M">flink-tests.src.test.scala.org.apache.flink.api.scala.runtime.ScalaSpecialTypesITCase.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.OptionTypeInfo.scala</file>
      <file type="M">flink-tests.src.test.scala.org.apache.flink.api.scala.types.TypeInformationGenTest.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.codegen.TypeInformationGen.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.codegen.TypeDescriptors.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.codegen.TypeAnalyzer.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.runtime.KryoGenericTypeSerializerTest.scala</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.typeutils.runtime.KryoSerializer.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.typeutils.SerializerTestBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="13783" opendate="2019-8-19 00:00:00" fixdate="2019-6-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement type inference for string functions</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.12.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.stringExpressions.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.PlannerExpressionConverter.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.hashExpressions.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.planner.functions.sql.FlinkSqlOperatorTable.java</file>
      <file type="M">flink-table.flink-table-common.src.test.java.org.apache.flink.table.types.inference.TypeStrategiesTest.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.TypeStrategies.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.functions.BuiltInFunctionDefinitions.java</file>
    </fixedFiles>
  </bug>
  <bug id="13784" opendate="2019-8-19 00:00:00" fixdate="2019-6-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement type inference for math functions</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.12.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.expressions.ScalarOperatorsTest.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.api.stream.table.OverWindowTest.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.expressions.PlannerExpressionParserImpl.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.expressions.PlannerExpressionConverter.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.planner.expressions.ScalarFunctionsTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.planner.calcite.FlinkTypeFactoryTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.planner.plan.stream.table.ValuesTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.planner.plan.stream.table.OverWindowTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.java.org.apache.flink.table.planner.expressions.MathFunctionsITCase.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.java.org.apache.flink.table.planner.expressions.BuiltInFunctionTestBase.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.typeutils.TypeInfoCheckUtils.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.typeutils.TypeCoercion.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.time.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.ReturnTypeInference.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.PlannerExpressionConverter.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.mathExpressions.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.arithmetic.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.codegen.calls.ScalarOperatorGens.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.calcite.FlinkTypeSystem.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.expressions.PlannerExpressionParserImpl.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.planner.plan.type.FlinkReturnTypes.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.planner.functions.sql.FlinkSqlOperatorTable.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.planner.expressions.converter.DirectConvertRule.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.planner.expressions.converter.CustomizedConvertRule.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.planner.catalog.FunctionCatalogOperatorTable.java</file>
      <file type="M">flink-table.flink-table-common.src.test.java.org.apache.flink.table.types.LogicalTypeGeneralizationTest.java</file>
      <file type="M">flink-table.flink-table-common.src.test.java.org.apache.flink.table.types.inference.TypeStrategiesTest.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.logical.utils.LogicalTypeGeneralization.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.logical.LogicalTypeRoot.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.logical.LogicalTypeFamily.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.logical.LogicalType.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.TypeStrategies.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.strategies.MapInputTypeStrategy.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.strategies.FamilyArgumentTypeStrategy.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.strategies.CommonTypeStrategy.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.strategies.CommonInputTypeStrategy.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.InputTypeStrategies.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.functions.BuiltInFunctionDefinitions.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.functions.BuiltInFunctionDefinition.java</file>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.operations.utils.ValuesOperationFactory.java</file>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.api.internal.BaseExpressions.java</file>
    </fixedFiles>
  </bug>
  <bug id="13785" opendate="2019-8-19 00:00:00" fixdate="2019-4-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement type inference for time functions</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.expressions.utils.ExpressionTestBase.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.expressions.TemporalTypesTest.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.expressions.SqlExpressionTest.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.functions.ExtractFunctionITCase.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.logical.LogicalType.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.TypeStrategies.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.strategies.VaryingSequenceInputTypeStrategy.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.strategies.UseArgumentTypeStrategy.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.strategies.TypeLiteralArgumentTypeStrategy.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.strategies.SymbolArgumentTypeStrategy.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.strategies.SubsequenceInputTypeStrategy.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.strategies.SpecificTypeStrategies.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.strategies.SpecificInputTypeStrategies.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.strategies.RootArgumentTypeStrategy.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.strategies.OutputArgumentTypeStrategy.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.strategies.LiteralArgumentTypeStrategy.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.strategies.FamilyArgumentTypeStrategy.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.strategies.ExplicitArgumentTypeStrategy.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.strategies.CurrentWatermarkInputTypeStrategy.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.strategies.ConstraintArgumentTypeStrategy.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.strategies.CompositeArgumentTypeStrategy.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.strategies.ComparableTypeStrategy.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.strategies.CommonInputTypeStrategy.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.strategies.CommonArgumentTypeStrategy.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.strategies.CastInputTypeStrategy.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.strategies.AnyArgumentTypeStrategy.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.Signature.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.InputTypeStrategies.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.inference.CallContext.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.functions.BuiltInFunctionDefinitions.java</file>
      <file type="M">flink-examples.flink-examples-table.src.main.java.org.apache.flink.table.examples.java.functions.InternalRowMergerFunction.java</file>
    </fixedFiles>
  </bug>
  <bug id="14230" opendate="2019-9-26 00:00:00" fixdate="2019-10-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change the endInput call of the downstream operator to after the upstream operator closes</summary>
      <description>This ticket is for fixing the error of propagating "endInput" on the chain immediately after the input of the headoperator is finished. Correctly, "endInput" of the downstream operator should be invoked only after closingthe upstream operator.After "endInput" of the downstream operator on the chain is invoked correctly, we revertthe changes of PR#9298 and PR#9221.</description>
      <version>None</version>
      <fixedVersion>1.10.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.TestBoundedTwoInputOperator.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.TwoInputStreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.TestBoundedOneInputStreamOperator.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.SourceStreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.OneInputStreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.OperatorChain.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.StreamTwoInputProcessor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamSource.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.api.ContinuousFileReaderOperatorITCase.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.OneInputStreamOperatorTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.async.AsyncWaitOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.async.AsyncWaitOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.ContinuousFileReaderOperator.java</file>
    </fixedFiles>
  </bug>
  <bug id="14231" opendate="2019-9-26 00:00:00" fixdate="2019-2-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support the timers of the upstream operator with endInput properly</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.11.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.SystemProcessingTimeServiceTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.TimerService.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.TestProcessingTimeService.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.SystemProcessingTimeService.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.ProcessingTimeServiceImpl.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.ProcessingTimeService.java</file>
      <file type="M">flink-libraries.flink-state-processing-api.src.main.java.org.apache.flink.state.api.runtime.NeverFireProcessingTimeService.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.test.java.org.apache.flink.table.runtime.operators.wmassigners.WatermarkAssignerOperatorTest.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.runtime.operators.wmassigners.WatermarkAssignerOperatorFactory.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.runtime.operators.wmassigners.WatermarkAssignerOperator.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.runtime.operators.CodeGenOperatorFactory.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.codegen.OperatorCodeGenerator.scala</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.MockStreamingRuntimeContext.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.KeyedBroadcastOperatorTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.BroadcastOperatorTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.AbstractBroadcastStreamOperatorTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.StreamTaskTimerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.StreamTaskOperatorTimerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.StreamSourceOperatorLatencyMetricsTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.SimpleOperatorFactory.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.async.AsyncWaitOperatorFactory.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.AbstractStreamOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.ContinuousFileReaderOperatorFactory.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.ContinuousFileReaderOperator.java</file>
      <file type="M">flink-fs-tests.src.test.java.org.apache.flink.hdfstests.ContinuousFileProcessingTest.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.test.java.org.apache.flink.table.runtime.operators.join.AsyncLookupJoinHarnessTest.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.runtime.operators.window.WindowOperator.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.TestBoundedTwoInputOperator.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.OneInputStreamOperatorTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.TwoInputStreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.TestBoundedOneInputStreamOperator.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.SourceStreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.OneInputStreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.MailboxOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.async.AsyncWaitOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.async.AsyncWaitOperator.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.MockStreamTask.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.AbstractStreamOperatorTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.OperatorChainTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.TestProcessingTimeServiceTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.StreamOperatorChainingTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.OperatorChain.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamOperatorFactoryUtil.java</file>
      <file type="M">flink-libraries.flink-state-processing-api.src.main.java.org.apache.flink.state.api.output.BoundedStreamTask.java</file>
    </fixedFiles>
  </bug>
  <bug id="14353" opendate="2019-10-9 00:00:00" fixdate="2019-10-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable fork-reuse for table-planner</summary>
      <description>Enable fork reuse for table-planner to half test times.</description>
      <version>None</version>
      <fixedVersion>1.10.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="333" opendate="2014-6-9 00:00:00" fixdate="2014-1-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Respect CrossWithSmall and CrossWithLarge hints</summary>
      <description>The Java and the Scala API offer crossWithHuge() and crossWithTiny() API methods that allow the user to give hints to the optimizer about the size of the inputs a cross.However, these hints are not considered and all cross transformations are handled the same by the optimizer. Similiar hints for Join exist and are implemented correctly.</description>
      <version>0.6.1-incubating,0.7.0-incubating</version>
      <fixedVersion>0.9</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.DataSet.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.crossDataSet.scala</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.tuple.TupleGenerator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.CrossOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.DataSet.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.CrossOperatorBase.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.dag.CrossNode.java</file>
    </fixedFiles>
  </bug>
</bugrepository>
