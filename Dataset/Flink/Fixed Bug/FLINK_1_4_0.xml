<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="FLINK">
  <bug id="10150" opendate="2018-8-15 00:00:00" fixdate="2018-9-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Chained batch operators interfere with each other other</summary>
      <description>The flink web ui displays an inconsistent number of "Records received" / "Records sent” in the job overview "Subtasks" view.When I run the example wordcount batch job with a small input file on flink 1.3.2 I get 3 records sent by the first subtask and 3 records received by the second subtaskThis is the result I would expect.If I run the same job on flink 1.4.0 / 1.5.2 / 1.6.0 I get 13 records sent by the first subtask and 3 records received by the second subtaskIn real life jobs the numbers are much more strange.</description>
      <version>1.4.0,1.5.0,1.6.0,1.7.0</version>
      <fixedVersion>1.5.4,1.6.1,1.7.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.testutils.MockEnvironmentBuilder.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.testutils.MockEnvironment.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.groups.TaskMetricGroup.java</file>
    </fixedFiles>
  </bug>
  <bug id="10195" opendate="2018-8-22 00:00:00" fixdate="2018-7-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RabbitMQ Source With Checkpointing Doesn&amp;#39;t Backpressure Correctly</summary>
      <description>The connection between the RabbitMQ server and the client does not appropriately back pressure when auto acking is disabled. This becomes very problematic when a downstream process throttles the data processing to slower then RabbitMQ sends the data to the client.The difference in records ends up being stored in the flink's heap space, which grows indefinitely (or technically to "Integer Max" Deliveries). Looking at RabbitMQ's metrics the number of unacked messages looks like steadily rising saw tooth shape.Upon further invesitgation it looks like this is due to how the QueueingConsumer works, messages are added to the BlockingQueue faster then they are being removed and processed, resulting in the previously described behavior.This may be intended behavior, however this isn't explicitly obvious in the documentation or any of the examples I have seen.</description>
      <version>1.4.0,1.5.0,1.5.1,1.6.0</version>
      <fixedVersion>1.12.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-rabbitmq.src.test.java.org.apache.flink.streaming.connectors.rabbitmq.RMQSourceTest.java</file>
      <file type="M">flink-connectors.flink-connector-rabbitmq.src.test.java.org.apache.flink.streaming.connectors.rabbitmq.common.RMQConnectionConfigTest.java</file>
      <file type="M">flink-connectors.flink-connector-rabbitmq.src.main.java.org.apache.flink.streaming.connectors.rabbitmq.RMQSource.java</file>
      <file type="M">flink-connectors.flink-connector-rabbitmq.src.main.java.org.apache.flink.streaming.connectors.rabbitmq.common.RMQConnectionConfig.java</file>
      <file type="M">docs.dev.connectors.rabbitmq.md</file>
    </fixedFiles>
  </bug>
  <bug id="10527" opendate="2018-10-11 00:00:00" fixdate="2018-10-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cleanup constant isNewMode in YarnTestBase</summary>
      <description>This seems to be a residual problem with FLINK-10396. It is set to true in that PR. Currently it has three usage scenarios:1. assert, caused an errorassumeTrue("The new mode does not start TMs upfront.", !isNewMode);2. if (!isNewMode) the logic in the block would not have invoked, the if block can be removed3. if (isNewMode) always been invoked, the if statement can be removed.</description>
      <version>None</version>
      <fixedVersion>1.7.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn-tests.src.test.java.org.apache.flink.yarn.YARNSessionFIFOITCase.java</file>
    </fixedFiles>
  </bug>
  <bug id="5406" opendate="2017-1-4 00:00:00" fixdate="2017-2-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>add normalization phase for predicate logical plan rewriting between decorrelate query phase and volcano optimization phase</summary>
      <description>Normalization phase is for predicate logical plan rewriting and is independent of cost module. The rules in normalization phase do not need to repeatedly applied to different logical plan which is different to volcano optimization phase. And the benefit of normalization phase is to reduce the running time of volcano planner.ReduceExpressionsRule can apply various simplifying transformations on RexNode trees. Currently, there are two transformations:1) Constant reduction, which evaluates constant subtrees, replacing them with a corresponding RexLiteral2) Removal of redundant casts, which occurs when the argument into the cast is the same as the type of the resulting cast expressionthe above transformations do not depend on the cost module, so we can move the rules in ReduceExpressionsRule from DATASET_OPT_RULES/DATASTREAM_OPT_RULES to DataSet/DataStream Normalization Rules.</description>
      <version>None</version>
      <fixedVersion>1.3.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.TableEnvironmentTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.utils.ExpressionTestBase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.CalciteConfigBuilderTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.scala.batch.table.FieldProjectionTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.scala.batch.sql.SetOperatorsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.AggregationTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.table.api.java.batch.TableEnvironmentITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.rules.FlinkRuleSets.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.dataset.DataSetCalc.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.calcite.CalciteConfig.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.TableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.StreamTableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.BatchTableEnvironment.scala</file>
    </fixedFiles>
  </bug>
  <bug id="5454" opendate="2017-1-11 00:00:00" fixdate="2017-1-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add Documentation about how to tune Checkpointing for large state</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.monitoring.rest.api.md</file>
      <file type="M">docs.monitoring.large.state.tuning.md</file>
    </fixedFiles>
  </bug>
  <bug id="5455" opendate="2017-1-11 00:00:00" fixdate="2017-3-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create documentation how to upgrade jobs and Flink framework versions</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.ops.upgrading.md</file>
    </fixedFiles>
  </bug>
  <bug id="5458" opendate="2017-1-11 00:00:00" fixdate="2017-1-11 01:00:00" resolution="Duplicate">
    <buginformation>
      <summary>Add documentation how to migrate from Flink 1.1. to Flink 1.2</summary>
      <description>Docs should go to docs/dev/migration.md</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.index.md</file>
    </fixedFiles>
  </bug>
  <bug id="5659" opendate="2017-1-26 00:00:00" fixdate="2017-1-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>FileBaseUtils#deleteFileOrDirectory not thread-safe on Windows</summary>
      <description>The FileBaseUtils#deleteFileOrDirectory is not thread-safe on Windows.First you will run into AccessDeniedExceptions since one thread tried to delete a file while another thread was already doing that, for which the file has to be opened.Once you resolve those exceptions (by catching them double checking whether the file still exists), you run into DirectoryNotEmptyExceptions since there is some wacky timing/visibility issue when deleting files concurrently.</description>
      <version>1.2.0,1.3.0,1.4.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.maven.spotbugs-exclude.xml</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.LambdaUtil.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.function.ThrowingConsumer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.FileUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="6367" opendate="2017-4-24 00:00:00" fixdate="2017-5-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>support custom header settings of allow origin</summary>
      <description>`jobmanager.web.access-control-allow-origin`: Enable custom access control parameter for allow origin header, default is `*`.</description>
      <version>None</version>
      <fixedVersion>1.3.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.WebRuntimeMonitor.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.WebMonitorConfig.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.RuntimeMonitorHandler.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.ConfigConstants.java</file>
      <file type="M">docs.setup.config.md</file>
    </fixedFiles>
  </bug>
  <bug id="6508" opendate="2017-5-9 00:00:00" fixdate="2017-5-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Include license files of packaged dependencies</summary>
      <description>The Maven artifact for flink-table bundles its (non-Flink) dependencies to have a self-contained JAR file that can be moved to the ./lib folder without adding additional dependencies.Currently, we include Apache Calcite, Guava (relocates and required by Calcite), Janino, and Reflections.Janino and Reflections are not under Apache license, so we need to include their license files into the JAR file.</description>
      <version>1.2.1,1.3.0,1.4.0</version>
      <fixedVersion>1.3.0,1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6541" opendate="2017-5-11 00:00:00" fixdate="2017-6-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Jar upload directory not created</summary>
      <description>Steps to reproduce: setup configuration property: jobmanager.web.tmpdir = /mnt/flink/web this directory should not exist Run flink job manager. in logs:2017-05-11 12:07:58,397 ERROR org.apache.flink.runtime.webmonitor.WebMonitorUtils - WebServer could not be created [main]java.io.IOException: Jar upload directory /mnt/flink/web/flink-web-3f2733c3-6f4c-4311-b617-1e93d9535421 cannot be created or is not writable.Expected: create parent directories if they do not exit. i.e. use "uploadDir.mkdirs()" instead of "uploadDir.mkdir()"Note: BlobServer create parent directories (See BlobUtils storageDir.mkdirs())</description>
      <version>1.2.0,1.3.0,1.4.0</version>
      <fixedVersion>1.3.2,1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskManagerServices.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.WebRuntimeMonitor.java</file>
    </fixedFiles>
  </bug>
  <bug id="6549" opendate="2017-5-11 00:00:00" fixdate="2017-3-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve error message for type mismatches with side outputs</summary>
      <description>A type mismatch when using side outputs causes a ClassCastException to be thrown. It would be neat to include the name of the OutputTags in the exception message.This can occur when multiple {{OutputTag]}s with different types but identical names are being used.</description>
      <version>1.3.0,1.4.0</version>
      <fixedVersion>1.3.4,1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.OperatorChain.java</file>
    </fixedFiles>
  </bug>
  <bug id="6550" opendate="2017-5-11 00:00:00" fixdate="2017-7-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Calling ctx.collect with a null OutputTag should log a warning or throw an exception</summary>
      <description>When using side outputs it is currently possible to call {Context#collect(OutputTag&lt;X&gt;, X record)} with null for the OutputTag. Effectively this causes the data to be swallowed. It is unlikely that a user actually intends this, so i propose to either log a warning or throw an exception.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.ProcessOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.ProcessOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.KeyedProcessOperator.java</file>
    </fixedFiles>
  </bug>
  <bug id="6552" opendate="2017-5-11 00:00:00" fixdate="2017-5-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Side outputs don&amp;#39;t allow differing output types</summary>
      <description>When calling {SingleOutputStreamOperator#getSideOutput(OutputTag&lt;X&gt;} multiple times with the output tags having different types you get the following exception: "Trying to add a side input for the same id with a different type. This is not allowed." This error message is ambiguous, as it could either mean that you cannot add 2 side outputs with the same name but different types or that 2 side outputs with different types cannot be retrieved from a single operator.Furthermore, the error message contains the concept of node id's (i guess?) which users aren't exposed to. This is confusing and should be reworded to work with operators.Lastly, i find this limitation rather odd. It is possible for an operator to have multiple side outputs. It is also possible to have a side output with a different type than the main output. Yet, it is not possible to have multiple side outputs with different types.</description>
      <version>1.3.0,1.4.0</version>
      <fixedVersion>1.3.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.runtime.util.TestListResultSink.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.runtime.SideOutputITCase.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamGraph.java</file>
    </fixedFiles>
  </bug>
  <bug id="6555" opendate="2017-5-11 00:00:00" fixdate="2017-5-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Generalize ConjunctFuture</summary>
      <description>The ConjunctFuture allows to combine multiple Futures into one. At the moment it does not return the collection of results of the individuals futures. In some cases this information is helpful and should, thus, be returned.</description>
      <version>1.4.0</version>
      <fixedVersion>1.3.0,1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.concurrent.FutureUtilsTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.failover.FailoverRegion.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.ExecutionJobVertex.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.ExecutionGraph.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.concurrent.FutureUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="6560" opendate="2017-5-11 00:00:00" fixdate="2017-5-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Restore maven parallelism in flink-tests</summary>
      <description>FLINK-6506 added the maven variable flink.forkCountTestPackage which is used by the TravisCI script but no default value is set.</description>
      <version>1.3.0,1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6562" opendate="2017-5-11 00:00:00" fixdate="2017-5-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support implicit table references for nested fields in SQL</summary>
      <description>Currently nested fields can only be accessed through fully qualified identifiers. For example, users need to specify the following query for the table f that has a nested field foo.barSELECT f.foo.bar FROM fOther query engines like Hive / Presto supports implicit table references. For example:SELECT foo.bar FROM fThis jira proposes to support the latter syntax in the SQL API.</description>
      <version>None</version>
      <fixedVersion>1.3.0,1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.CompositeAccessTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.schema.CompositeRelDataType.scala</file>
    </fixedFiles>
  </bug>
  <bug id="6575" opendate="2017-5-13 00:00:00" fixdate="2017-7-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Disable all tests on Windows that use HDFS</summary>
      <description>Similar reasoning as FLINK-6558.</description>
      <version>1.3.0,1.4.0</version>
      <fixedVersion>1.3.2,1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-fs-tests.src.test.java.org.apache.flink.hdfstests.HDFSTest.java</file>
      <file type="M">flink-fs-tests.src.test.java.org.apache.flink.hdfstests.FsNegativeRunningJobsRegistryTest.java</file>
      <file type="M">flink-fs-tests.src.test.java.org.apache.flink.hdfstests.FileStateBackendTest.java</file>
      <file type="M">flink-fs-tests.src.test.java.org.apache.flink.hdfstests.ContinuousFileProcessingTest.java</file>
      <file type="M">flink-fs-tests.src.test.java.org.apache.flink.hdfstests.ContinuousFileProcessingMigrationTest.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.test.java.org.apache.flink.streaming.connectors.fs.bucketing.RollingToBucketingMigrationTest.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.test.java.org.apache.flink.streaming.connectors.fs.bucketing.RollingSinkMigrationTest.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.test.java.org.apache.flink.streaming.connectors.fs.bucketing.BucketingSinkTest.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.test.java.org.apache.flink.streaming.connectors.fs.bucketing.BucketingSinkMigrationTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="6583" opendate="2017-5-15 00:00:00" fixdate="2017-5-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable QueryConfig in count base GroupWindow</summary>
      <description>Enable QueryConfig in count base GroupWindow by Add a custom Trigger `CountTriggerWithCleanupState`. See more in FLINK-6491.</description>
      <version>1.3.0,1.4.0</version>
      <fixedVersion>1.3.0,1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.scala.stream.table.GroupWindowAggregationsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.datastream.DataStreamGroupWindowAggregate.scala</file>
    </fixedFiles>
  </bug>
  <bug id="6584" opendate="2017-5-15 00:00:00" fixdate="2017-10-15 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Support multiple consecutive windows in SQL</summary>
      <description>Right now, the Table API supports multiple consecutive windows as follows:val table = stream.toTable(tEnv, 'rowtime.rowtime, 'int, 'double, 'float, 'bigdec, 'string)val t = table .window(Tumble over 2.millis on 'rowtime as 'w) .groupBy('w) .select('w.rowtime as 'rowtime, 'int.count as 'int) .window(Tumble over 4.millis on 'rowtime as 'w2) .groupBy('w2) .select('w2.rowtime, 'w2.end, 'int.count)Similar behavior should be supported by the SQL API as well. We need to introduce a new auxiliary group function, but this should happen in sync with Apache Calcite.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.stream.TimeAttributesITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.plan.TimeIndicatorConversionTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.stream.sql.GroupWindowTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.batch.sql.validation.GroupWindowValidationTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.batch.sql.GroupWindowTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.validate.FunctionCatalog.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.AggregateUtil.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.rules.FlinkRuleSets.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.rules.datastream.DataStreamLogicalWindowAggregateRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.rules.dataSet.DataSetLogicalWindowAggregateRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.rules.common.WindowStartEndPropertiesRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.rules.common.LogicalWindowAggregateRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.datastream.DataStreamGroupWindowAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.logical.rel.LogicalWindowAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.calcite.RelTimeIndicatorConverter.scala</file>
      <file type="M">docs.dev.table.sql.md</file>
    </fixedFiles>
  </bug>
  <bug id="6585" opendate="2017-5-15 00:00:00" fixdate="2017-5-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Table examples are not runnable in IDE</summary>
      <description>Running Table API examples in flink-examples-table fails with:Caused by: java.lang.ClassNotFoundException: org.apache.flink.table.api.TableEnvironmentSeems to be a Maven issue.</description>
      <version>None</version>
      <fixedVersion>1.3.0,1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-examples.flink-examples-table.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6590" opendate="2017-5-15 00:00:00" fixdate="2017-2-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Integrate generated tables into documentation</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn.pom.xml</file>
      <file type="M">flink-libraries.flink-python.pom.xml</file>
      <file type="M">flink-docs.README.md</file>
      <file type="M">flink-docs.pom.xml</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.configuration.ConfigOptionsDocGeneratorTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.configuration.ConfigDocsCompletenessChecker.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.SecurityOptions.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.QueryableStateOptions.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.MetricOptions.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.HistoryServerOptions.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.ConfigOptionsDocGenerator.java</file>
      <file type="M">flink-core.pom.xml</file>
      <file type="M">docs.page.css.flink.css</file>
      <file type="M">docs.ops.config.md</file>
    </fixedFiles>
  </bug>
  <bug id="6603" opendate="2017-5-16 00:00:00" fixdate="2017-5-16 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Enable checkstyle on test sources</summary>
      <description>With the addition of strict checkstyle to select modules (currently limited to flink-streaming-java) we can enable the checkstyle flag includeTestSourceDirectory to perform the same unused imports, whitespace, and other checks on test sources.Should first resolve the import grouping as discussed in FLINK-6107. Also, several tests exceed the 2500 line limit.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.FromElementsFunction.java</file>
      <file type="M">tools.maven.strict-checkstyle.xml</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.typeutils.FieldAccessorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.TypeInformationSerializationSchemaTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.TwoInputStreamOperatorTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.TestHarnessUtil.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.SourceFunctionUtil.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.serialization.SimpleStringSchemaTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.OperatorSnapshotUtil.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.OneInputStreamOperatorTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.NoOpIntMap.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.MockOutput.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.MockContext.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.keys.ArrayKeySelectorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.KeyedTwoInputStreamOperatorTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.KeyedOneInputStreamOperatorTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.HDFSCopyUtilitiesTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.EvenOddOutputSelector.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.CollectorOutput.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.CollectingSourceContext.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.AbstractStreamOperatorTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.AbstractDeserializationSchemaTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.TwoInputStreamTaskTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.TwoInputStreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.SystemProcessingTimeServiceTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskCancellationBarrierTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamMockEnvironment.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.SourceStreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.SourceExternalCheckpointTriggerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.OneInputStreamTaskTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.OneInputStreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.InterruptSensitiveRestoreTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.BlockingCheckpointsTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.streamstatus.StreamStatusTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValveTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.streamrecord.StreamRecordTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.streamrecord.StreamElementSerializerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.partitioner.ShufflePartitionerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.partitioner.RescalePartitionerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.partitioner.RebalancePartitionerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.partitioner.KeyGroupStreamPartitionerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.partitioner.GlobalPartitionerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.partitioner.ForwardPartitionerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.partitioner.BroadcastPartitionerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.WriteAheadSinkTestBase.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.WindowTranslationTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.WindowOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.WindowOperatorFrom12MigrationTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.WindowOperatorFrom11MigrationTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.WindowOperatorContractTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.WindowedValue.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.TumblingProcessingTimeWindowsTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.TumblingEventTimeWindowsTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.TriggerTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.TimeWindowTranslationTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.TimeWindowTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.StreamRecordMatchers.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.SlidingProcessingTimeWindowsTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.SlidingEventTimeWindowsTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.SimpleTriggerTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.RegularWindowOperatorContractTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.PurgingTriggerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.ProcessingTimeTriggerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.ProcessingTimeSessionWindowsTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.MergingWindowSetTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.KeyMapTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.KeyMapPutTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.KeyMapPutIfAbsentTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.GlobalWindowsTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.EvictingWindowOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.EvictingWindowOperatorContractTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.EventTimeTriggerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.EventTimeSessionWindowsTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.CountTriggerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.ContinuousEventTimeTriggerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.AllWindowTranslationTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.AggregatingAlignedProcessingTimeWindowOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.AccumulatingAlignedProcessingTimeWindowOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.TimestampsAndPunctuatedWatermarksOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.TimestampsAndPeriodicWatermarksOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.TestProcessingTimeServiceTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.StreamTaskTimerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.StreamSourceOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.StreamOperatorChainingTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.GenericWriteAheadSinkTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.ContinuousFileProcessingRescalingTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.io.StreamRecordWriterTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.io.SpilledBufferOrEventSequenceTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.io.MockInputGate.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.io.BufferSpillerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.io.BarrierTrackerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.io.BarrierBufferTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.io.BarrierBufferMassiveRandomTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.io.BarrierBufferAlignmentLimitTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.graph.WithMasterCheckpointHookConfigTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.graph.TranslationTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.graph.StreamingJobGraphGeneratorNodeHashTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.windowing.deltafunction.EuclideanDistanceTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.windowing.deltafunction.CosineDistanceTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.TypeFillTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.streamtask.StreamIterationHeadTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.streamtask.MockRecordWriter.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.StreamExecutionEnvironmentTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.SourceFunctionTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.RestartStrategyTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.WrappingFunctionSnapshotRestoreTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.windowing.functions.InternalWindowFunctionTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.TestInternalTimerService.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.StreamSourceContextIdleDetectionTests.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.StreamProjectTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.StreamOperatorSnapshotRestoreTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.StreamMapTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.StreamingRuntimeContextTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.StreamGroupedReduceTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.StreamGroupedFoldTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.StreamFlatMapTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.StreamFilterTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.StateSnapshotContextSynchronousImplTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.StateInitializationContextImplTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.StateDescriptorPassingTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.ProcessOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.OperatorSnapshotResultTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.KeyedProcessOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.HeapInternalTimerServiceTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.FoldApplyWindowFunctionTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.FoldApplyProcessWindowFunctionTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.co.KeyedCoProcessOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.co.CoStreamMapTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.co.CoStreamFlatMapTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.co.CoProcessOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.async.queue.UnorderedStreamElementQueueTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.async.queue.StreamElementQueueTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.async.queue.OrderedStreamElementQueueTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.async.EmitterTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.async.AsyncWaitOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.AbstractUdfStreamOperatorLifecycleTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.AbstractStreamOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.graph.StreamingJobGraphGeneratorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.graph.StreamGraphGeneratorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.graph.SlotAllocationTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.functions.windowing.delta.extractor.FieldsFromTupleTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.functions.windowing.delta.extractor.FieldsFromArrayTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.functions.windowing.delta.extractor.FieldFromTupleTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.functions.windowing.delta.extractor.FieldFromArrayTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.functions.windowing.delta.extractor.ConcatenatedExtractTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.functions.windowing.delta.extractor.ArrayFromTupleTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.functions.StatefulSequenceSourceTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.functions.source.SocketTextStreamFunctionTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.functions.source.InputFormatSourceFunctionTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.functions.source.FileMonitoringFunctionTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.functions.sink.SocketClientSinkTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.functions.sink.OutputFormatSinkFunctionTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.functions.ListSourceContext.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.functions.IngestionTimeExtractorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.functions.FromElementsFunctionTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.functions.BoundedOutOfOrdernessTimestampExtractorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.functions.async.RichAsyncFunctionTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.functions.AscendingTimestampExtractorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.environment.LocalStreamEnvironmentITCase.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.DataStreamTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.collector.OutputSelectorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.checkpoint.ListCheckpointedTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.AggregationFunctionTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.runtime.io.network.partition.consumer.StreamTestSingleInputGate.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.util.typeutils.FieldAccessorFactory.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.util.typeutils.FieldAccessor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.util.serialization.TypeInformationSerializationSchema.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.util.serialization.SimpleStringSchema.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.util.serialization.SerializationSchema.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.util.serialization.DeserializationSchema.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.util.serialization.AbstractDeserializationSchema.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.util.keys.KeySelectorUtil.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.util.HDFSCopyToLocal.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.util.HDFSCopyFromLocal.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.util.functions.StreamingFunctionUtils.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.TwoInputStreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.TimerException.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.TestProcessingTimeService.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.SystemProcessingTimeService.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamIterationTail.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamIterationHead.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StoppableSourceStreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.SourceStreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.package-info.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.OperatorStateHandles.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.OperatorChain.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.ExceptionInChainedOperatorException.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.streamstatus.StreamStatusProvider.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.streamstatus.StreamStatusMaintainer.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.streamrecord.StreamElementSerializer.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.streamrecord.LatencyMarker.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.partitioner.StreamPartitioner.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.partitioner.ShufflePartitioner.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.TimestampedValue.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.package-info.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.MergingWindowSet.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.KeyMap.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.functions.InternalWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.functions.InternalSingleValueWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.functions.InternalSingleValueProcessWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.functions.InternalSingleValueProcessAllWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.functions.InternalSingleValueAllWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.functions.InternalProcessWindowContext.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.functions.InternalProcessAllWindowContext.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.functions.InternalIterableWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.functions.InternalIterableProcessWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.functions.InternalIterableProcessAllWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.functions.InternalIterableAllWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.functions.InternalAggregateProcessWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.functions.InternalAggregateProcessAllWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.EvictingWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.AggregatingProcessingTimeWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.AccumulatingProcessingTimeWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.AccumulatingKeyedTimePanes.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.AbstractKeyedTimePanes.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.AbstractAlignedProcessingTimeWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.TimestampsAndPunctuatedWatermarksOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.TimestampsAndPeriodicWatermarksOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.package-info.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.GenericWriteAheadSink.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.CheckpointCommitter.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.StreamTwoInputProcessor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.StreamRecordWriter.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.StreamInputProcessor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.RecordWriterOutput.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.InputGateUtil.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.CheckpointBarrierHandler.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.BufferSpiller.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.BlockingQueueBroker.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.BarrierTracker.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.BarrierBuffer.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.windows.Window.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.windows.TimeWindow.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.windows.GlobalWindow.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.triggers.Trigger.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.triggers.PurgingTrigger.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.triggers.EventTimeTrigger.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.triggers.CountTrigger.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.time.Time.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.evictors.TimeEvictor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.evictors.Evictor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.evictors.DeltaEvictor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.evictors.CountEvictor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.assigners.WindowAssigner.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.assigners.TumblingProcessingTimeWindows.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.assigners.SlidingProcessingTimeWindows.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.assigners.SlidingEventTimeWindows.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.assigners.ProcessingTimeSessionWindows.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.assigners.MergingWindowAssigner.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.assigners.GlobalWindows.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.assigners.EventTimeSessionWindows.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.assigners.BaseAlignedWindowAssigner.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.UnionTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.TwoInputTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.StreamTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.SplitTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.SourceTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.SinkTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.SideOutputTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.SelectTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.PartitionTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.OneInputTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.FeedbackTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.CoFeedbackTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.TimerService.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.TimeDomain.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.TimeCharacteristic.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.SimpleTimerService.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.Triggerable.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamSourceContexts.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamSource.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamProject.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamingRuntimeContext.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamGroupedReduce.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamGroupedFold.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.ProcessOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.Output.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.OperatorSnapshotResult.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.OnWatermarkCallback.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.KeyedProcessOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.KeyContext.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.InternalTimeServiceManager.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.InternalTimerService.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.InternalTimer.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.HeapInternalTimerService.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.co.KeyedCoProcessOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.co.CoProcessOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.async.queue.UnorderedStreamElementQueue.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.async.queue.StreamRecordQueueEntry.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.async.queue.StreamElementQueueEntry.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.async.queue.StreamElementQueue.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.async.queue.OrderedStreamElementQueue.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.async.queue.AsyncCollectionResult.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.async.Emitter.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.async.AsyncWaitOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.AbstractStreamOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamNode.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamGraphUserHashHasher.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamGraphHasherV2.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamGraphHasher.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamGraphGenerator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamGraph.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamEdge.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamConfig.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.JSONGenerator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.FunctionMasterCheckpointHookFactory.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.WindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.RichAllWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.ReduceApplyWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.ReduceApplyProcessWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.ReduceApplyProcessAllWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.ReduceApplyAllWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.PassThroughWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.PassThroughAllWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.InternalProcessApplyWindowContext.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.InternalProcessApplyAllWindowContext.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.FoldApplyWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.FoldApplyProcessWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.FoldApplyProcessAllWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.FoldApplyAllWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.delta.extractor.FieldsFromArray.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.delta.extractor.FieldFromArray.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.delta.extractor.Extractor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.delta.DeltaFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.AllWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.AggregateApplyWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.AggregateApplyAllWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.timestamps.BoundedOutOfOrdernessTimestampExtractor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.timestamps.AscendingTimestampExtractor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.StatefulSequenceSource.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.SourceFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.SocketTextStreamFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.MultipleIdsMessageAcknowledgingSourceBase.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.MessageAcknowledgingSourceBase.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.InputFormatSourceFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.FromSplittableIteratorFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.FromIteratorFunction.java</file>
      <file type="M">flink-streaming-java.pom.xml</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.migration.streaming.api.graph.StreamGraphHasherV1.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.migration.streaming.runtime.streamrecord.MultiplexingStreamRecordSerializer.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.migration.streaming.runtime.streamrecord.StreamRecordSerializer.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.checkpoint.Checkpointed.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.checkpoint.CheckpointedAsynchronously.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.checkpoint.CheckpointedRestoring.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.checkpoint.ListCheckpointed.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.collector.selector.CopyingDirectedOutput.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.collector.selector.DirectedOutput.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.collector.selector.OutputSelector.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.AllWindowedStream.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.AsyncDataStream.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.CoGroupedStreams.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.ConnectedStreams.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.DataStream.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.IterativeStream.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.JoinedStreams.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.KeyedStream.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.SplitStream.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.WindowedStream.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.environment.CheckpointConfig.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.environment.LocalStreamEnvironment.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.environment.RemoteStreamEnvironment.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.environment.StreamContextEnvironment.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.aggregation.ComparableAggregator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.aggregation.Comparator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.aggregation.SumFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.AssignerWithPeriodicWatermarks.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.AssignerWithPunctuatedWatermarks.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.async.AsyncFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.async.collector.AsyncCollector.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.async.RichAsyncFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.co.CoFlatMapFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.co.CoMapFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.OutputFormatSinkFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.PrintSinkFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.SinkFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.SocketClientSink.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.WriteFormat.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.WriteFormatAsCsv.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.WriteFormatAsText.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.WriteSinkFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.ContinuousFileMonitoringFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.ContinuousFileReaderOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.FileMonitoringFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.FileProcessingMode.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.FileReadFunction.java</file>
    </fixedFiles>
  </bug>
  <bug id="6604" opendate="2017-5-16 00:00:00" fixdate="2017-5-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove Java Serialization from the CEP library.</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.3.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-cep.src.test.java.org.apache.flink.cep.operator.CEPOperatorTest.java</file>
      <file type="M">flink-libraries.flink-cep.src.test.java.org.apache.flink.cep.operator.CEPMigration11to13Test.java</file>
      <file type="M">flink-libraries.flink-cep.src.test.java.org.apache.flink.cep.operator.CEPFrom12MigrationTest.java</file>
      <file type="M">flink-libraries.flink-cep.src.test.java.org.apache.flink.cep.nfa.SharedBufferTest.java</file>
      <file type="M">flink-libraries.flink-cep.src.test.java.org.apache.flink.cep.nfa.NFATest.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.operator.AbstractKeyedCEPPatternOperator.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.nfa.State.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.nfa.SharedBuffer.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.nfa.NFA.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.nfa.DeweyNumber.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.nfa.compiler.NFACompiler.java</file>
    </fixedFiles>
  </bug>
  <bug id="6606" opendate="2017-5-17 00:00:00" fixdate="2017-5-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create checkpoint hook with user classloader</summary>
      <description>Flink should set the thread's classloader when calling the checkpoint hook factory's `create` method. Without that, the hook is likely to fail during initialization (e.g. using ServiceLoader).</description>
      <version>None</version>
      <fixedVersion>1.3.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.checkpoint.hooks.MasterHooksTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.hooks.MasterHooks.java</file>
    </fixedFiles>
  </bug>
  <bug id="6608" opendate="2017-5-17 00:00:00" fixdate="2017-5-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Relax Kerberos login contexts parsing by trimming whitespaces in contexts list</summary>
      <description>The Kerberos login contexts list parsing right now isn't quite user-friendly.The list must be provided as: security.kerberos.login.contexts: Client,KafkaClient, without any whitespace in between.We can relax this to be more user-friendly by trimming any whitespaces in the list.A user actually stumbled across this: http://apache-flink-user-mailing-list-archive.2336050.n4.nabble.com/Problems-with-Kerberos-Kafka-connection-in-version-1-2-0-td12580.html#a12589</description>
      <version>None</version>
      <fixedVersion>1.3.0,1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.security.SecurityUtilsTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.security.SecurityUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="6614" opendate="2017-5-17 00:00:00" fixdate="2017-5-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Applying function on window auxiliary function fails</summary>
      <description>SQL queries that apply a function or expression on a window auxiliary function (TUMBLE_START, TUMBLE_END, HOP_START, etc). cannot be translated and fail with a CodeGenException:Exception in thread "main" org.apache.flink.table.codegen.CodeGenException: Unsupported call: TUMBLE_ENDExample query:SELECT a, toLong(TUMBLE_END(rowtime, INTERVAL '10' MINUTE)) AS t, COUNT(b) AS cntBFROM myTableGROUP BY a, TUMBLE(rowtime, INTERVAL '10' MINUTE)</description>
      <version>1.3.0,1.4.0</version>
      <fixedVersion>1.3.0,1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.scala.stream.sql.WindowAggregateTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.rules.common.WindowStartEndPropertiesRule.scala</file>
    </fixedFiles>
  </bug>
  <bug id="6630" opendate="2017-5-19 00:00:00" fixdate="2017-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement FLIP-6 MesosAppMasterRunner</summary>
      <description>A new runner must be developed for the FLIP-6 RM. Target the "single job" scenario.Take some time to consider a general solution or a base implementation that is shared with the old implementation.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.entrypoint.SessionClusterEntrypoint.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.entrypoint.JobClusterEntrypoint.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.entrypoint.ClusterEntrypoint.java</file>
      <file type="M">flink-mesos.src.test.java.org.apache.flink.mesos.runtime.clusterframework.MesosResourceManagerTest.java</file>
      <file type="M">flink-mesos.src.test.java.org.apache.flink.mesos.runtime.clusterframework.MesosFlinkResourceManagerTest.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.runtime.clusterframework.services.ZooKeeperMesosServices.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.runtime.clusterframework.services.StandaloneMesosServices.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.runtime.clusterframework.services.MesosServicesUtils.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.runtime.clusterframework.services.MesosServices.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.runtime.clusterframework.MesosTaskManagerParameters.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.runtime.clusterframework.MesosResourceManager.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.runtime.clusterframework.MesosApplicationMasterRunner.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.runtime.clusterframework.LaunchableMesosWorker.java</file>
    </fixedFiles>
  </bug>
  <bug id="6632" opendate="2017-5-19 00:00:00" fixdate="2017-5-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix parameter case sensitive error for test passing/rejecting filter API</summary>
      <description>TableAPI testAllPassingFilter: val t = util.addTable[(Int, Long, String)]('int, 'long, 'string) val resScala = t.filter(Literal(true)).select('int as 'myInt, 'string) val resJava = t.filter("TrUe").select("int as myInt, string")We got error:org.apache.flink.table.api.ValidationException: Cannot resolve [TrUe] given input [int, long, string].The error is caused by : lazy val boolLiteral: PackratParser[Expression] = ("true" | "false") ^^ { str =&gt; Literal(str.toBoolean) }I want improve the method as follow: lazy val boolLiteral: PackratParser[Expression] = ("(t|T)(r|R)(u|U)(e|E)".r | "(f|F)(a|A)(l|L)(s|S)(e|E)".r) ^^ { str =&gt; Literal(str.toBoolean)}Is there any drawback to this improvement? Welcome anyone feedback ?</description>
      <version>None</version>
      <fixedVersion>1.3.0,1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.ScalarOperatorsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.scala.batch.table.stringexpr.CalcStringExpressionTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.ExpressionParser.scala</file>
    </fixedFiles>
  </bug>
  <bug id="6660" opendate="2017-5-22 00:00:00" fixdate="2017-5-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>expand the streaming connectors overview page</summary>
      <description>The overview page for streaming connectors is too lean &amp;#8211; it should provide more context and also guide the reader toward related topics.Note that FLINK-6038 will add links to the Bahir connectors.</description>
      <version>1.3.0,1.4.0</version>
      <fixedVersion>1.3.0,1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.dev.connectors.twitter.md</file>
      <file type="M">docs.dev.connectors.index.md</file>
      <file type="M">docs.dev.connectors.filesystem.sink.md</file>
    </fixedFiles>
  </bug>
  <bug id="6669" opendate="2017-5-23 00:00:00" fixdate="2017-5-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[Build] Scala style check errror on Windows</summary>
      <description>When build the source code on Windows, a scala style check error happend.Here is the error messages.&amp;#91;INFO&amp;#93;&amp;#91;INFO&amp;#93; &amp;#8212; scalastyle-maven-plugin:0.8.0:check (default) @ flink-scala_2.10 &amp;#8212;error file=E:\github\flink\flink-scala\src\main\scala\org\apache\flink\api\scala\utils\package.scala message=Input length = 2Saving to outputFile=E:\github\flink\flink-scala\target\scalastyle-output.xmlProcessed 78 file(s)Found 1 errorsFound 0 warningsFound 0 infosFinished in 1189 ms&amp;#91;INFO&amp;#93; ------------------------------------------------------------------------&amp;#91;INFO&amp;#93; Reactor Summary:&amp;#91;INFO&amp;#93;&amp;#91;INFO&amp;#93; force-shading ...................................... SUCCESS [ 37.206 s]&amp;#91;INFO&amp;#93; flink .............................................. SUCCESS &amp;#91;03:27 min&amp;#93;&amp;#91;INFO&amp;#93; flink-annotations .................................. SUCCESS [ 3.020 s]&amp;#91;INFO&amp;#93; flink-shaded-hadoop ................................ SUCCESS [ 0.928 s]&amp;#91;INFO&amp;#93; flink-shaded-hadoop2 ............................... SUCCESS [ 15.314 s]&amp;#91;INFO&amp;#93; flink-shaded-hadoop2-uber .......................... SUCCESS [ 13.085 s]&amp;#91;INFO&amp;#93; flink-shaded-curator ............................... SUCCESS [ 0.234 s]&amp;#91;INFO&amp;#93; flink-shaded-curator-recipes ....................... SUCCESS [ 3.336 s]&amp;#91;INFO&amp;#93; flink-shaded-curator-test .......................... SUCCESS [ 2.948 s]&amp;#91;INFO&amp;#93; flink-metrics ...................................... SUCCESS [ 0.286 s]&amp;#91;INFO&amp;#93; flink-metrics-core ................................. SUCCESS [ 9.065 s]&amp;#91;INFO&amp;#93; flink-test-utils-parent ............................ SUCCESS [ 0.327 s]&amp;#91;INFO&amp;#93; flink-test-utils-junit ............................. SUCCESS [ 1.452 s]&amp;#91;INFO&amp;#93; flink-core ......................................... SUCCESS [ 54.277 s][INFO] flink-java ......................................... SUCCESS [ 25.244 s]&amp;#91;INFO&amp;#93; flink-runtime ...................................... SUCCESS &amp;#91;03:08 min&amp;#93;&amp;#91;INFO&amp;#93; flink-optimizer .................................... SUCCESS [ 14.540 s]&amp;#91;INFO&amp;#93; flink-clients ...................................... SUCCESS [ 14.457 s]&amp;#91;INFO&amp;#93; flink-streaming-java ............................... SUCCESS [ 58.130 s]&amp;#91;INFO&amp;#93; flink-test-utils ................................... SUCCESS [ 19.906 s]&amp;#91;INFO&amp;#93; flink-scala ........................................ FAILURE [ 56.634 s]&amp;#91;INFO&amp;#93; flink-runtime-web .................................. SKIPPEDI think this is caused by the Windows default encoding. When I set the inputEncoding to UTF-8 in scalastyle-maven-plugin, the error don't happen.</description>
      <version>1.3.0,1.4.0</version>
      <fixedVersion>1.3.1,1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6691" opendate="2017-5-23 00:00:00" fixdate="2017-5-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add checkstyle import block rule for scala imports</summary>
      <description>Similar to java and javax imports we should give scala imports a separate import block.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.maven.strict-checkstyle.xml</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.OneInputStreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.util.typeutils.FieldAccessor.java</file>
      <file type="M">flink-metrics.flink-metrics-jmx.src.test.java.org.apache.flink.runtime.jobmanager.JMXJobManagerMetricTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="6695" opendate="2017-5-24 00:00:00" fixdate="2017-7-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Activate strict checkstyle in flink-contrib</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-contrib.flink-storm-examples.src.test.java.org.apache.flink.storm.tests.StormFieldsGroupingITCase.java</file>
      <file type="M">flink-contrib.flink-connector-wikiedits.src.test.java.org.apache.flink.streaming.connectors.wikiedits.WikipediaEditsSourceTest.java</file>
      <file type="M">flink-contrib.flink-connector-wikiedits.src.main.java.org.apache.flink.streaming.connectors.wikiedits.WikipediaEditsSource.java</file>
      <file type="M">flink-contrib.flink-connector-wikiedits.src.main.java.org.apache.flink.streaming.connectors.wikiedits.WikipediaEditEvent.java</file>
      <file type="M">flink-contrib.flink-connector-wikiedits.pom.xml</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackendTest.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackendFactoryTest.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackendConfigTest.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBReducingStateTest.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDbMultiClassLoaderTest.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBMergeIteratorTest.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBListStateTest.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBInitResetTest.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBAsyncSnapshotTest.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBAggregatingStateTest.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.benchmark.RocksDBPerformanceTest.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.migration.contrib.streaming.state.RocksDBStateBackend.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBValueState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackendFactory.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackend.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBReducingState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBMapState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBListState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackend.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBFoldingState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBAggregatingState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.PredefinedOptions.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.OptionsFactory.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.AbstractRocksDBState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.pom.xml</file>
      <file type="M">flink-contrib.flink-storm.src.test.resources.log4j-test.properties</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.wrappers.WrapperSetupInLocalClusterTest.java</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.wrappers.WrapperSetupHelperTest.java</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.wrappers.StormTupleTest.java</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.wrappers.SpoutWrapperTest.java</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.wrappers.SpoutCollectorTest.java</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.wrappers.SetupOutputFieldsDeclarerTest.java</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.wrappers.FlinkTopologyContextTest.java</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.wrappers.BoltWrapperTest.java</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.wrappers.BoltCollectorTest.java</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.util.TestSink.java</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.util.TestDummySpout.java</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.util.TestDummyBolt.java</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.util.StormStreamSelectorTest.java</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.util.SpoutOutputCollectorObserverTest.java</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.util.NullTerminatingSpoutTest.java</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.util.FiniteTestSpout.java</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.util.AbstractTest.java</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.api.TestSpout.java</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.api.TestBolt.java</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.api.FlinkTopologyTest.java</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.api.FlinkOutputFieldsDeclarerTest.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.wrappers.WrapperSetupHelper.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.wrappers.StormTuple.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.wrappers.SpoutWrapper.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.wrappers.SpoutCollector.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.wrappers.MergedInputsBoltWrapper.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.wrappers.FlinkTopologyContext.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.wrappers.BoltWrapper.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.wrappers.BoltCollector.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.wrappers.AbstractStormCollector.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.util.StormStreamSelector.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.util.StormConfig.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.util.SpoutOutputCollectorObserver.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.util.SplitStreamType.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.util.SplitStreamMapper.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.util.NullTerminatingSpout.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.util.FiniteSpout.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.api.TwoFlinkStreamsMerger.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.api.StormFlinkStreamMerger.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.api.FlinkTopology.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.api.FlinkSubmitter.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.api.FlinkOutputFieldsDeclarer.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.api.FlinkLocalCluster.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.api.FlinkClient.java</file>
      <file type="M">flink-contrib.flink-storm.pom.xml</file>
      <file type="M">flink-contrib.flink-streaming-contrib.src.test.java.org.apache.flink.contrib.streaming.SocketStreamIteratorTest.java</file>
      <file type="M">flink-contrib.flink-streaming-contrib.src.test.java.org.apache.flink.contrib.streaming.CollectITCase.java</file>
      <file type="M">flink-contrib.flink-streaming-contrib.src.main.java.org.apache.flink.contrib.streaming.SocketStreamIterator.java</file>
      <file type="M">flink-contrib.flink-streaming-contrib.src.main.java.org.apache.flink.contrib.streaming.DataStreamUtils.java</file>
      <file type="M">flink-contrib.flink-streaming-contrib.src.main.java.org.apache.flink.contrib.streaming.CollectSink.java</file>
      <file type="M">flink-contrib.flink-streaming-contrib.pom.xml</file>
      <file type="M">flink-contrib.flink-storm-examples.src.test.java.org.apache.flink.storm.wordcount.WordCountLocalNamedITCase.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.test.java.org.apache.flink.storm.wordcount.WordCountLocalITCase.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.test.java.org.apache.flink.storm.wordcount.SpoutSourceWordCountITCase.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.test.java.org.apache.flink.storm.wordcount.BoltTokenizerWordCountWithNamesITCase.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.test.java.org.apache.flink.storm.wordcount.BoltTokenizerWordCountPojoITCase.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.test.java.org.apache.flink.storm.wordcount.BoltTokenizerWordCountITCase.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.test.java.org.apache.flink.storm.tests.StormUnionITCase.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.test.java.org.apache.flink.storm.tests.StormMetaDataITCase.java</file>
      <file type="M">flink-contrib.flink-storm-examples.pom.xml</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.exclamation.ExclamationLocal.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.exclamation.ExclamationTopology.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.exclamation.ExclamationWithBolt.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.exclamation.ExclamationWithSpout.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.exclamation.operators.ExclamationBolt.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.join.SingleJoinExample.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.print.PrintSampleStream.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.split.operators.RandomSpout.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.split.operators.VerifyAndEnrichBolt.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.split.SpoutSplitExample.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.util.AbstractBoltSink.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.util.AbstractLineSpout.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.util.FileSpout.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.util.FiniteFileSpout.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.util.OutputFormatter.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.util.SimpleOutputFormatter.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.util.TupleOutputFormatter.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.wordcount.BoltTokenizerWordCount.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.wordcount.BoltTokenizerWordCountPojo.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.wordcount.BoltTokenizerWordCountWithNames.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.wordcount.operators.BoltCounter.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.wordcount.operators.BoltCounterByName.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.wordcount.operators.BoltTokenizer.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.wordcount.operators.BoltTokenizerByName.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.wordcount.operators.WordCountDataPojos.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.wordcount.operators.WordCountDataTuple.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.wordcount.operators.WordCountInMemorySpout.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.wordcount.SpoutSourceWordCount.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.wordcount.WordCountLocal.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.wordcount.WordCountLocalByName.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.wordcount.WordCountRemoteByClient.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.wordcount.WordCountRemoteBySubmitter.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.wordcount.WordCountTopology.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.test.java.org.apache.flink.storm.exclamation.ExclamationWithBoltITCase.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.test.java.org.apache.flink.storm.exclamation.ExclamationWithSpoutITCase.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.test.java.org.apache.flink.storm.exclamation.StormExclamationLocalITCase.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.test.java.org.apache.flink.storm.exclamation.util.ExclamationData.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.test.java.org.apache.flink.storm.join.SingleJoinITCase.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.test.java.org.apache.flink.storm.split.SplitBolt.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.test.java.org.apache.flink.storm.split.SplitBoltTopology.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.test.java.org.apache.flink.storm.split.SplitITCase.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.test.java.org.apache.flink.storm.split.SplitSpoutTopology.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.test.java.org.apache.flink.storm.split.SplitStreamBoltLocal.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.test.java.org.apache.flink.storm.split.SplitStreamSpoutLocal.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.test.java.org.apache.flink.storm.tests.operators.FiniteRandomSpout.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.test.java.org.apache.flink.storm.tests.operators.MergerBolt.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.test.java.org.apache.flink.storm.tests.operators.MetaDataSpout.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.test.java.org.apache.flink.storm.tests.operators.TaskIdBolt.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.test.java.org.apache.flink.storm.tests.operators.VerifyMetaDataBolt.java</file>
    </fixedFiles>
  </bug>
  <bug id="6703" opendate="2017-5-24 00:00:00" fixdate="2017-10-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document how to take a savepoint on YARN</summary>
      <description>The documentation should have a separate entry for savepoint related CLI commands in combination with YARN. It is currently not documented that you have to supply the application id, nor how you can pass it../bin/flink savepoint &lt;jobID&gt; -m yarn-cluster (-yid|-yarnapplicationId) &lt;appID&gt;</description>
      <version>1.3.0,1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.ops.state.savepoints.md</file>
      <file type="M">docs.ops.cli.md</file>
    </fixedFiles>
  </bug>
  <bug id="6704" opendate="2017-5-24 00:00:00" fixdate="2017-5-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cannot disable YARN user jar inclusion</summary>
      <description></description>
      <version>1.3.0,1.4.0</version>
      <fixedVersion>1.3.0,1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.AbstractYarnClusterDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="6709" opendate="2017-5-24 00:00:00" fixdate="2017-5-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Activate strict checkstyle for flink-gellies</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.drivers.HITSITCase.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.utils.proxy.OptionalBooleanTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.types.valuearray.ValueArrayTypeInfoTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.types.valuearray.StringValueArrayTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.types.valuearray.StringValueArraySerializerTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.types.valuearray.StringValueArrayComparatorTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.types.valuearray.NullValueArrayTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.types.valuearray.NullValueArraySerializerTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.types.valuearray.NullValueArrayComparatorTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.types.valuearray.LongValueArrayTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.types.valuearray.LongValueArraySerializerTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.types.valuearray.LongValueArrayComparatorTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.types.valuearray.IntValueArrayTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.types.valuearray.IntValueArraySerializerTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.types.valuearray.IntValueArrayComparatorTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.test.TestGraphUtils.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.test.ScatterGatherConfigurationITCase.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.test.operations.TypeExtractorTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.test.operations.ReduceOnNeighborsWithExceptionITCase.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.test.operations.ReduceOnNeighborMethodsITCase.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.test.operations.ReduceOnEdgesWithExceptionITCase.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.test.operations.ReduceOnEdgesMethodsITCase.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.test.operations.MapVerticesITCase.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.test.operations.MapEdgesITCase.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.test.operations.JoinWithVerticesITCase.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.test.operations.JoinWithEdgesITCase.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.test.operations.GraphOperationsITCase.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.test.operations.GraphMutationsITCase.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.test.operations.GraphCreationWithMapperITCase.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.test.operations.GraphCreationWithCsvITCase.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.test.operations.GraphCreationITCase.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.test.operations.FromCollectionITCase.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.test.operations.DegreesWithExceptionITCase.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.test.operations.DegreesITCase.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.test.GatherSumApplyConfigurationITCase.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.test.CollectionModeSuperstepITCase.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.spargel.SpargelTranslationTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.spargel.SpargelCompilerTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.pregel.PregelTranslationTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.pregel.PregelCompilerTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.library.similarity.JaccardIndexTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.library.similarity.AdamicAdarTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.library.metric.undirected.VertexMetricsTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.library.metric.undirected.EdgeMetricsTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.library.metric.directed.VertexMetricsTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.library.metric.directed.EdgeMetricsTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.library.metric.ChecksumHashCodeTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.library.link.analysis.PageRankTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.library.link.analysis.HITSTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.library.ConnectedComponentsWithRandomisedEdgesITCase.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.library.clustering.undirected.TriangleListingTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.library.clustering.undirected.TriadicCensusTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.library.clustering.undirected.LocalClusteringCoefficientTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.library.clustering.undirected.GlobalClusteringCoefficientTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.library.clustering.undirected.AverageClusteringCoefficientTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.library.clustering.directed.TriangleListingTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.library.clustering.directed.TriadicCensusTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.library.clustering.directed.LocalClusteringCoefficientTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.library.clustering.directed.GlobalClusteringCoefficientTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.library.clustering.directed.AverageClusteringCoefficientTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.gsa.GSATranslationTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.gsa.GSACompilerTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.generator.TestUtils.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.generator.StarGraphTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.generator.SingletonEdgeGraphTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.generator.RMatGraphTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.generator.PathGraphTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.generator.HypercubeGraphTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.generator.GridGraphTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.generator.EmptyGraphTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.generator.EchoGraphTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.generator.CycleGraphTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.generator.CompleteGraphTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.generator.CirculantGraphTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.generator.AbstractGraphTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.bipartite.ProjectionTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.bipartite.BipartiteGraphTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.bipartite.BipartiteEdgeTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.asm.translate.translators.ToNullValueTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.asm.translate.translators.LongValueToUnsignedIntValueTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.asm.translate.translators.LongValueToStringValueTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.asm.translate.translators.LongValueToSignedIntValueTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.asm.translate.translators.LongValueAddOffsetTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.asm.translate.TranslateTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.asm.simple.undirected.SimplifyTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.asm.simple.directed.SimplifyTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.asm.degree.filter.undirected.MaximumDegreeTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.asm.degree.annotate.undirected.VertexDegreeTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.asm.degree.annotate.undirected.EdgeTargetDegreeTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.asm.degree.annotate.undirected.EdgeSourceDegreeTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.asm.degree.annotate.undirected.EdgeDegreePairTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.asm.degree.annotate.directed.VertexOutDegreeTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.asm.degree.annotate.directed.VertexInDegreeTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.asm.degree.annotate.directed.VertexDegreesTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.asm.degree.annotate.directed.EdgeTargetDegreesTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.asm.degree.annotate.directed.EdgeSourceDegreesTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.asm.degree.annotate.directed.EdgeDegreesPairTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.asm.dataset.CountTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.asm.dataset.CollectTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.asm.dataset.ChecksumHashCodeTest.java</file>
      <file type="M">flink-libraries.flink-gelly.src.test.java.org.apache.flink.graph.asm.AsmTestBase.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.VertexJoinFunction.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.validation.InvalidVertexIdsValidator.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.validation.GraphValidator.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.utils.VertexToTuple2Map.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.utils.Tuple3ToEdgeMap.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.utils.Tuple2ToVertexMap.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.utils.Tuple2ToEdgeMap.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.utils.proxy.OptionalBoolean.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.utils.proxy.GraphAlgorithmWrappingGraph.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.utils.proxy.GraphAlgorithmWrappingDataSet.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.utils.Murmur3.32.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.utils.GraphUtils.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.utils.EdgeToTuple3Map.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.utils.EdgeToTuple2Map.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.types.valuearray.ValueArrayFactory.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.types.valuearray.ValueArray.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.types.valuearray.StringValueArrayComparator.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.types.valuearray.StringValueArray.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.types.valuearray.NullValueArrayComparator.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.types.valuearray.NullValueArray.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.types.valuearray.LongValueArrayComparator.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.types.valuearray.LongValueArray.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.types.valuearray.IntValueArrayComparator.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.types.valuearray.IntValueArray.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.Triplet.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.spargel.ScatterGatherIteration.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.spargel.ScatterGatherConfiguration.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.spargel.ScatterFunction.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.spargel.MessageIterator.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.spargel.GatherFunction.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.ReduceNeighborsFunction.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.ReduceEdgesFunction.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.pregel.VertexCentricIteration.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.pregel.VertexCentricConfiguration.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.pregel.MessageIterator.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.pregel.MessageCombiner.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.pregel.ComputeFunction.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.NeighborsFunctionWithVertexValue.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.NeighborsFunction.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.library.TriangleEnumerator.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.library.Summarization.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.library.SingleSourceShortestPaths.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.library.similarity.JaccardIndex.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.library.similarity.AdamicAdar.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.library.metric.undirected.VertexMetrics.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.library.metric.undirected.EdgeMetrics.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.library.metric.directed.VertexMetrics.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.library.metric.directed.EdgeMetrics.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.library.metric.ChecksumHashCode.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.library.link.analysis.PageRank.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.library.link.analysis.HITS.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.library.link.analysis.Functions.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.library.LabelPropagation.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.library.GSASingleSourceShortestPaths.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.library.GSAConnectedComponents.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.library.ConnectedComponents.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.library.CommunityDetection.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.library.clustering.undirected.TriangleListing.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.library.clustering.undirected.TriadicCensus.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.library.clustering.undirected.LocalClusteringCoefficient.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.library.clustering.undirected.GlobalClusteringCoefficient.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.library.clustering.undirected.AverageClusteringCoefficient.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.library.clustering.directed.TriangleListing.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.library.clustering.directed.TriadicCensus.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.library.clustering.directed.LocalClusteringCoefficient.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.library.clustering.directed.GlobalClusteringCoefficient.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.library.clustering.directed.AverageClusteringCoefficient.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.IterationConfiguration.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.gsa.SumFunction.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.gsa.Neighbor.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.gsa.GSAConfiguration.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.gsa.GatherSumApplyIteration.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.gsa.GatherFunction.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.gsa.ApplyFunction.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.GraphCsvReader.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.GraphAnalytic.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.Graph.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.generator.StarGraph.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.generator.SingletonEdgeGraph.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.generator.RMatGraph.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.generator.random.RandomGenerable.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.generator.random.MersenneTwisterFactory.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.generator.random.JDKRandomGeneratorFactory.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.generator.random.AbstractGeneratorFactory.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.generator.PathGraph.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.generator.HypercubeGraph.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.generator.GridGraph.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.generator.GraphGeneratorUtils.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.generator.GraphGenerator.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.generator.EmptyGraph.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.generator.EchoGraph.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.generator.CycleGraph.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.generator.CompleteGraph.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.generator.CirculantGraph.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.generator.AbstractGraphGenerator.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.EdgesFunctionWithVertexValue.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.EdgesFunction.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.EdgeOrder.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.EdgeJoinFunction.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.bipartite.Projection.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.bipartite.BipartiteGraph.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.asm.translate.translators.LongValueToUnsignedIntValue.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.asm.translate.translators.LongValueToSignedIntValue.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.asm.translate.translators.LongValueAddOffset.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.asm.translate.TranslateVertexValues.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.asm.translate.TranslateGraphIds.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.asm.translate.TranslateFunction.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.asm.translate.TranslateEdgeValues.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.asm.translate.Translate.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.asm.simple.undirected.Simplify.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.asm.simple.directed.Simplify.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.asm.degree.filter.undirected.MaximumDegree.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.asm.degree.annotate.undirected.VertexDegree.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.asm.degree.annotate.undirected.EdgeTargetDegree.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.asm.degree.annotate.undirected.EdgeSourceDegree.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.asm.degree.annotate.undirected.EdgeDegreePair.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.asm.degree.annotate.directed.VertexOutDegree.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.asm.degree.annotate.directed.VertexInDegree.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.asm.degree.annotate.directed.VertexDegrees.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.asm.degree.annotate.directed.EdgeTargetDegrees.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.asm.degree.annotate.directed.EdgeSourceDegrees.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.asm.degree.annotate.directed.EdgeDegreesPair.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.asm.degree.annotate.DegreeAnnotationFunctions.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.asm.dataset.DataSetAnalytic.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.asm.dataset.Count.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.asm.dataset.Collect.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.asm.dataset.ChecksumHashCode.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.asm.dataset.AbstractDataSetAnalytic.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.AnalyticHelper.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.AbstractGraphAnalytic.java</file>
      <file type="M">flink-libraries.flink-gelly.pom.xml</file>
      <file type="M">flink-libraries.flink-gelly-scala.src.test.scala.org.apache.flink.graph.scala.test.operations.JoinWithEdgesITCase.scala</file>
      <file type="M">flink-libraries.flink-gelly-scala.src.test.scala.org.apache.flink.graph.scala.test.operations.GraphOperationsITCase.scala</file>
      <file type="M">flink-libraries.flink-gelly-scala.src.test.scala.org.apache.flink.graph.scala.test.operations.GraphMutationsITCase.scala</file>
      <file type="M">flink-libraries.flink-gelly-scala.src.test.scala.org.apache.flink.graph.scala.test.GellyScalaAPICompletenessTest.scala</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.test.GatherSumApplyITCase.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.test.examples.SingleSourceShortestPathsITCase.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.test.examples.PageRankITCase.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.test.examples.MusicProfilesITCase.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.test.examples.IncrementalSSSPITCase.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.test.examples.EuclideanGraphWeighingITCase.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.RunnerITCase.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.library.TriangleEnumeratorITCase.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.library.SummarizationITCase.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.library.LabelPropagationITCase.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.library.CommunityDetectionITCase.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.drivers.TriangleListingITCase.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.drivers.parameter.StringParameterTest.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.drivers.parameter.SimplifyTest.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.drivers.parameter.ParameterTestBase.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.drivers.parameter.LongParameterTest.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.drivers.parameter.IterationConvergenceTest.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.drivers.parameter.DoubleParameterTest.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.drivers.parameter.ChoiceParameterTest.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.drivers.parameter.BooleanParameterTest.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.drivers.PageRankITCase.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.drivers.JaccardIndexITCase.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.drivers.input.GeneratedGraphTest.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.pom.xml</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.drivers.AdamicAdar.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.drivers.ClusteringCoefficient.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.drivers.ConnectedComponents.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.drivers.Driver.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.drivers.GraphMetrics.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.drivers.HITS.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.drivers.input.CirculantGraph.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.drivers.input.CSV.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.drivers.input.GeneratedGraph.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.drivers.input.GridGraph.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.drivers.input.RMatGraph.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.drivers.JaccardIndex.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.drivers.PageRank.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.drivers.parameter.ChoiceParameter.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.drivers.parameter.IterationConvergence.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.drivers.parameter.Parameter.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.drivers.parameter.ParameterizedBase.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.drivers.parameter.Simplify.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.drivers.SimpleDriver.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.drivers.TriangleListing.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.examples.data.CommunityDetectionData.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.examples.data.ConnectedComponentsDefaultData.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.examples.data.EuclideanGraphData.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.examples.data.IncrementalSSSPData.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.examples.data.LabelPropagationData.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.examples.data.MusicProfilesData.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.examples.data.PageRankData.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.examples.data.SingleSourceShortestPathsData.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.examples.data.SummarizationData.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.examples.data.TriangleCountData.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.examples.EuclideanGraphWeighing.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.examples.GSAPageRank.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.examples.GSASingleSourceShortestPaths.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.examples.IncrementalSSSP.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.examples.MusicProfiles.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.examples.PageRank.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.examples.PregelSSSP.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.examples.SingleSourceShortestPaths.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.Runner.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.resources.logback.xml</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.scala.org.apache.flink.graph.scala.examples.ConnectedComponents.scala</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.scala.org.apache.flink.graph.scala.examples.GSASingleSourceShortestPaths.scala</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.scala.org.apache.flink.graph.scala.examples.SingleSourceShortestPaths.scala</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.drivers.AdamicAdarITCase.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.drivers.ClusteringCoefficientITCase.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.drivers.ConnectedComponentsITCase.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.drivers.DriverBaseITCase.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.drivers.EdgeListITCase.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.test.java.org.apache.flink.graph.drivers.GraphMetricsITCase.java</file>
    </fixedFiles>
  </bug>
  <bug id="6710" opendate="2017-5-24 00:00:00" fixdate="2017-6-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove twitter-inputformat</summary>
      <description>I propose removing the twitter-inputformat under flink-contrib.It provides no interesting properties in terms of accessing tweets (since it just reads them from a file) in contrast to the streaming TwitterSource, nor provides any significant functionality that cannot be achieved using the jackson databind API.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-contrib.pom.xml</file>
      <file type="M">flink-contrib.flink-tweet-inputformat.src.test.resources.log4j-test.properties</file>
      <file type="M">flink-contrib.flink-tweet-inputformat.src.test.java.org.apache.flink.contrib.tweetinputformat.SimpleTweetInputFormatTest.java</file>
      <file type="M">flink-contrib.flink-tweet-inputformat.src.main.resources.HashTagTweetSample.json</file>
      <file type="M">flink-contrib.flink-tweet-inputformat.src.main.java.org.apache.flink.contrib.tweetinputformat.model.User.Users.java</file>
      <file type="M">flink-contrib.flink-tweet-inputformat.src.main.java.org.apache.flink.contrib.tweetinputformat.model.tweet.Tweet.java</file>
      <file type="M">flink-contrib.flink-tweet-inputformat.src.main.java.org.apache.flink.contrib.tweetinputformat.model.tweet.entities.UserMention.java</file>
      <file type="M">flink-contrib.flink-tweet-inputformat.src.main.java.org.apache.flink.contrib.tweetinputformat.model.tweet.entities.URL.java</file>
      <file type="M">flink-contrib.flink-tweet-inputformat.src.main.java.org.apache.flink.contrib.tweetinputformat.model.tweet.entities.Symbol.java</file>
      <file type="M">flink-contrib.flink-tweet-inputformat.src.main.java.org.apache.flink.contrib.tweetinputformat.model.tweet.entities.Size.java</file>
      <file type="M">flink-contrib.flink-tweet-inputformat.src.main.java.org.apache.flink.contrib.tweetinputformat.model.tweet.entities.Media.java</file>
      <file type="M">flink-contrib.flink-tweet-inputformat.src.main.java.org.apache.flink.contrib.tweetinputformat.model.tweet.entities.HashTags.java</file>
      <file type="M">flink-contrib.flink-tweet-inputformat.src.main.java.org.apache.flink.contrib.tweetinputformat.model.tweet.entities.Entities.java</file>
      <file type="M">flink-contrib.flink-tweet-inputformat.src.main.java.org.apache.flink.contrib.tweetinputformat.model.tweet.CurrentUserRetweet.java</file>
      <file type="M">flink-contrib.flink-tweet-inputformat.src.main.java.org.apache.flink.contrib.tweetinputformat.model.tweet.Coordinates.java</file>
      <file type="M">flink-contrib.flink-tweet-inputformat.src.main.java.org.apache.flink.contrib.tweetinputformat.model.tweet.Contributors.java</file>
      <file type="M">flink-contrib.flink-tweet-inputformat.src.main.java.org.apache.flink.contrib.tweetinputformat.model.places.Places.java</file>
      <file type="M">flink-contrib.flink-tweet-inputformat.src.main.java.org.apache.flink.contrib.tweetinputformat.model.places.BoundingBox.java</file>
      <file type="M">flink-contrib.flink-tweet-inputformat.src.main.java.org.apache.flink.contrib.tweetinputformat.model.places.Attributes.java</file>
      <file type="M">flink-contrib.flink-tweet-inputformat.src.main.java.org.apache.flink.contrib.tweetinputformat.io.TweetHandler.java</file>
      <file type="M">flink-contrib.flink-tweet-inputformat.src.main.java.org.apache.flink.contrib.tweetinputformat.io.SimpleTweetInputFormat.java</file>
      <file type="M">flink-contrib.flink-tweet-inputformat.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6711" opendate="2017-5-24 00:00:00" fixdate="2017-5-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Activate strict checkstyle for flink-connectors</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer08.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.test.java.org.apache.flink.test.hadoopcompatibility.mapred.wrapper.HadoopTupleUnwrappingIteratorTest.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.test.java.org.apache.flink.test.hadoopcompatibility.mapred.HadoopTestData.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.test.java.org.apache.flink.test.hadoopcompatibility.mapred.HadoopReduceFunctionITCase.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.test.java.org.apache.flink.test.hadoopcompatibility.mapred.HadoopReduceCombineFunctionITCase.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.test.java.org.apache.flink.test.hadoopcompatibility.mapred.HadoopMapredITCase.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.test.java.org.apache.flink.test.hadoopcompatibility.mapred.HadoopMapFunctionITCase.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.test.java.org.apache.flink.test.hadoopcompatibility.mapred.example.HadoopMapredCompatWordCount.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.test.java.org.apache.flink.test.hadoopcompatibility.mapreduce.HadoopInputOutputITCase.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.test.java.org.apache.flink.test.hadoopcompatibility.mapreduce.example.WordCount.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.test.java.org.apache.flink.hadoopcompatibility.HadoopUtilsTest.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.test.java.org.apache.flink.api.java.typeutils.WritableTypeInfoTest.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.test.java.org.apache.flink.api.java.typeutils.WritableInfoParserTest.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.test.java.org.apache.flink.api.java.typeutils.WritableExtractionTest.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.test.java.org.apache.flink.api.java.typeutils.runtime.WritableSerializerUUIDTest.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.test.java.org.apache.flink.api.java.typeutils.runtime.WritableSerializerTest.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.test.java.org.apache.flink.api.java.typeutils.runtime.WritableID.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.test.java.org.apache.flink.api.java.typeutils.runtime.WritableComparatorUUIDTest.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.test.java.org.apache.flink.api.java.typeutils.runtime.WritableComparatorTest.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.test.java.org.apache.flink.api.java.typeutils.runtime.StringArrayWritable.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.main.scala.org.apache.flink.hadoopcompatibility.scala.HadoopInputs.scala</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.main.java.org.apache.flink.hadoopcompatibility.mapred.wrapper.HadoopTupleUnwrappingIterator.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.main.java.org.apache.flink.hadoopcompatibility.mapred.wrapper.HadoopOutputCollector.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.main.java.org.apache.flink.hadoopcompatibility.mapred.HadoopReduceFunction.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.main.java.org.apache.flink.hadoopcompatibility.mapred.HadoopReduceCombineFunction.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.main.java.org.apache.flink.hadoopcompatibility.mapred.HadoopMapFunction.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.main.java.org.apache.flink.hadoopcompatibility.HadoopUtils.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.main.java.org.apache.flink.hadoopcompatibility.HadoopInputs.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.main.java.org.apache.flink.api.java.typeutils.WritableTypeInfo.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.main.java.org.apache.flink.api.java.typeutils.runtime.WritableSerializer.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.main.java.org.apache.flink.api.java.typeutils.runtime.WritableComparator.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-rabbitmq.src.test.java.org.apache.flink.streaming.connectors.rabbitmq.RMQSourceTest.java</file>
      <file type="M">flink-connectors.flink-connector-rabbitmq.src.test.java.org.apache.flink.streaming.connectors.rabbitmq.common.RMQSinkTest.java</file>
      <file type="M">flink-connectors.flink-connector-rabbitmq.src.test.java.org.apache.flink.streaming.connectors.rabbitmq.common.RMQConnectionConfigTest.java</file>
      <file type="M">flink-connectors.flink-connector-rabbitmq.src.main.java.org.apache.flink.streaming.connectors.rabbitmq.RMQSource.java</file>
      <file type="M">flink-connectors.flink-connector-rabbitmq.src.main.java.org.apache.flink.streaming.connectors.rabbitmq.RMQSink.java</file>
      <file type="M">flink-connectors.flink-connector-rabbitmq.src.main.java.org.apache.flink.streaming.connectors.rabbitmq.common.RMQConnectionConfig.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch.src.test.java.org.apache.flink.streaming.connectors.elasticsearch.examples.ElasticsearchSinkExample.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch.src.test.java.org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkITCase.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch.src.main.java.org.apache.flink.streaming.connectors.elasticsearch.IndexRequestBuilder.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch.src.main.java.org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSink.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch.src.main.java.org.apache.flink.streaming.connectors.elasticsearch.Elasticsearch1ApiCallBridge.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch5.src.test.java.org.apache.flink.streaming.connectors.elasticsearch.EmbeddedElasticsearchNodeEnvironmentImpl.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch5.src.test.java.org.apache.flink.streaming.connectors.elasticsearch5.examples.ElasticsearchSinkExample.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch5.src.test.java.org.apache.flink.streaming.connectors.elasticsearch5.ElasticsearchSinkITCase.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch5.src.main.java.org.apache.flink.streaming.connectors.elasticsearch5.ElasticsearchSink.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch5.src.main.java.org.apache.flink.streaming.connectors.elasticsearch5.Elasticsearch5ApiCallBridge.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch2.src.test.java.org.apache.flink.streaming.connectors.elasticsearch.EmbeddedElasticsearchNodeEnvironmentImpl.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch2.src.test.java.org.apache.flink.streaming.connectors.elasticsearch2.examples.ElasticsearchSinkExample.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch2.src.test.java.org.apache.flink.streaming.connectors.elasticsearch2.ElasticsearchSinkITCase.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch2.src.main.java.org.apache.flink.streaming.connectors.elasticsearch2.RequestIndexer.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch2.src.main.java.org.apache.flink.streaming.connectors.elasticsearch2.ElasticsearchSinkFunction.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch2.src.main.java.org.apache.flink.streaming.connectors.elasticsearch2.ElasticsearchSink.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch2.src.main.java.org.apache.flink.streaming.connectors.elasticsearch2.Elasticsearch2ApiCallBridge.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch2.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch-base.src.test.java.org.apache.flink.streaming.connectors.elasticsearch.testutils.SourceSinkDataTestKit.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch-base.src.test.java.org.apache.flink.streaming.connectors.elasticsearch.EmbeddedElasticsearchNodeEnvironment.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch-base.src.test.java.org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkTestBase.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch-base.src.test.java.org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBaseTest.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch-base.src.main.java.org.apache.flink.streaming.connectors.elasticsearch.util.RetryRejectedExecutionFailureHandler.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch-base.src.main.java.org.apache.flink.streaming.connectors.elasticsearch.util.NoOpFailureHandler.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch-base.src.main.java.org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkFunction.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch-base.src.main.java.org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch-base.src.main.java.org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchApiCallBridge.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch-base.src.main.java.org.apache.flink.streaming.connectors.elasticsearch.ActionRequestFailureHandler.java</file>
      <file type="M">flink-connectors.flink-avro.src.test.resources.avro.user.avsc</file>
      <file type="M">flink-connectors.flink-avro.src.test.java.org.apache.flink.api.java.io.AvroOutputFormatTest.java</file>
      <file type="M">flink-connectors.flink-avro.src.test.java.org.apache.flink.api.java.io.AvroInputFormatTypeExtractionTest.java</file>
      <file type="M">flink-connectors.flink-avro.src.test.java.org.apache.flink.api.io.avro.example.AvroTypeExample.java</file>
      <file type="M">flink-connectors.flink-avro.src.test.java.org.apache.flink.api.io.avro.AvroSplittableInputFormatTest.java</file>
      <file type="M">flink-connectors.flink-avro.src.test.java.org.apache.flink.api.io.avro.AvroRecordInputFormatTest.java</file>
      <file type="M">flink-connectors.flink-avro.src.test.java.org.apache.flink.api.io.avro.AvroPojoTest.java</file>
      <file type="M">flink-connectors.flink-avro.src.test.java.org.apache.flink.api.avro.testjar.AvroExternalJarProgram.java</file>
      <file type="M">flink-connectors.flink-avro.src.test.java.org.apache.flink.api.avro.EncoderDecoderTest.java</file>
      <file type="M">flink-connectors.flink-avro.src.test.java.org.apache.flink.api.avro.AvroOutputFormatITCase.java</file>
      <file type="M">flink-connectors.flink-avro.src.test.java.org.apache.flink.api.avro.AvroExternalJarProgramITCase.java</file>
      <file type="M">flink-connectors.flink-avro.src.test.assembly.test-assembly.xml</file>
      <file type="M">flink-connectors.flink-avro.src.main.java.org.apache.flink.api.java.io.AvroOutputFormat.java</file>
      <file type="M">flink-connectors.flink-avro.src.main.java.org.apache.flink.api.java.io.AvroInputFormat.java</file>
      <file type="M">flink-connectors.flink-avro.src.main.java.org.apache.flink.api.avro.FSDataInputStreamWrapper.java</file>
      <file type="M">flink-connectors.flink-avro.src.main.java.org.apache.flink.api.avro.DataOutputEncoder.java</file>
      <file type="M">flink-connectors.flink-avro.src.main.java.org.apache.flink.api.avro.DataInputDecoder.java</file>
      <file type="M">flink-connectors.flink-avro.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.testutils.TestableKinesisDataFetcher.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.testutils.TestableFlinkKinesisConsumer.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.testutils.KinesisShardIdGenerator.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.testutils.KinesisEventsGeneratorProducerThread.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.testutils.FakeKinesisBehavioursFactory.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.testutils.ExactlyOnceValidatingConsumerThread.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.proxy.KinesisProxyTest.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.manualtests.ManualExactlyOnceWithStreamReshardingTest.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.manualtests.ManualExactlyOnceTest.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.manualtests.ManualConsumerProducerTest.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.internals.ShardConsumerTest.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.internals.KinesisDataFetcherTest.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.FlinkKinesisConsumerTest.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.FlinkKinesisConsumerMigrationTest.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.util.KinesisConfigUtil.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.util.AWSUtil.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.serialization.KinesisSerializationSchema.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.serialization.KinesisDeserializationSchemaWrapper.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.serialization.KinesisDeserializationSchema.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.proxy.KinesisProxyInterface.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.proxy.KinesisProxy.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.proxy.GetShardListResult.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.model.StreamShardHandle.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.model.SentinelSequenceNumber.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.model.KinesisStreamShardState.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.model.KinesisStreamShard.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.KinesisPartitioner.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.internals.ShardConsumer.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.internals.KinesisDataFetcher.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.FlinkKinesisProducer.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.FlinkKinesisConsumer.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.examples.ProduceIntoKinesis.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.examples.ConsumeFromKinesis.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.config.ProducerConfigConstants.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.config.ConsumerConfigConstants.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.config.AWSConfigConstants.java</file>
      <file type="M">flink-connectors.flink-hcatalog.src.main.scala.org.apache.flink.hcatalog.scala.HCatInputFormat.scala</file>
      <file type="M">flink-connectors.flink-hcatalog.src.main.java.org.apache.flink.hcatalog.java.HCatInputFormat.java</file>
      <file type="M">flink-connectors.flink-hcatalog.src.main.java.org.apache.flink.hcatalog.HCatInputFormatBase.java</file>
      <file type="M">flink-connectors.flink-hcatalog.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-twitter.src.main.java.org.apache.flink.streaming.connectors.twitter.TwitterSource.java</file>
      <file type="M">flink-connectors.flink-connector-twitter.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.manualtests.ManualProducerTest.java</file>
      <file type="M">flink-connectors.flink-connector-nifi.src.test.java.org.apache.flink.streaming.connectors.nifi.examples.NiFiSourceTopologyExample.java</file>
      <file type="M">flink-connectors.flink-connector-nifi.src.test.java.org.apache.flink.streaming.connectors.nifi.examples.NiFiSinkTopologyExample.java</file>
      <file type="M">flink-connectors.flink-connector-nifi.src.main.java.org.apache.flink.streaming.connectors.nifi.StandardNiFiDataPacket.java</file>
      <file type="M">flink-connectors.flink-connector-nifi.src.main.java.org.apache.flink.streaming.connectors.nifi.NiFiSource.java</file>
      <file type="M">flink-connectors.flink-connector-nifi.src.main.java.org.apache.flink.streaming.connectors.nifi.NiFiSink.java</file>
      <file type="M">flink-connectors.flink-connector-nifi.src.main.java.org.apache.flink.streaming.connectors.nifi.NiFiDataPacketBuilder.java</file>
      <file type="M">flink-connectors.flink-connector-nifi.src.main.java.org.apache.flink.streaming.connectors.nifi.NiFiDataPacket.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.test.resources.log4j-test.properties</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.test.resources.log4j-test.properties</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.test.java.org.apache.flink.streaming.connectors.fs.RollingSinkSecuredITCase.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.test.java.org.apache.flink.streaming.connectors.fs.RollingSinkITCase.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.test.java.org.apache.flink.streaming.connectors.fs.RollingSinkFaultToleranceITCase.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.test.java.org.apache.flink.streaming.connectors.fs.bucketing.RollingToBucketingMigrationTest.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.test.java.org.apache.flink.streaming.connectors.fs.bucketing.RollingSinkMigrationTest.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.test.java.org.apache.flink.streaming.connectors.fs.bucketing.BucketingSinkTest.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.test.java.org.apache.flink.streaming.connectors.fs.bucketing.BucketingSinkFrom12MigrationTest.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.test.java.org.apache.flink.streaming.connectors.fs.bucketing.BucketingSinkFaultToleranceITCase.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.main.java.org.apache.flink.streaming.connectors.fs.Writer.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.main.java.org.apache.flink.streaming.connectors.fs.SystemClock.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.main.java.org.apache.flink.streaming.connectors.fs.StringWriter.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.main.java.org.apache.flink.streaming.connectors.fs.StreamWriterBase.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.main.java.org.apache.flink.streaming.connectors.fs.SequenceFileWriter.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.main.java.org.apache.flink.streaming.connectors.fs.RollingSink.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.main.java.org.apache.flink.streaming.connectors.fs.NonRollingBucketer.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.main.java.org.apache.flink.streaming.connectors.fs.DateTimeBucketer.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.main.java.org.apache.flink.streaming.connectors.fs.Clock.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.main.java.org.apache.flink.streaming.connectors.fs.bucketing.DateTimeBucketer.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.main.java.org.apache.flink.streaming.connectors.fs.bucketing.BucketingSink.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.main.java.org.apache.flink.streaming.connectors.fs.bucketing.Bucketer.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.main.java.org.apache.flink.streaming.connectors.fs.bucketing.BasePathBucketer.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.main.java.org.apache.flink.streaming.connectors.fs.Bucketer.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.main.java.org.apache.flink.streaming.connectors.fs.AvroKeyValueSinkWriter.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.pom.xml</file>
      <file type="M">flink-connectors.pom.xml</file>
      <file type="M">flink-connectors.flink-hbase.src.test.resources.log4j-test.properties</file>
      <file type="M">flink-connectors.flink-hbase.src.test.java.org.apache.flink.addons.hbase.HBaseTestingClusterAutostarter.java</file>
      <file type="M">flink-connectors.flink-hbase.src.test.java.org.apache.flink.addons.hbase.HBaseConnectorITCase.java</file>
      <file type="M">flink-connectors.flink-hbase.src.test.java.org.apache.flink.addons.hbase.example.HBaseWriteStreamExample.java</file>
      <file type="M">flink-connectors.flink-hbase.src.test.java.org.apache.flink.addons.hbase.example.HBaseWriteExample.java</file>
      <file type="M">flink-connectors.flink-hbase.src.test.java.org.apache.flink.addons.hbase.example.HBaseReadExample.java</file>
      <file type="M">flink-connectors.flink-hbase.src.test.java.org.apache.flink.addons.hbase.example.HBaseFlinkTestConstants.java</file>
      <file type="M">flink-connectors.flink-hbase.src.main.java.org.apache.flink.addons.hbase.TableInputSplit.java</file>
      <file type="M">flink-connectors.flink-hbase.src.main.java.org.apache.flink.addons.hbase.TableInputFormat.java</file>
      <file type="M">flink-connectors.flink-hbase.src.main.java.org.apache.flink.addons.hbase.HBaseTableSource.java</file>
      <file type="M">flink-connectors.flink-hbase.src.main.java.org.apache.flink.addons.hbase.HBaseTableSchema.java</file>
      <file type="M">flink-connectors.flink-hbase.src.main.java.org.apache.flink.addons.hbase.HBaseRowInputFormat.java</file>
      <file type="M">flink-connectors.flink-hbase.src.main.java.org.apache.flink.addons.hbase.AbstractTableInputFormat.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.resources.log4j-test.properties</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.testutils.ZooKeeperStringSerializer.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.testutils.ValidatingExactlyOnceSink.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.testutils.Tuple2FlinkPartitioner.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.testutils.ThrottledMapper.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.testutils.PartitionValidatingMapper.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.testutils.JobManagerCommunicationUtils.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.testutils.FakeStandardProducerConfig.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.testutils.FailingIdentityMapper.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.testutils.DataGenerators.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.testutils.AvroTestUtils.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.TestFlinkFixedPartitioner.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaTestEnvironment.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaTestBase.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaTableSourceTestBase.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaTableSinkTestBase.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaShortRetentionTestBase.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaProducerTestBase.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaConsumerTestBase.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaConsumerPartitionAssignmentTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.JsonRowSerializationSchemaTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.JsonRowDeserializationSchemaTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.JSONKeyValueDeserializationSchemaTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.JSONDeserializationSchemaTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcherTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducerBaseTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBaseTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBaseFrom12MigrationTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBaseFrom11MigrationTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.AvroRowDeSerializationSchemaTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.util.serialization.TypeInformationKeyValueSerializationSchema.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.util.serialization.KeyedSerializationSchemaWrapper.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.util.serialization.KeyedSerializationSchema.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.util.serialization.KeyedDeserializationSchemaWrapper.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.util.serialization.KeyedDeserializationSchema.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.util.serialization.JsonRowSerializationSchema.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.util.serialization.JsonRowDeserializationSchema.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.util.serialization.JSONDeserializationSchema.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.util.serialization.AvroRowSerializationSchema.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.util.serialization.AvroRowDeserializationSchema.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.partitioner.FlinkKafkaDelegatePartitioner.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.partitioner.FlinkFixedPartitioner.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.KafkaTableSource.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.KafkaTableSink.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.KafkaJsonTableSource.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.KafkaJsonTableSink.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.KafkaAvroTableSource.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionStateWithPunctuatedWatermarks.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionStateWithPeriodicWatermarks.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionStateSentinel.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionState.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.ExceptionProxy.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducerBase.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.config.StartupMode.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.config.OffsetCommitMode.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.test.resources.log4j-test.properties</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaTestEnvironmentImpl.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaProducerTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka09SecuredRunITCase.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka09ProducerITCase.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka09JsonTableSourceTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka09JsonTableSinkTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka09ITCase.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka09FetcherTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka09AvroTableSourceTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.test.java.org.apache.flink.streaming.connectors.kafka.internal.HandoverTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.resources.log4j.properties</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.Kafka09TableSource.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.Kafka09JsonTableSource.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.Kafka09JsonTableSink.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.Kafka09AvroTableSource.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerCallBridge.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.internal.Kafka09Fetcher.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.internal.Handover.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer09.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer09.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaTestEnvironmentImpl.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaShortRetention08ITCase.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaProducerTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaLocalSystemTime.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaConsumer08Test.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka08ProducerITCase.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka08JsonTableSourceTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka08JsonTableSinkTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka08ITCase.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka08AvroTableSourceTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.internals.ClosableBlockingQueueTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.Kafka08TableSource.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.Kafka08JsonTableSource.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.Kafka08JsonTableSink.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.Kafka08AvroTableSource.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.ZookeeperOffsetHandler.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.SimpleConsumerThread.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.PeriodicOffsetCommitter.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.PartitionInfoFetcher.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.KillerWatchDog.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.Kafka08Fetcher.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.ClosableBlockingQueue.java</file>
      <file type="M">flink-connectors.flink-connector-cassandra.src.main.java.org.apache.flink.batch.connectors.cassandra.CassandraInputFormat.java</file>
      <file type="M">flink-connectors.flink-connector-cassandra.src.main.java.org.apache.flink.batch.connectors.cassandra.CassandraOutputFormat.java</file>
      <file type="M">flink-connectors.flink-connector-cassandra.src.main.java.org.apache.flink.streaming.connectors.cassandra.AbstractCassandraTupleSink.java</file>
      <file type="M">flink-connectors.flink-connector-cassandra.src.main.java.org.apache.flink.streaming.connectors.cassandra.CassandraCommitter.java</file>
      <file type="M">flink-connectors.flink-connector-cassandra.src.main.java.org.apache.flink.streaming.connectors.cassandra.CassandraPojoSink.java</file>
      <file type="M">flink-connectors.flink-connector-cassandra.src.main.java.org.apache.flink.streaming.connectors.cassandra.CassandraScalaProductSink.java</file>
      <file type="M">flink-connectors.flink-connector-cassandra.src.main.java.org.apache.flink.streaming.connectors.cassandra.CassandraSink.java</file>
      <file type="M">flink-connectors.flink-connector-cassandra.src.main.java.org.apache.flink.streaming.connectors.cassandra.CassandraSinkBase.java</file>
      <file type="M">flink-connectors.flink-connector-cassandra.src.main.java.org.apache.flink.streaming.connectors.cassandra.CassandraTupleWriteAheadSink.java</file>
      <file type="M">flink-connectors.flink-connector-cassandra.src.main.java.org.apache.flink.streaming.connectors.cassandra.ClusterBuilder.java</file>
      <file type="M">flink-connectors.flink-connector-cassandra.src.test.java.org.apache.flink.batch.connectors.cassandra.example.BatchExample.java</file>
      <file type="M">flink-connectors.flink-connector-cassandra.src.test.java.org.apache.flink.streaming.connectors.cassandra.CassandraConnectorITCase.java</file>
      <file type="M">flink-connectors.flink-connector-cassandra.src.test.java.org.apache.flink.streaming.connectors.cassandra.CassandraTupleWriteAheadSinkTest.java</file>
      <file type="M">flink-connectors.flink-connector-cassandra.src.test.java.org.apache.flink.streaming.connectors.cassandra.example.CassandraPojoSinkExample.java</file>
      <file type="M">flink-connectors.flink-connector-cassandra.src.test.java.org.apache.flink.streaming.connectors.cassandra.example.CassandraTupleSinkExample.java</file>
      <file type="M">flink-connectors.flink-connector-cassandra.src.test.java.org.apache.flink.streaming.connectors.cassandra.example.CassandraTupleWriteAheadSinkExample.java</file>
      <file type="M">flink-connectors.flink-connector-cassandra.src.test.java.org.apache.flink.streaming.connectors.cassandra.example.Message.java</file>
      <file type="M">flink-connectors.flink-connector-cassandra.src.test.java.org.apache.flink.streaming.connectors.cassandra.Pojo.java</file>
      <file type="M">flink-connectors.flink-connector-cassandra.src.test.resources.log4j-test.properties</file>
      <file type="M">flink-connectors.flink-jdbc.pom.xml</file>
      <file type="M">flink-connectors.flink-jdbc.src.main.java.org.apache.flink.api.java.io.jdbc.JDBCInputFormat.java</file>
      <file type="M">flink-connectors.flink-jdbc.src.main.java.org.apache.flink.api.java.io.jdbc.JDBCOutputFormat.java</file>
      <file type="M">flink-connectors.flink-jdbc.src.main.java.org.apache.flink.api.java.io.jdbc.split.GenericParameterValuesProvider.java</file>
      <file type="M">flink-connectors.flink-jdbc.src.main.java.org.apache.flink.api.java.io.jdbc.split.NumericBetweenParametersProvider.java</file>
      <file type="M">flink-connectors.flink-jdbc.src.main.java.org.apache.flink.api.java.io.jdbc.split.ParameterValuesProvider.java</file>
      <file type="M">flink-connectors.flink-jdbc.src.test.java.org.apache.flink.api.java.io.jdbc.JDBCFullTest.java</file>
      <file type="M">flink-connectors.flink-jdbc.src.test.java.org.apache.flink.api.java.io.jdbc.JDBCInputFormatTest.java</file>
      <file type="M">flink-connectors.flink-jdbc.src.test.java.org.apache.flink.api.java.io.jdbc.JDBCOutputFormatTest.java</file>
      <file type="M">flink-connectors.flink-jdbc.src.test.java.org.apache.flink.api.java.io.jdbc.JDBCTestBase.java</file>
      <file type="M">flink-connectors.flink-jdbc.src.test.resources.log4j-test.properties</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer010.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer010.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.main.java.org.apache.flink.streaming.connectors.kafka.internal.Kafka010Fetcher.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.main.java.org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerCallBridge010.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.main.java.org.apache.flink.streaming.connectors.kafka.Kafka010AvroTableSource.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.main.java.org.apache.flink.streaming.connectors.kafka.Kafka010JsonTableSource.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.main.java.org.apache.flink.streaming.connectors.kafka.Kafka010TableSource.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.main.resources.log4j.properties</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka010AvroTableSourceTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka010FetcherTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka010ITCase.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka010JsonTableSourceTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka010ProducerITCase.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaTestEnvironmentImpl.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer08.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer081.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer082.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer.java</file>
    </fixedFiles>
  </bug>
  <bug id="6714" opendate="2017-5-25 00:00:00" fixdate="2017-5-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Operator state backend should set user classloader as context classloader when snapshotting</summary>
      <description>Now that the operator state backend creates a deep copy of the state during the synchronous part of async checkpoints, it needs to set the user classloader as the thread context classloader, otherwise serializers that uses serialization for copying will use the wrong classloader when deserializing the copy.</description>
      <version>None</version>
      <fixedVersion>1.3.0,1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.OperatorStateBackendTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.DefaultOperatorStateBackend.java</file>
    </fixedFiles>
  </bug>
  <bug id="6715" opendate="2017-5-25 00:00:00" fixdate="2017-5-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Activate strict checkstyle in for flink-mesos</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-mesos.src.test.java.org.apache.flink.mesos.runtime.clusterframework.MesosTaskManagerParametersTest.java</file>
      <file type="M">flink-mesos.src.test.java.org.apache.flink.mesos.runtime.clusterframework.MesosFlinkResourceManagerTest.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.util.ZooKeeperUtils.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.util.MesosConfiguration.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.util.MesosArtifactServer.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.util.MesosArtifactResolver.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.Utils.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.scheduler.TaskSchedulerBuilder.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.scheduler.SchedulerProxy.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.scheduler.messages.ResourceOffers.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.runtime.clusterframework.store.ZooKeeperMesosWorkerStore.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.runtime.clusterframework.store.StandaloneMesosWorkerStore.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.runtime.clusterframework.store.MesosWorkerStore.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.runtime.clusterframework.services.StandaloneMesosServices.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.runtime.clusterframework.services.MesosServicesUtils.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.runtime.clusterframework.MesosTaskManagerRunner.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.runtime.clusterframework.MesosTaskManagerParameters.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.runtime.clusterframework.MesosFlinkResourceManager.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.runtime.clusterframework.MesosConfigKeys.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.runtime.clusterframework.MesosApplicationMasterRunner.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.runtime.clusterframework.LaunchableMesosWorker.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.cli.FlinkMesosSessionCli.java</file>
      <file type="M">flink-mesos.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6728" opendate="2017-5-26 00:00:00" fixdate="2017-5-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Activate strict checkstyle for flink-quickstart</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-quickstart.pom.xml</file>
      <file type="M">flink-quickstart.flink-quickstart-scala.src.test.resources.projects.testArtifact.archetype.properties</file>
      <file type="M">flink-quickstart.flink-quickstart-scala.src.main.java.org.apache.flink.quickstart.Dummy.java</file>
      <file type="M">flink-quickstart.flink-quickstart-java.src.test.resources.projects.testArtifact.archetype.properties</file>
      <file type="M">flink-quickstart.flink-quickstart-java.src.main.resources.archetype-resources.src.main.java.WordCount.java</file>
      <file type="M">flink-quickstart.flink-quickstart-java.src.main.resources.archetype-resources.src.main.java.StreamingJob.java</file>
      <file type="M">flink-quickstart.flink-quickstart-java.src.main.resources.archetype-resources.src.main.java.SocketTextStreamWordCount.java</file>
      <file type="M">flink-quickstart.flink-quickstart-java.src.main.resources.archetype-resources.src.main.java.BatchJob.java</file>
      <file type="M">flink-quickstart.flink-quickstart-java.src.main.java.org.apache.flink.quickstart.Dummy.java</file>
    </fixedFiles>
  </bug>
  <bug id="6729" opendate="2017-5-26 00:00:00" fixdate="2017-1-26 01:00:00" resolution="Won&amp;#39;t Fix">
    <buginformation>
      <summary>Activate strict checkstyle for flink-runtime</summary>
      <description>Long term issue for incrementally introducing the strict checkstyle to flink-runtime.As proposed in https://github.com/apache/flink/pull/4032 we will introduce the checkstyle incrementally by package.The following is a list of all packages under org/apache/flink/runtime and their respective checkstyle violations:akka 25blob 140broadcast 94checkpoint 381client 83clusterframework 281concurrent 33deployment 27event 17execution 74executiongraph 881filecache 33fs 62heartbeat 30highavailability 94instance 370io 1592iterative 316jobgraph 283jobmanager 717jobmaster 84leaderelection 54leaderretrieval 11memory 249messages 135minicluster 53net 46operators 7953plugable 27process 1query 106registration 43resourcemanager 114rpc 127security 58state 463taskexecutor 153taskmanager 343testutils 204util 536metrics, history and webmonitor are excluded from this list, as I'm not aware of any large-scale issue/feature branch for any of then.There are a number of low-hanging fruits in there for which we could apply the checkstyle regardless of current efforts in there, like process, or leaderretrieval.I will reach out to committers that are active in the runtime components to see which of these we could modify without causing to much problems.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.accumulators.StringifiedAccumulatorResultTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.accumulators.StringifiedAccumulatorResult.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.accumulators.AccumulatorRegistry.java</file>
      <file type="M">flink-runtime.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6731" opendate="2017-5-26 00:00:00" fixdate="2017-7-26 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Activate strict checkstyle for flink-tests</summary>
      <description>Long term issue for incrementally introducing the strict checkstyle to flink-tests.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.completeness.TypeInfoTestCoverageTest.java</file>
      <file type="M">flink-tests.src.test.scala.org.apache.flink.api.scala.operators.GroupCombineITCase.scala</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.windowing.sessionwindows.TestEventPayload.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.windowing.sessionwindows.SessionWindowITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.windowing.sessionwindows.SessionGeneratorConfiguration.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.windowing.sessionwindows.SessionEventGeneratorImpl.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.windowing.sessionwindows.SessionEvent.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.windowing.sessionwindows.SessionConfiguration.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.windowing.sessionwindows.ParallelSessionsEventGenerator.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.windowing.sessionwindows.LongRandomGenerator.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.windowing.sessionwindows.GeneratorEventFactory.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.windowing.sessionwindows.GeneratorConfiguration.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.windowing.sessionwindows.EventGeneratorFactory.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.windowing.sessionwindows.EventGenerator.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.util.UniformIntTupleGeneratorInputFormat.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.util.TestUtils.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.util.PointInFormat.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.util.PointFormatter.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.util.InfiniteIntegerTupleInputFormat.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.util.InfiniteIntegerInputFormat.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.util.DataSetUtilsITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.util.CoordVector.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.typeserializerupgrade.PojoSerializerUpgradeTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.testfunctions.Tokenizer.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.runtime.WindowFoldITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.runtime.util.TestListWrapper.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.runtime.util.TestListResultSink.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.runtime.util.ReceiveCheckNoOpSink.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.runtime.util.NoOpIntMap.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.runtime.util.EvenOddOutputSelector.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.runtime.TimestampITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.runtime.StreamTaskTimerITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.runtime.StateBackendITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.runtime.SideOutputITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.runtime.SelfConnectionITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.runtime.PartitionerITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.runtime.OutputSplitterITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.runtime.IterateITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.runtime.DirectedOutputITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.runtime.DataStreamPojoITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.runtime.CoStreamITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.runtime.CoGroupJoinITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.runtime.ChainedRuntimeContextITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.api.StreamingOperatorsITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.api.outputformat.TextOutputFormatITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.api.outputformat.CsvOutputFormatITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.state.StateHandleSerializationTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.state.operator.restore.unkeyed.NonKeyedJob.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.state.operator.restore.unkeyed.ChainUnionTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.state.operator.restore.unkeyed.ChainOrderTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.state.operator.restore.unkeyed.ChainLengthIncreaseTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.state.operator.restore.unkeyed.ChainLengthDecreaseTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.state.operator.restore.unkeyed.ChainBreakTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.state.operator.restore.unkeyed.AbstractNonKeyedOperatorRestoreTestBase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.state.operator.restore.keyed.KeyedJob.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.state.operator.restore.keyed.KeyedComplexChainTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.state.operator.restore.ExecutionMode.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.state.operator.restore.AbstractOperatorRestoreTestBase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.state.ManualWindowSpeedITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.runtime.SelfJoinDeadlockITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.runtime.RegisterTypeWithKryoSerializerITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.runtime.NetworkStackThroughputITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.runtime.minicluster.LocalFlinkMiniClusterITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.runtime.leaderelection.ZooKeeperLeaderElectionITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.runtime.JoinDeadlockITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.runtime.IPv6HostnamesITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.runtime.ConsumePipelinedAndBlockingResultITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.recovery.TaskManagerProcessFailureStreamingRecoveryITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.recovery.TaskManagerProcessFailureBatchRecoveryITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.recovery.TaskManagerFailureRecoveryITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.recovery.SimpleRecoveryITCaseBase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.recovery.SimpleRecoveryFixedDelayRestartStrategyITBase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.recovery.SimpleRecoveryFailureRateStrategyITBase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.recovery.ProcessFailureCancelingITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.recovery.JobManagerHAProcessFailureBatchRecoveryITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.recovery.JobManagerHAJobGraphRecoveryITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.recovery.JobManagerHACheckpointRecoveryITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.recovery.FastFailuresITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.recovery.AbstractTaskManagerProcessFailureRecoveryTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.query.QueryableStateITCaseRocksDBBackend.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.query.QueryableStateITCaseFsBackend.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.query.KVStateRequestSerializerRocksDBTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.query.AbstractQueryableStateITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.optimizer.jsonplan.PreviewPlanDumpTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.optimizer.jsonplan.JsonJobGraphGenerationTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.optimizer.jsonplan.DumpCompiledPlanTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.optimizer.iterations.PageRankCompilerTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.optimizer.iterations.MultipleJoinsWithSolutionSetCompilerTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.optimizer.iterations.ConnectedComponentsCoGroupTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.optimizer.examples.WordCountCompilerTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.optimizer.examples.RelationalQueryCompilerTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.optimizer.examples.KMeansSingleStepTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.misc.SuccessAfterNetworkBuffersFailureITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.misc.MiscellaneousIssuesITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.misc.GenericTypeInfoTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.misc.CustomSerializationITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.misc.CustomPartitioningITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.misc.AutoParallelismITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.manual.StreamingScalabilityAndLatency.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.manual.ReducePerformance.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.manual.package-info.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.manual.OverwriteObjects.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.manual.NotSoMiniClusterIterations.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.manual.MassiveStringValueSorting.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.manual.MassiveStringSorting.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.manual.HashTableRecordWidthCombinations.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.manual.CheckForbiddenMethodsUsage.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.util.ValueCollectionDataSets.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.util.CollectionDataSets.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.UnionITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.TypeHintITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.SumMinMaxITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.SortPartitionITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.SampleITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.ReplicatingDataSourceITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.RemoteEnvironmentITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.ReduceWithCombinerITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.ReduceITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.ProjectITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.PartitionITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.OuterJoinITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.ObjectReuseITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.MapPartitionITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.MapITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.JoinITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.GroupReduceITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.GroupCombineITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.FlatMapITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.FirstNITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.FilterITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.ExecutionEnvironmentITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.DistinctITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.DataSourceITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.DataSinkITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.CustomDistributionITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.CrossITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.CoGroupITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.CoGroupGroupSortITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.AggregateITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.UnionStaticDynamicIterationITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.StaticlyNestedIterationsITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.SolutionSetDuplicatesITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.MultipleSolutionSetJoinsITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.KMeansWithBroadcastSetITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.IterationWithUnionITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.IterationWithChainingITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.IterationWithAllReducerITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.IterationTerminationWithTwoTails.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.IterationTerminationWithTerminationTail.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.IterationIncompleteStaticPathConsumptionITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.IterationIncompleteDynamicPathConsumptionITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.IdentityIterationITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.EmptyWorksetIterationITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.DependencyConnectedComponentsITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.DeltaIterationNotDependingOnSolutionSetITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.DanglingPageRankITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.ConnectedComponentsWithSolutionSetFirstITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.ConnectedComponentsWithObjectMapITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.ConnectedComponentsWithDeferredUpdateITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.ConnectedComponentsITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.CoGroupConnectedComponentsSecondITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.CoGroupConnectedComponentsITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.BulkIterationWithAllReducerITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.aggregators.AggregatorsITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.aggregators.AggregatorConvergenceITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.io.RichInputOutputITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.io.InputOutputITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.io.CsvReaderITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.hadoop.mapred.WordCountMapredITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.hadoop.mapred.HadoopIOFormatsITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.hadoop.mapreduce.WordCountMapreduceITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.failingPrograms.TaskFailureITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.failingPrograms.JobSubmissionFailsITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.exampleScalaPrograms.WordCountITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.exampleScalaPrograms.WebLogAnalysisITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.exampleScalaPrograms.TransitiveClosureITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.exampleScalaPrograms.PageRankITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.exampleScalaPrograms.EnumTriangleITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.exampleScalaPrograms.ConnectedComponentsITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.exampleJavaPrograms.WordCountWithCollectionITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.exampleJavaPrograms.WordCountSubclassPOJOITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.exampleJavaPrograms.WordCountSubclassInterfacePOJOITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.exampleJavaPrograms.WordCountSimplePOJOITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.exampleJavaPrograms.WordCountNestedPOJOITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.exampleJavaPrograms.WordCountITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.exampleJavaPrograms.WebLogAnalysisITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.exampleJavaPrograms.TransitiveClosureITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.exampleJavaPrograms.PageRankITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.exampleJavaPrograms.EnumTriangleBasicITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.exampleJavaPrograms.ConnectedComponentsITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.distributedCache.DistributedCacheTest.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.table.api.java.batch.sql.GroupingSetsITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.table.api.java.batch.sql.SqlITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.table.api.java.batch.TableEnvironmentITCase.java</file>
      <file type="M">flink-tests.pom.xml</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.accumulators.AccumulatorErrorITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.accumulators.AccumulatorITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.accumulators.AccumulatorIterativeITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.accumulators.AccumulatorLiveITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.actions.CountCollectITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.broadcastvars.BroadcastBranchingITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.broadcastvars.BroadcastUnionITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.broadcastvars.BroadcastVarInitializationITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.cancelling.CancelingTestBase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.cancelling.JoinCancelingITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.cancelling.MapCancelingITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.AbstractEventTimeWindowCheckpointingITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.AsyncFileBackendEventTimeWindowCheckpointingITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.AsyncMemBackendEventTimeWindowCheckpointingITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.ContinuousFileProcessingCheckpointITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.CoStreamCheckpointingITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.EventTimeAllWindowCheckpointingITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.FileBackendEventTimeWindowCheckpointingITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.IncrementalRocksDbBackendEventTimeWindowCheckpointingITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.KeyedStateCheckpointingITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.MemBackendEventTimeWindowCheckpointingITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.RescalingITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.RocksDbBackendEventTimeWindowCheckpointingITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.SavepointITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.StateCheckpointedITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.StreamCheckpointingITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.StreamCheckpointNotifierITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.StreamFaultToleranceTestBase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.TimestampedFileInputSplitTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.UdfStreamOperatorCheckpointingITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.utils.SavepointMigrationTestBase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.utils.StatefulJobSavepointFrom11MigrationITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.utils.StatefulJobSavepointFrom12MigrationITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.WindowCheckpointingITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.classloading.ClassLoaderITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.classloading.jar.CheckpointedStreamingProgram.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.classloading.jar.CheckpointingCustomKvStateProgram.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.classloading.jar.CustomInputSplitProgram.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.classloading.jar.CustomKvStateProgram.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.classloading.jar.KMeansForTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.classloading.jar.LegacyCheckpointedStreamingProgram.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.classloading.jar.StreamingCustomInputSplitProgram.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.classloading.jar.StreamingProgram.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.classloading.jar.UserCodeType.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.clients.examples.JobRetrievalITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.clients.examples.LocalExecutorITCase.java</file>
    </fixedFiles>
  </bug>
  <bug id="6732" opendate="2017-5-26 00:00:00" fixdate="2017-7-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Activate strict checkstyle for flink-java</summary>
      <description>Long term issue for incrementally introducing the strict checkstyle to flink-java.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.maven.suppressions-java.xml</file>
      <file type="M">flink-java.pom.xml</file>
      <file type="M">docs.internals.ide.setup.md</file>
    </fixedFiles>
  </bug>
  <bug id="6769" opendate="2017-5-30 00:00:00" fixdate="2017-6-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace usage of deprecated FileSystem#create(Path, boolean)</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.filesystem.FsCheckpointStateOutputStreamTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.checkpoint.savepoint.SavepointStoreTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.checkpoint.savepoint.MigrationV0ToV1Test.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.zookeeper.filesystem.FileSystemStateStorageHelper.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.filesystem.FsCheckpointStreamFactory.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.filecache.FileCache.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.FileSystemBlobStore.java</file>
      <file type="M">flink-fs-tests.src.test.java.org.apache.flink.hdfstests.HDFSTest.java</file>
      <file type="M">flink-examples.flink-examples-batch.src.main.java.org.apache.flink.examples.java.distcp.DistCp.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.core.fs.SafetyNetCloseableRegistryTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.core.fs.InitOutputPathTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="6776" opendate="2017-5-30 00:00:00" fixdate="2017-6-30 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Use skip instead of seek for small forward repositioning in DFS streams</summary>
      <description>Reading checkpoint meta data and finding key-groups in restores sometimes require to seek in input streams. Currently, we always use a seek, even for small position changes. As small true seeks are far more expensive than small reads/skips, we should just skip over small gaps instead of performing the seek.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.fs.hdfs.HadoopDataInputStream.java</file>
    </fixedFiles>
  </bug>
  <bug id="6777" opendate="2017-5-30 00:00:00" fixdate="2017-5-30 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Activate strict checkstyle for flink-scala-shell</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-scala-shell.src.test.java.org.apache.flink.api.java.FlinkILoopTest.java</file>
      <file type="M">flink-scala-shell.src.main.java.org.apache.flink.api.java.ScalaShellRemoteStreamEnvironment.java</file>
      <file type="M">flink-scala-shell.src.main.java.org.apache.flink.api.java.ScalaShellRemoteEnvironment.java</file>
      <file type="M">flink-scala-shell.src.main.java.org.apache.flink.api.java.JarHelper.java</file>
      <file type="M">flink-scala-shell.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6778" opendate="2017-5-30 00:00:00" fixdate="2017-5-30 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Activate strict checkstyle for flink-dist</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-dist.src.test.java.org.apache.flink.dist.TaskManagerHeapSizeCalculationJavaBashTest.java</file>
      <file type="M">flink-dist.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6779" opendate="2017-5-30 00:00:00" fixdate="2017-5-30 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Activate strict checkstyle in flink-scala</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-scala.src.main.java.org.apache.flink.api.scala.operators.ScalaCsvOutputFormat.java</file>
      <file type="M">flink-scala.src.main.java.org.apache.flink.api.scala.operators.ScalaAggregateOperator.java</file>
      <file type="M">flink-scala.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6780" opendate="2017-5-31 00:00:00" fixdate="2017-5-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ExternalTableSource should add time attributes in the row type</summary>
      <description>We observed that all streaming queries that refer to external tables fail when the Volcano planner converting LogicalTableScan to FlinkLogicalTableSourceScan:Type mismatch:rowtype of new rel:RecordType(&lt;table schema&gt;, TIMESTAMP(3) NOT NULL proctime) NOT NULLrowtype of set:RecordType(&lt;table schema&gt;, ...) NOT NULLTables that are registered through StreamTableEnvironment#registerTableSource() do not suffer from this problem as StreamTableSourceTable adds the processing time / event time attribute automatically.</description>
      <version>None</version>
      <fixedVersion>1.3.1,1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.catalog.ExternalTableSourceUtil.scala</file>
    </fixedFiles>
  </bug>
  <bug id="6787" opendate="2017-5-31 00:00:00" fixdate="2017-8-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Job-/StoppableException should extend FlinkException</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.StoppingException.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobmaster.JobManagerException.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.JobException.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.client.JobExecutionException.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.client.JobClientActorSubmissionTimeoutException.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.client.JobClientActorRegistrationTimeoutException.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.client.JobClientActorConnectionTimeoutException.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.program.ProgramMissingJobException.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.program.ClusterClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="6792" opendate="2017-6-1 00:00:00" fixdate="2017-6-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>flink-yarn-tests always fail on travis</summary>
      <description>flink-yarn-tests is currently failing all builds:Results :Failed tests: YARNSessionFIFOITCase.testJavaAPI:244 Error while deploying YARN cluster: Couldn't deploy Yarn clusterTests in error: YARNHighAvailabilityITCase.testMultipleAMKill:140 Â» Runtime Couldn't deploy Ya... YARNSessionCapacitySchedulerITCase.perJobYarnCluster:120-&gt;YarnTestBase.runWithArgs:612 Â» Runtime YARNSessionCapacitySchedulerITCase.perJobYarnClusterWithParallelism:344-&gt;YarnTestBase.runWithArgs:612 Â» Runtime YARNSessionCapacitySchedulerITCase.testClientStartup:99-&gt;YarnTestBase.runWithArgs:528-&gt;YarnTestBase.runWithArgs:612 Â» Runtime YARNSessionCapacitySchedulerITCase.testDetachedPerJobYarnCluster:373-&gt;testDetachedPerJobYarnClusterInternal:419-&gt;YarnTestBase.startWithArgs:515 Â» Runtime YARNSessionCapacitySchedulerITCase.testDetachedPerJobYarnClusterWithStreamingJob:390-&gt;testDetachedPerJobYarnClusterInternal:419-&gt;YarnTestBase.startWithArgs:515 Â» Runtime YARNSessionCapacitySchedulerITCase.testTaskManagerFailure:140-&gt;YarnTestBase.startWithArgs:515 Â» Runtime YARNSessionFIFOITCase.testDetachedMode:84-&gt;YarnTestBase.startWithArgs:515 Â» Runtime YARNSessionFIFOSecuredITCase&gt;YARNSessionFIFOITCase.testDetachedMode:84-&gt;YarnTestBase.startWithArgs:515 Â» Runtime}</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-dist.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6793" opendate="2017-6-1 00:00:00" fixdate="2017-6-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Activate checkstyle for runtime/metrics</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.util.TestReporter.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.util.TestingHistogram.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.util.DummyCharacterFilter.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.TaskManagerMetricsTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.MetricRegistryTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.groups.TaskMetricGroupTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.groups.TaskManagerJobGroupTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.groups.TaskManagerGroupTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.groups.TaskIOMetricGroupTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.groups.QueryScopeInfoTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.groups.OperatorGroupTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.groups.MetricGroupTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.groups.MetricGroupRegistrationTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.groups.JobManagerJobGroupTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.groups.JobManagerGroupTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.groups.AbstractMetricGroupTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.dump.QueryScopeInfoTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.dump.MetricQueryServiceTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.dump.MetricDumpTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.dump.MetricDumpSerializerTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.ViewUpdater.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.util.MetricUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.scope.ScopeFormats.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.scope.ScopeFormat.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.MetricRegistryConfiguration.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.MetricRegistry.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.MetricNames.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.groups.TaskMetricGroup.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.groups.TaskManagerMetricGroup.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.groups.TaskManagerJobMetricGroup.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.groups.TaskIOMetricGroup.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.groups.OperatorMetricGroup.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.groups.OperatorIOMetricGroup.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.groups.JobMetricGroup.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.groups.JobManagerMetricGroup.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.groups.JobManagerJobMetricGroup.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.groups.GenericMetricGroup.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.groups.ComponentMetricGroup.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.groups.AbstractMetricGroup.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.dump.QueryScopeInfo.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.dump.MetricQueryService.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.dump.MetricDumpSerialization.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.dump.MetricDump.java</file>
      <file type="M">flink-runtime.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6794" opendate="2017-6-1 00:00:00" fixdate="2017-6-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Activate checkstyle for migration/*</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.migration.streaming.runtime.tasks.StreamTaskStateList.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.migration.streaming.runtime.tasks.StreamTaskState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.migration.MigrationUtil.java</file>
      <file type="M">flink-runtime.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6795" opendate="2017-6-1 00:00:00" fixdate="2017-6-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Activate checkstyle for runtime/process</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.process.ProcessReaper.java</file>
      <file type="M">flink-runtime.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6803" opendate="2017-6-1 00:00:00" fixdate="2017-6-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add test for PojoSerializer when Pojo changes</summary>
      <description>We should add test cases for the PojoSerializer when the underlying Pojo type changes in order to test the proper behaviour of the serializer.</description>
      <version>1.4.0</version>
      <fixedVersion>1.3.1,1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.typeserializerupgrade.PojoSerializerUpgradeTest.java</file>
      <file type="M">flink-tests.pom.xml</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.AbstractStreamOperatorTestHarness.java</file>
      <file type="M">flink-streaming-java.pom.xml</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.StateBackendTestBase.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.heap.HeapKeyedStateBackend.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.runtime.FieldSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.CompatibilityUtil.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackendTest.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackend.java</file>
    </fixedFiles>
  </bug>
  <bug id="6811" opendate="2017-6-2 00:00:00" fixdate="2017-7-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add TIMESTAMPADD supported in SQL</summary>
      <description>TIMESTAMPADD(unit,interval,datetime_expr) Adds the integer expression interval to the date or datetime expression datetime_expr. The unit for interval is given by the unit argument, which should be one of the following values: MICROSECOND (microseconds), SECOND, MINUTE, HOUR, DAY, WEEK, MONTH, QUARTER, or YEAR. Syntax:TIMESTAMPADD(unit,interval,datetime_expr) Arguments**unit: -**interval: -**datetime_expr: - Return Types DATAETIME/DATE/TIME Example: SELECT TIMESTAMPADD(month, 1, '2017-05-31') --&gt; '2017-06-30 00:00:00.000' SELECT TIMESTAMPADD(WEEK,1,'2003-01-02') -&gt; '2003-01-09' See more: MySQL Note: Due to the difference of [&amp;#91;org.apache.calcite.rex.Rex Literal&amp;#93;] between calcite 1.12 and calcite master we should temp close support the construce of TIMESTAMPADD(SqlTypeFamily.ANY, SqlTypeFamily.INTEGER, SqlTypeFamily.DATE), until upgrade to calcite 1.13.See more: https://issues.apache.org/jira/browse/CALCITE-1639https://issues.apache.org/jira/browse/FLINK-6851See more: https://issues.apache.org/jira/browse/CALCITE-1827</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.validation.ScalarFunctionsValidationTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.validate.FunctionCatalog.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.typeutils.TypeCheckUtils.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.CodeGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.calls.ScalarOperators.scala</file>
      <file type="M">docs.dev.table.sql.md</file>
    </fixedFiles>
  </bug>
  <bug id="6815" opendate="2017-6-2 00:00:00" fixdate="2017-6-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Javadocs don&amp;#39;t work anymore in Flink 1.4-SNAPSHOT</summary>
      <description>https://ci.apache.org/projects/flink/flink-docs-master/api/java/org/apache/flink/streaming/api/scala/KeyedStream.html results in a 404 error.The problem (https://ci.apache.org/builders/flink-docs-master/builds/731/steps/Java%20&amp;%20Scala%20docs/logs/stdio) is the following:[ERROR] Failed to execute goal net.alchim31.maven:scala-maven-plugin:3.2.2:compile (doc) on project flink-annotations: wrap: org.apache.maven.artifact.resolver.ArtifactNotFoundException: Could not find artifact com.typesafe.genjavadoc:genjavadoc-plugin_2.10.6:jar:0.8 in central (https://repo.maven.apache.org/maven2)I think the problem is that we upgraded the scala version to 2.10.6, but the plugin doesn't have version 0.8 for that scala version.</description>
      <version>1.4.0</version>
      <fixedVersion>1.3.1,1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6816" opendate="2017-6-2 00:00:00" fixdate="2017-6-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix wrong usage of Scala string interpolation in Table API</summary>
      <description>This issue is to fix some wrong usage of Scala string interpolation, such as missing the "s" prefix .</description>
      <version>None</version>
      <fixedVersion>1.3.1,1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.RowTimeUnboundedOver.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.RowTimeBoundedRowsOver.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.RowTimeBoundedRangeOver.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.ProcTimeUnboundedPartitionedOver.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.ProcTimeUnboundedNonPartitionedOver.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.ProcTimeBoundedRowsOver.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.ProcTimeBoundedRangeOver.scala</file>
    </fixedFiles>
  </bug>
  <bug id="6818" opendate="2017-6-2 00:00:00" fixdate="2017-6-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Activate checkstyle for runtime/history</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.history.FsJobArchivist.java</file>
      <file type="M">flink-runtime.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6819" opendate="2017-6-2 00:00:00" fixdate="2017-6-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Activate checkstyle for runtime/leaderretrieval</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.leaderretrieval.ZooKeeperLeaderRetrievalService.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.leaderretrieval.StandaloneLeaderRetrievalService.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.leaderretrieval.LeaderRetrievalService.java</file>
      <file type="M">flink-runtime.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6820" opendate="2017-6-2 00:00:00" fixdate="2017-6-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Activate checkstyle for runtime/filecache</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.filecache.FileCacheDeleteValidationTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.filecache.FileCache.java</file>
      <file type="M">flink-runtime.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6821" opendate="2017-6-2 00:00:00" fixdate="2017-7-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Activate checkstyle for runtime/fs</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.fs.hdfs.HadoopDataInputStreamTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.fs.maprfs.MapRFileSystem.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.fs.hdfs.HadoopFileSystem.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.fs.hdfs.HadoopFileStatus.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.fs.hdfs.HadoopDataOutputStream.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.fs.hdfs.HadoopDataInputStream.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.fs.hdfs.HadoopBlockLocation.java</file>
      <file type="M">flink-runtime.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6824" opendate="2017-6-2 00:00:00" fixdate="2017-6-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Activate checkstyle for runtime/event</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.event.task.TaskEventTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.event.task.StringTaskEvent.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.event.task.IntegerTaskEvent.java</file>
      <file type="M">flink-runtime.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6825" opendate="2017-6-2 00:00:00" fixdate="2017-7-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Activate checkstyle for runtime/heartbeat</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.heartbeat.TestingHeartbeatServices.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.heartbeat.HeartbeatManagerTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.heartbeat.HeartbeatServices.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.heartbeat.HeartbeatManagerSenderImpl.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.heartbeat.HeartbeatManagerImpl.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.heartbeat.HeartbeatManager.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.heartbeat.HeartbeatListener.java</file>
      <file type="M">flink-runtime.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6826" opendate="2017-6-2 00:00:00" fixdate="2017-7-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Activate checkstyle for runtime/net</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.net.SSLUtilsTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.net.ConnectionUtilsTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.net.SSLUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.net.ConnectionUtils.java</file>
      <file type="M">flink-runtime.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6827" opendate="2017-6-2 00:00:00" fixdate="2017-6-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Activate checkstyle for runtime/webmonitor</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.webmonitor.history.ArchivedJsonTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.webmonitor.WebMonitorUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.webmonitor.WebMonitor.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.webmonitor.history.JsonArchivist.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.webmonitor.history.ArchivedJson.java</file>
      <file type="M">flink-runtime.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6828" opendate="2017-6-2 00:00:00" fixdate="2017-7-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Activate checkstyle for runtime/deployment</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.deployment.TaskDeploymentDescriptorTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.deployment.ResultPartitionDeploymentDescriptorTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.deployment.InputChannelDeploymentDescriptorTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.deployment.TaskDeploymentDescriptor.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.deployment.ResultPartitionLocation.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.deployment.ResultPartitionDeploymentDescriptor.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.deployment.PartialInputChannelDeploymentDescriptor.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.deployment.InputGateDeploymentDescriptor.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.deployment.InputChannelDeploymentDescriptor.java</file>
      <file type="M">flink-runtime.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6837" opendate="2017-6-2 00:00:00" fixdate="2017-6-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix a small error message bug, And improve some message info.</summary>
      <description>Fix a variable reference error, and improve some error message info.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.scala.stream.table.OverWindowITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.AggregateUtil.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.call.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.CodeGenUtils.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.calls.ScalarOperators.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.table.scala</file>
    </fixedFiles>
  </bug>
  <bug id="6840" opendate="2017-6-2 00:00:00" fixdate="2017-6-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>MultipleLinearRegression documentation contains outdated information</summary>
      <description>The documentation for MultipleLinearRegression contains outdated information. We should correct the documentation.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.dev.libs.ml.multiple.linear.regression.md</file>
    </fixedFiles>
  </bug>
  <bug id="6846" opendate="2017-6-4 00:00:00" fixdate="2017-8-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add TIMESTAMPADD supported in TableAPI</summary>
      <description>See FLINK-6811 for detail.</description>
      <version>1.4.0</version>
      <fixedVersion>1.7.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.time.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.symbols.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.ExpressionParser.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.scala.expressionDsl.scala</file>
      <file type="M">docs.dev.table.tableApi.md</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.validate.FunctionCatalog.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.expressions.time.scala</file>
    </fixedFiles>
  </bug>
  <bug id="6852" opendate="2017-6-6 00:00:00" fixdate="2017-6-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix misuse of GCD</summary>
      <description>There's no need to compare and swap values for gcd input</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.AggregateUtil.scala</file>
    </fixedFiles>
  </bug>
  <bug id="6861" opendate="2017-6-7 00:00:00" fixdate="2017-10-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use OperatorID in metric system</summary>
      <description>The metric system currently identifies operators by name, which frequently leads to problems when operators in chain have the same name.We recently introduced actual operator IDs into the runtime. We should look into whether we can expose these easily to the metric system.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.AbstractStreamOperator.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.testutils.UnregisteredTaskMetricsGroup.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.groups.TaskMetricGroupTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.groups.OperatorGroupTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.groups.MetricGroupTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.scope.ScopeFormat.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.scope.OperatorScopeFormat.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.groups.TaskMetricGroup.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.groups.OperatorMetricGroup.java</file>
      <file type="M">flink-metrics.flink-metrics-statsd.src.test.java.org.apache.flink.metrics.statsd.StatsDReporterTest.java</file>
      <file type="M">flink-metrics.flink-metrics-dropwizard.src.test.java.org.apache.flink.dropwizard.ScheduledDropwizardReporterTest.java</file>
      <file type="M">docs.monitoring.metrics.md</file>
    </fixedFiles>
  </bug>
  <bug id="6865" opendate="2017-6-7 00:00:00" fixdate="2017-7-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expand checkstyle docs to include import in intellij</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.internals.ide.setup.md</file>
    </fixedFiles>
  </bug>
  <bug id="6867" opendate="2017-6-8 00:00:00" fixdate="2017-7-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Elasticsearch 1.x ITCase still instable due to embedded node instability</summary>
      <description>The integration tests for Elasticsearch 1.x seems to still be instable, being that the test is failing more frequently recently. One example is &amp;#91;1&amp;#93;.The last attempt to fix this was FLINK-5772, in which the test attempts was increased to 3. This doesn't seem to fix the issue. In the worst scenario, since the root cause is an instability with Elasticsearch 1.x's embedded node, and ES 1.x is a very old version that is usually recommended to be upgraded from, we could also consider removing the IT test for ES 1.x.&amp;#91;1&amp;#93; https://travis-ci.org/apache/flink/jobs/240444523</description>
      <version>None</version>
      <fixedVersion>1.3.2,1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-elasticsearch.src.test.java.org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkITCase.java</file>
    </fixedFiles>
  </bug>
  <bug id="6868" opendate="2017-6-8 00:00:00" fixdate="2017-6-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Using `scala.binary.version` for `flink-streaming-scala` in `Cassandra Connector`</summary>
      <description>Shoud using `scala.binary.version` for `flink-streaming-scala` in `Cassandra Connector`.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-cassandra.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6877" opendate="2017-6-9 00:00:00" fixdate="2017-7-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Activate checkstyle for runtime/security</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.security.SecurityUtilsTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.security.KerberosUtilsTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.security.SecurityUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.security.SecurityContext.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.security.NoOpSecurityContext.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.security.modules.ZooKeeperModule.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.security.modules.SecurityModule.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.security.modules.JaasModule.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.security.modules.HadoopModule.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.security.KerberosUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.security.HadoopSecurityContext.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.security.DynamicConfiguration.java</file>
      <file type="M">flink-runtime.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6878" opendate="2017-6-9 00:00:00" fixdate="2017-7-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Activate checkstyle for runtime/query</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.QueryableStateClientTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.netty.message.KvStateRequestSerializerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.netty.KvStateServerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.netty.KvStateServerHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.netty.KvStateClientTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.netty.KvStateClientHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.KvStateLocationTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.KvStateLocationRegistryTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.AkkaKvStateLocationLookupServiceTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.TaskKvStateRegistry.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.QueryableStateClient.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.message.KvStateRequestSerializer.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.KvStateServerHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.KvStateServer.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.KvStateClientHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.KvStateClient.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.ChunkedByteBuf.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.KvStateServerAddress.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.KvStateRegistryGateway.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.KvStateRegistry.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.KvStateMessage.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.KvStateLocationLookupService.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.KvStateLocation.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.AkkaKvStateLocationLookupService.java</file>
      <file type="M">flink-runtime.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6879" opendate="2017-6-9 00:00:00" fixdate="2017-7-9 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Activate checkstyle for runtime/memory</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.memory.MemorySegmentSimpleTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.memory.MemoryManagerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.memory.MemoryManagerLazyAllocationTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.memory.MemoryManagerConcurrentModReleaseTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.memory.MemoryManager.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.memory.MemoryAllocationException.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.memory.ListMemorySegmentSource.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.memory.AbstractPagedOutputView.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.memory.AbstractPagedInputView.java</file>
      <file type="M">flink-runtime.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6880" opendate="2017-6-9 00:00:00" fixdate="2017-7-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Activate checkstyle for runtime/iterative</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.iterative.event.EventWithAggregatorsTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.iterative.concurrent.SuperstepKickoffLatchTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.iterative.concurrent.SuperstepBarrierTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.iterative.concurrent.StringPair.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.iterative.concurrent.BrokerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.iterative.concurrent.BlockingBackChannelTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.task.Terminable.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.task.SyncEventHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.task.RuntimeAggregatorRegistry.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.task.IterationTailTask.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.task.IterationSynchronizationSinkTask.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.task.IterationIntermediateTask.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.task.IterationHeadTask.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.task.AbstractIterativeTask.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.io.WorksetUpdateOutputCollector.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.io.SolutionSetUpdateOutputCollector.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.io.SolutionSetObjectsUpdateOutputCollector.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.io.SolutionSetFastUpdateOutputCollector.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.io.SerializedUpdateBuffer.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.io.HashPartitionIterator.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.event.WorkerDoneEvent.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.event.TerminationEvent.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.event.IterationEventWithAggregators.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.event.AllWorkersDoneEvent.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.convergence.WorksetEmptyConvergenceCriterion.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.concurrent.SuperstepKickoffLatchBroker.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.concurrent.SuperstepKickoffLatch.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.concurrent.SuperstepBarrier.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.concurrent.SolutionSetUpdateBarrierBroker.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.concurrent.SolutionSetBroker.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.concurrent.IterationAggregatorBroker.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.concurrent.Broker.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.concurrent.BlockingBackChannelBroker.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.concurrent.BlockingBackChannel.java</file>
      <file type="M">flink-runtime.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6882" opendate="2017-6-9 00:00:00" fixdate="2017-7-9 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Activate checkstyle for runtime/registration</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.registration.TestRegistrationGateway.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.registration.RetryingRegistrationTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.registration.RegisteredRpcConnectionTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.registration.RetryingRegistration.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.registration.RegistrationResponse.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.registration.RegisteredRpcConnection.java</file>
      <file type="M">flink-runtime.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6891" opendate="2017-6-12 00:00:00" fixdate="2017-7-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add LOG(X) supported in SQL</summary>
      <description>LOG(X), LOG(B,X)If called with one parameter, this function returns the natural logarithm of X. If X is less than or equal to 0.0E0, the function returns NULL and (as of MySQL 5.7.4) a warning “Invalid argument for logarithm” is reported.The inverse of this function (when called with a single argument) is the EXP() function.If called with two parameters, this function returns the logarithm of X to the base B. If X is less than or equal to 0, or if B is less than or equal to 1, then NULL is returned. Example: LOG(2) -&gt; 0.69314718055995 LOG(-2) -&gt; NULL LOG(2,65536) -&gt; 16 LOG(10,100) -&gt; 2 LOG(1,100) -&gt; NULL See more: MySQL -NOTE- In this JIRA. NULL case will throw IllegalArgumentException.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.validation.ScalarFunctionsValidationTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.validate.FunctionCatalog.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.functions.ScalarFunctions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.sql.ScalarSqlFunctions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.calls.FunctionGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.calls.BuiltInMethods.scala</file>
      <file type="M">docs.dev.table.sql.md</file>
    </fixedFiles>
  </bug>
  <bug id="6892" opendate="2017-6-12 00:00:00" fixdate="2017-1-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add L/RPAD supported in SQL</summary>
      <description>L/RPAD(str,len,padstr) Returns the string str, left/right-padded with the string padstr to a length of len characters. If str is longer than len, the return value is shortened to len characters. Syntax:LPAD(str,len,padstr) Arguments**str: -**len: -**padstr: - Return Types String Example: LPAD('hi',4,'??') -&gt; '??hi' LPAD('hi',1,'??') -&gt; 'h' RPAD('hi',4,'') -&gt; 'hi' RPAD('hi',1,'??') -&gt; 'h' See more: MySQL</description>
      <version>1.4.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.sql.ScalarSqlFunctions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.calls.FunctionGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.calls.BuiltInMethods.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.validate.FunctionCatalog.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.functions.ScalarFunctions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.stringExpressions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.scala.expressionDsl.scala</file>
      <file type="M">docs.dev.table.tableApi.md</file>
      <file type="M">docs.dev.table.sql.md</file>
    </fixedFiles>
  </bug>
  <bug id="6893" opendate="2017-6-12 00:00:00" fixdate="2017-1-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add BIN supported in SQL &amp; Table API</summary>
      <description>BIN(N) Returns a string representation of the binary value of N, where N is a longlong (BIGINT) number. This is equivalent to CONV(N,10,2). Returns NULL if N is NULL. Syntax:BIN(num) Arguments**num: a long/bigint value Return Types String Example: BIN(12) -&gt; '1100' See more: MySQL</description>
      <version>1.4.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.calls.BuiltInMethods.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.validation.ScalarFunctionsValidationTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.SqlExpressionTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.validate.FunctionCatalog.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.typeutils.TypeCheckUtils.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.sql.ScalarSqlFunctions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.mathExpressions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.calls.FunctionGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.scala.expressionDsl.scala</file>
      <file type="M">docs.dev.table.tableApi.md</file>
      <file type="M">docs.dev.table.sql.md</file>
    </fixedFiles>
  </bug>
  <bug id="6898" opendate="2017-6-12 00:00:00" fixdate="2017-7-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Limit size of operator component in metric name</summary>
      <description>The operator name for some operators (specifically windows) can be very, very long (250+) characters.I propose to limit the total space that the operator component can take up in a metric name to 60 characters.</description>
      <version>1.3.0,1.4.0</version>
      <fixedVersion>1.3.2,1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.groups.TaskMetricGroupTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.groups.TaskMetricGroup.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.groups.AbstractMetricGroup.java</file>
    </fixedFiles>
  </bug>
  <bug id="6902" opendate="2017-6-12 00:00:00" fixdate="2017-7-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Activate strict checkstyle for flink-streaming-scala</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-scala.src.test.java.org.apache.flink.streaming.scala.api.TextOutputFormatITCase.java</file>
      <file type="M">flink-streaming-scala.src.test.java.org.apache.flink.streaming.scala.api.StatefulFunctionITCase.java</file>
      <file type="M">flink-streaming-scala.src.test.java.org.apache.flink.streaming.scala.api.CsvOutputFormatITCase.java</file>
    </fixedFiles>
  </bug>
  <bug id="6903" opendate="2017-6-12 00:00:00" fixdate="2017-7-12 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Activate checkstyle for runtime/akka</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.akka.QuarantineMonitorTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.akka.FlinkUntypedActorTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.akka.QuarantineMonitor.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.akka.QuarantineHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.akka.FlinkUntypedActor.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.akka.DefaultQuarantineHandler.java</file>
      <file type="M">flink-runtime.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6904" opendate="2017-6-13 00:00:00" fixdate="2017-6-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support for quantifier range to CEP&amp;#39;s pattern API</summary>
      <description>Currently the quantifier has supported oneOrMore, times(int times), one()，we should also support API such as times(int from, int to) to specify a quantifier range.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-cep.src.test.java.org.apache.flink.cep.nfa.NFAITCase.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.pattern.Quantifier.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.pattern.Pattern.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.nfa.compiler.NFACompiler.java</file>
      <file type="M">flink-libraries.flink-cep-scala.src.main.scala.org.apache.flink.cep.scala.pattern.Pattern.scala</file>
    </fixedFiles>
  </bug>
  <bug id="6924" opendate="2017-6-15 00:00:00" fixdate="2017-4-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ADD LOG(X) supported in TableAPI</summary>
      <description>See FLINK-6891 for detail.</description>
      <version>1.4.0</version>
      <fixedVersion>1.6.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.validate.FunctionCatalog.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.mathExpressions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.ExpressionParser.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.scala.expressionDsl.scala</file>
      <file type="M">docs.dev.table.tableApi.md</file>
      <file type="M">docs.dev.table.sql.md</file>
    </fixedFiles>
  </bug>
  <bug id="6925" opendate="2017-6-15 00:00:00" fixdate="2017-7-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add CONCAT/CONCAT_WS supported in SQL</summary>
      <description>CONCAT(str1,str2,...)Returns the string that results from concatenating the arguments. May have one or more arguments. If all arguments are nonbinary strings, the result is a nonbinary string. If the arguments include any binary strings, the result is a binary string. A numeric argument is converted to its equivalent nonbinary string form.CONCAT() returns NULL if any argument is NULL. Syntax:CONCAT(str1,str2,...) Arguments str1,str2,... - Return Types string Example: CONCAT('F', 'lin', 'k') -&gt; 'Flink' CONCAT('M', NULL, 'L') -&gt; NULL CONCAT(14.3) -&gt; '14.3' See more: MySQL CONCAT_WS() stands for Concatenate With Separator and is a special form of CONCAT(). The first argument is the separator for the rest of the arguments. The separator is added between the strings to be concatenated. The separator can be a string, as can the rest of the arguments. If the separator is NULL, the result is NULL. Syntax:CONCAT_WS(separator,str1,str2,...) Arguments separator - str1,str2,... - Return Types string Example: CONCAT_WS(',','First name','Second name','Last Name') -&gt; 'First name,Second name,Last Name' See more: MySQL</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.validate.FunctionCatalog.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.utils.MathFunctions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.sql.ScalarSqlFunctions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.CodeGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.calls.ScalarOperators.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.calls.CallGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.calls.BuiltInMethods.scala</file>
      <file type="M">docs.dev.table.sql.md</file>
    </fixedFiles>
  </bug>
  <bug id="6926" opendate="2017-6-15 00:00:00" fixdate="2017-5-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add support for MD5, SHA1 and SHA2</summary>
      <description>MD5(str)Calculates an MD5 128-bit checksum for the string. The value is returned as a string of 32 hexadecimal digits, or NULL if the argument was NULL. The return value can, for example, be used as a hash key. See the notes at the beginning of this section about storing hash values efficiently.The return value is a nonbinary string in the connection character set. Example: MD5('testing') - 'ae2b1fca515949e5d54fb22b8ed95575' See more: MySQL SHA1(str), SHA(str)Calculates an SHA-1 160-bit checksum for the string, as described in RFC 3174 (Secure Hash Algorithm). The value is returned as a string of 40 hexadecimal digits, or NULL if the argument was NULL. One of the possible uses for this function is as a hash key. See the notes at the beginning of this section about storing hash values efficiently. You can also use SHA1() as a cryptographic function for storing passwords. SHA() is synonymous with SHA1().The return value is a nonbinary string in the connection character set. Example: SHA1('abc') -&gt; 'a9993e364706816aba3e25717850c26c9cd0d89d'SHA2(str, hash_length)Calculates the SHA-2 family of hash functions (SHA-224, SHA-256, SHA-384, and SHA-512). The first argument is the cleartext string to be hashed. The second argument indicates the desired bit length of the result, which must have a value of 224, 256, 384, 512, or 0 (which is equivalent to 256). If either argument is NULL or the hash length is not one of the permitted values, the return value is NULL. Otherwise, the function result is a hash value containing the desired number of bits. See the notes at the beginning of this section about storing hash values efficiently.The return value is a nonbinary string in the connection character set. Example:SHA2('abc', 224) -&gt; '23097d223405d8228642a477bda255b32aadbce4bda0b3f7e36c9da7' See more: MySQL</description>
      <version>1.4.0</version>
      <fixedVersion>1.6.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.utils.ScalarTypesTestBase.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.ProjectionTranslator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.logical.LogicalNode.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.calls.HashCalcCallGen.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.sql.DateTimeSqlFunction.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.time.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.stringExpressions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.CodeGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.calls.CallGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.SqlExpressionTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.validate.FunctionCatalog.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.sql.ScalarSqlFunctions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.hashExpressions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.calls.FunctionGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.scala.expressionDsl.scala</file>
      <file type="M">docs.dev.table.tableApi.md</file>
      <file type="M">docs.dev.table.sql.md</file>
    </fixedFiles>
  </bug>
  <bug id="6927" opendate="2017-6-15 00:00:00" fixdate="2017-7-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support pattern group in CEP</summary>
      <description>We should add support for pattern group. This would enrich the set of supported patterns. For example, users can write patterns like this with this feature available: A --&gt; (B --&gt; C.times(3)).optional() --&gt; DorA --&gt; (B --&gt; C).times(3) --&gt; D</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.pattern.Quantifier.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.pattern.Pattern.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.nfa.compiler.NFAStateNameHandler.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.nfa.compiler.NFACompiler.java</file>
      <file type="M">flink-libraries.flink-cep-scala.src.main.scala.org.apache.flink.cep.scala.pattern.Pattern.scala</file>
      <file type="M">docs.dev.libs.cep.md</file>
    </fixedFiles>
  </bug>
  <bug id="6937" opendate="2017-6-16 00:00:00" fixdate="2017-6-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix link markdown in Production Readiness Checklist doc</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.3.2,1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.ops.production.ready.md</file>
    </fixedFiles>
  </bug>
  <bug id="6940" opendate="2017-6-18 00:00:00" fixdate="2017-7-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clarify the effect of configuring per-job state backend</summary>
      <description>The documentation of having different options configuring flink state backend is confusing. We should add explicit doc explaining configuring a per-job flink state backend in code will overwrite any default state backend configured in flink-conf.yaml</description>
      <version>1.3.0,1.4.0</version>
      <fixedVersion>1.3.2,1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.ops.state.backends.md</file>
    </fixedFiles>
  </bug>
  <bug id="6942" opendate="2017-6-19 00:00:00" fixdate="2017-6-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add E() supported in TableAPI</summary>
      <description>See FLINK-6960 for detail.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.validate.FunctionCatalog.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.mathExpressions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.scala.expressionDsl.scala</file>
      <file type="M">docs.dev.table.tableApi.md</file>
    </fixedFiles>
  </bug>
  <bug id="6960" opendate="2017-6-21 00:00:00" fixdate="2017-6-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add E() supported in SQL</summary>
      <description>E=Math.E</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.validate.FunctionCatalog.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.calls.FunctionGenerator.scala</file>
      <file type="M">docs.dev.table.sql.md</file>
    </fixedFiles>
  </bug>
  <bug id="6962" opendate="2017-6-21 00:00:00" fixdate="2017-5-21 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Add a create table SQL DDL</summary>
      <description>This Jira adds support to allow user define the DDL for source and sink tables, including the waterMark(on source table) and emit SLA (on result table). The detailed design doc will be attached soon.This issue covered adding batch DDL support. Streaming-specific DDL support will be added later.</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.pom.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6964" opendate="2017-6-21 00:00:00" fixdate="2017-7-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix recovery for incremental checkpoints in StandaloneCompletedCheckpointStore</summary>
      <description>StandaloneCompletedCheckpointStore does not register shared states ion resume. However, for externalized checkpoints, it register the checkpoint from which it resumed. This checkpoint gets added to the completed checkpoint store as part of resume.</description>
      <version>None</version>
      <fixedVersion>1.3.2,1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.scala.org.apache.flink.runtime.testingUtils.TestingJobManagerMessages.scala</file>
      <file type="M">flink-runtime.src.test.scala.org.apache.flink.runtime.testingUtils.TestingJobManagerLike.scala</file>
      <file type="M">flink-runtime.src.test.scala.org.apache.flink.runtime.testingUtils.TestingCluster.scala</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.IncrementalKeyedStateHandleTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.checkpoint.ZooKeeperCompletedCheckpointStoreTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.checkpoint.savepoint.CheckpointTestUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.SharedStateRegistry.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.IncrementalKeyedStateHandle.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.savepoint.SavepointV2Serializer.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.CheckpointCoordinator.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackend.java</file>
    </fixedFiles>
  </bug>
  <bug id="6967" opendate="2017-6-21 00:00:00" fixdate="2017-6-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fully separate batch and storm examples</summary>
      <description>Like the streaming examples (see FLINK-6863) the storm examples have a dependency on the batch examples, exclusively for the WordCount example data.I propose to duplicate the test data again for the storm examples.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.wordcount.WordCountTopology.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.wordcount.WordCountRemoteBySubmitter.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.wordcount.WordCountRemoteByClient.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.wordcount.WordCountLocalByName.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.wordcount.WordCountLocal.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.wordcount.SpoutSourceWordCount.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.wordcount.operators.WordCountInMemorySpout.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.wordcount.operators.WordCountDataTuple.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.wordcount.operators.WordCountDataPojos.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.wordcount.BoltTokenizerWordCountWithNames.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.wordcount.BoltTokenizerWordCountPojo.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.wordcount.BoltTokenizerWordCount.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.exclamation.ExclamationWithSpout.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.exclamation.ExclamationWithBolt.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.main.java.org.apache.flink.storm.exclamation.ExclamationTopology.java</file>
      <file type="M">flink-contrib.flink-storm-examples.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6975" opendate="2017-6-22 00:00:00" fixdate="2017-7-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add CONCAT/CONCAT_WS supported in TableAPI</summary>
      <description>See FLINK-6925 for detail.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.validate.FunctionCatalog.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.stringExpressions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.InputTypeSpec.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.scala.expressionDsl.scala</file>
      <file type="M">docs.dev.table.tableApi.md</file>
    </fixedFiles>
  </bug>
  <bug id="6982" opendate="2017-6-22 00:00:00" fixdate="2017-8-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace guava dependencies</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.FileSystemBlobStore.java</file>
      <file type="M">tools.maven.suppressions.xml</file>
      <file type="M">tools.maven.checkstyle.xml</file>
      <file type="M">pom.xml</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.UdfStreamOperatorCheckpointingITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.SavepointITCase.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.TestHarnessUtil.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.WindowOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.ProcessingTimeTriggerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.ProcessingTimeSessionWindowsTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.MergingWindowSetTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.EventTimeTriggerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.EventTimeSessionWindowsTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.CountTriggerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.ContinuousEventTimeTriggerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.AggregationFunctionTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.EvictingWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.evictors.DeltaEvictor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.UnionTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.TwoInputTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.SplitTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.SinkTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.SideOutputTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.SelectTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.PartitionTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.OneInputTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.FeedbackTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.CoFeedbackTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamGraphHasherV2.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.SplitStream.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.migration.streaming.api.graph.StreamGraphHasherV1.java</file>
      <file type="M">flink-streaming-java.pom.xml</file>
      <file type="M">flink-shaded-curator.flink-shaded-curator-test.pom.xml</file>
      <file type="M">flink-shaded-curator.flink-shaded-curator-recipes.pom.xml</file>
      <file type="M">flink-runtime.src.test.scala.org.apache.flink.runtime.testingUtils.TestingUtils.scala</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.StateBackendTestBase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.RightOuterJoinTaskTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.LeftOuterJoinTaskTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.hash.InPlaceMutableHashTableTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.AbstractOuterJoinTaskTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.jobmanager.scheduler.ScheduleOrUpdateConsumersTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.jobmanager.JobManagerStartupTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.iterative.concurrent.BrokerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.iterative.concurrent.BlockingBackChannelTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.util.TestPooledBufferProvider.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.partition.SpilledSubpartitionViewTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.partition.consumer.RemoteInputChannelTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannelTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.buffer.LocalBufferPoolTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.filecache.FileCacheDeleteValidationTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.checkpoint.CheckpointCoordinatorTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.security.SecurityUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.KvStateServer.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.KvStateClient.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.TaskEventDispatcher.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.partition.ResultPartitionManager.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.partition.consumer.UnionInputGate.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.netty.PartitionRequestQueue.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.netty.PartitionRequestClientHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.netty.NettyServer.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.api.TaskEventHandler.java</file>
      <file type="M">flink-java.pom.xml</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.sampling.RandomSamplerTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.tuple.TupleGenerator.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.utils.ParameterToolTest.java</file>
      <file type="M">flink-scala.pom.xml</file>
      <file type="M">flink-streaming-scala.pom.xml</file>
      <file type="M">flink-tests.pom.xml</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.accumulators.AccumulatorITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.example.java.PageRankITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.example.scala.PageRankITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.io.CsvReaderITCase.java</file>
      <file type="M">flink-tests.src.test.scala.org.apache.flink.api.scala.io.ScalaCsvReaderWithPOJOITCase.scala</file>
      <file type="M">flink-yarn-tests.src.test.java.org.apache.flink.yarn.YARNSessionCapacitySchedulerITCase.java</file>
      <file type="M">flink-yarn.pom.xml</file>
      <file type="M">flink-yarn.src.test.java.org.apache.flink.yarn.YarnApplicationMasterRunnerTest.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch2.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaProducerTestBase.java</file>
      <file type="M">flink-connectors.flink-connector-twitter.pom.xml</file>
      <file type="M">flink-connectors.flink-hbase.pom.xml</file>
      <file type="M">flink-connectors.flink-hcatalog.pom.xml</file>
      <file type="M">flink-contrib.flink-storm-examples.pom.xml</file>
      <file type="M">flink-contrib.flink-storm-examples.src.test.java.org.apache.flink.storm.join.SingleJoinITCase.java</file>
      <file type="M">flink-libraries.flink-cep.pom.xml</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.nfa.compiler.NFACompiler.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.nfa.NFA.java</file>
      <file type="M">flink-libraries.flink-cep.src.test.java.org.apache.flink.cep.nfa.compiler.NFACompilerTest.java</file>
      <file type="M">flink-libraries.flink-cep.src.test.java.org.apache.flink.cep.nfa.GroupITCase.java</file>
      <file type="M">flink-libraries.flink-cep.src.test.java.org.apache.flink.cep.nfa.IterativeConditionsITCase.java</file>
      <file type="M">flink-libraries.flink-cep.src.test.java.org.apache.flink.cep.nfa.NFAITCase.java</file>
      <file type="M">flink-libraries.flink-cep.src.test.java.org.apache.flink.cep.nfa.NFATestUtilities.java</file>
      <file type="M">flink-libraries.flink-cep.src.test.java.org.apache.flink.cep.nfa.NotPatternITCase.java</file>
      <file type="M">flink-libraries.flink-cep.src.test.java.org.apache.flink.cep.nfa.SameElementITCase.java</file>
      <file type="M">flink-libraries.flink-cep.src.test.java.org.apache.flink.cep.nfa.TimesRangeITCase.java</file>
      <file type="M">flink-libraries.flink-cep.src.test.java.org.apache.flink.cep.nfa.UntilConditionITCase.java</file>
      <file type="M">flink-libraries.flink-cep.src.test.java.org.apache.flink.cep.operator.CEPOperatorTest.java</file>
      <file type="M">flink-libraries.flink-table.pom.xml</file>
      <file type="M">flink-optimizer.pom.xml</file>
      <file type="M">flink-optimizer.src.main.java.org.apache.flink.optimizer.dag.SingleInputNode.java</file>
      <file type="M">flink-optimizer.src.main.java.org.apache.flink.optimizer.dag.TwoInputNode.java</file>
      <file type="M">flink-runtime-web.pom.xml</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.BackPressureStatsTracker.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.checkpoints.CheckpointStatsCache.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.StackTraceSampleCoordinator.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.JarAccessDeniedHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.JobCancellationHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.JobDetailsHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.JobStoppingHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.TaskManagersHandlerTest.java</file>
      <file type="M">flink-runtime.pom.xml</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="6985" opendate="2017-6-22 00:00:00" fixdate="2017-6-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove bugfix version from docs title</summary>
      <description>The docs HTML title contains the minor version of the corresponding release. This can be confusing as we build the docs nightly from the respective release branch.</description>
      <version>None</version>
      <fixedVersion>1.2.0,1.3.0,1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs..layouts.base.html</file>
      <file type="M">docs..includes.sidenav.html</file>
      <file type="M">docs..config.yml</file>
      <file type="M">docs.index.md</file>
    </fixedFiles>
  </bug>
  <bug id="7004" opendate="2017-6-26 00:00:00" fixdate="2017-6-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Switch to Travis Trusty image</summary>
      <description>As shown in this PR https://github.com/apache/flink/pull/4167 switching to the Trusty image on Travis seems to stabilize the build times.We should switch for 1.2, 1.3 and 1.4.</description>
      <version>1.2.0,1.3.0,1.4.0</version>
      <fixedVersion>1.2.2,1.3.2,1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">.travis.yml</file>
    </fixedFiles>
  </bug>
  <bug id="7011" opendate="2017-6-27 00:00:00" fixdate="2017-7-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Instable Kafka testStartFromKafkaCommitOffsets failures on Travis</summary>
      <description>Example:https://s3.amazonaws.com/archive.travis-ci.org/jobs/246703474/log.txt?X-Amz-Expires=30&amp;X-Amz-Date=20170627T065647Z&amp;X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAJRYRXRSVGNKPKO5A/20170627/us-east-1/s3/aws4_request&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=dbfc90cfc386fef0990325b54ff74ee4d441944687e7fdaa73ce7b0c2b2ec0eaIn general, the test testStartFromKafkaCommitOffsets implementation is a bit of an overkill. Before continuing with the test, it writes some records just for the sake of committing offsets to Kafka and waits for some offsets to be committed (which leads to the instability), whereas we can do that simply using the test base's OffsetHandler.</description>
      <version>1.3.1,1.4.0</version>
      <fixedVersion>1.3.2,1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaConsumerTestBase.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka09ITCase.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka08ITCase.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka010ITCase.java</file>
    </fixedFiles>
  </bug>
  <bug id="7013" opendate="2017-6-27 00:00:00" fixdate="2017-6-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add shaded netty dependency</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.netty.NettyServerLowAndHighWatermarkTest.java</file>
      <file type="M">tools.travis.mvn.watchdog.sh</file>
      <file type="M">tools.maven.checkstyle.xml</file>
      <file type="M">pom.xml</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.netty.message.KvStateRequestSerializerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.netty.KvStateServerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.netty.KvStateServerHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.netty.KvStateClientTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.netty.KvStateClientHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.netty.ServerTransportErrorHandlingTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.netty.PartitionRequestQueueTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.netty.PartitionRequestClientHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.netty.PartitionRequestClientFactoryTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.netty.NettyTestUtil.java</file>
      <file type="M">flink-mesos.pom.xml</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.util.MesosArtifactServer.java</file>
      <file type="M">flink-runtime-web.pom.xml</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.files.StaticFileServerHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.AbstractJsonRequestHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.ConstantTextHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.HandlerRedirectUtils.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.JobCancellationWithSavepointHandlers.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.RequestHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.TaskManagerLogHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.history.HistoryServer.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.history.HistoryServerStaticFileServerHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.HttpRequestHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.PipelineErrorHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.RuntimeMonitorHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.RuntimeMonitorHandlerBase.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.utils.WebFrontendBootstrap.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.WebRuntimeMonitor.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.JobCancellationWithSavepointHandlersTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.TaskManagerLogHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.history.HistoryServerStaticFileServerHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.testutils.HttpTestClient.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.WebFrontendITCase.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.WebRuntimeMonitorITCase.java</file>
      <file type="M">flink-runtime.pom.xml</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.ExecutionAttemptID.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.netty.NettyBufferPool.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.netty.NettyClient.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.netty.NettyMessage.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.netty.NettyProtocol.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.netty.NettyServer.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.netty.PartitionRequestClient.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.netty.PartitionRequestClientFactory.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.netty.PartitionRequestClientHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.netty.PartitionRequestProtocol.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.netty.PartitionRequestQueue.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.netty.PartitionRequestServerHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.partition.consumer.InputChannelID.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.ChunkedByteBuf.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.KvStateClient.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.KvStateClientHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.KvStateServer.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.KvStateServerHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.message.KvStateRequestSerializer.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.netty.CancelPartitionRequestTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.netty.ClientTransportErrorHandlingTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.netty.NettyClientServerSslTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.netty.NettyConnectionManagerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.netty.NettyMessageSerializationTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="7014" opendate="2017-6-27 00:00:00" fixdate="2017-6-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expose isDeterministic interface to ScalarFunction and TableFunction</summary>
      <description>Currently, the `isDeterministic` method of implementations of `SqlFuntion` are always returning true, which cause inappropriate optimization in Calcite, such as taking user's stateful UDF as a pure functional procedure.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.ExpressionReductionTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.utils.TableSqlFunction.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.utils.ScalarSqlFunction.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.utils.AggSqlFunction.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.UserDefinedFunction.scala</file>
    </fixedFiles>
  </bug>
  <bug id="7017" opendate="2017-6-27 00:00:00" fixdate="2017-7-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove netty usages in flink-tests</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.web.WebFrontendITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.RescalingITCase.java</file>
      <file type="M">flink-runtime-web.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7025" opendate="2017-6-28 00:00:00" fixdate="2017-6-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Using NullByteKeySelector for Unbounded ProcTime NonPartitioned Over</summary>
      <description>Currently we added `Cleanup State` feature. But It not work well if we enabled the stateCleaning on Unbounded ProcTime NonPartitioned Over window, Because in `ProcessFunctionWithCleanupState` we has using the keyed state.So, In this JIRA. I'll change the `Unbounded ProcTime NonPartitioned Over` to `partitioned Over` by using NullByteKeySelector. OR created a `NonKeyedProcessFunctionWithCleanupState`. But I think the first way is simpler. What do you think? Fabian Hueske</description>
      <version>1.3.1,1.4.0</version>
      <fixedVersion>1.3.2,1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.harness.OverWindowHarnessTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.scala.stream.sql.OverWindowITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.ProcTimeUnboundedPartitionedOver.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.ProcTimeUnboundedNonPartitionedOver.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.AggregateUtil.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.datastream.DataStreamOverAggregate.scala</file>
    </fixedFiles>
  </bug>
  <bug id="7026" opendate="2017-6-28 00:00:00" fixdate="2017-6-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add shaded asm dependency</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.travis.mvn.watchdog.sh</file>
      <file type="M">tools.maven.checkstyle.xml</file>
      <file type="M">pom.xml</file>
      <file type="M">flink-streaming-scala.pom.xml</file>
      <file type="M">flink-shaded-curator.flink-shaded-curator-recipes.pom.xml</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.ClosureCleaner.scala</file>
      <file type="M">flink-scala.pom.xml</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.util.JarFileCreator.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.util.DependencyVisitor.java</file>
      <file type="M">flink-runtime.pom.xml</file>
      <file type="M">flink-libraries.flink-gelly-scala.pom.xml</file>
      <file type="M">flink-libraries.flink-cep-scala.pom.xml</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sca.UdfAnalyzerUtils.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sca.UdfAnalyzer.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sca.TaggedValue.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sca.NestedMethodAnalyzer.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sca.ModifiedASMFrame.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sca.ModifiedASMAnalyzer.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.ClosureCleaner.java</file>
      <file type="M">flink-java.pom.xml</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.TypeExtractionUtils.java</file>
      <file type="M">flink-core.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kinesis.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="703" opendate="2014-6-9 00:00:00" fixdate="2014-4-9 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Use complete element as join key.</summary>
      <description>In some situations such as semi-joins it could make sense to use a complete element as join key. Currently this can be done using a key-selector function, but we could offer a shortcut for that.This is not an urgent issue, but might be helpful.---------------- Imported from GitHub ----------------Url: https://github.com/stratosphere/stratosphere/issues/703Created by: fhueskeLabels: enhancement, java api, user satisfaction, Milestone: Release 0.6 (unplanned)Created at: Thu Apr 17 23:40:00 CEST 2014State: open</description>
      <version>None</version>
      <fixedVersion>0.9</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.scala.org.apache.flink.api.scala.operators.JoinOperatorTest.scala</file>
      <file type="M">flink-tests.src.test.scala.org.apache.flink.api.scala.operators.JoinITCase.scala</file>
      <file type="M">flink-tests.src.test.scala.org.apache.flink.api.scala.operators.GroupReduceITCase.scala</file>
      <file type="M">flink-tests.src.test.scala.org.apache.flink.api.scala.operators.GroupingTest.scala</file>
      <file type="M">flink-tests.src.test.scala.org.apache.flink.api.scala.operators.CoGroupOperatorTest.scala</file>
      <file type="M">flink-tests.src.test.scala.org.apache.flink.api.scala.operators.CoGroupITCase.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.unfinishedKeyPairOperation.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.DataSet.scala</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.JoinITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.GroupReduceITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.CoGroupITCase.java</file>
      <file type="M">flink-optimizer.src.main.java.org.apache.flink.optimizer.postpass.JavaApiPostPass.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.operator.JoinOperatorTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.operator.GroupingTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.operator.CoGroupOperatorTest.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.Keys.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.GroupReduceOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.GroupCombineOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.CoGroupOperatorBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="7030" opendate="2017-6-28 00:00:00" fixdate="2017-7-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Build with scala-2.11 by default</summary>
      <description>As proposed recently on the dev mailing list.I propose to switch to Scala 2.11 as a default and to have a Scala 2.10 build profile. Now it is the other way around. The reason for that is poor support for build profiles in Intellij, I was unable to make it work after I added Kafka 0.11 dependency (Kafka 0.11 dropped support for Scala 2.10).</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">docs.setup.building.md</file>
      <file type="M">.travis.yml</file>
    </fixedFiles>
  </bug>
  <bug id="7039" opendate="2017-6-29 00:00:00" fixdate="2017-7-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Increase forkCountTestPackage for sudo-enabled TravisCI</summary>
      <description>The switch from the container-based to sudo-enabled environment in TravisCI has increased available memory from 4 GB to 7.5 GB so use a forkCount of 2 in all packages including flink-test. See https://docs.travis-ci.com/user/ci-environment/The sudo-enabled machines look to be Google Compute Engine n1-standard-2 with 2 "virtual CPUs". See https://cloud.google.com/compute/pricing.</description>
      <version>1.4.0</version>
      <fixedVersion>1.3.0,1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.travis.mvn.watchdog.sh</file>
    </fixedFiles>
  </bug>
  <bug id="7040" opendate="2017-6-29 00:00:00" fixdate="2017-1-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Flip-6 client-cluster communication</summary>
      <description>With the new Flip-6 architecture, the client will communicate with the cluster in a RESTful manner.The cluster shall support the following REST calls: List jobs (GET): Get list of all running jobs on the cluster Submit job (POST): Submit a job to the cluster (only supported in session mode) Lookup job leader (GET): Gets the JM leader for the given job Get job status (GET): Get the status of an executed job (and maybe the JobExecutionResult) Cancel job (PUT): Cancel the given job Stop job (PUT): Stops the given job Take savepoint (POST): Take savepoint for given job (How to return the savepoint under which the savepoint was stored? Maybe always having to specify a path) Get KV state (GET): Gets the KV state for the given job and key (Queryable state) Poll/subscribe to notifications for job (GET, WebSocket): Polls new notifications from the execution of the given job/Opens WebSocket to receive notificationsThe first four REST calls will be served by the REST endpoint running in the application master/cluster entrypoint. The other calls will be served by a REST endpoint running along side to the JobManager.Detailed information about different implementations and their pros and cons can be found in this document:https://docs.google.com/document/d/1eIX6FS9stwraRdSUgRSuLXC1sL7NAmxtuqIXe_jSi-k/edit?usp=sharingThe implementation will most likely be Netty based.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.RestEndpointITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.messages.MessageParametersTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.util.RestClientException.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.RestServerEndpointConfiguration.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.RestServerEndpoint.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.RestClientEndpointConfiguration.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.RestClientEndpoint.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.MessageParameters.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.MessageParameter.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.RestHandlerException.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.PipelineErrorHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.HandlerRequest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.AbstractRestHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="7046" opendate="2017-6-29 00:00:00" fixdate="2017-7-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hide logging about downloaded artifacts on travis</summary>
      <description>We can reduce the verbosity of the travis logs by hiding messages about downloaded artifacts, such as this:[INFO] Downloading: https://repo.maven.apache.org/maven2/org/eclipse/tycho/tycho-compiler-jdt/0.21.0/tycho-compiler-jdt-0.21.0.pom[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/eclipse/tycho/tycho-compiler-jdt/0.21.0/tycho-compiler-jdt-0.21.0.pom (2 KB at 62.0 KB/sec)</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.travis.mvn.watchdog.sh</file>
    </fixedFiles>
  </bug>
  <bug id="7047" opendate="2017-6-29 00:00:00" fixdate="2017-7-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reorganize build profiles</summary>
      <description>With the current build times once again hitting the timeout it is time to revisit our approach.The current approach of splitting all tests by name, while easy to maintain or extend, has the big disadvantage that it's fairly binary in regards to the timeout: either we're below the timeout and all builds pass, or we're above and the entire merging process stalls. Furthermore, it requires all modules to be compiled.I propose a different approach by which we bundle several modules, only execute the tests of these modules and skip the compilation of some modules that are not required for these tests.5 groups are my current suggestion, which will result in 10 build profiles total.The groups are: core - core flink modules like core,runtime,streaming-java,metrics,rocksdb libraries - flink-libraries and flink-storm connectors - flink-connectors, flink-connector-wikiedits, flink-tweet-inputformat tests - flink-tests misc - flink-yarn, fink-yarn-tests, flink-mesos, flink-examples, flink-distTo not increase the total number of profiles to ridiculous numbers i also propose to only test against 2 combinations of jdk+hadoop+scala: oraclejdk8 + hadoop 2.8.0 + scala 2.11 openjdk7 + hadoop 2.4.1 + scala 2.10My current estimate is that this will cause profiles to take at most 40 minutes.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.travis.mvn.watchdog.sh</file>
      <file type="M">pom.xml</file>
      <file type="M">.travis.yml</file>
    </fixedFiles>
  </bug>
  <bug id="705" opendate="2014-6-9 00:00:00" fixdate="2014-8-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Check if TPC-H resources can be added</summary>
      <description>Some of our tests and examples are derived from the TPC-H. Although we do not import source code or libraries, we should check if it is OK with the TPC-H / Apache license to add SQL DDL or data generated by the TPC-H generator to our distribution.---------------- Imported from GitHub ----------------Url: https://github.com/stratosphere/stratosphere/issues/705Created by: fhueskeLabels: Created at: Fri Apr 18 11:20:39 CEST 2014State: open</description>
      <version>None</version>
      <fixedVersion>0.10.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.recordJobTests.TPCHQueryAsterixITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.recordJobTests.TPCHQuery9ITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.recordJobTests.TPCHQuery3WithUnionITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.recordJobTests.TPCHQuery3ITCase.java</file>
    </fixedFiles>
  </bug>
  <bug id="7052" opendate="2017-6-30 00:00:00" fixdate="2017-7-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>remove NAME_ADDRESSABLE mode</summary>
      <description>Remove the BLOB store's NAME_ADDRESSABLE mode as it is currently not used and partly broken.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.execution.librarycache.BlobLibraryCacheManagerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.blob.BlobServerPutTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.blob.BlobServerDeleteTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.blob.BlobRecoveryITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.blob.BlobClientTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.blob.BlobClientSslTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.VoidBlobStore.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.FileSystemBlobStore.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobView.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobStore.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobServerProtocol.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobServerConnection.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobServer.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="7056" opendate="2017-6-30 00:00:00" fixdate="2017-8-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>add API to allow job-related BLOBs to be stored</summary>
      <description>To ease cleanup, we will make job-related BLOBs be reflected in the blob storage so that they may be removed along with the job. This adds the jobId to many methods similar to the previous code from the NAME_ADDRESSABLE mode.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.jobmanager.JobSubmitTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.execution.librarycache.BlobLibraryCacheRecoveryITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.execution.librarycache.BlobLibraryCacheManagerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.blob.BlobUtilsTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.blob.BlobServerPutTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.blob.BlobServerGetTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.blob.BlobServerDeleteTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.blob.BlobRecoveryITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.blob.BlobClientTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.blob.BlobCacheSuccessTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.blob.BlobCacheRetriesTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobgraph.JobGraph.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.client.JobClient.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.VoidBlobStore.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.FileSystemBlobStore.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobView.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobStore.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobService.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobServerProtocol.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobServerConnection.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobServer.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobClient.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobCache.java</file>
    </fixedFiles>
  </bug>
  <bug id="7063" opendate="2017-7-3 00:00:00" fixdate="2017-7-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>test instability in OperatorStateBackendTest.testSnapshotAsyncCancel</summary>
      <description>OperatorStateBackendTest.testSnapshotAsyncCancel seems to be instable and sometimes fails:testSnapshotAsyncCancel(org.apache.flink.runtime.state.OperatorStateBackendTest) Time elapsed: 0.036 sec &lt;&lt;&lt; ERROR!java.util.concurrent.ExecutionException: java.io.IOException: Stream closed. at java.util.concurrent.FutureTask.report(FutureTask.java:122) at java.util.concurrent.FutureTask.get(FutureTask.java:206) at org.apache.flink.runtime.state.OperatorStateBackendTest.testSnapshotAsyncCancel(OperatorStateBackendTest.java:636)Caused by: java.io.IOException: Stream closed. at org.apache.flink.runtime.util.BlockerCheckpointStreamFactory$1.write(BlockerCheckpointStreamFactory.java:95) at java.io.DataOutputStream.writeInt(DataOutputStream.java:197) at org.apache.flink.core.io.VersionedIOReadableWritable.write(VersionedIOReadableWritable.java:40) at org.apache.flink.runtime.state.OperatorBackendSerializationProxy.write(OperatorBackendSerializationProxy.java:65) at org.apache.flink.runtime.state.DefaultOperatorStateBackend$1.performOperation(DefaultOperatorStateBackend.java:255) at org.apache.flink.runtime.state.DefaultOperatorStateBackend$1.performOperation(DefaultOperatorStateBackend.java:233) at org.apache.flink.runtime.io.async.AbstractAsyncIOCallable.call(AbstractAsyncIOCallable.java:72) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:748)logs: https://s3.amazonaws.com/archive.travis-ci.org/jobs/248822546/log.txt?X-Amz-Expires=30&amp;X-Amz-Date=20170703T092940Z&amp;X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAJRYRXRSVGNKPKO5A/20170703/us-east-1/s3/aws4_request&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=f468cd238236d7038a1e12086dd4a0e3ba538d93c883790d180e4c63b973a5f2 https://transfer.sh/MHawk/17392.5.tar.gz</description>
      <version>1.3.1,1.4.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.async.AsyncStoppableTaskWithCallback.java</file>
    </fixedFiles>
  </bug>
  <bug id="7069" opendate="2017-7-3 00:00:00" fixdate="2017-7-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Catch exceptions for each reporter separately</summary>
      <description>The metric system can be effectively disabled by a reporter that throws exceptions whenever it is notified of adding metrics.The reason is that the catching of exceptions isn't granular enough, as this peace of psude code shows:addMetric(metric): try for reporter in reporters: reporter.addMetric(metric) metricQueryService.addMetric(metric) catch (e) logError(e) If a reporter throws an exception we never even attempt the other reporters, not notify the MQS which disabled metrics in the WebUI.</description>
      <version>1.3.1,1.4.0</version>
      <fixedVersion>1.3.2,1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.MetricRegistryTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.groups.MetricGroupTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.MetricRegistry.java</file>
    </fixedFiles>
  </bug>
  <bug id="7072" opendate="2017-7-3 00:00:00" fixdate="2017-8-3 01:00:00" resolution="Done">
    <buginformation>
      <summary>Create RESTful cluster endpoint</summary>
      <description>In order to communicate with the cluster from the RESTful client, we have to implement a RESTful cluster endpoint. The endpoint shall support the following operations: List jobs (GET): Get list of all running jobs on the cluster Submit job (POST): Submit a job to the cluster (only supported in session mode) Get job status (GET): Get the status of an executed job (and maybe the JobExecutionResult) Lookup job leader (GET): Gets the JM leader for the given jobThis endpoint will run in session mode alongside the dispatcher/session runner and forward calls to this component which maintains a view on all currently executed jobs.In the per-job mode, the endpoint will return only the single running job and the address of the JobManager alongside which it is running. Furthermore, it won't accept job submissions.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.RestServerEndpoint.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.JobTerminationMessageParameters.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.dispatcher.DispatcherGateway.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.dispatcher.Dispatcher.java</file>
      <file type="M">flink-clients.src.test.java.org.apache.flink.client.program.ClusterClientTest.java</file>
      <file type="M">flink-clients.src.test.java.org.apache.flink.client.CliFrontendStopTest.java</file>
      <file type="M">flink-clients.src.test.java.org.apache.flink.client.CliFrontendRunTest.java</file>
      <file type="M">flink-clients.src.test.java.org.apache.flink.client.CliFrontendListCancelTest.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.program.ClusterClient.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.CliFrontend.java</file>
    </fixedFiles>
  </bug>
  <bug id="7078" opendate="2017-7-3 00:00:00" fixdate="2017-9-3 01:00:00" resolution="Done">
    <buginformation>
      <summary>Support fencing tokens to filter out outdated messages</summary>
      <description>In order to guard against split brain situations, it is important that RPC calls are guarded with a fencing token. The sender attaches his fencing token to a RPC message which is then used on the receiver side to compare against the expected fencing token. An example is the leader session ID which we attach to all critical RPC messages.So far, in the Flip-6 code base we send fencing tokens explicitly. This is not only cumbersome but also error-prone because you have to do it for all RPCs. Therefore, it would be better if we could automatically compare fencing tokens for a given RPC from a given source. This should ideally happen on the level of the RPC server.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rpc.TestingRpcService.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rpc.AsyncCallsTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rpc.RpcService.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rpc.RpcEndpoint.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rpc.akka.messages.Shutdown.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rpc.akka.messages.RunAsync.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rpc.akka.messages.RpcInvocation.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rpc.akka.messages.RemoteRpcInvocation.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rpc.akka.messages.Processing.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rpc.akka.messages.LocalRpcInvocation.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rpc.akka.messages.CallAsync.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rpc.akka.AkkaRpcService.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rpc.akka.AkkaRpcActor.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rpc.akka.AkkaInvocationHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="7103" opendate="2017-7-4 00:00:00" fixdate="2017-7-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement skeletal structure of dispatcher component</summary>
      <description>Implement the skeletal structure of the Dispatcher component. The initial functionality will support job submissions and listing of jobs.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.YarnFlinkApplicationMasterRunner.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.jobmaster.JobManagerRunnerMockTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.minicluster.MiniClusterJobDispatcher.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.minicluster.MiniCluster.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobmaster.JobManagerServices.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobmaster.JobManagerRunner.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobmanager.SubmittedJobGraph.java</file>
    </fixedFiles>
  </bug>
  <bug id="7105" opendate="2017-7-5 00:00:00" fixdate="2017-11-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make ActorSystem creation per default non-daemonic</summary>
      <description>At the moment, we create all ActorSystems with the setting daemonic=on. This has the consequence that we have to wait in the main thread on the ActorSystem's termination. By making the ActorSystems non-daemonic, we could get rid of this artifact. Especially since we have the ProcessReapers which terminate the process once a registered actor terminates.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.scala.org.apache.flink.runtime.akka.AkkaUtils.scala</file>
    </fixedFiles>
  </bug>
  <bug id="7111" opendate="2017-7-6 00:00:00" fixdate="2017-7-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>flink-scala-shell fails on mvn verify</summary>
      <description>Running mvn verify after mvn clean install -DskipTests causes the build to fail in flink-scala-shell with[ERROR] Failed to execute goal org.apache.maven.plugins:maven-assembly-plugin:2.4:single (create-library-loading-jar) on project flink-scala-shell_2.11: Failed to create assembly: Error creating assembly archive test-jar: You must set at least one file. -&gt; [Help 1]</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-scala-shell.src.test.scala.org.apache.flink.api.scala.ScalaShellITCase.scala</file>
      <file type="M">flink-scala-shell.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7126" opendate="2017-7-7 00:00:00" fixdate="2017-7-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support Distinct for Stream SQL and Table API</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.scala.stream.table.UnsupportedOpsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.scala.stream.table.GroupAggregationsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.scala.stream.sql.AggregationsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.logical.operators.scala</file>
      <file type="M">docs.dev.table.tableApi.md</file>
      <file type="M">docs.dev.table.sql.md</file>
    </fixedFiles>
  </bug>
  <bug id="7131" opendate="2017-7-7 00:00:00" fixdate="2017-7-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Streaming wordcount jar does not contain WordCountData</summary>
      <description>The WordCountData isn't included in the jar.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-examples.flink-examples-streaming.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7136" opendate="2017-7-7 00:00:00" fixdate="2017-11-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Docs search can be customized to be more useful</summary>
      <description>The google custom search engine we're using for search can be customized to make it more useful.I propose to turn off ads (which is allowed, since this site belongs to a non-profit org) add additional sources of information (mailing lists, JIRA, flips, stack overflow, flink forward) use refinements (tabs) to make it easy to navigate between these sources</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs..includes.sidenav.html</file>
      <file type="M">docs.search-results.md</file>
    </fixedFiles>
  </bug>
  <bug id="7138" opendate="2017-7-8 00:00:00" fixdate="2017-7-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Storm example jars do not contain WordCountData</summary>
      <description>Same as FLINK-7131.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-contrib.flink-storm-examples.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7166" opendate="2017-7-12 00:00:00" fixdate="2017-8-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>generated avro sources not cleaned up or re-created after changes</summary>
      <description>Since the AVRO upgrade to 1.8.2, I could compile the flink-avro module any more with a failure like this in mvn clean install -DskipTests -pl flink-connectors/flink-avro:Compilation failure[ERROR] flink-connectors/flink-avro/src/test/java/org/apache/flink/api/io/avro/generated/Fixed16.java:[10,8] org.apache.flink.api.io.avro.generated.Fixed16 is not abstract and does not override abstract method readExternal(java.io.ObjectInput) in org.apache.avro.specific.SpecificFixedThis was caused by maven both not cleaning up the generated sources and also not overwriting them with new ones itself. Only a manual rm -rf flink-connectors/flink-avro/src/test/java/org/apache/flink/api/io/avro/generated solved the issue.The cause for this, though, is that the avro files are generated under the src directory, not target/generated-test-sources as they should be. Either the generated sources should be cleaned up as well, or the generated files should be moved to this directory which is a more invasive change due to some hacks with respect to these files.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-avro.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7174" opendate="2017-7-13 00:00:00" fixdate="2017-7-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bump dependency of Kafka 0.10.x to the latest one</summary>
      <description>We are using pretty old Kafka version for 0.10. Besides any bug fixes and improvements that were made between 0.10.0.1 and 0.10.2.1, it 0.10.2.1 version is more similar to 0.11.0.</description>
      <version>1.2.1,1.3.1,1.4.0</version>
      <fixedVersion>1.3.2,1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.AbstractPartitionDiscoverer.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.test.java.org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThreadTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaTestEnvironmentImpl.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7176" opendate="2017-7-13 00:00:00" fixdate="2017-7-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Failed builds (due to compilation) don&amp;#39;t upload logs</summary>
      <description>If the compile phase fails on travis flink-dist may not be created. This causes the check for the inclusion of snappy in flink-dist to fail.The function doing this check calls exit 1 on error, which exits the entire shell, thus skipping subsequent actions like the upload of logs.</description>
      <version>1.3.0,1.4.0</version>
      <fixedVersion>1.3.0,1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.travis.mvn.watchdog.sh</file>
    </fixedFiles>
  </bug>
  <bug id="7206" opendate="2017-7-17 00:00:00" fixdate="2017-8-17 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Implementation of DataView to support state access for UDAGG</summary>
      <description>Implementation of MapView and ListView to support state access for UDAGG.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.stream.table.OverWindowITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.stream.table.GroupWindowITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.stream.table.AggregateITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.harness.HarnessTestBase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.batch.table.AggregateITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.table.runtime.utils.JavaUserDefinedAggFunctions.java</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.RowTimeUnboundedOver.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.RowTimeBoundedRowsOver.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.RowTimeBoundedRangeOver.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.ProcTimeUnboundedOver.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.ProcTimeBoundedRowsOver.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.ProcTimeBoundedRangeOver.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.GroupAggProcessFunction.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.GeneratedAggregations.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.AggregateUtil.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.utils.UserDefinedFunctionUtils.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.CodeGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.AggregationCodeGenerator.scala</file>
    </fixedFiles>
  </bug>
  <bug id="7208" opendate="2017-7-17 00:00:00" fixdate="2017-12-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Refactor build-in agg(MaxWithRetractAccumulator and MinWithRetractAccumulator) using the DataView</summary>
      <description>Refactor build-in agg(MaxWithRetractAccumulator and MinWithRetractAccumulator) using the DataView.</description>
      <version>None</version>
      <fixedVersion>1.8.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.stream.table.AggregateITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.harness.AggFunctionHarnessTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.aggfunctions.AggFunctionTestBase.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.AggregateUtil.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.aggfunctions.MinAggFunctionWithRetract.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.aggfunctions.MaxAggFunctionWithRetract.scala</file>
    </fixedFiles>
  </bug>
  <bug id="7211" opendate="2017-7-17 00:00:00" fixdate="2017-7-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Exclude Gelly javadoc jar from release</summary>
      <description></description>
      <version>1.3.2,1.4.0</version>
      <fixedVersion>1.3.2,1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-dist.src.main.assemblies.bin.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7220" opendate="2017-7-18 00:00:00" fixdate="2017-7-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update RocksDB dependency to 5.5.5</summary>
      <description>The latest release of RocksDB (5.5.5) fixes the issues from previous versions (slow merge performance, segfaults) in connection with Flink and seems stable for us to use. We can move away from our custom FRocksDB build, back to the latest release.</description>
      <version>1.3.2,1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackendConfigTest.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.benchmark.RocksDBPerformanceTest.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackend.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.PredefinedOptions.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7228" opendate="2017-7-19 00:00:00" fixdate="2017-7-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Harden HistoryServerStaticFileHandlerTest</summary>
      <description>We can harden the test to use a free port instead of the hard-coded 8081.</description>
      <version>1.3.1,1.4.0</version>
      <fixedVersion>1.3.2,1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.history.HistoryServerStaticFileServerHandlerTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="7230" opendate="2017-7-19 00:00:00" fixdate="2017-7-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Travis sometimes fails due to downloaded snapshot artifacts</summary>
      <description>The travis builds currently fail sometimes because for some reason snapshot artifacts are downloaded when executing tests, after compilation. This causes issues for the java 7 profiles, as the snapshot artifacts are released with java 8.The cause for this is currently unknown; I'm currently trying builds that forbid downloading snapshot artifacts or downloading artifacts during testing in general.Since this issue doesn't always occur I will run these tests multiple times until tomorrow, and if the issue hasn't appeared again will open a PR.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.travis.mvn.watchdog.sh</file>
    </fixedFiles>
  </bug>
  <bug id="7234" opendate="2017-7-19 00:00:00" fixdate="2017-7-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix CombineHint documentation</summary>
      <description>The CombineHint documentation applies to DataSet#reduce not DataSet#reduceGroup and should also be note for DataSet#distinct. It is also set with .setCombineHint(CombineHint) rather than alongside the UDF parameter.</description>
      <version>1.2.2,1.3.2,1.4.0</version>
      <fixedVersion>1.3.2,1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.ReduceOperatorBase.java</file>
      <file type="M">docs.dev.batch.index.md</file>
    </fixedFiles>
  </bug>
  <bug id="7249" opendate="2017-7-24 00:00:00" fixdate="2017-7-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bump Java version in build plugin</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-quickstart.flink-quickstart-scala.src.main.resources.archetype-resources.pom.xml</file>
      <file type="M">flink-quickstart.flink-quickstart-java.src.main.resources.archetype-resources.pom.xml</file>
      <file type="M">docs.setup.building.md</file>
      <file type="M">docs.quickstart.setup.quickstart.md</file>
      <file type="M">docs.quickstart.scala.api.quickstart.md</file>
      <file type="M">docs.quickstart.java.api.quickstart.md</file>
    </fixedFiles>
  </bug>
  <bug id="7250" opendate="2017-7-24 00:00:00" fixdate="2017-7-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Drop the jdk8 build profile</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">.travis.yml</file>
    </fixedFiles>
  </bug>
  <bug id="7253" opendate="2017-7-24 00:00:00" fixdate="2017-7-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove all &amp;#39;assume Java 8&amp;#39; code in tests</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-test-utils-parent.flink-test-utils-junit.src.main.java.org.apache.flink.core.testutils.CommonTestUtils.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.util.JvmExitOnFatalErrorTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.util.BlockingShutdownTest.java</file>
      <file type="M">flink-connectors.flink-connector-cassandra.src.test.java.org.apache.flink.streaming.connectors.cassandra.CassandraConnectorITCase.java</file>
    </fixedFiles>
  </bug>
  <bug id="7256" opendate="2017-7-24 00:00:00" fixdate="2017-7-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>End-to-end tests should only be run after successful compilation</summary>
      <description>If the compilation fails (for example due to checkstyle) the end-to-end tests are currently still run, even though flink-dist most likely wasn't even built.Similar to FLINK-7176.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.travis.mvn.watchdog.sh</file>
    </fixedFiles>
  </bug>
  <bug id="7257" opendate="2017-7-24 00:00:00" fixdate="2017-7-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Extend flink-runtime checkstyle coverage to tests</summary>
      <description>Checkstyle is currently completely skipped for the test files in flink-runtime, which is not what i intended.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.maven.suppressions-runtime.xml</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.util.ClassLoaderUtilsTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.resourcemanager.JobLeaderIdServiceTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.ReduceTaskExternalITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.jobgraph.jsonplan.JsonGeneratorTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.jobgraph.JobTaskVertexTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.executiongraph.ExecutionGraphTestUtils.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.clusterframework.overlays.KeytabOverlayTest.java</file>
      <file type="M">flink-runtime.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7263" opendate="2017-7-25 00:00:00" fixdate="2017-7-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve Pull Request Template</summary>
      <description>As discussed in the mailing list, the suggestion is to update the pull request template as follows:Thank you very much for contributing to Apache Flink - we are happy that you want to help us improve Flink. To help the community review you contribution in the best possible way, please go through the checklist below, which will get the contribution into a shape in which it can be best reviewed.Please understand that we do not do this to make contributions to Flink a hassle. In order to uphold a high standard of quality for code contributions, while at the same time managing a large number of contributions, we need contributors to prepare the contributions well, and give reviewers enough contextual information for the review. Please also understand that contributions that do not follow this guide will take longer to review and thus typically be picked up with lower priority by the community. Contribution Checklist Make sure that the pull request corresponds to a &amp;#91;JIRA issue&amp;#93;(https://issues.apache.org/jira/projects/FLINK/issues). Exceptions are made for typos in JavaDoc or documentation files, which need no JIRA issue. Name the pull request in the form "FLINK-1234 &amp;#91;component&amp;#93; Title of the pull request", where FLINK-1234 should be replaced by the actual issue number. Skip component if you are unsure about which is the best component. Typo fixes that have no associated JIRA issue should be named following this pattern: `&amp;#91;hotfix&amp;#93; &amp;#91;docs&amp;#93; Fix typo in event time introduction` or `&amp;#91;hotfix&amp;#93; &amp;#91;javadocs&amp;#93; Expand JavaDoc for PuncuatedWatermarkGenerator`. Fill out the template below to describe the changes contributed by the pull request. That will give reviewers the context they need to do the review. Make sure that the change passes the automated tests, i.e., `mvn clean verify` Each pull request should address only one issue, not mix up code from multiple issues. Each commit in the pull request has a meaningful commit message (including the JIRA id) Once all items of the checklist are addressed, remove the above text and this checklist, leaving only the filled out template below.*(The sections below can be removed for hotfixes of typos)* What is the purpose of the change (For example: This pull request makes task deployment go through the blob server, rather than through RPC. That way we avoid re-transferring them on each deployment (during recovery).) Brief change log (for example The TaskInfo is stored in the blob store on job creation time as a persistent artifact Deployments RPC transmits only the blob storage reference TaskManagers retrieve the TaskInfo from the blob cache Verifying this change (Please pick either of the following options)This change is a trivial rework / code cleanup without any test coverage.(or)This change is already covered by existing tests, such as (please describe tests).(or)This change added tests and can be verified as follows:(example Added integration tests for end-to-end deployment with large payloads (100MB) Extended integration test for recovery after master (JobManager) failure Added test that validates that TaskInfo is transferred only once across recoveries Manually verified the change by running a 4 node cluser with 2 JobManagers and 4 TaskManagers, a stateful streaming program, and killing one JobManager and to TaskManagers during the execution, verifying that recovery happens correctly. Does this pull request potentially affect one of the following parts: Dependencies (does it add or upgrade a dependency): *(yes / no)* The public API, i.e., is any changed class annotated with `@Public(Evolving)`: *(yes / no)* The serializers: *(yes / no / don't know)* The runtime per-record code paths (performance sensitive): *(yes / no / don't know)* Anything that affects deployment or recovery: JobManager (and its components), Checkpointing, Yarn/Mesos, ZooKeeper: *(yes / no / don't know)*: Documentation Does this pull request introduce a new feature? *(yes / no)* If yes, how is the feature documented? *(not applicable / docs / JavaDocs / not documented)*</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">.github.PULL.REQUEST.TEMPLATE.md</file>
    </fixedFiles>
  </bug>
  <bug id="7300" opendate="2017-7-31 00:00:00" fixdate="2017-11-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>End-to-end tests are instable on Travis</summary>
      <description>It seems like the end-to-end tests are instable, causing the misc build profile to sporadically fail.Incorrect matched output:https://s3.amazonaws.com/archive.travis-ci.org/jobs/258569408/log.txt?X-Amz-Expires=30&amp;X-Amz-Date=20170731T060526Z&amp;X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAJRYRXRSVGNKPKO5A/20170731/us-east-1/s3/aws4_request&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=4ef9ff5e60fe06db53a84be8d73775a46cb595a8caeb806b05dbbf824d3b69e8Another failure example of a different cause then the above, also on the end-to-end tests:https://s3.amazonaws.com/archive.travis-ci.org/jobs/258841693/log.txt?X-Amz-Expires=30&amp;X-Amz-Date=20170731T060007Z&amp;X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAJRYRXRSVGNKPKO5A/20170731/us-east-1/s3/aws4_request&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=4a106b3990228b7628c250cc15407bc2c131c8332e1a94ad68d649fe8d32d726</description>
      <version>1.4.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.java</file>
      <file type="M">test-infra.end-to-end-test.test.streaming.kafka010.sh</file>
      <file type="M">test-infra.end-to-end-test.common.sh</file>
    </fixedFiles>
  </bug>
  <bug id="7303" opendate="2017-7-31 00:00:00" fixdate="2017-8-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Build elasticsearch5 by default</summary>
      <description>The elasticsearch-5 connector is optionally included in flink-connectors, based on whether jdk8 is used or not. Now that we drop java 7 support we can include it by default.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.travis.mvn.watchdog.sh</file>
      <file type="M">flink-connectors.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7305" opendate="2017-7-31 00:00:00" fixdate="2017-8-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add new import block for shaded dependencies</summary>
      <description>Since we will start working against shaded namespaces I propose a new import block for these, to differentiate them from "original" flink imports.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.maven.checkstyle.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7311" opendate="2017-7-31 00:00:00" fixdate="2017-8-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>refrain from using fail(Exception#getMessage()) in core memory tests</summary>
      <description>Most unit tests in the flink/core/memory/ domain still relies on a code pattern like this:try { // ...} catch (Exception e) { e.printStackTrace(); fail(e.getMessage());}This does hides the exception details and should be removed.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-core.src.test.java.org.apache.flink.core.memory.OperationsOnFreedSegmentTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.core.memory.MemorySegmentUndersizedTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.core.memory.MemorySegmentTestBase.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.core.memory.HybridOnHeapMemorySegmentTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.core.memory.HybridOffHeapMemorySegmentTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.core.memory.HeapMemorySegmentTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.core.memory.EndiannessAccessChecks.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.core.memory.CrossSegmentTypeTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="7312" opendate="2017-7-31 00:00:00" fixdate="2017-11-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>activate checkstyle for flink/core/memory/*</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.maven.suppressions-core.xml</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.memory.MemoryManager.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.core.memory.OperationsOnFreedSegmentTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.core.memory.MemorySegmentUndersizedTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.core.memory.MemorySegmentTestBase.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.core.memory.MemorySegmentFactoryTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.core.memory.MemorySegmentChecksTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.core.memory.HybridOnHeapMemorySegmentTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.core.memory.HybridOffHeapMemorySegmentTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.core.memory.HeapMemorySegmentTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.core.memory.EndiannessAccessChecks.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.core.memory.CrossSegmentTypeTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.core.memory.ByteArrayOutputStreamWithPosTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.core.memory.ByteArrayInputStreamWithPosTest.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.SeekableDataOutputView.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.SeekableDataInputView.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.MemoryUtils.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.MemorySegmentSource.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.MemorySegmentFactory.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.MemorySegment.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.HybridMemorySegment.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.HeapMemorySegment.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.DataOutputViewStreamWrapper.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.DataOutputView.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.DataInputViewStreamWrapper.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.DataInputView.java</file>
    </fixedFiles>
  </bug>
  <bug id="7313" opendate="2017-7-31 00:00:00" fixdate="2017-8-31 01:00:00" resolution="Done">
    <buginformation>
      <summary>Add conversion utilities (Scala and old Flink futures)</summary>
      <description>In order to replace Flink's own Futures with Java 8's CompletableFutures we need some conversion utility to transform Scala's Futures and Flink's old Futures into Java 8's CompletableFutures until we have completed the replacement.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.concurrent.FutureUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.concurrent.Executors.java</file>
    </fixedFiles>
  </bug>
  <bug id="7316" opendate="2017-7-31 00:00:00" fixdate="2017-11-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>always use off-heap network buffers</summary>
      <description>In order to send flink buffers through netty into the network, we need to make the buffers use off-heap memory. Otherwise, there will be a hidden copy happening in the NIO stack.</description>
      <version>1.4.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn-tests.src.test.java.org.apache.flink.yarn.YARNSessionCapacitySchedulerITCase.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.io.BarrierBufferMassiveRandomTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskmanager.TaskManagerComponentsStartupShutdownTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskexecutor.TaskManagerServicesTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.legacy.backpressure.BackPressureStatsTrackerITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannelTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.NetworkEnvironmentTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.buffer.NetworkBufferPoolTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.buffer.LocalBufferPoolTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.buffer.LocalBufferPoolDestroyTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.buffer.BufferPoolFactoryTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.api.writer.RecordWriterTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.clusterframework.ContaineredTaskManagerParametersTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskmanager.NetworkEnvironmentConfiguration.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskManagerServicesConfiguration.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskManagerServices.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.buffer.NetworkBufferPool.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.clusterframework.ContaineredTaskManagerParameters.java</file>
      <file type="M">flink-dist.src.main.flink-bin.bin.config.sh</file>
      <file type="M">docs.ops.config.md</file>
    </fixedFiles>
  </bug>
  <bug id="7321" opendate="2017-7-31 00:00:00" fixdate="2017-8-31 01:00:00" resolution="Done">
    <buginformation>
      <summary>Remove Flink&amp;#39;s futures from HeartbeatManager</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.heartbeat.HeartbeatManagerTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskExecutor.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.resourcemanager.ResourceManager.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobmaster.JobMaster.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.heartbeat.HeartbeatManagerSenderImpl.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.heartbeat.HeartbeatManagerImpl.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.heartbeat.HeartbeatListener.java</file>
    </fixedFiles>
  </bug>
  <bug id="7334" opendate="2017-8-1 00:00:00" fixdate="2017-8-1 01:00:00" resolution="Done">
    <buginformation>
      <summary>Replace Flink&amp;#39;s futures by CompletableFuture in RpcGateway</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskTerminationTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.async.queue.UnorderedStreamElementQueueTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.async.queue.StreamElementQueueTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.async.queue.OrderedStreamElementQueueTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskmanager.TaskManagerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskexecutor.TaskExecutorTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskexecutor.TaskExecutorITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rpc.TestingSerialRpcService.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rpc.TestingRpcService.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rpc.TestingGatewayBase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rpc.RpcConnectionTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rpc.RpcCompletenessTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rpc.AsyncCallsTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rpc.akka.MessageSerializationTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rpc.akka.AkkaRpcServiceTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rpc.akka.AkkaRpcActorTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.resourcemanager.slotmanager.SlotProtocolTest.java</file>
      <file type="M">flink-mesos.src.test.java.org.apache.flink.mesos.runtime.clusterframework.MesosResourceManagerTest.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.TaskManagerLogHandler.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.TaskManagerLogHandlerTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.dispatcher.DispatcherGateway.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.Execution.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.instance.SlotPool.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.instance.SlotPoolGateway.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobmanager.slots.ActorTaskManagerGateway.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobmanager.slots.TaskManagerGateway.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobmaster.JobMaster.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobmaster.JobMasterGateway.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobmaster.RpcTaskManagerGateway.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.registration.RetryingRegistration.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.resourcemanager.JobLeaderIdService.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.resourcemanager.ResourceManager.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.resourcemanager.ResourceManagerGateway.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.resourcemanager.slotmanager.SlotManager.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rpc.akka.AkkaInvocationHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rpc.akka.AkkaRpcActor.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rpc.akka.AkkaRpcService.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rpc.MainThreadExecutable.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rpc.RpcEndpoint.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rpc.RpcService.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rpc.SelfGateway.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.JobLeaderService.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.rpc.RpcInputSplitProvider.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.rpc.RpcPartitionStateChecker.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.rpc.RpcResultPartitionConsumableNotifier.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskExecutor.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskExecutorGateway.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskExecutorToResourceManagerConnection.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskManagerRunner.java</file>
      <file type="M">flink-runtime.src.main.scala.org.apache.flink.runtime.jobmanager.JobManager.scala</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.akka.QuarantineMonitorTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.checkpoint.CheckpointCoordinatorMasterHooksTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.clusterframework.ResourceManagerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.dispatcher.DispatcherTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.executiongraph.ExecutionGraphMetricsTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.executiongraph.ExecutionGraphSchedulingTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.executiongraph.ExecutionGraphStopTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.executiongraph.utils.NotCancelAckingTaskGateway.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.executiongraph.utils.SimpleAckingTaskManagerGateway.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.instance.SlotPoolRpcTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.instance.SlotPoolTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.jobmaster.JobMasterTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.registration.RetryingRegistrationTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.registration.TestRegistrationGateway.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.resourcemanager.JobLeaderIdServiceTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.resourcemanager.ResourceManagerJobMasterTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.resourcemanager.ResourceManagerTaskExecutorTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="7335" opendate="2017-8-1 00:00:00" fixdate="2017-8-1 01:00:00" resolution="Done">
    <buginformation>
      <summary>Remove Flink&amp;#39;s own future implementation</summary>
      <description>Delete Flink's own future implementation.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.concurrent.FlinkFutureTest.java</file>
      <file type="M">flink-runtime.src.main.scala.org.apache.flink.runtime.jobmanager.JobManager.scala</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.ExecutionGraphUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.concurrent.impl.FlinkFuture.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.concurrent.impl.FlinkCompletableFuture.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.concurrent.FutureUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.concurrent.Future.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.concurrent.CompletableFuture.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.concurrent.BiFunction.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.concurrent.ApplyFunction.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.concurrent.AcceptFunction.java</file>
    </fixedFiles>
  </bug>
  <bug id="7337" opendate="2017-8-1 00:00:00" fixdate="2017-8-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Refactor handling of time indicator attributes</summary>
      <description>After a discussion on the dev mailing list I propose the following changes to the current handling of time indicator attributes: Remove the separation of logical and physical row type. Hold the event-time timestamp as regular Long field in Row Represent the processing-time indicator type as a null-valued field in Row (1 bit overhead) Remove materialization of event-time timestamps because timestamp is already accessible in Row. Add ProcessFunction to set timestamp into the timestamp field of a StreamRecord.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.DataSetSlideWindowAggReduceGroupFunction.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.harness.NonWindowHarnessTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.harness.JoinHarnessTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.harness.HarnessTestBase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.plan.TimeIndicatorConversionTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.stream.table.TableSourceTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.stream.sql.SortTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.join.WindowJoinUtil.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.CRowOutputMapRunner.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.SortUtil.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.ProcTimeSortProcessFunction.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.ProcTimeBoundedRangeOver.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.IncrementalAggregateTimeWindowFunction.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.IncrementalAggregateAllTimeWindowFunction.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.DataSetTumbleTimeWindowAggReduceGroupFunction.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.BatchTableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.StreamTableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.TableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.calcite.RelTimeIndicatorConverter.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.AggregationCodeGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.calls.ScalarOperators.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.CodeGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.CodeGenUtils.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.ProctimeSqlFunction.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.utils.UserDefinedFunctionUtils.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.datastream.DataStreamGroupWindowAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.AggregateUtil.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.RowTimeBoundedRangeOver.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.RowTimeBoundedRowsOver.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.RowTimeSortProcessFunction.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.RowTimeUnboundedOver.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.TimeWindowPropertyCollector.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.CRowInputMapRunner.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.CRowInputTupleOutputMapRunner.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.TimestampSetterProcessFunction.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.WrappingTimestampSetterProcessFunction.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.typeutils.TimeIndicatorTypeInfo.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.harness.OverWindowHarnessTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.harness.SortProcessFunctionHarnessTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.stream.table.TableSinkITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.stream.TimeAttributesITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.calcite.FlinkTypeFactory.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.TimeMaterializationSqlFunction.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.CommonCalc.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.CommonCorrelate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.dataset.BatchTableSourceScan.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.datastream.DataStreamCalc.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.datastream.DataStreamCorrelate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.datastream.DataStreamGroupAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.datastream.DataStreamOverAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.datastream.DataStreamScan.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.datastream.DataStreamSort.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.datastream.DataStreamUnion.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.datastream.DataStreamValues.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.datastream.DataStreamWindowJoin.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.datastream.StreamScan.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.datastream.StreamTableSourceScan.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.logical.FlinkLogicalTableSourceScan.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.PhysicalTableSourceScan.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.rules.datastream.DataStreamWindowJoinRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.schema.DataStreamTable.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.schema.FlinkTable.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.schema.RowSchema.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.schema.StreamTableSourceTable.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.DataSetSessionWindowAggReduceGroupFunction.scala</file>
    </fixedFiles>
  </bug>
  <bug id="7348" opendate="2017-8-2 00:00:00" fixdate="2017-8-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow redundant modifiers on methods</summary>
      <description>As per the discussion in https://github.com/apache/flink/pull/4447 we should allow redundant modifiers on methods, and revert changes that removed final modifiers from methods.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.maven.checkstyle.xml</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.spargel.MessageIterator.java</file>
      <file type="M">flink-libraries.flink-gelly.src.main.java.org.apache.flink.graph.pregel.MessageIterator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.PlanFilterOperator.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.wrappers.SpoutWrapper.java</file>
    </fixedFiles>
  </bug>
  <bug id="7349" opendate="2017-8-2 00:00:00" fixdate="2017-8-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Only execute checkstyle in one build profile</summary>
      <description>We can save some time in 4/5 build profiles by skipping checkstyle. One of the build profiles builds flink completely and would suffice as a check.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.travis.mvn.watchdog.sh</file>
    </fixedFiles>
  </bug>
  <bug id="7350" opendate="2017-8-2 00:00:00" fixdate="2017-8-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>only execute japicmp in one build profile</summary>
      <description>Similarly to FLINK-7349 we improve build times (and stability!) by only executing the japicmp plugin in the build profile that builds the all of flink.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.travis.mvn.watchdog.sh</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7363" opendate="2017-8-3 00:00:00" fixdate="2017-8-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>add hashes and signatures to the download page</summary>
      <description>As part of the releases, we also generate MD5 hashes and cryptographic signatures but neither link to those nor do we explain which keys are valid release-signing keys. This should be added.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.util.KinesisConfigUtilTest.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.manualtests.ManualProducerTest.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.manualtests.ManualConsumerProducerTest.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.examples.ProduceIntoKinesis.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.config.ProducerConfigConstants.java</file>
      <file type="M">docs.dev.connectors.kinesis.md</file>
    </fixedFiles>
  </bug>
  <bug id="7370" opendate="2017-8-4 00:00:00" fixdate="2017-11-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>rework operator documentation</summary>
      <description>The structure of the operator documentation could be improved the following way: Create category Streaming/Operators. Move Streaming/Overview/DataStream Transformations to Streaming/Operators/Overview. Move ProcessFunction, Windows, and Async IO to Streaming/Operators create any necessary redirects for old URLs</description>
      <version>1.3.0,1.4.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.dev.windows.md</file>
      <file type="M">docs.redirects.windows.2.md</file>
      <file type="M">docs.redirects.windows.md</file>
      <file type="M">docs.ops.state.checkpoints.md</file>
      <file type="M">docs.dev.stream.windows.md</file>
      <file type="M">docs.dev.stream.state.checkpointing.md</file>
      <file type="M">docs.dev.stream.side.output.md</file>
      <file type="M">docs.dev.stream.process.function.md</file>
      <file type="M">docs.dev.stream.operators.md</file>
      <file type="M">docs.dev.stream.asyncio.md</file>
      <file type="M">docs.dev.event.timestamp.extractors.md</file>
      <file type="M">docs.dev.event.time.md</file>
      <file type="M">docs.dev.datastream.api.md</file>
      <file type="M">docs.dev.connectors.index.md</file>
      <file type="M">docs.concepts.programming-model.md</file>
    </fixedFiles>
  </bug>
  <bug id="7379" opendate="2017-8-7 00:00:00" fixdate="2017-8-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove `HighAvailabilityServices` from QS client constructor.</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.query.QueryableStateITCaseRocksDBBackend.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.query.QueryableStateITCaseMemoryBackend.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.query.QueryableStateITCaseFsBackend.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.query.AbstractQueryableStateITCase.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.QueryableStateClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="7382" opendate="2017-8-7 00:00:00" fixdate="2017-3-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Broken links in `Apache Flink Documentation` page</summary>
      <description>Some links in the * External Resources * section are Broken.</description>
      <version>None</version>
      <fixedVersion>1.3.4,1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.index.md</file>
      <file type="M">docs.examples.index.md</file>
    </fixedFiles>
  </bug>
  <bug id="7388" opendate="2017-8-8 00:00:00" fixdate="2017-10-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ProcessFunction.onTimer() sets processing time as timestamp</summary>
      <description>The ProcessFunction.onTimer() method sets the current processing time as event-time timestamp when it is called from a processing time timer.I don't think this behavior is useful. Processing time timestamps won't be aligned with watermarks and are not deterministic. The only reason would be to have some value in the timestamp field. However, the behavior is very subtle and might not be noticed by users.IMO, it would be better to erase the timestamp. This will cause downstream operator that rely on timestamps to fail and notify the users that the logic they implemented was probably not what they intended to do.What do you think Aljoscha Krettek?</description>
      <version>1.3.2,1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.KeyedProcessOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.co.KeyedCoProcessOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.KeyedProcessOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.co.KeyedCoProcessOperator.java</file>
      <file type="M">docs.dev.stream.operators.process.function.md</file>
    </fixedFiles>
  </bug>
  <bug id="7414" opendate="2017-8-10 00:00:00" fixdate="2017-10-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hardcode scala.version to 2.11 in flink-quickstart-scala</summary>
      <description>Currently, the scala.binary.version of the Scala Quickstart is derived from the scala.binary.version of Flink at the time when the Quickstart is built. This means that whatever Scala version is active when we push the Quickstart takes precedence. Currently, when deploying SNAPSHOT versions we deploy 2.10 first, then 2.11, i.e. the 1.4-SNAPSHOT Scala Quickstart has Scala version 2.11. The release script deploys first 2.11 and then 2.10, meaning the final 1.4.0 Scala Quickstart would have 2.10.Simply fixing it to the latest supported (by Flink) will circumvent that issue and users can easily change the Scala version in the Quickstart.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-quickstart.flink-quickstart-scala.src.main.resources.archetype-resources.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7418" opendate="2017-8-10 00:00:00" fixdate="2017-10-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace all uses of jackson with flink-shaded-jackson</summary>
      <description>Jackson is currently used to create JSON responses in the web UI, in the future possibly for the client REST communication.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.DashboardConfigHandler.java</file>
      <file type="M">pom.xml</file>
      <file type="M">flink-yarn-tests.src.test.java.org.apache.flink.yarn.YARNSessionCapacitySchedulerITCase.java</file>
      <file type="M">flink-yarn-tests.pom.xml</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.optimizer.jsonplan.PreviewPlanDumpTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.optimizer.jsonplan.JsonJobGraphGenerationTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.optimizer.jsonplan.DumpCompiledPlanTest.java</file>
      <file type="M">flink-tests.pom.xml</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.AbstractDeserializationSchemaTest.java</file>
      <file type="M">flink-streaming-java.pom.xml</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.RestEndpointITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.messages.RestResponseMarshallingTestBase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.messages.RestRequestMarshallingTestBase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.legacy.utils.ArchivedJobGenerationUtils.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.legacy.SubtasksTimesHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.legacy.SubtasksAllAccumulatorsHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.legacy.SubtaskExecutionAttemptDetailsHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.legacy.SubtaskExecutionAttemptAccumulatorsHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.legacy.metrics.AbstractAggregatingMetricsHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.legacy.JobVertexTaskManagersHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.legacy.JobVertexDetailsHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.legacy.JobVertexBackPressureHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.legacy.JobVertexAccumulatorsHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.legacy.JobExceptionsHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.legacy.JobDetailsHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.legacy.JobConfigHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.legacy.JobCancellationWithSavepointHandlersTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.legacy.JobAccumulatorsHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.legacy.DashboardConfigHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.legacy.CurrentJobsOverviewHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.legacy.checkpoints.CheckpointStatsSubtaskDetailsHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.legacy.checkpoints.CheckpointStatsHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.legacy.checkpoints.CheckpointStatsDetailsHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.legacy.checkpoints.CheckpointConfigHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.messages.webmonitor.MultipleJobsDetailsTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.messages.webmonitor.JobDetailsTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.jobgraph.jsonplan.JsonGeneratorTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.webmonitor.WebMonitorUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.util.RestMapperUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.RestClient.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.json.JobVertexIDSerializer.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.json.JobVertexIDDeserializer.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.job.savepoints.SavepointTriggerResponseBody.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.job.JobSubmitResponseBody.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.job.JobSubmitRequestBody.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.JobVertexAccumulatorsInfo.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.JobPlanInfo.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.JobExceptionsInfo.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.JobConfigInfo.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.ErrorResponseBody.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.DashboardConfiguration.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.ClusterConfigurationInfoEntry.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.checkpoints.TaskCheckpointStatisticsWithSubtaskDetails.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.checkpoints.TaskCheckpointStatistics.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.checkpoints.SubtaskCheckpointStatistics.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.checkpoints.MinMaxAvgStatistics.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.checkpoints.CheckpointStatistics.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.checkpoints.CheckpointingStatistics.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.checkpoints.CheckpointConfigInfo.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.BlobServerPortResponseBody.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.util.MutableIOMetrics.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.util.HandlerUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.TaskManagersHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.SubtasksTimesHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.SubtasksAllAccumulatorsHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.SubtaskExecutionAttemptDetailsHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.SubtaskExecutionAttemptAccumulatorsHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.metrics.AbstractMetricsHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.metrics.AbstractAggregatingMetricsHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.messages.ClusterOverviewWithVersion.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.JsonFactory.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.JobVertexTaskManagersHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.JobVertexDetailsHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.JobVertexBackPressureHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.JobVertexAccumulatorsHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.JobExceptionsHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.JobDetailsHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.JobConfigHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.JobCancellationWithSavepointHandlers.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.JobAccumulatorsHandler.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.util.serialization.JSONDeserializationSchema.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.util.serialization.JsonRowDeserializationSchema.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.util.serialization.JsonRowSerializationSchema.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.JSONDeserializationSchemaTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.JSONKeyValueDeserializationSchemaTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.JsonRowDeserializationSchemaTest.java</file>
      <file type="M">flink-examples.flink-examples-streaming.pom.xml</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.java.org.apache.flink.streaming.examples.twitter.TwitterExample.java</file>
      <file type="M">flink-libraries.flink-gelly-examples.pom.xml</file>
      <file type="M">flink-libraries.flink-gelly-examples.src.main.java.org.apache.flink.graph.Runner.java</file>
      <file type="M">flink-libraries.flink-table.pom.xml</file>
      <file type="M">flink-libraries.flink-table.src.main.java.org.apache.flink.table.explain.PlanJsonParser.java</file>
      <file type="M">flink-mesos.pom.xml</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.cli.FlinkMesosSessionCli.java</file>
      <file type="M">flink-metrics.flink-metrics-datadog.pom.xml</file>
      <file type="M">flink-metrics.flink-metrics-datadog.src.main.java.org.apache.flink.metrics.datadog.DatadogHttpClient.java</file>
      <file type="M">flink-metrics.flink-metrics-datadog.src.main.java.org.apache.flink.metrics.datadog.DMetric.java</file>
      <file type="M">flink-metrics.flink-metrics-datadog.src.test.java.org.apache.flink.metrics.datadog.DatadogHttpClientTest.java</file>
      <file type="M">flink-optimizer.pom.xml</file>
      <file type="M">flink-optimizer.src.main.java.org.apache.flink.optimizer.plantranslate.JobGraphGenerator.java</file>
      <file type="M">flink-optimizer.src.main.java.org.apache.flink.optimizer.plantranslate.JsonMapper.java</file>
      <file type="M">flink-quickstart.flink-quickstart-java.src.main.resources.archetype-resources.pom.xml</file>
      <file type="M">flink-quickstart.flink-quickstart-scala.src.main.resources.archetype-resources.pom.xml</file>
      <file type="M">flink-runtime-web.pom.xml</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.JarActionHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.JarDeleteHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.JarListHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.JarPlanHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.JarRunHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.history.HistoryServerArchiveFetcher.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.history.HistoryServerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.WebFrontendITCase.java</file>
      <file type="M">flink-runtime.pom.xml</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.history.FsJobArchivist.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobgraph.jsonplan.JsonPlanGenerator.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.messages.webmonitor.ClusterOverview.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.messages.webmonitor.JobDetails.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.messages.webmonitor.JobsOverview.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.messages.webmonitor.MultipleJobsDetails.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.AbstractRestHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.checkpoints.CheckpointConfigHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.checkpoints.CheckpointStatsDetailsHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.checkpoints.CheckpointStatsDetailsSubtasksHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.checkpoints.CheckpointStatsHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.ClusterConfigHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.ClusterOverviewHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.CurrentJobIdsHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.CurrentJobsOverviewHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="7419" opendate="2017-8-10 00:00:00" fixdate="2017-11-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Shade jackson dependency in flink-avro</summary>
      <description>Avro uses org.codehouse.jackson which also exists in multiple incompatible versions. We should shade it to org.apache.flink.shaded.avro.org.codehouse.jackson.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.travis.mvn.watchdog.sh</file>
      <file type="M">flink-formats.flink-avro.pom.xml</file>
      <file type="M">flink-dist.pom.xml</file>
      <file type="M">flink-connectors.flink-avro.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7439" opendate="2017-8-14 00:00:00" fixdate="2017-9-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support variable arguments for UDTF in SQL</summary>
      <description>Currently, both UDF and UDAF support variable parameters, but UDTF not. FLINK-5882 supports variable UDTF for Table API only, but missed SQL.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.TableFunction.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.ScalarFunction.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.stream.table.validation.CorrelateValidationTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.stream.sql.CorrelateTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.batch.sql.CorrelateTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.table.runtime.utils.JavaUserDefinedTableFunctions.java</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.validate.FunctionCatalog.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.schema.FlinkTableFunctionImpl.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.rules.logical.LogicalUnnestRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.logical.operators.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.utils.UserDefinedFunctionUtils.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.utils.TableSqlFunction.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.UserDefinedFunction.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.calls.TableFunctionCallGen.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.calls.ScalarFunctionCallGen.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.TableEnvironment.scala</file>
      <file type="M">docs.dev.table.udfs.md</file>
    </fixedFiles>
  </bug>
  <bug id="7440" opendate="2017-8-14 00:00:00" fixdate="2017-9-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add eager serializable checks on provided de-/serialization schemas for Kinesis consumer / producer</summary>
      <description>For better user experience, we should add eager serializable checks on the provided KinesisDeserializationSchema / KinesisSerializationSchema, with better error messages pointing out exactly that the serialization schema isn't serializable.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.FlinkKinesisConsumerTest.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.FlinkKinesisConsumer.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.FlinkKinesisProducer.java</file>
    </fixedFiles>
  </bug>
  <bug id="7445" opendate="2017-8-14 00:00:00" fixdate="2017-8-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove FLINK-1234 reference from PR template</summary>
      <description>The PR template on github contains a reference to FLINK-1234 as an example for the PR title. The problem is that every PR that doesn't fill out the template, or rather does not delete that part of the template, will now be referenced in FLINK-1234, leading to spam on the mailing list.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">.github.PULL.REQUEST.TEMPLATE.md</file>
    </fixedFiles>
  </bug>
  <bug id="7446" opendate="2017-8-15 00:00:00" fixdate="2017-10-15 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Support to define an existing field as the rowtime field for TableSource</summary>
      <description>Currently DefinedRowtimeAttribute can define an appended rowtime field for a TableSource. But it would be helpful if we can support to define an existing field as the rowtime field. Just like registering a DataStream, the rowtime field can be appended but also can replace an existing field.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.stream.TimeAttributesITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.stream.table.TableSourceITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.validation.TableSourceValidationTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.stream.table.validation.TableSourceValidationTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.stream.table.TableSourceTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.sources.definedTimeAttributes.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.schema.StreamTableSourceTable.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.rules.logical.PushProjectIntoTableSourceScanRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.logical.FlinkLogicalTableSourceScan.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.datastream.StreamTableSourceScan.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.CodeGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.StreamTableEnvironment.scala</file>
      <file type="M">docs.dev.table.streaming.md</file>
      <file type="M">docs.dev.table.sourceSinks.md</file>
    </fixedFiles>
  </bug>
  <bug id="7457" opendate="2017-8-16 00:00:00" fixdate="2017-9-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make dispatcher highly available</summary>
      <description>The dispatcher component should be made highly available similar to the ResourceManager and the JobMasters.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.highavailability.YarnPreConfiguredMasterNonHaServices.java</file>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.highavailability.YarnIntraNonHaMasterServices.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskexecutor.TaskExecutorTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.highavailability.TestingManualHighAvailabilityServices.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.highavailability.TestingHighAvailabilityServices.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.highavailability.nonha.standalone.StandaloneHaServicesTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.dispatcher.DispatcherTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rpc.RpcUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.highavailability.zookeeper.ZooKeeperHaServices.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.highavailability.nonha.standalone.StandaloneHaServices.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedHaServices.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.highavailability.HighAvailabilityServicesUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.highavailability.HighAvailabilityServices.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.dispatcher.DispatcherGateway.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.dispatcher.Dispatcher.java</file>
    </fixedFiles>
  </bug>
  <bug id="7462" opendate="2017-8-16 00:00:00" fixdate="2017-8-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add very obvious warning about outdated docs</summary>
      <description>The current warning for outdated docs is not very obvious in the footer of the page. I would like to increase the visibility of this by adjusting this footer and adding a warning to actual content.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs..layouts.plain.html</file>
      <file type="M">docs..layouts.base.html</file>
      <file type="M">docs..config.yml</file>
    </fixedFiles>
  </bug>
  <bug id="7480" opendate="2017-8-18 00:00:00" fixdate="2017-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Set HADOOP_CONF_DIR to sane default if not set</summary>
      <description>Currently, both AWS and GCE don't have a HADOOP_CONF_DIR set by default. This makes the out-of-box experience on these cloud environments bad because not setting it results in errors that are not obviously clear.In case HADOOP_CONF_DIR is not set we should check if /etc/hadoop/conf exits and set HADOOP_CONF_DIR to that.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-dist.src.main.flink-bin.bin.config.sh</file>
    </fixedFiles>
  </bug>
  <bug id="7491" opendate="2017-8-22 00:00:00" fixdate="2017-10-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support COLLECT Aggregate function in Flink SQL</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.stream.sql.SqlITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.batch.sql.AggregateITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.validate.FunctionCatalog.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.AggregateUtil.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.FlinkRelNode.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.ExpressionReducer.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.calcite.FlinkTypeFactory.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.Types.scala</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.MapTypeInfo.java</file>
      <file type="M">docs.dev.table.sql.md</file>
    </fixedFiles>
  </bug>
  <bug id="7505" opendate="2017-8-24 00:00:00" fixdate="2017-8-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use lambdas in suppressed exception idiom</summary>
      <description>We can use Java 8 lamdas for the suppressed exception idiom on loops to unify the code for all possible methods without parameters that throw exceptions, such as close(), dispose(), etc.</description>
      <version>1.4.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.StateUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="7511" opendate="2017-8-25 00:00:00" fixdate="2017-5-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove dead code after dropping backward compatibility with &lt;=1.2</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.migration.MigrationVersion.java</file>
      <file type="M">flink-libraries.flink-cep.src.test.resources.cep-starting-1.2-snapshot</file>
      <file type="M">flink-libraries.flink-cep.src.test.resources.cep-single-pattern-1.2-snapshot</file>
      <file type="M">flink-libraries.flink-cep.src.test.resources.cep-non-keyed-1.1-snapshot</file>
      <file type="M">flink-libraries.flink-cep.src.test.resources.cep-migration-starting-new-pattern-flink1.2-snapshot</file>
      <file type="M">flink-libraries.flink-cep.src.test.resources.cep-migration-single-pattern-afterwards-flink1.2-snapshot</file>
      <file type="M">flink-libraries.flink-cep.src.test.resources.cep-migration-after-branching-flink1.2-snapshot</file>
      <file type="M">flink-libraries.flink-cep.src.test.resources.cep-keyed-1.1-snapshot</file>
      <file type="M">flink-libraries.flink-cep.src.test.resources.cep-branching-1.2-snapshot</file>
      <file type="M">flink-libraries.flink-cep.src.test.java.org.apache.flink.cep.operator.CEPMigrationTest.java</file>
      <file type="M">flink-libraries.flink-cep.src.test.java.org.apache.flink.cep.nfa.SharedBufferTest.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.pattern.SubtypeFilterFunction.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.pattern.OrFilterFunction.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.pattern.AndFilterFunction.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.NonDuplicatingTypeSerializer.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.nfa.StateTransition.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.nfa.State.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.nfa.SharedBuffer.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.nfa.NFA.java</file>
      <file type="M">docs.dev.libs.cep.md</file>
    </fixedFiles>
  </bug>
  <bug id="7521" opendate="2017-8-25 00:00:00" fixdate="2017-3-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove the 10MB limit from the current REST implementation.</summary>
      <description>In the current AbstractRestServer we impose an upper bound of 10MB in the states we can transfer. This is in the line .addLast(new HttpObjectAggregator(1024 * 1024 * 10)) of the server implementation. This limit is restrictive for some of the usecases planned to use this implementation (e.g. the job submission client which has to send full jars, or the queryable state client which may have to receive states bigger than that).This issue proposes the elimination of this limit.</description>
      <version>1.4.0,1.5.0,1.6.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.RestServerEndpointITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandlerTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.webmonitor.WebMonitorEndpoint.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.util.HandlerUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.RouterHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.RestHandlerConfiguration.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.PipelineErrorHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.job.JobSubmitRequestBody.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.RestServerEndpointConfiguration.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.RestServerEndpoint.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.RestClientConfiguration.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.RestClient.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.RestOptions.java</file>
    </fixedFiles>
  </bug>
  <bug id="7531" opendate="2017-8-26 00:00:00" fixdate="2017-9-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move existing REST handler to flink-runtime</summary>
      <description>Since the new REST endpoints live in flink-runtime we should move the existing rest handlers to flink-runtime as well. The static web server content remains in flink-runtime-web.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.history.HistoryServerStaticFileServerHandler.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.utils.ArchivedJobGenerationUtils.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.utils.ArchivedExecutionVertexBuilder.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.utils.ArchivedExecutionJobVertexBuilder.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.utils.ArchivedExecutionGraphBuilder.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.utils.ArchivedExecutionConfigBuilder.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.utils.ArchivedExecutionBuilder.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.StackTraceSampleCoordinatorTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.StackTraceSampleCoordinatorITCase.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.metrics.TaskManagerMetricsHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.metrics.MetricStoreTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.metrics.MetricFetcherTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.metrics.JobVertexMetricsHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.metrics.JobMetricsHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.metrics.JobManagerMetricsHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.metrics.AbstractMetricsHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.history.HistoryServerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.history.FsJobArchivistTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.TaskManagersHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.TaskManagerLogHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.SubtasksTimesHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.SubtasksAllAccumulatorsHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.SubtaskExecutionAttemptDetailsHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.SubtaskExecutionAttemptAccumulatorsHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.SubtaskCurrentAttemptDetailsHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.JobVertexTaskManagersHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.JobVertexDetailsHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.JobVertexBackPressureHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.JobVertexAccumulatorsHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.JobStoppingHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.JobPlanHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.JobManagerConfigHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.JobExceptionsHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.JobDetailsHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.JobConfigHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.JobCancellationWithSavepointHandlersTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.JobCancellationHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.JobAccumulatorsHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.JarActionHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.HandlerRedirectUtilsTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.DashboardConfigHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.CurrentJobsOverviewHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.CurrentJobIdsHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.ClusterOverviewHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.checkpoints.CheckpointStatsSubtaskDetailsHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.checkpoints.CheckpointStatsHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.checkpoints.CheckpointStatsDetailsHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.checkpoints.CheckpointStatsCacheTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.checkpoints.CheckpointConfigHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.files.MimeTypesTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.BackPressureStatsTrackerTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.BackPressureStatsTrackerITCase.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.WebRuntimeMonitor.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.WebHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.utils.MutableIOMetrics.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.StackTraceSampleCoordinator.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.StackTraceSample.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.RuntimeMonitorHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.OperatorBackPressureStats.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.NotFoundException.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.metrics.TaskManagerMetricsHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.metrics.MetricStore.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.metrics.MetricFetcher.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.metrics.JobVertexMetricsHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.metrics.JobMetricsHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.metrics.JobManagerMetricsHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.metrics.AbstractMetricsHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.BackPressureStatsTracker.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.ExecutionGraphHolder.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.files.StaticFileServerHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.AbstractExecutionGraphRequestHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.AbstractJobVertexRequestHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.AbstractJsonRequestHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.AbstractSubtaskAttemptRequestHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.AbstractSubtaskRequestHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.checkpoints.CheckpointConfigHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.checkpoints.CheckpointStatsCache.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.checkpoints.CheckpointStatsDetailsHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.checkpoints.CheckpointStatsDetailsSubtasksHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.checkpoints.CheckpointStatsHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.ClusterOverviewHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.ConstantTextHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.CurrentJobIdsHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.CurrentJobsOverviewHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.DashboardConfigHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.JarAccessDeniedHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.JarActionHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.JarDeleteHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.JarListHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.JarPlanHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.JarRunHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.JarUploadHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.JobAccumulatorsHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.JobCancellationHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.JobCancellationWithSavepointHandlers.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.JobConfigHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.JobDetailsHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.JobExceptionsHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.JobManagerConfigHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.JobPlanHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.JobStoppingHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.JobVertexAccumulatorsHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.JobVertexBackPressureHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.JobVertexDetailsHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.JobVertexTaskManagersHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.JsonFactory.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.RequestHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.RequestHandlerException.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.SubtaskCurrentAttemptDetailsHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.SubtaskExecutionAttemptAccumulatorsHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.SubtaskExecutionAttemptDetailsHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.SubtasksAllAccumulatorsHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.SubtasksTimesHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.TaskManagerLogHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.TaskManagersHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.history.HistoryServer.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.history.HistoryServerArchiveFetcher.java</file>
    </fixedFiles>
  </bug>
  <bug id="7543" opendate="2017-8-28 00:00:00" fixdate="2017-8-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Simplify REST parameter access.</summary>
      <description>Currently you have to do: {{final ParameterTypes.JobIdPathParam jobId = request.getPathParameter(ParameterTypes.JobIdPathParam.class); JobID jobID = jobId.getValue();}}This issue proposes to remove the second step and return directly the value, while performing the necessary checks internally (different for query and path parameters), without exposing it to the user.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.RestEndpointITCase.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.HandlerRequest.java</file>
    </fixedFiles>
  </bug>
  <bug id="7551" opendate="2017-8-29 00:00:00" fixdate="2017-11-29 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Add VERSION to the REST urls.</summary>
      <description>This is to guarantee that we can update the REST API without breaking existing third-party clients.</description>
      <version>1.4.0</version>
      <fixedVersion>1.7.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.RestServerEndpointITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.RestClientTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.RestServerEndpoint.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.RestClient.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.RestHandlerSpecification.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.history.HistoryServerStaticFileServerHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.history.HistoryServerStaticFileServerHandler.java</file>
      <file type="M">flink-docs.src.main.java.org.apache.flink.docs.rest.RestAPIDocGenerator.java</file>
      <file type="M">docs..includes.generated.rest.dispatcher.html</file>
      <file type="M">docs.monitoring.rest.api.md</file>
    </fixedFiles>
  </bug>
  <bug id="7571" opendate="2017-9-1 00:00:00" fixdate="2017-9-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Execution of TableSources with Time Indicators fails</summary>
      <description>The translation of queries that include a TableSource with time indicators fails during the code generation because field names and field indicies are not adjusted for the time indicators.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.stream.TimeAttributesITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.schema.TableSourceTable.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.schema.StreamTableSourceTable.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.datastream.StreamTableSourceScan.scala</file>
    </fixedFiles>
  </bug>
  <bug id="7579" opendate="2017-9-5 00:00:00" fixdate="2017-10-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Documentation of yarn.application-attempts is not accurate</summary>
      <description>In current documentation yarn.application-attempts: 10 is documented as resulting in at most 10 application restarts. That is a bit misleading: YARN can perform up to 9 restarts for "failed" attempts, resulting in 10 attempts. It can perform additional restarts for YARN attempts that failed because of YARN operations: Node failures, preemption, NodeManager resyncs, see http://johnjianfang.blogspot.de/2015/04/the-number-of-maximum-attempts-of-yarn.html</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.ops.jobmanager.high.availability.md</file>
    </fixedFiles>
  </bug>
  <bug id="7581" opendate="2017-9-5 00:00:00" fixdate="2017-9-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Name netty threads of rest components</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.RestServerEndpoint.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.RestClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="7583" opendate="2017-9-5 00:00:00" fixdate="2017-9-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create singleton isntance for the content type header</summary>
      <description>The content type header for all rest requests/responses is always the same, but we currently allocate a separate string for each request/response. We should instead use a static constant.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.RestClient.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.AbstractRestHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="7599" opendate="2017-9-7 00:00:00" fixdate="2017-12-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support aggregation functions in the define and measures clause of MatchRecognize</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.8.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.AggregateUtil.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.match.MatchRecognizeValidationTest.scala</file>
      <file type="M">docs.dev.table.streaming.match.recognize.md</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.stream.sql.MatchRecognizeITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.match.MatchOperatorValidationTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.rules.datastream.DataStreamMatchRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.MatchCodeGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.CodeGenerator.scala</file>
    </fixedFiles>
  </bug>
  <bug id="7623" opendate="2017-9-14 00:00:00" fixdate="2017-10-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Detecting whether an operator is restored doesn&amp;#39;t work with chained state</summary>
      <description>Originally reported on the ML: https://lists.apache.org/thread.html/22a2cf83de3107aa81a03a921325a191c29df8aa8676798fcd497199@%3Cuser.flink.apache.org%3EIf we have a chain of operators where multiple of them have operator state, detection of the context.isRestored() flag (of CheckpointedFunction) does not work correctly. It's best exemplified using this minimal example where both the source and the flatMap have state:final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();env .addSource(new MaSource()).uid("source-1") .flatMap(new MaFlatMap()).uid("flatMap-1");env.execute("testing");If I do a savepoint with these UIDs, then change "source-1" to "source-2" and restore from the savepoint context.isRestored() still reports true for the source.</description>
      <version>1.3.2,1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.StateAssignmentOperation.java</file>
    </fixedFiles>
  </bug>
  <bug id="7644" opendate="2017-9-20 00:00:00" fixdate="2017-9-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Line the extra semicolon in the source code</summary>
      <description>eg. final TestDuplicateSerializer keySerializer = new TestDuplicateSerializer();;Unnecessary semicolon in the end of line.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.heap.CopyOnWriteStateTableTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.CheckpointStatsTracker.java</file>
    </fixedFiles>
  </bug>
  <bug id="7654" opendate="2017-9-20 00:00:00" fixdate="2017-9-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update RabbitMQ Java client to 4.x</summary>
      <description>RabbitMQ Java ClientStarting with 4.0, this client releases are independent from RabbitMQ server releases.These versions can still be used with RabbitMQ server 3.x.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-rabbitmq.src.test.java.org.apache.flink.streaming.connectors.rabbitmq.RMQSourceTest.java</file>
      <file type="M">flink-connectors.flink-connector-rabbitmq.src.test.java.org.apache.flink.streaming.connectors.rabbitmq.common.RMQSinkTest.java</file>
      <file type="M">flink-connectors.flink-connector-rabbitmq.src.main.java.org.apache.flink.streaming.connectors.rabbitmq.RMQSource.java</file>
      <file type="M">flink-connectors.flink-connector-rabbitmq.src.main.java.org.apache.flink.streaming.connectors.rabbitmq.RMQSink.java</file>
      <file type="M">flink-connectors.flink-connector-rabbitmq.README.md</file>
      <file type="M">flink-connectors.flink-connector-rabbitmq.pom.xml</file>
      <file type="M">docs.dev.connectors.rabbitmq.md</file>
    </fixedFiles>
  </bug>
  <bug id="7658" opendate="2017-9-20 00:00:00" fixdate="2017-2-20 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Support COLLECT Aggregate function in Flink TABLE API</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.stream.table.AggregateITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.batch.table.AggregateITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.batch.table.stringexpr.AggregateStringExpressionTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.validate.FunctionCatalog.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.aggregations.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.scala.expressionDsl.scala</file>
      <file type="M">docs.dev.table.tableApi.md</file>
    </fixedFiles>
  </bug>
  <bug id="7661" opendate="2017-9-21 00:00:00" fixdate="2017-10-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add credit field in PartitionRequest message</summary>
      <description>Currently the PartitionRequest message contains ResultPartitionID | queueIndex | InputChannelID fields.We will add a new credit field indicating the initial credit of InputChannel, and this info can be got from InputChannel directly after assigning exclusive buffers to it.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.netty.ServerTransportErrorHandlingTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.netty.NettyMessageSerializationTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.netty.CancelPartitionRequestTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.partition.consumer.RemoteInputChannel.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.netty.PartitionRequestClient.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.netty.NettyMessage.java</file>
    </fixedFiles>
  </bug>
  <bug id="7662" opendate="2017-9-21 00:00:00" fixdate="2017-10-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove unnecessary packaged licenses</summary>
      <description>With the new shading approach, we no longer shade ASM into Flink artifacts, so we do not need to package the ASM license into those artifacts any more.Instead, a shaded ASM artifact already containing a packaged license is used in the distribution build.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-scala.packaged.licenses.LICENSE.asm.txt</file>
      <file type="M">flink-runtime.packaged.licenses.LICENSE.asm.txt</file>
      <file type="M">flink-java.packaged.licenses.LICENSE.asm.txt</file>
      <file type="M">flink-core.packaged.licenses.LICENSE.asm.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7675" opendate="2017-9-23 00:00:00" fixdate="2017-3-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LatestCompletedCheckpointExternalPathGauge should check if external path is exist</summary>
      <description>For internal checkpoint, CompletedCheckpointStats.getExternalPath() could be null.This will leads to LatestCompletedCheckpointExternalPathGauge to return null value to MetricDumpSerialization, then it will throw NullPointerException in serializeGauge function.</description>
      <version>1.3.3,1.4.0</version>
      <fixedVersion>1.3.4,1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.checkpoint.CheckpointStatsTrackerTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.CheckpointStatsTracker.java</file>
      <file type="M">docs.monitoring.metrics.md</file>
    </fixedFiles>
  </bug>
  <bug id="7698" opendate="2017-9-27 00:00:00" fixdate="2017-11-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Join with null literals leads to NPE</summary>
      <description>The following query fails: @Test def testProcessTimeInnerJoin(): Unit = { val env = StreamExecutionEnvironment.getExecutionEnvironment val tEnv = TableEnvironment.getTableEnvironment(env) env.setStateBackend(getStateBackend) StreamITCase.clear env.setParallelism(1) val sqlQuery = "SELECT t2.a, t2.c, t1.c from T1 as t1 join T2 as t2 on t1.a = t2.a and t1.nullField = t2.nullField and " + "t1.proctime between t2.proctime - interval '5' second and t2.proctime + interval '5' second" val data1 = new mutable.MutableList[(Int, Long, String)] data1.+=((1, 1L, "Hi1")) data1.+=((1, 2L, "Hi2")) data1.+=((1, 5L, "Hi3")) data1.+=((2, 7L, "Hi5")) data1.+=((1, 9L, "Hi6")) data1.+=((1, 8L, "Hi8")) data1.+=((1, 8L, "Hi8")) val data2 = new mutable.MutableList[(Int, Long, String)] data2.+=((1, 1L, "HiHi")) data2.+=((2, 2L, "HeHe")) val t1 = env.fromCollection(data1).toTable(tEnv, 'a, 'b, 'c, 'proctime.proctime) .select('a, 'b, 'c, 'proctime, Null(Types.LONG) as 'nullField) val t2 = env.fromCollection(data2).toTable(tEnv, 'a, 'b, 'c, 'proctime.proctime) .select('a, 'b, 'c, 'proctime, 12L as 'nullField) tEnv.registerTable("T1", t1) tEnv.registerTable("T2", t2) val result = tEnv.sqlQuery(sqlQuery).toAppendStream[Row] result.addSink(new StreamITCase.StringSink[Row]) env.execute() }It leads to:java.lang.NullPointerException at org.apache.calcite.rex.RexUtil.gatherConstraint(RexUtil.java:437) at org.apache.calcite.rex.RexUtil.gatherConstraints(RexUtil.java:399) at org.apache.calcite.rex.RexUtil.predicateConstants(RexUtil.java:336) at org.apache.calcite.plan.RelOptPredicateList.of(RelOptPredicateList.java:144) at org.apache.calcite.rel.metadata.RelMdPredicates$JoinConditionBasedPredicateInference.inferPredicates(RelMdPredicates.java:654) at org.apache.calcite.rel.metadata.RelMdPredicates.getPredicates(RelMdPredicates.java:326) at GeneratedMetadataHandler_Predicates.getPredicates_$(Unknown Source) at GeneratedMetadataHandler_Predicates.getPredicates(Unknown Source) at GeneratedMetadataHandler_Predicates.getPredicates_$(Unknown Source) at GeneratedMetadataHandler_Predicates.getPredicates(Unknown Source) at org.apache.calcite.rel.metadata.RelMetadataQuery.getPulledUpPredicates(RelMetadataQuery.java:803) at org.apache.calcite.rel.rules.ReduceExpressionsRule$ProjectReduceExpressionsRule.onMatch(ReduceExpressionsRule.java:264) at org.apache.calcite.plan.AbstractRelOptPlanner.fireRule(AbstractRelOptPlanner.java:317) at org.apache.calcite.plan.hep.HepPlanner.applyRule(HepPlanner.java:506) at org.apache.calcite.plan.hep.HepPlanner.applyRules(HepPlanner.java:385) at org.apache.calcite.plan.hep.HepPlanner.executeInstruction(HepPlanner.java:251) at org.apache.calcite.plan.hep.HepInstruction$RuleInstance.execute(HepInstruction.java:125) at org.apache.calcite.plan.hep.HepPlanner.executeProgram(HepPlanner.java:210) at org.apache.calcite.plan.hep.HepPlanner.findBestExp(HepPlanner.java:197) at org.apache.flink.table.api.TableEnvironment.runHepPlanner(TableEnvironment.scala:257) at org.apache.flink.table.api.StreamTableEnvironment.optimize(StreamTableEnvironment.scala:663) at org.apache.flink.table.api.StreamTableEnvironment.translate(StreamTableEnvironment.scala:728) at org.apache.flink.table.api.scala.StreamTableEnvironment.toAppendStream(StreamTableEnvironment.scala:219) at org.apache.flink.table.api.scala.StreamTableEnvironment.toAppendStream(StreamTableEnvironment.scala:195) at org.apache.flink.table.api.scala.TableConversions.toAppendStream(TableConversions.scala:121) at org.apache.flink.table.runtime.stream.sql.JoinITCase.testProcessTimeInnerJoin(JoinITCase.scala:67) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48) at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55) at org.junit.rules.RunRules.evaluate(RunRules.java:20) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48) at org.junit.rules.RunRules.evaluate(RunRules.java:20) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51) at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242) at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)Seems to be a Calcite bug, but we have to investigate this first. Replacing Null(Types.LONG) with a value works.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0,1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.stream.sql.JoinTest.scala</file>
    </fixedFiles>
  </bug>
  <bug id="7701" opendate="2017-9-27 00:00:00" fixdate="2017-11-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>IllegalArgumentException in Netty bootstrap with small memory state segment size</summary>
      <description>FLINK-7258 broke setting high and low watermarks for small segment sizes. We should tackle both use cases.</description>
      <version>1.3.2,1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.netty.NettyServerLowAndHighWatermarkTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.netty.NettyServer.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-client-java.src.main.java.org.apache.flink.queryablestate.network.AbstractServerBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="7702" opendate="2017-9-27 00:00:00" fixdate="2017-11-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Javadocs are not being built</summary>
      <description>The "Javadocs" link in the left side menu of this page doesn't work:https://ci.apache.org/projects/flink/flink-docs-master/Note that it works in 1.3:https://ci.apache.org/projects/flink/flink-docs-release-1.3/</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn-tests.pom.xml</file>
      <file type="M">flink-test-utils-parent.flink-test-utils.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-filesystem.pom.xml</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7719" opendate="2017-9-27 00:00:00" fixdate="2017-1-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Send checkpoint id to task as part of deployment descriptor when resuming</summary>
      <description>As a preparation for local recovery, we need to make the tasks aware of the checkpoint id from which they are supposed to recover. Currently, tasks only get the state handles from which they will recover and do not have any information from which checkpoint those states handles have been produced. For local recovery, the tasks must identify the matching local state on their own and need the checkpoint id for this.The plan is to simply make the checkpoint id part of the task deployment descriptor.</description>
      <version>1.4.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.InterruptSensitiveRestoreTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTask.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskmanager.TaskAsyncCallTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.executiongraph.ExecutionVertexLocalityTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.deployment.TaskDeploymentDescriptorTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.checkpoint.CheckpointStateRestoreTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.checkpoint.CheckpointCoordinatorTest.java</file>
      <file type="M">flink-runtime.src.main.scala.org.apache.flink.runtime.taskmanager.TaskManager.scala</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskmanager.Task.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskExecutor.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.ExecutionVertex.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.Execution.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.deployment.TaskDeploymentDescriptor.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.StateAssignmentOperation.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.CheckpointCoordinator.java</file>
    </fixedFiles>
  </bug>
  <bug id="7725" opendate="2017-9-28 00:00:00" fixdate="2017-9-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add test base for marshalling requests</summary>
      <description>We should have a test base for marshalling rest request bodies as we have for responses.Additionally, it should be possible to throw an exception when creating the instance.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.legacy.messages.RestResponseMarshallingTestBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="7727" opendate="2017-9-28 00:00:00" fixdate="2017-2-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Extend logging in file server handlers</summary>
      <description>The file server handlers check several failure conditions but don't log anything (like the path), making debugging difficult.</description>
      <version>1.4.0</version>
      <fixedVersion>1.11.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.files.StaticFileServerHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.history.HistoryServerStaticFileServerHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="7736" opendate="2017-9-28 00:00:00" fixdate="2017-1-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix some of the alerts raised by lgtm.com</summary>
      <description>lgtm.com has identified a number of issues giving scope for improvement in the code: https://lgtm.com/projects/g/apache/flink/alerts/?mode=listThis issue is to address some of the simpler ones. Some of these are quite clear bugs such as off-by-one errors. Others are areas where the code might be made clearer, such as use of a variable name which shadows another variable.</description>
      <version>None</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.YarnResourceManager.java</file>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.YarnApplicationMasterRunner.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.util.typeutils.FieldAccessor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.SocketTextStreamFunction.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.webmonitor.history.ArchivedJsonTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.webmonitor.history.ArchivedJson.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.util.JarFileCreator.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskExecutor.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.hash.InPlaceMutableHashTable.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.memory.MemoryManager.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.handlers.JarListHandler.java</file>
      <file type="M">flink-optimizer.src.main.java.org.apache.flink.optimizer.dag.GroupReduceNode.java</file>
    </fixedFiles>
  </bug>
  <bug id="7745" opendate="2017-10-2 00:00:00" fixdate="2017-11-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>add tests for ensuring NetworkBufferPool overprovisioning behaviour</summary>
      <description>Currently, there are no unit tests verifying NetworkBufferPool's behaviour in the case that the available number of buffers is too small for it to create LocalBufferPool instances. We should add some.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.buffer.BufferPoolFactoryTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="7755" opendate="2017-10-2 00:00:00" fixdate="2017-10-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Null values are not correctly handled by batch inner and outer joins</summary>
      <description>Join predicates of batch joins are not correctly evaluated according to three-value logic.This affects inner as well as outer joins.The problem is that some equality predicates are only evaluated by the internal join algorithms of Flink which are based on TypeComparator. The field TypeComparator for Row are implemented such that null == null results in TRUE to ensure correct ordering and grouping. However, three-value logic requires that null == null results to UNKNOWN (or null). The code generator implements this logic correctly, but for equality predicates, no code is generated.For outer joins, the problem is a bit tricker because these do not support code-generated predicates yet (see FLINK-5520). FLINK-5498 proposes a solution for this issue.We also need to extend several of the existing tests and add null values to ensure that the join logic is correctly implemented.</description>
      <version>1.3.2,1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.batch.table.JoinITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.batch.table.validation.JoinValidationTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.batch.sql.validation.JoinValidationTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.rules.dataSet.DataSetJoinRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.logical.FlinkLogicalJoin.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.dataset.DataSetJoin.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.logical.operators.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.FunctionCodeGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.calls.ScalarOperators.scala</file>
    </fixedFiles>
  </bug>
  <bug id="7761" opendate="2017-10-4 00:00:00" fixdate="2017-10-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Twitter example is not self-contained</summary>
      <description>The Twitter example jar is not self-contained as it excludes the shaded guava dependency from the twitter connector.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-examples.flink-examples-streaming.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7765" opendate="2017-10-5 00:00:00" fixdate="2017-1-5 01:00:00" resolution="Unresolved">
    <buginformation>
      <summary>Enable dependency convergence</summary>
      <description>For motivation check https://issues.apache.org/jira/browse/FLINK-7739SubTasks of this task depends on one another - to enable convergence in `flink-runtime` it has to be enabled for `flink-shaded-hadoop` first.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-yarn.pom.xml</file>
      <file type="M">flink-yarn-tests.pom.xml</file>
      <file type="M">flink-tests.pom.xml</file>
      <file type="M">flink-streaming-scala.pom.xml</file>
      <file type="M">flink-shaded-hadoop.pom.xml</file>
      <file type="M">flink-scala.pom.xml</file>
      <file type="M">flink-runtime.pom.xml</file>
      <file type="M">flink-libraries.pom.xml</file>
      <file type="M">flink-java.pom.xml</file>
      <file type="M">flink-fs-tests.pom.xml</file>
      <file type="M">flink-filesystems.pom.xml</file>
      <file type="M">flink-examples.pom.xml</file>
      <file type="M">flink-connectors.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7766" opendate="2017-10-5 00:00:00" fixdate="2017-11-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove obsolete reflection for hflush on HDFS</summary>
      <description>This code originally existed for compatibility with Hadoop 1.Since Hadoop 1 support is dropped, this is no longer necessary.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-filesystem.src.main.java.org.apache.flink.streaming.connectors.fs.StreamWriterBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="7767" opendate="2017-10-5 00:00:00" fixdate="2017-11-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Avoid loading Hadoop conf dynamically at runtime</summary>
      <description>The bucketing sink dynamically loads the Hadoop configuration in various places.The result of that configuration is not always predictable, as it tries to automagically discover the Hadoop config files.A better approach is to rely on the Flink configuration to find the Hadoop configuration, or to directly use the Hadoop configuration used by the Hadoop file systems.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.fs.hdfs.HadoopFileSystem.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.test.java.org.apache.flink.streaming.connectors.fs.bucketing.BucketingSinkTest.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.main.java.org.apache.flink.streaming.connectors.fs.SequenceFileWriter.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.main.java.org.apache.flink.streaming.connectors.fs.RollingSink.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.main.java.org.apache.flink.streaming.connectors.fs.bucketing.BucketingSink.java</file>
    </fixedFiles>
  </bug>
  <bug id="7768" opendate="2017-10-5 00:00:00" fixdate="2017-11-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Load File Systems via Java Service abstraction</summary>
      <description>We should change the discovery mechanism of file from static class name configurations to a service mechanism (META-INF/services). With this change, users can add new filesystem implementations and make them available by simply adding them to the class path. As part of that, factoring HDFS and MapR FS implementations into separate modules helps with a better and more fine grained dependency management, needing less explicit reflection logic.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.travis.mvn.watchdog.sh</file>
      <file type="M">pom.xml</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.fs.hdfs.HadoopDataInputStreamTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.util.HadoopUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.fs.maprfs.MapRFileSystem.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.fs.hdfs.HadoopFsFactory.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.fs.hdfs.HadoopFileSystem.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.fs.hdfs.HadoopFileStatus.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.fs.hdfs.HadoopDataOutputStream.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.fs.hdfs.HadoopDataInputStream.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.fs.hdfs.HadoopBlockLocation.java</file>
      <file type="M">flink-runtime.pom.xml</file>
      <file type="M">flink-dist.pom.xml</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.testutils.TestFileSystem.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.io.DelimitedInputFormatSamplingTest.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.FileSystemFactory.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.FileSystem.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.factories.UnsupportedSchemeFactory.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.factories.MapRFsFactory.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.factories.LocalFileSystemFactory.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.factories.HadoopFileSystemFactoryLoader.java</file>
    </fixedFiles>
  </bug>
  <bug id="7769" opendate="2017-10-6 00:00:00" fixdate="2017-10-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move Queryable State outside the runtime.</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.query.NonHAQueryableStateITCaseRocksDBBackend.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.query.NonHAQueryableStateITCaseFsBackend.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.query.NonHAAbstractQueryableStateITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.query.KVStateRequestSerializerRocksDBTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.query.HAQueryableStateITCaseRocksDBBackend.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.query.HAQueryableStateITCaseFsBackend.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.query.HAAbstractQueryableStateITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.query.AbstractQueryableStateITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.StateBackendTestBase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.QueryableStateClientTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.netty.message.KvStateRequestSerializerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.netty.KvStateServerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.netty.KvStateServerHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.netty.KvStateClientTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.netty.KvStateClientHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.AkkaKvStateLocationLookupServiceTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskManagerServicesConfiguration.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskManagerServices.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.QueryableStateConfiguration.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.heap.HeapMapState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.heap.AbstractHeapState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.UnknownKvStateKeyGroupLocation.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.UnknownJobManager.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.QueryableStateClient.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.package-info.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.UnknownKvStateID.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.UnknownKeyOrNamespace.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.package-info.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.message.KvStateRequestType.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.message.KvStateRequestSerializer.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.message.KvStateRequestResult.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.message.KvStateRequestFailure.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.message.KvStateRequest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.KvStateServerHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.KvStateServer.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.KvStateRequestStats.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.KvStateClientHandlerCallback.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.KvStateClientHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.KvStateClient.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.ChunkedByteBuf.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.KvStateServerAddress.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.KvStateRegistry.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.KvStateLocationLookupService.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.KvStateLocation.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.AkkaKvStateLocationLookupService.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.NetworkEnvironment.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBMapState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.AbstractRocksDBState.java</file>
    </fixedFiles>
  </bug>
  <bug id="7770" opendate="2017-10-6 00:00:00" fixdate="2017-10-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hide Queryable State behind a proxy.</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskmanager.TaskManagerComponentsStartupShutdownTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.NetworkEnvironmentTest.java</file>
      <file type="M">flink-runtime.src.main.scala.org.apache.flink.runtime.taskmanager.TaskManager.scala</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskManagerServicesConfiguration.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskManagerServices.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.QueryableStateConfiguration.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.QueryableStateUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.KvStateRequestStats.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.KvStateServer.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.KvStateLocation.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.NetworkEnvironment.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.concurrent.FutureUtils.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.network.QueryableStateClientTest.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.network.KvStateServerTest.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.network.KvStateServerHandlerTest.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.network.KvStateRequestSerializerTest.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.network.KvStateClientTest.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.network.KvStateClientHandlerTest.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.network.AkkaKvStateLocationLookupServiceTest.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.itcases.NonHAAbstractQueryableStateITCase.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.itcases.HAAbstractQueryableStateITCase.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.itcases.AbstractQueryableStateITCase.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.UnknownKvStateKeyGroupLocation.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.UnknownKvStateID.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.UnknownKeyOrNamespace.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.UnknownJobManager.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.server.KvStateServerImpl.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.server.KvStateServerHandler.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.server.ChunkedByteBuf.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.network.messages.MessageType.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.network.messages.MessageSerializer.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.messages.KvStateRequestResult.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.messages.KvStateRequestFailure.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.messages.KvStateRequest.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.client.QueryableStateClient.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.client.KvStateLocationLookupService.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.client.KvStateClientHandlerCallback.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.client.KvStateClientHandler.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.client.KvStateClient.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.client.AkkaKvStateLocationLookupService.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.AbstractID.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.QueryableStateOptions.java</file>
    </fixedFiles>
  </bug>
  <bug id="7778" opendate="2017-10-9 00:00:00" fixdate="2017-11-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Relocate ZooKeeper</summary>
      <description>If possible, then we should also try to relocate ZooKeeper in order to avoid dependency clashes between Flink's ZooKeeper and Hadoop's ZooKeeper dependency.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.travis.mvn.watchdog.sh</file>
      <file type="M">flink-shaded-hadoop.pom.xml</file>
      <file type="M">flink-shaded-curator-recipes.pom.xml</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.zookeeper.ZooKeeperStateHandleStore.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.zookeeper.ZookeeperAccess.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.runtime.clusterframework.store.ZooKeeperMesosWorkerStore.java</file>
      <file type="M">pom.xml</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.recovery.JobManagerHAJobGraphRecoveryITCase.java</file>
      <file type="M">flink-tests.pom.xml</file>
      <file type="M">flink-shaded-curator.pom.xml</file>
      <file type="M">flink-shaded-curator.flink-shaded-curator-test.pom.xml</file>
      <file type="M">flink-shaded-curator.flink-shaded-curator-recipes.pom.xml</file>
      <file type="M">flink-runtime.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7780" opendate="2017-10-9 00:00:00" fixdate="2017-12-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Integrate savepoint command into REST client</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-clients.src.test.java.org.apache.flink.client.program.ClusterClientTest.java</file>
      <file type="M">flink-clients.src.test.java.org.apache.flink.client.CliFrontendSavepointTest.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.program.ClusterClient.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.CliFrontend.java</file>
      <file type="M">flink-clients.src.test.java.org.apache.flink.client.program.rest.RestClusterClientTest.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.program.rest.RestClusterClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="7788" opendate="2017-10-9 00:00:00" fixdate="2017-10-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow port range for queryable state client proxy.</summary>
      <description>Currently the newly introduced queryable state client proxy can only take one port as a parameter to bind to. In case of multiple proxies running on one machine, this can result in port clashes and inability to start the corresponding proxies. This issue proposes to allow the specification of a port range, so that if some ports in the range are occupied, the proxy can still pick from the remaining free ones.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskManagerServicesConfiguration.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskManagerServices.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.QueryableStateConfiguration.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.QueryableStateUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.KvStateServer.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.NetworkEnvironment.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.network.KvStateServerTest.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.network.KvStateServerHandlerTest.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.network.ClientTest.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.itcases.NonHAAbstractQueryableStateITCase.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.itcases.HAAbstractQueryableStateITCase.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.itcases.AbstractQueryableStateITCase.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.server.KvStateServerImpl.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.network.AbstractServerBase.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.client.proxy.KvStateClientProxyImpl.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.QueryableStateOptions.java</file>
    </fixedFiles>
  </bug>
  <bug id="7789" opendate="2017-10-10 00:00:00" fixdate="2017-6-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add handler for Async IO operator timeouts</summary>
      <description>Currently Async IO operator does not provide a mechanism to handle timeouts. When a request times out it an exception is thrown and job is restarted. It would be good to pass a AsyncIOTimeoutHandler which can be implemented by the user and passed in the constructor.Here is the discussion from apache flink users mailing list http://apache-flink-user-mailing-list-archive.2336050.n4.nabble.com/async-io-operator-timeouts-tt16068.html</description>
      <version>None</version>
      <fixedVersion>1.6.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.async.AsyncFunction.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.AsyncDataStream.scala</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.async.AsyncWaitOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.async.AsyncWaitOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.async.AsyncFunction.java</file>
      <file type="M">docs.dev.stream.operators.asyncio.md</file>
    </fixedFiles>
  </bug>
  <bug id="7790" opendate="2017-10-10 00:00:00" fixdate="2017-10-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unresolved query parameters are not omitted from request</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.messages.MessageParametersTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.MessageParameters.java</file>
    </fixedFiles>
  </bug>
  <bug id="7791" opendate="2017-10-10 00:00:00" fixdate="2017-10-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Integrate LIST command into REST client</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-clients.src.test.java.org.apache.flink.client.program.ClusterClientTest.java</file>
      <file type="M">flink-clients.src.test.java.org.apache.flink.client.CliFrontendListCancelTest.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.program.ClusterClient.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.CliFrontend.java</file>
      <file type="M">flink-clients.src.test.java.org.apache.flink.client.program.rest.RestClusterClientTest.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.program.rest.RestClusterClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="7797" opendate="2017-10-10 00:00:00" fixdate="2017-2-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add support for windowed outer joins for streaming tables</summary>
      <description>Currently, only windowed inner joins for streaming tables are supported.This issue is about adding support for windowed LEFT, RIGHT, and FULL OUTER joins.</description>
      <version>1.4.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.stream.sql.JoinITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.harness.JoinHarnessTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.stream.table.JoinTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.stream.sql.JoinTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.join.TimeBoundedStreamInnerJoin.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.join.RowTimeBoundedStreamInnerJoin.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.join.ProcTimeBoundedStreamInnerJoin.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.datastream.DataStreamWindowJoin.scala</file>
      <file type="M">docs.dev.table.tableApi.md</file>
      <file type="M">docs.dev.table.sql.md</file>
    </fixedFiles>
  </bug>
  <bug id="7798" opendate="2017-10-10 00:00:00" fixdate="2017-10-10 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Add support for windowed joins to Table API</summary>
      <description>Currently, windowed joins on streaming tables are only supported through SQL.The Table API should support these joins as well. For that, we have to adjust the Table API validation and translate the API into the respective logical plan. Since most of the code should already be there for the batch Table API joins, this should be fairly straightforward.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.stream.sql.JoinITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.logical.operators.scala</file>
      <file type="M">docs.dev.table.tableApi.md</file>
      <file type="M">docs.dev.table.sql.md</file>
    </fixedFiles>
  </bug>
  <bug id="7802" opendate="2017-10-11 00:00:00" fixdate="2017-3-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Exception occur when empty field collection was pushed into CSVTableSource</summary>
      <description>Consider such SQL: select count(1) from csv_table. When above SQL was executed, an exception will occur:java.lang.IllegalArgumentException: At least one field must be specifiedat org.apache.flink.api.java.io.RowCsvInputFormat.&lt;init&gt;(RowCsvInputFormat.java:50)So if no fields will be used, we should also keep some columns for CSVTableSource to get row count.</description>
      <version>None</version>
      <fixedVersion>1.3.4,1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.TableSourceTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.sources.CsvTableSource.scala</file>
    </fixedFiles>
  </bug>
  <bug id="7810" opendate="2017-10-11 00:00:00" fixdate="2017-11-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Switch from custom Flakka to Akka 2.4.x</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn.pom.xml</file>
      <file type="M">flink-yarn-tests.src.test.java.org.apache.flink.yarn.YarnTestBase.java</file>
      <file type="M">flink-yarn-tests.pom.xml</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.misc.AutoParallelismITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.SavepointITCase.java</file>
      <file type="M">flink-tests.pom.xml</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskmanager.TaskManagerComponentsStartupShutdownTest.java</file>
      <file type="M">flink-runtime.pom.xml</file>
      <file type="M">flink-runtime-web.pom.xml</file>
      <file type="M">flink-quickstart.flink-quickstart-scala.src.main.resources.archetype-resources.pom.xml</file>
      <file type="M">flink-quickstart.flink-quickstart-java.src.main.resources.archetype-resources.pom.xml</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.pom.xml</file>
      <file type="M">flink-mesos.pom.xml</file>
      <file type="M">flink-clients.pom.xml</file>
      <file type="M">test-infra.end-to-end-test.common.sh</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7814" opendate="2017-10-11 00:00:00" fixdate="2017-5-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add BETWEEN and NOT BETWEEN expression to Table API</summary>
      <description>The Table API does not have a BETWEEN expression. BETWEEN is quite handy when defining join predicates for window joins.</description>
      <version>1.4.0</version>
      <fixedVersion>1.6.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.validation.ScalarOperatorsValidationTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.SqlExpressionTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.ScalarOperatorsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.validate.FunctionCatalog.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.comparison.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.scala.expressionDsl.scala</file>
      <file type="M">docs.dev.table.tableApi.md</file>
    </fixedFiles>
  </bug>
  <bug id="7823" opendate="2017-10-12 00:00:00" fixdate="2017-11-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Adjust queryable state configuration parameters</summary>
      <description>The revamping of the queryable state for 1.4, implies changes in the required user-specified parameters.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.scala.org.apache.flink.runtime.minicluster.LocalFlinkMiniCluster.scala</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskManagerServicesConfiguration.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskManagerServices.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.QueryableStateConfiguration.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.NetworkEnvironment.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-runtime.src.test.java.org.apache.flink.queryablestate.network.AbstractServerTest.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-runtime.src.test.java.org.apache.flink.queryablestate.itcases.NonHAAbstractQueryableStateTestBase.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-runtime.src.test.java.org.apache.flink.queryablestate.itcases.HAAbstractQueryableStateTestBase.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-client-java.src.main.java.org.apache.flink.queryablestate.network.AbstractServerBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.QueryableStateOptions.java</file>
    </fixedFiles>
  </bug>
  <bug id="7838" opendate="2017-10-13 00:00:00" fixdate="2017-11-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Kafka011ProducerExactlyOnceITCase do not finish</summary>
      <description>See attached log</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-kafka-0.11.src.main.java.org.apache.flink.streaming.connectors.kafka.internal.FlinkKafkaProducer.java</file>
    </fixedFiles>
  </bug>
  <bug id="7840" opendate="2017-10-14 00:00:00" fixdate="2017-10-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Shade Akka&amp;#39;s Netty Dependency</summary>
      <description>In order to avoid clashes between different Netty versions we should shade Akka's Netty away.These dependency version clashed manifest themselves in very subtle ways, like occasional deadlocks.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.travis.mvn.watchdog.sh</file>
      <file type="M">flink-yarn.pom.xml</file>
      <file type="M">flink-test-utils-parent.flink-test-utils.src.main.java.org.apache.flink.networking.NetworkFailureHandler.java</file>
      <file type="M">flink-test-utils-parent.flink-test-utils.pom.xml</file>
      <file type="M">flink-runtime.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7841" opendate="2017-10-14 00:00:00" fixdate="2017-11-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add docs for Flink&amp;#39;s S3 support</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.ops.deployment.aws.md</file>
    </fixedFiles>
  </bug>
  <bug id="7842" opendate="2017-10-14 00:00:00" fixdate="2017-11-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Shade jackson (org.codehouse.jackson) in flink-shaded-hadoop2</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-shaded-hadoop.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7844" opendate="2017-10-15 00:00:00" fixdate="2017-10-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fine Grained Recovery triggers checkpoint timeout failure</summary>
      <description>Context: We are using "individual" failover (fine-grained) recovery strategy for our embarrassingly parallel router use case. The topic has over 2000 partitions, and parallelism is set to ~180 that dispatched to over 20 task managers with around 180 slots.Observations:We've noticed after one task manager termination, even though the individual recovery happens correctly, that the workload was re-dispatched to a new available task manager instance. However, the checkpoint would take 10 mins to eventually timeout, causing all other task managers not able to commit checkpoints. In a worst-case scenario, if job got restarted for other reasons (i.e. job manager termination), that would cause more messages to be re-processed/duplicates compared to the job without fine-grained recovery enabled.I am suspecting that uber checkpoint was waiting for a previous checkpoint that initiated by the old task manager and thus taking a long time to time out.Two questions:1. Is there a configuration that controls this checkpoint timeout?2. Is there any reason that when Job Manager realizes that Task Manager is gone and workload is redispatched, it still need to wait for the checkpoint initiated by the old task manager?Checkpoint screenshot in attachments.</description>
      <version>1.3.2,1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.executiongraph.IndividualRestartsConcurrencyTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.ExecutionGraph.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.Execution.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.PendingCheckpoint.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.CheckpointCoordinator.java</file>
    </fixedFiles>
  </bug>
  <bug id="7847" opendate="2017-10-16 00:00:00" fixdate="2017-11-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix typo in flink-avro shading pattern</summary>
      <description>&lt;relocation&gt; &lt;pattern&gt;org.codehaus.jackson&lt;/pattern&gt; &lt;shadedPattern&gt;org.apache.flink.avro.shaded.org.codehouse.jackson&lt;/shadedPattern&gt;&lt;/relocation&gt;The shaded pattern should be "org.apache.flink.avro.shaded.org.codehaus.jackson".</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-formats.flink-avro.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7849" opendate="2017-10-16 00:00:00" fixdate="2017-10-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove guava shading from hcatalog connector</summary>
      <description>Same issue as FLINK-7846.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-hcatalog.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="785" opendate="2014-6-9 00:00:00" fixdate="2014-5-9 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Add Chained operators for AllReduce and AllGroupReduce</summary>
      <description>Because the operators `AllReduce` and `AllGroupReduce` are used both for the pre-reduce (combiner side) and the final reduce, they would greatly benefit from a chained version.---------------- Imported from GitHub ----------------Url: https://github.com/stratosphere/stratosphere/issues/785Created by: StephanEwenLabels: runtime, Milestone: Release 0.6 (unplanned)Created at: Sun May 11 17:41:12 CEST 2014State: open</description>
      <version>None</version>
      <fixedVersion>0.9</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.DriverStrategy.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.operators.ObjectReuseITCase.java</file>
    </fixedFiles>
  </bug>
  <bug id="7850" opendate="2017-10-16 00:00:00" fixdate="2017-5-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Given each maven profile an activation property</summary>
      <description>We should give every maven profile an activation property so that they can be activated with -Dabcde. This makes them a lot easier to work with in scripts that want to control profile activation, since you can just append -D switches. This doesn't work with the -P switch as it can only be specified once.&lt;activation&gt; &lt;property&gt; &lt;name&gt;profile_name_or_something&lt;/name&gt; &lt;/property&gt;&lt;/activation&gt;</description>
      <version>1.4.0</version>
      <fixedVersion>1.6.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.force-shading.pom.xml</file>
      <file type="M">pom.xml</file>
      <file type="M">flink-shaded-hadoop.flink-shaded-hadoop2.pom.xml</file>
      <file type="M">flink-libraries.flink-python.pom.xml</file>
      <file type="M">flink-libraries.flink-ml.pom.xml</file>
      <file type="M">flink-formats.flink-json.pom.xml</file>
      <file type="M">flink-connectors.pom.xml</file>
      <file type="M">flink-connectors.flink-hbase.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.11.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7861" opendate="2017-10-17 00:00:00" fixdate="2017-10-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Suppress ActorKilledExceptions</summary>
      <description>When stopping a RpcEndpoint, the AkkaRpcService sends a Kill message which causes an ActorKilledException to be thrown. This exception is logged by the StoppingSupervisorStrategy. This is not necessary because we voluntarily stopped the RpcEndpoint. In order to clean up logs, I think we should not log this kind of exception.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.scala.org.apache.flink.runtime.akka.AkkaUtils.scala</file>
    </fixedFiles>
  </bug>
  <bug id="7862" opendate="2017-10-17 00:00:00" fixdate="2017-11-17 01:00:00" resolution="Done">
    <buginformation>
      <summary>Add TaskManagerDetailsHandler</summary>
      <description>In order to server detailed TaskManager information we need a TaskManagerDetailsHandler.</description>
      <version>1.4.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.messages.taskmanager.TaskManagerInfoTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.taskmanager.TaskManagerInfo.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.resourcemanager.ResourceManagerGateway.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.resourcemanager.ResourceManager.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.MetricRegistry.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.dump.QueryScopeInfo.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.dump.MetricDump.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.entrypoint.SessionClusterEntrypoint.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.TaskManagersHandler.java</file>
      <file type="M">flink-runtime-web.web-dashboard.app.scripts.modules.taskmanager.taskmanager.svc.coffee</file>
      <file type="M">flink-runtime-web.web-dashboard.app.scripts.modules.taskmanager.taskmanager.ctrl.coffee</file>
      <file type="M">flink-runtime-web.web-dashboard.web.partials.taskmanager.taskmanager.metrics.html</file>
      <file type="M">flink-runtime-web.web-dashboard.web.js.index.js</file>
      <file type="M">flink-runtime-web.web-dashboard.web.js.hs.index.js</file>
      <file type="M">flink-runtime-web.web-dashboard.app.partials.taskmanager.taskmanager.metrics.jade</file>
    </fixedFiles>
  </bug>
  <bug id="7866" opendate="2017-10-18 00:00:00" fixdate="2017-6-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Weigh list of preferred locations for scheduling</summary>
      <description>Sihua Zhou proposed to not only use the list of preferred locations to decide where to schedule a task, but to also weigh the list according to how often a location appeared and then select the location based on the weight. That way, we would obtain better locality in some cases.Example:Preferred locations list: &amp;#91;location1, location2, location2&amp;#93;Weighted preferred locations list &amp;#91;(location2 , 2), (location1, 1)&amp;#93;</description>
      <version>1.3.2,1.4.0</version>
      <fixedVersion>1.6.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.clusterframework.types.SlotProfileTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.clusterframework.types.SlotProfile.java</file>
    </fixedFiles>
  </bug>
  <bug id="7868" opendate="2017-10-18 00:00:00" fixdate="2017-10-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Only run checkstyleonce for compilation</summary>
      <description>We currently run checkstyle twice in the Misc profile, once during compilation and again during tests which wastes build time.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.travis.mvn.watchdog.sh</file>
    </fixedFiles>
  </bug>
  <bug id="7874" opendate="2017-10-19 00:00:00" fixdate="2017-10-19 01:00:00" resolution="Done">
    <buginformation>
      <summary>Add environment logging to cluster entrypoints</summary>
      <description>Add environment logging to all ClusterEntrypoints.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.entrypoint.YarnSessionClusterEntrypoint.java</file>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.entrypoint.YarnJobClusterEntrypoint.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.entrypoint.StandaloneSessionClusterEntrypoint.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.entrypoint.MesosSessionClusterEntrypoint.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.entrypoint.MesosJobClusterEntrypoint.java</file>
    </fixedFiles>
  </bug>
  <bug id="7875" opendate="2017-10-19 00:00:00" fixdate="2017-10-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>StaticFileServer should not reuse the tmp dir</summary>
      <description>The flip-6 DispatcherRestEndpoint starts the StaticFileServer always with the same temporay directory. This should be changed, because otherwise multiple rest endpoints might interfere with each other.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.RestHandlerConfiguration.java</file>
    </fixedFiles>
  </bug>
  <bug id="7879" opendate="2017-10-20 00:00:00" fixdate="2017-10-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>only execute apache-rat in one build profile</summary>
      <description>Similarly to FLINK-7350 we improve build times (and stability!) by only executing the Apache Rat plugin in the build profile that builds the all of flink.Bump apache-rat-plugin to 0.12, [RAT-173Cannot skip plugin run completely, but check only | https://issues.apache.org/jira/browse/RAT-173]</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.travis.mvn.watchdog.sh</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7880" opendate="2017-10-20 00:00:00" fixdate="2017-12-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>flink-queryable-state-java fails with core-dump</summary>
      <description>The flink-queryable-state-java module fails on Travis with a core dump.https://travis-ci.org/tillrohrmann/flink/jobs/289949829</description>
      <version>1.4.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-queryable-state.flink-queryable-state-runtime.src.test.java.org.apache.flink.queryablestate.itcases.NonHAAbstractQueryableStateTestBase.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-runtime.src.test.java.org.apache.flink.queryablestate.itcases.HAAbstractQueryableStateTestBase.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-runtime.src.test.java.org.apache.flink.queryablestate.itcases.AbstractQueryableStateTestBase.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-runtime.src.test.java.org.apache.flink.queryablestate.itcases.NonHAQueryableStateRocksDBBackendITCase.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-runtime.src.test.java.org.apache.flink.queryablestate.itcases.KVStateRequestSerializerRocksDBTest.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-runtime.src.test.java.org.apache.flink.queryablestate.itcases.HAQueryableStateRocksDBBackendITCase.java</file>
    </fixedFiles>
  </bug>
  <bug id="7882" opendate="2017-10-20 00:00:00" fixdate="2017-10-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Writing to S3 from EMR fails with exception</summary>
      <description>Writing to S3 from EMR fails with exception:The program finished with the following exception:org.apache.flink.client.program.ProgramInvocationException: The program execution failed: Job execution failed. at org.apache.flink.client.program.ClusterClient.run(ClusterClient.java:485) at org.apache.flink.yarn.YarnClusterClient.submitJob(YarnClusterClient.java:215) at org.apache.flink.client.program.ClusterClient.run(ClusterClient.java:449) at org.apache.flink.streaming.api.environment.StreamContextEnvironment.execute(StreamContextEnvironment.java:66) at org.apache.flink.streaming.examples.wordcount.WordCount.main(WordCount.java:89) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:525) at org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:417) at org.apache.flink.client.program.ClusterClient.run(ClusterClient.java:389) at org.apache.flink.client.CliFrontend.executeProgram(CliFrontend.java:819) at org.apache.flink.client.CliFrontend.run(CliFrontend.java:282) at org.apache.flink.client.CliFrontend.parseParameters(CliFrontend.java:1071) at org.apache.flink.client.CliFrontend$2.call(CliFrontend.java:1118) at org.apache.flink.client.CliFrontend$2.call(CliFrontend.java:1115) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:422) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1746) at org.apache.flink.runtime.security.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41) at org.apache.flink.client.CliFrontend.main(CliFrontend.java:1115)Caused by: org.apache.flink.runtime.client.JobExecutionException: Job execution failed. at org.apache.flink.runtime.jobmanager.JobManager$$anonfun$handleMessage$1$$anonfun$applyOrElse$6.apply$mcV$sp(JobManager.scala:923) at org.apache.flink.runtime.jobmanager.JobManager$$anonfun$handleMessage$1$$anonfun$applyOrElse$6.apply(JobManager.scala:866) at org.apache.flink.runtime.jobmanager.JobManager$$anonfun$handleMessage$1$$anonfun$applyOrElse$6.apply(JobManager.scala:866) at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39) at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415) at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)Caused by: java.lang.NoClassDefFoundError: com/sun/xml/bind/v2/model/impl/ModelBuilderI at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:763) at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) at java.net.URLClassLoader.defineClass(URLClassLoader.java:467) at java.net.URLClassLoader.access$100(URLClassLoader.java:73) at java.net.URLClassLoader$1.run(URLClassLoader.java:368) at java.net.URLClassLoader$1.run(URLClassLoader.java:362) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:361) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:763) at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) at java.net.URLClassLoader.defineClass(URLClassLoader.java:467) at java.net.URLClassLoader.access$100(URLClassLoader.java:73) at java.net.URLClassLoader$1.run(URLClassLoader.java:368) at java.net.URLClassLoader$1.run(URLClassLoader.java:362) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:361) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at com.sun.xml.bind.v2.runtime.JAXBContextImpl.getTypeInfoSet(JAXBContextImpl.java:444) at com.sun.xml.bind.v2.runtime.JAXBContextImpl.&lt;init&gt;(JAXBContextImpl.java:292) at com.sun.xml.bind.v2.runtime.JAXBContextImpl.&lt;init&gt;(JAXBContextImpl.java:139) at com.sun.xml.bind.v2.runtime.JAXBContextImpl$JAXBContextBuilder.build(JAXBContextImpl.java:1138) at com.sun.xml.bind.v2.ContextFactory.createContext(ContextFactory.java:162) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at javax.xml.bind.ContextFinder.newInstance(ContextFinder.java:247) at javax.xml.bind.ContextFinder.newInstance(ContextFinder.java:234) at javax.xml.bind.ContextFinder.find(ContextFinder.java:441) at javax.xml.bind.JAXBContext.newInstance(JAXBContext.java:641) at javax.xml.bind.JAXBContext.newInstance(JAXBContext.java:584) at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.util.Base64.&lt;clinit&gt;(Base64.java:44) at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.util.BinaryUtils.fromBase64(BinaryUtils.java:71) at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.AmazonS3Client.putObject(AmazonS3Client.java:1715) at com.amazon.ws.emr.hadoop.fs.s3.lite.call.PutObjectCall.performCall(PutObjectCall.java:34) at com.amazon.ws.emr.hadoop.fs.s3.lite.call.PutObjectCall.performCall(PutObjectCall.java:9) at com.amazon.ws.emr.hadoop.fs.s3.lite.call.AbstractUploadingS3Call.perform(AbstractUploadingS3Call.java:62) at com.amazon.ws.emr.hadoop.fs.s3.lite.executor.GlobalS3Executor.execute(GlobalS3Executor.java:80) at com.amazon.ws.emr.hadoop.fs.s3.lite.AmazonS3LiteClient.invoke(AmazonS3LiteClient.java:176) at com.amazon.ws.emr.hadoop.fs.s3.lite.AmazonS3LiteClient.putObject(AmazonS3LiteClient.java:104) at com.amazon.ws.emr.hadoop.fs.s3n.Jets3tNativeFileSystemStore.storeFile(Jets3tNativeFileSystemStore.java:165) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) at com.sun.proxy.$Proxy26.storeFile(Unknown Source) at com.amazon.ws.emr.hadoop.fs.s3n.S3NativeFileSystem$NativeS3FsOutputStream.close(S3NativeFileSystem.java:364) at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72) at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106) at org.apache.flink.runtime.fs.hdfs.HadoopDataOutputStream.close(HadoopDataOutputStream.java:52) at org.apache.flink.core.fs.ClosingFSDataOutputStream.close(ClosingFSDataOutputStream.java:64) at org.apache.flink.api.common.io.FileOutputFormat.close(FileOutputFormat.java:267) at org.apache.flink.streaming.api.functions.sink.OutputFormatSinkFunction.close(OutputFormatSinkFunction.java:93) at org.apache.flink.api.common.functions.util.FunctionUtils.closeFunction(FunctionUtils.java:43) at org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.close(AbstractUdfStreamOperator.java:109) at org.apache.flink.streaming.runtime.tasks.StreamTask.closeAllOperators(StreamTask.java:394) at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:281) at org.apache.flink.runtime.taskmanager.Task.run(Task.java:712) at java.lang.Thread.run(Thread.java:748)Caused by: java.lang.ClassNotFoundException: com.sun.xml.bind.v2.model.impl.ModelBuilderI at java.net.URLClassLoader.findClass(URLClassLoader.java:381) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ... 68 moreGit bisect between commits 84a07a34ac22af14f2dd0319447ca5f45de6d0bb (good) and c81a6db44817ce818c949c2fd55ebfc2af0cc913 (bad)identified 5a5006ceb8d19bc0f3cc490451a18b8fc21197cb to be the first bad commit.Command to start the job:HADOOP_CONF_DIR=/etc/hadoop/conf bin/flink run -m yarn-cluster -yn 1 examples/streaming/WordCount.jar --output s3://mybucket/out --input s3://mybucket/inputEMR release label: emr-5.9.0Hadoop distribution: Amazon 2.7.3 Commands used to compile Flink:mvn clean install -Pdocs-and-source -DskipTests -Dhadoop.version=2.7.3cd flink-distmvn clean install -Pdocs-and-source -DskipTests -Dhadoop.version=2.7.3Java and Maven version used to compile Flink:java -versionopenjdk version "1.8.0_144"OpenJDK Runtime Environment (Zulu 8.23.0.3-macosx) (build 1.8.0_144-b01)OpenJDK 64-Bit Server VM (Zulu 8.23.0.3-macosx) (build 25.144-b01, mixed mode)mvn -versionApache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-10T17:41:47+01:00)</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7898" opendate="2017-10-22 00:00:00" fixdate="2017-10-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TaskExecutorTest.testTriggerRegistrationOnLeaderChange fails on Travis</summary>
      <description>The TaskExecutorTest.testTriggerRegistrationOnLeaderChange fails spuriously on Travis.https://travis-ci.org/aljoscha/flink/jobs/291074999</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.registration.RetryingRegistration.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.registration.RegisteredRpcConnection.java</file>
    </fixedFiles>
  </bug>
  <bug id="7903" opendate="2017-10-23 00:00:00" fixdate="2017-1-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add Flip6 build profile</summary>
      <description>In order to separate Flip-6 related from non Flip-6 related test cases we should introduce a flip-6 build profile which runs only the flip-6 related tests. I suggest to use JUnit's Category for that.</description>
      <version>1.4.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskexecutor.TaskManagerServicesTest.java</file>
      <file type="M">pom.xml</file>
      <file type="M">flink-yarn.pom.xml</file>
      <file type="M">flink-yarn-tests.pom.xml</file>
      <file type="M">flink-tests.pom.xml</file>
      <file type="M">flink-streaming-scala.pom.xml</file>
      <file type="M">flink-streaming-java.pom.xml</file>
      <file type="M">flink-scala.pom.xml</file>
      <file type="M">flink-clients.pom.xml</file>
      <file type="M">flink-clients.src.test.java.org.apache.flink.client.program.rest.RestClusterClientTest.java</file>
      <file type="M">flink-connectors.pom.xml</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.pom.xml</file>
      <file type="M">flink-contrib.pom.xml</file>
      <file type="M">flink-core.pom.xml</file>
      <file type="M">flink-examples.pom.xml</file>
      <file type="M">flink-filesystems.flink-hadoop-fs.pom.xml</file>
      <file type="M">flink-filesystems.flink-mapr-fs.pom.xml</file>
      <file type="M">flink-filesystems.flink-s3-fs-hadoop.pom.xml</file>
      <file type="M">flink-filesystems.flink-s3-fs-presto.pom.xml</file>
      <file type="M">flink-filesystems.pom.xml</file>
      <file type="M">flink-fs-tests.pom.xml</file>
      <file type="M">flink-java.pom.xml</file>
      <file type="M">flink-libraries.pom.xml</file>
      <file type="M">flink-mesos.pom.xml</file>
      <file type="M">flink-metrics.pom.xml</file>
      <file type="M">flink-optimizer.pom.xml</file>
      <file type="M">flink-queryable-state.pom.xml</file>
      <file type="M">flink-runtime-web.pom.xml</file>
      <file type="M">flink-runtime.pom.xml</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.dispatcher.DispatcherTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.heartbeat.HeartbeatManagerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.jobmaster.JobManagerRunnerMockTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.jobmaster.JobMasterTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.minicluster.MiniClusterITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.resourcemanager.JobLeaderIdServiceTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.resourcemanager.ResourceManagerHATest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.resourcemanager.ResourceManagerJobMasterTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.resourcemanager.ResourceManagerTaskExecutorTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.resourcemanager.slotmanager.SlotProtocolTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.job.BlobServerPortHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.job.JobSubmitHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.messages.MessageParametersTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.messages.RestRequestMarshallingTestBase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.messages.RestResponseMarshallingTestBase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.RestEndpointITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rpc.akka.AkkaRpcActorTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rpc.akka.AkkaRpcServiceTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rpc.akka.MainThreadValidationTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rpc.akka.MessageSerializationTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rpc.AsyncCallsTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rpc.FencedRpcEndpointTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rpc.RpcConnectionTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rpc.RpcEndpointTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskexecutor.slot.TimerServiceTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskexecutor.TaskExecutorITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskexecutor.TaskExecutorTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskexecutor.TaskManagerServicesConfigurationTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="7904" opendate="2017-10-23 00:00:00" fixdate="2017-1-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable Flip6 build profile on Travis</summary>
      <description>In order to continuously test Flip-6 components, we should add a new Travis build matrix entry which runs the Flip-6 test cases.</description>
      <version>1.4.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">.travis.yml</file>
    </fixedFiles>
  </bug>
  <bug id="7908" opendate="2017-10-24 00:00:00" fixdate="2017-10-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Restructure the QS module to reduce client deps.</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.state.ImmutableFoldingStateTest.java</file>
      <file type="M">tools.travis.mvn.watchdog.sh</file>
      <file type="M">pom.xml</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.completeness.TypeInfoTestCoverageTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.StateBackendTestBase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.netty.message.KvStateRequestSerializerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.KvStateLocationTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.KvStateLocationRegistryTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.jobmanager.JobManagerTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskmanager.ActorGatewayKvStateRegistryListener.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskManagerServices.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.rpc.RpcKvStateRegistryListener.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.heap.HeapMapState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.heap.AbstractHeapState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.TaskKvStateRegistry.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.QueryableStateUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.message.KvStateSerializer.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.KvStateRequestStats.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.DisabledKvStateRequestStats.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.AtomicKvStateRequestStats.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.KvStateServerAddress.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.KvStateServer.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.KvStateRegistryListener.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.KvStateRegistryGateway.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.KvStateRegistry.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.KvStateMessage.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.KvStateLocationRegistry.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.KvStateLocation.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.KvStateID.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobmaster.JobMasterGateway.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobmaster.JobMaster.java</file>
      <file type="M">flink-runtime.pom.xml</file>
      <file type="M">flink-queryable-state.pom.xml</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.resources.log4j-test.properties</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.state.ImmutableValueStateTest.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.state.ImmutableReducingStateTest.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.state.ImmutableMapStateTest.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.state.ImmutableListStateTest.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.AbstractRocksDBState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBMapState.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.pom.xml</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.client.proxy.KvStateClientProxyHandler.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.client.proxy.KvStateClientProxyImpl.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.client.QueryableStateClient.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.client.state.ImmutableAggregatingState.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.client.state.ImmutableFoldingState.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.client.state.ImmutableListState.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.client.state.ImmutableMapState.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.client.state.ImmutableReducingState.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.client.state.ImmutableState.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.client.state.ImmutableStateBinder.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.client.state.ImmutableValueState.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.messages.KvStateInternalRequest.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.messages.KvStateRequest.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.messages.KvStateResponse.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.network.AbstractServerBase.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.network.AbstractServerHandler.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.network.BadRequestException.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.network.ChunkedByteBuf.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.network.Client.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.network.ClientHandler.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.network.ClientHandlerCallback.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.network.messages.MessageBody.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.network.messages.MessageDeserializer.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.network.messages.MessageSerializer.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.network.messages.MessageType.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.network.messages.RequestFailure.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.server.KvStateServerHandler.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.server.KvStateServerImpl.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.UnknownJobManagerException.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.UnknownKeyOrNamespaceException.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.UnknownKvStateIdException.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.main.java.org.apache.flink.queryablestate.UnknownKvStateKeyGroupLocationException.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.itcases.AbstractQueryableStateTestBase.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.itcases.HAAbstractQueryableStateTestBase.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.itcases.HAQueryableStateFsBackendITCase.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.itcases.HAQueryableStateRocksDBBackendITCase.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.itcases.KVStateRequestSerializerRocksDBTest.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.itcases.NonHAAbstractQueryableStateTestBase.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.itcases.NonHAQueryableStateFsBackendITCase.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.itcases.NonHAQueryableStateRocksDBBackendITCase.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.network.AbstractServerTest.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.network.ClientTest.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.network.KvStateClientHandlerTest.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.network.KvStateServerHandlerTest.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.network.KvStateServerTest.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.network.MessageSerializerTest.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-java.src.test.java.org.apache.flink.queryablestate.state.ImmutableAggregatingStateTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="7923" opendate="2017-10-25 00:00:00" fixdate="2017-2-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support accessing subfields of a Composite element in an Object Array type column</summary>
      <description>Access type such as:SELECT a[1].f0 FROM MyTablewill cause problem. See following test sample for more details:https://github.com/walterddr/flink/commit/03c93bcb0fb30bd2d327e35b5e244322d449b06a</description>
      <version>1.4.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.utils.CompositeTypeTestBase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.CompositeAccessTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.CodeGenerator.scala</file>
    </fixedFiles>
  </bug>
  <bug id="7924" opendate="2017-10-25 00:00:00" fixdate="2017-10-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix incorrect names of checkpoint options</summary>
      <description>Checkpoint options are incorrectly always called 'FULL_CHECKPOINT' when actually,the checkpoints may always be incremental and only savepoints have to be fulland self contained.Initially, we planned to add options for multiple checkpoints, like checkpointsthat were foreced to be full, and checkpoints that were incremental. That is not necessary at this point.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.ExternalizedCheckpointITCase.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.AbstractStreamOperatorTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.TwoInputStreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskTerminationTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskCancellationBarrierTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.SourceStreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.SourceExternalCheckpointTriggerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.RestoreStreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.OneInputStreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.BlockingCheckpointsTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.io.BarrierTrackerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.io.BarrierBufferTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.io.BarrierBufferMassiveRandomTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.io.BarrierBufferAlignmentLimitTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.async.AsyncWaitOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.AbstractUdfStreamOperatorLifecycleTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.AbstractStreamOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.SourceStreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.AbstractStreamOperator.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskmanager.TaskAsyncCallTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.StateSnapshotCompressionTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.StateBackendTestBase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.OperatorStateBackendTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.MemoryStateBackendTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.heap.HeapKeyedStateBackendSnapshotMigrationTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.messages.CheckpointMessagesTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.api.writer.RecordWriterTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.api.serialization.EventSerializerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.api.CheckpointBarrierTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.checkpoint.CheckpointTypeTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.checkpoint.CheckpointOptionsTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.checkpoint.CheckpointCoordinatorTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.api.serialization.EventSerializer.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.CheckpointOptions.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.CheckpointCoordinator.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackendTest.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBAsyncSnapshotTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="7925" opendate="2017-10-25 00:00:00" fixdate="2017-1-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add CheckpointingOptions</summary>
      <description>The CheckpointingOptions should consolidate all checkpointing and state backend-relatedsettings that were previously split across different classes.</description>
      <version>None</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn-tests.src.test.java.org.apache.flink.yarn.YARNHighAvailabilityITCase.java</file>
      <file type="M">flink-tests.src.test.scala.org.apache.flink.api.scala.migration.StatefulJobSavepointMigrationITCase.scala</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.state.operator.restore.unkeyed.NonKeyedJob.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.state.operator.restore.keyed.KeyedJob.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.recovery.JobManagerHACheckpointRecoveryITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.classloading.ClassLoaderITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.utils.SavepointMigrationTestBase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.SavepointITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.RescalingITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.ExternalizedCheckpointITCase.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.environment.CheckpointConfig.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.testutils.ZooKeeperTestUtils.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.legacy.JobCancellationWithSavepointHandlersTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.jobmanager.JobManagerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.executiongraph.ExecutionGraphDeploymentTest.java</file>
      <file type="M">flink-runtime.src.main.scala.org.apache.flink.runtime.jobmanager.JobManager.scala</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.webmonitor.WebMonitorEndpoint.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.JobCancellationWithSavepointHandlers.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.CheckpointCoordinator.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.WebRuntimeMonitor.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.CoreOptions.java</file>
      <file type="M">flink-connectors.flink-connector-filesystem.src.test.java.org.apache.flink.streaming.connectors.fs.RollingSinkSecuredITCase.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.cli.CliFrontendParser.java</file>
    </fixedFiles>
  </bug>
  <bug id="7934" opendate="2017-10-26 00:00:00" fixdate="2017-1-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade Calcite dependency to 1.15</summary>
      <description>Umbrella issue for all related issues for Apache Calcite 1.15 release.</description>
      <version>None</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.symbols.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.ExpressionUtils.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.calls.ExtractCallGen.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.stream.sql.GroupWindowTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.batch.table.CalcTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.batch.sql.GroupWindowTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.validate.FunctionCatalog.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.time.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.aggregations.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.calls.FunctionGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.calcite.FlinkTypeFactory.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.java.org.apache.calcite.sql.fun.SqlGroupFunction.java</file>
      <file type="M">flink-libraries.flink-table.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7986" opendate="2017-11-5 00:00:00" fixdate="2017-11-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Introduce FilterSetOpTransposeRule to Flink</summary>
      <description>A.unionAll(B).where.groupBy.select =&gt;A.where.unionAll(B.where).groupBy.selectthis rule will reduce networkIO</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.batch.table.SetOperatorsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.rules.FlinkRuleSets.scala</file>
    </fixedFiles>
  </bug>
  <bug id="7989" opendate="2017-11-6 00:00:00" fixdate="2017-11-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>flink-dist jar is deployed twice onto YARN</summary>
      <description>We always add the flink-dist*.jar ourselves, but it could also be inside a shipped folder such as the "lib/" folder and is then deployed again.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0,1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.AbstractYarnClusterDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="7992" opendate="2017-11-6 00:00:00" fixdate="2017-11-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>extend PR template with S3 question</summary>
      <description>S3 file system tests are only run if AWS credentials are specified, i.e. ARTIFACTS_AWS_BUCKET, ARTIFACTS_AWS_ACCESS_KEY, and ARTIFACTS_AWS_SECRET_KEY. Since these must remain secret, they are only set in Apache Flink's Travis CI configuration and not available in the Travis runs on pull requests (PR) to not leak them in any way. This however means that if a contributor changes something S3-related, the PR's test results will not reflect the actual changes and if something breaks there, we will only see it once merged.Therefore, I propose to add one more question to the PR template so that the committer is aware of this fact and the need to run the tests in his own Travis CI configuration first with proper AWS credentials set up.</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">.github.PULL.REQUEST.TEMPLATE.md</file>
    </fixedFiles>
  </bug>
  <bug id="7993" opendate="2017-11-6 00:00:00" fixdate="2017-11-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Kafka 08 curator shading pattern out-of-sync</summary>
      <description>The kafka 08 shading pattern for curator is out-of-sync with flink-runtime.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7994" opendate="2017-11-6 00:00:00" fixdate="2017-11-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove direct curator dependency from flink-mesos</summary>
      <description>Flink-mesos defines a direct flink-shaded-curator dependency, however all used paths go through utitlity methods flink-runtime to avoid issues related to shading.The only usage in flink-mesos is in the ZookeeperUtils class, this is however unused.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.util.ZooKeeperUtils.java</file>
      <file type="M">flink-mesos.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7996" opendate="2017-11-6 00:00:00" fixdate="2017-11-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add support for (left.time = right.time) predicates to window join.</summary>
      <description>A common operation is to join the result of two window aggregations on the same timestamp. However, window joins do not support equality predicates on time attributes such as left.time = right.time but require two range predicates such as left.time &gt;= right.time AND left.time &lt;= right.time.This can be fixed in the translation code (the operator does not have to be touched).</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0,1.5.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.stream.sql.JoinITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.stream.table.JoinTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.stream.sql.validation.JoinValidationTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.stream.sql.JoinTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.join.WindowJoinUtil.scala</file>
      <file type="M">docs.dev.table.tableApi.md</file>
      <file type="M">docs.dev.table.sql.md</file>
    </fixedFiles>
  </bug>
  <bug id="7997" opendate="2017-11-6 00:00:00" fixdate="2017-11-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Avro should be always in the user code</summary>
      <description>Having Avro in the user code space makes it possible for users to use different Avro versions that the ones pulled in by an overloaded classpath (for example when having Hadoop in the classpath)This is possible through the new child-first classloading in Flink 1.4.Also, this should fix the problem of "X cannot be cast to X", because Avro classes will be scoped to the user code class loader, and the Avro schema cache will not be JVM-wide-</description>
      <version>None</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-kafka-base.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.11.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-filesystem.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8002" opendate="2017-11-6 00:00:00" fixdate="2017-11-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Incorrect join window boundaries for LESS_THAN and GREATER_THAN predicates</summary>
      <description>The boundaries of LESS_THAN and GREATER_THAN predicates are not correctly computed if the time attribute of the right table is referenced on the left side of the join predicate.Instead of adding (subtracting) 1 millisecond, 1 millisecond is subtracted (added). Hence, the boundary is off-by-2.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0,1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.stream.sql.JoinTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.join.WindowJoinUtil.scala</file>
    </fixedFiles>
  </bug>
  <bug id="8009" opendate="2017-11-7 00:00:00" fixdate="2017-11-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>flink-dist pulls in flink-runtime&amp;#39;s transitive avro/jackson dependency</summary>
      <description>The promotion of transitive dependencies in flink-runtime causes flink-dist to contain some transitive dependencies from flink-shaded-hadoop. (most notably, avro and codehaus.jackson)We will either have to add an exclusion for each dependency to flink-dist, set flink-shaded-hadoop to provided in flink-runtime (hacky, but less intrusive), or remove the promotion and explicitly depend on various akka dependencies.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-runtime.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8010" opendate="2017-11-7 00:00:00" fixdate="2017-11-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bump remaining flink-shaded dependencies</summary>
      <description></description>
      <version>1.4.0,1.5.0</version>
      <fixedVersion>1.4.0,1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8014" opendate="2017-11-7 00:00:00" fixdate="2017-11-7 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Add Kafka010JsonTableSink</summary>
      <description>Offer a TableSource for JSON-encoded Kafka 0.10 topics but no TableSink.Since, the required base classes are already there, a Kafka010JsonTableSink can be easily added.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0,1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaTableSinkTestBase.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.JsonRowSerializationSchemaTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.util.serialization.JsonRowSerializationSchema.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.KafkaTableSink.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.KafkaJsonTableSink.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka09JsonTableSinkTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.Kafka09JsonTableSink.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka08JsonTableSinkTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.Kafka08JsonTableSink.java</file>
    </fixedFiles>
  </bug>
  <bug id="8016" opendate="2017-11-7 00:00:00" fixdate="2017-11-7 01:00:00" resolution="Done">
    <buginformation>
      <summary>Add documentation for KafkaJsonTableSink</summary>
      <description>The documentation of available TableSources should be extended to include the KafkaJsonTableSinks.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0,1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.dev.table.sourceSinks.md</file>
    </fixedFiles>
  </bug>
  <bug id="8033" opendate="2017-11-8 00:00:00" fixdate="2017-7-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>JDK 9 support</summary>
      <description>This is a JIRA to track all issues that found to make Flink compatible with Java 9.</description>
      <version>1.4.0</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8038" opendate="2017-11-8 00:00:00" fixdate="2017-11-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support MAP value constructor</summary>
      <description>Similar to https://issues.apache.org/jira/browse/FLINK-4554We want to support Map value constructor which is supported by Calcite:https://calcite.apache.org/docs/reference.html#value-constructorsSELECT MAP['key1', f0, 'key2', f1] AS stringKeyedMap, MAP['key', 'value'] AS literalMap, MAP[f0, f1] AS fieldMapFROM tableThis should enable users to construct MapTypeInfo, one of the CompositeType.</description>
      <version>None</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.validation.MapTypeValidationTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.utils.MapTypeTestBase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.SqlExpressionTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.ArrayTypeTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.validate.FunctionCatalog.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.typeutils.TypeCheckUtils.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.ProjectionTranslator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.ExpressionParser.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.CodeGenUtils.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.calcite.FlinkTypeFactory.scala</file>
      <file type="M">docs.dev.table.tableApi.md</file>
      <file type="M">docs.dev.table.sql.md</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.stream.table.CalcITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.MapTypeTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.map.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.item.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.ExpressionUtils.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.cardinality.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.array.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.CodeGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.calls.ScalarOperators.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.scala.expressionDsl.scala</file>
    </fixedFiles>
  </bug>
  <bug id="8050" opendate="2017-11-12 00:00:00" fixdate="2017-1-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RestServer#shutdown() ignores exceptions thrown when shutting down netty.</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.RestServerEndpoint.java</file>
    </fixedFiles>
  </bug>
  <bug id="8059" opendate="2017-11-13 00:00:00" fixdate="2017-11-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Querying the state of a non-existing jobs should throw JobNotFoundException</summary>
      <description>When querying the state for a non-existing job you currently get a IllegalStateException. Given that this isn't an illegal state we should return a JobNotFoundException instead.</description>
      <version>1.4.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.jobmanager.JobManagerTest.java</file>
      <file type="M">flink-runtime.src.main.scala.org.apache.flink.runtime.jobmanager.JobManager.scala</file>
      <file type="M">flink-queryable-state.flink-queryable-state-runtime.src.test.java.org.apache.flink.queryablestate.itcases.AbstractQueryableStateTestBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="8063" opendate="2017-11-13 00:00:00" fixdate="2017-11-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Client blocks indefinitely when querying a non-existing state</summary>
      <description>When querying for a non-existing state (as in, no state was registered under queryableStateName) the client blocks indefinitely.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-queryable-state.flink-queryable-state-runtime.src.test.java.org.apache.flink.queryablestate.itcases.AbstractQueryableStateTestBase.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-runtime.src.main.java.org.apache.flink.queryablestate.client.proxy.KvStateClientProxyHandler.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-client-java.src.main.java.org.apache.flink.queryablestate.network.AbstractServerHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="8064" opendate="2017-11-13 00:00:00" fixdate="2017-5-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Extend dependency section to list flink-core</summary>
      <description>The dependency section of the Queryable State documentation should also list flink-core as it is inherently required when working with the client. (Which has flink-core set to provided)</description>
      <version>1.4.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.dev.stream.state.queryable.state.md</file>
    </fixedFiles>
  </bug>
  <bug id="8069" opendate="2017-11-14 00:00:00" fixdate="2017-11-14 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Support empty watermark strategy for TableSources</summary>
      <description>In case the underlying data stream source emits watermarks, it should be possible to define an empty watermark strategy for rowtime attributes in the RowtimeAttributeDescriptor.</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.utils.testTableSources.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.stream.table.TableSourceITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.sources.wmstrategies.watermarkStrategies.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.datastream.StreamTableSourceScan.scala</file>
    </fixedFiles>
  </bug>
  <bug id="8071" opendate="2017-11-14 00:00:00" fixdate="2017-11-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Akka shading sometimes produces invalid code</summary>
      <description>On 2 separate occasions on separate machines I hit the exception below when starting a cluster. Once it happened in the yarn tests, another time after starting a standalone cluster with flink-dist.The issue appears to be related to some asm bug that affects both sbt-assembly and the maven-shade-plugin.References: https://github.com/akka/akka/issues/21596 https://github.com/sbt/sbt-assembly/issues/205From what I have found this should be fixable my bumping the asm version of the maven-shade-plugin to 5.1 (our version uses 5.0.2), or just increment the plugin version to 3.0.0 (which already uses 5.1).Important: This only occurs if a relocation is performed in flink-dist.java.lang.Exception: Could not create actor system at org.apache.flink.runtime.clusterframework.BootstrapTools.startActorSystem(BootstrapTools.java:171) at org.apache.flink.runtime.clusterframework.BootstrapTools.startActorSystem(BootstrapTools.java:115) at org.apache.flink.yarn.YarnApplicationMasterRunner.runApplicationMaster(YarnApplicationMasterRunner.java:313) at org.apache.flink.yarn.YarnApplicationMasterRunner$1.call(YarnApplicationMasterRunner.java:199) at org.apache.flink.yarn.YarnApplicationMasterRunner$1.call(YarnApplicationMasterRunner.java:196) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:422) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1556) at org.apache.flink.runtime.security.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41) at org.apache.flink.yarn.YarnApplicationMasterRunner.run(YarnApplicationMasterRunner.java:196) at org.apache.flink.yarn.YarnApplicationMasterRunner.main(YarnApplicationMasterRunner.java:123)Caused by: java.lang.VerifyError: Inconsistent stackmap frames at branch target 152Exception Details: Location: akka/dispatch/Mailbox.processAllSystemMessages()V @152: getstatic Reason: Type top (current frame, locals[9]) is not assignable to 'akka/dispatch/sysmsg/SystemMessage' (stack map, locals[9]) Current Frame: bci: @131 flags: { } locals: { 'akka/dispatch/Mailbox', 'java/lang/InterruptedException', 'akka/dispatch/sysmsg/SystemMessage', top, 'akka/dispatch/Mailbox', 'java/lang/Throwable', 'java/lang/Throwable' } stack: { integer } Stackmap Frame: bci: @152 flags: { } locals: { 'akka/dispatch/Mailbox', 'java/lang/InterruptedException', 'akka/dispatch/sysmsg/SystemMessage', top, 'akka/dispatch/Mailbox', 'java/lang/Throwable', 'java/lang/Throwable', top, top, 'akka/dispatch/sysmsg/SystemMessage' } stack: { } Bytecode: 0x0000000: 014c 2ab2 0132 b601 35b6 0139 4db2 013e 0x0000010: 2cb6 0142 9900 522a b600 c69a 004b 2c4e 0x0000020: b201 3e2c b601 454d 2db9 0148 0100 2ab6 0x0000030: 0052 2db6 014b b801 0999 000e bb00 e759 0x0000040: 1301 4db7 010f 4cb2 013e 2cb6 0150 99ff 0x0000050: bf2a b600 c69a ffb8 2ab2 0132 b601 35b6 0x0000060: 0139 4da7 ffaa 2ab6 0052 b600 56b6 0154 0x0000070: b601 5a3a 04a7 0091 3a05 1905 3a06 1906 0x0000080: c100 e799 0015 1906 c000 e73a 0719 074c 0x0000090: b200 f63a 08a7 0071 b201 5f19 06b6 0163 0x00000a0: 3a0a 190a b601 6899 0006 1905 bf19 0ab6 0x00000b0: 016c c000 df3a 0b2a b600 52b6 0170 b601 0x00000c0: 76bb 000f 5919 0b2a b600 52b6 017a b601 0x00000d0: 80b6 0186 2ab6 018a bb01 8c59 b701 8e13 0x00000e0: 0190 b601 9419 09b6 0194 1301 96b6 0194 0x00000f0: 190b b601 99b6 0194 b601 9ab7 019d b601 0x0000100: a3b2 00f6 3a08 b201 3e2c b601 4299 0026 0x0000110: 2c3a 09b2 013e 2cb6 0145 4d19 09b9 0148 0x0000120: 0100 1904 2ab6 0052 b601 7a19 09b6 01a7 0x0000130: a7ff d62b c600 09b8 0109 572b bfb1 Exception Handler Table: bci [290, 307] =&gt; handler: 120 Stackmap Table: append_frame(@13,Object[#231],Object[#177]) append_frame(@71,Object[#177]) chop_frame(@102,1) full_frame(@120,{Object[#2],Object[#231],Object[#177],Top,Object[#2],Object[#177]},{Object[#223]}) full_frame(@152,{Object[#2],Object[#231],Object[#177],Top,Object[#2],Object[#223],Object[#223],Top,Top,Object[#177]},{}) append_frame(@173,Object[#357]) full_frame(@262,{Object[#2],Object[#231],Object[#177],Top,Object[#2]},{}) same_frame(@307) same_frame(@317) at akka.dispatch.Mailboxes.&lt;init&gt;(Mailboxes.scala:33) at akka.actor.ActorSystemImpl.&lt;init&gt;(ActorSystem.scala:800) at akka.actor.ActorSystem$.apply(ActorSystem.scala:245) at akka.actor.ActorSystem$.apply(ActorSystem.scala:288) at akka.actor.ActorSystem$.apply(ActorSystem.scala:263) at akka.actor.ActorSystem$.create(ActorSystem.scala:191) at org.apache.flink.runtime.akka.AkkaUtils$.createActorSystem(AkkaUtils.scala:106) at org.apache.flink.runtime.akka.AkkaUtils.createActorSystem(AkkaUtils.scala) at org.apache.flink.runtime.clusterframework.BootstrapTools.startActorSystem(BootstrapTools.java:158)</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8076" opendate="2017-11-15 00:00:00" fixdate="2017-11-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade KinesisProducer to 0.10.6 to set properties approperiately</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.util.KinesisConfigUtilTest.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.util.KinesisConfigUtil.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8079" opendate="2017-11-15 00:00:00" fixdate="2017-1-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Skip remaining E2E tests if one failed</summary>
      <description>I propose that if one end-to-end tests fails the remaining tests are skipped.aljoscha What do you think?</description>
      <version>1.4.0,1.5.0</version>
      <fixedVersion>1.4.1,1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.travis.mvn.watchdog.sh</file>
    </fixedFiles>
  </bug>
  <bug id="8081" opendate="2017-11-15 00:00:00" fixdate="2017-11-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Annotate MetricRegistry#getReporters() with @VisibleForTesting</summary>
      <description>MetricRegistry#getReporters() is only used for testing purposes to provide access to instantiated reporters. We should annotate this method with @VisibleForTesting.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0,1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.MetricRegistryImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="8084" opendate="2017-11-15 00:00:00" fixdate="2017-11-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove japicmp deactivations in several modules</summary>
      <description>The japicmp module is explicitly deactivated in the following modules: java8 quickstart yarn-testsSince the module has to be explicitly enabled these entries can be removed.</description>
      <version>1.4.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn-tests.pom.xml</file>
      <file type="M">flink-quickstart.pom.xml</file>
      <file type="M">flink-java8.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8095" opendate="2017-11-17 00:00:00" fixdate="2017-11-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Introduce ProjectSetOpTransposeRule to Flink</summary>
      <description>ProjectSetOpTransposeRule is similar to FilterSetOpTransposeRule, adding ProjectSetOpTransposeRule is necessary.</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.plan.TimeIndicatorConversionTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.stream.table.SetOperatorsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.batch.table.SetOperatorsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.rules.FlinkRuleSets.scala</file>
    </fixedFiles>
  </bug>
  <bug id="8097" opendate="2017-11-17 00:00:00" fixdate="2017-11-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add built-in support for min/max aggregation for Date/Time</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.aggfunctions.MinWithRetractAggFunctionTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.aggfunctions.MinAggFunctionTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.aggfunctions.MaxWithRetractAggFunctionTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.aggfunctions.MaxAggFunctionTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.AggregateUtil.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.aggfunctions.Ordering.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.aggfunctions.MinAggFunctionWithRetract.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.aggfunctions.MinAggFunction.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.aggfunctions.MaxAggFunctionWithRetract.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.aggfunctions.MaxAggFunction.scala</file>
    </fixedFiles>
  </bug>
  <bug id="8105" opendate="2017-11-19 00:00:00" fixdate="2017-11-19 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Removed unnecessary null check</summary>
      <description>eg.if (value != null &amp;&amp; value instanceof String)null instanceof String returns false hence replaced the check withif (value instanceof String)</description>
      <version>1.4.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.GenericWriteAheadSink.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.TimestampedFileInputSplit.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskmanager.TaskManagerRegistrationTest.java</file>
      <file type="M">flink-optimizer.src.main.java.org.apache.flink.optimizer.traversals.PlanFinalizer.java</file>
      <file type="M">flink-optimizer.src.main.java.org.apache.flink.optimizer.plantranslate.JobGraphGenerator.java</file>
      <file type="M">flink-optimizer.src.main.java.org.apache.flink.optimizer.dataproperties.RequestedGlobalProperties.java</file>
      <file type="M">flink-optimizer.src.main.java.org.apache.flink.optimizer.dataproperties.InterestingProperties.java</file>
      <file type="M">flink-optimizer.src.main.java.org.apache.flink.optimizer.dataproperties.GlobalProperties.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.io.CollectionInputFormatTest.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sca.UdfAnalyzerUtils.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sca.UdfAnalyzer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.io.LocatableInputSplit.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.io.GenericInputSplit.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.FileInputSplit.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.runtime.RuntimeSerializerFactory.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.FileInputFormat.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.DelimitedInputFormat.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.BinaryInputFormat.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.api.FlinkLocalCluster.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.main.java.org.apache.flink.api.java.hadoop.mapred.HadoopInputFormatBase.java</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.src.main.java.org.apache.flink.api.java.hadoop.mapreduce.HadoopInputFormatBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="8110" opendate="2017-11-20 00:00:00" fixdate="2017-11-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>fasterxml jackson services are not relocated</summary>
      <description>The jackson services aren't properly relocated. Flink-shaded uses maven-shade-plugin:2.4.1 which doesn't properly relocate services as described in the flink-s3-fs-presto shade-plugin configuration.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-dist.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8113" opendate="2017-11-20 00:00:00" fixdate="2017-11-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bump maven-shade-plugin to 3.0.0</summary>
      <description>We should investigate whether we can bump the shade plugin to 3.0.0. Earlier versions do not properly relocate services, forcing some modules to set a different plugin version in their own configuration (flink-s3-fs-presto for example, or flink-dist after FLINK-8111).</description>
      <version>None</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-quickstart.flink-quickstart-scala.src.main.resources.archetype-resources.pom.xml</file>
      <file type="M">flink-quickstart.flink-quickstart-java.src.main.resources.archetype-resources.pom.xml</file>
      <file type="M">flink-filesystems.flink-s3-fs-presto.pom.xml</file>
      <file type="M">flink-filesystems.flink-s3-fs-hadoop.pom.xml</file>
      <file type="M">flink-dist.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-cassandra.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8115" opendate="2017-11-20 00:00:00" fixdate="2017-11-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Kafka E2E tests fail on travis</summary>
      <description>The kafka E2E tests fail on travis since the download of kafka fails.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">test-infra.end-to-end-test.test.streaming.kafka010.sh</file>
    </fixedFiles>
  </bug>
  <bug id="8123" opendate="2017-11-21 00:00:00" fixdate="2017-11-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bundle python library in jar</summary>
      <description>Currently, the flink-python library is split into 2 parts in flink-dist; the flink-python jar in the /lib directory, and the python scripts in the /resources directory.I propose to bundle the python scripts in the flink-python jar. This way, the jar is self-contained and we no longer need to search for the python scripts (which was hacky and had a separate codepath for tests).</description>
      <version>None</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-python.src.main.java.org.apache.flink.python.api.PythonPlanBinder.java</file>
      <file type="M">flink-libraries.flink-python.pom.xml</file>
      <file type="M">flink-dist.src.main.assemblies.bin.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8142" opendate="2017-11-23 00:00:00" fixdate="2017-11-23 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Cleanup reference to deprecated constants in ConfigConstants</summary>
      <description>ConfigConstants contains several deprecated String constants that are used by other Flink modules. Those should be cleaned up.</description>
      <version>1.4.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.cli.FlinkYarnSessionCli.java</file>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.AbstractYarnClusterDescriptor.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskmanager.TaskManagerStartupTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.restart.RestartStrategyFactory.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.manualtests.ManualExactlyOnceWithStreamReshardingTest.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.manualtests.ManualExactlyOnceTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="8149" opendate="2017-11-24 00:00:00" fixdate="2017-11-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace usages of deprecated SerializationSchema</summary>
      <description>The deprecated SerializationSchema in flink-streaming-java, has been moved to flink-core.But, the deprecate SerializationSchema is still used in flink-connector-kinesis.</description>
      <version>1.4.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.testutils.TestableKinesisDataFetcher.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.testutils.TestableFlinkKinesisConsumer.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.testutils.KinesisEventsGeneratorProducerThread.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.testutils.ExactlyOnceValidatingConsumerThread.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.manualtests.ManualConsumerProducerTest.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.FlinkKinesisProducerTest.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.FlinkKinesisConsumerTest.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.serialization.KinesisDeserializationSchemaWrapper.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.serialization.KinesisDeserializationSchema.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.FlinkKinesisProducer.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.FlinkKinesisConsumer.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.examples.ProduceIntoKinesis.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.examples.ConsumeFromKinesis.java</file>
    </fixedFiles>
  </bug>
  <bug id="8156" opendate="2017-11-27 00:00:00" fixdate="2017-1-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bump commons-beanutils version to 1.9.3</summary>
      <description>Commons-beanutils v1.8.0 dependency is not security compliant. See CVE-2014-0114:Apache Commons BeanUtils, as distributed in lib/commons-beanutils-1.8.0.jar in Apache Struts 1.x through 1.3.10 and in other products requiring commons-beanutils through 1.9.2, does not suppress the class property, which allows remote attackers to "manipulate" the ClassLoader and execute arbitrary code via the class parameter, as demonstrated by the passing of this parameter to the getClass method of the ActionForm object in Struts 1.Note that current version commons-beanutils 1.9.2 in turn has a CVE in its dependency commons-collections (CVE-2015-6420, see BEANUTILS-488), which is fixed in 1.9.3.We should upgrade commons-beanutils from 1.8.3 to 1.9.3</description>
      <version>1.4.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-shaded-hadoop.flink-shaded-hadoop2.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8173" opendate="2017-11-30 00:00:00" fixdate="2017-12-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix input unboxing and support Avro Utf8 in Table API</summary>
      <description>It is a stream of Avro objects, simply select a String field and trying to print out val query = "SELECT nd_key FROM table1" val result = tableEnv.sql(query) tableEnv.toAppendStream&amp;#91;org.apache.avro.util.Utf8&amp;#93;(result).print()11/29/2017 16:07:36 Source: Custom Source -&gt; from: (accepted_cohort_id, admin_id, after_submission, amount_paid, anonymous_id, application_id, atom_key, bd_group_key, biz_geo, braavos_purchase_id, category, cohort_id, concept_key, concept_rank, context, context_campaign, context_experiment, coupon_code, course_key, course_rank, cta_destination, cta_location, cta_message, cta_type, currency, decision_group_id, device_browser, device_os, device_os_version, device_type, duration, evaluation_id, event_type, fin_geo, in_collaboration_with, lab_id, lab_rank, label, lesson_key, lesson_rank, locale, max_pause_duration, message, message_id, module_key, module_rank, nd_key, nd_unit_id, nd_unit_rank, new_cohort_id, notification_id, num_concepts_completed, num_interactions, num_lessons_completed, old_cohort_id, part_key, part_rank, pause_duration, pause_reason, payment_plan, payment_provider, points_earned, points_possible, price, price_sheet, product_key, product_type, provider_charge_id, provider_refund_id, quiz_type, referrer, refund_amount, requested_cohort_id, results, scholarship_group_key, search_term, skill_level, subscription_id, suspension_length, suspension_reason, technology, timestamp, total_concepts, total_lessons, total_time_sec, type, unenroll_reason, user_id, user_locale, user_response, variant, version, workspace_id, workspace_session, workspace_type) -&gt; select: (nd_key) -&gt; to: Utf8 -&gt; Sink: Unnamed(5/8) switched to FAILED org.apache.flink.api.common.InvalidProgramException: Table program cannot be compiled. This is a bug. Please file an issue. at org.apache.flink.table.codegen.Compiler$class.compile(Compiler.scala:36) at org.apache.flink.table.runtime.CRowOutputMapRunner.compile(CRowOutputMapRunner.scala:33) at org.apache.flink.table.runtime.CRowOutputMapRunner.open(CRowOutputMapRunner.scala:48) at org.apache.flink.api.common.functions.util.FunctionUtils.openFunction(FunctionUtils.java:36) at org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.open(AbstractUdfStreamOperator.java:111) at org.apache.flink.streaming.runtime.tasks.StreamTask.openAllOperators(StreamTask.java:376) at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:253) at org.apache.flink.runtime.taskmanager.Task.run(Task.java:702) at java.lang.Thread.run(Thread.java:748)Caused by: org.codehaus.commons.compiler.CompileException: Line 790, Column 15: Assignment conversion not possible from type "java.lang.CharSequence" to type "org.apache.avro.util.Utf8" at org.codehaus.janino.UnitCompiler.compileError(UnitCompiler.java:11672) at org.codehaus.janino.UnitCompiler.assignmentConversion(UnitCompiler.java:10528) at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:2534) at org.codehaus.janino.UnitCompiler.access$2600(UnitCompiler.java:212) at org.codehaus.janino.UnitCompiler$6.visitLocalVariableDeclarationStatement(UnitCompiler.java:1459) at org.codehaus.janino.UnitCompiler$6.visitLocalVariableDeclarationStatement(UnitCompiler.java:1443) at org.codehaus.janino.Java$LocalVariableDeclarationStatement.accept(Java.java:3348) at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:1443) at org.codehaus.janino.UnitCompiler.compileStatements(UnitCompiler.java:1523) at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:3052) at org.codehaus.janino.UnitCompiler.compileDeclaredMethods(UnitCompiler.java:1313) at org.codehaus.janino.UnitCompiler.compileDeclaredMethods(UnitCompiler.java:1286) at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:785) at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:436) at org.codehaus.janino.UnitCompiler.access$400(UnitCompiler.java:212) at org.codehaus.janino.UnitCompiler$2.visitPackageMemberClassDeclaration(UnitCompiler.java:390) at org.codehaus.janino.UnitCompiler$2.visitPackageMemberClassDeclaration(UnitCompiler.java:385) at org.codehaus.janino.Java$PackageMemberClassDeclaration.accept(Java.java:1405) at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:385) at org.codehaus.janino.UnitCompiler.compileUnit(UnitCompiler.java:357) at org.codehaus.janino.SimpleCompiler.cook(SimpleCompiler.java:234) at org.codehaus.janino.SimpleCompiler.compileToClassLoader(SimpleCompiler.java:446) at org.codehaus.janino.SimpleCompiler.cook(SimpleCompiler.java:213) at org.codehaus.janino.SimpleCompiler.cook(SimpleCompiler.java:204) at org.codehaus.commons.compiler.Cookable.cook(Cookable.java:80) at org.codehaus.commons.compiler.Cookable.cook(Cookable.java:75) at org.apache.flink.table.codegen.Compiler$class.compile(Compiler.scala:33) ... 8 more</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0,1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.harness.JoinHarnessTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.CodeGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8174" opendate="2017-11-30 00:00:00" fixdate="2017-12-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Mesos RM unable to accept offers for unreserved resources</summary>
      <description>Flink has suffered a regression due to FLINK-7294. Any attempt to accept a resource offer that is based on unreserved resources will fail, because Flink (as of FLINK-7294) erroneously insists that the resource come from a prior reservation.Looking at the original issue, the problem may have been misdiagnosed. Ideally Flink should work with both reserved and unreserved resources, but the latter is a more common situation that is now broken.</description>
      <version>1.3.3,1.4.0</version>
      <fixedVersion>1.4.0,1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-mesos.src.test.scala.org.apache.flink.mesos.scheduler.LaunchCoordinatorTest.scala</file>
      <file type="M">flink-mesos.src.main.scala.org.apache.flink.mesos.scheduler.LaunchCoordinator.scala</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.util.MesosConfiguration.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.Utils.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.scheduler.LaunchableTask.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.runtime.clusterframework.LaunchableMesosWorker.java</file>
    </fixedFiles>
  </bug>
  <bug id="8186" opendate="2017-12-1 00:00:00" fixdate="2017-12-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>AvroInputFormat regression: fails to deserialize GenericRecords on standalone cluster with hadoop27 compat</summary>
      <description>The following job runs fine on a Flink 1.3.2 cluster, but fails on a Flink 1.4.0 RC2 standalone cluster, "hadoop27" flavour:public class GenericRecordCount { public static void main(String[] args) throws Exception { String input = ParameterTool.fromArgs(args).getRequired("input"); ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment(); long count = env.readFile(new AvroInputFormat&lt;&gt;(new Path(input), GenericRecord.class), input) .count(); System.out.printf("Counted %d records\n", count); }}Runs fine in LocalExecutionEnvironment and also on no-hadoop flavour standalone cluster, though. Exception thrown in Flink 1.4.0 hadoop27:12/01/2017 13:22:09 DataSource (at readFile(ExecutionEnvironment.java:514) (org.apache.flink.formats.avro.AvroInputFormat))(4/4) switched to FAILEDjava.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.avro.generic.GenericRecord.&lt;init&gt;() at org.apache.avro.specific.SpecificData.newInstance(SpecificData.java:353) at org.apache.avro.specific.SpecificData.newRecord(SpecificData.java:369) at org.apache.avro.reflect.ReflectData.newRecord(ReflectData.java:901) at org.apache.avro.generic.GenericDatumReader.readRecord(GenericDatumReader.java:212) at org.apache.avro.generic.GenericDatumReader.readWithoutConversion(GenericDatumReader.java:175) at org.apache.avro.generic.GenericDatumReader.read(GenericDatumReader.java:153) at org.apache.avro.generic.GenericDatumReader.read(GenericDatumReader.java:145) at org.apache.avro.file.DataFileStream.next(DataFileStream.java:233) at org.apache.flink.formats.avro.AvroInputFormat.nextRecord(AvroInputFormat.java:165) at org.apache.flink.runtime.operators.DataSourceTask.invoke(DataSourceTask.java:167) at org.apache.flink.runtime.taskmanager.Task.run(Task.java:718) at java.lang.Thread.run(Thread.java:748)Caused by: java.lang.NoSuchMethodException: org.apache.avro.generic.GenericRecord.&lt;init&gt;() at java.lang.Class.getConstructor0(Class.java:3082) at java.lang.Class.getDeclaredConstructor(Class.java:2178) at org.apache.avro.specific.SpecificData.newInstance(SpecificData.java:347) ... 11 more</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-dist.pom.xml</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.AvroUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="8194" opendate="2017-12-4 00:00:00" fixdate="2017-12-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Disable akka.actor.warn-about-java-serializer-usage to suppress akka warnings when using the Java serializer</summary>
      <description>With Akka 2.4, Akka is logging warnings when using the Java serializer for message serialization. We should turn this off via akka.actor.warn-about-java-serializer-usage since we used Java serialization before and it is only cluttering the logs making the users worry.</description>
      <version>1.4.0,1.5.0</version>
      <fixedVersion>1.4.0,1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.scala.org.apache.flink.runtime.akka.AkkaUtils.scala</file>
    </fixedFiles>
  </bug>
  <bug id="8196" opendate="2017-12-4 00:00:00" fixdate="2017-12-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix Hadoop Servlet Dependency Exclusion</summary>
      <description>We currently exclude the `javax.servlet` API dependency, which is unfortunately needed as a core dependency by Hadoop 2.7.</description>
      <version>None</version>
      <fixedVersion>1.4.0,1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-shaded-hadoop.flink-shaded-hadoop2.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8203" opendate="2017-12-5 00:00:00" fixdate="2017-1-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make schema definition of DataStream/DataSet to Table conversion more flexible</summary>
      <description>When converting or registering a DataStream or DataSet as Table, the schema of the table can be defined (by default it is extracted from the TypeInformation.The schema needs to be manually specified to select (project) fields, rename fields, or define time attributes. Right now, there are several limitations how the fields can be defined that also depend on the type of the DataStream / DataSet. Types with explicit field ordering (e.g., tuples, case classes, Row) require schema definition based on the position of fields. Pojo types which have no fixed order of fields, require to refer to fields by name. Moreover, there are several restrictions on how time attributes can be defined, e.g., event time attribute must replace an existing field or be appended and proctime attributes must be appended.I think we can make the schema definition more flexible and provide two modes:1. Reference input fields by name: All fields in the schema definition are referenced by name (and possibly renamed using an alias (as). In this mode, fields can be reordered and projected out. Moreover, we can define proctime and eventtime attributes at arbitrary positions using arbitrary names (except those that existing the result schema). This mode can be used for any input type, including POJOs. This mode is used if all field references exist in the input type.2. Reference input fields by position: Field references might not refer to existing fields in the input type. In this mode, fields are simply renamed. Event-time attributes can replace the field on their position in the input data (if it is of correct type) or be appended at the end. Proctime attributes must be appended at the end. This mode can only be used if the input type has a defined field order (tuple, case class, Row).We need to add more tests the check for all combinations of input types and schema definition modes.</description>
      <version>1.4.0,1.5.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.utils.TableTestBase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.batch.table.TableEnvironmentITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.validation.TableEnvironmentValidationTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.TableEnvironmentTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.stream.StreamTableEnvironmentValidationTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.table.runtime.batch.table.JavaTableEnvironmentITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.sources.TableSourceUtil.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.SortUtil.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.schema.InlineTable.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.schema.FlinkTableFunctionImpl.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.CodeGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.TableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.StreamTableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.BatchTableEnvironment.scala</file>
    </fixedFiles>
  </bug>
  <bug id="8209" opendate="2017-12-6 00:00:00" fixdate="2017-1-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Do not relay on specific method names in LocalBufferPoolTest</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskmanager.TaskCancelAsyncProducerConsumerITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.buffer.LocalBufferPoolDestroyTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="8222" opendate="2017-12-7 00:00:00" fixdate="2017-12-7 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Update Scala version</summary>
      <description>Update Scala to version 2.11.12. I don't believe this affects the Flink distribution but rather anyone who is compiling Flink or a Flink-quickstart-derived program on a shared system."A privilege escalation vulnerability (CVE-2017-15288) has been identified in the Scala compilation daemon."https://www.scala-lang.org/news/security-update-nov17.html</description>
      <version>1.4.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-quickstart.flink-quickstart-scala.src.main.resources.archetype-resources.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8235" opendate="2017-12-11 00:00:00" fixdate="2017-12-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cannot run spotbugs for single module</summary>
      <description>When running the spotbugs plugin (-Dspotbugs) in a sub-module of Flink the build will fail because it cannot find the exclusion file.[ERROR] Could not find resource 'tools/maven/spotbugs-exclude.xml'. -&gt; [Help 1]The problem is that the configured relative path is resolved against the sub-module directory, and not the parent one.</description>
      <version>1.4.0,1.5.0</version>
      <fixedVersion>1.4.1,1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8255" opendate="2017-12-13 00:00:00" fixdate="2017-1-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Key expressions on named row types do not work</summary>
      <description>The following program fails with a ClassCastException. It seems that key expressions and rows are not tested well. We should add more tests for them.final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();TypeInformation[] types = new TypeInformation[] {Types.INT, Types.INT};String[] fieldNames = new String[]{"id", "value"};RowTypeInfo rowTypeInfo = new RowTypeInfo(types, fieldNames);env.fromCollection(Collections.singleton(new Row(2)), rowTypeInfo).keyBy("id").sum("value").print();env.execute("Streaming WordCount");</description>
      <version>1.4.0,1.5.0</version>
      <fixedVersion>1.11.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.typeutils.FieldAccessorTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.util.typeutils.FieldAccessorFactory.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.operator.MinByOperatorTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.operator.MaxByOperatorTest.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.UnsortedGrouping.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.DataSet.java</file>
    </fixedFiles>
  </bug>
  <bug id="8258" opendate="2017-12-14 00:00:00" fixdate="2017-1-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable query configuration for batch queries</summary>
      <description>Query configuration holds some parameters to configure the behavior of batch queries. However, since there was nothing to set for batch queries before, the configuration was not really passed. Due to FLINK-8236, we need to enable it now.</description>
      <version>None</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.dataset.DataSetWindowAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.dataset.DataSetValues.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.dataset.DataSetUnion.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.dataset.DataSetSort.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.dataset.DataSetSingleRowJoin.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.dataset.DataSetScan.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.dataset.DataSetRel.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.dataset.DataSetMinus.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.dataset.DataSetJoin.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.dataset.DataSetIntersect.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.dataset.DataSetDistinct.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.dataset.DataSetCorrelate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.dataset.DataSetCalc.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.dataset.DataSetAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.nodes.dataset.BatchTableSourceScan.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.scala.TableConversions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.scala.BatchTableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.java.BatchTableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.BatchTableEnvironment.scala</file>
    </fixedFiles>
  </bug>
  <bug id="8260" opendate="2017-12-14 00:00:00" fixdate="2017-1-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document API of Kafka 0.11 Producer</summary>
      <description>The API of the Flink Kafka Producer changed for Kafka 0.11, for example there is no writeToKafkaWithTimestamps method anymore.This needs to be added to the Kafka connector documentation, i.e., a new tab with a code snippet needs to be added for Kafka 0.11.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.1,1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.dev.connectors.kafka.md</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer010.java</file>
    </fixedFiles>
  </bug>
  <bug id="8261" opendate="2017-12-14 00:00:00" fixdate="2017-12-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Typos in the shading exclusion for jsr305 in the quickstarts</summary>
      <description>This affects both the Java and the Scala quickstarts.The typo is findbgs instead of findbugs.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.1,1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-quickstart.flink-quickstart-scala.src.main.resources.archetype-resources.pom.xml</file>
      <file type="M">flink-quickstart.flink-quickstart-java.src.main.resources.archetype-resources.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8263" opendate="2017-12-14 00:00:00" fixdate="2017-12-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Wrong packaging of flink-core in scala quickstarty</summary>
      <description>The scala quickstart currently does not set flink-core to "provided" in the "build-jar" profile.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.1,1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-quickstart.flink-quickstart-scala.src.main.resources.archetype-resources.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8264" opendate="2017-12-14 00:00:00" fixdate="2017-12-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add Scala to the parent-first loading patterns</summary>
      <description>A confusing experience happens when users accidentally package the Scala Library into their jar file. The reversed class loading duplicates Scala's classes, leading to exceptions like the one below.By adding scala. to the default 'parent-first-patterns' we can improve the user experience in such situations.Exception Stack Trace:java.lang.ClassCastException: cannot assign instance of org.peopleinmotion.TestFunction$$anonfun$1 to field org.apache.flink.streaming.api.scala.DataStream$$anon$7.cleanFun$6 of type scala.Function1 in instance of org.apache.flink.streaming.api.scala.DataStream$$anon$7 at java.io.ObjectStreamClass$FieldReflector.setObjFieldValues(ObjectStreamClass.java:2233) at java.io.ObjectStreamClass.setObjFieldValues(ObjectStreamClass.java:1405) at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2288) at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206) at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568) at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282) at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206) at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568) at java.io.ObjectInputStream.readObject(ObjectInputStream.java:428) at org.apache.flink.util.InstantiationUtil.deserializeObject(InstantiationUtil.java:290) at org.apache.flink.util.InstantiationUtil.readObjectFromConfig(InstantiationUtil.java:248) at org.apache.flink.streaming.api.graph.StreamConfig.getStreamOperator(StreamConfig.java:220) ... 6 more</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.1,1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.CoreOptions.java</file>
    </fixedFiles>
  </bug>
  <bug id="8265" opendate="2017-12-14 00:00:00" fixdate="2017-1-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Missing jackson dependency for flink-mesos</summary>
      <description>The Jackson library that is required by Fenzo is missing from the Flink distribution jar-file.This manifests as an exception in certain circumstances when a hard constraint is configured ("mesos.constraints.hard.hostattribute").NoClassDefFoundError: org/apache/flink/mesos/shaded/com/fasterxml/jackson/databind/ObjectMapper at com.netflix.fenzo.ConstraintFailure.&lt;clinit&gt;(ConstraintFailure.java:35) at com.netflix.fenzo.AssignableVirtualMachine.findFailedHardConstraints(AssignableVirtualMachine.java:784) at com.netflix.fenzo.AssignableVirtualMachine.tryRequest(AssignableVirtualMachine.java:581) at com.netflix.fenzo.TaskScheduler.evalAssignments(TaskScheduler.java:796) at com.netflix.fenzo.TaskScheduler.access$1500(TaskScheduler.java:70)</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.1,1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-mesos.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8271" opendate="2017-12-17 00:00:00" fixdate="2017-1-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>upgrade from deprecated classes to AmazonKinesis</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.4.1,1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.manualtests.ManualExactlyOnceWithStreamReshardingTest.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.manualtests.ManualExactlyOnceTest.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.util.AWSUtil.java</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.proxy.KinesisProxy.java</file>
    </fixedFiles>
  </bug>
  <bug id="8276" opendate="2017-12-18 00:00:00" fixdate="2017-1-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Annotation for Kafka connector</summary>
      <description>See parent issue.</description>
      <version>None</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.ExceptionProxy.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.util.serialization.TypeInformationKeyValueSerializationSchema.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.util.serialization.KeyedSerializationSchemaWrapper.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.util.serialization.KeyedSerializationSchema.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.util.serialization.KeyedDeserializationSchemaWrapper.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.util.serialization.KeyedDeserializationSchema.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.util.serialization.JsonRowSerializationSchema.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.util.serialization.JsonRowDeserializationSchema.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.util.serialization.JSONDeserializationSchema.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.partitioner.KafkaPartitioner.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.partitioner.FlinkKafkaPartitioner.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.partitioner.FlinkKafkaDelegatePartitioner.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.partitioner.FlinkFixedPartitioner.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.KafkaTableSource.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.KafkaTableSink.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.KafkaJsonTableSource.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.KafkaJsonTableSink.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.KafkaAvroTableSource.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.metrics.KafkaMetricWrapper.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicsDescriptor.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionStateWithPunctuatedWatermarks.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionStateWithPeriodicWatermarks.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionStateSentinel.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionState.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionLeader.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionAssigner.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.KafkaCommitCallback.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer010.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer010.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.main.java.org.apache.flink.streaming.connectors.kafka.internal.Kafka010Fetcher.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.main.java.org.apache.flink.streaming.connectors.kafka.internal.Kafka010PartitionDiscoverer.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.main.java.org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerCallBridge010.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.main.java.org.apache.flink.streaming.connectors.kafka.Kafka010AvroTableSource.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.main.java.org.apache.flink.streaming.connectors.kafka.Kafka010JsonTableSink.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.main.java.org.apache.flink.streaming.connectors.kafka.Kafka010JsonTableSource.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.main.java.org.apache.flink.streaming.connectors.kafka.Kafka010TableSource.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.11.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafka011ErrorCode.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.11.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafka011Exception.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.11.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer011.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.11.src.main.java.org.apache.flink.streaming.connectors.kafka.internal.FlinkKafkaProducer.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.11.src.main.java.org.apache.flink.streaming.connectors.kafka.internal.metrics.KafkaMetricMuttableWrapper.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.11.src.main.java.org.apache.flink.streaming.connectors.kafka.internal.TransactionalIdsGenerator.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.11.src.main.java.org.apache.flink.streaming.connectors.kafka.Kafka011AvroTableSource.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.11.src.main.java.org.apache.flink.streaming.connectors.kafka.Kafka011JsonTableSource.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.11.src.main.java.org.apache.flink.streaming.connectors.kafka.Kafka011TableSource.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer08.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer08.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.Kafka08Fetcher.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.Kafka08PartitionDiscoverer.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.KillerWatchDog.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.PartitionInfoFetcher.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.PeriodicOffsetCommitter.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.SimpleConsumerThread.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.ZookeeperOffsetHandler.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.Kafka08AvroTableSource.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.Kafka08JsonTableSink.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.Kafka08JsonTableSource.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.Kafka08TableSource.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer09.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer09.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.internal.Handover.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.internal.Kafka09Fetcher.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.internal.Kafka09PartitionDiscoverer.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerCallBridge.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.Kafka09AvroTableSource.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.Kafka09JsonTableSink.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.Kafka09JsonTableSource.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.Kafka09TableSource.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.config.OffsetCommitMode.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.config.OffsetCommitModes.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.config.StartupMode.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducerBase.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.AbstractPartitionDiscoverer.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.ClosableBlockingQueue.java</file>
    </fixedFiles>
  </bug>
  <bug id="8278" opendate="2017-12-18 00:00:00" fixdate="2017-12-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scala examples in Metric documentation do not compile</summary>
      <description>The Scala examples in the Metrics documentation do not compile.The line @transient private var counter: Counterneeds to be extended to@transient private var counter: Counter = _</description>
      <version>1.3.2,1.4.0,1.5.0</version>
      <fixedVersion>1.4.1,1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.monitoring.metrics.md</file>
      <file type="M">docs.dev.stream.state.state.md</file>
    </fixedFiles>
  </bug>
  <bug id="8280" opendate="2017-12-18 00:00:00" fixdate="2017-1-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable checkstyle for org.apache.flink.runtime.blob</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.maven.suppressions-runtime.xml</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.blob.TestingFailingBlobServer.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.blob.BlobClientTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.blob.BlobClientSslTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.blob.BlobCacheGetTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.FileSystemBlobStore.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobServerProtocol.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobServer.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobKey.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobInputStream.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="8286" opendate="2017-12-18 00:00:00" fixdate="2017-5-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix Flink-Yarn-Kerberos integration for FLIP-6</summary>
      <description>The current Flink-Yarn-Kerberos in Flip-6 is broken.</description>
      <version>None</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.YarnTaskExecutorRunner.java</file>
    </fixedFiles>
  </bug>
  <bug id="8287" opendate="2017-12-18 00:00:00" fixdate="2017-1-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Flink Kafka Producer docs should clearly state what partitioner is used by default</summary>
      <description>See original discussion in ML: http://apache-flink-user-mailing-list-archive.2336050.n4.nabble.com/FlinkKafkaProducerXX-td16951.htmlIt is worth mentioning what partitioning scheme is used by the FlinkKafkaProducer by default when writing to Kafka, as it seems user are often surprised by the default FlinkFixedPartitioner.</description>
      <version>None</version>
      <fixedVersion>1.4.1,1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer09.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer08.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.11.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer011.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer010.java</file>
      <file type="M">docs.dev.connectors.kafka.md</file>
    </fixedFiles>
  </bug>
  <bug id="8295" opendate="2017-12-19 00:00:00" fixdate="2017-12-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Netty shading does not work properly</summary>
      <description>Multiple users complained that the Cassandra connector is not usable in Flink 1.4.0 due to wrong/insufficient shading of Netty.See:http://mail-archives.apache.org/mod_mbox/flink-user/201712.mbox/%3Cb1f584b918c8aaf98b744c168407b0f5%40dbruhn.de%3Ehttp://mail-archives.apache.org/mod_mbox/flink-user/201712.mbox/%3CCACk7FTgMPR03bPBoKzmeVKCqS%2BumTR1u1X%2BKdPtHRgbnUZiO3A%40mail.gmail.com%3E</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.1,1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-cassandra.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8301" opendate="2017-12-21 00:00:00" fixdate="2017-12-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support Unicode in codegen for SQL &amp;&amp; TableAPI</summary>
      <description>The current code generation do not support Unicode, "\u0001" will be generated to "u0001", function call like concat(str, "\u0001") will lead to wrong result.This issue intend to handle char/varchar literal correctly, some examples followed as below.literal: '\u0001abc' -&gt; codegen: "\u0001abc"literal: '\u0022\' -&gt; codegen: "\""</description>
      <version>1.4.0,1.5.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.stream.table.CalcITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.stream.sql.SqlITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.batch.table.CalcITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.batch.sql.CalcITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.utils.userDefinedScalarFunctions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.literals.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.ExpressionReducer.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.CodeGenerator.scala</file>
    </fixedFiles>
  </bug>
  <bug id="8303" opendate="2017-12-21 00:00:00" fixdate="2017-10-21 01:00:00" resolution="Won&amp;#39;t Fix">
    <buginformation>
      <summary>Update Savepoint Compatibility Table for 1.4</summary>
      <description>The savepoint compatibility table of the upgrading applications documentation needs to be extended for 1.4.Also, the whole page should be double checked.</description>
      <version>1.4.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.build.docs.sh</file>
      <file type="M">docs.Gemfile.lock</file>
      <file type="M">docs.Gemfile</file>
    </fixedFiles>
  </bug>
  <bug id="8308" opendate="2017-12-22 00:00:00" fixdate="2017-2-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update yajl-ruby dependency to 1.3.1 or higher</summary>
      <description>We got notified that yajl-ruby &lt; 1.3.1, a dependency which is used to build the Flink website, has a security vulnerability of high severity.We should update yajl-ruby to 1.3.1 or higher.Since the website is built offline and served as static HTML, I don't think this is a super critical issue (please correct me if I'm wrong), but we should resolve this soon.</description>
      <version>None</version>
      <fixedVersion>1.4.2,1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs..plugins.highlightCode.rb</file>
      <file type="M">docs..layouts.plain.html</file>
      <file type="M">docs..config.yml</file>
      <file type="M">docs.ruby2.Gemfile.lock</file>
      <file type="M">docs.ruby2.Gemfile</file>
      <file type="M">docs.Gemfile.lock</file>
      <file type="M">docs.Gemfile</file>
      <file type="M">docs.build.docs.sh</file>
    </fixedFiles>
  </bug>
  <bug id="8312" opendate="2017-12-23 00:00:00" fixdate="2017-12-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix ScalarFunction varargs length exceeds 254 for SQL</summary>
      <description>With Varargs, TableAPI can handle scalar function call with parameters exceeds 254 correctly.This issue is intend to support long parameters for SQL</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.stream.sql.SqlITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.utils.ScalarSqlFunction.scala</file>
    </fixedFiles>
  </bug>
  <bug id="8320" opendate="2017-12-26 00:00:00" fixdate="2017-1-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Flink cluster does not work on Java 9</summary>
      <description>Recently got a new macbook and figured it was a good time to install java 9 and try it out. I didn't realize that Java 9 was such a breaking update (eg: https://blog.codefx.org/java/java-9-migration-guide/) and took the Flink documentation at face value and assumed that Java 7+ or higher would be fine.Here's is what happens after starting a local cluster and attempting to run the sample WordCount program under Java 9:flink-1.4.0 $ export JAVA_HOME=$(/usr/libexec/java_home -v 9)cru@lappy:flink-1.4.0 $ java -versionjava version "9.0.1"Java(TM) SE Runtime Environment (build 9.0.1+11)Java HotSpot(TM) 64-Bit Server VM (build 9.0.1+11, mixed mode)cru@lappy:flink-1.4.0 $ bin/start-cluster.shStarting cluster.Starting jobmanager daemon on host lappy.local.Starting taskmanager daemon on host lappy.local.cru@lappy:flink-1.4.0 $ bin/flink run examples/streaming/WordCount.jarCluster configuration: Standalone cluster with JobManager at localhost/127.0.0.1:6123Using address localhost:6123 to connect to JobManager.JobManager web interface address http://localhost:8081Starting execution of programExecuting WordCount example with default input data set.Use --input to specify file input.Printing result to stdout. Use --output to specify output path.Submitting job with JobID: ee054ffeb4784848143b76b7d51d99c1. Waiting for job completion.------------------------------------------------------------ The program finished with the following exception:org.apache.flink.client.program.ProgramInvocationException: The program execution failed: Couldn't retrieve the JobExecutionResult from the JobManager. at org.apache.flink.client.program.ClusterClient.run(ClusterClient.java:492) at org.apache.flink.client.program.StandaloneClusterClient.submitJob(StandaloneClusterClient.java:105) at org.apache.flink.client.program.ClusterClient.run(ClusterClient.java:456) at org.apache.flink.streaming.api.environment.StreamContextEnvironment.execute(StreamContextEnvironment.java:66) at org.apache.flink.streaming.examples.wordcount.WordCount.main(WordCount.java:89) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:564) at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:525) at org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:417) at org.apache.flink.client.program.ClusterClient.run(ClusterClient.java:396) at org.apache.flink.client.CliFrontend.executeProgram(CliFrontend.java:802) at org.apache.flink.client.CliFrontend.run(CliFrontend.java:282) at org.apache.flink.client.CliFrontend.parseParameters(CliFrontend.java:1054) at org.apache.flink.client.CliFrontend$1.call(CliFrontend.java:1101) at org.apache.flink.client.CliFrontend$1.call(CliFrontend.java:1098) at org.apache.flink.runtime.security.NoOpSecurityContext.runSecured(NoOpSecurityContext.java:30) at org.apache.flink.client.CliFrontend.main(CliFrontend.java:1098)Caused by: org.apache.flink.runtime.client.JobExecutionException: Couldn't retrieve the JobExecutionResult from the JobManager. at org.apache.flink.runtime.client.JobClient.awaitJobResult(JobClient.java:300) at org.apache.flink.runtime.client.JobClient.submitJobAndWait(JobClient.java:387) at org.apache.flink.client.program.ClusterClient.run(ClusterClient.java:481) ... 18 moreCaused by: org.apache.flink.runtime.client.JobClientActorConnectionTimeoutException: Lost connection to the JobManager. at org.apache.flink.runtime.client.JobClientActor.handleMessage(JobClientActor.java:219) at org.apache.flink.runtime.akka.FlinkUntypedActor.handleLeaderSessionID(FlinkUntypedActor.java:104) at org.apache.flink.runtime.akka.FlinkUntypedActor.onReceive(FlinkUntypedActor.java:71) at akka.actor.UntypedActor$$anonfun$receive$1.applyOrElse(UntypedActor.scala:165) at akka.actor.Actor$class.aroundReceive(Actor.scala:502) at akka.actor.UntypedActor.aroundReceive(UntypedActor.scala:95) at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526) at akka.actor.ActorCell.invoke(ActorCell.scala:495) at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257) at akka.dispatch.Mailbox.run(Mailbox.scala:224) at akka.dispatch.Mailbox.exec(Mailbox.scala:234) at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)WARNING: An illegal reflective access operation has occurredWARNING: Illegal reflective access by org.apache.flink.shaded.akka.org.jboss.netty.util.internal.ByteBufferUtil (file:/Users/cru/proj/flink/flink-1.4.0/lib/flink-dist_2.11-1.4.0.jar) to method java.nio.DirectByteBuffer.cleaner()WARNING: Please consider reporting this to the maintainers of org.apache.flink.shaded.akka.org.jboss.netty.util.internal.ByteBufferUtilWARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operationsWARNING: All illegal access operations will be denied in a future releaseStrangely, the logs seemed to suggest that the JobManager was running fine before submitting the job, so figured this was just a problem with the client. The long timeout also made it seem like a low level network issue.Changing to Java 8 (without bouncing the local cluster) similarly times out as well, but gives a slightly different error. Including it here just for posterity in case someone doesn't bounce the server like I did (To be clear: in this case JobManager and TaskManager processes are still running under java 9.):$ java -versionjava version "1.8.0_151"Java(TM) SE Runtime Environment (build 1.8.0_151-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.151-b12, mixed mode)cru@lappy:flink-1.4.0 $ bin/flink run examples/streaming/WordCount.jarCluster configuration: Standalone cluster with JobManager at localhost/127.0.0.1:6123Using address localhost:6123 to connect to JobManager.JobManager web interface address http://localhost:8081Starting execution of programExecuting WordCount example with default input data set.Use --input to specify file input.Printing result to stdout. Use --output to specify output path.Submitting job with JobID: 6bd8fb1a904098473634a7290fbde812. Waiting for job completion.Connected to JobManager at Actor[akka.tcp://flink@localhost:6123/user/jobmanager#1031166856] with leader session id 00000000-0000-0000-0000-000000000000.------------------------------------------------------------ The program finished with the following exception:org.apache.flink.client.program.ProgramInvocationException: The program execution failed: Could not retrieve BlobServer address. at org.apache.flink.client.program.ClusterClient.run(ClusterClient.java:492) at org.apache.flink.client.program.StandaloneClusterClient.submitJob(StandaloneClusterClient.java:105) at org.apache.flink.client.program.ClusterClient.run(ClusterClient.java:456) at org.apache.flink.streaming.api.environment.StreamContextEnvironment.execute(StreamContextEnvironment.java:66) at org.apache.flink.streaming.examples.wordcount.WordCount.main(WordCount.java:89) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:525) at org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:417) at org.apache.flink.client.program.ClusterClient.run(ClusterClient.java:396) at org.apache.flink.client.CliFrontend.executeProgram(CliFrontend.java:802) at org.apache.flink.client.CliFrontend.run(CliFrontend.java:282) at org.apache.flink.client.CliFrontend.parseParameters(CliFrontend.java:1054) at org.apache.flink.client.CliFrontend$1.call(CliFrontend.java:1101) at org.apache.flink.client.CliFrontend$1.call(CliFrontend.java:1098) at org.apache.flink.runtime.security.NoOpSecurityContext.runSecured(NoOpSecurityContext.java:30) at org.apache.flink.client.CliFrontend.main(CliFrontend.java:1098)Caused by: org.apache.flink.runtime.client.JobSubmissionException: Could not retrieve BlobServer address. at org.apache.flink.runtime.client.JobSubmissionClientActor$1.call(JobSubmissionClientActor.java:166) at akka.dispatch.Futures$$anonfun$future$1.apply(Future.scala:97) at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39) at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415) at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)Caused by: java.util.concurrent.TimeoutException at java.util.concurrent.CompletableFuture.timedGet(CompletableFuture.java:1771) at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1915) at org.apache.flink.runtime.client.JobSubmissionClientActor$1.call(JobSubmissionClientActor.java:160) ... 9 moreWhile I get that supporting Java 9 completely is probably a larger task, at the very least we should update documentation / prereqs to say that Flink is not yet compatible.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.1,1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.quickstart.scala.api.quickstart.md</file>
      <file type="M">docs.quickstart.java.api.quickstart.md</file>
    </fixedFiles>
  </bug>
  <bug id="8335" opendate="2018-1-1 00:00:00" fixdate="2018-4-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade hbase connector dependency to 1.4.3</summary>
      <description>hbase 1.4.3 has been released.1.4.0 shows speed improvement over previous 1.x releases.http://search-hadoop.com/m/HBase/YGbbBxedD1Mnm8t?subj=Re+VOTE+The+second+HBase+1+4+0+release+candidate+RC1+is+availableThis issue is to upgrade the dependency to 1.4.3</description>
      <version>None</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-hbase.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8346" opendate="2018-1-2 00:00:00" fixdate="2018-1-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>add S3 signature v4 workaround to docs</summary>
      <description>As per https://lists.apache.org/thread.html/dd59f94d76ae809f83dc36958006974d0a13dc0798856d1d64bb7293@%3Cuser.flink.apache.org%3E, we should add a hint to enable signature v4 for older Hadoop versions to work with S3 (for the non-shaded S3 file systems and regions only accepting v4, e.g. eu-central-1)</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.1,1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.ops.deployment.aws.md</file>
    </fixedFiles>
  </bug>
  <bug id="8350" opendate="2018-1-2 00:00:00" fixdate="2018-1-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>replace "taskmanager.tmp.dirs" with "env.io.tmp.dirs" for all components</summary>
      <description>Currently, there is only a taskmanager.tmp.dirs configuration parameter which (if unset) is set to YARN/Mesos' application environment paths (the latter not quite yet). With FLINK-8279, we also used this as a fall-back for the BLOB caches and would like to use it for the BLOB server as well. This, however, does not reside on the TaskManager and it only makes sense to have a single temporary directory configuration parameter (if desired, this could be extended).I propose to change this to a more generic env.io.tmp.dirs used by all components, i.e. JobManager, JobMaster, Dispatcher, and all the TaskManager-related instances for both YARN and Mesos. TODO: set this value to the appropriate folders for the JobManager code paths during cluster deployment (this exists for the TaskManager only for now)</description>
      <version>1.4.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.YarnTaskManagerRunner.java</file>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.YarnTaskExecutorRunner.java</file>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.YarnApplicationMasterRunner.java</file>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.entrypoint.YarnSessionClusterEntrypoint.java</file>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.entrypoint.YarnJobClusterEntrypoint.java</file>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.entrypoint.YarnEntrypointUtils.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskmanager.TaskManagerStartupTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskmanager.TaskManagerComponentsStartupShutdownTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.blob.BlobUtilsTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskManagerServicesConfiguration.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskManagerConfiguration.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobUtils.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.runtime.clusterframework.MesosTaskManagerRunner.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.runtime.clusterframework.MesosApplicationMasterRunner.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.entrypoint.MesosTaskExecutorRunner.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.entrypoint.MesosSessionClusterEntrypoint.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.entrypoint.MesosJobClusterEntrypoint.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.entrypoint.MesosEntrypointUtils.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.CoreOptions.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.ConfigConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="8362" opendate="2018-1-4 00:00:00" fixdate="2018-2-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Shade Elasticsearch dependencies away</summary>
      <description>It would be nice to make the Elasticsearch connectors self-contained just like the s3 file system implementations and the cassandra connector.</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.1,1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.dev.connectors.elasticsearch.md</file>
      <file type="M">tools.travis.mvn.watchdog.sh</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch5.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch2.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8373" opendate="2018-1-5 00:00:00" fixdate="2018-1-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Inconsistencies in some FileSystem directory functions</summary>
      <description>There are some minor differences in the behaviors of some File System functions, like mkdirs(). On some filesystems, it tolerates existing directories or files in place of parent directories. Some return false in an error case, some throw an exception.I encountered this during writing tests for the file basted state backends. We should harmonize the behavior of FileSystem.mkdirs().I suggest to adopt the behavior that is used by HDFS, which seems the most correct one.</description>
      <version>1.4.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-fs-tests.src.test.java.org.apache.flink.runtime.fs.hdfs.HdfsKindTest.java</file>
      <file type="M">flink-filesystems.flink-s3-fs-presto.pom.xml</file>
      <file type="M">flink-filesystems.flink-s3-fs-hadoop.pom.xml</file>
      <file type="M">flink-filesystems.flink-hadoop-fs.pom.xml</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.core.fs.PathTest.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.local.LocalFileSystem.java</file>
    </fixedFiles>
  </bug>
  <bug id="8374" opendate="2018-1-5 00:00:00" fixdate="2018-1-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unstable Yarn tests due to Akka Shutdown Exception Logging</summary>
      <description>Akka may log the following in some cases during shutdown:java.util.concurrent.RejectedExecutionException: Worker has already been shutdownThe Yarn tests search the logs for unexpected exceptions and fail when encountering that exception. We should whitelist it, as it is not a problem, merely an Akka shutdown artifact.</description>
      <version>1.4.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn-tests.src.test.java.org.apache.flink.yarn.YarnTestBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="8381" opendate="2018-1-5 00:00:00" fixdate="2018-1-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document more flexible schema definition</summary>
      <description>FLINK-8203 implemented a more flexible schema definition for registering DataSet/DataStream as a table. Documentation should be added with examples.</description>
      <version>None</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.TableEnvironment.scala</file>
      <file type="M">docs.dev.table.common.md</file>
    </fixedFiles>
  </bug>
  <bug id="8407" opendate="2018-1-10 00:00:00" fixdate="2018-1-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Setting the parallelism after a partitioning operation should be forbidden</summary>
      <description>Partitioning operations (shuffle, rescale, etc.) for a DataStream create new DataStreams, which allow the users to set parallelisms for them. However, the PartitionTransformations in these returned DataStreams will only add virtual nodes, whose parallelisms could not be specified, in the execution graph. We should forbid users to set the parallelism after a partitioning operation since they won't actually work. Also the corresponding documents should be updated.</description>
      <version>None</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-scala.src.test.scala.org.apache.flink.streaming.api.scala.DataStreamTest.scala</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator.java</file>
    </fixedFiles>
  </bug>
  <bug id="8446" opendate="2018-1-17 00:00:00" fixdate="2018-2-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add support for multiple broadcast states.</summary>
      <description></description>
      <version>1.4.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.co.CoBroadcastWithNonKeyedOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.DataStreamTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.co.KeyedBroadcastProcessFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.co.BroadcastProcessFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.DataStream.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.BroadcastStream.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.BroadcastConnectedStream.java</file>
    </fixedFiles>
  </bug>
  <bug id="8451" opendate="2018-1-18 00:00:00" fixdate="2018-2-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CaseClassSerializer is not backwards compatible in 1.4</summary>
      <description>There seems to be problems with the updated Scala version and the CaseClassSerializer that make it impossible to restore from a Flink 1.3 savepoint.http://mail-archives.apache.org/mod_mbox/flink-user/201801.mbox/%3CCACk7FThV5itjSj_1fG9oaWS86z8WTKWs7abHvok6FnHzq9XT-A%40mail.gmail.com%3Ehttp://mail-archives.apache.org/mod_mbox/flink-user/201801.mbox/%3C7CABB00B-D52F-4878-B04F-201415CEB658%40mediamath.com%3E</description>
      <version>1.4.0,1.5.0</version>
      <fixedVersion>1.4.2,1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.InstantiationUtil.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.runtime.TupleSerializerConfigSnapshot.java</file>
    </fixedFiles>
  </bug>
  <bug id="8455" opendate="2018-1-18 00:00:00" fixdate="2018-1-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add Hadoop to the parent-first loading patterns</summary>
      <description>Various users have reported issues (mainly in the BucketingSink) where they get ClassCastExceptions related to Hadoop classes.In all cases, users had Hadoop dependencies bundled into their application jar files. To make the experience better, I suggest to let Hadoop always load its classes parent-first. </description>
      <version>1.4.0</version>
      <fixedVersion>1.4.1,1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.CoreOptions.java</file>
    </fixedFiles>
  </bug>
  <bug id="8458" opendate="2018-1-19 00:00:00" fixdate="2018-3-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add the switch for keeping both the old mode and the new credit-based mode</summary>
      <description>After the whole feature of credit-based flow control is done, we should add a config parameter to switch on/off the new credit-based mode. To do so, we can roll back to the old network mode for any expected risks.The parameter is defined as taskmanager.network.credit-based-flow-control.enabled and the default value is true. This switch may be removed after next release.</description>
      <version>None</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.TaskManagerOptions.java</file>
      <file type="M">docs..includes.generated.netty.configuration.html</file>
    </fixedFiles>
  </bug>
  <bug id="8468" opendate="2018-1-20 00:00:00" fixdate="2018-6-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make the connector to take advantage of AMQP features (routing key, exchange and message properties)</summary>
      <description>Make the connector to take advantage of AMQP features by adding a constructor and an interface to implement</description>
      <version>1.4.0</version>
      <fixedVersion>1.6.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-rabbitmq.src.main.java.org.apache.flink.streaming.connectors.rabbitmq.RMQSinkPublishOptions.java</file>
      <file type="M">flink-connectors.flink-connector-rabbitmq.src.test.java.org.apache.flink.streaming.connectors.rabbitmq.RMQSinkTest.java</file>
      <file type="M">flink-connectors.flink-connector-rabbitmq.src.main.java.org.apache.flink.streaming.connectors.rabbitmq.RMQSink.java</file>
      <file type="M">flink-connectors.flink-connector-rabbitmq.README.md</file>
    </fixedFiles>
  </bug>
  <bug id="8475" opendate="2018-1-22 00:00:00" fixdate="2018-2-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move remaining sections to generated tables</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.HeartbeatManagerOptions.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.AkkaOptions.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.io.DelimitedInputFormatSamplingTest.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.DelimitedInputFormat.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.JobManagerOptions.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.runtime.clusterframework.MesosTaskManagerParameters.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.configuration.MesosOptions.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.SecurityOptions.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.HighAvailabilityOptions.java</file>
      <file type="M">flink-docs.pom.xml</file>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.YarnResourceManager.java</file>
      <file type="M">flink-tests.src.test.scala.org.apache.flink.api.scala.runtime.jobmanager.JobManagerFailsITCase.scala</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskmanager.TaskManagerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskmanager.TaskManagerStartupTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskmanager.TaskManagerRegistrationTest.java</file>
      <file type="M">flink-runtime.src.main.scala.org.apache.flink.runtime.taskmanager.TaskManager.scala</file>
      <file type="M">flink-runtime.src.main.scala.org.apache.flink.runtime.minicluster.LocalFlinkMiniCluster.scala</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskManagerServicesConfiguration.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskManagerConfiguration.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.netty.NettyConfig.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.clusterframework.BootstrapTools.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.TaskManagerOptions.java</file>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.configuration.YarnConfigOptions.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.ResourceManagerOptions.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.CheckpointingOptions.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.cancelling.CancelingTestBase.java</file>
      <file type="M">flink-test-utils-parent.flink-test-utils.src.main.java.org.apache.flink.test.util.TestBaseUtils.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.ConfigConstants.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.FileOutputFormat.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.LocalExecutor.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.BlobServerOptions.java</file>
      <file type="M">flink-docs.src.main.java.org.apache.flink.docs.configuration.ConfigOptionsDocGenerator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.CoreOptions.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.JoinDriver.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.AbstractCachedBuildSideJoinDriver.java</file>
      <file type="M">flink-optimizer.src.main.java.org.apache.flink.optimizer.plantranslate.JobGraphGenerator.java</file>
      <file type="M">docs.ops.config.md</file>
    </fixedFiles>
  </bug>
  <bug id="8479" opendate="2018-1-22 00:00:00" fixdate="2018-8-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement time-bounded inner join of streams as a TwoInputStreamOperator</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.6.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.TestHarnessUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="8489" opendate="2018-1-23 00:00:00" fixdate="2018-2-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Data is not emitted by second ElasticSearch connector</summary>
      <description>A user reported this issue on the user@f.a.o mailing list.Setup: A program with two pipelines that write to ElasticSearch. The pipelines can be connected or completely separate. ElasticSearch 5.6.4, connector flink-connector-elasticsearch5_2.11Problem: Only one of the ES connectors correctly emits data. The other connector writes a single record and then stops emitting data (or does not write any data at all). The problem does not exist, if the second ES connector is replaced by a different connector (for example Cassandra).Below is a program to reproduce the issue:public class ElasticSearchTest1 { public static void main(String[] args) throws Exception { StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); // set elasticsearch connection details Map&lt;String, String&gt; config = new HashMap&lt;&gt;(); config.put("bulk.flush.max.actions", "1"); config.put("cluster.name", "&lt;cluster name&gt;"); List&lt;InetSocketAddress&gt; transports = new ArrayList&lt;&gt;(); transports.add(new InetSocketAddress(InetAddress.getByName("&lt;host ip&gt;"), 9300)); //Set properties for Kafka Streaming Properties properties = new Properties(); properties.setProperty("bootstrap.servers", "&lt;host ip&gt;"+":9092"); properties.setProperty("group.id", "testGroup"); properties.setProperty("auto.offset.reset", "latest"); //Create consumer for log records FlinkKafkaConsumer011 inputConsumer1 = new FlinkKafkaConsumer011&lt;&gt;("elastic_test1", new JSONDeserializationSchema(), properties); DataStream&lt;RecordOne&gt; firstStream = env .addSource(inputConsumer1) .flatMap(new CreateRecordOne()); firstStream .addSink(new ElasticsearchSink&lt;RecordOne&gt;(config, transports, new ElasticSearchOutputRecord("elastic_test_index1","elastic_test_index1"))); FlinkKafkaConsumer011 inputConsumer2 = new FlinkKafkaConsumer011&lt;&gt;("elastic_test2", new JSONDeserializationSchema(), properties); DataStream&lt;RecordTwo&gt; secondStream = env .addSource(inputConsumer2) .flatMap(new CreateRecordTwo()); secondStream .addSink(new ElasticsearchSink&lt;RecordTwo&gt;(config, transports, new ElasticSearchOutputRecord2("elastic_test_index2","elastic_test_index2"))); env.execute("Elastic Search Test"); }}public class ElasticSearchOutputRecord implements ElasticsearchSinkFunction&lt;RecordOne&gt; { String index; String type; // Initialize filter function public ElasticSearchOutputRecord(String index, String type) { this.index = index; this.type = type; } // construct index request @Override public void process( RecordOne record, RuntimeContext ctx, RequestIndexer indexer) { // construct JSON document to index Map&lt;String, String&gt; json = new HashMap&lt;&gt;(); json.put("item_one", record.item1); json.put("item_two", record.item2); IndexRequest rqst = Requests.indexRequest() .index(index) // index name .type(type) // mapping name .source(json); indexer.add(rqst); }}public class ElasticSearchOutputRecord2 implements ElasticsearchSinkFunction&lt;RecordTwo&gt; { String index; String type; // Initialize filter function public ElasticSearchOutputRecord2(String index, String type) { this.index = index; this.type = type; } // construct index request @Override public void process( RecordTwo record, RuntimeContext ctx, RequestIndexer indexer) { // construct JSON document to index Map&lt;String, String&gt; json = new HashMap&lt;&gt;(); json.put("item_three", record.item3); json.put("item_four", record.item4); IndexRequest rqst = Requests.indexRequest() .index(index) // index name .type(type) // mapping name .source(json); indexer.add(rqst); }}public class CreateRecordOne implements FlatMapFunction&lt;ObjectNode,RecordOne&gt; { static final Logger log = LoggerFactory.getLogger(CreateRecordOne.class); @Override public void flatMap(ObjectNode value, Collector&lt;RecordOne&gt; out) throws Exception { try { out.collect(new RecordOne(value.get("item1").asText(),value.get("item2").asText())); } catch(Exception e) { log.error("error while creating RecordOne", e); } }}public class CreateRecordTwo implements FlatMapFunction&lt;ObjectNode,RecordTwo&gt; { static final Logger log = LoggerFactory.getLogger(CreateRecordTwo.class); @Override public void flatMap(ObjectNode value, Collector&lt;RecordTwo&gt; out) throws Exception { try { out.collect(new RecordTwo(value.get("item1").asText(),value.get("item2").asText())); } catch(Exception e) { log.error("error while creating RecordTwo", e); } }}public class RecordOne { public String item1; public String item2; public RecordOne() {}; public RecordOne ( String item1, String item2 ) { this.item1 = item1; this.item2 = item2; } }public class RecordTwo { public String item3; public String item4; public RecordTwo() {}; public RecordTwo ( String item3, String item4 ) { this.item3 = item3; this.item4 = item4; } }</description>
      <version>1.4.0,1.5.0</version>
      <fixedVersion>1.4.1,1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-elasticsearch.src.test.java.org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkITCase.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch-base.src.test.java.org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkTestBase.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch-base.src.test.java.org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBaseTest.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch-base.src.main.java.org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="8496" opendate="2018-1-23 00:00:00" fixdate="2018-1-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>WebUI does not display TM MemorySegment metrics</summary>
      <description></description>
      <version>1.4.0,1.5.0</version>
      <fixedVersion>1.4.1,1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.util.MetricUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="8499" opendate="2018-1-23 00:00:00" fixdate="2018-1-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Kryo must not be child-first loaded</summary>
      <description>Kryo classes are part of Flink API and hence move between Flink's core (serializers) and the user-application (Avro-Kryo-utils).Duplicating the kryo dependency through reversed classloading yields problems. If Kryo is in the user application jar, together with Avro, the following error happens:(this seems a semi-bug in the JVM, because this should clearly be a ClassCastException, not such a cryptic byte code error).java.lang.VerifyError: Bad type on operand stackException Details: Location: org/apache/flink/formats/avro/utils/AvroKryoSerializerUtils.addAvroGenericDataArrayRegistration(Ljava/util/LinkedHashMap;)V @23: invokespecial Reason: Type 'org/apache/flink/api/java/typeutils/runtime/kryo/Serializers$SpecificInstanceCollectionSerializerForArrayList' (current frame, stack[7]) is not assignable to 'com/esotericsoftware/kryo/Serializer' Current Frame: bci: @23 flags: { } locals: { 'org/apache/flink/formats/avro/utils/AvroKryoSerializerUtils', 'java/util/LinkedHashMap' } stack: { 'java/util/LinkedHashMap', 'java/lang/String', uninitialized 6, uninitialized 6, 'java/lang/Class', uninitialized 12, uninitialized 12, 'org/apache/flink/api/java/typeutils/runtime/kryo/Serializers$SpecificInstanceCollectionSerializerForArrayList' } Bytecode: 0x0000000: 2b12 05b6 000b bb00 0c59 1205 bb00 0d59 0x0000010: bb00 0659 b700 0eb7 000f b700 10b6 0011 0x0000020: 57b1</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.1,1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.CoreOptions.java</file>
    </fixedFiles>
  </bug>
  <bug id="8553" opendate="2018-2-3 00:00:00" fixdate="2018-2-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>switch flink-metrics-datadog to async mode</summary>
      <description>Even though currently flink-metrics-datadog is designed as `fire-and-forget`, it's still using sync calls which may block or slow down core. Need to switch it to async mode.cc Zentol</description>
      <version>1.4.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-metrics.flink-metrics-datadog.src.main.java.org.apache.flink.metrics.datadog.DatadogHttpClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="8555" opendate="2018-2-4 00:00:00" fixdate="2018-2-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix TableFunction varargs length exceeds 254 for SQL</summary>
      <description>With Varargs, TableAPI can handle table function call with parameters exceeds 254 correctly.This issue is intend to support long parameters for SQL</description>
      <version>None</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.table.runtime.utils.JavaUserDefinedTableFunctions.java</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.stream.sql.SqlITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.utils.UserDefinedFunctionUtils.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.utils.TableSqlFunction.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.utils.ScalarSqlFunction.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.utils.AggSqlFunction.scala</file>
    </fixedFiles>
  </bug>
  <bug id="8559" opendate="2018-2-5 00:00:00" fixdate="2018-2-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Exceptions in RocksDBIncrementalSnapshotOperation#takeSnapshot cause job to get stuck</summary>
      <description>In the RocksDBKeyedStatebackend#snapshotIncrementally we can find this code final RocksDBIncrementalSnapshotOperation&lt;K&gt; snapshotOperation = new RocksDBIncrementalSnapshotOperation&lt;&gt;( this, checkpointStreamFactory, checkpointId, checkpointTimestamp);snapshotOperation.takeSnapshot();return new FutureTask&lt;KeyedStateHandle&gt;( new Callable&lt;KeyedStateHandle&gt;() { @Override public KeyedStateHandle call() throws Exception { return snapshotOperation.materializeSnapshot(); } }) { @Override public boolean cancel(boolean mayInterruptIfRunning) { snapshotOperation.stop(); return super.cancel(mayInterruptIfRunning); } @Override protected void done() { snapshotOperation.releaseResources(isCancelled()); }};In the constructor of RocksDBIncrementalSnapshotOperation we call aquireResource() on the RocksDB ResourceGuard. If snapshotOperation.takeSnapshot() fails with an exception these resources are never released. When the task is shutdown due to the exception it will get stuck on releasing RocksDB.</description>
      <version>1.4.0,1.5.0</version>
      <fixedVersion>1.4.1,1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackend.java</file>
    </fixedFiles>
  </bug>
  <bug id="8560" opendate="2018-2-5 00:00:00" fixdate="2018-3-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>add KeyedProcessFunction to expose the key in onTimer() and other methods</summary>
      <description>Currently it is required to store the key of a keyBy() in the processElement method to have access to it in the OnTimerContext.This is not so good as you have to check in the processElement method for every element if the key is already stored and set it if it's not already set.A possible solution would adding OnTimerContext#getCurrentKey() or a similar method. Maybe having it in the open() method could maybe work as well.http://apache-flink-user-mailing-list-archive.2336050.n4.nabble.com/Getting-Key-from-keyBy-in-ProcessFunction-tt18126.html</description>
      <version>1.4.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-scala.src.test.scala.org.apache.flink.streaming.api.scala.DataStreamTest.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.KeyedStream.scala</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.KeyedProcessOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.DataStreamTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.KeyedProcessOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.KeyedStream.java</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.harness.SortProcessFunctionHarnessTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.harness.OverWindowHarnessTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.harness.NonWindowHarnessTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.operators.KeyedProcessOperatorWithWatermarkDelay.scala</file>
      <file type="M">docs.dev.stream.operators.process.function.md</file>
    </fixedFiles>
  </bug>
  <bug id="8576" opendate="2018-2-7 00:00:00" fixdate="2018-2-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Log message for QueryableState loading failure too verbose</summary>
      <description>Whenever a job- or taskmanager is started it attempts to load the queryable state via reflection. If this fails due to the classes not being in the classpath (which is common and the default path) we log the full stacktrace as DEBUG.We should reduce this to a single line as it get's really verbose when sifting through debug logs.</description>
      <version>1.4.0,1.5.0</version>
      <fixedVersion>1.4.2,1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.QueryableStateUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="8650" opendate="2018-2-14 00:00:00" fixdate="2018-7-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add tests and documentation for WINDOW clause</summary>
      <description>We support queries with a WINDOW clause like:SELECT a, SUM(c) OVER w, MIN(c) OVER w FROM MyTable WINDOW w AS (PARTITION BY a ORDER BY proctime ROWS BETWEEN 4 PRECEDING AND CURRENT ROW)But this is neither documented nor tested.</description>
      <version>None</version>
      <fixedVersion>1.4.3,1.5.1,1.6.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.utils.TableTestBase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.stream.sql.OverWindowTest.scala</file>
      <file type="M">docs.dev.table.sql.md</file>
    </fixedFiles>
  </bug>
  <bug id="8657" opendate="2018-2-14 00:00:00" fixdate="2018-2-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix incorrect description for external checkpoint vs savepoint</summary>
      <description>I checked that external checkpoint also supported rescale both in code and practice. But in the doc it still note that "do not support Flink specific features like rescaling." I am afraid whether I have missed something, if so please just close this issue.</description>
      <version>1.4.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.ops.state.state.backends.md</file>
      <file type="M">docs.ops.state.checkpoints.md</file>
    </fixedFiles>
  </bug>
  <bug id="8661" opendate="2018-2-15 00:00:00" fixdate="2018-4-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace Collections.EMPTY_MAP with Collections.emptyMap()</summary>
      <description>The use of Collections.EMPTY_SET and Collections.EMPTY_MAP often causes unchecked assignment. It should be replaced with Collections.emptySet() and Collections.emptyMap() .</description>
      <version>None</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn.src.test.java.org.apache.flink.yarn.UtilsTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.messages.JobAccumulatorsInfoTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.clusterframework.types.ResourceProfileTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.clusterframework.types.ResourceProfile.java</file>
    </fixedFiles>
  </bug>
  <bug id="8680" opendate="2018-2-16 00:00:00" fixdate="2018-2-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Name printing sinks by default.</summary>
      <description>The sinks that pring to std. out and std. err show up as "Sink: Unnamed" in logs and the UI.They should be named "Print to Std. Out" and "Print to Std. Err" by default.</description>
      <version>1.4.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.DataStream.java</file>
    </fixedFiles>
  </bug>
  <bug id="8736" opendate="2018-2-21 00:00:00" fixdate="2018-2-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Memory segment offsets for slices of slices are wrong</summary>
      <description>FLINK-8588 introduced memory segment offsets but the offsets of slices of slices do not account for their parent's slice offset.</description>
      <version>None</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.buffer.ReadOnlySlicedBufferTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.buffer.ReadOnlySlicedNetworkBuffer.java</file>
    </fixedFiles>
  </bug>
  <bug id="8738" opendate="2018-2-21 00:00:00" fixdate="2018-2-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Converge runtime dependency versions for &amp;#39;scala-lang&amp;#39; and for &amp;#39;com.typesafe:config&amp;#39;</summary>
      <description>These dependencies are currently diverged:Dependency convergence error for com.typesafe:config:1.3.0 paths to dependency are:+-com.daplatform.flink:txn-api:1.0-SNAPSHOT +-org.apache.flink:flink-streaming-java_2.11:1.5-SNAPSHOT +-org.apache.flink:flink-runtime_2.11:1.5-SNAPSHOT +-com.typesafe.akka:akka-actor_2.11:2.4.20 +-com.typesafe:config:1.3.0and+-com.daplatform.flink:txn-api:1.0-SNAPSHOT +-org.apache.flink:flink-streaming-java_2.11:1.5-SNAPSHOT +-org.apache.flink:flink-runtime_2.11:1.5-SNAPSHOT +-com.typesafe.akka:akka-stream_2.11:2.4.20 +-com.typesafe:ssl-config-core_2.11:0.2.1 +-com.typesafe:config:1.2.0andDependency convergence error for org.scala-lang:scala-library:2.11.12 paths to dependency are:+-com.daplatform.flink:txn-api:1.0-SNAPSHOT +-org.apache.flink:flink-streaming-java_2.11:1.5-SNAPSHOT +-org.apache.flink:flink-runtime_2.11:1.5-SNAPSHOT +-org.scala-lang:scala-library:2.11.12and+-com.daplatform.flink:txn-api:1.0-SNAPSHOT +-org.apache.flink:flink-streaming-java_2.11:1.5-SNAPSHOT +-org.apache.flink:flink-runtime_2.11:1.5-SNAPSHOT +-com.typesafe.akka:akka-actor_2.11:2.4.20 +-org.scala-lang:scala-library:2.11.11and+-com.daplatform.flink:txn-api:1.0-SNAPSHOT +-org.apache.flink:flink-streaming-java_2.11:1.5-SNAPSHOT +-org.apache.flink:flink-runtime_2.11:1.5-SNAPSHOT +-com.typesafe.akka:akka-actor_2.11:2.4.20 +-org.scala-lang.modules:scala-java8-compat_2.11:0.7.0 +-org.scala-lang:scala-library:2.11.7and+-com.daplatform.flink:txn-api:1.0-SNAPSHOT +-org.apache.flink:flink-streaming-java_2.11:1.5-SNAPSHOT +-org.apache.flink:flink-runtime_2.11:1.5-SNAPSHOT +-com.typesafe.akka:akka-stream_2.11:2.4.20 +-org.scala-lang:scala-library:2.11.11and+-com.daplatform.flink:txn-api:1.0-SNAPSHOT +-org.apache.flink:flink-streaming-java_2.11:1.5-SNAPSHOT +-org.apache.flink:flink-runtime_2.11:1.5-SNAPSHOT +-com.typesafe.akka:akka-stream_2.11:2.4.20 +-com.typesafe:ssl-config-core_2.11:0.2.1 +-org.scala-lang:scala-library:2.11.8and+-com.daplatform.flink:txn-api:1.0-SNAPSHOT +-org.apache.flink:flink-streaming-java_2.11:1.5-SNAPSHOT +-org.apache.flink:flink-runtime_2.11:1.5-SNAPSHOT +-com.typesafe.akka:akka-stream_2.11:2.4.20 +-com.typesafe:ssl-config-core_2.11:0.2.1 +-org.scala-lang.modules:scala-parser-combinators_2.11:1.0.4 +-org.scala-lang:scala-library:2.11.6and+-com.daplatform.flink:txn-api:1.0-SNAPSHOT +-org.apache.flink:flink-streaming-java_2.11:1.5-SNAPSHOT +-org.apache.flink:flink-runtime_2.11:1.5-SNAPSHOT +-com.typesafe.akka:akka-protobuf_2.11:2.4.20 +-org.scala-lang:scala-library:2.11.11and+-com.daplatform.flink:txn-api:1.0-SNAPSHOT +-org.apache.flink:flink-streaming-java_2.11:1.5-SNAPSHOT +-org.apache.flink:flink-runtime_2.11:1.5-SNAPSHOT +-com.typesafe.akka:akka-slf4j_2.11:2.4.20 +-org.scala-lang:scala-library:2.11.11and+-com.daplatform.flink:txn-api:1.0-SNAPSHOT +-org.apache.flink:flink-streaming-java_2.11:1.5-SNAPSHOT +-org.apache.flink:flink-runtime_2.11:1.5-SNAPSHOT +-org.clapper:grizzled-slf4j_2.11:1.0.2 +-org.scala-lang:scala-library:2.11.0and+-com.daplatform.flink:txn-api:1.0-SNAPSHOT +-org.apache.flink:flink-streaming-java_2.11:1.5-SNAPSHOT +-org.apache.flink:flink-runtime_2.11:1.5-SNAPSHOT +-com.twitter:chill_2.11:0.7.4 +-org.scala-lang:scala-library:2.11.7</description>
      <version>None</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8739" opendate="2018-2-21 00:00:00" fixdate="2018-1-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Optimize runtime support for distinct filter</summary>
      <description>Possible optimizaitons:1. Decouple distinct map and actual accumulator so that they can separately be created in codegen.2. Reuse same distinct accumulator for filtering, e.g. `SELECT COUNT(DISTINCT(a)), SUM(DISTINCT(a))` should reuse the same distinct map.</description>
      <version>None</version>
      <fixedVersion>1.8.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.stream.table.AggregateITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.stream.sql.SqlITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.stream.sql.OverWindowITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.harness.HarnessTestBase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.harness.GroupAggregateHarnessTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.table.runtime.utils.JavaUserDefinedAggFunctions.java</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.aggregate.AggregateUtil.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.utils.UserDefinedFunctionUtils.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.aggfunctions.DistinctAccumulator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.MatchCodeGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.AggregationCodeGenerator.scala</file>
    </fixedFiles>
  </bug>
  <bug id="8897" opendate="2018-3-8 00:00:00" fixdate="2018-11-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Rowtime materialization causes "mismatched type" AssertionError</summary>
      <description>As raised in this thread, the query created by the following code will throw a calcite "mismatch type" (Timestamp(3) and TimeIndicator) exception.String sql1 = "select id, eventTs as t1, count(*) over (partition by id order by eventTs rows between 100 preceding and current row) as cnt1 from myTable1";String sql2 = "select distinct id as r_id, eventTs as t2, count(*) over (partition by id order by eventTs rows between 50 preceding and current row) as cnt2 from myTable2";Table left = tableEnv.sqlQuery(sql1);Table right = tableEnv.sqlQuery(sql2);left.join(right).where("id === r_id &amp;&amp; t1 === t2").select("id, t1").writeToSink(...)The logical plan is as follows.LogicalProject(id=[$0], t1=[$1]) LogicalFilter(condition=[AND(=($0, $3), =($1, $4))]) LogicalJoin(condition=[true], joinType=[inner]) LogicalAggregate(group=[{0, 1, 2}]) LogicalWindow(window#0=[window(partition {0} order by [1] rows between $2 PRECEDING and CURRENT ROW aggs [COUNT()])]) LogicalProject(id=[$0], eventTs=[$3]) LogicalTableScan(table=[[_DataStreamTable_0]]) LogicalAggregate(group=[{0, 1, 2}]) LogicalWindow(window#0=[window(partition {0} order by [1] rows between $2 PRECEDING and CURRENT ROW aggs [COUNT()])]) LogicalProject(id=[$0], eventTs=[$3]) LogicalTableScan(table=[[_DataStreamTable_0]])That is because the the rowtime field after an aggregation will be materialized while the RexInputRef type for the filter's operands (t1 === t2) is still TimeIndicator. We should make them unified.</description>
      <version>None</version>
      <fixedVersion>1.7.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.stream.TimeAttributesITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.plan.TimeIndicatorConversionTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.stream.table.JoinTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.stream.sql.JoinTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.join.WindowJoinUtil.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.rules.datastream.DataStreamWindowJoinRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.rules.datastream.DataStreamJoinRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.calcite.RelTimeIndicatorConverter.scala</file>
    </fixedFiles>
  </bug>
  <bug id="9103" opendate="2018-3-28 00:00:00" fixdate="2018-4-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>SSL verification on TaskManager when parallelism &gt; 1</summary>
      <description>In dynamic environments like Kubernetes, the SSL certificates can be generated to use only the DNS addresses for validation of the identity of servers, given that the IP can change eventually. In this cases when executing Jobs with Parallelism set to 1, the SSL validations are good and the Jobmanager can communicate with Task manager and vice versa. But with parallelism set to more than 1, SSL validation fails when Task Managers communicate to each other as it seems to try to validate against IP address:Caused by: java.security.cert.CertificateException: No subject alternative names matching IP address 172.xx.xxx.xxx found at sun.security.util.HostnameChecker.matchIP(HostnameChecker.java:168) at sun.security.util.HostnameChecker.match(HostnameChecker.java:94) at sun.security.ssl.X509TrustManagerImpl.checkIdentity(X509TrustManagerImpl.java:455) at sun.security.ssl.X509TrustManagerImpl.checkIdentity(X509TrustManagerImpl.java:436) at sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:252) at sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:136) at sun.security.ssl.ClientHandshaker.serverCertificate(ClientHandshaker.java:1601) ... 21 more  From the logs, it seems the task managers register successfully its full address to Netty, but still the IP is used. Attached pertinent logs from JobManager and a TaskManager. </description>
      <version>1.4.0</version>
      <fixedVersion>1.4.3,1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.netty.NettyClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="9107" opendate="2018-3-29 00:00:00" fixdate="2018-4-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document timer coalescing for ProcessFunctions</summary>
      <description>In a ProcessFunction, registering timers for each event via ctx.timerService().registerEventTimeTimer() using times like ctx.timestamp() + timeout will get a millisecond accuracy and may thus create one timer per millisecond which may lead to some overhead in the TimerService.This problem can be mitigated by using timer coalescing if the desired accuracy of the timer can be larger than 1ms. A timer firing at full seconds only, for example, can be realised like this:coalescedTime = ((ctx.timestamp() + timeout) / 1000) * 1000;ctx.timerService().registerEventTimeTimer(coalescedTime);As a result, only a single timer may exist for every second since we do not add timers for timestamps that are already there.This should be documented in the ProcessFunction docs.</description>
      <version>1.3.0,1.4.0,1.5.0,1.6.0</version>
      <fixedVersion>1.4.3,1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.dev.stream.operators.process.function.md</file>
    </fixedFiles>
  </bug>
  <bug id="9108" opendate="2018-3-29 00:00:00" fixdate="2018-4-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>invalid ProcessWindowFunction link in Document</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.dev.stream.side.output.md</file>
    </fixedFiles>
  </bug>
  <bug id="9274" opendate="2018-4-30 00:00:00" fixdate="2018-5-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add thread name to Kafka Partition Discovery</summary>
      <description>For debugging, threads should have names to filter on and get a quick overview. The Kafka partition discovery thread(s) currently don't have any name assigned.</description>
      <version>1.4.0,1.4.1,1.4.2,1.5.0,1.6.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="9275" opendate="2018-4-30 00:00:00" fixdate="2018-5-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Set more distinctive output flusher thread names</summary>
      <description>All output flusher threads are named "OutputFlusher" while at the only place the StreamWriter is initialized, we already have the task name at hand.</description>
      <version>1.4.0,1.4.1,1.4.2,1.5.0,1.6.0</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.StreamRecordWriter.java</file>
    </fixedFiles>
  </bug>
  <bug id="9306" opendate="2018-5-7 00:00:00" fixdate="2018-5-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Execute YARN IT tests for legacy and new mode</summary>
      <description>Currently, we are not executing the YARN IT cases for legacy mode.I opened a PR that changes that but it's currently failing on one of the tests in legacy mode: https://github.com/apache/flink/pull/5953</description>
      <version>None</version>
      <fixedVersion>1.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn-tests.src.test.java.org.apache.flink.yarn.YarnTestBase.java</file>
      <file type="M">flink-yarn-tests.src.test.java.org.apache.flink.yarn.YARNSessionFIFOSecuredITCase.java</file>
      <file type="M">flink-yarn-tests.src.test.java.org.apache.flink.yarn.YARNSessionFIFOITCase.java</file>
      <file type="M">flink-yarn-tests.src.test.java.org.apache.flink.yarn.YARNSessionCapacitySchedulerITCase.java</file>
    </fixedFiles>
  </bug>
  <bug id="9349" opendate="2018-5-13 00:00:00" fixdate="2018-5-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>KafkaConnector Exception while fetching from multiple kafka topics</summary>
      <description>./flink-connectors/flink-connector-kafka-0.9/src/main/java/org/apache/flink/streaming/connectors/kafka/internal/Kafka09Fetcher.java It seems the List subscribedPartitionStates was being modified when runFetchLoop iterated the List.This can happen if, e.g., FlinkKafkaConsumer runs the following code concurrently:                kafkaFetcher.addDiscoveredPartitions(discoveredPartitions);  java.util.ConcurrentModificationException at java.util.LinkedList$ListItr.checkForComodification(LinkedList.java:966) at java.util.LinkedList$ListItr.next(LinkedList.java:888) at org.apache.flink.streaming.connectors.kafka.internal.Kafka09Fetcher.runFetchLoop(Kafka09Fetcher.java:134)</description>
      <version>1.4.0</version>
      <fixedVersion>1.4.3,1.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.testutils.TestSourceContext.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcherTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.java</file>
    </fixedFiles>
  </bug>
  <bug id="9463" opendate="2018-5-29 00:00:00" fixdate="2018-6-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Setting taskmanager.network.netty.transport to epoll</summary>
      <description>https://github.com/apache/flink-shaded/issues/30 </description>
      <version>1.4.0,1.4.1,1.4.2,1.5.0</version>
      <fixedVersion>1.6.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.ExceptionUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="9793" opendate="2018-7-10 00:00:00" fixdate="2018-7-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>When submitting a flink job with yarn-cluster, flink-dist*.jar is repeatedly uploaded</summary>
      <description>We are using flink1.4.2 in our company. When the flink job is submitted to run on yarn with yarn-cluster mode，we actually find that the flink-dist_2.11-1.4.2.jar is uploaded to HDFS. The jars lies in different directories e.g.,1..flink/application_1525941455002_539197/flink-dist_2.11-1.4.2.jar2..flink/application_1525941455002_539197/lib/flink-dist_2.11-1.4.2.jarThrough reviewing source code of flink and having some tests, we suppose that the code below may have a bug in the Linux environment.java.nio.file.Path file!(file.getFileName().startsWith("flink-dist") &amp;&amp;file.getFileName().endsWith("jar")) is Always be true</description>
      <version>1.4.0,1.5.0</version>
      <fixedVersion>1.4.3,1.5.2,1.6.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.AbstractYarnClusterDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="9990" opendate="2018-7-29 00:00:00" fixdate="2018-10-29 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Add regexp_extract supported in TableAPI and SQL</summary>
      <description>regex_extract is a very useful function, it returns a string based on a regex pattern and a index.For example : regexp_extract('foothebar', 'foo(.*?)(bar)', 2) // returns 'bar.'It is provided as a UDF in Hive, more details please see&amp;#91;1&amp;#93;.&amp;#91;1&amp;#93;: https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.SqlExpressionTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.validate.FunctionCatalog.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.functions.ScalarFunctions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.sql.ScalarSqlFunctions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.stringExpressions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.calls.FunctionGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.calls.BuiltInMethods.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.scala.expressionDsl.scala</file>
      <file type="M">docs.dev.table.functions.md</file>
    </fixedFiles>
  </bug>
  <bug id="9991" opendate="2018-7-29 00:00:00" fixdate="2018-9-29 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Add regexp_replace supported in TableAPI and SQL</summary>
      <description>regexp_replace is a very userful function to process String. For example :regexp_replace("foobar", "oo|ar", "") //returns 'fb.'It is supported as a UDF in Hive, more details please see&amp;#91;1&amp;#93;.&amp;#91;1&amp;#93;: https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF </description>
      <version>None</version>
      <fixedVersion>1.7.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.SqlExpressionTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.expressions.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.validate.FunctionCatalog.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.runtime.functions.ScalarFunctions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.functions.sql.ScalarSqlFunctions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.expressions.stringExpressions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.calls.FunctionGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.codegen.calls.BuiltInMethods.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.scala.expressionDsl.scala</file>
      <file type="M">docs.dev.table.functions.md</file>
    </fixedFiles>
  </bug>
</bugrepository>
