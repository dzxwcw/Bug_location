<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="FLINK">
  <bug id="3138" opendate="2015-12-7 00:00:00" fixdate="2015-8-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Method References are not supported as lambda expressions</summary>
      <description>For many functions (here for example KeySelectors), one can use lambda expressions:DataStream&lt;MyType&gt; stream = ...;stream.keyBy( v -&gt; v.getId() )Java's other syntax for this, Method References, do not work:DataStream&lt;MyType&gt; stream = ...;stream.keyBy( MyType::getId )</description>
      <version>0.10.2</version>
      <fixedVersion>1.0.0,1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-java8.src.test.java.org.apache.flink.test.javaApiOperators.lambdas.MapITCase.java</file>
      <file type="M">flink-java8.src.test.java.org.apache.flink.api.java.type.lambdas.LambdaExtractionTest.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.TypeExtractor.java</file>
    </fixedFiles>
  </bug>
  <bug id="3421" opendate="2016-2-16 00:00:00" fixdate="2016-2-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove all unused ClassTag context bounds in the Streaming Scala API</summary>
      <description>Many methods have a ClassTag as a context bound, but they are never used / needed.The same information as can be drawn from a ClassTag should also be available in the TypeInformation.</description>
      <version>0.10.2</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.WindowedStream.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.StreamExecutionEnvironment.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.KeyedStream.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.JoinedStreams.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.DataStream.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.ConnectedStreams.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.CoGroupedStreams.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.AllWindowedStream.scala</file>
    </fixedFiles>
  </bug>
  <bug id="3435" opendate="2016-2-17 00:00:00" fixdate="2016-2-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change interplay of Ingestion Time and Event Time</summary>
      <description>Currently, "EventTime" and "IngestionTime" are completely the same.For both happens the following: Sources generate ingestion time timestamps and watermarks If a user adds a manual timestamp extractor / watermark generator, then those override the ingestion time timestamps and watermarks That implies that event time on a certain input falls back to ingestion time, if one forgets (or incorrectly uses) the timestamp extractors Also, Ingestion Time and Event Time simply mix if some inputs have timestamp assigners, and others have not.This behavior is quite tricky to understand. After some discussions with aljoscha and rmetzger, we suggest to change it the following way. 1. On Ingestion Time, the timestamps and watermarks are generated as they are now. 2. On event time, no default timestamps and watermarks are generated. If a user does not implement a timestamp extractor / watermark generator, then the event time operations will fail fast. 3. If one wants to use ingestion time on event time settings (mix), one can use an explicit "WallClockTimetampsAndWatermark" generator. 4. Later, the "Ingestion Time" settings should automatically disable and user-defined timestamp extractors / assigners.</description>
      <version>0.10.2</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.functions.source.FileMonitoringFunctionTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.EventTimeWindowCheckpointingITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.EventTimeAllWindowCheckpointingITCase.java</file>
      <file type="M">flink-streaming-scala.src.test.scala.org.apache.flink.streaming.api.scala.WindowFoldITCase.scala</file>
      <file type="M">flink-streaming-scala.src.test.scala.org.apache.flink.streaming.api.scala.CoGroupJoinITCase.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.DataStream.scala</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.SourceFunctionUtil.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.MockOutput.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.timestamp.TimestampITCase.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskTimerITCase.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.streamrecord.StreamRecordSerializerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.WindowFoldITCase.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.CoGroupJoinITCase.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.TimestampsAndPunctuatedWatermarksOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.TimestampsAndPeriodicWatermarksOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.graph.StreamingJobGraphGeneratorTest.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.wrappers.BoltWrapper.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.wrappers.MergedInputsBoltWrapper.java</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.wrappers.BoltWrapperTest.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.ExecutionConfig.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.java.org.apache.flink.streaming.examples.join.WindowJoin.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.java.org.apache.flink.streaming.examples.ml.IncrementalLearningSkeleton.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.java.org.apache.flink.streaming.examples.windowing.SessionWindowing.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.java.org.apache.flink.streaming.examples.windowing.TopSpeedWindowing.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.scala.org.apache.flink.streaming.scala.examples.join.WindowJoin.scala</file>
      <file type="M">flink-libraries.flink-cep.src.test.java.org.apache.flink.cep.CEPITCase.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer08.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer09.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.DataStream.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.AscendingTimestampExtractor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.AssignerWithPeriodicWatermarks.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.AssignerWithPunctuatedWatermarks.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.EventTimeSourceFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.RichEventTimeSourceFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.SourceFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.TimestampAssigner.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamConfig.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamGraph.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.co.CoStreamFlatMap.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamFlatMap.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamSource.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.TimestampedCollector.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.TimeCharacteristic.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.assigners.SlidingTimeWindows.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.assigners.TumblingTimeWindows.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.assigners.WindowAssigner.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.TimestampsAndPeriodicWatermarksOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.TimestampsAndPunctuatedWatermarksOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.AbstractAlignedProcessingTimeWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.EvictingNonKeyedWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.EvictingWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.NonKeyedWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.streamrecord.MultiplexingStreamRecordSerializer.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.streamrecord.StreamRecord.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.streamrecord.StreamRecordSerializer.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.OperatorChain.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.SourceStreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamIterationHead.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.TwoInputStreamTask.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.CoStreamTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.functions.AscendingTimestampExtractorTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="3440" opendate="2016-2-18 00:00:00" fixdate="2016-2-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Kafka should also checkpoint partitions where no initial offset was retrieved</summary>
      <description>For the discussion, see here: http://apache-flink-user-mailing-list-archive.2336050.n4.nabble.com/Kafka-partition-alignment-for-event-time-td4782.html#a4998</description>
      <version>0.10.2</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka08ITCase.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.LegacyFetcher.java</file>
    </fixedFiles>
  </bug>
  <bug id="3475" opendate="2016-2-23 00:00:00" fixdate="2016-2-23 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>DISTINCT aggregate function support for SQL queries</summary>
      <description>DISTINCT aggregate function may be able to reuse the aggregate function instead of separate implementation, and let Flink runtime take care of duplicate records.</description>
      <version>None</version>
      <fixedVersion>1.3.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.scala.batch.sql.QueryDecorrelationTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.scala.batch.sql.AggregationsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.rules.FlinkRuleSets.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.rules.dataSet.DataSetAggregateWithNullValuesRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.rules.dataSet.DataSetAggregateRule.scala</file>
      <file type="M">docs.dev.table.api.md</file>
    </fixedFiles>
  </bug>
  <bug id="3477" opendate="2016-2-23 00:00:00" fixdate="2016-7-23 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Add hash-based combine strategy for ReduceFunction</summary>
      <description>This issue is about adding a hash-based combine strategy for ReduceFunctions.The interface of the reduce() method is as follows:public T reduce(T v1, T v2)Input type and output type are identical and the function returns only a single value. A Reduce function is incrementally applied to compute a final aggregated value. This allows to hold the preaggregated value in a hash-table and update it with each function call. The hash-based strategy requires special implementation of an in-memory hash table. The hash table should support in place updates of elements (if the updated value has the same size as the new value) but also appending updates with invalidation of the old value (if the binary length of the new value differs). The hash table needs to be able to evict and emit all elements if it runs out-of-memory.We should also add HASH and SORT compiler hints to DataSet.reduce() and Grouping.reduce() to allow users to pick the execution strategy.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.scala.org.apache.flink.api.scala.operators.ReduceITCase.scala</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.ReduceITCase.java</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.GroupedDataSet.scala</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.hash.MemoryHashTableTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.hash.HashTablePerformanceComparison.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.hash.CompactingHashTableTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.ReduceCombineDriver.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.hash.MutableHashTable.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.hash.CompactingHashTable.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.hash.AbstractMutableHashTable.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.hash.AbstractHashTableProber.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.GroupReduceCombineDriver.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.DriverStrategy.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.chaining.SynchronousChainedCombineDriver.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.chaining.GroupCombineChainedDriver.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.disk.RandomAccessInputView.java</file>
      <file type="M">flink-optimizer.src.test.java.org.apache.flink.optimizer.java.ReduceCompilationTest.java</file>
      <file type="M">flink-optimizer.src.main.java.org.apache.flink.optimizer.operators.ReduceProperties.java</file>
      <file type="M">flink-optimizer.src.main.java.org.apache.flink.optimizer.dag.ReduceNode.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.ReduceOperator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.MathUtils.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.ReduceOperatorBase.java</file>
      <file type="M">docs.apis.batch.index.md</file>
    </fixedFiles>
  </bug>
  <bug id="3503" opendate="2016-2-25 00:00:00" fixdate="2016-3-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ProjectJoinTransposeRule fails to push down project.</summary>
      <description>val ds1 = CollectionDataSets.getSmall3TupleDataSet(env).as('a, 'b, 'c) val ds2 = CollectionDataSets.get5TupleDataSet(env).as('d, 'e, 'f, 'g, 'h) val joinT = ds1.join(ds2).where('b === 'e).select('c, 'g)For this query, ProjectJoinTransposeRule should pushes a Project past a Join by splitting the projection into a projection on top of each child of the join.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.TranslationContext.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.schema.DataSetTable.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetUnion.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetSource.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetRel.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetJoin.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetCalc.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetAggregate.scala</file>
    </fixedFiles>
  </bug>
  <bug id="3504" opendate="2016-2-25 00:00:00" fixdate="2016-3-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Join fails while have expression inside join condition.</summary>
      <description>val ds1 = CollectionDataSets.get3TupleDataSet(env).as('a, 'b, 'c) val ds2 = CollectionDataSets.get5TupleDataSet(env).as('d, 'e, 'f, 'g, 'h) val joinT = ds1.join(ds2).filter('a + 3 === 'd).select('c, 'g)This query would throw exception:Caused by: org.apache.flink.api.table.TableException: Joins should have at least one equality condition at org.apache.flink.api.table.plan.rules.dataset.DataSetJoinRule.convert(DataSetJoinRule.scala:57) at org.apache.calcite.rel.convert.ConverterRule.onMatch(ConverterRule.java:116) at org.apache.calcite.plan.volcano.VolcanoRuleCall.onMatch(VolcanoRuleCall.java:228) ... 44 moreThere are 2 issues here: DataSetJoinRule does not support expression inside join condition. JoinPushExpressionsRulewould add a Project to calculate expression value before Join, so the join condition does not include expression any more, however, it's not returned after the logical optimization.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.table.test.JoinITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.logical.FlinkJoinRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.java.table.JavaBatchTranslator.scala</file>
    </fixedFiles>
  </bug>
  <bug id="3508" opendate="2016-2-25 00:00:00" fixdate="2016-2-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add more test cases to verify the rules of logical plan optimization</summary>
      <description>We have enabled many rules in logical plan optimization phase, more complicated test cases should be added to verify whether these rules actally work.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.table.test.SelectITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.table.test.JoinITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.table.test.GroupedAggregationsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.table.test.FilterITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.table.test.AggregationsITCase.scala</file>
    </fixedFiles>
  </bug>
  <bug id="3517" opendate="2016-2-25 00:00:00" fixdate="2016-3-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Number of job and task managers not checked in scripts</summary>
      <description>The start up scripts determine whether a job or task manager is running via a pids file. If a process, which is part of the pid file, is destroyed (for example on failure) outside of the scripts, a warning for multiple job managers are printed even though they are not running.</description>
      <version>None</version>
      <fixedVersion>1.0.0,1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-dist.src.main.flink-bin.bin.flink-daemon.sh</file>
    </fixedFiles>
  </bug>
  <bug id="3520" opendate="2016-2-26 00:00:00" fixdate="2016-2-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Periodic watermark operator should emit current watermark in close()</summary>
      <description>This makes sure that for bounded data sets with watermarks, the final elements get properly reflected in window results</description>
      <version>0.10.2</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.TimestampsAndPeriodicWatermarksOperator.java</file>
    </fixedFiles>
  </bug>
  <bug id="3526" opendate="2016-2-26 00:00:00" fixdate="2016-2-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ProcessingTime Window Assigner and Trigger are broken</summary>
      <description></description>
      <version>0.10.2</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.triggers.ProcessingTimeTrigger.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.assigners.TumblingProcessingTimeWindows.java</file>
    </fixedFiles>
  </bug>
  <bug id="3528" opendate="2016-2-26 00:00:00" fixdate="2016-2-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add Incremental Fold for Non-Keyed Window Operator</summary>
      <description>Right now, non-keyed fold does not have constant space requirements.</description>
      <version>None</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.EventTimeAllWindowCheckpointingITCase.java</file>
      <file type="M">flink-streaming-scala.src.test.scala.org.apache.flink.streaming.api.scala.AllWindowTranslationTest.scala</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.NonKeyedWindowOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.EvictingNonKeyedWindowOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.AllWindowTranslationTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.NonKeyedWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.EvictingNonKeyedWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.buffers.WindowBufferFactory.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.buffers.WindowBuffer.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.buffers.PreAggregatingHeapWindowBuffer.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.buffers.HeapWindowBuffer.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.buffers.EvictingWindowBuffer.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.AllWindowedStream.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.FoldFunction.java</file>
    </fixedFiles>
  </bug>
  <bug id="3529" opendate="2016-2-27 00:00:00" fixdate="2016-4-27 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Add pull request template</summary>
      <description>Add a template for pull requests, checking if prerequisites of opening a PR have been fulfilled.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">CONTRIBUTING.md</file>
    </fixedFiles>
  </bug>
</bugrepository>
