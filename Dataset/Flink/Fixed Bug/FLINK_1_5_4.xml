<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="FLINK">
  <bug id="10365" opendate="2018-9-18 00:00:00" fixdate="2018-9-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Consolidate shaded Hadoop classes for filesystems</summary>
      <description>We currently have have three bundled/shaded filesystem connectors that build on top of Hadoop's classes. More will probably come. Each of them re-builds the shaded Hadoop module, including creating the relocated config, adapting native code loading, etc.We should factor that out into a single base project to avoid duplicating work.</description>
      <version>None</version>
      <fixedVersion>1.7.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.maven.suppressions.xml</file>
      <file type="M">flink-filesystems.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="10366" opendate="2018-9-18 00:00:00" fixdate="2018-9-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create a shared base for S3 file systems</summary>
      <description>We are adding extensions to the FileSystem logic on top of what Hadoop offers, like entropy injection, recoverable writers.To be able to share the code across the Presto and Hadoop s3a implementations, we should rebase them both onto a common shared project.</description>
      <version>None</version>
      <fixedVersion>1.7.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-filesystems.flink-s3-fs-hadoop.src.test.resources.core-site.xml</file>
      <file type="M">flink-filesystems.flink-s3-fs-hadoop.src.test.java.org.apache.flink.fs.s3hadoop.HadoopS3FileSystemITCase.java</file>
      <file type="M">flink-filesystems.flink-s3-fs-hadoop.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-filesystems.flink-s3-fs-hadoop.src.main.resources.core-default-shaded.xml</file>
      <file type="M">flink-filesystems.flink-s3-fs-hadoop.src.main.java.org.apache.hadoop.util.NativeCodeLoader.java</file>
      <file type="M">flink-filesystems.flink-s3-fs-hadoop.src.main.java.org.apache.hadoop.conf.Configuration.java</file>
      <file type="M">flink-filesystems.flink-s3-fs-hadoop.pom.xml</file>
      <file type="M">tools.travis.mvn.watchdog.sh</file>
      <file type="M">flink-filesystems.flink-s3-fs-presto.src.test.java.org.apache.flink.fs.s3presto.PrestoS3FileSystemTest.java</file>
      <file type="M">flink-filesystems.flink-s3-fs-hadoop.src.test.java.org.apache.flink.fs.s3hadoop.HadoopS3FileSystemTest.java</file>
      <file type="M">flink-filesystems.flink-s3-fs-hadoop.src.main.java.org.apache.flink.fs.s3hadoop.S3FileSystemFactory.java</file>
      <file type="M">flink-filesystems.flink-s3-fs-base.pom.xml</file>
      <file type="M">flink-filesystems.flink-hadoop-fs.src.main.java.org.apache.flink.runtime.fs.hdfs.HadoopConfigLoader.java</file>
      <file type="M">flink-filesystems.flink-hadoop-fs.src.main.java.org.apache.flink.runtime.fs.hdfs.AbstractFileSystemFactory.java</file>
      <file type="M">flink-filesystems.flink-s3-fs-presto.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-filesystems.flink-s3-fs-presto.src.main.resources.core-default-shaded.xml</file>
      <file type="M">flink-filesystems.flink-s3-fs-presto.src.main.java.org.apache.hadoop.util.NativeCodeLoader.java</file>
      <file type="M">flink-filesystems.flink-s3-fs-presto.src.main.java.org.apache.hadoop.conf.Configuration.java</file>
      <file type="M">flink-filesystems.flink-s3-fs-presto.src.main.java.org.apache.flink.fs.s3presto.S3FileSystemFactory.java</file>
      <file type="M">flink-filesystems.flink-s3-fs-presto.pom.xml</file>
      <file type="M">flink-filesystems.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="10416" opendate="2018-9-25 00:00:00" fixdate="2018-9-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add files generated by jepsen tests to rat excludes</summary>
      <description>Currently jepsen generates some files that results in rat plugin failures.</description>
      <version>None</version>
      <fixedVersion>1.7.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="10613" opendate="2018-10-19 00:00:00" fixdate="2018-10-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove logger casts in HBaseConnectorITCase</summary>
      <description>During the testing of 1.5.5-rc1 an issue was discovered in the HBaseConnectorITCase where a cast could fail if flink-table tests were previously executed, since in this case the jcl-over-slf4j bridge is being loaded.Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=128m; support was removed in 8.0Running org.apache.flink.addons.hbase.HBaseConnectorITCaseTests run: 2, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 0.557 sec &lt;&lt;&lt; FAILURE! - in org.apache.flink.addons.hbase.HBaseConnectorITCaseorg.apache.flink.addons.hbase.HBaseConnectorITCase  Time elapsed: 0.556 sec  &lt;&lt;&lt; ERROR!java.lang.ClassCastException: org.apache.commons.logging.impl.SLF4JLocationAwareLog cannot be cast to org.apache.commons.logging.impl.Log4JLoggerorg.apache.flink.addons.hbase.HBaseConnectorITCase  Time elapsed: 0.557 sec  &lt;&lt;&lt; ERROR!java.lang.NullPointerExceptionWhile the logger-loading issue itself is rather subtle I believe the underlying issue to be the casts to set the log-level.It should be possible to enable said logging through the log4j-test.properties configuration instead.</description>
      <version>1.5.4</version>
      <fixedVersion>1.5.6,1.6.3,1.7.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-hbase.src.test.java.org.apache.flink.addons.hbase.HBaseTestingClusterAutostarter.java</file>
    </fixedFiles>
  </bug>
  <bug id="10638" opendate="2018-10-22 00:00:00" fixdate="2018-11-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Invalid table scan resolution for temporal join queries</summary>
      <description>Registered tables that contain a temporal join are not properly resolved when performing a table scan.A planning error occurs when registering a table with a temporal join and reading from it again.LogicalProject(amount=[*($0, $4)]) LogicalFilter(condition=[=($3, $1)]) LogicalCorrelate(correlation=[$cor0], joinType=[inner], requiredColumns=[{2}]) LogicalTableScan(table=[[_DataStreamTable_0]]) LogicalTableFunctionScan(invocation=[Rates(CAST($cor0.rowtime):TIMESTAMP(3) NOT NULL)], rowType=[RecordType(VARCHAR(65536) currency, BIGINT rate, TIME ATTRIBUTE(ROWTIME) rowtime)], elementType=[class [Ljava.lang.Object;])</description>
      <version>None</version>
      <fixedVersion>1.7.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.runtime.stream.sql.TemporalJoinITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.stream.table.TemporalTableJoinTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.table.api.stream.sql.TemporalTableJoinTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.rules.FlinkRuleSets.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.TableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.StreamTableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.api.BatchTableEnvironment.scala</file>
    </fixedFiles>
  </bug>
  <bug id="10690" opendate="2018-10-26 00:00:00" fixdate="2018-10-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Tests leak resources via Files.list</summary>
      <description>Files.list has the unfortunate property that is has to be explicitly closed to cleanup the underlying DirectoryStream. This is not done automatically by collectors.Several tests don't close the stream.</description>
      <version>1.5.4,1.6.1,1.7.0</version>
      <fixedVersion>1.5.6,1.6.3,1.7.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn.src.test.java.org.apache.flink.yarn.UtilsTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.ResumeCheckpointManuallyITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.runtime.jobmaster.JobMasterTriggerSavepointIT.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.MultipartUploadResource.java</file>
      <file type="M">flink-filesystems.flink-s3-fs-hadoop.src.test.java.org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterTest.java</file>
      <file type="M">flink-filesystems.flink-s3-fs-base.src.test.java.org.apache.flink.fs.s3.common.utils.RefCountedFileTest.java</file>
      <file type="M">flink-end-to-end-tests.flink-distributed-cache-via-blob-test.src.main.java.org.apache.flink.streaming.tests.DistributedCacheViaBlobTestProgram.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.util.FileUtilsTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="933" opendate="2014-6-12 00:00:00" fixdate="2014-11-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add an input format to read primitive types directly (not through tuples)</summary>
      <description>Right now, reading primitive types goes either through custom formats (work intensive), or through CSV inputs. The latter return tuples.To read a sequence of primitives, you need to go though Tuple1, which is clumsy.I would suggest to add an input format to read primitive types line wise (or otherwise delimited), and also add a method to the environment for that.</description>
      <version>None</version>
      <fixedVersion>0.8.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.ExecutionEnvironment.scala</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.ExecutionEnvironment.java</file>
    </fixedFiles>
  </bug>
</bugrepository>
