<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="FLINK">
  <bug id="3612" opendate="2016-3-14 00:00:00" fixdate="2016-3-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix/adjust Table API examples</summary>
      <description>The Table API examples are currently failing with different exceptions. We should check whether these signify bugs or whether we need to adjust the examples.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.table.test.AggregationsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.scala.table.test.PageRankTableITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.table.test.AggregationsITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.examples.scala.PageRankTable.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.java.org.apache.flink.examples.java.JavaTableExample.java</file>
    </fixedFiles>
  </bug>
  <bug id="3711" opendate="2016-4-7 00:00:00" fixdate="2016-4-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scala fold() example syntax incorrect</summary>
      <description>Scala's KeyedStream#fold which accepts scala.Function2 is defined as a partially appliable function. The documentation, however, is written as if it is a non-partial function.</description>
      <version>1.0.0,1.0.1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.apis.streaming.index.md</file>
    </fixedFiles>
  </bug>
  <bug id="3729" opendate="2016-4-11 00:00:00" fixdate="2016-7-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Several SQL tests fail on Windows OS</summary>
      <description>The Table API SqlExplain(Test/ITCase) fail categorically on Windows due to different line-endings. These tests generate an string representation of an abstract syntax tree; problem is there is a difference in line-endings.The expected ones contain LF, the actual one CRLF.The tests should be either changed to either include CRLF line-endings in the expected string when run on windows always use LF line-endings regardless of OS use a compare method that is aware of this issue.</description>
      <version>1.0.1</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.stream.TableSinkITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.TableSinkITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.ExplainTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.ExplainTest.java</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.BatchTableEnvironment.scala</file>
    </fixedFiles>
  </bug>
  <bug id="3761" opendate="2016-4-14 00:00:00" fixdate="2016-9-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Refactor State Backends/Make Keyed State Key-Group Aware</summary>
      <description>After an off-line discussion with aljoscha, we came to the conclusion that it would be beneficial to reflect the differences between a keyed and a non-keyed stream also in the state backends. A state backend which is used for a keyed stream offers a value, list, folding and value state and has to group its keys into key groups. A state backend for non-keyed streams can only offer a union state to make it work with dynamic scaling. A union state is a state which is broadcasted to all tasks in case of a recovery. The state backends can then select what information they need to recover from the whole state (formerly distributed).</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.filesystem.FsStateBackend.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.memory.MemCheckpointStreamFactory.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackend.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.runtime.StateBackendITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.state.StateHandleSerializationTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.classloading.jar.CustomKvStateProgram.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.classloading.ClassLoaderITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.EventTimeWindowCheckpointingITCase.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.WindowingTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.TestHarnessUtil.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.OneInputStreamOperatorTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.MockContext.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamMockEnvironment.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.OneInputStreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.InterruptSensitiveRestoreTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.WindowOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.EvictingWindowOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.AggregatingAlignedProcessingTimeWindowOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.AccumulatingAlignedProcessingTimeWindowOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.StreamOperatorChainingTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.StreamingRuntimeContextTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.StreamGroupedReduceTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.StreamGroupedFoldTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.AbstractAlignedProcessingTimeWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.GenericWriteAheadSink.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.AbstractStreamOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamGraphGenerator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.ContinuousFileReaderOperator.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskmanager.TaskTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskmanager.TaskManagerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskmanager.TaskAsyncCallTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.StateBackendTestBase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.MemoryStateBackendTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.filesystem.FsCheckpointStateOutputStreamTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.FileStateBackendTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.QueryableStateClientTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.netty.KvStateServerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.netty.KvStateServerHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.query.netty.KvStateClientTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.testutils.MockEnvironment.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.testutils.DummyEnvironment.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.groups.TaskManagerGroupTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.messages.CheckpointMessagesTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.deployment.TaskDeploymentDescriptorTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.checkpoint.savepoint.SavepointLoaderTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.StreamStateHandle.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.StateObject.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.RetrievableStreamStateHandle.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.memory.MemValueState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.memory.MemReducingState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.memory.MemoryStateBackend.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.memory.MemListState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.memory.MemFoldingState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.memory.ByteStreamStateHandle.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.memory.AbstractMemStateSnapshot.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.memory.AbstractMemState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.KvStateSnapshot.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.KvState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.KeyGroupRange.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.GenericReducingState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.GenericListState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.GenericFoldingState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.filesystem.FsValueState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.AbstractRocksDBState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBFoldingState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBListState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBReducingState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackend.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBValueState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.FullyAsyncRocksDBStateBackendTest.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBAsyncKVSnapshotTest.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackendConfigTest.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackendTest.java</file>
      <file type="M">flink-contrib.flink-storm-examples.src.test.java.org.apache.flink.storm.tests.StormFieldsGroupingITCase.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.wrappers.BoltWrapper.java</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.wrappers.BoltWrapperTest.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.CollectionExecutor.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.TaskInfo.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.FSDataOutputStream.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.local.LocalDataOutputStream.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.functions.util.RuntimeUDFContextTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.io.RichInputFormatTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.io.RichOutputFormatTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.operators.base.FlatMapOperatorCollectionTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.operators.base.InnerJoinOperatorBaseTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.operators.base.MapOperatorTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.operators.base.PartitionMapOperatorTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.operators.GenericDataSinkBaseTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.operators.GenericDataSourceBaseTest.java</file>
      <file type="M">flink-fs-tests.src.test.java.org.apache.flink.hdfstests.FileStateBackendTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.common.operators.base.CoGroupOperatorCollectionTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.common.operators.base.GroupReduceOperatorTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.common.operators.base.InnerJoinOperatorBaseTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.common.operators.base.ReduceOperatorTest.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.nfa.NFA.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.operator.AbstractKeyedCEPPatternOperator.java</file>
      <file type="M">flink-libraries.flink-cep.src.test.java.org.apache.flink.cep.operator.CEPOperatorTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.CheckpointCoordinator.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.deployment.TaskDeploymentDescriptor.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.ExecutionVertex.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.fs.hdfs.HadoopDataOutputStream.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.KvStateRegistry.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.netty.KvStateServerHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.query.TaskKvStateRegistry.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.AbstractHeapState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.AbstractStateBackend.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.AsynchronousKvStateSnapshot.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.filesystem.AbstractFsState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.filesystem.AbstractFsStateSnapshot.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.filesystem.FileStateHandle.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.filesystem.FsFoldingState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.filesystem.FsListState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.filesystem.FsReducingState.java</file>
    </fixedFiles>
  </bug>
  <bug id="3763" opendate="2016-4-15 00:00:00" fixdate="2016-6-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RabbitMQ Source/Sink standardize connection parameters</summary>
      <description>The RabbitMQ source and sink should have the same capabilities in terms of establishing a connection, currently the sink is lacking connection parameters that are available on the source. Additionally, VirtualHost should be an offered parameter for multi-tenant RabbitMQ clusters (if not specified it goes to the vhost '/').Connection Parameters=================== Host - Offered on both Port - Source only Virtual Host - Neither User - Source only Password - Source onlyAdditionally, it might be worth offer the URI as a valid constructor because that would offer all 5 of the above parameters in a single String.</description>
      <version>1.0.1</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-connectors.flink-connector-rabbitmq.src.test.java.org.apache.flink.streaming.connectors.rabbitmq.RMQSourceTest.java</file>
      <file type="M">docs.apis.streaming.connectors.rabbitmq.md</file>
      <file type="M">flink-streaming-connectors.flink-connector-rabbitmq.src.main.java.org.apache.flink.streaming.connectors.rabbitmq.RMQSource.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-rabbitmq.src.main.java.org.apache.flink.streaming.connectors.rabbitmq.RMQSink.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-rabbitmq.src.main.java.org.apache.flink.streaming.connectors.rabbitmq.common.RMQConnectionConfig.java</file>
    </fixedFiles>
  </bug>
  <bug id="3764" opendate="2016-4-15 00:00:00" fixdate="2016-4-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LeaderChangeStateCleanupTest.testStateCleanupAfterListenerNotification fails on Travis</summary>
      <description>The LeaderChangeStateCleanupTest.testStateCleanupAfterListenerNotification fails spuriously on Travis because of a NullPointerException. The reason is that it's not properly waited until the ResourceManager has been started. Due to this, it can happen that a leader notification message is tried to be sent to a LeaderRetrievalListener which has not been set by the ResourceManager.&amp;#91;1&amp;#93; https://s3.amazonaws.com/archive.travis-ci.org/jobs/123271732/log.txt</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.scala.org.apache.flink.runtime.testingUtils.TestingCluster.scala</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.testutils.TestingResourceManager.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.leaderelection.TestingLeaderRetrievalService.java</file>
    </fixedFiles>
  </bug>
  <bug id="377" opendate="2014-6-9 00:00:00" fixdate="2014-4-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create a general purpose framework for language bindings</summary>
      <description>A general purpose API to run operators with arbitrary binaries. This will allow to run Stratosphere programs written in Python, JavaScript, Ruby, Go or whatever you like. We suggest using Google Protocol Buffers for data serialization. This is the list of languages that currently support ProtoBuf: https://code.google.com/p/protobuf/wiki/ThirdPartyAddOns Very early prototype with python: https://github.com/rmetzger/scratch/tree/learn-protobuf (basically testing protobuf)For Ruby: https://github.com/infochimps-labs/wukongTwo new students working at Stratosphere (@skunert and @filiphaase) are working on this.The reference binding language will be for Python, but other bindings are very welcome.The best name for this so far is "stratosphere-lang-bindings".I created this issue to track the progress (and give everybody a chance to comment on this)---------------- Imported from GitHub ----------------Url: https://github.com/stratosphere/stratosphere/issues/377Created by: rmetzgerLabels: enhancement, Assignee: filiphaaseCreated at: Tue Jan 07 19:47:20 CET 2014State: open</description>
      <version>None</version>
      <fixedVersion>pre-apache</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-staging.pom.xml</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.DriverStrategy.java</file>
      <file type="M">flink-optimizer.src.main.java.org.apache.flink.optimizer.traversals.GraphCreatingVisitor.java</file>
      <file type="M">flink-optimizer.src.main.java.org.apache.flink.optimizer.costs.CostEstimator.java</file>
      <file type="M">flink-dist.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="3782" opendate="2016-4-18 00:00:00" fixdate="2016-5-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ByteArrayOutputStream and ObjectOutputStream should close</summary>
      <description>ByteArrayOutputStream and ObjectOutputStream should close@Test public void testSerializability() { try { Collection&lt;ElementType&gt; inputCollection = new ArrayList&lt;ElementType&gt;(); ElementType element1 = new ElementType(1); ElementType element2 = new ElementType(2); ElementType element3 = new ElementType(3); inputCollection.add(element1); inputCollection.add(element2); inputCollection.add(element3); @SuppressWarnings("unchecked") TypeInformation&lt;ElementType&gt; info = (TypeInformation&lt;ElementType&gt;) TypeExtractor.createTypeInfo(ElementType.class); CollectionInputFormat&lt;ElementType&gt; inputFormat = new CollectionInputFormat&lt;ElementType&gt;(inputCollection, info.createSerializer(new ExecutionConfig())); ByteArrayOutputStream buffer = new ByteArrayOutputStream();// &lt;----open in here ObjectOutputStream out = new ObjectOutputStream(buffer);// &lt;----open in here out.writeObject(inputFormat); ObjectInputStream in = new ObjectInputStream(new ByteArrayInputStream(buffer.toByteArray())); // &lt;----open in here Object serializationResult = in.readObject(); assertNotNull(serializationResult); assertTrue(serializationResult instanceof CollectionInputFormat&lt;?&gt;); @SuppressWarnings("unchecked") CollectionInputFormat&lt;ElementType&gt; result = (CollectionInputFormat&lt;ElementType&gt;) serializationResult; GenericInputSplit inputSplit = new GenericInputSplit(0, 1); inputFormat.open(inputSplit); result.open(inputSplit); while(!inputFormat.reachedEnd() &amp;&amp; !result.reachedEnd()){ ElementType expectedElement = inputFormat.nextRecord(null); ElementType actualElement = result.nextRecord(null); assertEquals(expectedElement, actualElement); } } catch(Exception e) { e.printStackTrace(); fail(e.toString()); } }</description>
      <version>1.0.1</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.io.CollectionInputFormatTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="3840" opendate="2016-4-28 00:00:00" fixdate="2016-4-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RocksDB local parent dir is polluted with empty folders with random names</summary>
      <description>For some reason when the job starts the rocksdb root dir filled with hundreds of empty folders with random names like:041da1c-5fec-42ed-a69c-298240f1a065 4e6061aa-0c69-4755-a1ad-5ac4dec1d3f0 a7004bd1-778c-4a0f-96d4-9941208d188800db8406-6cb4-46ad-aac9-beeaa3247d16</description>
      <version>1.0.0,1.0.1,1.0.2,1.1.0</version>
      <fixedVersion>1.0.3,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackend.java</file>
    </fixedFiles>
  </bug>
  <bug id="3916" opendate="2016-5-17 00:00:00" fixdate="2016-7-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow generic types passing the Table API</summary>
      <description>The Table API currently only supports BasicTypes that can pass the Table API. Other types should also be supported but treated as black boxes.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.expressions.utils.ExpressionTestBase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.stream.sql.SqlITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.FromDataSetITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.typeutils.TypeConverter.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.typeutils.TypeCheckUtils.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.TableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.table.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.StreamTableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.aggregate.AggregateUtil.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.schema.FlinkTable.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.schema.DataStreamTable.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.logical.operators.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.FlinkPlannerImpl.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.literals.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.cast.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.CodeGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.BatchTableEnvironment.scala</file>
    </fixedFiles>
  </bug>
  <bug id="4150" opendate="2016-7-4 00:00:00" fixdate="2016-7-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Problem with Blobstore in Yarn HA setting on recovery after cluster shutdown</summary>
      <description>Submitting a job in Yarn with HA can lead to the following exception:org.apache.flink.streaming.runtime.tasks.StreamTaskException: Cannot load user class: org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer09ClassLoader info: URL ClassLoader: file: '/tmp/blobStore-ccec0f4a-3e07-455f-945b-4fcd08f5bac1/cache/blob_7fafffe9595cd06aff213b81b5da7b1682e1d6b0' (invalid JAR: zip file is empty)Class not resolvable through given classloader. at org.apache.flink.streaming.api.graph.StreamConfig.getStreamOperator(StreamConfig.java:207) at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:222) at org.apache.flink.runtime.taskmanager.Task.run(Task.java:588) at java.lang.Thread.run(Thread.java:745)Some job information, including the Blob ids, are stored in Zookeeper. The actual Blobs are stored in a dedicated BlobStore, if the recovery mode is set to Zookeeper. This BlobStore is typically located in a FS like HDFS. When the cluster is shut down, the path for the BlobStore is deleted. When the cluster is then restarted, recovering jobs cannot restore because it's Blob ids stored in Zookeeper now point to deleted files.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.leaderelection.TestingLeaderElectionService.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.execution.librarycache.BlobLibraryCacheRecoveryITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.blob.BlobRecoveryITCase.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.execution.librarycache.BlobLibraryCacheManager.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.FileSystemBlobStore.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobServerConnection.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="4151" opendate="2016-7-5 00:00:00" fixdate="2016-7-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Address Travis CI build time: We are exceeding the 2 hours limit</summary>
      <description>We've recently started hitting the two hours limit for Travis CI.I'll look into some approaches to get our build stable again.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">.travis.yml</file>
    </fixedFiles>
  </bug>
  <bug id="4169" opendate="2016-7-7 00:00:00" fixdate="2016-7-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CEP Does Not Work with RocksDB StateBackend</summary>
      <description>A job will never match any patterns because ValueState.update() is not called in the keyed CEP operators for updating the NFA state and the priority queue state.The reason why it works for other state backends is that they are very lax in their handling of state: if the object returned from ValueState.value()) is mutable changes to this will be reflected in checkpoints even if ValueState.update() is not called. RocksDB, on the other hand, does always deserialize/serialize state values when accessing/updating them, so changes to the returned object will not be reflected in the state unless update() is called.We should fix this and also add a test for it. This might be tricky because we have to pull together RocksDB and CEP.</description>
      <version>1.0.0,1.0.1,1.0.2,1.0.3,1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-cep.src.test.java.org.apache.flink.cep.operator.CEPOperatorTest.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.operator.AbstractKeyedCEPPatternOperator.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.operator.AbstractCEPPatternOperator.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.operator.AbstractCEPBasePatternOperator.java</file>
      <file type="M">flink-libraries.flink-cep.pom.xml</file>
    </fixedFiles>
  </bug>
</bugrepository>
