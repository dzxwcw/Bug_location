<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="FLINK">
  <bug id="3790" opendate="2016-4-20 00:00:00" fixdate="2016-4-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Rolling File sink does not pick up hadoop configuration</summary>
      <description>In the rolling file sink function, a new hadoop configuration is created to get the FileSystem every time, which completely ignores the hadoop config set in flink-conf.yaml</description>
      <version>1.0.2</version>
      <fixedVersion>1.0.3,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-connectors.flink-connector-filesystem.src.main.java.org.apache.flink.streaming.connectors.fs.SequenceFileWriter.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-filesystem.src.main.java.org.apache.flink.streaming.connectors.fs.RollingSink.java</file>
    </fixedFiles>
  </bug>
  <bug id="3835" opendate="2016-4-27 00:00:00" fixdate="2016-4-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>JSON execution plan not helpful to debug plans with KeySelectors</summary>
      <description>The JSON execution plans are not helpful when debugging plans that include join operators with key selectors. For joins with hash join strategy, the driver strategy shows: "Hybrid Hash (build: Key Extractor)" where (build: Key Extractor) shall help to identify the build side of the join. However, if both inputs use KeySelectors, the build side cannot be identified.I propose to add the operator id to the build side information. The same issue applied for cross driver strategies.</description>
      <version>1.0.2,1.1.0</version>
      <fixedVersion>1.0.3,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-optimizer.src.main.java.org.apache.flink.optimizer.plandump.PlanJSONDumpGenerator.java</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.resources.testJoin1.out</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.resources.testJoin0.out</file>
    </fixedFiles>
  </bug>
  <bug id="3837" opendate="2016-4-27 00:00:00" fixdate="2016-5-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create FLOOR/CEIL function</summary>
      <description>Create the FLOOR/CEIL function for Table API and SQL. They will later be extended in FLINK-3580 to support date and time.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.expression.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.call.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.TrimCallGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.ScalarFunctions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.scala.table.expressionDsl.scala</file>
    </fixedFiles>
  </bug>
  <bug id="3838" opendate="2016-4-27 00:00:00" fixdate="2016-6-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CLI parameter parser is munging application params</summary>
      <description>If parameters for an application use a single '-' (e.g. -maxtasks) then the CLI argument parser will munge these, and the app gets passed either just the parameter name (e.g. 'maxtask') if the start of the parameter doesn't match a Flink parameter, or you get two values, with the first value being the part that matched (e.g. '-m') and the second value being the rest (e.g. 'axtasks').The parser should ignore everything after the jar path parameter.Note that using --&lt;parameter name&gt; does seem to work.</description>
      <version>1.0.2,1.0.3</version>
      <fixedVersion>1.0.4,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-clients.src.test.java.org.apache.flink.client.CliFrontendRunTest.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.cli.CliFrontendParser.java</file>
    </fixedFiles>
  </bug>
  <bug id="3840" opendate="2016-4-28 00:00:00" fixdate="2016-4-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RocksDB local parent dir is polluted with empty folders with random names</summary>
      <description>For some reason when the job starts the rocksdb root dir filled with hundreds of empty folders with random names like:041da1c-5fec-42ed-a69c-298240f1a065 4e6061aa-0c69-4755-a1ad-5ac4dec1d3f0 a7004bd1-778c-4a0f-96d4-9941208d188800db8406-6cb4-46ad-aac9-beeaa3247d16</description>
      <version>1.0.0,1.0.1,1.0.2,1.1.0</version>
      <fixedVersion>1.0.3,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackend.java</file>
    </fixedFiles>
  </bug>
  <bug id="3859" opendate="2016-5-2 00:00:00" fixdate="2016-6-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add BigDecimal/BigInteger support to Table API</summary>
      <description>Since FLINK-3786 has been solved, we can now start integrating BigDecimal/BigInteger into the Table API.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.runtime.aggregate.SumAggregateTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.runtime.aggregate.MinAggregateTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.runtime.aggregate.MaxAggregateTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.runtime.aggregate.AvgAggregateTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.runtime.aggregate.AggregateTestBase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.expressions.utils.ExpressionEvaluator.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.expressions.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.ExpressionsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.sql.AggregationsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.typeutils.TypeConverter.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.typeutils.TypeCoercion.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.typeutils.TypeCheckUtils.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.TableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.aggregate.SumAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.aggregate.MinAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.aggregate.MaxAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.aggregate.AvgAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.aggregate.AggregateUtil.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetRel.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.literals.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.ExpressionParser.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.comparison.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.arithmetic.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.CodeGenUtils.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.CodeGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.ScalarOperators.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.ScalarFunctions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.FloorCeilCallGen.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.BuiltInMethods.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.scala.table.expressionDsl.scala</file>
      <file type="M">docs.apis.table.md</file>
    </fixedFiles>
  </bug>
  <bug id="386" opendate="2014-6-9 00:00:00" fixdate="2014-7-9 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Duplicate dependencies in lib folder</summary>
      <description>There are some dependencies for which two different versions end up in the lib folder```servlet-api-2.5-6.1.14.jarservlet-api-3.0.20100224.jarstax-api-1.0.1.jarstax-api-1.0-2.jar```As far as I see it, these are transitive dependencies.Teh problem is that what classes are available at runtime depends on which jar is loaded first by the classloader. This is somewhat unpredictable and can lead to weird errors in the components that have these dependencies. ---------------- Imported from GitHub ----------------Url: https://github.com/stratosphere/stratosphere/issues/386Created by: StephanEwenLabels: Created at: Thu Jan 09 19:44:07 CET 2014State: open</description>
      <version>None</version>
      <fixedVersion>pre-apache</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.CombineTaskExternalITCase.java</file>
      <file type="M">pom.xml</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.util.FailingTestBase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.javaApiOperators.MapITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.BulkIterationWithAllReducerITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.aggregators.ConnectedComponentsWithParametrizableAggregatorITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.iterative.aggregators.AggregatorsITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.cancelling.CancellingTestBase.java</file>
      <file type="M">flink-tests.pom.xml</file>
      <file type="M">flink-test-utils.pom.xml</file>
      <file type="M">flink-scala.pom.xml</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.util.RecordOutputEmitterTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.util.OutputEmitterTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.testutils.TaskCancelThread.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.testutils.DriverTestBase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.sort.ExternalSortITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.sort.CombiningUnilateralSortMergerITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.sort.AsynchonousPartialSorterITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.resettable.SpillingResettableMutableObjectIteratorTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.resettable.SpillingResettableIteratorTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.resettable.BlockResettableMutableObjectIteratorTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.resettable.BlockResettableIteratorTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.ReduceTaskTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.ReduceTaskExternalITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.MatchTaskExternalITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.DataSourceTaskTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.DataSinkTaskTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.CrossTaskTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.CrossTaskExternalITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.CombineTaskTest.java</file>
      <file type="M">flink-addons.flink-avro.pom.xml</file>
      <file type="M">flink-addons.flink-avro.src.test.java.org.apache.flink.api.java.record.io.avro.AvroRecordInputFormatTest.java</file>
      <file type="M">flink-addons.flink-jdbc.src.test.java.org.apache.flink.api.java.io.jdbc.JDBCInputFormatTest.java</file>
      <file type="M">flink-addons.flink-jdbc.src.test.java.org.apache.flink.api.java.io.jdbc.JDBCOutputFormatTest.java</file>
      <file type="M">flink-addons.flink-jdbc.src.test.java.org.apache.flink.api.java.record.io.jdbc.JDBCInputFormatTest.java</file>
      <file type="M">flink-addons.flink-jdbc.src.test.java.org.apache.flink.api.java.record.io.jdbc.JDBCOutputFormatTest.java</file>
      <file type="M">flink-clients.pom.xml</file>
      <file type="M">flink-compiler.src.test.java.org.apache.flink.compiler.DOPChangeTest.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.Configuration.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.io.FileOutputFormatTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.typeutils.SerializerTestBase.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.distributions.SimpleDataDistributionTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.types.CollectionsDataTypeTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.types.NormalizableKeyTest.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.types.PrimitiveDataTypeTest.java</file>
      <file type="M">flink-java.pom.xml</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.functions.SemanticPropUtilTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.operator.AggregateOperatorTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.operator.CoGroupOperatorTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.operator.CrossOperatorTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.operator.DistinctOperatorTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.operator.GroupingTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.operator.JoinOperatorTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.operator.ProjectionOperatorTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.record.io.CsvInputFormatTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.record.io.CsvOutputFormatTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.record.io.ExternalProcessFixedLengthInputFormatTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.record.io.ExternalProcessInputFormatTest.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.tuple.Tuple2Test.java</file>
      <file type="M">flink-java.src.test.java.org.apache.flink.api.java.typeutils.TypeInfoParserTest.java</file>
      <file type="M">flink-runtime.pom.xml</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.filecache.FileCacheDeleteValidationTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.instance.DefaultInstanceManagerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.instance.HostInClusterTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.instance.local.LocalInstanceManagerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.disk.ChannelViewsTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.disk.iomanager.IOManagerITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.disk.iomanager.IOManagerPerformanceBenchmark.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.disk.iomanager.IOManagerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.disk.SpillingBufferTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.netty.InboundEnvelopeDecoderTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.netty.NettyConnectionManagerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.netty.OutboundEnvelopeEncoderTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.serialization.DataInputOutputSerializerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.serialization.SpanningRecordSerializationTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.serialization.SpanningRecordSerializerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.memory.DefaultMemoryManagerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.memory.MemorySegmentTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.CoGroupTaskExternalITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.CoGroupTaskTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="3903" opendate="2016-5-12 00:00:00" fixdate="2016-2-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Homebrew Installation</summary>
      <description>Recently I submitted a formula for apache-flink to the homebrew project. Homebrew simplifies installation on Mac:$ brew install apache-flink...$ flink --versionVersion: 1.0.2, Commit ID: d39af15Updates to the formula are adhoc at the moment. I opened this issue to formalize updating homebrew into the release process. I drafted a procedure doc here:https://gist.github.com/EronWright/b62bd3b192a15be4c200a2542f7c9376Please also consider updating the website documentation to suggest homebrew as an alternate installation method for Mac users.</description>
      <version>None</version>
      <fixedVersion>1.2.1,1.3.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.quickstart.setup.quickstart.md</file>
    </fixedFiles>
  </bug>
  <bug id="3912" opendate="2016-5-13 00:00:00" fixdate="2016-5-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Typos in Batch Scala API Documentation</summary>
      <description>In the Batch Guide Documentation, in the Join section there are some small typos/errors for the Scala API.In particular, in the section: Join with Flat-Join Function, "left" is used as "rating", and "right" is used as "weight".Also a parenthesis is missing.</description>
      <version>None</version>
      <fixedVersion>1.0.4,1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.apis.batch.dataset.transformations.md</file>
    </fixedFiles>
  </bug>
  <bug id="4025" opendate="2016-6-5 00:00:00" fixdate="2016-6-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add possiblity for the RMQ Streaming Source to customize the queue</summary>
      <description>This patch adds the possibilty for the user of the RabbitMQStreaming Connector to customize the queue which is used. Thereare use-cases in which you want to set custom parameters for thequeue (i.e. TTL of the messages if Flink reboots) or thepossibility to bind the queue to an exchange afterwards.The commit doesn't change the actual behaviour but makes itpossible for users to override the newly create `setupQueue`method and cutomize their implementation. This was not possiblebefore.</description>
      <version>1.0.2</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-connectors.flink-connector-rabbitmq.src.main.java.org.apache.flink.streaming.connectors.rabbitmq.RMQSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="4150" opendate="2016-7-4 00:00:00" fixdate="2016-7-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Problem with Blobstore in Yarn HA setting on recovery after cluster shutdown</summary>
      <description>Submitting a job in Yarn with HA can lead to the following exception:org.apache.flink.streaming.runtime.tasks.StreamTaskException: Cannot load user class: org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer09ClassLoader info: URL ClassLoader: file: '/tmp/blobStore-ccec0f4a-3e07-455f-945b-4fcd08f5bac1/cache/blob_7fafffe9595cd06aff213b81b5da7b1682e1d6b0' (invalid JAR: zip file is empty)Class not resolvable through given classloader. at org.apache.flink.streaming.api.graph.StreamConfig.getStreamOperator(StreamConfig.java:207) at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:222) at org.apache.flink.runtime.taskmanager.Task.run(Task.java:588) at java.lang.Thread.run(Thread.java:745)Some job information, including the Blob ids, are stored in Zookeeper. The actual Blobs are stored in a dedicated BlobStore, if the recovery mode is set to Zookeeper. This BlobStore is typically located in a FS like HDFS. When the cluster is shut down, the path for the BlobStore is deleted. When the cluster is then restarted, recovering jobs cannot restore because it's Blob ids stored in Zookeeper now point to deleted files.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.leaderelection.TestingLeaderElectionService.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.execution.librarycache.BlobLibraryCacheRecoveryITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.blob.BlobRecoveryITCase.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.execution.librarycache.BlobLibraryCacheManager.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.FileSystemBlobStore.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobServerConnection.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.blob.BlobServer.java</file>
    </fixedFiles>
  </bug>
  <bug id="4151" opendate="2016-7-5 00:00:00" fixdate="2016-7-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Address Travis CI build time: We are exceeding the 2 hours limit</summary>
      <description>We've recently started hitting the two hours limit for Travis CI.I'll look into some approaches to get our build stable again.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">.travis.yml</file>
    </fixedFiles>
  </bug>
  <bug id="4169" opendate="2016-7-7 00:00:00" fixdate="2016-7-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CEP Does Not Work with RocksDB StateBackend</summary>
      <description>A job will never match any patterns because ValueState.update() is not called in the keyed CEP operators for updating the NFA state and the priority queue state.The reason why it works for other state backends is that they are very lax in their handling of state: if the object returned from ValueState.value()) is mutable changes to this will be reflected in checkpoints even if ValueState.update() is not called. RocksDB, on the other hand, does always deserialize/serialize state values when accessing/updating them, so changes to the returned object will not be reflected in the state unless update() is called.We should fix this and also add a test for it. This might be tricky because we have to pull together RocksDB and CEP.</description>
      <version>1.0.0,1.0.1,1.0.2,1.0.3,1.1.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-cep.src.test.java.org.apache.flink.cep.operator.CEPOperatorTest.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.operator.AbstractKeyedCEPPatternOperator.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.operator.AbstractCEPPatternOperator.java</file>
      <file type="M">flink-libraries.flink-cep.src.main.java.org.apache.flink.cep.operator.AbstractCEPBasePatternOperator.java</file>
      <file type="M">flink-libraries.flink-cep.pom.xml</file>
    </fixedFiles>
  </bug>
</bugrepository>
