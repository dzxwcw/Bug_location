<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="FLINK">
  <bug id="23021" opendate="2021-6-17 00:00:00" fixdate="2021-7-17 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Check for illegal modifications of JobGraph with finished operators</summary>
      <description>Users might modify the job topology before restart for external checkpoint and savepoint. To overcome this issue, we would need to check if a fully finished operator has been added after a non-fully-finished operator. If so, we would throw exception to disallow this situation or re-mark the fully finished operator as alive. </description>
      <version>None</version>
      <fixedVersion>1.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.checkpoint.CheckpointCoordinatorRestoringTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.checkpoint.CheckpointCoordinator.java</file>
    </fixedFiles>
  </bug>
  <bug id="28355" opendate="2022-7-1 00:00:00" fixdate="2022-7-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Python Bash e2e tests don&amp;#39;t clean-up after they&amp;#39;ve ran, causing disk space issues</summary>
      <description>The Bash based E2E tests that are used in Python aren't cleaned-up after they've ran. These cause disk space issues further downstream.See the CI run from https://github.com/apache/flink/pull/20114 for results, for example:&amp;#8211; When starting with the Bash e2e tests08:47:10 ##[group]Top 15 biggest directories in terms of used disk spaceJul 01 08:47:12 3983560 .Jul 01 08:47:12 1266692 ./flink-end-to-end-testsJul 01 08:47:12 624568 ./flink-distJul 01 08:47:12 624180 ./flink-dist/targetJul 01 08:47:12 500076 ./flink-dist/target/flink-1.16-SNAPSHOT-binJul 01 08:47:12 500072 ./flink-dist/target/flink-1.16-SNAPSHOT-bin/flink-1.16-SNAPSHOTJul 01 08:47:12 460812 ./flink-connectorsJul 01 08:47:12 392588 ./.gitJul 01 08:47:12 366396 ./.git/objectsJul 01 08:47:12 366388 ./.git/objects/packJul 01 08:47:12 349272 ./flink-tableJul 01 08:47:12 335592 ./.git/objects/pack/pack-38d46915823ebec2bc660fd160e5cfca5bc3e567.packJul 01 08:47:12 293044 ./flink-dist/target/flink-1.16-SNAPSHOT-bin/flink-1.16-SNAPSHOT/optJul 01 08:47:12 251272 ./flink-filesystemsJul 01 08:47:12 246596 ./flink-end-to-end-tests/flink-streaming-kinesis-testhttps://dev.azure.com/apache-flink/apache-flink/_build/results?buildId=37425&amp;view=logs&amp;j=ef799394-2d67-5ff4-b2e5-410b80c9c0af&amp;t=860bfb5d-81b0-5968-f128-2a8b5362110d&amp;l=664&amp;#8211; After completing all Bash bashed e2e tests:2022-07-01T10:20:17.3594718Z Jul 01 10:20:17 ##[group]Top 15 biggest directories in terms of used disk space2022-07-01T10:20:18.7520631Z Jul 01 10:20:18 5425892 .2022-07-01T10:20:18.7521823Z Jul 01 10:20:18 1521472 ./flink-end-to-end-tests2022-07-01T10:20:18.7522566Z Jul 01 10:20:18 1242528 ./flink-python2022-07-01T10:20:18.7523244Z Jul 01 10:20:18 952336 ./flink-python/dev2022-07-01T10:20:18.7524159Z Jul 01 10:20:18 878764 ./flink-python/dev/.conda2022-07-01T10:20:18.7524870Z Jul 01 10:20:18 834200 ./flink-python/dev/.conda/lib2022-07-01T10:20:18.7525619Z Jul 01 10:20:18 726528 ./flink-python/dev/.conda/lib/python3.72022-07-01T10:20:18.7526397Z Jul 01 10:20:18 683256 ./flink-python/dev/.conda/lib/python3.7/site-packages2022-07-01T10:20:18.7527101Z Jul 01 10:20:18 624568 ./flink-dist2022-07-01T10:20:18.7527768Z Jul 01 10:20:18 624180 ./flink-dist/target2022-07-01T10:20:18.7528494Z Jul 01 10:20:18 500076 ./flink-dist/target/flink-1.16-SNAPSHOT-bin2022-07-01T10:20:18.7529298Z Jul 01 10:20:18 500072 ./flink-dist/target/flink-1.16-SNAPSHOT-bin/flink-1.16-SNAPSHOT2022-07-01T10:20:18.7530046Z Jul 01 10:20:18 460812 ./flink-connectors2022-07-01T10:20:18.7530546Z Jul 01 10:20:18 392588 ./.git2022-07-01T10:20:18.7531014Z Jul 01 10:20:18 366396 ./.git/objectshttps://dev.azure.com/apache-flink/apache-flink/_build/results?buildId=37425&amp;view=logs&amp;j=ef799394-2d67-5ff4-b2e5-410b80c9c0af&amp;t=860bfb5d-81b0-5968-f128-2a8b5362110d&amp;l=9631</description>
      <version>1.16.0,1.15.2,1.14.6</version>
      <fixedVersion>1.16.0,1.15.2,1.14.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-python.dev.lint-python.sh</file>
      <file type="M">flink-end-to-end-tests.test-scripts.test.pyflink.yarn.sh</file>
      <file type="M">flink-end-to-end-tests.test-scripts.test.pyflink.sh</file>
      <file type="M">flink-end-to-end-tests.test-scripts.test.kubernetes.pyflink.application.sh</file>
    </fixedFiles>
  </bug>
  <bug id="28960" opendate="2022-8-15 00:00:00" fixdate="2022-10-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Pulsar throws java.lang.NoClassDefFoundError: javax/xml/bind/annotation/XmlElement</summary>
      <description>Unknown HK2 failure detected:MultiException stack 1 of 2java.lang.NoClassDefFoundError: javax/xml/bind/annotation/XmlElement at org.apache.pulsar.shade.com.fasterxml.jackson.module.jaxb.JaxbAnnotationIntrospector.&lt;init&gt;(JaxbAnnotationIntrospector.java:137) at org.apache.pulsar.shade.com.fasterxml.jackson.module.jaxb.JaxbAnnotationIntrospector.&lt;init&gt;(JaxbAnnotationIntrospector.java:124) at org.apache.pulsar.shade.com.fasterxml.jackson.module.jaxb.JaxbAnnotationIntrospector.&lt;init&gt;(JaxbAnnotationIntrospector.java:116) at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490) at java.base/java.lang.Class.newInstance(Class.java:584)</description>
      <version>1.15.1,1.14.6</version>
      <fixedVersion>1.17.0,1.15.3,1.14.7,1.16.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-pulsar.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="29502" opendate="2022-10-4 00:00:00" fixdate="2022-10-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update the Hadoop implementation for filesystems to 3.3.4</summary>
      <description>Flink currently uses Hadoop version 3.3.2 for the Flink filesystem implementations. Upgrading this to version 3.3.4 will resolve some CVEs like https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-25168 (which Flink is not affected by)</description>
      <version>None</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-filesystems.pom.xml</file>
      <file type="M">flink-filesystems.flink-s3-fs-presto.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-filesystems.flink-s3-fs-presto.pom.xml</file>
      <file type="M">flink-filesystems.flink-s3-fs-hadoop.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-filesystems.flink-s3-fs-hadoop.pom.xml</file>
      <file type="M">flink-filesystems.flink-s3-fs-base.pom.xml</file>
      <file type="M">flink-filesystems.flink-oss-fs-hadoop.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-filesystems.flink-oss-fs-hadoop.pom.xml</file>
      <file type="M">flink-filesystems.flink-gs-fs-hadoop.pom.xml</file>
      <file type="M">flink-filesystems.flink-fs-hadoop-shaded.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-filesystems.flink-fs-hadoop-shaded.pom.xml</file>
      <file type="M">flink-filesystems.flink-azure-fs-hadoop.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-filesystems.flink-azure-fs-hadoop.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="29846" opendate="2022-11-2 00:00:00" fixdate="2022-12-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade Archunit to 1.0.0</summary>
      <description>Flink still uses Archunit version 0.22.0. Recently Archunit 1.0.0 has been introduced; we should upgrade to this major version and remove all the deprecated usages</description>
      <version>None</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-formats.flink-hadoop-bulk.src.test.java.org.apache.flink.formats.hadoop.bulk.HadoopPathBasedPartFileWriterTest.java</file>
      <file type="M">flink-formats.flink-hadoop-bulk.src.test.java.org.apache.flink.formats.hadoop.bulk.committer.HadoopRenameCommitterLocalFSTest.java</file>
      <file type="M">flink-formats.flink-hadoop-bulk.src.test.java.org.apache.flink.formats.hadoop.bulk.committer.HadoopRenameCommitterHDFSTest.java</file>
      <file type="M">flink-formats.flink-hadoop-bulk.archunit-violations.83371291-f688-4eaf-a207-24981f1067f3</file>
      <file type="M">flink-architecture-tests.flink-architecture-tests-test.src.main.java.org.apache.flink.architecture.rules.ITCaseRules.java</file>
      <file type="M">flink-architecture-tests.flink-architecture-tests-production.src.main.java.org.apache.flink.architecture.rules.ApiAnnotationRules.java</file>
      <file type="M">flink-architecture-tests.flink-architecture-tests-production.archunit-violations.e5126cae-f3fe-48aa-b6fb-60ae6cc3fcd5</file>
      <file type="M">flink-architecture-tests.flink-architecture-tests-production.archunit-violations.b8900323-6aab-4e7e-9b17-f53b3c3dca46</file>
      <file type="M">flink-architecture-tests.flink-architecture-tests-production.archunit-violations.5b9eed8a-5fb6-4373-98ac-3be2a71941b8</file>
      <file type="M">flink-architecture-tests.flink-architecture-tests-base.src.main.java.org.apache.flink.architecture.common.SourcePredicates.java</file>
      <file type="M">flink-architecture-tests.flink-architecture-tests-base.src.main.java.org.apache.flink.architecture.common.Predicates.java</file>
      <file type="M">flink-architecture-tests.flink-architecture-tests-base.src.main.java.org.apache.flink.architecture.common.Conditions.java</file>
    </fixedFiles>
  </bug>
  <bug id="30679" opendate="2023-1-13 00:00:00" fixdate="2023-1-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Can not load the data of hive dim table when project-push-down is introduced</summary>
      <description>维表project push down优化引入：https://issues.apache.org/jira/browse/FLINK-29138hive维表的两个问题：https://issues.apache.org/jira/browse/FLINK-29992https://issues.apache.org/jira/browse/FLINK-30679   Can not load the data of hive dim table when project-push-down is introduced. hive-exec  version: 2.3.4flink version: 1.14.6flink-hive-connector: the latest code for release-1.14 branch vectorize read: java.lang.ArrayIndexOutOfBoundsException: 3    at org.apache.flink.connectors.hive.read.HiveTableInputFormat.useOrcVectorizedRead(HiveTableInputFormat.java:276) ~[flink-connector-hive-1.14.1-SNAPSHOT.jar:1.14-SNAPSHOT]    at org.apache.flink.connectors.hive.read.HiveTableInputFormat.open(HiveTableInputFormat.java:129) ~[flink-connector-hive-1.14.1-SNAPSHOT.jar:1.14-SNAPSHOT]    at org.apache.flink.connectors.hive.read.HiveInputFormatPartitionReader.open(HiveInputFormatPartitionReader.java:86) ~[flink-connector-hive-1.14.1-SNAPSHOT.jar:1.14-SNAPSHOT]    at org.apache.flink.table.filesystem.FileSystemLookupFunction.checkCacheReload(FileSystemLookupFunction.java:132) ~[flink-table-runtime_2.11-1.14.6.jar:1.14.6]    at org.apache.flink.table.filesystem.FileSystemLookupFunction.eval(FileSystemLookupFunction.java:105) ~[flink-table-runtime_2.11-1.14.6.jar:1.14.6]    at LookupFunction$26.flatMap(Unknown Source) ~[?:?]   mapreduce read: java.lang.ArrayIndexOutOfBoundsException: 3    at org.apache.flink.connectors.hive.read.HiveMapredSplitReader.lambda$new$0(HiveMapredSplitReader.java:139) ~[flink-connector-hive-1.14.1-SNAPSHOT.jar:1.14-SNAPSHOT]    at java.util.stream.IntPipeline$4$1.accept(IntPipeline.java:250) ~[?:1.8.0_301]    at java.util.Spliterators$IntArraySpliterator.forEachRemaining(Spliterators.java:1032) ~[?:1.8.0_301]    at java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:693) ~[?:1.8.0_301]    at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) ~[?:1.8.0_301]    at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) ~[?:1.8.0_301]    at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:546) ~[?:1.8.0_301]    at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260) ~[?:1.8.0_301]    at java.util.stream.ReferencePipeline.toArray(ReferencePipeline.java:438) ~[?:1.8.0_301]    at org.apache.flink.connectors.hive.read.HiveMapredSplitReader.&lt;init&gt;(HiveMapredSplitReader.java:141) ~[flink-connector-hive-1.14.1-SNAPSHOT.jar:1.14-SNAPSHOT]    at org.apache.flink.connectors.hive.read.HiveTableInputFormat.open(HiveTableInputFormat.java:157) ~[flink-connector-hive-1.14.1-SNAPSHOT.jar:1.14-SNAPSHOT]    at org.apache.flink.connectors.hive.read.HiveInputFormatPartitionReader.open(HiveInputFormatPartitionReader.java:86) ~[flink-connector-hive-1.14.1-SNAPSHOT.jar:1.14-SNAPSHOT]    at org.apache.flink.table.filesystem.FileSystemLookupFunction.checkCacheReload(FileSystemLookupFunction.java:132) ~[flink-table-runtime_2.11-1.14.6.jar:1.14.6]    at org.apache.flink.table.filesystem.FileSystemLookupFunction.eval(FileSystemLookupFunction.java:105) ~[flink-table-runtime_2.11-1.14.6.jar:1.14.6]    at LookupFunction$26.flatMap(Unknown Source) ~[?:?]    at org.apache.flink.table.runtime.operators.join.lookup.LookupJoinRunner.processElement(LookupJoinRunner.java:81) ~[flink-table-runtime_2.11-1.14.6.jar:1.14.6]    at org.apache.flink.table.runtime.operators.join.lookup.LookupJoinRunner.processElement(LookupJoinRunner.java:34) ~[flink-table-runtime_2.11-1.14.6.jar:1.14.6]   The sql : CREATE TABLE kafkaTableSource ( name string, age int, sex string, address string, ptime AS PROCTIME()) WITH ( 'connector' = 'kafka', 'topic' = 'hehuiyuan1', 'scan.startup.mode' = 'latest-offset', 'properties.bootstrap.servers' = 'localhost:9092', 'properties.client.id' = 'test-consumer-group', 'properties.group.id' = 'test-consumer-group', 'format' = 'csv');CREATE TABLE printsink ( name string, age int, sex string, address string, score bigint, dt string) WITH ( 'connector' = 'print');CREATE CATALOG myhiveWITH ( 'type' = 'hive', 'default-database' = 'hhy', 'hive-version' = '2.0.0', 'hadoop-conf-dir'='/Users/hehuiyuan/soft/hadoop/hadoop-2.7.3/etc/hadoop');USE CATALOG myhive;USE hhy;set table.sql-dialect=hive;CREATE TABLE IF NOT EXISTS tmp_flink_test_text ( name STRING, age INT, score BIGINT) PARTITIONED BY (dt STRING) STORED AS TEXTFILE TBLPROPERTIES ( 'streaming-source.enable' = 'false', 'streaming-source.partition.include' = 'all', 'lookup.join.cache.ttl' = '5 min');set table.sql-dialect=default;USE CATALOG default_catalog;INSERT INTO default_catalog.default_database.printsinkSELECT s.name, s.age, s.sex, s.address, r.score, r.dtFROM default_catalog.default_database.kafkaTableSource as sJOIN myhive.hhy.tmp_flink_test_text FOR SYSTEM_TIME AS OF s.ptime AS rON r.name = s.name;   </description>
      <version>1.14.6</version>
      <fixedVersion>1.17.0,1.14.7,1.15.4,1.16.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-hive.src.test.java.org.apache.flink.connectors.hive.HiveLookupJoinITCase.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.connectors.hive.HiveLookupTableSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="3165" opendate="2015-12-13 00:00:00" fixdate="2015-1-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[py] Add support for Windows OS</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-python.src.main.python.org.apache.flink.python.api.flink.plan.Environment.py</file>
      <file type="M">flink-libraries.flink-python.src.main.python.org.apache.flink.python.api.flink.functions.Function.py</file>
      <file type="M">flink-libraries.flink-python.src.main.python.org.apache.flink.python.api.flink.connection.Connection.py</file>
      <file type="M">flink-libraries.flink-python.src.main.java.org.apache.flink.python.api.PythonPlanBinder.java</file>
    </fixedFiles>
  </bug>
</bugrepository>
