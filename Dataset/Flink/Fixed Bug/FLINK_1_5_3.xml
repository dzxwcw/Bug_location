<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="FLINK">
  <bug id="10070" opendate="2018-8-6 00:00:00" fixdate="2018-8-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Flink cannot be compiled with maven 3.0.x</summary>
      <description>In FLINK-9986 we bumped the version of the git-commit-id-plugin to 2.1.14 which is incompatible with various maven versions, like 3.0.X.We can either bump the version to 2.2.4 to support all versions, or downgrade to 2.1.9 and rework FLINK-9986 with property exclusions.Additionally we should setup a test that checks the compatibility of Flink with various maven versions.</description>
      <version>1.5.3,1.6.0</version>
      <fixedVersion>1.5.3,1.6.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-runtime.pom.xml</file>
      <file type="M">flink-dist.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="10071" opendate="2018-8-6 00:00:00" fixdate="2018-8-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document usage of INSERT INTO in SQL Client</summary>
      <description>Document the usage of INSERT INTO statements in SQL.</description>
      <version>None</version>
      <fixedVersion>1.6.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.dev.table.sqlClient.md</file>
    </fixedFiles>
  </bug>
  <bug id="10142" opendate="2018-8-14 00:00:00" fixdate="2018-11-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reduce synchronization overhead for credit notifications</summary>
      <description>When credit-based flow control was introduced, we also added some checks and optimisations for uncommon code paths that make common code paths unnecessarily more expensive, e.g. checking whether a channel was released before forwarding a credit notification to Netty. Such checks would have to be confirmed by the Netty thread anyway and thus only add additional load for something that happens only once (per channel).</description>
      <version>1.5.0,1.5.1,1.5.2,1.5.3,1.6.0,1.7.0</version>
      <fixedVersion>1.5.4,1.6.1,1.7.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.partition.consumer.RemoteInputChannelTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.partition.consumer.RemoteInputChannel.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.netty.PartitionRequestClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="10247" opendate="2018-8-29 00:00:00" fixdate="2018-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Run MetricQueryService in separate thread pool</summary>
      <description>In order to make the MetricQueryService run independently of the main Flink components, it should get its own dedicated thread pool assigned.</description>
      <version>1.5.3,1.6.0,1.7.0</version>
      <fixedVersion>1.7.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.SerializableOptional.java</file>
      <file type="M">flink-runtime.src.test.scala.org.apache.flink.runtime.akka.AkkaUtilsTest.scala</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskexecutor.TestingTaskExecutorGateway.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskexecutor.TaskExecutorTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskexecutor.TaskExecutorITCase.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskExecutorGateway.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskExecutor.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.resourcemanager.ResourceManager.java</file>
      <file type="M">flink-runtime.src.main.scala.org.apache.flink.runtime.akka.AkkaUtils.scala</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskManagerRunner.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.minicluster.MiniCluster.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.entrypoint.ClusterEntrypoint.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.util.MetricUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.clusterframework.BootstrapTools.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.MetricOptions.java</file>
      <file type="M">docs..includes.generated.metric.configuration.html</file>
    </fixedFiles>
  </bug>
  <bug id="10253" opendate="2018-8-29 00:00:00" fixdate="2018-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Run MetricQueryService with lower priority</summary>
      <description>We should run the MetricQueryService with a lower priority than the main Flink components. An idea would be to start the underlying threads with a lower priority.</description>
      <version>1.5.3,1.6.0,1.7.0</version>
      <fixedVersion>1.7.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.util.MetricUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.entrypoint.ClusterEntrypoint.java</file>
      <file type="M">flink-runtime.src.test.scala.org.apache.flink.runtime.akka.AkkaUtilsTest.scala</file>
      <file type="M">flink-runtime.src.main.scala.org.apache.flink.runtime.akka.AkkaUtils.scala</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.clusterframework.BootstrapTools.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.MetricOptions.java</file>
      <file type="M">docs..includes.generated.metric.configuration.html</file>
    </fixedFiles>
  </bug>
  <bug id="10267" opendate="2018-8-30 00:00:00" fixdate="2018-9-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[State] Fix arbitrary iterator access on RocksDBMapIterator</summary>
      <description>Currently, RocksDBMapIterator would load 128 entries into local cacheEntries every time if needed. Both RocksDBMapIterator#next() and RocksDBMapIterator#hasNext() action might trigger to load RocksDBEntry into cacheEntries.However, if the iterator's size larger than 128 and we continue to access the iterator with following order: hasNext() -&gt; next() -&gt; hasNext() -&gt; remove(), we would meet weird exception when we try to remove the 128th element:java.lang.IllegalStateException: The remove operation must be called after a valid next operation.Since we could not control user's access on iterator, we should fix this bug to avoid unexpected exception.</description>
      <version>1.5.3,1.6.0</version>
      <fixedVersion>1.5.4,1.6.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-state-backends.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBMapState.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.StateBackendTestBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="10274" opendate="2018-8-31 00:00:00" fixdate="2018-1-31 01:00:00" resolution="Unresolved">
    <buginformation>
      <summary>The stop-cluster.sh cannot stop cluster properly when there are multiple clusters running</summary>
      <description>When you are preparing to do a Flink framework version upgrading by using the strategy shadow copy , you have to run multiple clusters concurrently,  however when you are ready to stop the old version cluster after upgrading, you would find the stop-cluster.sh wouldn't work as you expected, the following is the steps to duplicate the issue: There is already a running Flink 1.5.x cluster instance; Installing another Flink 1.6.x cluster instance at the same cluster machines; Migrating the jobs from Flink 1.5.x  to Flink 1.6.x ; go to the bin dir of the Flink 1.5.x cluster instance and run stop-cluster.sh ;You would expect the old Flink 1.5.x cluster instance be stopped ,right? Unfortunately the stopped cluster is the new installed Flink 1.6.x cluster instance instead!</description>
      <version>1.5.1,1.5.2,1.5.3,1.6.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.CoreOptions.java</file>
      <file type="M">docs..includes.generated.environment.configuration.html</file>
    </fixedFiles>
  </bug>
  <bug id="10309" opendate="2018-9-9 00:00:00" fixdate="2018-11-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cancel with savepoint fails with java.net.ConnectException when using the per job-mode</summary>
      <description>The problem occurs when using the Yarn per-job detached mode. Trying to cancel with savepoint fails with the following exception before being able to retrieve the savepoint path:exception stack trace : org.apache.flink.util.FlinkException: Could not cancel job xxxx.        at org.apache.flink.client.cli.CliFrontend.lambda$cancel$4(CliFrontend.java:585)        at org.apache.flink.client.cli.CliFrontend.runClusterAction(CliFrontend.java:960)        at org.apache.flink.client.cli.CliFrontend.cancel(CliFrontend.java:577)        at org.apache.flink.client.cli.CliFrontend.parseParameters(CliFrontend.java:1034)        at java.lang.Thread.run(Thread.java:748)Caused by: java.util.concurrent.ExecutionException: org.apache.flink.runtime.concurrent.FutureUtils$RetryException: Could not complete the operation. Number of retries has been exhausted.        at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)        at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1895)        at org.apache.flink.client.program.rest.RestClusterClient.cancelWithSavepoint(RestClusterClient.java:398)        at org.apache.flink.client.cli.CliFrontend.lambda$cancel$4(CliFrontend.java:583)        ... 6 moreCaused by: org.apache.flink.runtime.concurrent.FutureUtils$RetryException: Could not complete the operation. Number of retries has been exhausted.        at org.apache.flink.runtime.concurrent.FutureUtils.lambda$retryOperationWithDelay$5(FutureUtils.java:213)        at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:760)        at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:736)        at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)        at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1977)        at org.apache.flink.runtime.rest.RestClient.lambda$submitRequest$1(RestClient.java:274)        at org.apache.flink.shaded.netty4.io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:680)        at org.apache.flink.shaded.netty4.io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:603)        at org.apache.flink.shaded.netty4.io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:563)        at org.apache.flink.shaded.netty4.io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:424)        at org.apache.flink.shaded.netty4.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.fulfillConnectPromise(AbstractNioChannel.java:268)        at org.apache.flink.shaded.netty4.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:284)        at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:528)        at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)        at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)        at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)        at org.apache.flink.shaded.netty4.io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)        at org.apache.flink.shaded.netty4.io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137)        ... 1 moreCaused by: java.util.concurrent.CompletionException: java.net.ConnectException: Connect refuse: xxx/xxx.xxx.xxx.xxx:xxx        at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)        at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308)        at java.util.concurrent.CompletableFuture.uniCompose(CompletableFuture.java:943)        at java.util.concurrent.CompletableFuture$UniCompose.tryFire(CompletableFuture.java:926)        ... 16 moreCaused by: java.net.ConnectException: Connect refuse: xxx/xxx.xxx.xxx.xxx:xxx        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)        at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)        at org.apache.flink.shaded.netty4.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:224)        at org.apache.flink.shaded.netty4.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:281)        ... 7 moresome discussion in mailing list : http://apache-flink-mailing-list-archive.1008284.n3.nabble.com/Cancel-flink-job-occur-exception-td24056.html</description>
      <version>1.5.3,1.6.0,1.7.0</version>
      <fixedVersion>1.5.6,1.6.3,1.7.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.recovery.ProcessFailureCancelingITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.RestServerEndpointITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.async.AbstractAsynchronousOperationHandlersTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.AbstractHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.dispatcher.FileArchivedExecutionGraphStoreTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.RestServerEndpoint.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.util.HandlerUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.taskmanager.AbstractTaskManagerFileHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.job.AsynchronousJobOperationKey.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.async.AbstractAsynchronousOperationHandlers.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.AbstractRestHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.AbstractHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.entrypoint.component.DispatcherResourceManagerComponent.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.entrypoint.ClusterEntrypoint.java</file>
    </fixedFiles>
  </bug>
  <bug id="10331" opendate="2018-9-13 00:00:00" fixdate="2018-9-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reduce number of flush requests to the network stack</summary>
      <description>With the re-design of the record writer interaction with the result(sub)partitions, flush requests can currently pile up in these scenarios: a previous flush request has not been completely handled yet and/or is still enqueued or the network stack is still polling from this subpartition and doesn't need a new notificationThese lead to increased notifications in low latency settings (low output flusher intervals) which can be avoided.</description>
      <version>1.5.0,1.5.1,1.5.2,1.5.3,1.6.0,1.7.0</version>
      <fixedVersion>1.5.5,1.6.2,1.7.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.partition.PipelinedSubpartitionTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.partition.PipelinedSubpartition.java</file>
    </fixedFiles>
  </bug>
  <bug id="9885" opendate="2018-7-18 00:00:00" fixdate="2018-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>End-to-end test: Elasticsearch 6.x connector</summary>
      <description>We have decided to try and merge the pending Elasticsearch 6.x PRs. This should also come with an end-to-end test that covers this.</description>
      <version>None</version>
      <fixedVersion>1.6.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.travis.mvn.watchdog.sh</file>
      <file type="M">flink-end-to-end-tests.test-scripts.test.streaming.elasticsearch.sh</file>
      <file type="M">flink-end-to-end-tests.test-scripts.elasticsearch-common.sh</file>
      <file type="M">flink-end-to-end-tests.flink-elasticsearch6-test.src.main.java.org.apache.flink.streaming.tests.Elasticsearch6SinkExample.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch.src.test.java.org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkITCase.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch.src.main.java.org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSink.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch.src.main.java.org.apache.flink.streaming.connectors.elasticsearch.Elasticsearch1ApiCallBridge.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch6.src.test.resources.log4j-test.properties</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch6.src.test.java.org.apache.flink.streaming.connectors.elasticsearch.EmbeddedElasticsearchNodeEnvironmentImpl.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch6.src.test.java.org.apache.flink.streaming.connectors.elasticsearch6.examples.ElasticsearchSinkExample.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch6.src.test.java.org.apache.flink.streaming.connectors.elasticsearch6.ElasticsearchSinkITCase.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch6.src.main.java.org.apache.flink.streaming.connectors.elasticsearch6.ElasticsearchSink.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch6.src.main.java.org.apache.flink.streaming.connectors.elasticsearch6.Elasticsearch6ApiCallBridge.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch6.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch5.src.test.java.org.apache.flink.streaming.connectors.elasticsearch5.ElasticsearchSinkITCase.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch5.src.main.java.org.apache.flink.streaming.connectors.elasticsearch5.ElasticsearchSink.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch5.src.main.java.org.apache.flink.streaming.connectors.elasticsearch5.Elasticsearch5ApiCallBridge.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch2.src.test.java.org.apache.flink.streaming.connectors.elasticsearch2.ElasticsearchSinkITCase.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch2.src.main.java.org.apache.flink.streaming.connectors.elasticsearch2.ElasticsearchSink.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch2.src.main.java.org.apache.flink.streaming.connectors.elasticsearch2.Elasticsearch2ApiCallBridge.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch-base.src.test.java.org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkTestBase.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch-base.src.test.java.org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBaseTest.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch-base.src.main.java.org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch-base.src.main.java.org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchApiCallBridge.java</file>
      <file type="M">docs.dev.connectors.elasticsearch.md</file>
      <file type="M">flink-end-to-end-tests.run-nightly-tests.sh</file>
      <file type="M">flink-end-to-end-tests.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9886" opendate="2018-7-18 00:00:00" fixdate="2018-7-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Build SQL jars with every build</summary>
      <description>Currently, the shaded fat jars for SQL are only built in the -Prelease profile. However, end-to-end tests require those jars and should also be able to test them. E.g. existing META-INF entry and proper shading. We should build them with every release. If a build should happen quicker one can use the -Pfast profile.</description>
      <version>None</version>
      <fixedVersion>1.6.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-formats.flink-json.pom.xml</file>
      <file type="M">flink-formats.flink-avro.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.11.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.pom.xml</file>
    </fixedFiles>
  </bug>
</bugrepository>
