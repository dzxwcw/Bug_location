<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="FLINK">
  <bug id="11232" opendate="2018-12-29 00:00:00" fixdate="2018-1-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Empty Start Time of sub-task on web dashboard</summary>
      <description></description>
      <version>1.5.5,1.6.2,1.6.3,1.7.0,1.7.1</version>
      <fixedVersion>1.6.4,1.7.2,1.8.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.JobVertexDetailsInfo.java</file>
    </fixedFiles>
  </bug>
  <bug id="11235" opendate="2018-12-31 00:00:00" fixdate="2018-1-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Elasticsearch connector leaks threads if no connection could be established</summary>
      <description>elasticsearch transport sink init steps1, create client thread2, try to check every host:port3, if each host:port is unreachable, while throw RuntimeExceptionbut, because of throw RuntimeException, the client can not close, so causing thread leaktransport client code```TransportClient transportClient = new PreBuiltTransportClient(settings);for (TransportAddress transport : ElasticsearchUtils.convertInetSocketAddresses(transportAddresses)) { transportClient.addTransportAddress(transport);}// verify that we actually are connected to a clusterif (transportClient.connectedNodes().isEmpty()) { throw new RuntimeException("Elasticsearch client is not connected to any Elasticsearch nodes!");}return transportClient;}```thread leakthread dump </description>
      <version>1.6.3,1.7.1,1.8.0</version>
      <fixedVersion>1.6.4,1.7.2,1.8.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-elasticsearch5.src.main.java.org.apache.flink.streaming.connectors.elasticsearch5.Elasticsearch5ApiCallBridge.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch2.src.main.java.org.apache.flink.streaming.connectors.elasticsearch2.Elasticsearch2ApiCallBridge.java</file>
    </fixedFiles>
  </bug>
  <bug id="11262" opendate="2019-1-3 00:00:00" fixdate="2019-1-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bump jython-standalone to 2.7.1</summary>
      <description>Due to security issue: https://ossindex.sonatype.org/vuln/7a4be7b3-74f5-4a9b-a24f-d1fd80ed6bbca</description>
      <version>1.6.3,1.7.1,1.8.0</version>
      <fixedVersion>1.6.4,1.7.2,1.8.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">NOTICE-binary</file>
      <file type="M">flink-libraries.flink-streaming-python.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-libraries.flink-streaming-python.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11391" opendate="2019-1-18 00:00:00" fixdate="2019-6-18 01:00:00" resolution="Done">
    <buginformation>
      <summary>Introduce ShuffleMaster in Job Master</summary>
      <description>Implement PartitionShuffleDescriptor for covering necessary abstract info. Implement ShuffleDeploymentDecriptor generated from PartitionShuffleDecriptor. Define ShuffleMaster interface and create a simple implementation on JM side which relies on currently implemented NetworkEnviroment on TM side. Define ShuffleManager interface for creating ShuffleMaster. Introduce a Flink configuration option for ShuffleManager implementation. Default value for it could be &lt;none&gt; which serves as a feature flag at the moment to use current code paths.</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.io.benchmark.StreamNetworkBenchmarkEnvironment.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskmanager.TaskTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskexecutor.TaskSubmissionTestEnvironment.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskexecutor.TaskExecutorSubmissionTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.partition.ResultPartitionTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.partition.consumer.SingleInputGateTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.partition.consumer.InputChannelBuilder.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.NetworkEnvironmentBuilder.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.executiongraph.FinalizeOnMasterTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.executiongraph.ExecutionVertexDeploymentTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.executiongraph.ExecutionTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.executiongraph.ExecutionGraphDeploymentTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.deployment.ResultPartitionDeploymentDescriptorTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.deployment.InputChannelDeploymentDescriptorTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskManagerServices.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskExecutor.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.partition.consumer.SingleInputGateFactory.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.partition.consumer.RemoteInputChannel.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.NetworkEnvironment.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.PartitionInfo.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.ExecutionVertex.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.ExecutionJobVertex.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.ExecutionGraph.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.Execution.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.deployment.ResultPartitionLocation.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.deployment.ResultPartitionDeploymentDescriptor.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.deployment.InputGateDeploymentDescriptor.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.deployment.InputChannelDeploymentDescriptor.java</file>
    </fixedFiles>
  </bug>
  <bug id="11427" opendate="2019-1-24 00:00:00" fixdate="2019-10-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Protobuf parquet writer implementation</summary>
      <description>Right now only ParquetAvroWriters exist to create ParquetWriterFactory. We want to implement a protobuf ParquetProtoWriters to create ParquetWriterFactory.  I am happy to submit a PR if this approach sounds good . </description>
      <version>None</version>
      <fixedVersion>1.12.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-formats.flink-parquet.pom.xml</file>
      <file type="M">docs.dev.connectors.streamfile.sink.zh.md</file>
      <file type="M">docs.dev.connectors.streamfile.sink.md</file>
    </fixedFiles>
  </bug>
  <bug id="11469" opendate="2019-1-30 00:00:00" fixdate="2019-1-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix example in "Tuning Checkpoints and Large State" documentation</summary>
      <description>Sample code for subtitle Tuning RocksDB in Tuning Checkpoints and Large State is wrong  Affects Version：All versions after 1.1  </description>
      <version>1.6.2,1.6.3,1.6.4,1.7.0,1.7.1,1.7.2,1.8.0</version>
      <fixedVersion>1.6.4,1.7.2,1.8.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.ops.state.large.state.tuning.md</file>
    </fixedFiles>
  </bug>
  <bug id="11585" opendate="2019-2-12 00:00:00" fixdate="2019-2-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Prefix matching in ConfigDocsGenerator can result in wrong assignments</summary>
      <description>There are some cases where the key-prefix matching does not work as intended: given the prefixes "a.b" and "a.b.c.d", then an option with a key "a.b.c.X" will be assigned to the default groups instead of "a.b" given a prefix "a.b", an option "a.c.b" will be matched to that group instead of the default</description>
      <version>1.6.3,1.7.1,1.8.0</version>
      <fixedVersion>1.6.4,1.7.3,1.8.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-docs.src.test.java.org.apache.flink.docs.configuration.ConfigOptionsDocGeneratorTest.java</file>
      <file type="M">flink-docs.src.main.java.org.apache.flink.docs.configuration.ConfigOptionsDocGenerator.java</file>
    </fixedFiles>
  </bug>
  <bug id="11617" opendate="2019-2-14 00:00:00" fixdate="2019-3-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Kinesis Connector getRecords() failure logging is misleading</summary>
      <description>There isn't enough information in the current logging to diagnose a getRecords() failure.  Also there is a hardcoded string that states the failure cause was always ProvisionedThroughputExceededException which isn't true.  There are many possible causes of failures.  This is misleading.</description>
      <version>1.5.6,1.6.3,1.7.1</version>
      <fixedVersion>1.8.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.proxy.KinesisProxy.java</file>
    </fixedFiles>
  </bug>
  <bug id="1171" opendate="2014-10-17 00:00:00" fixdate="2014-10-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move scala tests to flink-tests project</summary>
      <description>Eclipse does not manage to make the macros defined in src/main/scala available to src/test/scala - making it impossible to develop the scala project in Eclipse.Moving the tests to a different project (here: flink-tests/src/test/scala) solves the issue.See mailing list archive for discussion: http://mail-archives.apache.org/mod_mbox/flink-dev/201410.mbox/browser</description>
      <version>None</version>
      <fixedVersion>0.7.0-incubating</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.pom.xml</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.util.CollectionDataSets.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.types.TypeInformationGenTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.ScalaAPICompletenessTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.runtime.tuple.base.TupleComparatorTestBase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.runtime.tuple.base.PairComparatorTestBase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.runtime.TupleSerializerTestInstance.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.runtime.TupleSerializerTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.runtime.TupleComparatorISD3Test.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.runtime.TupleComparatorISD2Test.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.runtime.TupleComparatorISD1Test.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.runtime.TupleComparatorILDXC2Test.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.runtime.TupleComparatorILDX1Test.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.runtime.TupleComparatorILDC3Test.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.runtime.TupleComparatorILD3Test.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.runtime.TupleComparatorILD2Test.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.runtime.GenericPairComparatorTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.UnionITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.translation.ReduceTranslationTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.translation.DistinctTranslationTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.translation.DeltaIterationTranslationTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.translation.AggregateTranslationTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.SumMinMaxITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.ReduceITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.PartitionITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.MapITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.JoinOperatorTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.JoinITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.GroupReduceITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.GroupingTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.FlatMapITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.FirstNOperatorTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.FirstNITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.FilterITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.ExamplesITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.DistinctOperatorTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.DistinctITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.CrossITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.CoGroupOperatorTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.CoGroupITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.AggregateOperatorTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.AggregateITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.io.CsvInputFormatTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.io.CollectionInputFormatTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.functions.SemanticPropertiesTranslationTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.DeltaIterationSanityCheckTest.scala</file>
      <file type="M">flink-scala.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11732" opendate="2019-2-23 00:00:00" fixdate="2019-5-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a language switch to the sidebar for Flink documents</summary>
      <description>Add a language switch similar to the project webpage. We didn't add the switch in the first version of supporting Chinese language, because we want to expose the switch when we satisfied the translation coverage.</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs..layouts.plain.html</file>
      <file type="M">docs..includes.sidenav.html</file>
      <file type="M">docs.page.css.flink.css</file>
    </fixedFiles>
  </bug>
  <bug id="1183" opendate="2014-10-26 00:00:00" fixdate="2014-1-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Generate gentle notification message when Flink is started with Java 6</summary>
      <description>With Java 6 is reaching EOL we would like to let Flink's applications to know that it is recommended to move to Jav 7 or higher.This could be done as logging message when Flink Job Manager is starting.This will allow us to "deprecate" the support for Java 6 in the future by providing early notification to the users.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.scala.org.apache.flink.runtime.jobmanager.JobManager.scala</file>
    </fixedFiles>
  </bug>
  <bug id="11834" opendate="2019-3-6 00:00:00" fixdate="2019-3-6 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Introduce flink logical relational nodes</summary>
      <description>Adds nodes extended from Calcite, including FlinkLogicalAggregate, FlinkLogicalCalc,FlinkLogicalCorrelate, FlinkLogicalIntersect, FlinkLogicalJoin, FlinkLogicalMinus, FlinkLogicalOverWindow, FlinkLogicalSort, FlinkLogicalUnion, FlinkLogicalValues, FlinkLogicalTableSourceScan, FlinkLogicalTableFunctionScan Adds new RelNode for Flink, including Expand, Rank, Sink, WatermarkAssigner</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.type.TimestampType.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.type.InternalTypes.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.schema.DataStreamTable.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.nodes.logical.FlinkLogicalDataStreamTableScan.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.nodes.FlinkRelNode.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.calcite.FlinkTypeFactory.scala</file>
    </fixedFiles>
  </bug>
  <bug id="11887" opendate="2019-3-12 00:00:00" fixdate="2019-3-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Latency metrics drift apart</summary>
      <description>The operator's latency time is increased by approximately 2.7 minutes per day (see the attached).We compute the latency by System.currentTimeMillis - marker.getMarkedTime.There is no guarantee that System.currentTimeMillis and System.nanoTime don't drift apart.If a GC pause or linux preemptive scheduling happenes, this should affect latency metrics.Latency metrics drift away from their initial values with time(verify this result via the JVM Heap Dump).</description>
      <version>1.6.3</version>
      <fixedVersion>1.7.3,1.8.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.StreamSourceOperatorLatencyMetricsTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="11889" opendate="2019-3-12 00:00:00" fixdate="2019-4-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove "stop" signal along with Stoppable interfaces</summary>
      <description>During the ML discussion of FLIP-34 we realised that it would be beneficial for this new feature to replace the existing "stop" functionality. The current "stop" functionality cannot be used because no real-world sources support the functionality. Therefore, I think it is save to remove because it should not break existing workflows.The issue proposes completely removing the old stop feature, introduced via FLINK-2111, as preparation for FLIP-34.We have to be careful when doing this because it touches quite a few things. Basically, we have to do a manual revert of this commit: https://github.com/apache/flink/commit/bdd4024e20fdfb0accb6121a68780ce3a0c218c0</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.StreamSourceOperatorWatermarksTest.java</file>
      <file type="M">flink-runtime-web.web-dashboard.web.partials.jobs.job.plan.node.checkpoints.details.html</file>
      <file type="M">flink-runtime-web.web-dashboard.web.partials.jobs.job.html</file>
      <file type="M">flink-runtime-web.web-dashboard.web.js.index.js</file>
      <file type="M">flink-runtime-web.web-dashboard.web.js.hs.index.js</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.runtime.TimestampITCase.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.SourceStreamTaskStoppingTest.java</file>
      <file type="M">flink-runtime-web.web-dashboard.app.partials.jobs.job.jade</file>
      <file type="M">flink-runtime-web.web-dashboard.app.scripts.modules.jobs.jobs.ctrl.coffee</file>
      <file type="M">flink-runtime-web.web-dashboard.app.scripts.modules.jobs.jobs.svc.coffee</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.program.rest.RestClusterClient.java</file>
      <file type="M">flink-clients.src.test.java.org.apache.flink.client.program.rest.RestClusterClientTest.java</file>
      <file type="M">flink-connectors.flink-connector-nifi.src.main.java.org.apache.flink.streaming.connectors.nifi.NiFiSource.java</file>
      <file type="M">flink-connectors.flink-connector-twitter.src.main.java.org.apache.flink.streaming.connectors.twitter.TwitterSource.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.StoppableFunction.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.WebFrontendITCase.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.dispatcher.Dispatcher.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.Execution.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.ExecutionGraph.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.ExecutionVertex.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobgraph.JobVertex.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobgraph.tasks.StoppableTask.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobmanager.slots.ActorTaskManagerGateway.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobmanager.slots.TaskManagerGateway.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobmaster.JobMaster.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobmaster.JobMasterGateway.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobmaster.RpcTaskManagerGateway.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.minicluster.MiniCluster.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.job.JobTerminationHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.JobTerminationHeaders.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.JobTerminationMessageParameters.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.TerminationModeQueryParameter.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.YarnCancelJobTerminationHeaders.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.YarnStopJobTerminationHeaders.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.StoppingException.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskExecutor.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskExecutorGateway.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskmanager.Task.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.webmonitor.RestfulGateway.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.webmonitor.WebMonitorEndpoint.java</file>
      <file type="M">flink-runtime.src.main.scala.org.apache.flink.runtime.messages.JobManagerMessages.scala</file>
      <file type="M">flink-runtime.src.main.scala.org.apache.flink.runtime.messages.TaskControlMessages.scala</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.executiongraph.ExecutionGraphStopTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.executiongraph.utils.SimpleAckingTaskManagerGateway.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.jobmaster.utils.TestingJobMasterGateway.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.jobmaster.utils.TestingJobMasterGatewayBuilder.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskexecutor.TaskExecutorSubmissionTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskexecutor.TestingTaskExecutorGateway.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskmanager.TaskAsyncCallTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.testutils.StoppableInvokable.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.webmonitor.TestingDispatcherGateway.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.webmonitor.TestingRestfulGateway.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.SourceFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamGraph.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StoppableStreamSource.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StoppableSourceStreamTask.java</file>
    </fixedFiles>
  </bug>
  <bug id="11910" opendate="2019-3-13 00:00:00" fixdate="2019-4-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make Yarn Application Type Customizable with Flink Version</summary>
      <description>Internally, our organization support multiple version of Flink in production. It will be more convenient for us to distinguish different version of jobs by using the Application Type. The simple solution is let user to use dynamic properties to set "flink-version". If the property is set, we add it as suffix of "Apache Flink" by default.</description>
      <version>1.6.3,1.6.4,1.7.2</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.cli.FlinkYarnSessionCli.java</file>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.AbstractYarnClusterDescriptor.java</file>
      <file type="M">flink-yarn-tests.src.test.java.org.apache.flink.yarn.YARNSessionFIFOITCase.java</file>
      <file type="M">docs.ops.deployment.yarn.setup.md</file>
    </fixedFiles>
  </bug>
  <bug id="11966" opendate="2019-3-19 00:00:00" fixdate="2019-3-19 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Add support for generating optimized logical plan for simple query(Project, Filter, Values and Union all)</summary>
      <description>Add support for generating optimized logical plan for simple query, 1. Project and Filter: SELECT a, b + 1 FROM MyTable WHERE b &gt; 22. Values: SELECT * FROM (VALUES (1, 2, 3)) AS T(a, b, c)3. Union all: SELECT a, c FROM (SELECT a, c FROM MyTable1 UNION ALL SELECT a, c FROM MyTable2)Union depends on Aggregate to eliminate duplicates, so it will be introduced after Aggregate spported.</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.util.TableTestBase.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.util.RelTreeWriterImpl.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.util.FlinkRelOptUtil.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.rules.FlinkStreamRuleSets.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.rules.FlinkBatchRuleSets.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.optimize.program.FlinkStreamProgram.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.optimize.program.FlinkBatchProgram.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.nodes.logical.FlinkLogicalValues.scala</file>
    </fixedFiles>
  </bug>
  <bug id="12073" opendate="2019-4-1 00:00:00" fixdate="2019-4-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support appropriate precision and scale processing of Decimal in Blink SQL</summary>
      <description>1.Make Decimal's output more precise than random.2.Let Decimal process closer to mainstream databases such as Hive/SqlServer.</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.type.TypeConverters.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.dataformat.DataFormatConverters.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.calcite.FlinkTypeSystem.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.calcite.FlinkTypeFactory.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.api.TableImpl.scala</file>
    </fixedFiles>
  </bug>
  <bug id="12152" opendate="2019-4-10 00:00:00" fixdate="2019-5-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make the vcore that Application Master used configurable for Flink on YARN</summary>
      <description>Now, for Flink on YARN deployment mode, each am's vcores is specified to 1 (hard code).In some scene, we found many Akka timeout logs, the Flink web UI cannot be opened, but it is alive. I think there is no more threads resource to be used for am. So we suggest that make the vcores num of application master can be configurable.</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.configuration.YarnConfigOptions.java</file>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.AbstractYarnClusterDescriptor.java</file>
      <file type="M">docs..includes.generated.yarn.config.configuration.html</file>
    </fixedFiles>
  </bug>
  <bug id="12248" opendate="2019-4-18 00:00:00" fixdate="2019-4-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support e2e over window in blink batch</summary>
      <description>Supporting all major over window operations</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-runtime-blink.src.test.java.org.apache.flink.table.runtime.over.BufferDataOverWindowOperatorTest.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.runtime.over.frame.RowUnboundedPrecedingOverFrame.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.runtime.over.frame.RowUnboundedFollowingOverFrame.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.runtime.over.frame.RowSlidingOverFrame.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.runtime.over.frame.OffsetOverFrame.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.runtime.over.BufferDataOverWindowOperator.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.plan.batch.sql.agg.SortAggregateTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.plan.batch.sql.agg.HashAggregateTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.util.OverAggregateUtil.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.util.AggregateUtil.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.nodes.physical.batch.BatchExecOverAggregate.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.dataview.DataViewUtils.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.codegen.agg.ImperativeAggCodeGen.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.functions.aggfunctions.RankLikeAggFunctionBase.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.functions.aggfunctions.RankAggFunction.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.functions.aggfunctions.DenseRankAggFunction.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.expressions.RexNodeConverter.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.expressions.ExpressionBuilder.java</file>
    </fixedFiles>
  </bug>
  <bug id="12261" opendate="2019-4-19 00:00:00" fixdate="2019-4-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support e2e group window in blink batch</summary>
      <description>1.Add support for generating optimized logical plan for Group window. (Almost same to Legacy runner)2.Let WindowProperty be independent of Expression.3.Introduce batch execution sort group window4.Introduce batch execution hash group window</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.runtime.sort.BinaryKVInMemorySortBuffer.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.runtime.aggregate.BytesHashMap.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.api.TableConfigOptions.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.runtime.utils.BatchTestBase.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.runtime.batch.sql.agg.HashDistinctAggregateITCase.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.runtime.batch.sql.agg.HashAggITCase.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.runtime.batch.sql.agg.DistinctAggregateITCaseBase.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.stream.sql.join.WindowJoinTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.plan.stream.sql.join.WindowJoinTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.util.RelExplainUtil.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.util.AggregateUtil.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.rules.FlinkStreamRuleSets.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.rules.FlinkBatchRuleSets.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.expressions.windowProperties.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.codegen.CodeGeneratorContext.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.codegen.agg.batch.SortAggCodeGenerator.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.codegen.agg.batch.HashAggCodeGenHelper.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.codegen.agg.batch.HashAggCodeGenerator.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.codegen.agg.batch.AggWithoutKeysCodeGenerator.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.codegen.agg.batch.AggCodeGenHelper.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.codegen.agg.AggsHandlerCodeGenerator.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.calcite.FlinkTypeFactory.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.functions.sql.FlinkSqlOperatorTable.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.expressions.RexNodeConverter.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.expressions.ExpressionBuilder.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.expressions.BuiltInFunctionDefinitions.java</file>
    </fixedFiles>
  </bug>
  <bug id="12285" opendate="2019-4-22 00:00:00" fixdate="2019-5-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Memory leak in SavepointITCase and SavepointMigrationTestBase</summary>
      <description>The tests in SavepointITCase and SavepointMigrationTestBase do not cancel running jobs before exit. It will cause exceptions in {{TaskExecutor}}s and unreleased memory segments. Succeeding tests may fail due to insufficient amount of memory.The problem is caused by cancelling {{TaskExecutor}}s with running tasks. Another issue caused by the reason can be seen in FLINK-11343. Maybe we can find a more dedicated method to cancel those {{TaskExecutor}}s still having running tasks.</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.testutils.MiniClusterResource.java</file>
    </fixedFiles>
  </bug>
  <bug id="12296" opendate="2019-4-23 00:00:00" fixdate="2019-5-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Data loss silently in RocksDBStateBackend when more than one operator(has states) chained in a single task</summary>
      <description>As the mail list said&amp;#91;1&amp;#93;, there may be a problem when more than one operator chained in a single task, and all the operators have states, we'll encounter data loss silently problem.Currently, the local directory we used is like below../local_state_root_1/allocation_id/job_id/vertex_id_subtask_idx/chk_1/(state), if more than one operator chained in a single task, and all the operators have states, then all the operators will share the same local directory(because the vertext_id is the same), this will lead a data loss problem.  The path generation logic is below:// LocalRecoveryDirectoryProviderImpl.java@Overridepublic File subtaskSpecificCheckpointDirectory(long checkpointId) { return new File(subtaskBaseDirectory(checkpointId), checkpointDirString(checkpointId));}@VisibleForTestingString subtaskDirString() { return Paths.get("jid_" + jobID, "vtx_" + jobVertexID + "_sti_" + subtaskIndex).toString();}@VisibleForTestingString checkpointDirString(long checkpointId) { return "chk_" + checkpointId;}&amp;#91;1&amp;#93; http://mail-archives.apache.org/mod_mbox/flink-user/201904.mbox/%3Cm2ef5tpfwy.wl-ningshi2@gmail.com%3E</description>
      <version>1.6.3,1.6.4,1.7.2,1.8.0</version>
      <fixedVersion>1.7.3,1.8.1,1.9.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamMockEnvironment.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamConfigChainer.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.OneInputStreamTaskTestHarness.java</file>
      <file type="M">flink-state-backends.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.snapshot.RocksIncrementalSnapshotStrategy.java</file>
      <file type="M">flink-state-backends.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.ttl.mock.MockStateBackend.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.ttl.mock.MockKeyedStateBackendBuilder.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.StateSnapshotCompressionTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.CheckpointStreamWithResultProviderTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="12556" opendate="2019-5-20 00:00:00" fixdate="2019-6-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Extend some end-to-end tests to run with custom (input) File System implementation</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.travis.splits.split.container.sh</file>
      <file type="M">flink-end-to-end-tests.test-scripts.test.yarn.kerberos.docker.sh</file>
      <file type="M">flink-end-to-end-tests.test-scripts.test.docker.embedded.job.sh</file>
      <file type="M">flink-end-to-end-tests.test-scripts.test.batch.wordcount.sh</file>
      <file type="M">flink-end-to-end-tests.run-pre-commit-tests.sh</file>
      <file type="M">flink-end-to-end-tests.run-nightly-tests.sh</file>
      <file type="M">flink-end-to-end-tests.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="12559" opendate="2019-5-20 00:00:00" fixdate="2019-5-20 01:00:00" resolution="Implemented">
    <buginformation>
      <summary>Introduce metadata handlers on window aggregate</summary>
      <description>In FLINK-11822, we have introduced all Flink metadata handlers, several RelNode s (e.g. window aggregate) have not be implemented. So this issue aims to introduce all metadata handlers on window aggregate.</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.stream.sql.agg.OverWindowAggregateTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.metadata.MetadataTestUtil.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.metadata.FlinkRelMdUniqueKeysTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.metadata.FlinkRelMdUniqueGroupsTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.metadata.FlinkRelMdSizeTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.metadata.FlinkRelMdSelectivityTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.metadata.FlinkRelMdRowCountTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.metadata.FlinkRelMdPopulationSizeTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.metadata.FlinkRelMdHandlerTestBase.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.metadata.FlinkRelMdDistinctRowCountTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.metadata.FlinkRelMdColumnUniquenessTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.metadata.FlinkRelMdColumnIntervalTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.batch.sql.agg.OverWindowAggregateTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.plan.stream.sql.agg.OverWindowAggregateTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.plan.rules.logical.FlinkLogicalRankRuleForRangeEndTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.plan.rules.logical.FlinkLogicalRankRuleForConstantRangeTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.plan.batch.sql.DagOptimizationTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.plan.batch.sql.agg.WindowAggregateTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.plan.batch.sql.agg.OverWindowAggregateTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.util.FlinkRelMdUtil.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.util.AggregateUtil.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.rules.physical.stream.StreamExecOverAggregateRule.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.rules.physical.batch.BatchExecOverWindowAggRule.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.rules.logical.FlinkLogicalRankRule.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.rules.FlinkStreamRuleSets.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.rules.FlinkBatchRuleSets.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.nodes.physical.stream.StreamExecGroupWindowAggregate.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.nodes.physical.batch.BatchExecOverAggregate.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.nodes.physical.batch.BatchExecLocalSortWindowAggregate.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.nodes.physical.batch.BatchExecLocalHashWindowAggregate.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.nodes.logical.FlinkLogicalTableFunctionScan.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.nodes.logical.FlinkLogicalOverWindow.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.metadata.FlinkRelMdUniqueKeys.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.metadata.FlinkRelMdUniqueGroups.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.metadata.FlinkRelMdSize.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.metadata.FlinkRelMdSelectivity.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.metadata.FlinkRelMdRowCount.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.metadata.FlinkRelMdPopulationSize.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.metadata.FlinkRelMdModifiedMonotonicity.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.metadata.FlinkRelMdFilteredColumnInterval.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.metadata.FlinkRelMdDistinctRowCount.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.metadata.FlinkRelMdColumnUniqueness.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.metadata.FlinkRelMdColumnInterval.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.metadata.AggCallSelectivityEstimator.scala</file>
    </fixedFiles>
  </bug>
  <bug id="12560" opendate="2019-5-20 00:00:00" fixdate="2019-5-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Documentation language build flags</summary>
      <description>Most documentation writers are only ever focused on one language at a time. Adding language-specific build flags can dramatically reduce render time during local development.</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.README.md</file>
      <file type="M">docs.build.docs.sh</file>
    </fixedFiles>
  </bug>
  <bug id="12607" opendate="2019-5-23 00:00:00" fixdate="2019-3-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Introduce a REST API that returns the maxParallelism of a job</summary>
      <description>Today, Flink does not offer any way to get the maxParallelism for a job and it's operators through any of the REST APIs. Since, the internal state already tracks maxParallelism for a job and it's operators, we should expose this via the REST APIs so that application developer can get more insights on the current state.There can be two approaches on how we can do this -Approach 1 :Modify the existing rest API response model to additionally expose a new field 'maxParallelism'. Some of the REST APIs that would be affected by this/jobs/:jobid/vertices/:vertexid/jobs/:jobid Approach 2 :Create a new REST API that would only return maxParallelism for a job and it's operators.</description>
      <version>1.6.3</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.messages.job.JobDetailsInfoTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.messages.JobVertexDetailsInfoTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.legacy.utils.ArchivedExecutionConfigBuilder.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.job.JobDetailsInfo.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.JobVertexDetailsInfo.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.job.JobDetailsHandler.java</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.interfaces.job-detail.ts</file>
      <file type="M">flink-runtime-web.src.test.resources.rest.api.v1.snapshot</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.ArchivedExecutionConfig.java</file>
      <file type="M">docs.layouts.shortcodes.generated.rest.v1.dispatcher.html</file>
    </fixedFiles>
  </bug>
  <bug id="13403" opendate="2019-7-24 00:00:00" fixdate="2019-7-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Correct package name after relocation</summary>
      <description>some scala classes's package name is not updated after FLINK-13266, this issue aims to correct the package names</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.planner.calcite.FlinkTypeFactoryTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.planner.calcite.CalciteConfigBuilderTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.validate.ValidationResult.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.typeutils.TypeInfoCheckUtils.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.typeutils.TypeCoercion.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.sources.TableSourceUtil.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.plan.TreeNode.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.plan.schema.TableSourceTable.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecTableSourceScan.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.plan.nodes.physical.batch.BatchExecTableSourceScan.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.windowProperties.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.time.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.subquery.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.stringExpressions.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.ReturnTypeInference.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.Reinterpret.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.PlannerExpression.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.ordering.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.mathExpressions.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.logic.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.InputTypeSpec.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.fieldExpression.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.composite.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.comparison.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.collection.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.cast.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.call.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.arithmetic.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.aggregations.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.codegen.calls.ScalarOperatorGens.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.planner.expressions.PlannerTypeInferenceUtilImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="13656" opendate="2019-8-8 00:00:00" fixdate="2019-9-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade Calcite dependency to 1.21</summary>
      <description>Umbrella issue for all tasks related to the next Calcite upgrade to 1.21.x releaseCalcite 1.21 has been released recently, we need to upgrade to version 1.21 for these reasons: Previously we have made some temp code to support full data types in sql parser, since CALCITE-3213 has been resolved, we can do some refactoring for these codes; We also fixed some important bug for Join which bring in from Calcite 1.20 join like expression promotion, such as CALCITE-3170, CALCITE-3171. CALCITE-2302 has been resolved, there is possibility we support implicit type coercion for Flink now.</description>
      <version>None</version>
      <fixedVersion>1.10.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.plan.rules.dataSet.DataSetCalcRule.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.plan.rules.datastream.DataStreamMatchRule.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.plan.nodes.logical.FlinkLogicalMatch.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.plan.nodes.datastream.DataStreamMatch.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.plan.nodes.CommonMatchRecognize.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.plan.logical.MatchRecognize.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.codegen.MatchCodeGenerator.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.calcite.RelTimeIndicatorConverter.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.plan.rules.physical.stream.StreamExecMatchRule.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecMatch.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalMatch.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.plan.logical.MatchRecognize.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.codegen.MatchCodeGenerator.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.codegen.ExprCodeGenerator.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.codegen.calls.ScalarOperatorGens.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.calcite.RelTimeIndicatorConverter.scala</file>
      <file type="M">flink-table.pom.xml</file>
      <file type="M">flink-table.flink-sql-parser.src.test.java.org.apache.flink.sql.parser.FlinkSqlParserImplTest.java</file>
      <file type="M">flink-table.flink-sql-parser.src.test.java.org.apache.flink.sql.parser.FlinkDDLDataTypeTest.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.java.org.apache.flink.sql.parser.type.SqlTimeType.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.java.org.apache.flink.sql.parser.type.SqlTimestampType.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.java.org.apache.flink.sql.parser.type.SqlStringType.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.java.org.apache.flink.sql.parser.type.SqlRowType.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.java.org.apache.flink.sql.parser.type.SqlMultisetType.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.java.org.apache.flink.sql.parser.type.SqlMapType.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.java.org.apache.flink.sql.parser.type.SqlBytesType.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.java.org.apache.flink.sql.parser.type.SqlArrayType.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.java.org.apache.flink.sql.parser.type.ExtendedSqlType.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.java.org.apache.flink.sql.parser.FlinkSqlDataTypeSpec.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.java.org.apache.flink.sql.parser.ExtendedSqlNode.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.java.org.apache.flink.sql.parser.error.SqlParseException.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.java.org.apache.flink.sql.parser.dml.RichSqlInsert.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.java.org.apache.flink.sql.parser.ddl.SqlTableColumn.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.java.org.apache.flink.sql.parser.ddl.SqlCreateView.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.java.org.apache.flink.sql.parser.ddl.SqlCreateTable.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.codegen.includes.parserImpls.ftl</file>
      <file type="M">flink-table.flink-sql-parser.src.main.codegen.data.Parser.tdd</file>
      <file type="M">flink-table.flink-sql-parser.pom.xml</file>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.api.stream.table.AggregateTest.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.api.stream.sql.DistinctAggregateTest.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.api.batch.sql.DistinctAggregateTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.planner.plan.stream.table.AggregateTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.planner.plan.rules.logical.FlinkAggregateRemoveRuleTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.planner.plan.rules.logical.FlinkAggregateExpandDistinctAggregatesRuleTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.planner.plan.rules.logical.AggregateReduceGroupingRuleTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.planner.plan.batch.sql.agg.DistinctAggregateTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.planner.plan.batch.sql.agg.AggregateReduceGroupingTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.planner.plan.rules.logical.FlinkAggregateExpandDistinctAggregatesRule.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.plan.rules.datastream.DataStreamWindowJoinRule.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.plan.rules.datastream.DataStreamValuesRule.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.plan.rules.datastream.DataStreamTemporalTableJoinRule.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.plan.rules.datastream.DataStreamSortRule.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.plan.rules.datastream.DataStreamJoinRule.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.plan.rules.datastream.DataStreamCorrelateRule.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.plan.rules.datastream.DataStreamCalcRule.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.plan.rules.dataSet.DataSetValuesRule.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.plan.rules.dataSet.DataSetSingleRowJoinRule.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.plan.rules.dataSet.DataSetJoinRule.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.plan.rules.dataSet.DataSetDistinctRule.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.plan.rules.dataSet.DataSetCorrelateRule.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.planner.operations.SqlToOperationConverter.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.calcite.FlinkLogicalRelFactories.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.calcite.FlinkPlannerImpl.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.calcite.FlinkRelBuilder.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.calcite.FlinkTypeFactory.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.calcite.FlinkTypeSystem.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.planner.expressions.TemporalTypesTest.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.calcite.sql.validate.SqlValidatorImpl.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.sqlexec.SqlToOperationConverter.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.calcite.FlinkPlannerImpl.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.calcite.FlinkRelBuilder.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.runtime.harness.TemporalJoinHarnessTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.calcite.sql2rel.RelDecorrelator.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.planner.plan.rules.logical.FlinkFilterJoinRule.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.planner.plan.rules.logical.FlinkJoinPushExpressionsRule.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.planner.plan.rules.logical.FlinkJoinToMultiJoinRule.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.plan.rules.FlinkBatchRuleSets.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.plan.rules.FlinkStreamRuleSets.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.plan.utils.FlinkRelOptUtil.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.planner.plan.batch.sql.join.BroadcastHashJoinTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.planner.plan.batch.sql.join.BroadcastHashSemiAntiJoinTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.planner.plan.batch.sql.join.NestedLoopJoinTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.planner.plan.batch.sql.join.NestedLoopSemiAntiJoinTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.planner.plan.batch.sql.join.SemiAntiJoinTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.planner.plan.batch.sql.join.ShuffledHashJoinTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.planner.plan.batch.sql.join.ShuffledHashSemiAntiJoinTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.planner.plan.batch.sql.join.SortMergeJoinTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.planner.plan.batch.sql.join.SortMergeSemiAntiJoinTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.planner.plan.batch.table.JoinTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.planner.plan.rules.logical.FlinkFilterJoinRuleTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.planner.plan.rules.logical.subquery.SubQueryAntiJoinTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.planner.plan.rules.logical.subquery.SubQuerySemiJoinTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.planner.plan.stream.sql.join.JoinTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.planner.plan.stream.sql.join.SemiAntiJoinTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.planner.plan.stream.table.JoinTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.planner.plan.rules.logical.FlinkAggregateJoinTransposeRuleTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.planner.plan.rules.logical.FlinkFilterJoinRuleTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.planner.plan.rules.logical.FlinkJoinToMultiJoinRuleTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.planner.plan.rules.logical.JoinDependentConditionDerivationRuleTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.planner.plan.rules.logical.RewriteMultiJoinConditionRuleTest.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.api.batch.sql.JoinTest.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.api.stream.sql.JoinTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.pom.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-table.flink-table-planner.pom.xml</file>
      <file type="M">flink-table.flink-table-planner.src.main.resources.META-INF.NOTICE</file>
      <file type="M">NOTICE-binary</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.planner.plan.batch.sql.DeadlockBreakupTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.planner.plan.batch.sql.SetOperatorsTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.planner.plan.stream.sql.SetOperatorsTest.xml</file>
    </fixedFiles>
  </bug>
  <bug id="13868" opendate="2019-8-27 00:00:00" fixdate="2019-9-27 01:00:00" resolution="Done">
    <buginformation>
      <summary>Job vertex add taskmanager id in rest api</summary>
      <description>In web, user want to see subtask run in which taskmanager. But now there is no taskmanager's id, user have to judge it by host and port. </description>
      <version>None</version>
      <fixedVersion>1.10.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.messages.job.SubtaskExecutionAttemptDetailsInfoTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.messages.JobVertexDetailsInfoTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandlerTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.job.SubtaskExecutionAttemptDetailsInfo.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.JobVertexDetailsInfo.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler.java</file>
      <file type="M">flink-runtime-web.src.test.resources.rest.api.v1.snapshot</file>
      <file type="M">docs..includes.generated.rest.v1.dispatcher.html</file>
    </fixedFiles>
  </bug>
  <bug id="14590" opendate="2019-11-1 00:00:00" fixdate="2019-12-1 01:00:00" resolution="Resolved">
    <buginformation>
      <summary>Unify the working directory of Java process and Python process when submitting python jobs via "flink run -py"</summary>
      <description>Assume we enter this flink directory with following structure:flink/ bin/ flink pyflink-shell.sh python-gateway-server.sh ... bad_case/ word_count.py data.txt lib/... opt/... And the word_count.py has such a piece of code: t_config = TableConfig() env = StreamExecutionEnvironment.get_execution_environment() t_env = StreamTableEnvironment.create(env, t_config) env._j_stream_execution_environment.registerCachedFile("data", "bad_case/data.txt") with open("bad_case/data.txt", "r") as f: content = f.read() elements = [(word, 1) for word in content.split(" ")] t_env.from_elements(elements, ["word", "count"])Then we enter the "flink" directory and run:bin/flink run -py bad_case/word_count.pyThe program will fail at the line of "with open("bad_case/data.txt", "r") as f:".It is because the working directory of Java process is current directory but the working directory of Python process is a temporary directory.So there is no problem when relative path is used in the api call to java process. But if relative path is used in other place such as native file access, it will fail, because the working directory of python process has been change to a temporary directory that is not known to users.I think it will cause some confusion for users, especially after we support dependency management. It will be great if we unify the working directory of Java process and Python process.</description>
      <version>None</version>
      <fixedVersion>1.10.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-python.src.test.java.org.apache.flink.client.python.PythonDriverEnvUtilsTest.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.client.python.PythonDriverEnvUtils.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.client.python.PythonDriver.java</file>
    </fixedFiles>
  </bug>
  <bug id="14618" opendate="2019-11-5 00:00:00" fixdate="2019-11-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Give more detailed debug information on akka framesize exception</summary>
      <description>I'm hitting the akka framesize limit in production with some regularity, often when the job has been running for a long time and we try to deploy or restart. I suspect it's checkpoint related because clearing the checkpoint enables the job to start up. The Guidance says:If Flink fails because messages exceed this limit, then you should increase it.The error message is not very helpful towards that end. How large does it need to be? How do I know whether increasing the size will fix it, or if the message is unreasonably large due to a bug?I'd like to modify the exception message to report the size of the message we tried to send.This is related to FLINK-4399 but should be a much simpler fix.</description>
      <version>1.6.3</version>
      <fixedVersion>1.10.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rpc.akka.AkkaRpcActorOversizedResponseMessageTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rpc.akka.AkkaInvocationHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="15897" opendate="2020-2-4 00:00:00" fixdate="2020-2-4 01:00:00" resolution="Resolved">
    <buginformation>
      <summary>Defer the deserialization of the Python UDF execution results</summary>
      <description>Currently, the Python UDF execution results are deserialized and then buffered in a collection when received from the Python worker. The deserialization could be deferred when sending the execution results to the downstream operator. That's to say, it buffers the serialized bytes instead of the deserialized Java objects in the buffer. This could reduce the memory footprint of the Java operator.</description>
      <version>None</version>
      <fixedVersion>1.11.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-python.src.test.java.org.apache.flink.table.runtime.operators.python.PythonScalarFunctionOperatorTestBase.java</file>
      <file type="M">flink-python.src.test.java.org.apache.flink.table.runtime.operators.python.PythonScalarFunctionOperatorTest.java</file>
      <file type="M">flink-python.src.test.java.org.apache.flink.table.runtime.operators.python.PassThroughPythonFunctionRunner.java</file>
      <file type="M">flink-python.src.test.java.org.apache.flink.table.runtime.operators.python.BaseRowPythonScalarFunctionOperatorTest.java</file>
      <file type="M">flink-python.src.test.java.org.apache.flink.table.functions.python.PythonScalarFunctionRunnerTest.java</file>
      <file type="M">flink-python.src.test.java.org.apache.flink.table.functions.python.BaseRowPythonScalarFunctionRunnerTest.java</file>
      <file type="M">flink-python.src.test.java.org.apache.flink.table.functions.python.AbstractPythonScalarFunctionRunnerTest.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.table.runtime.runners.python.PythonScalarFunctionRunner.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.table.runtime.runners.python.BaseRowPythonScalarFunctionRunner.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.table.runtime.runners.python.AbstractPythonScalarFunctionRunner.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.table.runtime.operators.python.PythonScalarFunctionOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.table.runtime.operators.python.BaseRowPythonScalarFunctionOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.table.runtime.operators.python.AbstractPythonScalarFunctionOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.table.runtime.functions.python.PythonScalarFunctionFlatMap.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.streaming.api.operators.python.AbstractPythonFunctionOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.python.AbstractPythonFunctionRunner.java</file>
    </fixedFiles>
  </bug>
  <bug id="17107" opendate="2020-4-13 00:00:00" fixdate="2020-4-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CheckpointCoordinatorConfiguration#isExactlyOnce() is inconsistent with StreamConfig#getCheckpointMode()</summary>
      <description>CheckpointCoordinatorConfiguration#isExactlyOnce() is inconsistent with StreamConfig#getCheckpointMode() when checkpoint is disabled. CheckpointCoordinatorConfiguration#isExactlyOnce() returns true if checkpoint mode is  EXACTLY_ONCE mode and return false if checkpoint mode is AT_LEAST_ONCE while StreamConfig#getCheckpointMode() will always return AT_LEAST_ONCE which means always not exactly once.</description>
      <version>1.6.3,1.7.2,1.8.0,1.9.0,1.10.0</version>
      <fixedVersion>1.10.1,1.11.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.graph.StreamingJobGraphGeneratorTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator.java</file>
    </fixedFiles>
  </bug>
</bugrepository>
