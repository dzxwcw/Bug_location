<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="FLINK">
  
  
  <bug fixdate="2021-5-20 01:00:00" id="22373" opendate="2021-4-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add Flink 1.13 release notes</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.content..index.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-7-19 01:00:00" id="2248" opendate="2015-6-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow disabling of sdtout logging output</summary>
      <description>Currently when a job is submitted through the CLI we get in stdout all the log output about each stage in the job.It would useful to have an easy way to disable this output when submitting the job, as most of the time we are only interested in the log output if something goes wrong.</description>
      <version>None</version>
      <fixedVersion>0.9.1,0.10.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-clients.src.test.java.org.apache.flink.client.testjar.WordCount.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.cli.ProgramOptions.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.cli.CliFrontendParser.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.CliFrontend.java</file>
      <file type="M">docs.apis.cli.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2021-5-4 01:00:00" id="22556" opendate="2021-5-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Extend license checker to scan for traces of (L)GPL licensed code</summary>
      <description>This is a follow up to FLINK-22555.The goal is to catch this and similar cases automatically.</description>
      <version>None</version>
      <fixedVersion>1.14.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.ci.java-ci-tools.src.test.java.org.apache.flink.tools.ci.licensecheck.JarFileCheckerTest.java</file>
      <file type="M">tools.ci.java-ci-tools.src.main.java.org.apache.flink.tools.ci.licensecheck.JarFileChecker.java</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2021-5-24 01:00:00" id="22759" opendate="2021-5-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Correct the applicability of RocksDB related options as per operator</summary>
      <description>Hotfix of https://github.com/apache/flink/commit/f93d350e14ce3e56790672740cba91c06a77b940 tries to clarify RocksDB thread options applicability per operator/TM. However, some descriptions are not correct, and this ticket targets to resolve them.</description>
      <version>None</version>
      <fixedVersion>1.14.0,1.13.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-state-backends.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBConfigurableOptions.java</file>
      <file type="M">docs.layouts.shortcodes.generated.rocksdb.configurable.configuration.html</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2021-9-27 01:00:00" id="24023" opendate="2021-8-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>the names of metrics are incomplete</summary>
      <description>we cannot see the total name of metics on the page  because the selected box is too narrow . </description>
      <version>1.12.3</version>
      <fixedVersion>1.15.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.chart.job-overview-drawer-chart.component.html</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2021-12-30 01:00:00" id="24413" opendate="2021-9-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Casting to a CHAR() and VARCHAR() doesn&amp;#39;t trim the string to the specified precision</summary>
      <description>CAST('abcdfe' AS CHAR(3)) should trim the string to 3 chars but currently returns the whole string 'abcdfe'. PostgreSQL and Oracle for example behave as such:postgres=# select '123456afas'::char(4); bpchar -------- 1234 (1 row)postgres=# select '123456afas'::varchar(5); varchar --------- 12345 (1 row)</description>
      <version>None</version>
      <fixedVersion>1.15.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.expressions.ScalarFunctionsTest.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.functions.casting.CastRulesTest.java</file>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.functions.casting.CastRuleProviderTest.java</file>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.functions.CastFunctionITCase.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.calls.IfCallGen.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.functions.casting.TimeToStringCastRule.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.functions.casting.TimestampToStringCastRule.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.functions.casting.RowToStringCastRule.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.functions.casting.RawToStringCastRule.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.functions.casting.NumericToStringCastRule.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.functions.casting.MapAndMultisetToStringCastRule.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.functions.casting.IntervalToStringCastRule.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.functions.casting.DateToStringCastRule.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.functions.casting.CastRuleProvider.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.functions.casting.CastRulePredicate.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.functions.casting.BooleanToStringCastRule.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.functions.casting.BinaryToStringCastRule.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.functions.casting.ArrayToStringCastRule.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.logical.VarCharType.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2021-11-30 01:00:00" id="24414" opendate="2021-9-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Casting a decimal to a String doesn&amp;#39;t do left zero padding</summary>
      <description>CAST(a AS STRING) where a is a DECIMAL(5.3) with value 9.87 results in9.870 so we only get right 0 padding to fill in the fractional digits. Postgres and Oracle also don't do left zero padding.</description>
      <version>None</version>
      <fixedVersion>1.15.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.functions.CastFunctionITCase.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2021-10-30 01:00:00" id="24418" opendate="2021-9-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support cast of RAW() to BINARY/VARBINARY/BYTES</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.15.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.functions.CastFunctionMiscITCase.java</file>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.functions.CastFunctionITCase.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.calls.ScalarOperatorGens.scala</file>
      <file type="M">flink-table.flink-table-common.src.test.java.org.apache.flink.table.types.LogicalTypeCastsTest.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.types.logical.utils.LogicalTypeCasts.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2021-12-30 01:00:00" id="24419" opendate="2021-9-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Casting to a bounded BINARY/VARBINARY doesn&amp;#39;t trim to the specified precision</summary>
      <description>Currently:CastTestSpecBuilder.testCastTo(BINARY(2)).from(STRING(), "Apache").resultsIn(new byte[] {65, 112, 97, 99, 104, 101})</description>
      <version>None</version>
      <fixedVersion>1.15.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.functions.casting.CastRulesTest.java</file>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.functions.CastFunctionMiscITCase.java</file>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.functions.CastFunctionITCase.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.functions.casting.StringToBinaryCastRule.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.functions.casting.RawToBinaryCastRule.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.functions.casting.CastRuleUtils.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.functions.casting.CastRuleProvider.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2021-10-14 01:00:00" id="24546" opendate="2021-10-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Acknowledged description miss on Monitoring Checkpointing page</summary>
      <description>Acknowledged description miss on Monitoring Checkpointing page</description>
      <version>None</version>
      <fixedVersion>1.15.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.content.docs.ops.monitoring.checkpoint.monitoring.md</file>
      <file type="M">docs.content.zh.docs.ops.monitoring.checkpoint.monitoring.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2021-11-27 01:00:00" id="24665" opendate="2021-10-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update Presto Hadoop dependency to latest version</summary>
      <description>The Flink Presto Hadoop dependency com.facebook.presto.hadoop:hadoop-apache2 that Flink uses is rather outdated (released in March 2017). We should upgrade to the latest released version for Hadoop2 (which was released in March 2021)</description>
      <version>None</version>
      <fixedVersion>1.15.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-filesystems.flink-s3-fs-presto.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-filesystems.flink-s3-fs-presto.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-5-16 01:00:00" id="27649" opendate="2022-5-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reduce the number of outputted log lines by Elasticsearch6SinkE2ECase</summary>
      <description>The current ElasticSearch tests create a large number of log lines, see https://dev.azure.com/apache-flink/apache-flink/_build/results?buildId=35694&amp;view=logs&amp;j=af184cdd-c6d8-5084-0b69-7e9c67b35f7a&amp;t=160c9ae5-96fd-516e-1c91-deb81f59292a&amp;l=14702 as an example.We should disable the logging by default.</description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-end-to-end-tests.flink-end-to-end-tests-elasticsearch6.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-10-25 01:00:00" id="2765" opendate="2015-9-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade hbase version for hadoop-2 to 1.2 release</summary>
      <description>Currently 0.98.11 is used: &lt;hbase.hadoop2.version&gt;0.98.11-hadoop2&lt;/hbase.hadoop2.version&gt;Stable release for hadoop-2 is 1.2.x lineWe should upgrade to 1.2.1</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-batch-connectors.flink-hbase.pom.xml</file>
    </fixedFiles>
  </bug>
</bugrepository>