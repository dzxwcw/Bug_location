<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="FLINK">
  
  
  <bug fixdate="2020-3-15 01:00:00" id="19667" opendate="2020-10-15 00:00:00" resolution="Done">
    <buginformation>
      <summary>Add integration with AWS Glue</summary>
      <description>AWS Glue is releasing new features for the AWS Glue Data Catalog. This request is to add a new format to launch an integration for Apache Flink with AWS Glue Data Catalog</description>
      <version>1.11.0,1.11.1,1.11.2,1.11.3</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.maven.suppressions.xml</file>
      <file type="M">tools.azure-pipelines.jobs-template.yml</file>
      <file type="M">tools.azure-pipelines.build-apache-repo.yml</file>
      <file type="M">flink-formats.pom.xml</file>
      <file type="M">flink-end-to-end-tests.test-scripts.common.sh</file>
      <file type="M">flink-end-to-end-tests.run-nightly-tests.sh</file>
      <file type="M">flink-end-to-end-tests.pom.xml</file>
      <file type="M">azure-pipelines.yml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2020-3-16 01:00:00" id="20165" opendate="2020-11-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>YARNSessionFIFOITCase.checkForProhibitedLogContents: Error occurred during initialization of boot layer java.lang.IllegalStateException: Module system already initialized</summary>
      <description>https://dev.azure.com/apache-flink/apache-flink/_build/results?buildId=9597&amp;view=logs&amp;j=298e20ef-7951-5965-0e79-ea664ddc435e&amp;t=8560c56f-9ec1-5c40-4ff5-9d3eaaaa882d2020-11-15T22:42:03.3053212Z 22:42:03,303 [ Time-limited test] INFO org.apache.flink.yarn.YARNSessionFIFOITCase [] - Finished testDetachedMode()2020-11-15T22:42:37.9020133Z [ERROR] Tests run: 5, Failures: 2, Errors: 0, Skipped: 2, Time elapsed: 67.485 s &lt;&lt;&lt; FAILURE! - in org.apache.flink.yarn.YARNSessionFIFOSecuredITCase2020-11-15T22:42:37.9022015Z [ERROR] testDetachedMode(org.apache.flink.yarn.YARNSessionFIFOSecuredITCase) Time elapsed: 12.841 s &lt;&lt;&lt; FAILURE!2020-11-15T22:42:37.9023701Z java.lang.AssertionError: 2020-11-15T22:42:37.9025649Z Found a file /__w/2/s/flink-yarn-tests/target/flink-yarn-tests-fifo-secured/flink-yarn-tests-fifo-secured-logDir-nm-1_0/application_1605480087188_0002/container_1605480087188_0002_01_000002/taskmanager.out with a prohibited string (one of [Exception, Started SelectChannelConnector@0.0.0.0:8081]). Excerpts:2020-11-15T22:42:37.9026730Z [2020-11-15T22:42:37.9027080Z Error occurred during initialization of boot layer2020-11-15T22:42:37.9027623Z java.lang.IllegalStateException: Module system already initialized2020-11-15T22:42:37.9033278Z java.lang.IllegalStateException: Module system already initialized2020-11-15T22:42:37.9033825Z ]2020-11-15T22:42:37.9034291Z at org.junit.Assert.fail(Assert.java:88)2020-11-15T22:42:37.9034971Z at org.apache.flink.yarn.YarnTestBase.ensureNoProhibitedStringInLogFiles(YarnTestBase.java:479)2020-11-15T22:42:37.9035814Z at org.apache.flink.yarn.YARNSessionFIFOITCase.checkForProhibitedLogContents(YARNSessionFIFOITCase.java:83)</description>
      <version>1.11.3,1.13.0</version>
      <fixedVersion>1.11.3,1.12.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.azure-pipelines.build-apache-repo.yml</file>
      <file type="M">azure-pipelines.yml</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  
  <bug fixdate="2021-1-16 01:00:00" id="20997" opendate="2021-1-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>YarnTestBaseTest fails due to NPE</summary>
      <description>YarnTestBase depends on classpaths generated by Maven dependency plugin in `package` phase, but YarnTestBaseTest is a unit test that executed in `test` phase (which is before `package`), so it's unable to find `yarn.classpath` and causes NPE.</description>
      <version>1.11.3,1.12.0</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn-tests.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2021-3-22 01:00:00" id="21103" opendate="2021-1-22 00:00:00" resolution="Duplicate">
    <buginformation>
      <summary>E2e tests time out on azure</summary>
      <description>https://dev.azure.com/apache-flink/apache-flink/_build/results?buildId=12377&amp;view=logs&amp;j=c88eea3b-64a0-564d-0031-9fdcd7b8abee&amp;t=ff888d9b-cd34-53cc-d90f-3e446d355529Creating worker2 ... doneJan 22 13:16:17 Waiting for hadoop cluster to come up. We have been trying for 0 seconds, retrying ...Jan 22 13:16:22 Waiting for hadoop cluster to come up. We have been trying for 5 seconds, retrying ...Jan 22 13:16:27 Waiting for hadoop cluster to come up. We have been trying for 10 seconds, retrying ...Jan 22 13:16:32 Waiting for hadoop cluster to come up. We have been trying for 15 seconds, retrying ...Jan 22 13:16:37 Waiting for hadoop cluster to come up. We have been trying for 20 seconds, retrying ...Jan 22 13:16:43 Waiting for hadoop cluster to come up. We have been trying for 26 seconds, retrying ...Jan 22 13:16:48 Waiting for hadoop cluster to come up. We have been trying for 31 seconds, retrying ...Jan 22 13:16:53 Waiting for hadoop cluster to come up. We have been trying for 36 seconds, retrying ...Jan 22 13:16:58 Waiting for hadoop cluster to come up. We have been trying for 41 seconds, retrying ...Jan 22 13:17:03 Waiting for hadoop cluster to come up. We have been trying for 46 seconds, retrying ...Jan 22 13:17:08 We only have 0 NodeManagers up. We have been trying for 0 seconds, retrying ...21/01/22 13:17:10 INFO client.RMProxy: Connecting to ResourceManager at master.docker-hadoop-cluster-network/172.19.0.3:803221/01/22 13:17:11 INFO client.AHSProxy: Connecting to Application History server at master.docker-hadoop-cluster-network/172.19.0.3:10200Jan 22 13:17:11 We now have 2 NodeManagers up.============================================================================================= WARNING: This E2E Run took already 80% of the allocated time budget of 250 minutes ====================================================================================================================================================================================================== WARNING: This E2E Run will time out in the next few minutes. Starting to upload the log output =========================================================================================================##[error]The task has timed out.Async Command Start: Upload ArtifactUploading 1 filesFile upload succeed.Upload '/tmp/_e2e_watchdog.output.0' to file container: '#/11824779/e2e-timeout-logs'Associated artifact 140921 with build 12377Async Command End: Upload ArtifactAsync Command Start: Upload ArtifactUploading 1 filesFile upload succeed.Upload '/tmp/_e2e_watchdog.output.1' to file container: '#/11824779/e2e-timeout-logs'Associated artifact 140921 with build 12377Async Command End: Upload ArtifactAsync Command Start: Upload ArtifactUploading 1 filesFile upload succeed.Upload '/tmp/_e2e_watchdog.output.2' to file container: '#/11824779/e2e-timeout-logs'Associated artifact 140921 with build 12377Async Command End: Upload ArtifactFinishing: Run e2e tests</description>
      <version>1.11.3,1.12.1,1.13.0</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-end-to-end-tests.run-nightly-tests.sh</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2021-2-28 01:00:00" id="21176" opendate="2021-1-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Translate updates on Confluent Avro Format page</summary>
      <description>We have updated examples in FLINK-20999 in commit 2596c12f7fe6b55bfc8708e1f61d3521703225b3. We should translate the updates to Chinese.</description>
      <version>None</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.content.docs.connectors.table.formats.avro-confluent.md</file>
      <file type="M">docs.content.zh.docs.connectors.table.formats.avro-confluent.md</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2021-3-10 01:00:00" id="21354" opendate="2021-2-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add ChangelogStateBackend (proxy-everything)</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.pom.xml</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.runtime.util.StateConfigUtil.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.InternalTimeServiceManagerImpl.java</file>
      <file type="M">flink-state-backends.pom.xml</file>
      <file type="M">flink-state-backends.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.EmbeddedRocksDBStateBackendTest.java</file>
      <file type="M">flink-state-backends.flink-statebackend-rocksdb.pom.xml</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.ttl.mock.MockKeyedStateBackend.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.StateSnapshotTransformerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.StateBackendTestBase.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.StateBackendLoader.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.KeyedStateBackend.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.heap.HeapKeyedStateBackend.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.CheckpointStorageLoader.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.AbstractKeyedStateBackend.java</file>
      <file type="M">flink-libraries.flink-state-processing-api.pom.xml</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.CheckpointingOptions.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2021-1-15 01:00:00" id="21376" opendate="2021-2-15 00:00:00" resolution="Unresolved">
    <buginformation>
      <summary>Failed state might not provide failureCause</summary>
      <description>Task.executionState and Task.failureCause are not set atomically. This became an issue when implementing the exception history (FLINK-21187) where we relied on the invariant that a failureCause is present when the Task failed.Adding this check to Task.notifyFinalStage() will reveal the race condition.TaskExecutorSlotLifetimeTest becomes unstable when adding this invariant. The reason is that the test starts a task but does not wait for the task to be finished. The task finalization and the cancellation of the task triggered through stopping the TaskManager shutdown compete with each other and could cause the executionState to be set to FAILED while the failureCause still being null. This is then forwarded to Execution through Task.notifyFinalState.We should set failureCause while setting the executionState to failed to not miss any caught error.</description>
      <version>1.11.3,1.12.1,1.13.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.scheduler.adaptive.StopWithSavepoint.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.scheduler.adaptive.Executing.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.failover.flip1.FailureHandlingResult.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2021-7-23 01:00:00" id="21448" opendate="2021-2-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Test Changelog State backend (Wrapper)</summary>
      <description>This is a follow-up ticket for FLINK-21354ChangelogStatebackend is a wrapper on top of the existing state backends. It is necessary to test/enable it by default.However, after ChangelogStatebackend is moved to a different module, it is impossible to enable it by default for all tests due to dependency. However, we do think test coverage for ChangelogStateBackend is valuable in ITTests &amp; End-2-end Tests.This ticket is to address this problem.</description>
      <version>None</version>
      <fixedVersion>1.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-test-utils-parent.flink-test-utils.src.main.java.org.apache.flink.streaming.util.TestStreamEnvironment.java</file>
      <file type="M">flink-test-utils-parent.flink-test-utils.src.test.java.org.apache.flink.streaming.util.PseudoRandomValueSelectorTest.java</file>
      <file type="M">flink-test-utils-parent.flink-test-utils.src.main.java.org.apache.flink.streaming.util.PseudoRandomValueSelector.java</file>
      <file type="M">flink-table.flink-table-planner-blink.pom.xml</file>
      <file type="M">flink-table.flink-sql-client.pom.xml</file>
      <file type="M">flink-streaming-scala.pom.xml</file>
      <file type="M">flink-runtime-web.pom.xml</file>
      <file type="M">flink-queryable-state.flink-queryable-state-runtime.pom.xml</file>
      <file type="M">flink-metrics.flink-metrics-jmx.pom.xml</file>
      <file type="M">flink-libraries.flink-cep.pom.xml</file>
      <file type="M">flink-kubernetes.pom.xml</file>
      <file type="M">flink-fs-tests.pom.xml</file>
      <file type="M">flink-formats.flink-sequence-file.pom.xml</file>
      <file type="M">flink-formats.flink-parquet.pom.xml</file>
      <file type="M">flink-formats.flink-orc.pom.xml</file>
      <file type="M">flink-formats.flink-json.pom.xml</file>
      <file type="M">flink-formats.flink-hadoop-bulk.pom.xml</file>
      <file type="M">flink-formats.flink-csv.pom.xml</file>
      <file type="M">flink-formats.flink-compress.pom.xml</file>
      <file type="M">flink-formats.flink-avro.pom.xml</file>
      <file type="M">flink-examples.flink-examples-table.pom.xml</file>
      <file type="M">flink-examples.flink-examples-streaming.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-rabbitmq.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kinesis.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kafka.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-jdbc.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-hive.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-hbase-1.4.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-files.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch7.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch6.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch5.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-base.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2021-3-8 01:00:00" id="21656" opendate="2021-3-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add antlr parser for hive dialect</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-hive.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2021-1-15 01:00:00" id="21790" opendate="2021-3-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Shuffle data directories to make directory selection of different TaskManagers fairer</summary>
      <description>Currently, different TaskManagers select data directory in the same order and if there are multiple disk, some disks may stores more data than others which is bad for performance. A simple improvement is that each TaskManager shuffles the given data directories randomly and select the data directory in different order.</description>
      <version>None</version>
      <fixedVersion>1.15.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskmanager.NettyShuffleEnvironmentConfiguration.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2021-10-18 01:00:00" id="21853" opendate="2021-3-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Running HA per-job cluster (rocks, non-incremental) end-to-end test could not finished in 900 seconds</summary>
      <description>https://dev.azure.com/apache-flink/apache-flink/_build/results?buildId=14921&amp;view=logs&amp;j=91bf6583-3fb2-592f-e4d4-d79d79c3230a&amp;t=03dbd840-5430-533d-d1a7-05d0ebe03873&amp;l=7318Waiting for text Completed checkpoint [1-9]* for job 00000000000000000000000000000000 to appear 2 of times in logs...grep: /home/vsts/work/1/s/flink-dist/target/flink-1.11-SNAPSHOT-bin/flink-1.11-SNAPSHOT/log/*standalonejob-2*.log: No such file or directorygrep: /home/vsts/work/1/s/flink-dist/target/flink-1.11-SNAPSHOT-bin/flink-1.11-SNAPSHOT/log/*standalonejob-2*.log: No such file or directorygrep: /home/vsts/work/1/s/flink-dist/target/flink-1.11-SNAPSHOT-bin/flink-1.11-SNAPSHOT/log/*standalonejob-2*.log: No such file or directoryStarting standalonejob daemon on host fv-az232-135.grep: /home/vsts/work/1/s/flink-dist/target/flink-1.11-SNAPSHOT-bin/flink-1.11-SNAPSHOT/log/*standalonejob-2*.log: No such file or directoryKilled TM @ 15744Killed TM @ 19625Test (pid: 9232) did not finish after 900 seconds.</description>
      <version>1.11.3,1.13.0</version>
      <fixedVersion>1.13.3,1.14.3,1.15.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-end-to-end-tests.test-scripts.common.ha.sh</file>
      <file type="M">flink-end-to-end-tests.test-scripts.test.ha.per.job.cluster.datastream.sh</file>
      <file type="M">flink-end-to-end-tests.test-scripts.test.ha.datastream.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2021-4-26 01:00:00" id="21986" opendate="2021-3-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>taskmanager native memory not release timely after restart</summary>
      <description>I run a regular join job with flink_1.12.1 , and find taskmanager native memory not release timely after restart cause by exceeded checkpoint tolerable failure threshold.problem job information： job first restart cause by exceeded checkpoint tolerable failure threshold. then taskmanager be killed by yarn many times in this case，tm heap is set to 7.68G，bug all tm heap size is under 4.2G nonheap size increase after restart，but still under 160M. taskmanager process memory increase 3-4G after restart（this figure show one of taskmanager）  my guess：RocksDB wiki mentioned ：Many of the Java Objects used in the RocksJava API will be backed by C++ objects for which the Java Objects have ownership. As C++ has no notion of automatic garbage collection for its heap in the way that Java does, we must explicitly free the memory used by the C++ objects when we are finished with them.So, is it possible that RocksDBStateBackend not call AbstractNativeReference#close() to release memory use by RocksDB C++ Object ?I make a change:        Actively call System.gc() and System.runFinalization() every minute. And run this test again: taskmanager process memory no obvious increase job run for several days，and restart many times，but no taskmanager killed by yarn like before Summary： first，there is some native memory can not release timely after restart in this situation I guess it maybe RocksDB C++ object，but I hive not check it from source code of RocksDBStateBackend </description>
      <version>1.11.3,1.12.1,1.13.0</version>
      <fixedVersion>1.11.4,1.13.0,1.12.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-state-backends.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBOperationUtils.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2021-3-30 01:00:00" id="22051" opendate="2021-3-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Better document the distinction between stop-with-savepoint and stop-with-savepoint-with-drain</summary>
      <description>The Flink documentation only contains very few details about the difference between stop-with-savepoint and stop-with-savepoint-with-drain. We should better explain the semantic differences.</description>
      <version>1.11.3,1.12.2,1.13.0</version>
      <fixedVersion>1.13.0,1.12.3</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.content.docs.deployment.cli.md</file>
      <file type="M">docs.content.zh.docs.deployment.cli.md</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2021-4-27 01:00:00" id="22489" opendate="2021-4-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>subtask backpressure indicator shows value for entire job</summary>
      <description>In the backpressure tab of the web UI, the OK/LOW/HIGH indication is displaying the job-level backpressure for every subtask, rather than the individual subtask values (effectively showing max back pressure from all of the subtasks of the given task for every subtask, instead of the individual values).</description>
      <version>1.9.3,1.10.3,1.11.3,1.12.2,1.13.0</version>
      <fixedVersion>1.11.4,1.14.0,1.13.1,1.12.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.backpressure.job-overview-drawer-backpressure.component.html</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2021-6-6 01:00:00" id="22886" opendate="2021-6-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thread leak in RocksDBStateUploader</summary>
      <description>ExecutorService in RocksDBStateUploader is not shut down, which may leak thread when tasks fail.BTW, we should name the thread group in ExecutorService, otherwise what we see in the stack, is a lot of threads named with pool-m-thread-n like this: </description>
      <version>1.11.3,1.13.1,1.12.4</version>
      <fixedVersion>1.14.0,1.12.5,1.13.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-state-backends.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.EmbeddedRocksDBStateBackendTest.java</file>
      <file type="M">flink-state-backends.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.snapshot.RocksIncrementalSnapshotStrategy.java</file>
      <file type="M">flink-state-backends.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBStateDataTransfer.java</file>
      <file type="M">flink-state-backends.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2021-6-10 01:00:00" id="22957" opendate="2021-6-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Rank TTL should use enableTimeToLive of state instead of timer</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-runtime-blink.src.test.java.org.apache.flink.table.runtime.operators.rank.UpdatableTopNFunctionTest.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.test.java.org.apache.flink.table.runtime.operators.rank.TopNFunctionTestBase.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.test.java.org.apache.flink.table.runtime.operators.rank.RetractableTopNFunctionTest.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.test.java.org.apache.flink.table.runtime.operators.rank.AppendOnlyTopNFunctionTest.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.test.java.org.apache.flink.table.runtime.operators.rank.AppendOnlyFirstNFunctionTest.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.runtime.operators.rank.UpdatableTopNFunction.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.runtime.operators.rank.RetractableTopNFunction.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.runtime.operators.rank.AppendOnlyTopNFunction.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.runtime.operators.rank.AppendOnlyFirstNFunction.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.runtime.operators.rank.AbstractTopNFunction.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecRank.java</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2021-8-27 01:00:00" id="24026" opendate="2021-8-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix FLIP-XXX link can&amp;#39;t be recognized correctly by IDEA</summary>
      <description>In FLINK-24013, we support link for FLINK-XXX to JIRA issue in IDEA git log display. However, the FLIP-XXX is also processed in the same way which leads to a wrong link, e.g. FLIP-33 is linked to https://issues.apache.org/jira/browse/FLIP-33.</description>
      <version>None</version>
      <fixedVersion>1.14.0,1.15.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">.idea.vcs.xml</file>
    </fixedFiles>
  </bug>
</bugrepository>