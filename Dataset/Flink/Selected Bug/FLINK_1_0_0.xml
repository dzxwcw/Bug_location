<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="FLINK">
  
  
  <bug fixdate="2022-5-2 01:00:00" id="27476" opendate="2022-5-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Build new import option that only focus on maven main classes</summary>
      <description>ImportOption.DoNotIncludeTests.class used currently has some issue when running test with testContainer. It would be good to define the target class path precisely.</description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-architecture-tests.flink-architecture-tests-production.src.main.java.org.apache.flink.architecture.rules.ApiAnnotationRules.java</file>
      <file type="M">flink-architecture-tests.flink-architecture-tests-base.src.main.java.org.apache.flink.architecture.common.SourcePredicates.java</file>
      <file type="M">flink-architecture-tests.flink-architecture-tests-base.src.main.java.org.apache.flink.architecture.common.ImportOptions.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2022-7-30 01:00:00" id="28311" opendate="2022-6-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Introduce REST APIs for the environmental information</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.webmonitor.WebMonitorEndpoint.java</file>
      <file type="M">flink-runtime-web.src.test.resources.rest.api.v1.snapshot</file>
      <file type="M">docs.static.generated.rest.v1.dispatcher.yml</file>
      <file type="M">docs.layouts.shortcodes.generated.rest.v1.dispatcher.html</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-7-30 01:00:00" id="28312" opendate="2022-6-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Introduce REST APIs for log URL retrieval</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.webmonitor.WebMonitorEndpoint.java</file>
      <file type="M">flink-runtime-web.src.test.resources.rest.api.v1.snapshot</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.history.HistoryServer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.HistoryServerOptions.java</file>
      <file type="M">docs.static.generated.rest.v1.dispatcher.yml</file>
      <file type="M">docs.layouts.shortcodes.generated.rest.v1.dispatcher.html</file>
      <file type="M">docs.layouts.shortcodes.generated.history.server.configuration.html</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-4-23 01:00:00" id="2909" opendate="2015-10-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Gelly Graph Generators</summary>
      <description>Include a selection of graph generators in Gelly. Generated graphs will be useful for performing scalability, stress, and regression testing as well as benchmarking and comparing algorithms, for both Flink users and developers. Generated data is infinitely scalable yet described by a few simple parameters and can often substitute for user data or sharing large files when reporting issues.There are at multiple categories of graphs as documented by NetworkX and elsewhere.Graphs may be a well-defined, i.e. the Chv√°tal graph. These may be sufficiently small to populate locally.Graphs may be scalable, i.e. complete and star graphs. These should use Flink's distributed parallelism.Graphs may be stochastic, i.e. RMat graphs . A key consideration is that the graphs should source randomness from a seedable PRNG and generate the same Graph regardless of parallelism.</description>
      <version>1.0.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.Utils.java</file>
      <file type="M">docs.page.css.flink.css</file>
      <file type="M">docs.apis.batch.libs.gelly.md</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  <bug fixdate="2015-2-17 01:00:00" id="3025" opendate="2015-11-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Flink Kafka consumer may get stuck due to Kafka/Zookeeper client bug</summary>
      <description>In some cases the Flink kafka consumer might fail due to https://issues.apache.org/jira/browse/KAFKA-824.Subsequently it can happen that the sources gets stuck in a Zookeeper client call (zookeeper bug).A proposed fix would be bumping the zookeeper dependency to a version that includes the fix for this bug.</description>
      <version>0.10.0,1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-connectors.flink-connector-kafka.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2023-1-6 01:00:00" id="30584" opendate="2023-1-6 00:00:00" resolution="Done">
    <buginformation>
      <summary>Update the flame graph doc of subtask level</summary>
      <description>Update the flame graph doc of subtask level</description>
      <version>None</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.content.docs.ops.debugging.flame.graphs.md</file>
      <file type="M">docs.content.zh.docs.ops.debugging.flame.graphs.md</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2015-12-2 01:00:00" id="3098" opendate="2015-12-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cast from Date to Long throw compile error.</summary>
      <description>While cast Date to Long in Table API, the generated code throw comile error. Looks like:Caused by: org.codehaus.commons.compiler.CompileException: Line 33, Column 23: Expression "result$5" is not an rvalue at org.codehaus.janino.UnitCompiler.compileError(UnitCompiler.java:10062) at org.codehaus.janino.UnitCompiler.toRvalueOrCompileException(UnitCompiler.java:5960) at org.codehaus.janino.UnitCompiler.compileContext2(UnitCompiler.java:3172) at org.codehaus.janino.UnitCompiler.access$5400(UnitCompiler.java:182)</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-staging.flink-table.src.test.scala.org.apache.flink.api.scala.table.test.CastingITCase.scala</file>
      <file type="M">flink-staging.flink-table.src.test.java.org.apache.flink.api.java.table.test.CastingITCase.java</file>
      <file type="M">flink-staging.flink-table.src.main.scala.org.apache.flink.api.table.codegen.ExpressionCodeGenerator.scala</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-3-4 01:00:00" id="3115" opendate="2015-12-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update Elasticsearch connector to 2.X</summary>
      <description>The Elasticsearch connector is not up to date anymore. In version 2.X the API changed. The code needs to be adapted. Probably it makes sense to have a new class ElasticsearchSink2.</description>
      <version>0.10.0,0.10.1,1.0.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-connectors.pom.xml</file>
      <file type="M">docs.apis.streaming.connectors.index.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-1-7 01:00:00" id="3135" opendate="2015-12-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add chainable driver for UNARY_NO_OP strategy</summary>
      <description>A chainable driver for UNARY_NO_OP strategy would decrease the serialization overhead in certain situations.Should be fairly easy to implement.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.NoOpDriver.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.DriverStrategy.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-5-9 01:00:00" id="3155" opendate="2015-12-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update Flink docker version to latest stable Flink version</summary>
      <description>It would be nice to always set the Docker Flink binary URL to point to the latest Flink version. Until then, this JIRA keeps track of the updates for releases.</description>
      <version>1.0.0,1.1.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-contrib.docker-flink.Dockerfile</file>
      <file type="M">flink-contrib.docker-flink.docker-compose.yml</file>
      <file type="M">flink-contrib.docker-flink.flink.Dockerfile</file>
      <file type="M">flink-contrib.docker-flink.base.Dockerfile</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-2-10 01:00:00" id="3158" opendate="2015-12-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Shading does not remove google guava from flink-dist fat jar</summary>
      <description>It seems that guava somehow slipped our checks and made it into the flink-dist fat jar again.</description>
      <version>0.10.1,1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-2-11 01:00:00" id="3161" opendate="2015-12-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Externalize cluster start-up and tear-down when available</summary>
      <description>I have been using pdsh, pdcp, and rpdcp to both distribute compiled Flink and to start and stop the TaskManagers. The current shell script initializes TaskManagers one-at-a-time. This is trivial to background but would be unthrottled.From pdsh's archived homepage: "uses a sliding window of threads to execute remote commands, conserving socket resources while allowing some connections to timeout if needed".What other tools could be supported when available?</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-dist.src.main.flink-bin.bin.stop-cluster.sh</file>
      <file type="M">flink-dist.src.main.flink-bin.bin.start-cluster.sh</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2023-5-12 01:00:00" id="31780" opendate="2023-4-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow users to disable "Ensemble tracking" for ZooKeeper</summary>
      <description>In Apache Curator an option to skip ensemble tracking was added since version 5.0.0 (CURATOR-568)This can be useful in certain scenarios in which CuratorFramework is accessing to ZK clusters via load balancer or Virtual IPs. Thus in case Zookeeper of Flink user is running behind LB or Virtual IP ensemble tracking could be disabled too.In case ZooKeeper is hidden under VIP it can return URL during Ensemble Tracking, which would lead to Unresolved Host Exception inside Curator Framework. On Flink level it would lead to cluster restart.Currently HA with ZooKeeper can even lead to the JobManager failure. The scenario of the failure is next: Flink connects to ZooKeeper via configured URL. Ensemble tracking gets a new URL of ensemble, which is not obligatory accessible for Flink, because Zookeeper is under VIP. In case of reconnect Flink fails to Zookeeper, moreover due to "UnresolvedHostException" Flink's jobManager is killed.Acceptance Criteria: Users of Apache Flink has a Zookeeper config option to disable ensemble tracking for ZooKeeper.</description>
      <version>None</version>
      <fixedVersion>1.18.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.util.ZooKeeperUtils.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.HighAvailabilityOptions.java</file>
      <file type="M">docs.layouts.shortcodes.generated.high.availability.configuration.html</file>
      <file type="M">docs.layouts.shortcodes.generated.expert.high.availability.zk.section.html</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2023-5-12 01:00:00" id="31786" opendate="2023-4-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Removing unused HighAvailabilityServices implementations</summary>
      <description/>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.highavailability.TestingManualHighAvailabilityServices.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.highavailability.ManualLeaderService.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2023-4-12 01:00:00" id="31787" opendate="2023-4-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add the explicit ROW constructor to the system function doc</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.18.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.layouts.shortcodes.sql.functions.zh.html</file>
      <file type="M">docs.layouts.shortcodes.sql.functions.html</file>
      <file type="M">docs.data.sql.functions.zh.yml</file>
      <file type="M">docs.data.sql.functions.yml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2023-5-4 01:00:00" id="32000" opendate="2023-5-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expose vertex max parallelism in the WebUI</summary>
      <description>It would be great to expose max parallelism in the vertex detail drawer for debug purposes .</description>
      <version>None</version>
      <fixedVersion>1.18.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.detail.job-overview-drawer-detail.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.detail.job-overview-drawer-detail.component.html</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-1-12 01:00:00" id="3220" opendate="2016-1-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Flink does not start on Hortonworks Sandbox 2.3.2 due to missing class</summary>
      <description>Steps to reproduce: Check out current master build flink mvn clean install -DskipTests -Dhadoop.version=2.7.1.2.3.2.0-2950 -Pvendor-repos start flink ./bin/yarn-session.sh -n 1 failure:[root@sandbox build-target]# ./bin/yarn-session.sh -n 113:29:58,170 WARN org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable13:29:58,709 INFO org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl - Timeline service address: http://sandbox.hortonworks.com:8188/ws/v1/timeline/13:29:58,849 INFO org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at sandbox.hortonworks.com/10.0.2.15:805013:29:59,039 INFO org.apache.flink.yarn.FlinkYarnClient - Using values:13:29:59,040 INFO org.apache.flink.yarn.FlinkYarnClient - TaskManager count = 113:29:59,040 INFO org.apache.flink.yarn.FlinkYarnClient - JobManager memory = 102413:29:59,040 INFO org.apache.flink.yarn.FlinkYarnClient - TaskManager memory = 1024Exception in thread "main" java.lang.NoClassDefFoundError: javax/servlet/Filter at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:800) at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) at java.net.URLClassLoader.defineClass(URLClassLoader.java:449) at java.net.URLClassLoader.access$100(URLClassLoader.java:71) at java.net.URLClassLoader$1.run(URLClassLoader.java:361) at java.net.URLClassLoader$1.run(URLClassLoader.java:355) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:354) at java.lang.ClassLoader.loadClass(ClassLoader.java:425) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308) at java.lang.ClassLoader.loadClass(ClassLoader.java:358) at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:800) at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) at java.net.URLClassLoader.defineClass(URLClassLoader.java:449) at java.net.URLClassLoader.access$100(URLClassLoader.java:71) at java.net.URLClassLoader$1.run(URLClassLoader.java:361) at java.net.URLClassLoader$1.run(URLClassLoader.java:355) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:354) at java.lang.ClassLoader.loadClass(ClassLoader.java:425) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308) at java.lang.ClassLoader.loadClass(ClassLoader.java:358) at org.apache.hadoop.hdfs.DFSConfigKeys.&lt;clinit&gt;(DFSConfigKeys.java:245) at org.apache.hadoop.hdfs.DFSClient$Conf.&lt;init&gt;(DFSClient.java:509) at org.apache.hadoop.hdfs.DFSClient.&lt;init&gt;(DFSClient.java:638) at org.apache.hadoop.hdfs.DFSClient.&lt;init&gt;(DFSClient.java:619) at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:149) at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2653) at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:92) at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2687) at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2669) at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:170) at org.apache.flink.yarn.FlinkYarnClientBase.deployInternal(FlinkYarnClientBase.java:516) at org.apache.flink.yarn.FlinkYarnClientBase.deploy(FlinkYarnClientBase.java:337) at org.apache.flink.client.FlinkYarnSessionCli.run(FlinkYarnSessionCli.java:406) at org.apache.flink.client.FlinkYarnSessionCli.main(FlinkYarnSessionCli.java:348)Caused by: java.lang.ClassNotFoundException: javax.servlet.Filter at java.net.URLClassLoader$1.run(URLClassLoader.java:366) at java.net.URLClassLoader$1.run(URLClassLoader.java:355) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:354) at java.lang.ClassLoader.loadClass(ClassLoader.java:425) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308) at java.lang.ClassLoader.loadClass(ClassLoader.java:358) ... 39 moreThis is a similar issue https://issues.apache.org/jira/browse/FLINK-3032</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-shaded-hadoop.flink-shaded-hadoop2.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2023-6-8 01:00:00" id="32290" opendate="2023-6-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable -XX:+IgnoreUnrecognizedVMOptions</summary>
      <description>We can make our lives a lot easier by enabling IgnoreUnrecognizedVMOptions for all processes. With this we can set add-opens/add-exports independent of what JDK is actually being used, removing a major source of complexity.</description>
      <version>None</version>
      <fixedVersion>1.18.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn.src.test.java.org.apache.flink.yarn.YarnClusterDescriptorTest.java</file>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.YarnClusterDescriptor.java</file>
      <file type="M">flink-test-utils-parent.flink-test-utils.src.main.java.org.apache.flink.test.util.TestProcessBuilder.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.testutils.TestJvmProcess.java</file>
      <file type="M">flink-python.pyflink.pyflink.gateway.server.py</file>
      <file type="M">flink-dist.src.main.flink-bin.bin.config.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-1-15 01:00:00" id="3241" opendate="2016-1-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scala 2.11 Flink binaries pull in Scala 2.10 dependencies</summary>
      <description>A user reported that Flink Scala 2.11 jars depend on Scala 2.10 dependencies. This might be caused by the recent changes to the project structure (removing flink-staging) which broke apparently the Scala version changing scripts.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.deploy.to.maven.sh</file>
      <file type="M">tools.change-scala-version.sh</file>
      <file type="M">flink-quickstart.flink-quickstart-scala.src.main.resources.archetype-resources.pom.xml</file>
      <file type="M">flink-quickstart.flink-quickstart-java.src.main.resources.archetype-resources.pom.xml</file>
      <file type="M">flink-java8.pom.xml</file>
      <file type="M">flink-dist.pom.xml</file>
      <file type="M">docs.quickstart.java.api.quickstart.md</file>
      <file type="M">docs.index.md</file>
      <file type="M">docs.apis.local.execution.md</file>
      <file type="M">docs.apis.batch.index.md</file>
      <file type="M">docs.apis.batch.examples.md</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.explain.PlanJsonParser.java</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.explain.Node.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2023-7-25 01:00:00" id="32430" opendate="2023-6-25 00:00:00" resolution="Implemented">
    <buginformation>
      <summary>Support configuring CatalogStore through flink conf</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.18.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.api.EnvironmentTest.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.catalog.CommonCatalogOptions.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.catalog.CatalogStoreHolder.java</file>
      <file type="M">flink-table.flink-table-api-scala-bridge.src.main.scala.org.apache.flink.table.api.bridge.scala.internal.StreamTableEnvironmentImpl.scala</file>
      <file type="M">flink-table.flink-table-api-java.src.test.java.org.apache.flink.table.catalog.CatalogManagerTest.java</file>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.operations.ddl.CreateCatalogOperation.java</file>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.factories.TableFactoryUtil.java</file>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.api.TableEnvironment.java</file>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.api.internal.TableEnvironmentImpl.java</file>
      <file type="M">flink-table.flink-table-api-java-bridge.src.main.java.org.apache.flink.table.api.bridge.java.internal.StreamTableEnvironmentImpl.java</file>
      <file type="M">flink-table.flink-sql-gateway.src.test.java.org.apache.flink.table.gateway.service.session.SessionManagerImplTest.java</file>
      <file type="M">flink-table.flink-sql-gateway.src.main.java.org.apache.flink.table.gateway.service.context.SessionContext.java</file>
      <file type="M">flink-table.flink-sql-gateway.pom.xml</file>
      <file type="M">flink-python.pyflink.table.tests.test.environment.completeness.py</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2023-7-25 01:00:00" id="32431" opendate="2023-6-25 00:00:00" resolution="Implemented">
    <buginformation>
      <summary>Support configuring CatalogStore in Table API</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.18.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.api.EnvironmentSettings.java</file>
      <file type="M">flink-python.pyflink.table.tests.test.environment.settings.completeness.py</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2023-7-25 01:00:00" id="32433" opendate="2023-6-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add built-in FileCatalogStore</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.18.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-common.src.test.java.org.apache.flink.table.factories.TestCatalogStoreFactory.java</file>
      <file type="M">flink-table.flink-table-common.src.test.java.org.apache.flink.table.factories.FactoryUtilTest.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.factories.FactoryUtil.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.factories.CatalogStoreFactory.java</file>
      <file type="M">flink-table.flink-table-api-java.src.test.java.org.apache.flink.table.catalog.GenericInMemoryCatalogStoreFactoryTest.java</file>
      <file type="M">flink-table.flink-table-api-java.src.main.resources.META-INF.services.org.apache.flink.table.factories.Factory</file>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.catalog.GenericInMemoryCatalogStoreFactory.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-2-17 01:00:00" id="3247" opendate="2016-1-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Kafka Connector unusable with quickstarts - shading issue</summary>
      <description>The Kafka Connector now requires Curator, which is referenced as flink-shaded-curator. The quickstarts make sure it is not packaged into the jar file via exclusions.The curator classes are however only in relocated form in the flink-dist.jar - relocated manually in the flink-runtime project. The connector can thus not use find the Curator classes and fails.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-quickstart.flink-quickstart-scala.src.main.resources.archetype-resources.pom.xml</file>
      <file type="M">flink-quickstart.flink-quickstart-java.src.main.resources.archetype-resources.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2023-7-28 01:00:00" id="32473" opendate="2023-6-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Introduce base interfaces for time travel</summary>
      <description/>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.catalog.ResolvedCatalogTable.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.catalog.DefaultCatalogTable.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.catalog.CatalogTable.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.catalog.Catalog.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2023-9-28 01:00:00" id="32475" opendate="2023-6-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add doc for time travel</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.18.0,1.19.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.content.docs.dev.table.sql.queries.overview.md</file>
      <file type="M">docs.content.docs.dev.table.catalogs.md</file>
      <file type="M">docs.content.zh.docs.dev.table.sql.queries.overview.md</file>
      <file type="M">docs.content.zh.docs.dev.table.catalogs.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-2-18 01:00:00" id="3254" opendate="2016-1-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>CombineFunction interface not respected</summary>
      <description>The DataSet API offers a CombineFunction interface, which differs from the GroupCombineFunction interface by being restricted to return a single value instead of returning arbitrary many values through a Collector.The JavaDocs of the GroupCombineFunction point to the CombineFunction interface, advertising it as more efficient.However, the CombineFunction interface is nor respected by Flink, i.e., a GroupReduceFunction that implements this interface is executed without leveraging the combine method.</description>
      <version>0.10.1,1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.GroupReduceOperator.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-2-25 01:00:00" id="3287" opendate="2016-1-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Flink Kafka Consumer fails due to Curator version conflict</summary>
      <description>14:32:38,542 INFO org.apache.flink.yarn.YarnJobManager - Status of job 8eb92c1e3a1c050ecaccd50c6298ac7a (Flink Streaming Job) changed to FAILING.java.lang.NoSuchMethodError: org.apache.curator.utils.ZKPaths.fixForNamespace(Ljava/lang/String;Ljava/lang/String;Z)Ljava/lang/String; at org.apache.curator.framework.imps.NamespaceImpl.fixForNamespace(NamespaceImpl.java:82) at org.apache.curator.framework.imps.NamespaceImpl.newNamespaceAwareEnsurePath(NamespaceImpl.java:87) at org.apache.curator.framework.imps.CuratorFrameworkImpl.newNamespaceAwareEnsurePath(CuratorFrameworkImpl.java:457) at org.apache.flink.streaming.connectors.kafka.internals.ZookeeperOffsetHandler.getOffsetFromZooKeeper(ZookeeperOffsetHandler.java:122) at org.apache.flink.streaming.connectors.kafka.internals.ZookeeperOffsetHandler.seekFetcherToInitialOffsets(ZookeeperOffsetHandler.java:90) at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer.open(FlinkKafkaConsumer.java:401) at org.apache.flink.api.common.functions.util.FunctionUtils.openFunction(FunctionUtils.java:36) at org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.open(AbstractUdfStreamOperator.java:89) at org.apache.flink.streaming.runtime.tasks.StreamTask.openAllOperators(StreamTask.java:305) at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:227) at org.apache.flink.runtime.taskmanager.Task.run(Task.java:567) at java.lang.Thread.run(Thread.java:745)This flink snapshot version was built from master commit c7ada8d785087e0209071a8219ff841006b96639</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-1-25 01:00:00" id="3289" opendate="2016-1-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Double reference to flink-contrib</summary>
      <description>A commit to solve FLINK-1452 introduced the flink-contrib sub-project in the documentation. This other commit to solve FLINK-1712 duplicated the flink-contrib line to specify it as a container of early-stage project.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.internals.general.arch.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-2-28 01:00:00" id="3300" opendate="2016-1-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Concurrency Bug in Yarn JobManager</summary>
      <description>The change to use the async ResourceManager client introduced concurrency problems: The ResourceManager callback threads run and change data structures at the same time as the actor methods, voiding the actor concurrency model.One example that can happen is that the callback tries to start containers while the ContainerLaunchContext is still not set (because the actor method is still in the StartYarnSession method).Bug introducing commit: https://github.com/apache/flink/commit/4e52fe4304566e5239996b3d48290e0c1f0772e8Quick fix could be to revert the commit. Better solution would be to let the callback methods send actor messages to the YobManager, rather than directly acting.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn.src.main.scala.org.apache.flink.yarn.YarnMessages.scala</file>
      <file type="M">flink-yarn.src.main.scala.org.apache.flink.yarn.YarnJobManager.scala</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2016-6-3 01:00:00" id="3323" opendate="2016-2-3 00:00:00" resolution="Done">
    <buginformation>
      <summary>Add documentation for NiFi connector</summary>
      <description>Add Nifi-connector documentation to the "Data Stream / Connectors" web page docs. See also FLINK-3324</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.apis.streaming.connectors.index.md</file>
      <file type="M">docs.apis.streaming.connectors.elasticsearch2.md</file>
      <file type="M">docs.apis.streaming.connectors.elasticsearch.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-2-3 01:00:00" id="3328" opendate="2016-2-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Incorrectly shaded dependencies in flink-runtime</summary>
      <description>There are apparently some dependencies shaded into flink-runtime fat jar that are not relocated. (the flink-runtime jar is now 70 MB)From the output of the shading in flink-dist, it looks as if this concerns at least Zookeeper slf4j jline netty (3.x)Possible more.[WARNING] zookeeper-3.4.6.jar, flink-runtime_2.10-1.0-SNAPSHOT.jar define 440 overlapping classes: [WARNING] - org.apache.zookeeper.server.NettyServerCnxnFactory[WARNING] - org.apache.jute.compiler.JFile[WARNING] - org.apache.zookeeper.server.SessionTracker$Session[WARNING] - org.apache.zookeeper.server.quorum.AuthFastLeaderElection$1[WARNING] - org.apache.jute.compiler.JLong[WARNING] - org.apache.zookeeper.client.ZooKeeperSaslClient$SaslState[WARNING] - org.apache.zookeeper.server.auth.KerberosName$Rule[WARNING] - org.apache.jute.CsvOutputArchive[WARNING] - org.apache.zookeeper.server.quorum.QuorumPeer[WARNING] - org.apache.zookeeper.ZooKeeper$DataWatchRegistration[WARNING] - 430 more...[WARNING] slf4j-api-1.7.7.jar, flink-runtime_2.10-1.0-SNAPSHOT.jar define 24 overlapping classes: [WARNING] - org.slf4j.spi.MarkerFactoryBinder[WARNING] - org.slf4j.helpers.SubstituteLogger[WARNING] - org.slf4j.helpers.BasicMarker[WARNING] - org.slf4j.helpers.Util[WARNING] - org.slf4j.LoggerFactory[WARNING] - org.slf4j.Marker[WARNING] - org.slf4j.helpers.NamedLoggerBase[WARNING] - org.slf4j.Logger[WARNING] - org.slf4j.spi.LocationAwareLogger[WARNING] - org.slf4j.ILoggerFactory[WARNING] - 14 more...[WARNING] jansi-1.4.jar, jline-2.10.4.jar define 23 overlapping classes: [WARNING] - org.fusesource.jansi.Ansi$Erase[WARNING] - org.fusesource.jansi.Ansi[WARNING] - org.fusesource.jansi.AnsiOutputStream[WARNING] - org.fusesource.jansi.internal.CLibrary[WARNING] - org.fusesource.jansi.Ansi$2[WARNING] - org.fusesource.jansi.WindowsAnsiOutputStream[WARNING] - org.fusesource.jansi.AnsiRenderer$Code[WARNING] - org.fusesource.jansi.AnsiConsole[WARNING] - org.fusesource.jansi.Ansi$Attribute[WARNING] - org.fusesource.jansi.internal.Kernel32[WARNING] - 13 more...[WARNING] commons-beanutils-core-1.8.0.jar, commons-collections-3.2.2.jar, commons-beanutils-1.7.0.jar define 10 overlapping classes: [WARNING] - org.apache.commons.collections.FastHashMap$EntrySet[WARNING] - org.apache.commons.collections.ArrayStack[WARNING] - org.apache.commons.collections.FastHashMap$1[WARNING] - org.apache.commons.collections.FastHashMap$KeySet[WARNING] - org.apache.commons.collections.FastHashMap$CollectionView[WARNING] - org.apache.commons.collections.BufferUnderflowException[WARNING] - org.apache.commons.collections.Buffer[WARNING] - org.apache.commons.collections.FastHashMap$CollectionView$CollectionViewIterator[WARNING] - org.apache.commons.collections.FastHashMap$Values[WARNING] - org.apache.commons.collections.FastHashMap[WARNING] flink-streaming-scala_2.10-1.0-SNAPSHOT.jar, flink-core-1.0-SNAPSHOT.jar, flink-runtime_2.10-1.0-SNAPSHOT.jar, flink-java-1.0-SNAPSHOT.jar, flink-streaming-java_2.10-1.0-SNAPSHOT.jar, flink-scala_2.10-1.0-SNAPSHOT.jar, flink-clients_2.10-1.0-SNAPSHOT.jar, flink-optimizer_2.10-1.0-SNAPSHOT.jar, flink-runtime-web_2.10-1.0-SNAPSHOT.jar define 1690 overlapping classes: [WARNING] - org.apache.flink.shaded.com.google.common.collect.LinkedListMultimap[WARNING] - org.apache.flink.shaded.com.google.common.io.ByteSource$AsCharSource[WARNING] - org.apache.flink.shaded.com.google.common.escape.Platform[WARNING] - org.apache.flink.shaded.com.google.common.util.concurrent.Futures$ImmediateFailedCheckedFuture[WARNING] - org.apache.flink.shaded.com.google.common.primitives.SignedBytes$LexicographicalComparator[WARNING] - org.apache.flink.shaded.com.google.common.cache.LocalCache$WriteQueue$2[WARNING] - org.apache.flink.shaded.com.google.common.escape.Escaper$1[WARNING] - org.apache.flink.shaded.com.google.common.collect.MultimapBuilder$SetMultimapBuilder[WARNING] - org.apache.flink.shaded.com.google.common.collect.Ordering$ArbitraryOrdering[WARNING] - org.apache.flink.shaded.com.google.common.collect.Synchronized$SynchronizedAsMapEntries$1[WARNING] - 1680 more...[WARNING] flink-scala_2.10-1.0-SNAPSHOT.jar, flink-java-1.0-SNAPSHOT.jar, flink-streaming-scala_2.10-1.0-SNAPSHOT.jar, flink-runtime_2.10-1.0-SNAPSHOT.jar define 25 overlapping classes: [WARNING] - org.apache.flink.shaded.org.objectweb.asm.Context[WARNING] - org.apache.flink.shaded.org.objectweb.asm.FieldWriter[WARNING] - org.apache.flink.shaded.org.objectweb.asm.TypePath[WARNING] - org.apache.flink.shaded.org.objectweb.asm.Handler[WARNING] - org.apache.flink.shaded.org.objectweb.asm.TypeReference[WARNING] - org.apache.flink.shaded.org.objectweb.asm.signature.SignatureVisitor[WARNING] - org.apache.flink.shaded.org.objectweb.asm.Frame[WARNING] - org.apache.flink.shaded.org.objectweb.asm.FieldVisitor[WARNING] - org.apache.flink.shaded.org.objectweb.asm.ByteVector[WARNING] - org.apache.flink.shaded.org.objectweb.asm.ClassVisitor[WARNING] - 15 more...[WARNING] jline-0.9.94.jar, flink-runtime_2.10-1.0-SNAPSHOT.jar define 35 overlapping classes: [WARNING] - jline.ArgumentCompletor$ArgumentList[WARNING] - jline.UnsupportedTerminal[WARNING] - jline.Terminal[WARNING] - jline.WindowsTerminal$ReplayPrefixOneCharInputStream[WARNING] - jline.History[WARNING] - jline.WindowsTerminal$1[WARNING] - jline.ConsoleReader[WARNING] - jline.ClassNameCompletor[WARNING] - jline.SimpleCompletor$SimpleCompletorFilter[WARNING] - jline.CandidateCycleCompletionHandler[WARNING] - 25 more...[WARNING] netty-3.8.0.Final.jar, flink-runtime_2.10-1.0-SNAPSHOT.jar define 810 overlapping classes: [WARNING] - org.jboss.netty.handler.codec.http.websocketx.WebSocketClientHandshaker[WARNING] - org.jboss.netty.handler.codec.base64.Base64Decoder[WARNING] - org.jboss.netty.channel.socket.nio.NioDatagramPipelineSink$1[WARNING] - org.jboss.netty.util.VirtualExecutorService[WARNING] - org.jboss.netty.util.DefaultObjectSizeEstimator[WARNING] - org.jboss.netty.util.internal.ConcurrentIdentityHashMap$HashEntry[WARNING] - org.jboss.netty.channel.socket.oio.OioDatagramChannel[WARNING] - org.jboss.netty.logging.InternalLoggerFactory[WARNING] - org.jboss.netty.handler.codec.spdy.DefaultSpdyDataFrame[WARNING] - org.jboss.netty.channel.LifeCycleAwareChannelHandler[WARNING] - 800 more...[WARNING] flink-java-1.0-SNAPSHOT.jar, flink-runtime_2.10-1.0-SNAPSHOT.jar define 141 overlapping classes: [WARNING] - org.apache.flink.shaded.org.objectweb.asm.tree.ClassNode[WARNING] - org.apache.flink.shaded.org.objectweb.asm.commons.JSRInlinerAdapter$Instantiation[WARNING] - org.apache.flink.shaded.org.objectweb.asm.tree.analysis.BasicValue[WARNING] - org.apache.flink.shaded.org.objectweb.asm.xml.Processor$SingleDocElement[WARNING] - org.apache.flink.shaded.org.objectweb.asm.tree.TypeAnnotationNode[WARNING] - org.apache.flink.shaded.org.objectweb.asm.commons.CodeSizeEvaluator[WARNING] - org.apache.flink.shaded.org.objectweb.asm.xml.Processor$SAXWriter[WARNING] - org.apache.flink.shaded.org.objectweb.asm.util.TraceFieldVisitor[WARNING] - org.apache.flink.shaded.org.objectweb.asm.xml.Processor$ContentHandlerFactory[WARNING] - org.apache.flink.shaded.org.objectweb.asm.xml.ASMContentHandler$FrameTypeRule[WARNING] - 131 more...[WARNING] commons-beanutils-core-1.8.0.jar, commons-beanutils-1.7.0.jar define 82 overlapping classes: [WARNING] - org.apache.commons.beanutils.Converter[WARNING] - org.apache.commons.beanutils.WrapDynaBean[WARNING] - org.apache.commons.beanutils.converters.IntegerConverter[WARNING] - org.apache.commons.beanutils.locale.LocaleBeanUtilsBean[WARNING] - org.apache.commons.beanutils.locale.converters.DoubleLocaleConverter[WARNING] - org.apache.commons.beanutils.locale.converters.DecimalLocaleConverter[WARNING] - org.apache.commons.beanutils.converters.ShortConverter[WARNING] - org.apache.commons.beanutils.converters.StringArrayConverter[WARNING] - org.apache.commons.beanutils.locale.LocaleConvertUtilsBean[WARNING] - org.apache.commons.beanutils.LazyDynaClass[WARNING] - 72 more...[WARNING] commons-lang3-3.3.2.jar, flink-runtime_2.10-1.0-SNAPSHOT.jar define 217 overlapping classes: [WARNING] - org.apache.commons.lang3.builder.DiffResult[WARNING] - org.apache.commons.lang3.CharRange[WARNING] - org.apache.commons.lang3.builder.ToStringStyle$ShortPrefixToStringStyle[WARNING] - org.apache.commons.lang3.concurrent.ConcurrentException[WARNING] - org.apache.commons.lang3.builder.DiffBuilder$1[WARNING] - org.apache.commons.lang3.builder.DiffBuilder[WARNING] - org.apache.commons.lang3.builder.Diff[WARNING] - org.apache.commons.lang3.time.FastDatePrinter$TwoDigitYearField[WARNING] - org.apache.commons.lang3.ObjectUtils$Null[WARNING] - org.apache.commons.lang3.reflect.MemberUtils[WARNING] - 207 more...</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-shaded-curator.pom.xml</file>
      <file type="M">flink-shaded-curator.flink-shaded-curator-recipes.pom.xml</file>
      <file type="M">flink-runtime.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-6-4 01:00:00" id="3332" opendate="2016-2-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Provide an exactly-once Cassandra connector</summary>
      <description>With FLINK-3311, we are adding a Cassandra connector to Flink.It would be good to also provide an "exactly-once" C* connector.I would like to first discuss how we are going to implement this in Flink.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.GenericAtLeastOnceSinkTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.AtLeastOnceSinkTestBase.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.GenericAtLeastOnceSink.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.test.resources.log4j-test.properties</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.test.resources.cassandra.yaml</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.test.java.org.apache.flink.streaming.connectors.cassandra.example.CassandraTupleAtLeastOnceSinkExample.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.test.java.org.apache.flink.streaming.connectors.cassandra.example.CassandraPojoAtLeastOnceSinkExample.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.test.java.org.apache.flink.streaming.connectors.cassandra.example.CassandraIdempotentExactlyOnceSinkExample.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.test.java.org.apache.flink.streaming.connectors.cassandra.CassandraConnectorTest.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.test.java.org.apache.flink.batch.connectors.cassandra.example.BatchExample.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.main.java.org.apache.flink.streaming.connectors.cassandra.ClusterBuilder.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.main.java.org.apache.flink.streaming.connectors.cassandra.CassandraTupleAtLeastOnceSink.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.main.java.org.apache.flink.streaming.connectors.cassandra.CassandraSink.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.main.java.org.apache.flink.streaming.connectors.cassandra.CassandraPojoAtLeastOnceSink.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.main.java.org.apache.flink.streaming.connectors.cassandra.CassandraIdempotentExactlyOnceSink.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.main.java.org.apache.flink.streaming.connectors.cassandra.CassandraCommitter.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.main.java.org.apache.flink.streaming.connectors.cassandra.CassandraAtLeastOnceSink.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.main.java.org.apache.flink.batch.connectors.cassandra.CassandraOutputFormat.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.src.main.java.org.apache.flink.batch.connectors.cassandra.CassandraInputFormat.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-cassandra.pom.xml</file>
      <file type="M">docs.apis.streaming.connectors.cassandra.md</file>
      <file type="M">.travis.yml</file>
      <file type="M">flink-streaming-connectors.pom.xml</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.api.writer.ResultPartitionWriter.java</file>
      <file type="M">docs.apis.streaming.fault.tolerance.md</file>
      <file type="M">docs.apis.streaming.connectors.index.md</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2016-2-7 01:00:00" id="3359" opendate="2016-2-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make RocksDB file copies asynchronous</summary>
      <description>While the incremental backup of the RocksDB files needs to be synchronous, the copying of that file to the backup file system can be fully asynchronous.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.EventTimeWindowCheckpointingITCase.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskAsyncCheckpointTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.OneInputStreamTaskTestHarness.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTaskStateList.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTask.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.StateBackendTestBase.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackendTest.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBValueState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackend.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBReducingState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBListState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBFoldingState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.AbstractRocksDBState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-2-8 01:00:00" id="3367" opendate="2016-2-8 00:00:00" resolution="Done">
    <buginformation>
      <summary>Annotate all user-facing API classes with @Public or @PublicEvolving</summary>
      <description>At the moment, only stable public classes are annotated with @Public. It is not possible to identify whether a non-annotated class is supposed to be API-facing or not.This issue proposes to annotate all API classes either with @Public or @PublicEvolving. Classes which are not annotated belong to Flink's internals.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.InnerJoinOperatorBase.java</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.unfinishedKeyPairOperation.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.UnitSerializer.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.TypeUtils.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.TrySerializer.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.TraversableSerializer.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.OptionSerializer.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.NothingSerializer.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.EnumValueSerializer.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.EnumValueComparator.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.EitherSerializer.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.CaseClassSerializer.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.CaseClassComparator.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.joinDataSet.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.CrossDataSet.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.codegen.TypeInformationGen.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.codegen.TypeDescriptors.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.codegen.TypeAnalyzer.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.codegen.TreeGen.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.codegen.MacroContextHolder.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.codegen.Counter.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.ClosureCleaner.scala</file>
      <file type="M">flink-scala.src.main.java.org.apache.flink.api.scala.operators.ScalaCsvOutputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.utils.RequiredParametersException.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.utils.RequiredParameters.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.utils.OptionType.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.utils.Option.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.Utils.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sca.UdfAnalyzerUtils.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sca.UdfAnalyzer.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sca.TaggedValue.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sca.NestedMethodAnalyzer.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sca.ModifiedASMFrame.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sca.ModifiedASMAnalyzer.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sca.CodeErrorException.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sca.CodeAnalyzerException.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sampling.ReservoirSamplerWithReplacement.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sampling.ReservoirSamplerWithoutReplacement.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sampling.RandomSampler.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sampling.PoissonSampler.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sampling.IntermediateSampleData.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sampling.DistributedRandomSampler.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sampling.BernoulliSampler.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.UdfOperatorUtils.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.WrappingFunction.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.TwoKeyExtractingMapper.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.TupleWrappingCollector.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.TupleUnwrappingJoiner.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.TupleUnwrappingIterator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.TupleRightUnwrappingJoiner.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.TupleLeftUnwrappingJoiner.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.Tuple3WrappingCollector.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.Tuple3UnwrappingIterator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.PlanUnwrappingSortedReduceGroupOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.PlanUnwrappingSortedGroupCombineOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.PlanUnwrappingReduceOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.PlanUnwrappingReduceGroupOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.PlanUnwrappingGroupCombineOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.PlanRightUnwrappingCoGroupOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.PlanProjectOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.PlanLeftUnwrappingCoGroupOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.PlanFilterOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.PlanBothUnwrappingCoGroupOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.KeyRemovingMapper.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.KeyExtractingMapper.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.translation.CombineToGroupCombineWrapper.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.OperatorTranslation.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.KeyFunctions.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.CoGroupRawOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.TypeSerializerOutputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.TypeSerializerInputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.TupleCsvInputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.TextValueInputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.TextOutputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.TextInputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.SplitDataProperties.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.PrintingOutputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.PrimitiveInputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.PojoCsvInputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.ParallelIteratorInputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.LocalCollectionOutputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.IteratorInputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.CsvOutputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.CsvInputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.io.CollectionInputFormat.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.hadoop.mapred.wrapper.HadoopInputSplit.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.hadoop.mapred.wrapper.HadoopDummyReporter.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.hadoop.mapred.wrapper.HadoopDummyProgressable.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.hadoop.mapred.utils.HadoopUtils.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.hadoop.mapred.HadoopOutputFormatBase.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.hadoop.mapred.HadoopInputFormatBase.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.hadoop.mapreduce.utils.HadoopUtils.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.hadoop.mapreduce.HadoopOutputFormatBase.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.hadoop.mapreduce.HadoopInputFormatBase.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.hadoop.common.HadoopOutputFormatCommonBase.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.hadoop.common.HadoopInputFormatCommonBase.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.functions.SemanticPropUtil.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.functions.SelectByMinFunction.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.functions.SelectByMaxFunction.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.functions.SampleWithFraction.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.functions.SampleInPartition.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.functions.SampleInCoordinator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.functions.IdPartitioner.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.functions.GroupReduceIterator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.functions.FormattingMapper.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.functions.FlatMapIterator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.functions.FirstReducer.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.CollectionEnvironment.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.ClosureCleaner.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.aggregation.UnsupportedAggregationTypeException.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.aggregation.SumAggregationFunction.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.aggregation.MinAggregationFunction.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.aggregation.MaxAggregationFunction.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.aggregation.AggregationFunctionFactory.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.aggregation.AggregationFunction.java</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.ConnectedStreams.scala</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.util.serialization.SimpleStringSchema.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.util.keys.KeySelectorUtil.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.util.FieldAccessor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.TwoInputStreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.TimerException.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTaskStateList.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTaskState.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTaskException.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamIterationTail.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamIterationHead.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.SourceStreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.OperatorChain.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.ExceptionInChainedOperatorException.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.AsynchronousException.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.streamrecord.StreamRecordSerializer.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.streamrecord.StreamRecord.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.streamrecord.StreamElement.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.streamrecord.MultiplexingStreamRecordSerializer.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.partitioner.StreamPartitioner.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.partitioner.ShufflePartitioner.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.partitioner.RescalePartitioner.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.partitioner.RebalancePartitioner.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.partitioner.HashPartitioner.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.partitioner.GlobalPartitioner.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.partitioner.ForwardPartitioner.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.partitioner.CustomPartitionerWrapper.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.partitioner.BroadcastPartitioner.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.NonKeyedWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.KeyMap.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.EvictingWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.EvictingNonKeyedWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.buffers.WindowBufferFactory.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.buffers.WindowBuffer.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.buffers.PreAggregatingHeapWindowBuffer.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.buffers.HeapWindowBuffer.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.buffers.EvictingWindowBuffer.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.AggregatingProcessingTimeWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.AggregatingKeyedTimePanes.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.AccumulatingProcessingTimeWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.AccumulatingKeyedTimePanes.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.AbstractKeyedTimePanes.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.windowing.AbstractAlignedProcessingTimeWindowOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.Triggerable.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.StreamingOperatorMetrics.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.ExtractTimestampsOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.operators.BucketStreamSortOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.StreamTwoInputProcessor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.StreamRecordWriter.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.StreamInputProcessor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.StreamingReader.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.RecordWriterOutput.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.InputGateUtil.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.CheckpointBarrierHandler.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.BufferSpiller.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.BlockingQueueBroker.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.BarrierTracker.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.BarrierBuffer.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.windows.Window.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.windows.TimeWindow.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.windows.GlobalWindow.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.triggers.Trigger.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.triggers.PurgingTrigger.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.triggers.ProcessingTimeTrigger.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.triggers.EventTimeTrigger.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.triggers.DeltaTrigger.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.triggers.CountTrigger.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.triggers.ContinuousProcessingTimeTrigger.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.triggers.ContinuousEventTimeTrigger.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.evictors.TimeEvictor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.evictors.Evictor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.evictors.DeltaEvictor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.evictors.CountEvictor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.assigners.WindowAssigner.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.assigners.TumblingTimeWindows.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.assigners.SlidingTimeWindows.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.windowing.assigners.GlobalWindows.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.watermark.Watermark.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.UnionTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.TwoInputTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.StreamTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.SplitTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.SourceTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.SinkTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.SelectTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.PartitionTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.OneInputTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.FeedbackTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.transformations.CoFeedbackTransformation.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.TimeCharacteristic.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.TwoInputStreamOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.TimestampedCollector.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamSource.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamSink.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamProject.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamMap.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamingRuntimeContext.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamGroupedReduce.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamGroupedFold.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamFlatMap.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamFilter.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamCounter.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.OutputTypeConfigurable.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.Output.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.OneInputStreamOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.co.CoStreamMap.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.co.CoStreamFlatMap.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.ChainingStrategy.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.AbstractStreamOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamNode.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamGraphGenerator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamGraph.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamEdge.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamConfig.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.JSONGenerator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.RichWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.ReduceIterableWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.ReduceIterableAllWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.ReduceApplyWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.ReduceApplyAllWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.PassThroughWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.PassThroughAllWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.FoldApplyWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.FoldApplyAllWindowFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.delta.extractor.FieldsFromTuple.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.delta.extractor.FieldsFromArray.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.delta.extractor.FieldFromTuple.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.delta.extractor.FieldFromArray.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.delta.extractor.Extractor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.delta.extractor.ConcatenatedExtract.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.delta.extractor.ArrayFromTuple.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.delta.ExtractionAwareDeltaFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.delta.EuclideanDistance.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.delta.DeltaFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.windowing.delta.CosineDistance.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.TimestampExtractor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.StatefulSequenceSource.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.SocketTextStreamFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.RichEventTimeSourceFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.MultipleIdsMessageAcknowledgingSourceBase.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.MessageAcknowledgingSourceBase.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.FromSplittableIteratorFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.FromIteratorFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.FromElementsFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.FileSourceFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.FileReadFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.FileMonitoringFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.ConnectorSource.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.WriteSinkFunctionByMillis.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.WriteSinkFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.WriteFormatAsText.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.WriteFormatAsCsv.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.WriteFormat.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.SocketClientSink.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.PrintSinkFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.FileSinkFunctionByMillis.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.sink.FileSinkFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.AscendingTimestampExtractor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.aggregation.SumFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.aggregation.SumAggregator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.aggregation.Comparator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.aggregation.ComparableAggregator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.aggregation.AggregationFunction.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.environment.StreamPlanEnvironment.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.environment.StreamExecutionEnvironmentFactory.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.environment.StreamContextEnvironment.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.StreamProjection.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.collector.selector.OutputSelectorWrapper.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.collector.selector.OutputSelector.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.checkpoint.CheckpointedAsynchronously.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.checkpoint.Checkpointed.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.Visitor.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.Visitable.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.StringUtils.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.SimpleStringUtils.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.SerializedValue.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.ReflectionUtil.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.OperatingSystem.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.NetUtils.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.MutableObjectIterator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.MavenForkNumberPrefixLayout.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.IterableIterator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.InstantiationUtil.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.ExternalProcessRunner.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.ExceptionUtils.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.AbstractID.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.StringValueParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.StringParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.ShortValueParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.ShortParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.LongValueParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.LongParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.IntValueParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.IntParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.FloatValueParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.FloatParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.FieldParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.DoubleValueParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.DoubleParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.ByteValueParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.ByteParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.BooleanValueParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.parser.BooleanParser.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.Pair.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.NullKeyFieldException.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.Key.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.types.JavaToValueConverter.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.SeekableDataOutputView.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.SeekableDataInputView.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.MemoryUtils.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.MemoryType.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.MemorySegmentSource.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.MemorySegmentFactory.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.MemorySegment.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.HybridMemorySegment.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.HeapMemorySegment.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.DataOutputViewStreamWrapper.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.memory.DataInputViewStreamWrapper.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.io.InputSplitAssigner.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.local.LocalFileSystem.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.local.LocalFileStatus.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.local.LocalDataOutputStream.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.local.LocalDataInputStream.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.local.LocalBlockLocation.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.core.fs.HadoopFileSystemWrapper.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.IllegalConfigurationException.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.GlobalConfiguration.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.runtime.kryo.Serializers.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.runtime.KryoUtils.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.java.typeutils.PojoField.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.TypeSerializerFactory.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.TypeSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.TypePairComparatorFactory.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.TypePairComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.TypeComparatorFactory.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.TypeComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.GenericPairComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.CompositeTypeComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.VoidSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.TypeSerializerSingleton.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.StringValueSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.StringSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.StringComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.ShortValueSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.ShortSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.ShortComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.LongValueSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.LongSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.LongComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.IntValueSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.IntSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.IntComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.GenericArraySerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.FloatValueSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.FloatSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.FloatComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.EnumSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.EnumComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.DoubleValueSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.DoubleSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.DoubleComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.DateSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.DateComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.CharValueSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.CharSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.CharComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.ByteValueSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.ByteSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.ByteComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.BooleanValueSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.BooleanSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.BooleanComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.BasicTypeComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.StringArraySerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.ShortPrimitiveArraySerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.ShortPrimitiveArrayComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.PrimitiveArrayComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.LongPrimitiveArraySerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.LongPrimitiveArrayComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.IntPrimitiveArraySerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.IntPrimitiveArrayComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.FloatPrimitiveArraySerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.FloatPrimitiveArrayComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.DoublePrimitiveArraySerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.DoublePrimitiveArrayComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.CharPrimitiveArraySerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.CharPrimitiveArrayComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArrayComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.BooleanPrimitiveArraySerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.array.BooleanPrimitiveArrayComparator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.TaskInfo.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.ValueStateDescriptor.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.ValueState.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.StateDescriptor.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.StateBackend.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.State.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.ReducingStateDescriptor.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.ReducingState.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.OperatorState.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.MergingState.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.ListStateDescriptor.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.ListState.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.FoldingStateDescriptor.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.FoldingState.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.ProgramDescription.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.Program.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.PlanExecutor.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.Plan.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.util.UserCodeWrapper.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.util.UserCodeObjectWrapper.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.util.UserCodeClassWrapper.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.util.TypeComparable.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.util.ListKeyGroupedIterator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.util.JoinHashMap.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.util.FieldSet.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.util.FieldList.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.Union.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.UnaryOperatorInformation.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.SingleInputSemanticProperties.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.SingleInputOperator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.SemanticProperties.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.Ordering.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.OperatorInformation.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.Operator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.Keys.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.IterationOperator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.GenericDataSourceBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.GenericDataSinkBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.DualInputSemanticProperties.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.DualInputOperator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.CompilerHints.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.CollectionExecutor.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.BinaryOperatorInformation.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.SortPartitionOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.ReduceOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.PartitionOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.OuterJoinOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.MapPartitionOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.MapOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.JoinOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.accumulators.AccumulatorHelper.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.accumulators.DoubleCounter.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.accumulators.IntCounter.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.accumulators.LongCounter.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.accumulators.SerializedListAccumulator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.aggregators.Aggregator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.aggregators.AggregatorRegistry.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.aggregators.AggregatorWithName.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.aggregators.ConvergenceCriterion.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.aggregators.DoubleSumAggregator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.aggregators.DoubleZeroConvergence.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.aggregators.LongSumAggregator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.aggregators.LongZeroConvergence.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.ApplicationID.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.CodeAnalysisMode.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.distributions.CommonRangeBoundaries.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.distributions.DataDistribution.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.distributions.RangeBoundaries.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.distributions.SimpleDistribution.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.distributions.SimpleIntegerDistribution.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.distributions.UniformDoubleDistribution.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.distributions.UniformIntegerDistribution.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.util.AbstractRuntimeUDFContext.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.util.CopyingIterator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.util.CopyingListCollector.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.util.FunctionUtils.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.util.ListCollector.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.util.NoOpFunction.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.functions.util.RuntimeUDFContext.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.InvalidProgramException.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.compression.DeflateInflaterInputStreamFactory.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.compression.GzipInflaterInputStreamFactory.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.compression.InflaterInputStreamFactory.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.DefaultInputSplitAssigner.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.GenericCsvInputFormat.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.ParseException.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.ReplicatingInputFormat.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.ReplicatingInputSplitAssigner.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.io.StrictlyLocalAssignment.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.NonSerializableUserCodeException.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.AbstractUdfOperator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.BulkIterationBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.CoGroupOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.CoGroupRawOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.CrossOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.DeltaIterationBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.FilterOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.FlatMapOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.GroupCombineOperatorBase.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.GroupReduceOperatorBase.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-3-9 01:00:00" id="3383" opendate="2016-2-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Separate Maven deployment from CI testing</summary>
      <description>We currently handle our tests and the deployment of the Maven artifacts via Travis CI. Travis has a maximum allowed build time of two hours which we reach nearly every time. By that time, the tests have already been run but the deployment is still undergoing.I propose to remove the Maven deployment from Travis. Instead, we could use Apache's Jenkins service or Apache's Buildbot service to trigger a deployment once a day.</description>
      <version>1.0.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.force-shading.pom.xml</file>
      <file type="M">tools.deploy.to.maven.sh</file>
      <file type="M">pom.xml</file>
      <file type="M">.travis.yml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-4-11 01:00:00" id="3389" opendate="2016-2-11 00:00:00" resolution="Done">
    <buginformation>
      <summary>Add Pre-defined Options settings for RocksDB State backend</summary>
      <description>The RocksDB State Backend performance can be optimized for certain settings (for example running on disk or SSD) with certain options.Since it is hard to tune for users, we should add a set of predefined options for certain settings.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackend.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.OptionsFactory.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-3-12 01:00:00" id="3396" opendate="2016-2-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Job submission Savepoint restore logic flawed</summary>
      <description>When savepoint restoring fails, the thrown Exception fails the execution graph, but the client is not informed about the failure.The expected behaviour is that the submission should be acked with success or failure in any case. With savepoint restore failures, the ack message will be skipped.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.scala.org.apache.flink.runtime.jobmanager.JobManager.scala</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-3-15 01:00:00" id="3398" opendate="2016-2-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Flink Kafka consumer should support auto-commit opt-outs</summary>
      <description>Currently the Kafka source will commit consumer offsets to Zookeeper, either upon a checkpoint if checkpointing is enabled, otherwise periodically based on auto.commit.interval.msIt should be possible to opt-out of committing consumer offsets to Zookeeper. Kafka has this config as auto.commit.enable (0.8) and enable.auto.commit (0.9).</description>
      <version>None</version>
      <fixedVersion>1.3.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.PropertiesUtil.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBaseTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBaseMigrationTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka09FetcherTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.internal.Kafka09Fetcher.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer09.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaConsumer08Test.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka08ITCase.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.8.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer08.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka010FetcherTest.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.main.java.org.apache.flink.streaming.connectors.kafka.internal.Kafka010Fetcher.java</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.src.main.java.org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer010.java</file>
      <file type="M">docs.dev.connectors.kafka.md</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-2-16 01:00:00" id="3416" opendate="2016-2-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[py] .bat files fail when path contains spaces</summary>
      <description/>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-dist.src.main.flink-bin.bin.pyflink3.bat</file>
      <file type="M">flink-dist.src.main.flink-bin.bin.pyflink2.bat</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-2-19 01:00:00" id="3455" opendate="2016-2-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bump Kafka 0.9 connector dependency to Kafka 0.9.0.1</summary>
      <description>The Kafka project released the 0.9.0.1 version.I saw some issues (in our integration tests) while developing the code. My hope is that the upgraded version will improve stability.</description>
      <version>None</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaConsumerTestBase.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.pom.xml</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.9.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaShortRetention09Test.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.9.pom.xml</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaShortRetention08Test.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-2-21 01:00:00" id="3458" opendate="2016-2-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Shading broken in flink-shaded-hadoop</summary>
      <description>The shading in flink-shaded-hadoop relocates the guava dependencies of Hadoop twice.Once under org.apache.flink.shaded.hadoop.com.google and org.apache.flink.shaded.com.google. This causes merge resolution problems when building a fat jar including the flink-shaded-hadoop jar.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-shaded-hadoop.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-2-21 01:00:00" id="3459" opendate="2016-2-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make build SBT compatible</summary>
      <description>The current flink-shaded-hadoop2 dependency is not SBT compatible because it contains commons-collection:3.2.1, commons-beanutils:1.7 and commons-beanutils-core:1.8 dependencies. These dependencies contain overlapping classes which are binary compatible but not binary identical. This is a problem for the SBT assembly plugin which requires binary identity for merging them. Otherwise, the build is aborted. I propose to exclude the conflicting dependencies and use instead the commons-beanutils-bean-collection class which contains only then non-conflicting classes.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-shaded-hadoop.flink-shaded-hadoop2.pom.xml</file>
      <file type="M">flink-core.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-2-21 01:00:00" id="3460" opendate="2016-2-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make flink-streaming-connectors&amp;#39; flink dependencies provided</summary>
      <description>All of the flink-streaming-connectors depend on flink-streaming-java (compile scope). This entails that whenever you have a project which depends on the a connector this will also pull in the heavy-weight flink-streaming-java dependency. If you now build a fat-jar, you have to use exclusion rules to filter them out again.It would be more natural to simply declare the dependencies as provided which will automatically avoid the inclusion in the fat jar with respect to the connector dependency.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-connectors.flink-connector-twitter.pom.xml</file>
      <file type="M">flink-streaming-connectors.flink-connector-rabbitmq.pom.xml</file>
      <file type="M">flink-streaming-connectors.flink-connector-nifi.pom.xml</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.pom.xml</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.9.pom.xml</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.pom.xml</file>
      <file type="M">flink-streaming-connectors.flink-connector-flume.pom.xml</file>
      <file type="M">flink-streaming-connectors.flink-connector-filesystem.pom.xml</file>
      <file type="M">flink-streaming-connectors.flink-connector-elasticsearch.pom.xml</file>
      <file type="M">flink-libraries.flink-ml.pom.xml</file>
      <file type="M">flink-libraries.flink-gelly.pom.xml</file>
      <file type="M">flink-libraries.flink-gelly-scala.pom.xml</file>
      <file type="M">flink-libraries.flink-cep.pom.xml</file>
      <file type="M">flink-batch-connectors.flink-jdbc.pom.xml</file>
      <file type="M">flink-batch-connectors.flink-hcatalog.pom.xml</file>
      <file type="M">flink-batch-connectors.flink-hbase.pom.xml</file>
      <file type="M">flink-batch-connectors.flink-hadoop-compatibility.pom.xml</file>
      <file type="M">flink-batch-connectors.flink-avro.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-2-22 01:00:00" id="3463" opendate="2016-2-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement Calc Support</summary>
      <description/>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.logical.FlinkProjectRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.logical.FlinkFilterRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.FlinkRuleSets.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.dataset.DataSetProjectRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.dataset.DataSetFilterRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.dataset.DataSetCalcRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.logical.FlinkProject.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.logical.FlinkFilter.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetMap.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetFlatMap.scala</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-4-22 01:00:00" id="3469" opendate="2016-2-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve documentation for grouping keys</summary>
      <description>The transformation documentation for "Reduce on DataSet Grouped by KeySelector Function" uses a field expression in the Java example.There are four ways to specify keys and only two have named examples in the documentation. Expand the documentation to cover all cases.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.1,1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.apis.batch.dataset.transformations.md</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-2-23 01:00:00" id="3482" opendate="2016-2-23 00:00:00" resolution="Implemented">
    <buginformation>
      <summary>Implement Union Support</summary>
      <description/>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.table.test.UnionITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.table.test.UnionITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.FlinkRuleSets.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetUnion.scala</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-2-23 01:00:00" id="3483" opendate="2016-2-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Job graph visualization not working properly in OS X Chrome</summary>
      <description>In the Chrome browser on OS X (Version 48.0.2564.116 (64-bit)) the job graph visualization does not work properly. There are no edges displayed in the graph, and dragging the mouse does not move the graph.However, Safari (9.0.3) and Firefox (41.0.2) on OS X do display the job graph visualization properly.This is the example application I used to create the job:package com.bannoimport org.apache.flink.streaming.api.scala._object JobGraphUIProblem extends App { val environment = StreamExecutionEnvironment.getExecutionEnvironment val ints1 = environment.fromElements((1 to 100): _*) val ints2 = environment.fromElements((101 to 200): _*) ints1.union(ints2) .map(_.toString) .print() println(environment.getExecutionPlan) environment.execute("JobGraphUIProblem")}Here is the execution plan json:{ "nodes": [ { "id": 1, "type": "Source: Collection Source", "pact": "Data Source", "contents": "Source: Collection Source", "parallelism": 1 }, { "id": 2, "type": "Source: Collection Source", "pact": "Data Source", "contents": "Source: Collection Source", "parallelism": 1 }, { "id": 4, "type": "Map", "pact": "Operator", "contents": "Map", "parallelism": 8, "predecessors": [ { "id": 1, "ship_strategy": "REBALANCE", "side": "second" }, { "id": 2, "ship_strategy": "REBALANCE", "side": "second" } ] }, { "id": 5, "type": "Sink: Unnamed", "pact": "Data Sink", "contents": "Sink: Unnamed", "parallelism": 8, "predecessors": [ { "id": 4, "ship_strategy": "FORWARD", "side": "second" } ] } ]}</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime-web.web-dashboard.web.js.vendor.js</file>
      <file type="M">flink-runtime-web.web-dashboard.web.js.index.js</file>
      <file type="M">flink-runtime-web.web-dashboard.bower.json</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-3-23 01:00:00" id="3484" opendate="2016-2-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add setSlotSharingGroup documentation</summary>
      <description>The newly introduced setSlotSharingGroup functionality replaces the setNewResourceGroup and isoloateResources API calls. Documentation should be added for the new API calls. Outdated documentation for the old API calls should be removed.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.apis.streaming.index.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-5-24 01:00:00" id="3488" opendate="2016-2-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Kafka08ITCase.testBigRecordJob fails on Travis</summary>
      <description>The test case Kafka08ITCase.testBigRecordJob failed on Travis &amp;#91;1&amp;#93;.&amp;#91;1&amp;#93; https://s3.amazonaws.com/archive.travis-ci.org/jobs/111268604/log.txt</description>
      <version>1.0.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaConsumerTestBase.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-2-24 01:00:00" id="3490" opendate="2016-2-24 00:00:00" resolution="Done">
    <buginformation>
      <summary>Bump Chill version to 0.7.4</summary>
      <description>Chill's version 0.7.3 includes fixes which are relevant for Flink (see release nodes).It would be good to bump Chill to the latest version 0.7.x version (0.7.4) for the 1.0.0 release to include these fixes. Chill 0.7.4's dependency are the same as our current version Chill 0.5.2.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-3-24 01:00:00" id="3496" opendate="2016-2-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Flink-ml tests fail on Windows</summary>
      <description>&amp;#91;INFO&amp;#93; &amp;#8212; maven-surefire-plugin:2.18.1:test (default-test) @ flink-ml_2.10 &amp;#8212;&amp;#91;INFO&amp;#93;&amp;#91;INFO&amp;#93; &amp;#8212; scalatest-maven-plugin:1.0:test (scala-test) @ flink-ml_2.10 &amp;#8212;The system cannot find the file specified.&amp;#91;INFO&amp;#93; ------------------------------------------------------------------------&amp;#91;INFO&amp;#93; BUILD FAILURE&amp;#91;INFO&amp;#93; ------------------------------------------------------------------------&amp;#91;INFO&amp;#93; Total time: 01:03 min&amp;#91;INFO&amp;#93; Finished at: 2016-02-24T12:47:23+01:00&amp;#91;INFO&amp;#93; Final Memory: 28M/506M</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-ml.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-3-24 01:00:00" id="3497" opendate="2016-2-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add SQL scalar functions to Table API</summary>
      <description>In order to use the Table API as ETL tool and prepare for FLINK-2099, we need to add more scalar functions such as trim(), abs(), like(), etc.Calcite implements the most important functions. We can basically forward calls to Calcites built-in runtime functions. Some functions need special treatment because of Flink specifics.I would propose the following steps: Implement TRIM, SUBSTRING as reference design remaining string functions math functions Date/time functions System functions Case function Array functions otherEach step includes implementation, test and documentation.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.ExpressionParser.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.comparison.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.generated.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.CodeGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.ScalarOperators.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.stringExpressions.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.expressions.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.validate.FunctionCatalog.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.mathExpressions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.ScalarFunctions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.BuiltInMethods.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.scala.table.expressionDsl.scala</file>
      <file type="M">docs.dev.table.api.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-3-24 01:00:00" id="3498" opendate="2016-2-24 00:00:00" resolution="Implemented">
    <buginformation>
      <summary>Implement TRIM, SUBSTRING as reference design for Table API</summary>
      <description>As described in FLINK-3497 TRIM and SUBSTRING are the first scalar functions implemented in Calcite and used in Table API.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.test.utils.ExpressionEvaluator.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.test.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.TypeConverter.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.TranslationContext.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.RexNodeTranslator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.parser.ExpressionParser.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.stringExpressions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.CodeGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.ScalarFunctions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.scala.table.expressionDsl.scala</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-2-25 01:00:00" id="3513" opendate="2016-2-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix interplay of automatic Operator UID and Changing name of WindowOperator</summary>
      <description>WindowOperator can have a changing name because it has the TypeSerializer .toString() output in it's name. For some type serializers that don't implement toString() this means that the name changes.This means that savepoint restore does not work for the automatically generated UID.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.graph.StreamingJobGraphGeneratorNodeHashTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-6-29 01:00:00" id="3530" opendate="2016-2-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Kafka09ITCase.testBigRecordJob fails on Travis</summary>
      <description>The test case Kafka09ITCase.testBigRecordJob failed on Travis.https://s3.amazonaws.com/archive.travis-ci.org/jobs/112049279/log.txt</description>
      <version>1.0.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaConsumerTestBase.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-2-29 01:00:00" id="3532" opendate="2016-2-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Flink-gelly-examples jar contains an underscore instead of an hyphen</summary>
      <description>The newly introduced flink-gelly-examples module uses an underscore to separate examples from flink-gelly in it's artifact id. This is not consistent and, thus, the artifact id flink-gelly_examples_2.10 should be changed to flink-gelly-examples_2.10.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-gelly-examples.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-3-29 01:00:00" id="3533" opendate="2016-2-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update the Gelly docs wrt examples and cluster execution</summary>
      <description>Links to examples and cluster execution instructions are currently broken in the Gelly docs.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.1,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.apis.batch.libs.gelly.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-3-29 01:00:00" id="3537" opendate="2016-2-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Faulty code generation for disjunctions</summary>
      <description>The Table API generates conjunction (&amp;&amp;) code for disjunctions (||).</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.table.test.JoinITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.table.test.FilterITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.table.test.FilterITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.ScalarOperators.scala</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-2-29 01:00:00" id="3540" opendate="2016-2-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hadoop 2.6.3 build contains /com/google/common (guava) classes in flink-dist.jar</summary>
      <description>While testing the 1.0.0 RC2, I found that the "flink-dist.jar" contains unshaded guava classes.The dependency tree of "flink-dist" shows where the dependency is coming from[INFO] | \- org.apache.flink:flink-shaded-hadoop2:jar:1.1-SNAPSHOT:compile[INFO] | +- xmlenc:xmlenc:jar:0.52:compile[INFO] | +- commons-codec:commons-codec:jar:1.4:compile[INFO] | +- commons-io:commons-io:jar:2.4:compile[INFO] | +- commons-net:commons-net:jar:3.1:compile[INFO] | +- commons-collections:commons-collections:jar:3.2.2:compile[INFO] | +- javax.servlet:servlet-api:jar:2.5:compile[INFO] | +- org.mortbay.jetty:jetty-util:jar:6.1.26:compile[INFO] | +- com.sun.jersey:jersey-core:jar:1.9:compile[INFO] | +- commons-el:commons-el:jar:1.0:runtime[INFO] | +- commons-logging:commons-logging:jar:1.1.3:compile[INFO] | +- com.jamesmurty.utils:java-xmlbuilder:jar:0.4:compile[INFO] | +- commons-lang:commons-lang:jar:2.6:compile[INFO] | +- commons-configuration:commons-configuration:jar:1.7:compile[INFO] | +- commons-digester:commons-digester:jar:1.8.1:compile[INFO] | +- org.xerial.snappy:snappy-java:jar:1.0.5:compile[INFO] | +- com.google.code.gson:gson:jar:2.2.4:compile[INFO] | +- org.apache.directory.server:apacheds-kerberos-codec:jar:2.0.0-M15:compile[INFO] | +- org.apache.directory.server:apacheds-i18n:jar:2.0.0-M15:compile[INFO] | +- org.apache.directory.api:api-asn1-api:jar:1.0.0-M20:compile[INFO] | +- org.apache.directory.api:api-util:jar:1.0.0-M20:compile[INFO] | +- com.jcraft:jsch:jar:0.1.42:compile[INFO] | +- org.htrace:htrace-core:jar:3.0.4:compile[INFO] | | \- com.google.guava:guava:jar:12.0.1:compile[INFO] | | \- com.google.code.findbugs:jsr305:jar:1.3.9:compile</description>
      <version>None</version>
      <fixedVersion>1.0.0,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-shaded-hadoop.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-6-29 01:00:00" id="3551" opendate="2016-2-29 00:00:00" resolution="Implemented">
    <buginformation>
      <summary>Sync Scala and Java Streaming Examples</summary>
      <description>The Scala Examples lack behind the Java Examples</description>
      <version>1.0.0</version>
      <fixedVersion>1.4.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-examples.flink-examples-streaming.src.test.scala.org.apache.flink.streaming.scala.examples.WindowJoinITCase.scala</file>
      <file type="M">flink-examples.flink-examples-streaming.src.test.java.org.apache.flink.streaming.test.examples.wordcount.WordCountITCase.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.test.java.org.apache.flink.streaming.test.examples.wordcount.PojoExampleITCase.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.test.java.org.apache.flink.streaming.test.examples.windowing.WindowWordCountITCase.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.test.java.org.apache.flink.streaming.test.examples.windowing.SessionWindowingITCase.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.test.java.org.apache.flink.streaming.test.examples.twitter.TwitterStreamITCase.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.test.java.org.apache.flink.streaming.test.examples.ml.IncrementalLearningSkeletonITCase.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.test.java.org.apache.flink.streaming.test.examples.join.WindowJoinITCase.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.test.java.org.apache.flink.streaming.test.examples.iteration.IterateExampleITCase.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.scala.org.apache.flink.streaming.scala.examples.socket.SocketWindowWordCount.scala</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.scala.org.apache.flink.streaming.scala.examples.join.WindowJoin.scala</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.java.org.apache.flink.streaming.examples.wordcount.PojoExample.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.java.org.apache.flink.streaming.examples.windowing.SessionWindowing.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.java.org.apache.flink.streaming.examples.windowing.GroupedProcessingTimeWindowExample.java</file>
      <file type="M">flink-examples.flink-examples-streaming.src.main.java.org.apache.flink.streaming.examples.ml.IncrementalLearningSkeleton.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-3-1 01:00:00" id="3557" opendate="2016-3-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scala DataStream fold method should take fold function in secondary parameter list</summary>
      <description>The current Scala DataStream API offers a fold method. The fold method takes two parameters, the initial value and the fold function. However, both parameters are specified in the same parameter list. This makes it clumsy to provide a multi-line anonymous function as the fold function parameter in Scala. One would have to wrap the function in an additional pair of curly braces. This could be avoided by having a second parameter list which takes the fold function. This would, additionally, be consistent with Scala's collection API.Old stylewindowedStream.fold(("R:", 0), { (acc: (String, Int), v: (String, Int)) =&gt; (acc._1 + v._1, acc._2 + v._2) })vs. new stylewindowedStream.fold(("R:", 0)){ (acc, v) =&gt; (acc._1 + v._1, acc._2 + v._2) }These changes are API breaking.</description>
      <version>1.0.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-scala.src.test.scala.org.apache.flink.streaming.api.scala.WindowFoldITCase.scala</file>
      <file type="M">flink-streaming-scala.src.test.scala.org.apache.flink.streaming.api.scala.DataStreamTest.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.WindowedStream.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.KeyedStream.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.AllWindowedStream.scala</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-3-1 01:00:00" id="3559" opendate="2016-3-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Don&amp;#39;t print pid file check if no active PID</summary>
      <description>If there is a pid file but no alive process for the pids:[INFO] 0 instance(s) of jobmanager are already running on pablo.</description>
      <version>None</version>
      <fixedVersion>1.0.0,1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-dist.src.main.flink-bin.bin.flink-daemon.sh</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2016-3-3 01:00:00" id="3573" opendate="2016-3-3 00:00:00" resolution="Implemented">
    <buginformation>
      <summary>Implement more String functions for Table API</summary>
      <description>Implement the remaining string functions:CHARACTER_LENGTHCONCATUPPERLOWERINITCAPLIKESIMILAR</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.test.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.RexNodeTranslator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.call.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.CodeGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.TrimCallGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.ScalarFunctions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.MethodCallGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.CallGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.scala.table.expressionDsl.scala</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-3-3 01:00:00" id="3574" opendate="2016-3-3 00:00:00" resolution="Implemented">
    <buginformation>
      <summary>Implement math functions for Table API</summary>
      <description>MODEXPPOWERLNLOG10ABS</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.test.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.RexNodeTranslator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.parser.ExpressionParser.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.call.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.arithmetic.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.ScalarFunctions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.scala.table.expressionDsl.scala</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-3-4 01:00:00" id="3577" opendate="2016-3-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Display anchor links when hovering over headers.</summary>
      <description>This is useful to share the document url if display anchor links when hovering over headers. Currently we must scroll up to the TOC, find the section,click it, then copy the url.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">LICENSE</file>
      <file type="M">docs..layouts.base.html</file>
      <file type="M">docs.page.js.codetabs.js</file>
      <file type="M">docs.page.css.flink.css</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-4-4 01:00:00" id="3579" opendate="2016-3-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve String concatenation</summary>
      <description>Concatenation of a String and non-String does not work properly.e.g. f0 + 42 leads to RelBuilder ExceptionExpressionParser does not like f0 + 42.cast(STRING) either.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.table.test.StringExpressionsITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.RexNodeTranslator.scala</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-1-4 01:00:00" id="3580" opendate="2016-3-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reintroduce Date/Time and implement scalar functions for it</summary>
      <description>This task includes:DATETIME_PLUSEXTRACT_DATEFLOORCEILCURRENT_TIMECURRENT_TIMESTAMPLOCALTIMELOCALTIMESTAMP</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.expressions.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.validate.FunctionCatalog.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.time.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.ScalarFunctions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.FloorCeilCallGen.scala</file>
      <file type="M">docs.dev.table.api.md</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.ExpressionsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.sql.ExpressionsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.typeutils.TypeConverter.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.typeutils.TypeCoercion.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.typeutils.TypeCheckUtils.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.FunctionCompiler.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.literals.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.ExpressionParser.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.comparison.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.CodeGenUtils.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.CodeGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.ScalarOperators.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.scala.table.expressionDsl.scala</file>
      <file type="M">docs.apis.table.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-3-7 01:00:00" id="3585" opendate="2016-3-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Deploy scripts don&amp;#39;t support spaces in paths</summary>
      <description/>
      <version>1.0.0,1.1.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.generate.specific.pom.sh</file>
      <file type="M">tools.deploy.to.maven.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-5-8 01:00:00" id="3586" opendate="2016-3-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Risk of data overflow while use sum/count to calculate AVG value</summary>
      <description>Now, we use (sum: Long, count: Long to store AVG partial aggregate data, which may have data overflow risk, we should use unbounded data type(such as BigInteger) to store them for necessary data types.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.aggregate.SumAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.aggregate.MinAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.aggregate.MaxAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.aggregate.CountAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.aggregate.AvgAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.aggregate.AggregateUtil.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.aggregate.Aggregate.scala</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-4-8 01:00:00" id="3587" opendate="2016-3-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bump Calcite version to 1.7.0</summary>
      <description>We currently depend on Calcite 1.5.0. The latest stable release is 1.6.0, but I propose we bump the version to 1.7.0-SNAPSHOT to benefit from latest features. If we do that, we can also get rid of the custom FlinkJoinUnionTransposeRule.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.StreamTableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.FlinkRuleSets.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.dataSet.FlinkFilterAggregateTransposeRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.dataSet.DataSetUnionRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.dataSet.DataSetScanRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.dataSet.DataSetJoinRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.dataSet.DataSetCalcRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.dataSet.DataSetAggregateRule.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.datastream.DataStreamUnion.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.datastream.DataStreamSource.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.datastream.DataStreamRel.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.datastream.DataStreamCalc.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetUnion.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetSource.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetRel.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetJoin.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetCalc.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.CodeGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.BatchTableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.scala.table.StreamTableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.scala.table.BatchTableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.java.table.StreamTableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.java.table.BatchTableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-3-8 01:00:00" id="3591" opendate="2016-3-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace Quickstart K-Means Example by Streaming Example</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.0.1,1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.quickstart.run.example.quickstart.md</file>
      <file type="M">docs.page.img.quickstart-example.result015.png</file>
      <file type="M">docs.page.img.quickstart-example.result008.png</file>
      <file type="M">docs.page.img.quickstart-example.result003.png</file>
      <file type="M">docs.page.img.quickstart-example.kmeans015.png</file>
      <file type="M">docs.page.img.quickstart-example.kmeans008.png</file>
      <file type="M">docs.page.img.quickstart-example.kmeans003.png</file>
      <file type="M">docs.page.img.quickstart-example.jobmanager.kmeans.submit.png</file>
      <file type="M">docs.page.img.quickstart-example.jobmanager.kmeans.execute.png</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-3-8 01:00:00" id="3593" opendate="2016-3-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>DistinctITCase is failing</summary>
      <description>Failed tests: DistinctITCase.testDistinctAfterAggregate:70 Internal error: Error while applying rule DataSetAggregateRule, args [rel#28:FlinkAggregate.FLINK.[](input=rel#27:Subset#5.FLINK.[],group={1})] DistinctITCase.testDistinctAfterAggregate:70 Internal error: Error while applying rule DataSetAggregateRule, args [rel#86:FlinkAggregate.FLINK.[](input=rel#85:Subset#17.FLINK.[],group={1})] DistinctITCase.testDistinct:53 Internal error: Error while applying rule DataSetAggregateRule, args [rel#53:FlinkAggregate.FLINK.[](input=rel#52:Subset#10.FLINK.[],group={1})] DistinctITCase.testDistinct:53 Internal error: Error while applying rule DataSetAggregateRule, args [rel#111:FlinkAggregate.FLINK.[](input=rel#110:Subset#22.FLINK.[],group={1})] DistinctITCase.testDistinctAfterAggregate:56 Internal error: Error while applying rule DataSetAggregateRule, args [rel#28:FlinkAggregate.FLINK.[](input=rel#27:Subset#5.FLINK.[],group={1})] DistinctITCase.testDistinctAfterAggregate:56 Internal error: Error while applying rule DataSetAggregateRule, args [rel#86:FlinkAggregate.FLINK.[](input=rel#85:Subset#17.FLINK.[],group={1})] DistinctITCase.testDistinct:44 Internal error: Error while applying rule DataSetAggregateRule, args [rel#53:FlinkAggregate.FLINK.[](input=rel#52:Subset#10.FLINK.[],group={1})] DistinctITCase.testDistinct:44 Internal error: Error while applying rule DataSetAggregateRule, args [rel#111:FlinkAggregate.FLINK.[](input=rel#110:Subset#22.FLINK.[],group={1})]</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.aggregate.AggregateUtil.scala</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-3-11 01:00:00" id="3603" opendate="2016-3-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Re-enable Table API explain</summary>
      <description>The Table API explain was temporarily disabled to port the Table API on top of Calcite. It should be re-enabled before merge the changes back to the master branch.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.resources.testUnion1.out</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.resources.testUnion0.out</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.resources.testJoin1.out</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.resources.testJoin0.out</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.resources.testFilter1.out</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.resources.testFilter0.out</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.table.test.SqlExplainITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.table.test.SqlExplainITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.table.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.TranslationContext.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetJoin.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetAggregate.scala</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-5-11 01:00:00" id="3607" opendate="2016-3-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Decrease default forkCount for tests</summary>
      <description>I'm seeing many tests failures because of timeouts:https://builds.apache.org/job/flink-ci/1/testReport/The forkCount is set to the aggressive value 1.5C. We should consider to reduce it at least to 1C (1 fork per exposed physical/virtual core). That could improve the test stability.I did another test using 1C on Jenkins and had only one failed test and a decreased run time: https://builds.apache.org/job/flink-ci/2/testReport/1.5C: 1h 57m1C: 1h 35mI'll run some more tests to verify this.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-4-21 01:00:00" id="3638" opendate="2016-3-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Invalid default ports in documentation</summary>
      <description>Documentation has invalid information about ports by default. For example look at `taskmanager.data.port` option. It has default port 6121 in documentation but in code default port set to 0.Please review all ports in documentation and set valid default values.</description>
      <version>1.0.0</version>
      <fixedVersion>1.0.0,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.setup.config.md</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-4-22 01:00:00" id="3654" opendate="2016-3-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Disable Write-Ahead-Log in RocksDB State</summary>
      <description>We do our own checkpointing of the RocksDB database so the WAL is useless to us. Disabling writes to the WAL should give us a very large performance boost.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBValueState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBReducingState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBListState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBFoldingState.java</file>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.AbstractRocksDBState.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-4-23 01:00:00" id="3664" opendate="2016-3-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create a method to easily Summarize a DataSet</summary>
      <description>Here is an example:/** * Summarize a DataSet of Tuples by collecting single pass statistics for all columns */public Tuple summarize()Dataset&lt;Tuple3&lt;Double, String, Boolean&gt;&gt; input = // [...]Tuple3&lt;DoubleColumnSummary,StringColumnSummary,BooleanColumnSummary&gt; summary = input.summarize()summary.getField(0).stddev()summary.getField(1).maxStringLength()</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.util.DataSetUtilsITCase.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.utils.DataSetUtils.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-3-29 01:00:00" id="3676" opendate="2016-3-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>WebClient hasn&amp;#39;t been removed from the docs</summary>
      <description/>
      <version>1.0.0,1.1.0</version>
      <fixedVersion>1.0.0,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-contrib.docker-flink.flink.conf.flink-conf.yaml</file>
      <file type="M">flink-contrib.docker-flink.flink.config-flink.sh</file>
      <file type="M">docs.apis.common.index.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-11-30 01:00:00" id="3680" opendate="2016-3-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove or improve (not set) text in the Job Plan UI</summary>
      <description>When running streaming jobs the UI display (not set) in the UI in a few different places. This is not the case for batch jobs.To illustrate I've included screen shots of the UI for the batch and streaming WordCount examples.</description>
      <version>None</version>
      <fixedVersion>1.1.4,1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobgraph.jsonplan.JsonPlanGenerator.java</file>
      <file type="M">flink-runtime-web.web-dashboard.app.scripts.modules.jobs.jobs.dir.coffee</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2016-4-7 01:00:00" id="3711" opendate="2016-4-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scala fold() example syntax incorrect</summary>
      <description>Scala's KeyedStream#fold which accepts scala.Function2 is defined as a partially appliable function. The documentation, however, is written as if it is a non-partial function.</description>
      <version>1.0.0,1.0.1</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.apis.streaming.index.md</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2016-5-14 01:00:00" id="3754" opendate="2016-4-14 00:00:00" resolution="Implemented">
    <buginformation>
      <summary>Add a validation phase before construct RelNode using TableAPI</summary>
      <description>Unlike sql string's execution, which have a separate validation phase before RelNode construction, Table API lacks the counterparts and the validation is scattered in many places.I suggest to add a single validation phase and detect problems as early as possible.</description>
      <version>1.0.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.stream.table.UnsupportedOpsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.stream.table.UnionITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.expression.utils.ExpressionEvaluator.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.UnionITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.StringExpressionsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.SelectITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.JoinITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.GroupedAggregationsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.FilterITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.ExpressionsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.AggregationsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.TableEnvironmentITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.UnionITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.StringExpressionsITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.SelectITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.JoinITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.GroupedAggregationsITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.FilterITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.ExpressionsITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.AggregationsITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.TableEnvironmentITCase.java</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.TableException.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.TableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.table.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.StreamTableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.RexNodeTranslator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.FlinkPlannerImpl.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.TreeNode.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.ordering.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.logic.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.literals.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.fieldExpression.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.ExpressionParser.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.Expression.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.comparison.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.cast.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.call.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.arithmetic.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.aggregations.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.ExpressionParserException.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.BatchTableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.scala.table.expressionDsl.scala</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2016-4-26 01:00:00" id="3817" opendate="2016-4-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove unused Guava dependency from RocksDB StateBackend</summary>
      <description/>
      <version>1.0.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-4-26 01:00:00" id="3819" opendate="2016-4-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace Guava Preconditions usage in flink-gelly-scala</summary>
      <description/>
      <version>1.0.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-gelly-scala.src.main.scala.org.apache.flink.graph.scala.Graph.scala</file>
      <file type="M">flink-libraries.flink-gelly-scala.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-4-28 01:00:00" id="3840" opendate="2016-4-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>RocksDB local parent dir is polluted with empty folders with random names</summary>
      <description>For some reason when the job starts the rocksdb root dir filled with hundreds of empty folders with random names like:041da1c-5fec-42ed-a69c-298240f1a065 4e6061aa-0c69-4755-a1ad-5ac4dec1d3f0 a7004bd1-778c-4a0f-96d4-9941208d188800db8406-6cb4-46ad-aac9-beeaa3247d16</description>
      <version>1.0.0,1.0.1,1.0.2,1.1.0</version>
      <fixedVersion>1.0.3,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackend.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-7-10 01:00:00" id="3891" opendate="2016-5-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a class containing all supported Table API types</summary>
      <description>In order to make working with the Table API easier. It would be great to have a class that contains the supported types.Such that an expression could look like:.select(42.cast(TableType.INT), 43.cast(TableType.DECIMAL))The constants would map to the original TypeInformation object (in BasicTypeInfo, SqlTimeTypeInfo, etc.).</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.expressions.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.expressions.DecimalTypeTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.expression.TimeTypesTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.ExpressionsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.CastingITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.java.org.apache.flink.api.java.batch.table.CastingITCase.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-6-9 01:00:00" id="4038" opendate="2016-6-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Impossible to set more than 1 JVM argument in env.java.opts</summary>
      <description>The Taskmanager start scripts fail when env.java.opts contains more than 1 jvm opts due to:if [[ $FLINK_TM_MEM_PRE_ALLOCATE == "false" ]] &amp;&amp; [ -z $FLINK_ENV_JAVA_OPTS ]; then-z checks the length of the first argument but it fails if it has more than 1 argument</description>
      <version>1.0.0,1.1.0</version>
      <fixedVersion>1.0.4,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-dist.src.main.flink-bin.bin.taskmanager.sh</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-7-5 01:00:00" id="4151" opendate="2016-7-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Address Travis CI build time: We are exceeding the 2 hours limit</summary>
      <description>We've recently started hitting the two hours limit for Travis CI.I'll look into some approaches to get our build stable again.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">.travis.yml</file>
    </fixedFiles>
  </bug>
  
</bugrepository>