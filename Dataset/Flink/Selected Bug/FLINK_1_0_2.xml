<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="FLINK">
  <bug fixdate="2016-4-20 01:00:00" id="3790" opendate="2016-4-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Rolling File sink does not pick up hadoop configuration</summary>
      <description>In the rolling file sink function, a new hadoop configuration is created to get the FileSystem every time, which completely ignores the hadoop config set in flink-conf.yaml</description>
      <version>1.0.2</version>
      <fixedVersion>1.0.3,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-connectors.flink-connector-filesystem.src.main.java.org.apache.flink.streaming.connectors.fs.SequenceFileWriter.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-filesystem.src.main.java.org.apache.flink.streaming.connectors.fs.RollingSink.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-4-27 01:00:00" id="3835" opendate="2016-4-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>JSON execution plan not helpful to debug plans with KeySelectors</summary>
      <description>The JSON execution plans are not helpful when debugging plans that include join operators with key selectors. For joins with hash join strategy, the driver strategy shows: "Hybrid Hash (build: Key Extractor)" where (build: Key Extractor) shall help to identify the build side of the join. However, if both inputs use KeySelectors, the build side cannot be identified.I propose to add the operator id to the build side information. The same issue applied for cross driver strategies.</description>
      <version>1.0.2,1.1.0</version>
      <fixedVersion>1.0.3,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-optimizer.src.main.java.org.apache.flink.optimizer.plandump.PlanJSONDumpGenerator.java</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.resources.testJoin1.out</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.resources.testJoin0.out</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-5-27 01:00:00" id="3837" opendate="2016-4-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create FLOOR/CEIL function</summary>
      <description>Create the FLOOR/CEIL function for Table API and SQL. They will later be extended in FLINK-3580 to support date and time.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.expression.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.call.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.TrimCallGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.ScalarFunctions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.scala.table.expressionDsl.scala</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-6-27 01:00:00" id="3838" opendate="2016-4-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>CLI parameter parser is munging application params</summary>
      <description>If parameters for an application use a single '-' (e.g. -maxtasks) then the CLI argument parser will munge these, and the app gets passed either just the parameter name (e.g. 'maxtask') if the start of the parameter doesn't match a Flink parameter, or you get two values, with the first value being the part that matched (e.g. '-m') and the second value being the rest (e.g. 'axtasks').The parser should ignore everything after the jar path parameter.Note that using --&lt;parameter name&gt; does seem to work.</description>
      <version>1.0.2,1.0.3</version>
      <fixedVersion>1.0.4,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-clients.src.test.java.org.apache.flink.client.CliFrontendRunTest.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.cli.CliFrontendParser.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-4-28 01:00:00" id="3840" opendate="2016-4-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>RocksDB local parent dir is polluted with empty folders with random names</summary>
      <description>For some reason when the job starts the rocksdb root dir filled with hundreds of empty folders with random names like:041da1c-5fec-42ed-a69c-298240f1a065 4e6061aa-0c69-4755-a1ad-5ac4dec1d3f0 a7004bd1-778c-4a0f-96d4-9941208d188800db8406-6cb4-46ad-aac9-beeaa3247d16</description>
      <version>1.0.0,1.0.1,1.0.2,1.1.0</version>
      <fixedVersion>1.0.3,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-contrib.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackend.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-6-2 01:00:00" id="3859" opendate="2016-5-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add BigDecimal/BigInteger support to Table API</summary>
      <description>Since FLINK-3786 has been solved, we can now start integrating BigDecimal/BigInteger into the Table API.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.runtime.aggregate.SumAggregateTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.runtime.aggregate.MinAggregateTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.runtime.aggregate.MaxAggregateTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.runtime.aggregate.AvgAggregateTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.runtime.aggregate.AggregateTestBase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.expressions.utils.ExpressionEvaluator.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.expressions.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.ExpressionsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.sql.AggregationsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.typeutils.TypeConverter.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.typeutils.TypeCoercion.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.typeutils.TypeCheckUtils.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.TableEnvironment.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.aggregate.SumAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.aggregate.MinAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.aggregate.MaxAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.aggregate.AvgAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.runtime.aggregate.AggregateUtil.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetRel.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.literals.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.ExpressionParser.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.comparison.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.arithmetic.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.CodeGenUtils.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.CodeGenerator.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.ScalarOperators.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.ScalarFunctions.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.FloorCeilCallGen.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.BuiltInMethods.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.scala.table.expressionDsl.scala</file>
      <file type="M">docs.apis.table.md</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-2-12 01:00:00" id="3903" opendate="2016-5-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Homebrew Installation</summary>
      <description>Recently I submitted a formula for apache-flink to the homebrew project. Homebrew simplifies installation on Mac:$ brew install apache-flink...$ flink --versionVersion: 1.0.2, Commit ID: d39af15Updates to the formula are adhoc at the moment. I opened this issue to formalize updating homebrew into the release process. I drafted a procedure doc here:https://gist.github.com/EronWright/b62bd3b192a15be4c200a2542f7c9376Please also consider updating the website documentation to suggest homebrew as an alternate installation method for Mac users.</description>
      <version>None</version>
      <fixedVersion>1.2.1,1.3.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.quickstart.setup.quickstart.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-5-13 01:00:00" id="3912" opendate="2016-5-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Typos in Batch Scala API Documentation</summary>
      <description>In the Batch Guide Documentation, in the Join section there are some small typos/errors for the Scala API.In particular, in the section: Join with Flat-Join Function, "left" is used as "rating", and "right" is used as "weight".Also a parenthesis is missing.</description>
      <version>None</version>
      <fixedVersion>1.0.4,1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.apis.batch.dataset.transformations.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-6-5 01:00:00" id="4025" opendate="2016-6-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add possiblity for the RMQ Streaming Source to customize the queue</summary>
      <description>This patch adds the possibilty for the user of the RabbitMQStreaming Connector to customize the queue which is used. Thereare use-cases in which you want to set custom parameters for thequeue (i.e. TTL of the messages if Flink reboots) or thepossibility to bind the queue to an exchange afterwards.The commit doesn't change the actual behaviour but makes itpossible for users to override the newly create `setupQueue`method and cutomize their implementation. This was not possiblebefore.</description>
      <version>1.0.2</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-connectors.flink-connector-rabbitmq.src.main.java.org.apache.flink.streaming.connectors.rabbitmq.RMQSource.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-7-5 01:00:00" id="4151" opendate="2016-7-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Address Travis CI build time: We are exceeding the 2 hours limit</summary>
      <description>We've recently started hitting the two hours limit for Travis CI.I'll look into some approaches to get our build stable again.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">.travis.yml</file>
    </fixedFiles>
  </bug>
  
</bugrepository>