<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="FLINK">
  <bug fixdate="2014-9-27 01:00:00" id="1072" opendate="2014-8-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Extend Travis testing to more Hadoop versions.</summary>
      <description>http://apache-flink-incubator-mailing-list-archive.1008284.n3.nabble.com/Extend-Travis-CI-build-matrix-td1516.html</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">.travis.yml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2018-11-6 01:00:00" id="10799" opendate="2018-11-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Set -Xms when starting JobManager in YARN mode</summary>
      <description>When start JobManager on Yarn mode, only set -Xmx parameter , add -Xms also to avoid high frequency full gc  at start up phase.</description>
      <version>1.3.3,1.4.2,1.5.5,1.6.2</version>
      <fixedVersion>1.8.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn.src.test.java.org.apache.flink.yarn.YarnClusterDescriptorTest.java</file>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.AbstractYarnClusterDescriptor.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2018-11-13 01:00:00" id="10863" opendate="2018-11-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Assign uids to all operators</summary>
      <description>We should assign uids to operators in the test so that we can also properly test removing operators.</description>
      <version>1.5.5,1.6.2,1.7.0</version>
      <fixedVersion>1.5.6,1.6.3,1.7.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-end-to-end-tests.flink-datastream-allround-test.src.main.java.org.apache.flink.streaming.tests.DataStreamAllroundTestProgram.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2018-12-21 01:00:00" id="10968" opendate="2018-11-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement TaskManager Entrypoint</summary>
      <description>implement the main() entrypoint to start task manager pod.</description>
      <version>None</version>
      <fixedVersion>1.10.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-kubernetes.src.main.java.org.apache.flink.kubernetes.utils.Constants.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-11-26 01:00:00" id="11003" opendate="2018-11-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document of Java Lambda Expressions has a mistake</summary>
      <description>Documentation of Java Lambda Expressions has a mistake which may cause confusion.In the last code block, it presents some way to solve type missing problem.In 15 line:public static class MyTuple2Mapper extends MapFunction&lt;Integer, Integer&gt; {    @Override    public Tuple2&lt;Integer, Integer&gt; map(Integer i){         return Tuple2.of(i, i);     }}The second generic type in MapFunction should be Tuple2&lt;Integer, Integer&gt;</description>
      <version>1.5.5,1.6.2,1.7.0</version>
      <fixedVersion>1.7.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.dev.java.lambdas.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-1-28 01:00:00" id="11023" opendate="2018-11-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update LICENSE and NOTICE files for flink-connectors</summary>
      <description>Similar to FLINK-10987 we should also update the LICENSE and NOTICE files for flink-connectors.</description>
      <version>1.5.5,1.6.2,1.7.0</version>
      <fixedVersion>1.7.2,1.8.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-sql-connector-elasticsearch6.pom.xml</file>
      <file type="M">flink-connectors.flink-sql-connector-kafka.pom.xml</file>
      <file type="M">flink-connectors.flink-sql-connector-kafka-0.9.pom.xml</file>
      <file type="M">flink-connectors.flink-sql-connector-kafka-0.11.pom.xml</file>
      <file type="M">flink-connectors.flink-sql-connector-kafka-0.10.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch5.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch5.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch2.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch2.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-1-5 01:00:00" id="11079" opendate="2018-12-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Skip deployment for flnk-storm-examples</summary>
      <description>Similar to FLINK-10987 we should also update the LICENSE and NOTICE for flink-storm-examples. This project creates several fat example jars that are deployed to maven central.Alternatively we could about dropping these examples.</description>
      <version>1.5.5,1.6.2,1.7.0</version>
      <fixedVersion>1.6.4,1.7.2,1.8.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-contrib.flink-storm-examples.pom.xml</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.ListSerializerSnapshot.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.ListSerializer.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.typeutils.base.CollectionSerializerConfigSnapshot.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-12-12 01:00:00" id="11142" opendate="2018-12-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Undefined behavior in the conversion from DataStream/DataSet to Table</summary>
      <description>When we try to convert DataStream/DataSet to Table. There are two ways of adding schema information, ByName or ByPosition.This feature first proposed in this pr.In ByPosition mode, the current code does not check if the number of fields less than its in  DataStream/DataSet. This may cause undefined behavior, e.g. make a projection in ByPosition mode.We can either fix it by adding some checking or regard this as a feature and just improve the doc to clarify it. In my opinion, the latter way seems better.twalthr Could you take a look at it when you free?</description>
      <version>1.5.5,1.6.2,1.7.0</version>
      <fixedVersion>1.8.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.dev.table.common.md</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2018-1-20 01:00:00" id="11207" opendate="2018-12-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update Apache commons-compress from 1.4.1 to 1.18</summary>
      <description>There is at least one security vulnerability in the current version that we should address by upgrading to 1.18+:https://app.snyk.io/vuln/SNYK-JAVA-ORGAPACHECOMMONS-32473</description>
      <version>1.5.5,1.6.2,1.7.0,1.8.0</version>
      <fixedVersion>1.6.4,1.7.2,1.8.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">NOTICE-binary</file>
      <file type="M">flink-shaded-hadoop.flink-shaded-hadoop2-uber.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-filesystems.flink-swift-fs-hadoop.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-dist.src.main.resources.META-INF.NOTICE</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-1-29 01:00:00" id="11232" opendate="2018-12-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Empty Start Time of sub-task on web dashboard</summary>
      <description/>
      <version>1.5.5,1.6.2,1.6.3,1.7.0,1.7.1</version>
      <fixedVersion>1.6.4,1.7.2,1.8.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.JobVertexDetailsInfo.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-10-20 01:00:00" id="11665" opendate="2019-2-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Flink fails to remove JobGraph from ZK even though it reports it did</summary>
      <description>We recently have seen the following issue with Flink 1.5.5:Given Flink Job ID 1d24cad26843dcebdfca236d5e3ad82a: 1- A job is activated successfully and the job graph added to ZK:Added SubmittedJobGraph(1d24cad26843dcebdfca236d5e3ad82a, null) to ZooKeeper.2- Job is deactivated, Flink reports that the job graph has been successfully removed from ZK and the blob is deleted from the blob server (in this case S3):Removed job graph 1d24cad26843dcebdfca236d5e3ad82a from ZooKeeper.3- JM is later restarted, Flink for some reason attempts to recover the job that it reported earlier it has removed from ZK but since the blob has already been deleted the JM goes into a crash loop. The only way to recover it manually is to remove the job graph entry from ZK:Recovered SubmittedJobGraph(1d24cad26843dcebdfca236d5e3ad82a, null). andorg.apache.flink.fs.s3presto.shaded.com.amazonaws.services.s3.model.AmazonS3Exception: The specified key does not exist. (Service: Amazon S3; Status Code: 404; Error Code: NoSuchKey; Request ID: 1BCDFD83FC4546A2), S3 Extended Request ID: OzZtMbihzCm1LKy99s2+rgUMxyll/xYmL6ouMvU2eo30wuDbUmj/DAWoTCs9pNNCLft0FWqbhTo= (Path: s3://blam-state-staging/flink/default/blob/job_1d24cad26843dcebdfca236d5e3ad82a/blob_p-c51b25cc0b20351f6e32a628bb6e674ee48a273e-ccfa96b0fd795502897c73714185dde3)My question is under what circumstances would this happen? this seems to happen very infrequently but since the consequence is severe (JM crash loop) we'd like to understand how it would happen.This all seems a little similar to https://issues.apache.org/jira/browse/FLINK-9575 but that issue is reported fixed in Flink 1.5.2 and we are already on Flink 1.5.5</description>
      <version>1.5.5,1.6.4,1.7.2,1.8.0</version>
      <fixedVersion>1.10.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.dispatcher.runner.ZooKeeperDefaultDispatcherRunnerTest.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.runtime.leaderelection.ZooKeeperLeaderElectionITCase.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.dispatcher.runner.DispatcherRunnerImpl.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.dispatcher.runner.DispatcherRunner.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.dispatcher.runner.ZooKeeperDispatcherRunnerImplTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.dispatcher.runner.DispatcherRunnerImplNGFactory.java</file>
    </fixedFiles>
  </bug>
</bugrepository>