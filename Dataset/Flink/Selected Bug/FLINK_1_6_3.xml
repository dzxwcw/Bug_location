<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="FLINK">
  <bug fixdate="2018-1-29 01:00:00" id="11232" opendate="2018-12-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Empty Start Time of sub-task on web dashboard</summary>
      <description/>
      <version>1.5.5,1.6.2,1.6.3,1.7.0,1.7.1</version>
      <fixedVersion>1.6.4,1.7.2,1.8.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.JobVertexDetailsInfo.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-1-31 01:00:00" id="11235" opendate="2018-12-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Elasticsearch connector leaks threads if no connection could be established</summary>
      <description>elasticsearch transport sink init steps1, create client thread2, try to check every host:port3, if each host:port is unreachable, while throw RuntimeExceptionbut, because of throw RuntimeException, the client can not close, so causing thread leaktransport client code```TransportClient transportClient = new PreBuiltTransportClient(settings);for (TransportAddress transport : ElasticsearchUtils.convertInetSocketAddresses(transportAddresses)) { transportClient.addTransportAddress(transport);}// verify that we actually are connected to a clusterif (transportClient.connectedNodes().isEmpty()) { throw new RuntimeException("Elasticsearch client is not connected to any Elasticsearch nodes!");}return transportClient;}```thread leakthread dump </description>
      <version>1.6.3,1.7.1,1.8.0</version>
      <fixedVersion>1.6.4,1.7.2,1.8.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-elasticsearch5.src.main.java.org.apache.flink.streaming.connectors.elasticsearch5.Elasticsearch5ApiCallBridge.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch2.src.main.java.org.apache.flink.streaming.connectors.elasticsearch2.Elasticsearch2ApiCallBridge.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-1-3 01:00:00" id="11262" opendate="2019-1-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bump jython-standalone to 2.7.1</summary>
      <description>Due to security issue: https://ossindex.sonatype.org/vuln/7a4be7b3-74f5-4a9b-a24f-d1fd80ed6bbca</description>
      <version>1.6.3,1.7.1,1.8.0</version>
      <fixedVersion>1.6.4,1.7.2,1.8.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">NOTICE-binary</file>
      <file type="M">flink-libraries.flink-streaming-python.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-libraries.flink-streaming-python.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-10-24 01:00:00" id="11427" opendate="2019-1-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Protobuf parquet writer implementation</summary>
      <description>Right now only ParquetAvroWriters exist to create ParquetWriterFactory. We want to implement a protobuf ParquetProtoWriters to create ParquetWriterFactory.  I am happy to submit a PR if this approach sounds good . </description>
      <version>None</version>
      <fixedVersion>1.12.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-formats.flink-parquet.pom.xml</file>
      <file type="M">docs.dev.connectors.streamfile.sink.zh.md</file>
      <file type="M">docs.dev.connectors.streamfile.sink.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-1-30 01:00:00" id="11469" opendate="2019-1-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix example in "Tuning Checkpoints and Large State" documentation</summary>
      <description>Sample code for subtitle Tuning RocksDB in Tuning Checkpoints and Large State is wrong  Affects Version：All versions after 1.1  </description>
      <version>1.6.2,1.6.3,1.6.4,1.7.0,1.7.1,1.7.2,1.8.0</version>
      <fixedVersion>1.6.4,1.7.2,1.8.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.ops.state.large.state.tuning.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-2-12 01:00:00" id="11585" opendate="2019-2-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Prefix matching in ConfigDocsGenerator can result in wrong assignments</summary>
      <description>There are some cases where the key-prefix matching does not work as intended: given the prefixes "a.b" and "a.b.c.d", then an option with a key "a.b.c.X" will be assigned to the default groups instead of "a.b" given a prefix "a.b", an option "a.c.b" will be matched to that group instead of the default</description>
      <version>1.6.3,1.7.1,1.8.0</version>
      <fixedVersion>1.6.4,1.7.3,1.8.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-docs.src.test.java.org.apache.flink.docs.configuration.ConfigOptionsDocGeneratorTest.java</file>
      <file type="M">flink-docs.src.main.java.org.apache.flink.docs.configuration.ConfigOptionsDocGenerator.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2014-10-17 01:00:00" id="1171" opendate="2014-10-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move scala tests to flink-tests project</summary>
      <description>Eclipse does not manage to make the macros defined in src/main/scala available to src/test/scala - making it impossible to develop the scala project in Eclipse.Moving the tests to a different project (here: flink-tests/src/test/scala) solves the issue.See mailing list archive for discussion: http://mail-archives.apache.org/mod_mbox/flink-dev/201410.mbox/browser</description>
      <version>None</version>
      <fixedVersion>0.7.0-incubating</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.pom.xml</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.util.CollectionDataSets.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.types.TypeInformationGenTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.ScalaAPICompletenessTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.runtime.tuple.base.TupleComparatorTestBase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.runtime.tuple.base.PairComparatorTestBase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.runtime.TupleSerializerTestInstance.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.runtime.TupleSerializerTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.runtime.TupleComparatorISD3Test.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.runtime.TupleComparatorISD2Test.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.runtime.TupleComparatorISD1Test.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.runtime.TupleComparatorILDXC2Test.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.runtime.TupleComparatorILDX1Test.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.runtime.TupleComparatorILDC3Test.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.runtime.TupleComparatorILD3Test.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.runtime.TupleComparatorILD2Test.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.runtime.GenericPairComparatorTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.UnionITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.translation.ReduceTranslationTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.translation.DistinctTranslationTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.translation.DeltaIterationTranslationTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.translation.AggregateTranslationTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.SumMinMaxITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.ReduceITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.PartitionITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.MapITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.JoinOperatorTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.JoinITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.GroupReduceITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.GroupingTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.FlatMapITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.FirstNOperatorTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.FirstNITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.FilterITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.ExamplesITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.DistinctOperatorTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.DistinctITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.CrossITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.CoGroupOperatorTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.CoGroupITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.AggregateOperatorTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.operators.AggregateITCase.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.io.CsvInputFormatTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.io.CollectionInputFormatTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.functions.SemanticPropertiesTranslationTest.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.DeltaIterationSanityCheckTest.scala</file>
      <file type="M">flink-scala.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-5-23 01:00:00" id="11732" opendate="2019-2-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a language switch to the sidebar for Flink documents</summary>
      <description>Add a language switch similar to the project webpage. We didn't add the switch in the first version of supporting Chinese language, because we want to expose the switch when we satisfied the translation coverage.</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs..layouts.plain.html</file>
      <file type="M">docs..includes.sidenav.html</file>
      <file type="M">docs.page.css.flink.css</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-1-26 01:00:00" id="1183" opendate="2014-10-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Generate gentle notification message when Flink is started with Java 6</summary>
      <description>With Java 6 is reaching EOL we would like to let Flink's applications to know that it is recommended to move to Jav 7 or higher.This could be done as logging message when Flink Job Manager is starting.This will allow us to "deprecate" the support for Java 6 in the future by providing early notification to the users.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.scala.org.apache.flink.runtime.jobmanager.JobManager.scala</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-3-6 01:00:00" id="11834" opendate="2019-3-6 00:00:00" resolution="Implemented">
    <buginformation>
      <summary>Introduce flink logical relational nodes</summary>
      <description>Adds nodes extended from Calcite, including FlinkLogicalAggregate, FlinkLogicalCalc,FlinkLogicalCorrelate, FlinkLogicalIntersect, FlinkLogicalJoin, FlinkLogicalMinus, FlinkLogicalOverWindow, FlinkLogicalSort, FlinkLogicalUnion, FlinkLogicalValues, FlinkLogicalTableSourceScan, FlinkLogicalTableFunctionScan Adds new RelNode for Flink, including Expand, Rank, Sink, WatermarkAssigner</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.type.TimestampType.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.type.InternalTypes.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.schema.DataStreamTable.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.nodes.logical.FlinkLogicalDataStreamTableScan.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.nodes.FlinkRelNode.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.calcite.FlinkTypeFactory.scala</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-3-12 01:00:00" id="11887" opendate="2019-3-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Latency metrics drift apart</summary>
      <description>The operator's latency time is increased by approximately 2.7 minutes per day (see the attached).We compute the latency by System.currentTimeMillis - marker.getMarkedTime.There is no guarantee that System.currentTimeMillis and System.nanoTime don't drift apart.If a GC pause or linux preemptive scheduling happenes, this should affect latency metrics.Latency metrics drift away from their initial values with time(verify this result via the JVM Heap Dump).</description>
      <version>1.6.3</version>
      <fixedVersion>1.7.3,1.8.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.StreamSourceOperatorLatencyMetricsTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamSource.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2019-3-19 01:00:00" id="11966" opendate="2019-3-19 00:00:00" resolution="Implemented">
    <buginformation>
      <summary>Add support for generating optimized logical plan for simple query(Project, Filter, Values and Union all)</summary>
      <description>Add support for generating optimized logical plan for simple query, 1. Project and Filter: SELECT a, b + 1 FROM MyTable WHERE b &gt; 22. Values: SELECT * FROM (VALUES (1, 2, 3)) AS T(a, b, c)3. Union all: SELECT a, c FROM (SELECT a, c FROM MyTable1 UNION ALL SELECT a, c FROM MyTable2)Union depends on Aggregate to eliminate duplicates, so it will be introduced after Aggregate spported.</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.util.TableTestBase.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.util.RelTreeWriterImpl.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.util.FlinkRelOptUtil.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.rules.FlinkStreamRuleSets.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.rules.FlinkBatchRuleSets.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.optimize.program.FlinkStreamProgram.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.optimize.program.FlinkBatchProgram.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.nodes.logical.FlinkLogicalValues.scala</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-4-1 01:00:00" id="12073" opendate="2019-4-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support appropriate precision and scale processing of Decimal in Blink SQL</summary>
      <description>1.Make Decimal's output more precise than random.2.Let Decimal process closer to mainstream databases such as Hive/SqlServer.</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.type.TypeConverters.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.dataformat.DataFormatConverters.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.calcite.FlinkTypeSystem.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.calcite.FlinkTypeFactory.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.api.TableImpl.scala</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-5-10 01:00:00" id="12152" opendate="2019-4-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make the vcore that Application Master used configurable for Flink on YARN</summary>
      <description>Now, for Flink on YARN deployment mode, each am's vcores is specified to 1 (hard code).In some scene, we found many Akka timeout logs, the Flink web UI cannot be opened, but it is alive. I think there is no more threads resource to be used for am. So we suggest that make the vcores num of application master can be configurable.</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.configuration.YarnConfigOptions.java</file>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.AbstractYarnClusterDescriptor.java</file>
      <file type="M">docs..includes.generated.yarn.config.configuration.html</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2019-5-22 01:00:00" id="12285" opendate="2019-4-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Memory leak in SavepointITCase and SavepointMigrationTestBase</summary>
      <description>The tests in SavepointITCase and SavepointMigrationTestBase do not cancel running jobs before exit. It will cause exceptions in {{TaskExecutor}}s and unreleased memory segments. Succeeding tests may fail due to insufficient amount of memory.The problem is caused by cancelling {{TaskExecutor}}s with running tasks. Another issue caused by the reason can be seen in FLINK-11343. Maybe we can find a more dedicated method to cancel those {{TaskExecutor}}s still having running tasks.</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.testutils.MiniClusterResource.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-6-20 01:00:00" id="12556" opendate="2019-5-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Extend some end-to-end tests to run with custom (input) File System implementation</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.travis.splits.split.container.sh</file>
      <file type="M">flink-end-to-end-tests.test-scripts.test.yarn.kerberos.docker.sh</file>
      <file type="M">flink-end-to-end-tests.test-scripts.test.docker.embedded.job.sh</file>
      <file type="M">flink-end-to-end-tests.test-scripts.test.batch.wordcount.sh</file>
      <file type="M">flink-end-to-end-tests.run-pre-commit-tests.sh</file>
      <file type="M">flink-end-to-end-tests.run-nightly-tests.sh</file>
      <file type="M">flink-end-to-end-tests.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-5-20 01:00:00" id="12559" opendate="2019-5-20 00:00:00" resolution="Implemented">
    <buginformation>
      <summary>Introduce metadata handlers on window aggregate</summary>
      <description>In FLINK-11822, we have introduced all Flink metadata handlers, several RelNode s (e.g. window aggregate) have not be implemented. So this issue aims to introduce all metadata handlers on window aggregate.</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.stream.sql.agg.OverWindowAggregateTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.metadata.MetadataTestUtil.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.metadata.FlinkRelMdUniqueKeysTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.metadata.FlinkRelMdUniqueGroupsTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.metadata.FlinkRelMdSizeTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.metadata.FlinkRelMdSelectivityTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.metadata.FlinkRelMdRowCountTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.metadata.FlinkRelMdPopulationSizeTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.metadata.FlinkRelMdHandlerTestBase.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.metadata.FlinkRelMdDistinctRowCountTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.metadata.FlinkRelMdColumnUniquenessTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.metadata.FlinkRelMdColumnIntervalTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.batch.sql.agg.OverWindowAggregateTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.plan.stream.sql.agg.OverWindowAggregateTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.plan.rules.logical.FlinkLogicalRankRuleForRangeEndTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.plan.rules.logical.FlinkLogicalRankRuleForConstantRangeTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.plan.batch.sql.DagOptimizationTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.plan.batch.sql.agg.WindowAggregateTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.plan.batch.sql.agg.OverWindowAggregateTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.util.FlinkRelMdUtil.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.util.AggregateUtil.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.rules.physical.stream.StreamExecOverAggregateRule.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.rules.physical.batch.BatchExecOverWindowAggRule.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.rules.logical.FlinkLogicalRankRule.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.rules.FlinkStreamRuleSets.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.rules.FlinkBatchRuleSets.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.nodes.physical.stream.StreamExecGroupWindowAggregate.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.nodes.physical.batch.BatchExecOverAggregate.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.nodes.physical.batch.BatchExecLocalSortWindowAggregate.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.nodes.physical.batch.BatchExecLocalHashWindowAggregate.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.nodes.logical.FlinkLogicalTableFunctionScan.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.nodes.logical.FlinkLogicalOverWindow.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.metadata.FlinkRelMdUniqueKeys.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.metadata.FlinkRelMdUniqueGroups.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.metadata.FlinkRelMdSize.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.metadata.FlinkRelMdSelectivity.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.metadata.FlinkRelMdRowCount.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.metadata.FlinkRelMdPopulationSize.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.metadata.FlinkRelMdModifiedMonotonicity.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.metadata.FlinkRelMdFilteredColumnInterval.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.metadata.FlinkRelMdDistinctRowCount.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.metadata.FlinkRelMdColumnUniqueness.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.metadata.FlinkRelMdColumnInterval.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.metadata.AggCallSelectivityEstimator.scala</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-5-20 01:00:00" id="12560" opendate="2019-5-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Documentation language build flags</summary>
      <description>Most documentation writers are only ever focused on one language at a time. Adding language-specific build flags can dramatically reduce render time during local development.</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.README.md</file>
      <file type="M">docs.build.docs.sh</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-7-24 01:00:00" id="13403" opendate="2019-7-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Correct package name after relocation</summary>
      <description>some scala classes's package name is not updated after FLINK-13266, this issue aims to correct the package names</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.planner.calcite.FlinkTypeFactoryTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.planner.calcite.CalciteConfigBuilderTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.validate.ValidationResult.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.typeutils.TypeInfoCheckUtils.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.typeutils.TypeCoercion.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.sources.TableSourceUtil.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.plan.TreeNode.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.plan.schema.TableSourceTable.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecTableSourceScan.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.plan.nodes.physical.batch.BatchExecTableSourceScan.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.windowProperties.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.time.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.subquery.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.stringExpressions.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.ReturnTypeInference.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.Reinterpret.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.PlannerExpression.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.ordering.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.mathExpressions.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.logic.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.InputTypeSpec.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.fieldExpression.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.composite.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.comparison.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.collection.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.cast.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.call.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.arithmetic.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.expressions.aggregations.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.codegen.calls.ScalarOperatorGens.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.planner.expressions.PlannerTypeInferenceUtilImpl.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2020-2-4 01:00:00" id="15897" opendate="2020-2-4 00:00:00" resolution="Resolved">
    <buginformation>
      <summary>Defer the deserialization of the Python UDF execution results</summary>
      <description>Currently, the Python UDF execution results are deserialized and then buffered in a collection when received from the Python worker. The deserialization could be deferred when sending the execution results to the downstream operator. That's to say, it buffers the serialized bytes instead of the deserialized Java objects in the buffer. This could reduce the memory footprint of the Java operator.</description>
      <version>None</version>
      <fixedVersion>1.11.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-python.src.test.java.org.apache.flink.table.runtime.operators.python.PythonScalarFunctionOperatorTestBase.java</file>
      <file type="M">flink-python.src.test.java.org.apache.flink.table.runtime.operators.python.PythonScalarFunctionOperatorTest.java</file>
      <file type="M">flink-python.src.test.java.org.apache.flink.table.runtime.operators.python.PassThroughPythonFunctionRunner.java</file>
      <file type="M">flink-python.src.test.java.org.apache.flink.table.runtime.operators.python.BaseRowPythonScalarFunctionOperatorTest.java</file>
      <file type="M">flink-python.src.test.java.org.apache.flink.table.functions.python.PythonScalarFunctionRunnerTest.java</file>
      <file type="M">flink-python.src.test.java.org.apache.flink.table.functions.python.BaseRowPythonScalarFunctionRunnerTest.java</file>
      <file type="M">flink-python.src.test.java.org.apache.flink.table.functions.python.AbstractPythonScalarFunctionRunnerTest.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.table.runtime.runners.python.PythonScalarFunctionRunner.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.table.runtime.runners.python.BaseRowPythonScalarFunctionRunner.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.table.runtime.runners.python.AbstractPythonScalarFunctionRunner.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.table.runtime.operators.python.PythonScalarFunctionOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.table.runtime.operators.python.BaseRowPythonScalarFunctionOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.table.runtime.operators.python.AbstractPythonScalarFunctionOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.table.runtime.functions.python.PythonScalarFunctionFlatMap.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.streaming.api.operators.python.AbstractPythonFunctionOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.python.AbstractPythonFunctionRunner.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2020-4-13 01:00:00" id="17107" opendate="2020-4-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>CheckpointCoordinatorConfiguration#isExactlyOnce() is inconsistent with StreamConfig#getCheckpointMode()</summary>
      <description>CheckpointCoordinatorConfiguration#isExactlyOnce() is inconsistent with StreamConfig#getCheckpointMode() when checkpoint is disabled. CheckpointCoordinatorConfiguration#isExactlyOnce() returns true if checkpoint mode is  EXACTLY_ONCE mode and return false if checkpoint mode is AT_LEAST_ONCE while StreamConfig#getCheckpointMode() will always return AT_LEAST_ONCE which means always not exactly once.</description>
      <version>1.6.3,1.7.2,1.8.0,1.9.0,1.10.0</version>
      <fixedVersion>1.10.1,1.11.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.graph.StreamingJobGraphGeneratorTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator.java</file>
    </fixedFiles>
  </bug>
</bugrepository>