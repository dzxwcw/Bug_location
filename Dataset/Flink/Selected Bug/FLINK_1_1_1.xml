<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="FLINK">
  
  <bug fixdate="2016-8-16 01:00:00" id="4403" opendate="2016-8-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>RPC proxy classloading should use Flink class&amp;#39; classloader</summary>
      <description>The RPC service's proxies use the ClassLoader.getSystemClassLoader() for all reflective classloading.In settings where Flink runs embedded, the Flink framework classes may not be in the System classloader, but for example in the classloader of an OSGI bundle. It is hence better to use the classloader of a Flink Framework class. In most cases, that will be the system classloader, in other cases it will be the classloader for the Flink code bundle: RpcService.class.getClassLoader().</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rpc.akka.AkkaRpcService.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-10-17 01:00:00" id="4406" opendate="2016-8-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement job master registration at resource manager</summary>
      <description>Job Master needs to register to Resource Manager when starting and then watches leadership changes of RM, and trigger re-registration.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.jobmaster.JobManagerRunnerMockTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.resourcemanager.ResourceManager.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobmaster.JobMasterToResourceManagerConnection.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobmaster.JobMasterRegistrationSuccess.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobmaster.JobMasterGateway.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobmaster.JobMaster.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobmaster.JobManagerRunner.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-9-17 01:00:00" id="4408" opendate="2016-8-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Submit Job and setup ExecutionGraph</summary>
      <description>Once granted the leadership, JM will start to execute the job.Most code remains the same except that (1) In old implementation where JM manages the execution of multiple jobs, JM has to load all submitted JobGraphs from SubmittedJobGraphStore and recover them. Now that the components creating JM will be responsible for the recovery of JobGraphs, JM will be created with submitted/recovered JobGraph, without the need to load the JobGraph.(2) JM should not rely on Akka to listen on the updates of JobStatus and Execution.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rpc.RpcConnectionTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.highavailability.TestingHighAvailabilityServices.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskExecutor.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobmaster.JobMasterGateway.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobmaster.JobMaster.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobmanager.scheduler.Scheduler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.highavailability.NonHaServices.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.highavailability.HighAvailabilityServices.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.JobSubmissionResult.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.JobExecutionResult.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-8-17 01:00:00" id="4412" opendate="2016-8-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[py] Chaining does not properly handle broadcast variables</summary>
      <description/>
      <version>1.1.1</version>
      <fixedVersion>1.1.2,1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-python.src.main.python.org.apache.flink.python.api.flink.plan.Environment.py</file>
      <file type="M">flink-libraries.flink-python.src.main.python.org.apache.flink.python.api.flink.plan.DataSet.py</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-8-19 01:00:00" id="4434" opendate="2016-8-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a testing RPC service</summary>
      <description>I suggest to add a simple testing RPC service that allows to register mock gateways under certain names.That way, if a component connects to another component via the RPC service, it will call the mock gateway, rather than the proper proxy gateway that will try to send actor messages.Tests on mocks are very easy and powerful with tools like Mockito.</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rpc.RpcCompletenessTest.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2016-8-26 01:00:00" id="4514" opendate="2016-8-26 00:00:00" resolution="Resolved">
    <buginformation>
      <summary>ExpiredIteratorException in Kinesis Consumer on long catch-ups to head of stream</summary>
      <description>Original mailing thread for the reported issue:http://apache-flink-user-mailing-list-archive.2336050.n4.nabble.com/Kinesis-connector-Iterator-expired-exception-td8711.htmlNormally, the exception is thrown when the consumer uses the same shard iterator after 5 minutes since it was retrieved. I've still yet to clarify &amp; reproduce the root cause of the ExpiredIteratorException, because from the code this seems to be impossible. I'm leaning towards suspecting this is a Kinesis-side issue (from the description in the ML, the behaviour also seems indeterminate).Either way, the exception can be fairly easily handled so that the consumer doesn't just fail. When caught, we request a new shard iterator from Kinesis with the last sequence number.</description>
      <version>1.1.0,1.1.1</version>
      <fixedVersion>1.1.3,1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.testutils.FakeKinesisBehavioursFactory.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kinesis.src.test.java.org.apache.flink.streaming.connectors.kinesis.internals.ShardConsumerTest.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.util.KinesisConfigUtil.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.internals.ShardConsumer.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kinesis.src.main.java.org.apache.flink.streaming.connectors.kinesis.config.ConsumerConfigConstants.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-11-5 01:00:00" id="4743" opendate="2016-10-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>The sqrt/power function not accept the real data types.</summary>
      <description>At time calculate the sequences sql aggregate functions for real type column, got exception: No applicable constructor/method found for actual parameters "float, java.math.BigDecimal"And for column of integer type the problem does not occur.Code reproduce:@Test def test():Unit={ val env = ExecutionEnvironment.getExecutionEnvironment val tEnv = TableEnvironment.getTableEnvironment(env, config) val ds = env.fromElements( (1.0f, 1), (2.0f, 2)).toTable(tEnv) tEnv.registerTable("MyTable", ds) val sqlQuery = "SELECT " + "SQRT((SUM(a*a) - SUM(a)*SUM(a)/COUNT(a))/COUNT(a)) "+ "from (select _1 as a from MyTable)" tEnv.sql(sqlQuery).toDataSet[Row].collect().foreach(x=&gt;print(s"$x ")) }got exception:org.apache.flink.api.common.InvalidProgramException: Table program cannot be compiled. This is a bug. Please file an issue. at org.apache.flink.api.table.runtime.FunctionCompiler$class.compile(FunctionCompiler.scala:37) at org.apache.flink.api.table.runtime.FlatMapRunner.compile(FlatMapRunner.scala:28) at org.apache.flink.api.table.runtime.FlatMapRunner.open(FlatMapRunner.scala:42) at org.apache.flink.api.common.functions.util.FunctionUtils.openFunction(FunctionUtils.java:38) at org.apache.flink.api.common.operators.base.FlatMapOperatorBase.executeOnCollections(FlatMapOperatorBase.java:62) at org.apache.flink.api.common.operators.CollectionExecutor.executeUnaryOperator(CollectionExecutor.java:249) at org.apache.flink.api.common.operators.CollectionExecutor.execute(CollectionExecutor.java:147) at org.apache.flink.api.common.operators.CollectionExecutor.execute(CollectionExecutor.java:129) at org.apache.flink.api.common.operators.CollectionExecutor.executeDataSink(CollectionExecutor.java:180) at org.apache.flink.api.common.operators.CollectionExecutor.execute(CollectionExecutor.java:156) at org.apache.flink.api.common.operators.CollectionExecutor.execute(CollectionExecutor.java:129) at org.apache.flink.api.common.operators.CollectionExecutor.execute(CollectionExecutor.java:113) at org.apache.flink.api.java.CollectionEnvironment.execute(CollectionEnvironment.java:35) at org.apache.flink.test.util.CollectionTestEnvironment.execute(CollectionTestEnvironment.java:47) at org.apache.flink.test.util.CollectionTestEnvironment.execute(CollectionTestEnvironment.java:42) at org.apache.flink.api.scala.ExecutionEnvironment.execute(ExecutionEnvironment.scala:637) at org.apache.flink.api.scala.DataSet.collect(DataSet.scala:547) at org.apache.flink.api.scala.batch.sql.AggregationsITCase.test(AggregationsITCase.scala:307) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55) at org.junit.rules.RunRules.evaluate(RunRules.java:20) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229) at org.junit.runners.ParentRunner.run(ParentRunner.java:309) at org.junit.runners.Suite.runChild(Suite.java:127) at org.junit.runners.Suite.runChild(Suite.java:26) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229) at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) at org.junit.runners.ParentRunner.run(ParentRunner.java:309) at org.junit.runner.JUnitCore.run(JUnitCore.java:160) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69) at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:234) at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:74) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)Caused by: org.codehaus.commons.compiler.CompileException: Line 118, Column 57: No applicable constructor/method found for actual parameters "float, java.math.BigDecimal"; candidates are: "public static double org.apache.calcite.runtime.SqlFunctions.power(double, double)", "public static double org.apache.calcite.runtime.SqlFunctions.power(long, java.math.BigDecimal)", "public static double org.apache.calcite.runtime.SqlFunctions.power(long, long)" at org.codehaus.janino.UnitCompiler.compileError(UnitCompiler.java:10062) at org.codehaus.janino.UnitCompiler.findMostSpecificIInvocable(UnitCompiler.java:7476) at org.codehaus.janino.UnitCompiler.findIMethod(UnitCompiler.java:7346) at org.codehaus.janino.UnitCompiler.findIMethod(UnitCompiler.java:7250) at org.codehaus.janino.UnitCompiler.compileGet2(UnitCompiler.java:3862) at org.codehaus.janino.UnitCompiler.access$6900(UnitCompiler.java:182) at org.codehaus.janino.UnitCompiler$10.visitMethodInvocation(UnitCompiler.java:3263) at org.codehaus.janino.Java$MethodInvocation.accept(Java.java:3971) at org.codehaus.janino.UnitCompiler.compileGet(UnitCompiler.java:3290) at org.codehaus.janino.UnitCompiler.compileGetValue(UnitCompiler.java:4356) at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:2669) at org.codehaus.janino.UnitCompiler.access$4500(UnitCompiler.java:182) at org.codehaus.janino.UnitCompiler$7.visitAssignment(UnitCompiler.java:2619) at org.codehaus.janino.Java$Assignment.accept(Java.java:3402) at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:2654) at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:1635) at org.codehaus.janino.UnitCompiler.access$1100(UnitCompiler.java:182) at org.codehaus.janino.UnitCompiler$4.visitExpressionStatement(UnitCompiler.java:936) at org.codehaus.janino.Java$ExpressionStatement.accept(Java.java:2094) at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:958) at org.codehaus.janino.UnitCompiler.compileStatements(UnitCompiler.java:999) at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:985) at org.codehaus.janino.UnitCompiler.access$1000(UnitCompiler.java:182) at org.codehaus.janino.UnitCompiler$4.visitBlock(UnitCompiler.java:935) at org.codehaus.janino.Java$Block.accept(Java.java:2009) at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:958) at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:1737) at org.codehaus.janino.UnitCompiler.access$1200(UnitCompiler.java:182) at org.codehaus.janino.UnitCompiler$4.visitIfStatement(UnitCompiler.java:937) at org.codehaus.janino.Java$IfStatement.accept(Java.java:2154) at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:958) at org.codehaus.janino.UnitCompiler.compileStatements(UnitCompiler.java:999) at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:2284) at org.codehaus.janino.UnitCompiler.compileDeclaredMethods(UnitCompiler.java:822) at org.codehaus.janino.UnitCompiler.compileDeclaredMethods(UnitCompiler.java:794) at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:504) at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:390) at org.codehaus.janino.UnitCompiler.access$400(UnitCompiler.java:182) at org.codehaus.janino.UnitCompiler$2.visitPackageMemberClassDeclaration(UnitCompiler.java:344) at org.codehaus.janino.Java$PackageMemberClassDeclaration.accept(Java.java:1136) at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:351) at org.codehaus.janino.UnitCompiler.compileUnit(UnitCompiler.java:319) at org.codehaus.janino.SimpleCompiler.compileToClassLoader(SimpleCompiler.java:358) at org.codehaus.janino.SimpleCompiler.cook(SimpleCompiler.java:201) at org.codehaus.janino.SimpleCompiler.cook(SimpleCompiler.java:192) at org.codehaus.commons.compiler.Cookable.cook(Cookable.java:84) at org.codehaus.commons.compiler.Cookable.cook(Cookable.java:77) at org.apache.flink.api.table.runtime.FunctionCompiler$class.compile(FunctionCompiler.scala:34) ... 55 more</description>
      <version>1.1.1</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.expressions.ScalarFunctionsTest.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.InputTypeSpec.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.calls.BuiltInMethods.scala</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-10-5 01:00:00" id="4745" opendate="2016-10-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Convert KafkaTableSource test to unit tests</summary>
      <description>Kafka tests are extremely heavy and Table Sources and Sinks are only thin wrappers on top of the Kafka Sources / Sinks. That should not need to bring up Kafka clusters.</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaTableSinkTestBase.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaConsumerTestBase.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.9.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka09JsonTableSinkTest.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.9.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka09ITCase.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka08JsonTableSinkTest.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-0.8.src.test.java.org.apache.flink.streaming.connectors.kafka.Kafka08ITCase.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-10-21 01:00:00" id="4881" opendate="2016-10-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Docker: Remove dependency on shared volumes</summary>
      <description>Our Dockerfile assumes a shared volume configuration to access the config. Instead, we can configure the Docker container to directly write the hostname into /etc/hosts and use "jobmanager" as the default hostname.This has been proposed here: https://github.com/apache/flink/pull/2667</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-contrib.docker-flink.README.md</file>
      <file type="M">flink-contrib.docker-flink.docker-entrypoint.sh</file>
      <file type="M">flink-contrib.docker-flink.docker-compose.yml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-11-25 01:00:00" id="4913" opendate="2016-10-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Per-job Yarn clusters: include user jar in system class loader</summary>
      <description>Including the jar directly in the system classloader avoids loading it for every instantiation of the ExecutionGraph and every Task execution. Note, this is only possible for per-job clusters (i.e. Yarn/Mesos).</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.YarnClusterClient.java</file>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.cli.FlinkYarnSessionCli.java</file>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.AbstractYarnClusterDescriptor.java</file>
      <file type="M">flink-yarn-tests.src.test.java.org.apache.flink.yarn.YarnTestBase.java</file>
      <file type="M">flink-yarn-tests.src.test.java.org.apache.flink.yarn.CliFrontendYarnAddressConfigurationTest.java</file>
      <file type="M">flink-scala-shell.src.main.scala.org.apache.flink.api.scala.FlinkShell.scala</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.program.StandaloneClusterClient.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.program.PackagedProgram.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.program.ClusterClient.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.cli.DefaultCLI.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.cli.CustomCommandLine.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.CliFrontend.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-12-25 01:00:00" id="4918" opendate="2016-10-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add SSL support to Mesos artifact server</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.security.SecurityContext.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.util.MesosArtifactServer.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.runtime.clusterframework.MesosTaskManagerRunner.java</file>
      <file type="M">flink-mesos.src.main.java.org.apache.flink.mesos.runtime.clusterframework.MesosApplicationMasterRunner.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.ConfigConstants.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-11-26 01:00:00" id="4921" opendate="2016-10-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade to Mesos 1.0.1</summary>
      <description>Upgrade the client library to 1.0.1.</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-mesos.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-10-26 01:00:00" id="4924" opendate="2016-10-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Simplify Operator Test Harness Constructors</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.WindowingTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.TwoInputStreamOperatorTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.OneInputStreamOperatorTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.KeyedTwoInputStreamOperatorTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.KeyedOneInputStreamOperatorTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.AbstractStreamOperatorTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamMockEnvironment.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.OneInputStreamTaskTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.WindowOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.WindowingTestHarnessTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.AggregatingAlignedProcessingTimeWindowOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.AccumulatingAlignedProcessingTimeWindowOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.TimestampsAndPeriodicWatermarksOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.StreamOperatorSnapshotRestoreTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.AbstractStreamOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamConfig.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-filesystem.src.test.java.org.apache.flink.streaming.connectors.fs.bucketing.BucketingSinkTest.java</file>
      <file type="M">flink-fs-tests.src.test.java.org.apache.flink.hdfstests.ContinuousFileMonitoringTest.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-11-23 01:00:00" id="5143" opendate="2016-11-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add EXISTS to list of supported operators</summary>
      <description>EXISTS is supported in certain cases. We should add it so that e.g. TPC-H query 4 runs properly.</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.table.utils.TableTestBase.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.validate.FunctionCatalog.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetJoin.scala</file>
      <file type="M">docs.dev.table.api.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-1-23 01:00:00" id="5144" opendate="2016-11-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Error while applying rule AggregateJoinTransposeRule</summary>
      <description>AggregateJoinTransposeRule seems to cause errors. We have to investigate if this is a Flink or Calcite error. Here a simplified example:select sum(l_extendedprice)from lineitem, partwhere p_partkey = l_partkey and l_quantity &lt; ( select avg(l_quantity) from lineitem where l_partkey = p_partkey )Exception:Exception in thread "main" java.lang.AssertionError: Internal error: Error occurred while applying rule AggregateJoinTransposeRule at org.apache.calcite.util.Util.newInternal(Util.java:792) at org.apache.calcite.plan.volcano.VolcanoRuleCall.transformTo(VolcanoRuleCall.java:148) at org.apache.calcite.plan.RelOptRuleCall.transformTo(RelOptRuleCall.java:225) at org.apache.calcite.rel.rules.AggregateJoinTransposeRule.onMatch(AggregateJoinTransposeRule.java:342) at org.apache.calcite.plan.volcano.VolcanoRuleCall.onMatch(VolcanoRuleCall.java:213) at org.apache.calcite.plan.volcano.VolcanoPlanner.findBestExp(VolcanoPlanner.java:819) at org.apache.calcite.tools.Programs$RuleSetProgram.run(Programs.java:334) at org.apache.flink.api.table.BatchTableEnvironment.optimize(BatchTableEnvironment.scala:251) at org.apache.flink.api.table.BatchTableEnvironment.translate(BatchTableEnvironment.scala:286) at org.apache.flink.api.scala.table.BatchTableEnvironment.toDataSet(BatchTableEnvironment.scala:139) at org.apache.flink.api.scala.table.package$.table2RowDataSet(package.scala:77) at org.apache.flink.api.scala.sql.tpch.TPCHQueries$.runQ17(TPCHQueries.scala:826) at org.apache.flink.api.scala.sql.tpch.TPCHQueries$.main(TPCHQueries.scala:57) at org.apache.flink.api.scala.sql.tpch.TPCHQueries.main(TPCHQueries.scala) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)Caused by: java.lang.AssertionError: Type mismatch:rowtype of new rel:RecordType(BIGINT l_partkey, BIGINT p_partkey) NOT NULLrowtype of set:RecordType(BIGINT p_partkey) NOT NULL at org.apache.calcite.util.Litmus$1.fail(Litmus.java:31) at org.apache.calcite.plan.RelOptUtil.equal(RelOptUtil.java:1838) at org.apache.calcite.plan.volcano.RelSubset.add(RelSubset.java:273) at org.apache.calcite.plan.volcano.RelSet.add(RelSet.java:148) at org.apache.calcite.plan.volcano.VolcanoPlanner.addRelToSet(VolcanoPlanner.java:1820) at org.apache.calcite.plan.volcano.VolcanoPlanner.registerImpl(VolcanoPlanner.java:1766) at org.apache.calcite.plan.volcano.VolcanoPlanner.register(VolcanoPlanner.java:1032) at org.apache.calcite.plan.volcano.VolcanoPlanner.ensureRegistered(VolcanoPlanner.java:1052) at org.apache.calcite.plan.volcano.VolcanoPlanner.ensureRegistered(VolcanoPlanner.java:1942) at org.apache.calcite.plan.volcano.VolcanoRuleCall.transformTo(VolcanoRuleCall.java:136) ... 17 more</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.plan.rules.FlinkRuleSets.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.table.calcite.FlinkPlannerImpl.scala</file>
    </fixedFiles>
  </bug>
  
</bugrepository>