<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="FLINK">
  
  <bug fixdate="2014-8-26 01:00:00" id="1065" opendate="2014-8-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>"flink-streaming-core" build fails with Hadoop 2.4.0 dependencies</summary>
      <description>Hi,building Flink with "mvn clean package -Dhadoop.profile=2 -DskipTests -Dhadoop-two.version=2.4.0"results in the following error[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project flink-streaming-core: Compilation failure: Compilation failure:[ERROR] /home/robert/incubator-flink/flink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/invokable/operator/BatchReduceInvokable.java:[22,36] package org.apache.commons.math.util does not exist[ERROR] /home/robert/incubator-flink/flink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/invokable/operator/WindowReduceInvokable.java:[22,36] package org.apache.commons.math.util does not exist[ERROR] /home/robert/incubator-flink/flink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/invokable/operator/BatchReduceInvokable.java:[39,36] cannot find symbol[ERROR] symbol: variable MathUtils[ERROR] location: class org.apache.flink.streaming.api.invokable.operator.BatchReduceInvokable&lt;IN,OUT&gt;[ERROR] /home/robert/incubator-flink/flink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/invokable/operator/BatchReduceInvokable.java:[48,36] cannot find symbol[ERROR] symbol: variable MathUtils[ERROR] location: class org.apache.flink.streaming.api.invokable.operator.BatchReduceInvokable&lt;IN,OUT&gt;[ERROR] /home/robert/incubator-flink/flink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/invokable/operator/WindowReduceInvokable.java:[40,36] cannot find symbol[ERROR] symbol: variable MathUtils[ERROR] location: class org.apache.flink.streaming.api.invokable.operator.WindowReduceInvokable&lt;IN,OUT&gt;[ERROR] /home/robert/incubator-flink/flink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/invokable/operator/WindowReduceInvokable.java:[49,36] cannot find symbol[ERROR] symbol: variable MathUtils[ERROR] location: class org.apache.flink.streaming.api.invokable.operator.WindowReduceInvokable&lt;IN,OUT&gt;[ERROR] -&gt; [Help 1][ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.[ERROR] Re-run Maven using the -X switch to enable full debug logging.[ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles:[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException[ERROR] [ERROR] After correcting the problems, you can resume the build with the command[ERROR] mvn &lt;goals&gt; -rf :flink-streaming-coreI think older Hadoop versions (its working with Hadoop 2.2.0) are pulling in transitive dependencies that are not present with Hadoop 2.4.0 anymore.</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>0.7.0-incubating</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-dist.src.main.flink-bin.LICENSE</file>
      <file type="M">flink-addons.flink-streaming.flink-streaming-core.pom.xml</file>
      <file type="M">DEPENDENCIES</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-8-27 01:00:00" id="1068" opendate="2014-8-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace "cdh4" profile with generic "hadoop 2.0.0-alpha" support</summary>
      <description>As per mailing list discussion, we decided to remove the vendor specific "cdh4" profile.Users compiling against "hadoop 2.0.0-alpha" can use Flink with CDH4 and other distributions relying on hadoop 2.0.0-alpha.I'm planning to include this into 0.6.1 and 0.7</description>
      <version>0.6-incubating,0.7.0-incubating</version>
      <fixedVersion>0.6.1-incubating,0.7.0-incubating</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.create.release.files.sh</file>
      <file type="M">pom.xml</file>
      <file type="M">flink-tests.pom.xml</file>
      <file type="M">flink-test-utils.pom.xml</file>
      <file type="M">flink-runtime.pom.xml</file>
      <file type="M">flink-dist.pom.xml</file>
      <file type="M">flink-addons.flink-spargel.pom.xml</file>
      <file type="M">flink-addons.flink-hadoop-compatibility.pom.xml</file>
      <file type="M">flink-addons.flink-avro.pom.xml</file>
      <file type="M">docs.building.md</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2018-1-31 01:00:00" id="10740" opendate="2018-10-31 00:00:00" resolution="Unresolved">
    <buginformation>
      <summary>FLIP-27: Refactor Source Interface</summary>
      <description>Please see the FLIP for any details: https://cwiki.apache.org/confluence/display/FLINK/FLIP-27%3A+Refactor+Source+Interface</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.collect.CollectSinkFunctionTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.source.coordinator.SourceCoordinatorTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.coordination.TestingOperatorCoordinator.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.coordination.MockOperatorCoordinator.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.source.coordinator.SourceCoordinator.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.scheduler.DefaultScheduler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.operators.coordination.OperatorCoordinator.java</file>
      <file type="M">docs.dev.stream.sources.zh.md</file>
      <file type="M">docs.dev.stream.sources.md</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.SourceOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.SourceOperator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.CollectionUtil.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2014-10-22 01:00:00" id="1106" opendate="2014-9-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Deprecate old Record API</summary>
      <description>For the upcoming 0.7 release, we should mark all user-facing methods from the old Record Java API as deprecated, with a warning that we are going to remove it at some point.I would suggest to wait one or two releases from the 0.7 release (given our current release cycle). I'll start a mailing-list discussion at some point regarding this.</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>0.7.0-incubating</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.OperatorInfoHelper.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.MapPartitionOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.MapOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.JoinOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.GenericDataSource.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.GenericDataSink.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.FileDataSource.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.FileDataSink.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.DeltaIteration.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.CrossWithSmallOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.CrossWithLargeOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.CrossOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.CollectionDataSource.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.CoGroupOperator.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.operators.BulkIteration.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.functions.ReduceFunction.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.functions.MapPartitionFunction.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.functions.MapFunction.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.functions.JoinFunction.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.functions.FunctionAnnotation.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.functions.CrossFunction.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.record.functions.CoGroupFunction.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-2-22 01:00:00" id="1107" opendate="2014-9-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document how to use Avro files and the Hadoop Input Format Wrappers</summary>
      <description>The documentation lacks any examples or description on how to read from avro files. Also, we should document the Hadoop Input Formats a bit.</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs..includes.sidenav.html</file>
      <file type="M">docs.spargel.guide.md</file>
      <file type="M">docs.hadoop.compatibility.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-9-23 01:00:00" id="1119" opendate="2014-9-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>StreamComponentTest fails with NoResourceAvailableException</summary>
      <description>On my machine, the current master branch (commit f329fe2b654eea078de085442d68dd1d5a9fc09a) fails to build due to two tests in error in StreamComponentTest.Both tests fail with a NoResourceAvailableException:22:08:56.779 [IPC Server handler 0 on 1624] ERROR org.apache.flink.runtime.jobmanager.JobManager - Job submission failed.org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Not enough free slots available to run the job. You can decrease the operator parallelism or increase the number of slots per TaskManager in the configuration. at org.apache.flink.runtime.jobmanager.scheduler.Scheduler.scheduleTask(Scheduler.java:201) ~[flink-runtime-0.7-incubating-SNAPSHOT.jar:0.7-incubating-SNAPSHOT] at org.apache.flink.runtime.jobmanager.scheduler.Scheduler.scheduleImmediately(Scheduler.java:116) ~[flink-runtime-0.7-incubating-SNAPSHOT.jar:0.7-incubating-SNAPSHOT] at org.apache.flink.runtime.executiongraph.Execution.scheduleForExecution(Execution.java:203) ~[flink-runtime-0.7-incubating-SNAPSHOT.jar:0.7-incubating-SNAPSHOT] at org.apache.flink.runtime.executiongraph.ExecutionVertex.scheduleForExecution(ExecutionVertex.java:326) ~[flink-runtime-0.7-incubating-SNAPSHOT.jar:0.7-incubating-SNAPSHOT] at org.apache.flink.runtime.executiongraph.ExecutionJobVertex.scheduleAll(ExecutionJobVertex.java:238) ~[flink-runtime-0.7-incubating-SNAPSHOT.jar:0.7-incubating-SNAPSHOT] at org.apache.flink.runtime.executiongraph.ExecutionGraph.scheduleForExecution(ExecutionGraph.java:293) ~[flink-runtime-0.7-incubating-SNAPSHOT.jar:0.7-incubating-SNAPSHOT] at org.apache.flink.runtime.jobmanager.JobManager.submitJob(JobManager.java:377) ~[flink-runtime-0.7-incubating-SNAPSHOT.jar:0.7-incubating-SNAPSHOT] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.7.0_67] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.7.0_67] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_67] at java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_67] at org.apache.flink.runtime.ipc.RPC$Server.call(RPC.java:418) [flink-runtime-0.7-incubating-SNAPSHOT.jar:0.7-incubating-SNAPSHOT] at org.apache.flink.runtime.ipc.Server$Handler.run(Server.java:947) [flink-runtime-0.7-incubating-SNAPSHOT.jar:0.7-incubating-SNAPSHOT]</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>0.7.0-incubating</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.minicluster.NepheleMiniCluster.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2014-9-24 01:00:00" id="1123" opendate="2014-9-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add First-N operator to Scala API</summary>
      <description>The first&amp;#40;n&amp;#41; operator is only supported by the Java API (see FLINK-970).This functionality needs to be ported to the ScalaAPI as well. Right now, the corresponding methods are excluded from the ScalaAPICompletenessTest.</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>0.7.0-incubating</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.GroupedDataSet.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.DataSet.scala</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2014-11-8 01:00:00" id="1142" opendate="2014-10-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Log IOManager temp path directories</summary>
      <description/>
      <version>0.6.1-incubating,0.7.0-incubating</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskmanager.TaskManager.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-1-30 01:00:00" id="11461" opendate="2019-1-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove unused MockRecordWriter</summary>
      <description>The MockRecordWriter is not used in current code path, so delete it directly.</description>
      <version>None</version>
      <fixedVersion>1.8.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.operators.sort.MockRecordReader.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-11-30 01:00:00" id="11466" opendate="2019-1-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement LocalStandaloneKafkaResource</summary>
      <description>Implement a common KafkaResource interface for interacting with Kafka across various environments, and provide a LocalStandaloneKafkaResource implementation that downloads kafka sets up a local standalone cluster with the bundled zookeeper.Effectively this is JIRA is about porting the logic in kafka-common.sh to Java.</description>
      <version>None</version>
      <fixedVersion>1.10.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-end-to-end-tests.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-11-30 01:00:00" id="11467" opendate="2019-1-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Port Kafka Streaming end-to-end test</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.10.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-end-to-end-tests.test-scripts.test.streaming.kafka.common.sh</file>
      <file type="M">flink-end-to-end-tests.test-scripts.test.streaming.kafka011.sh</file>
      <file type="M">flink-end-to-end-tests.test-scripts.test.streaming.kafka010.sh</file>
      <file type="M">flink-end-to-end-tests.test-scripts.test.streaming.kafka.sh</file>
      <file type="M">flink-end-to-end-tests.run-pre-commit-tests.sh</file>
      <file type="M">flink-end-to-end-tests.flink-streaming-kafka011-test.pom.xml</file>
      <file type="M">flink-end-to-end-tests.flink-streaming-kafka010-test.pom.xml</file>
      <file type="M">flink-end-to-end-tests.flink-streaming-kafka-test.pom.xml</file>
      <file type="M">flink-end-to-end-tests.flink-end-to-end-tests-common-kafka.pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  <bug fixdate="2019-11-31 01:00:00" id="11491" opendate="2019-1-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support all TPC-DS queries</summary>
      <description>A more detailed description can be found in FLIP-32.This issue describes the goal of supporting all TPC-DS queries on a unified runtime for batch and streaming.Operations might not be executed with the full performance until changes in other Flink core components have taken place.This includes external catalog support and Hive integration.</description>
      <version>None</version>
      <fixedVersion>1.10.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-end-to-end-tests.run-nightly-tests.sh</file>
      <file type="M">flink-end-to-end-tests.pom.xml</file>
      <file type="M">.travis.yml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-2-31 01:00:00" id="11495" opendate="2019-1-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove legacy job archiving paths</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.8.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.scala.org.apache.flink.runtime.jobmanager.MemoryArchivist.scala</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.webmonitor.history.JsonArchivist.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.history.FsJobArchivist.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.history.FsJobArchivistTest.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.history.HistoryServerArchiveFetcher.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2014-1-16 01:00:00" id="1169" opendate="2014-10-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Join Hint Specification in .join() Function is not Documented</summary>
      <description/>
      <version>0.7.0-incubating</version>
      <fixedVersion>0.9</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.operators.base.JoinOperatorBase.java</file>
      <file type="M">docs.programming.guide.md</file>
      <file type="M">docs.dataset.transformations.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-3-4 01:00:00" id="11802" opendate="2019-3-4 00:00:00" resolution="Implemented">
    <buginformation>
      <summary>Create TypeInfo and TypeSerializer for blink data format</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.util.SegmentsUtil.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.dataformat.TypeGetterSetters.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.dataformat.BinaryWriter.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.dataformat.BinaryString.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.dataformat.BinaryRow.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.dataformat.BinaryMap.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.dataformat.BinaryArray.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.pom.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.java.org.apache.flink.table.type.InternalTypeTest.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.TypeConverters.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.TimeType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.TimestampType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.StringType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.ShortType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.RowType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.PrimitiveType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.MapType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.LongType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.IntType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.InternalTypes.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.InternalType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.GenericType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.FloatType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.DoubleType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.DecimalType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.DateType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.CharType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.ByteType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.BooleanType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.AtomicType.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.java.org.apache.flink.table.type.ArrayType.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2014-10-27 01:00:00" id="1194" opendate="2014-10-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Wrong manifest entries and compiler configuration in Java Quickstarts</summary>
      <description>The quickstart archetype for java: sets wrong main class attribute in jar sets wrong main class attribute in fat jar is unnecessarily compilcated to enable for java 8 unnecessarily requires an extra m2e connector in eclipsePull request is pending</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>0.8.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-quickstart.flink-quickstart-java.src.main.resources.archetype-resources.pom.xml</file>
      <file type="M">flink-java8.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-11-4 01:00:00" id="1209" opendate="2014-11-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Forgetting to close an iteration leads to a confusing error message</summary>
      <description>The rror message you get is "Unknown operator - SolutionSetPlaceholder / WorksetPlaceholder / PartialSolutionPlaceholder"</description>
      <version>0.7.0-incubating,0.8.0</version>
      <fixedVersion>0.8.0,0.7.1-incubating</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.OperatorTranslation.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.operators.IterativeDataSet.java</file>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.PactCompiler.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-11-4 01:00:00" id="1210" opendate="2014-11-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve Error Message in Delta Iteratione when Next Workset does not Depend on Workset.</summary>
      <description>Currently, the job fails with a NullPointerException in the NepheleJobGraphGenerator</description>
      <version>0.7.0-incubating,0.8.0</version>
      <fixedVersion>0.8.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-compiler.src.main.java.org.apache.flink.compiler.PactCompiler.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-4-3 01:00:00" id="12100" opendate="2019-4-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Kafka 0.10/0.11 tests fail on Java 9</summary>
      <description>java.lang.NoClassDefFoundError: javax/xml/bind/DatatypeConverter at kafka.utils.CoreUtils$.urlSafeBase64EncodeNoPadding(CoreUtils.scala:294) at kafka.utils.CoreUtils$.generateUuidAsBase64(CoreUtils.scala:282) at kafka.server.KafkaServer$$anonfun$getOrGenerateClusterId$1.apply(KafkaServer.scala:335) at kafka.server.KafkaServer$$anonfun$getOrGenerateClusterId$1.apply(KafkaServer.scala:335) at scala.Option.getOrElse(Option.scala:121) at kafka.server.KafkaServer.getOrGenerateClusterId(KafkaServer.scala:335) at kafka.server.KafkaServer.startup(KafkaServer.scala:190) at org.apache.flink.streaming.connectors.kafka.KafkaTestEnvironmentImpl.getKafkaServer(KafkaTestEnvironmentImpl.java:430) at org.apache.flink.streaming.connectors.kafka.KafkaTestEnvironmentImpl.prepare(KafkaTestEnvironmentImpl.java:256) at org.apache.flink.streaming.connectors.kafka.KafkaTestBase.startClusters(KafkaTestBase.java:137) at org.apache.flink.streaming.connectors.kafka.KafkaTestBase.prepare(KafkaTestBase.java:100) at org.apache.flink.streaming.connectors.kafka.KafkaTestBase.prepare(KafkaTestBase.java:92) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:564) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24) at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48) at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48) at org.junit.rules.RunRules.evaluate(RunRules.java:20) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365) at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159) at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345) at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)Caused by: java.lang.ClassNotFoundException: javax.xml.bind.DatatypeConverter at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:582) at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:185) at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:496) ... 33 more</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-kafka-0.11.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-9-10 01:00:00" id="12481" opendate="2019-5-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make processing time timer trigger run via the mailbox</summary>
      <description>This sub-task integrates the mailbox with processing time timer triggering. Those triggers should now be enqueued as mailbox events and picked up by the stream task's main thread for processing.</description>
      <version>None</version>
      <fixedVersion>1.10.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-scala.src.test.scala.org.apache.flink.streaming.api.scala.AsyncDataStreamITCase.scala</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.async.AsyncWaitOperatorTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskmanager.DispatcherThreadFactory.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.SystemProcessingTimeServiceTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamMockEnvironment.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.TestProcessingTimeServiceTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.StreamTaskTimerTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.SystemProcessingTimeService.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTask.java</file>
      <file type="M">flink-state-backends.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBAsyncSnapshotTest.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-5-10 01:00:00" id="12483" opendate="2019-5-10 00:00:00" resolution="Implemented">
    <buginformation>
      <summary>Support (legacy) SourceFunctions with mailbox</summary>
      <description>We need to modify the current source stream task to run sources in a separate thread that is mutually exclusive to the mailbox mode thread. See section 4 in https://docs.google.com/document/d/1eDpsUKv2FqwZiS1Pm6gYO5eFHScBHfULKmH1-ZEWB4g</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.SourceStreamTask.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2014-2-19 01:00:00" id="1255" opendate="2014-11-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Problems with generic types in Scala API</summary>
      <description>the code below produces the following exception:Error:(47, 18) could not find implicit value for evidence parameter of type org.apache.flink.api.common.typeinfo.TypeInformation[K] data.groupBy { extractKey }Fixing K to Long made the code run though def groupCount[T, K](data: DataSet[T], extractKey: (T) =&gt; K): DataSet[(K, Long)] = { data.groupBy { extractKey } .reduceGroup { group =&gt; countBy(extractKey, group) } } private[this] def countBy[T, K](extractKey: T =&gt; K, group: Iterator[T]): (K, Long) = { val key = extractKey(group.next()) var count = 1L while (group.hasNext) { group.next() count += 1 } key -&gt; count }</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>0.9</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.faq.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-5-23 01:00:00" id="12600" opendate="2019-5-23 00:00:00" resolution="Implemented">
    <buginformation>
      <summary>Introduce planner rules to do deterministic rewriting on RelNode</summary>
      <description>This issue aims to introduce planner rules to to do deterministic rewriting on RelNode , rules include:1. FlinkLimit0RemoveRule that rewrites `limit 0` to empty Values2. FlinkRewriteSubQueryRule that rewrites a Filter with condition: `(select count from T) &gt; 0` to a Filter with condition: `exists(select * from T)` which could be converted to SEMI Join by FlinkSubQueryRemoveRule3. ReplaceIntersectWithSemiJoinRule that rewrites distinct Intersect to a distinct Aggregate on a SEMI Join.4. ReplaceMinusWithAntiJoinRule that rewrites distinct Minus to a distinct Aggregate on an ANTI Join.</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.runtime.utils.TestSinkUtil.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.runtime.utils.StreamTestSink.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.util.pojos.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.stream.sql.SubplanReuseTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.stream.sql.SortLimitTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.stream.sql.LimitTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.batch.sql.SubplanReuseTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.batch.sql.SortLimitTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.scala.org.apache.flink.table.plan.batch.sql.LimitTest.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.plan.stream.sql.SubplanReuseTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.plan.stream.sql.SortLimitTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.plan.stream.sql.LimitTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.plan.batch.sql.SubplanReuseTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.plan.batch.sql.SortLimitTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.test.resources.org.apache.flink.table.plan.batch.sql.LimitTest.xml</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.rules.logical.FlinkCalcMergeRule.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.rules.FlinkStreamRuleSets.scala</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.plan.rules.FlinkBatchRuleSets.scala</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-11-20 01:00:00" id="1265" opendate="2014-11-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>configure() not called with usercode classloader as context classloader</summary>
      <description>The configure() method of user functions is called with the system classloader as context classloader.Since, configure() is usercode, context classloader must be the usercode classloader to have acccess usercode classes.</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>0.7.1-incubating</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.execution.RuntimeEnvironment.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-6-31 01:00:00" id="12690" opendate="2019-5-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Introduce Table API Planner interface</summary>
      <description>The planner interface is the bridge between base API and different planner modules.</description>
      <version>None</version>
      <fixedVersion>1.9.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.operations.Operation.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  <bug fixdate="2015-1-9 01:00:00" id="1378" opendate="2015-1-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>could not find implicit value for evidence parameter of type TypeInformation</summary>
      <description>This is an example of one of many cases that I cannot get to compile with the scala API. I have tried using T : TypeInformation and : ClassTag but still cannot get it to work.//libraryDependencies += "org.apache.flink" % "flink-scala" % "0.7.0-incubating"////libraryDependencies += "org.apache.flink" % "flink-clients" % "0.7.0-incubating"import org.apache.flink.api.scala._import scala.util.{Success, Try}object Main extends App { val env = ExecutionEnvironment.getExecutionEnvironment val data: DataSet&amp;#91;Double&amp;#93; = env.fromElements(1.0, 2.0, 3.0, 4.0) def f&amp;#91;T&amp;#93;(data: DataSet&amp;#91;T&amp;#93;): DataSet[(T, Try[Seq&amp;#91;Double&amp;#93;])] = { data.mapPartition((iterator: Iterator&amp;#91;T&amp;#93;) =&gt; { val first = iterator.next() val second = iterator.next() Iterator((first, Success(Seq(2.0, 3.0))), (second, Success(Seq(3.0, 1.0)))) }) } val g = f(data) g.print() env.execute("Flink Test")}</description>
      <version>0.7.0-incubating</version>
      <fixedVersion>0.8.0,0.9</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.scala.org.apache.flink.api.scala.runtime.ScalaSpecialTypesSerializerTest.scala</file>
      <file type="M">flink-tests.src.test.scala.org.apache.flink.api.scala.runtime.ScalaSpecialTypesITCase.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.typeutils.OptionTypeInfo.scala</file>
      <file type="M">flink-tests.src.test.scala.org.apache.flink.api.scala.types.TypeInformationGenTest.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.codegen.TypeInformationGen.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.codegen.TypeDescriptors.scala</file>
      <file type="M">flink-scala.src.main.scala.org.apache.flink.api.scala.codegen.TypeAnalyzer.scala</file>
      <file type="M">flink-scala.src.test.scala.org.apache.flink.api.scala.runtime.KryoGenericTypeSerializerTest.scala</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.typeutils.runtime.KryoSerializer.java</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.api.common.typeutils.SerializerTestBase.java</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2019-10-26 01:00:00" id="14230" opendate="2019-9-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change the endInput call of the downstream operator to after the upstream operator closes</summary>
      <description>This ticket is for fixing the error of propagating "endInput" on the chain immediately after the input of the head operator is finished. Correctly, "endInput" of the downstream operator should be invoked only after closing the upstream operator.After "endInput" of the downstream operator on the chain is invoked correctly, we revert the changes of PR#9298 and PR#9221.</description>
      <version>None</version>
      <fixedVersion>1.10.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.TestBoundedTwoInputOperator.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.TwoInputStreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.TestBoundedOneInputStreamOperator.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.SourceStreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.OneInputStreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.OperatorChain.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.StreamTwoInputProcessor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamSource.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.streaming.api.ContinuousFileReaderOperatorITCase.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.OneInputStreamOperatorTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.async.AsyncWaitOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.async.AsyncWaitOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.ContinuousFileReaderOperator.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-2-26 01:00:00" id="14231" opendate="2019-9-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support the timers of the upstream operator with endInput properly</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.11.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.SystemProcessingTimeServiceTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.TimerService.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.TestProcessingTimeService.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.SystemProcessingTimeService.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.ProcessingTimeServiceImpl.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.ProcessingTimeService.java</file>
      <file type="M">flink-libraries.flink-state-processing-api.src.main.java.org.apache.flink.state.api.runtime.NeverFireProcessingTimeService.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.test.java.org.apache.flink.table.runtime.operators.wmassigners.WatermarkAssignerOperatorTest.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.runtime.operators.wmassigners.WatermarkAssignerOperatorFactory.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.runtime.operators.wmassigners.WatermarkAssignerOperator.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.runtime.operators.CodeGenOperatorFactory.java</file>
      <file type="M">flink-table.flink-table-planner-blink.src.main.scala.org.apache.flink.table.planner.codegen.OperatorCodeGenerator.scala</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.MockStreamingRuntimeContext.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.KeyedBroadcastOperatorTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.BroadcastOperatorTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.AbstractBroadcastStreamOperatorTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.StreamTaskTimerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.StreamTaskOperatorTimerTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.StreamSourceOperatorLatencyMetricsTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.SimpleOperatorFactory.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.async.AsyncWaitOperatorFactory.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.AbstractStreamOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.ContinuousFileReaderOperatorFactory.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.ContinuousFileReaderOperator.java</file>
      <file type="M">flink-fs-tests.src.test.java.org.apache.flink.hdfstests.ContinuousFileProcessingTest.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.test.java.org.apache.flink.table.runtime.operators.join.AsyncLookupJoinHarnessTest.java</file>
      <file type="M">flink-table.flink-table-runtime-blink.src.main.java.org.apache.flink.table.runtime.operators.window.WindowOperator.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.TestBoundedTwoInputOperator.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.OneInputStreamOperatorTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.TwoInputStreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.TestBoundedOneInputStreamOperator.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.SourceStreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.OneInputStreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.MailboxOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.async.AsyncWaitOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.async.AsyncWaitOperator.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.MockStreamTask.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.util.AbstractStreamOperatorTestHarness.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.OperatorChainTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.TestProcessingTimeServiceTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.operators.StreamOperatorChainingTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.OperatorChain.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamOperatorFactoryUtil.java</file>
      <file type="M">flink-libraries.flink-state-processing-api.src.main.java.org.apache.flink.state.api.output.BoundedStreamTask.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-10-9 01:00:00" id="14353" opendate="2019-10-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable fork-reuse for table-planner</summary>
      <description>Enable fork reuse for table-planner to half test times.</description>
      <version>None</version>
      <fixedVersion>1.10.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.pom.xml</file>
    </fixedFiles>
  </bug>
  
</bugrepository>