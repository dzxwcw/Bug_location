<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="FLINK">
  <bug fixdate="2018-8-6 01:00:00" id="10070" opendate="2018-8-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Flink cannot be compiled with maven 3.0.x</summary>
      <description>In FLINK-9986 we bumped the version of the git-commit-id-plugin to 2.1.14 which is incompatible with various maven versions, like 3.0.X.We can either bump the version to 2.2.4 to support all versions, or downgrade to 2.1.9 and rework FLINK-9986 with property exclusions.Additionally we should setup a test that checks the compatibility of Flink with various maven versions.</description>
      <version>1.5.3,1.6.0</version>
      <fixedVersion>1.5.3,1.6.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-runtime.pom.xml</file>
      <file type="M">flink-dist.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-8-6 01:00:00" id="10071" opendate="2018-8-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document usage of INSERT INTO in SQL Client</summary>
      <description>Document the usage of INSERT INTO statements in SQL.</description>
      <version>None</version>
      <fixedVersion>1.6.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.dev.table.sqlClient.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-11-14 01:00:00" id="10142" opendate="2018-8-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reduce synchronization overhead for credit notifications</summary>
      <description>When credit-based flow control was introduced, we also added some checks and optimisations for uncommon code paths that make common code paths unnecessarily more expensive, e.g. checking whether a channel was released before forwarding a credit notification to Netty. Such checks would have to be confirmed by the Netty thread anyway and thus only add additional load for something that happens only once (per channel).</description>
      <version>1.5.0,1.5.1,1.5.2,1.5.3,1.6.0,1.7.0</version>
      <fixedVersion>1.5.4,1.6.1,1.7.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.partition.consumer.RemoteInputChannelTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.partition.consumer.RemoteInputChannel.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.netty.PartitionRequestClient.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2018-10-29 01:00:00" id="10253" opendate="2018-8-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Run MetricQueryService with lower priority</summary>
      <description>We should run the MetricQueryService with a lower priority than the main Flink components. An idea would be to start the underlying threads with a lower priority.</description>
      <version>1.5.3,1.6.0,1.7.0</version>
      <fixedVersion>1.7.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.util.MetricUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.entrypoint.ClusterEntrypoint.java</file>
      <file type="M">flink-runtime.src.test.scala.org.apache.flink.runtime.akka.AkkaUtilsTest.scala</file>
      <file type="M">flink-runtime.src.main.scala.org.apache.flink.runtime.akka.AkkaUtils.scala</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.clusterframework.BootstrapTools.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.MetricOptions.java</file>
      <file type="M">docs..includes.generated.metric.configuration.html</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2018-1-31 01:00:00" id="10274" opendate="2018-8-31 00:00:00" resolution="Unresolved">
    <buginformation>
      <summary>The stop-cluster.sh cannot stop cluster properly when there are multiple clusters running</summary>
      <description>When you are preparing to do a Flink framework version upgrading by using the strategy shadow copy , you have to run multiple clusters concurrently,  however when you are ready to stop the old version cluster after upgrading, you would find the stop-cluster.sh wouldn't work as you expected, the following is the steps to duplicate the issue: There is already a running Flink 1.5.x cluster instance; Installing another Flink 1.6.x cluster instance at the same cluster machines; Migrating the jobs from Flink 1.5.x  to Flink 1.6.x ; go to the bin dir of the Flink 1.5.x cluster instance and run stop-cluster.sh ;You would expect the old Flink 1.5.x cluster instance be stopped ,right? Unfortunately the stopped cluster is the new installed Flink 1.6.x cluster instance instead!</description>
      <version>1.5.1,1.5.2,1.5.3,1.6.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.CoreOptions.java</file>
      <file type="M">docs..includes.generated.environment.configuration.html</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2018-8-18 01:00:00" id="9885" opendate="2018-7-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>End-to-end test: Elasticsearch 6.x connector</summary>
      <description>We have decided to try and merge the pending Elasticsearch 6.x PRs. This should also come with an end-to-end test that covers this.</description>
      <version>None</version>
      <fixedVersion>1.6.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.travis.mvn.watchdog.sh</file>
      <file type="M">flink-end-to-end-tests.test-scripts.test.streaming.elasticsearch.sh</file>
      <file type="M">flink-end-to-end-tests.test-scripts.elasticsearch-common.sh</file>
      <file type="M">flink-end-to-end-tests.flink-elasticsearch6-test.src.main.java.org.apache.flink.streaming.tests.Elasticsearch6SinkExample.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch.src.test.java.org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkITCase.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch.src.main.java.org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSink.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch.src.main.java.org.apache.flink.streaming.connectors.elasticsearch.Elasticsearch1ApiCallBridge.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch6.src.test.resources.log4j-test.properties</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch6.src.test.java.org.apache.flink.streaming.connectors.elasticsearch.EmbeddedElasticsearchNodeEnvironmentImpl.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch6.src.test.java.org.apache.flink.streaming.connectors.elasticsearch6.examples.ElasticsearchSinkExample.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch6.src.test.java.org.apache.flink.streaming.connectors.elasticsearch6.ElasticsearchSinkITCase.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch6.src.main.java.org.apache.flink.streaming.connectors.elasticsearch6.ElasticsearchSink.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch6.src.main.java.org.apache.flink.streaming.connectors.elasticsearch6.Elasticsearch6ApiCallBridge.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch6.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch5.src.test.java.org.apache.flink.streaming.connectors.elasticsearch5.ElasticsearchSinkITCase.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch5.src.main.java.org.apache.flink.streaming.connectors.elasticsearch5.ElasticsearchSink.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch5.src.main.java.org.apache.flink.streaming.connectors.elasticsearch5.Elasticsearch5ApiCallBridge.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch2.src.test.java.org.apache.flink.streaming.connectors.elasticsearch2.ElasticsearchSinkITCase.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch2.src.main.java.org.apache.flink.streaming.connectors.elasticsearch2.ElasticsearchSink.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch2.src.main.java.org.apache.flink.streaming.connectors.elasticsearch2.Elasticsearch2ApiCallBridge.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch-base.src.test.java.org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkTestBase.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch-base.src.test.java.org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBaseTest.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch-base.src.main.java.org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.java</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch-base.src.main.java.org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchApiCallBridge.java</file>
      <file type="M">docs.dev.connectors.elasticsearch.md</file>
      <file type="M">flink-end-to-end-tests.run-nightly-tests.sh</file>
      <file type="M">flink-end-to-end-tests.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-7-18 01:00:00" id="9886" opendate="2018-7-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Build SQL jars with every build</summary>
      <description>Currently, the shaded fat jars for SQL are only built in the -Prelease profile. However, end-to-end tests require those jars and should also be able to test them. E.g. existing META-INF entry and proper shading. We should build them with every release. If a build should happen quicker one can use the -Pfast profile.</description>
      <version>None</version>
      <fixedVersion>1.6.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-formats.flink-json.pom.xml</file>
      <file type="M">flink-formats.flink-avro.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.9.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.11.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kafka-0.10.pom.xml</file>
    </fixedFiles>
  </bug>
</bugrepository>