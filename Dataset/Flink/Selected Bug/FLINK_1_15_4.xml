<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="FLINK">
  
  <bug fixdate="2023-2-2 01:00:00" id="30878" opendate="2023-2-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>KubernetesHighAvailabilityRecoverFromSavepointITCase fails due to a deadlock</summary>
      <description>We're seeing a test failure in KubernetesHighAvailabilityRecoverFromSavepointITCase due to a deadlock:2023-02-01T18:53:35.5540322Z "ForkJoinPool-1-worker-1" #14 daemon prio=5 os_prio=0 tid=0x00007f68ecb18000 nid=0x43dd1 waiting on condition [0x00007f68c1711000]2023-02-01T18:53:35.5540900Z java.lang.Thread.State: TIMED_WAITING (parking)2023-02-01T18:53:35.5541272Z at sun.misc.Unsafe.park(Native Method)2023-02-01T18:53:35.5541932Z - parking to wait for &lt;0x00000000d14d7b60&gt; (a java.util.concurrent.CompletableFuture$Signaller)2023-02-01T18:53:35.5542496Z at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)2023-02-01T18:53:35.5543088Z at java.util.concurrent.CompletableFuture$Signaller.block(CompletableFuture.java:1709)2023-02-01T18:53:35.5543672Z at java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3313)2023-02-01T18:53:35.5544240Z at java.util.concurrent.CompletableFuture.timedGet(CompletableFuture.java:1788)2023-02-01T18:53:35.5544801Z at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1928)2023-02-01T18:53:35.5545632Z at org.apache.flink.kubernetes.highavailability.KubernetesHighAvailabilityRecoverFromSavepointITCase.testRecoverFromSavepoint(KubernetesHighAvailabilityRecoverFromSavepointITCase.java:113)2023-02-01T18:53:35.5546409Z at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) https://dev.azure.com/apache-flink/apache-flink/_build/results?buildId=45565&amp;view=logs&amp;j=bea52777-eaf8-5663-8482-18fbc3630e81&amp;t=b2642e3a-5b86-574d-4c8a-f7e2842bfb14&amp;l=61916The build failure happens on 1.16. I'm adding 1.17 and 1.15 as fixVersions as well because it might be due to some recent changes which were introduced with FLINK-30462 and/or FLINK-30474</description>
      <version>1.17.0,1.15.4,1.16.2</version>
      <fixedVersion>1.17.0,1.15.4,1.16.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.leaderelection.DefaultMultipleComponentLeaderElectionServiceTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.leaderelection.DefaultMultipleComponentLeaderElectionService.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2023-2-9 01:00:00" id="30972" opendate="2023-2-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>E2e tests always fail in phase "Prepare E2E run"</summary>
      <description>Installing required softwareReading package lists...Building dependency tree...Reading state information...bc is already the newest version (1.07.1-2build1).bc set to manually installed.libapr1 is already the newest version (1.6.5-1ubuntu1).libapr1 set to manually installed.0 upgraded, 0 newly installed, 0 to remove and 13 not upgraded.--2023-02-09 04:38:47-- http://security.ubuntu.com/ubuntu/pool/main/o/openssl1.0/libssl1.0.0_1.0.2n-1ubuntu5.10_amd64.debResolving security.ubuntu.com (security.ubuntu.com)... 91.189.91.39, 185.125.190.36, 185.125.190.39, ...Connecting to security.ubuntu.com (security.ubuntu.com)|91.189.91.39|:80... connected.HTTP request sent, awaiting response... 404 Not Found2023-02-09 04:38:47 ERROR 404: Not Found.WARNING: apt does not have a stable CLI interface. Use with caution in scripts.Reading package lists...E: Unsupported file ./libssl1.0.0_1.0.2n-1ubuntu5.10_amd64.deb given on commandline##[error]Bash exited with code '100'.Finishing: Prepare E2E run</description>
      <version>1.17.0,1.15.4,1.16.2,1.18.0</version>
      <fixedVersion>1.17.0,1.15.4,1.16.2,1.18.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.azure-pipelines.e2e-template.yml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2023-5-6 01:00:00" id="31743" opendate="2023-4-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Avoid relocating the RocksDB&amp;#39;s log failure when filename exceeds 255 characters</summary>
      <description>Since FLINK-24785 , the file name of the rocksdb LOG is generated by parsing the db path, when the db path is long and the filename exceeds 255 characters, the creation of the file will fail, so the relevant rocksdb LOG cannot be seen in the flink log dir.</description>
      <version>1.16.1,1.15.4</version>
      <fixedVersion>1.16.2,1.18.0,1.17.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-state-backends.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackendConfigTest.java</file>
      <file type="M">flink-state-backends.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.EmbeddedRocksDBStateBackendTest.java</file>
      <file type="M">flink-state-backends.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBStateBackend.java</file>
      <file type="M">flink-state-backends.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBResourceContainer.java</file>
      <file type="M">flink-state-backends.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.java</file>
      <file type="M">flink-state-backends.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.EmbeddedRocksDBStateBackend.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  
  <bug fixdate="2023-6-19 01:00:00" id="32379" opendate="2023-6-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Skip archunit tests in java1X-target profiles</summary>
      <description>When compiling to Java 11/17 byte code archunit fails; not sure why. Maybe it finds more/less stuff or signatures are represented differently.In any case let's use the Java 8 bytecode version as the "canonical" version and skip archunit otherwise.</description>
      <version>None</version>
      <fixedVersion>1.18.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-architecture-tests.flink-architecture-tests-production.src.main.java.org.apache.flink.architecture.rules.ConnectorRules.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2023-7-28 01:00:00" id="32457" opendate="2023-6-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>update current documentation of JSON_OBJECTAGG/JSON_ARRAYAGG to clarify the limitation</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.18.0,1.17.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.data.sql.functions.zh.yml</file>
      <file type="M">docs.data.sql.functions.yml</file>
      <file type="M">flink-table.flink-table-planner.src.test.resources.org.apache.flink.table.planner.plan.rules.logical.WrapJsonAggFunctionArgumentsRuleTest.xml</file>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.plan.rules.logical.WrapJsonAggFunctionArgumentsRuleTest.java</file>
    </fixedFiles>
  </bug>
  
  
</bugrepository>